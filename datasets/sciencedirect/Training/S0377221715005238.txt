@&#MAIN-TITLE@&#
A bicriterion algorithm for the allocation of cross-trained workers based on operational and human resource objectives

@&#HIGHLIGHTS@&#
A nonlinear bicriterion workforce allocation model.An exact algorithm for generating the complete Pareto efficient frontier.Recommendations for selecting solutions from the frontier.Illustrative examples using adaptations of test problems from the literature.A simulation study to evaluate the efficiency of the algorithm.

@&#KEYPHRASES@&#
Workforce assignment,Cross-training,Bicriterion programming,Algorithms,Services,

@&#ABSTRACT@&#
The problem of allocating a pool of cross-trained workers across multiple departments, units, or work centers is important for both manufacturing and service environments. Within the context of services, such as hospital nursing, the problem has commonly been formulated as a nonlinear assignment problem with an operationally-oriented objective function that focuses on the maximization of service utility as a function of deviations from target staffing levels in the departments. However, service managers might also deem it appropriate to consider human resource-oriented goals, such as accommodating worker preferences, avoiding decay of skill productivity, or the provision of training. We present a bicriterion formulation of the nonlinear worker assignment problem that incorporates both operational and human resource objective criteria. An algorithm for generating the entire Pareto efficient set associated with the bicriterion model is subsequently presented. A small numerical example is used to illustrate the bicriterion model and algorithm. A second example based on a test problem from the literature is also contained in the paper, and a third example is provided in an online supplement. In addition, a simulation experiment was conducted to evaluate the sensitivity of the algorithm to a variety of environmental characteristics.

@&#INTRODUCTION@&#
Abernathy, Baloff, Hershey, and Wandel (1973) described a hierarchical workforce planning model for service operations that is comprised of three stages (see also Thompson, 1999a, 1999b for an extended discussion of the latter two stages). The first stage (planning) occurs at the strategic level, where staffing levels are determined for each skill class of workers in each unit. The second stage (scheduling) involves the assignment of workers to schedules for a planning horizon that is commonly one to four weeks. The scheduling stage can require the assignment of employees to work and non-work days, as well as the daily shift assignments (starting times, break times, and ending times) for the employees. The third stage (allocation) concerns the short-term assignment of employees, perhaps on a day-to-day (or shift-to-shift) basis. The literature on the first and second stages of the workforce planning process is vast. Extensive reviews of workforce staffing and scheduling have been provided by Ernst, Jiang, Krishnamoorthy, and Sier (2004) and Alfares (2004). Van den Bergh, Beliën, De Bruecker, Demeulemeester, and De Boeck (2013) provide a more recent review that offers updates regarding contributions to the literature subsequent to the Ernst et al. (2004) and Alfares (2004) reviews. We refer readers to these resources for broad coverage of the workforce staffing and scheduling literature.Throughout the remainder of this paper, we restrict our focus to the third stage (allocation) of the workforce planning process. The critical nature of the allocation stage is underscored by the need for service managers to respond effectively to real-time changes that can arise with respect to demand (unanticipated changes in requirements) and/or capacity (e.g., absenteeism and tardiness). The problem of managing these changes is exacerbated when they can occur simultaneously for multiple departments or work centers. Accordingly, it is not surprising that a number of response measures for addressing real-time overstaffing and understaffing have been developed. These measures include temporary or on-call workers (Berman & Larson, 1994; Pinker & Larson, 2003), overtime (Campbell, 2012), and worker reassignment (Batta, Berman, & Wang, 2007). A review of real-time adjustment methods is provided by Hur, Mabert, and Bretthauer (2004).Included within the framework of the allocation stage is the single-period assignment of a cross-trained workforce across multiple departments (the term ‘departments’ is used generically and can be replaced by work centers, units, stations, or tasks, as warranted by the particular application). The workforce can be treated as a distinct body of flexible workers, such as a float pool in the context of hospital nursing, or consist of workers with a primary departmental assignment, as well as training in one or more secondary departments. The skill level of cross-trained employees need not be the same for each of their potential departmental assignments, and this can be reflected by differential productivity coefficients (Campbell, 1999; Easton & Rossin, 1991; Thompson & Goodale, 2007). Examples of the single-period allocation problem can occur in a variety of service settings, such as hospital nursing (Inman, Blumenfeld, & Ko, 2005), hotel management (Johnson, 1994), airport stations (Brusco, Jacobs, Bongiorno, Lyons, & Tang, 1995), call centers (Iravani, Kolfal, & Van Oyen, 2007), maintenance services (Jordan, Inman, & Blumenfeld, 2004), and postal services (Bard, 2004).Wolfe (1964) and Wolfe and Young (1965) presented one of the earliest assignment models for single period allocation of nurses to units of a hospital. Their model permitted limited substitution and sought to minimize costs. Hershey, Abernathy, and Baloff (1974) investigated a number of nurse allocation policies using Monte Carlo simulation. Drawing from earlier work at the scheduling level by Warner and Prawda (1972), Trivedi and Warner (1976) presented a branch-and-bound algorithm that attempted to minimize a quadratic cost function. Campbell (1999) extended the work of Trivedi and Warner (1976) by proposing a nonlinear workforce assignment problem (that maximized a quadratic utility function) for the allocation of a cross-trained labor force with varying levels of productivity. Campbell and Diaby (2002) presented a heuristic procedure for this formulation and Brusco (2008) subsequently developed an exact method. More recently, there has been a concerted effort to integrate decision making in the scheduling and allocation phases of the workforce planning process (Bard & Purnomo, 2005b; Campbell, 2011, 2012; Easton, 2011; Pinker, Lee, & Berman, 2010; Wright, Bretthauer, & Côté, 2006; Wright & Bretthauer, 2010; Wright & Mahar, 2013).Of particular relevance to our intended contribution are articles by Sayin and Karabati (2007) and Wright and Bretthauer (2010), which have examined the single-period allocation problem within a multiobjective programming framework. These authors recognized the inherent limitations of extant methods for assigning a pool of cross-trained workers with respect to the reliance on objective functions that consider only deviations from target staffing levels. Although service level criteria are appropriate for measuring the provided level of capacity relative to demand, they are wholly inadequate for accommodating any of a variety of human resource goals that might be pertinent to the assignment process. These goals include, but are not necessarily limited to, the following issues: (1) providing sufficient training and learning opportunities for workers in departments (Pinker & Shumsky, 2000), (2) mitigating the potential for productivity decay effects that might occur if workers are not assigned to departments with sufficient frequency (Eitzen & Panton, 2004), and (3) preserving fairness and equity with respect to worker preferences (Bard & Purnomo, 2005a; Warner, 1976). In light of these issues, it seemed natural to develop a workforce allocation model that can produce assignments that achieve both operational and human resource objectives.Sayin and Karabati (2007) presented a bicriterion formulation that considered both utility and skill improvement as objectives. The authors proposed a two-stage solution procedure. The first stage required the solution of a utility maximization problem similar to the formulation of Campbell (1999) and Campbell and Diaby (2002). The second stage sought to assign workers with the goal of maximizing skill improvement (based on a hyperbolic learning curve), subject to a constraint on the tolerable departure from the optimum utility value from the first stage. The quadratic objective functions for both stages were approximated by piecewise linear functions, and CPLEX (with a 1000-second time limit) was used to solve the resulting formulations. In light of the heuristic nature of both stages of the solution process, the resulting solutions could not be verified as Pareto efficient.Wright and Bretthauer (2010) presented a multicriterion integer programming model for allocation of nurses. The three objective criteria considered in the model were: (1) minimizing shortage plus surplus costs (i.e., maximizing utility), (2) maximizing the training (total productivity) of the nursing labor assigned to the units, and (3) maximizing nurse preferences for assignments. Essentially, the first two objectives involve a disentangling of productivity and service level from Campbell's (1999) model. In other words, whereas Campbell's (1999) model incorporates differential productivity of workers in the service utility computation, Wright and Bretthauer's (2010) model does not capture differential productivity in the utility (shortage/surplus) function, but considers it separately in the training objective function. Similar to the approach of Sayin and Karabati (2007), Wright and Bretthauer (2010) proposed a sequential solution procedure whereby the utility objective function was optimized first, the training objective was optimized second (subject to a constraint on utility based on the first stage), and preference was optimized third (subject to constraints on utility and training from the first two stages).The models of Sayin and Karabati (2007) and Wright and Bretthauer (2010) provided a significant contribution to the workforce allocation literature. The goal herein is to extend their work through the development of a formalized multiobjective programming framework (Ehrgott, 2005; Ehrgott & Wiecek, 2005). Sayin and Karabati (2007) and Wright and Bretthauer (2010) describe sequential methods that have the potential to produce a single Pareto efficient solution on any individual run; however, this is predicated on the assumption that CPLEX (used in both studies) will obtain globally-optimal solutions for the subproblems within the allotted time limit. Ideally, it would be desirable to employ a model and method whereby the complete Pareto efficient set of solutions can be obtained and made available to decision makers. Accordingly, our paper extends previous models and methods for workforce allocation (Brusco, 2008; Campbell, 1999; Campbell & Diaby, 2002; Trivedi & Warner, 1976) by presenting a bicriterion formulation of a nonlinear workforce assignment problem that captures both operational (service utility) and human resource (shift assignment desirability) goals. A bicriterion formulation that incorporates both a shortage-based utility function and a shift assignment desirability function would seem to be especially appropriate for a service industry such as hospital nursing, where shortages are expected to persist throughout the remainder of the decade and attractive assignments can help curb turnover (Wright & Mahan, 2013). In addition, an exact algorithm is presented for generating either the entire Pareto efficient set of assignment solutions, or only a portion of the efficient set if that is preferred. The new model and method are demonstrated using extensions of two examples from the literature.In Section 2 of this paper, we present the bicriterion formulation for the allocation of a cross-trained workforce. Section 3 describes the algorithm used to generate the Pareto efficient set of solutions to the bicriterion model, as well as a process for selecting a solution from the Pareto efficient set. Section 4 presents an application of the proposed model to a modified and extended version of a previously published example (Campbell, 1999; Campbell & Diaby, 2002). A hospital nursing example (Brusco, 2008) is offered in the online supplement. The results of a simulation study designed to investigate the efficiency of the algorithm is reported in Section 5. The paper concludes in Section 6 with a brief discussion of the findings and recommendations for future research.m = The number of departments (or work centers, units, etc.), indexed 1 ≤ j ≤ m.n = The number of workers in the labor pool, indexed 1 ≤ i ≤ n.pij= The productivity (0 ≤ pij≤ 1) of worker i in department j, for 1 ≤ i ≤ n and 1 ≤ j ≤ m.rj= The labor requirement in department j, for 1 ≤ j ≤ m.τij= The target number of shift assignments for worker i in department j, for 1 ≤ i ≤ n and 1 ≤ j ≤ m.dij= The desirability of assigning worker i to department j, which is defined as the reduction in the squared target staffing level for worker i in department j that would be realized from assignment of that worker to that department, for 1 ≤ i ≤ n and 1 ≤ j ≤ m. It is noteworthy that the value of dijis only equal to zero when τij= 0.(1)dij=max{(τij2−(τij−1)2),0}=max{2τij−1,0}∀1≤i≤nand1≤j≤m.wj= A weight reflecting the relative importance of staffing shortages in department j, for 1 ≤ j ≤ m.xij= 1 if worker i is assigned to department j and 0 otherwise, for 1 ≤ i ≤ n and 1 ≤ j ≤ m.X = A feasible solution to the allocation problem, X = [xijfor 1 ≤ i ≤ n and 1 ≤ j ≤ m], which is based on the readily apparent conditions that xij∈ {0, 1} for 1 ≤ i ≤ n and 1 ≤ j ≤ m and pij= 0 ⇒ xij= 0 for 1 ≤ i ≤ n and 1 ≤ j ≤ m, as well as the constraint that∑j=1mxij=1, for 1 ≤ i ≤ n. The first condition is that the assignment variables are binary, whereas the second forbids the assignment of workers to departments for which they are not trained. The constraint guarantees that each worker is assigned to exactly one department.Ψ = The set of all feasible solutions to the allocation problem.cj= The labor coverage in department j,cj=∑i=1npijxij, for 1 ≤ j ≤ m.There are many possible objective functions that can be established to measure the utility provided by an allocation of cross-trained workers to departments (see, for example, Billionnet, 1999; Brusco, 2008; Campbell, 1999; Easton, 2011; Hershey et al., 1974; Trivedi & Warner, 1976; Warner & Prawda, 1972; Wright & Bretthauer, 2010). Typically, these objective functions are defined based on deviations (shortages or surpluses) from the target staffing levels in the departments.Several authors have assumed conditions of a labor shortage whereby only a shortage component should be considered in the objective function (Brusco, 2008; Campbell, 1999; Campbell & Diaby, 2002; Sayin & Karabati, 2007). Their rationale is that surpluses, although possibly occurring in one or more departments, are not inherently a detriment to the provision of service and, accordingly, the goal should be to mitigate shortages to the greatest extent possible. The following objective function, which was originally developed by Campbell (1999), seeks to maximize service utility as a function of weighted shortages:(2)maxX∈Ψ:f(X)=∑j=1mwjrj2−∑j=1mwj(max{rj−cj,0})2.Brusco (2008) noted that the first term in Eq. (2) is a constant, and that the objective function is, effectively, the minimization of a weighted shortage function. He subsequently presented two variations of Eq. (2) that incorporate surplus costs or measure shortage as a percentage of demand. Wright and Bretthauer (2010) also adapted Campbell's (1999) criterion to include a linear function of surpluses. Nevertheless, to facilitate consistency with previous studies (Brusco, 2008; Campbell, 1999; Campbell & Diaby, 2002; Sayin & Karabati, 2007), we use Eq. (2) in our computational analyses.Although the objective criterion in Eq. (2) is conducive to the achievement of operational goals regarding the provision of service, it does not address properties pertaining to the desirability of the assignments for individual employees. There are several dimensions to consider when seeking to identify an appropriate measure of shift desirability: (1) The source (i.e., management, workers, or input from both) providing the desirability measure, (2) the criteria for the desirability measure, and (3) the process for collecting the input data for the desirability measure. As an example, consider the approach used by Warner (1976) for scheduling based on nursing preferences. In that particular context, the source of the desirability information was the worker (nurse). The criteria for constructing the desirability measure were penalty measures for various properties of a work stretch (e.g., single day on, single day off, too many work days in a row, etc.). The process for collecting the information was a constant sum-scale, whereby each nurse allocated 50 ‘penalty’ points to the various undesirable properties of the work stretch.Herein, we consider a straightforward linear function of the desirability of shift assignments based on the following criterion:(3)maxX∈Ψ:g(X)=∑i=1n∑j=1mdijxij.The establishment of the dijvalues can be obtained using any of a variety of possible approaches. For example, each worker could specify their desired preference for each shift. Unfortunately, such an approach is arbitrary, and it also fails to capture the potentially dynamic nature of shift assignments over time. In this paper, we adopt a different approach. We assume that service management (perhaps in consultation with the worker) determines the target number of assignments for each worker (i) in each department (j) for a particular time horizon. These target values, denoted τij, can be specified based on an assortment of human resource and operational criteria, such as worker career goals, assignment equity across workers, training and enhancement of the learning effect, or possibly mitigating the forgetting (or skill decay) effect.The desirability coefficients (dij) are linked to the target staffing levels (τij) as shown in Eq. (1). In this context, the dijvalues represent the reduction of sum-of-squared target staffing levels. For example, suppose that the target number of assignments for worker 1 to department 3 is equal to 5 (τ13 = 5) for the current planning period. If worker 1 is assigned to department 3, then the target number of assignments is reduced from 5 to 4, and the sum-of-squares for the target number of assignments is reduced by d13 = 2τ13 − 1 = 2(5) – 1 = 9, from 25 to 16.As is the case for the utility function in Eq. (2), there are many possible variations for the desirability function. However, this particular formulation has two advantages. First, and most importantly, it enables a viable model for a multiple-day planning horizon (e.g., a two- or four-week scheduling horizon) by permitting dynamic adjustment of the target staffing levels after each day's assignments. Second, it corresponds to reduction of a quadratic measure, which comports well with the utility function that is also quadratic in nature.A worker assignment X that maximizes the desirability function (Eq. (3)) can often produce a disastrous result for service utility (Eq. (2)). Similarly, an allocation that maximizes service utility can yield a rather poor result for the desirability function. To better understand the tradeoffs between these criteria, a bicriterion approach to the workforce allocation problem is necessary. An assignment X′ dominates assignment X if one of the following two conditions holds:Condition1:f(X′)>f(X)∧g(X′)≥g(X)Condition2:g(X′)>g(X)∧f(X′)≥f(X)The set of all nondominated (or Pareto efficient) solutions is denoted as Γ = {X1, X2, …, Xκ}, where κ = |Γ| is the number of solutions in the Pareto efficient set. Without loss of generality, we assume that the assignment solutions in the Pareto efficient set (Γ) are in descending order of f(X) values (or, equivalently, ascending order of g(X) values).There are several possible approaches for generating Pareto efficient solutions (Ehrgott, 2005; Ehrgott & Wiecek, 2005). One option is to combine the two objective functions into a single objective function using a convex combination of weights. This approach, which is sometimes identified as the weighted-sum, transformation, or scalarization method, would necessitate maximization of the following function:(4)maxX∈Ψ:αf(X)+(1−α)g(X),where 0 ≤ α ≤ 1. The limitations of the weighted-sum approach are twofold. First, identification of the appropriate value of α to use for the weighted-sum method is a somewhat ad hoc task. Second, the weighted-sum approach can fail to identify unsupported Pareto efficient solutions when used for multiobjective combinatorial optimization problems (see Ehrgott & Gandibleux, 2000; Ulungu & Teghem, 1994). An unsupported Pareto efficient solution is one for which there is no value of α that will result in that solution having a maximal value of Eq. (4), yet the solution still satisfies Conditions 1 and 2 for nondominated solutions as described above.A second approach to the generation of Pareto efficient solutions is the constraint method. With this approach, one of the two criteria is maximized subject to a constraint that guarantees the achievement of a certain threshold for the other criterion. A potential limitation of this approach is that it is sometimes difficult to ascertain precisely what the constraint thresholds should be. A third approach, the direct method, seeks to generate the entire Pareto efficient set via a direct search process that dynamically adds and removes solutions from the efficient set as appropriate. The direct approach has been criticized because of its propensity for computational infeasibility, as well as its potential for producing a rather large efficient set that yields too much information (Sayin & Karabati, 2007).In the next section, we present an algorithm that uses the ε-constraint method (a combination of the second and third approaches) to generate the complete Pareto efficient set. Our experience is that the algorithm typically provides the Pareto efficient set in modest computation time. Moreover, selection of good tradeoff solutions can often be accomplished via visual inspection of the resulting Pareto curves, even when the efficient set is large.The bicriterion algorithm for generating the efficient frontier uses a forward, depth-first, search of assignments of workers to departments. Following Brusco (2008), the input data are assumed to be pre-ordered such that workers with primary assignment in departments with greater workload are first in the ordered list. Ties among workers in the same primary department are broken based on descending order of productivity in the secondary department(s). One alternative reordering approach would be to dynamically update the ordering of the workers after each assignment, taking into account the changes in the departmental coverage. The computational demand of this approach, however, is prohibitive because of the intensiveness of sorting workers each time assignments are updated. A second approach that might be more computationally feasible is to consider reordering the workers after each Pareto efficient solution is generated, perhaps incorporating information pertaining to shortages (i.e., f(X) values) or desirability rankings (i.e., g(X) values) from the previous solution. In any case, although we acknowledge that there are apt to be alternative reordering approaches that could improve efficiency, computational feasibility of the algorithm is ultimately governed by n, m, and the number of departments for which the workers are trained.The algorithm is repetitive in nature, initially assumes a lower bound of zero for the desirability criterion, and systematically increases this bound for subsequent repetitions. At each repetition, the algorithm seeks to maximize the utility criterion as its primary objective and desirability as the secondary objective; however, the lower bound constraint for desirability must be achieved for a feasible solution to be obtained. The algorithm terminates when a feasible solution cannot be achieved for the current repetition (i.e., there is no feasible solution that meets the desirability function value associated with the constraint). Indeed, the identification of the termination condition is readily apparent because the maximization of g(X) can be trivially obtained by assigning each worker to a department for which they have their greatest level of desirability. Of course, if workers have the same maximum desirability for multiple departments, then the effects of assignments on productivity must be evaluated as well. The efficient execution of the algorithm is assisted by several pruning rules. A description of the algorithm requires the following additional notation to augment the descriptive terminology provided in Section 2.1.κ = The number of solutions contained in the Pareto efficient set, this number is updated in the algorithm as additional Pareto efficient solutions are found.λ = A scalar that represents the index of the worker currently under consideration for assignment to a department (1 ≤ λ ≤ n). When λ = n, a complete assignment of all workers has been made; however, for λ < n, the current solution is a partial assignment.y(i) = An array containing the departmental assignments for the workers (for 1 ≤ i ≤ λ). The y(i) array is a more convenient representation of the departmental assignments for the algorithm description, but is straightforwardly mapped to xijby the relationship: ∀1 ≤ i ≤ n, y(i) = k ⇒ (xik= 1 ∧ xij= 0 ∀1 ≤ j ≠ k ≤ m).ξ = The contribution to the desirability function associated with the current assignment of λ workers.fLB = The current lower bound for the utility function.gLB = The current lower bound for the desirability function.δij= An upper bound on the maximum possible contribution to coverage of the labor requirement in department j that can be achieved from the assignment of workers after worker i in the ordered list of workers:(5)δij=∑h=i+1nphj∀1≤i≤nand1≤j≤m.ηi= An upper bound on the maximum contribution to the desirability objective that can be achieved from the assignment of workers after worker i in the ordered list of workers:(6)ηi=∑h=i+1nmax1≤j≤m{dhj}∀1≤i≤n.gT= A minimum threshold on the desirability function that must be attained by the solution to the assignment problem.βhijk= Dominance parameters that will prevent the assignment of a worker with index i to department k, if there is a worker with index h (h < i) that has already been assigned to department j (k ≠ j), such that workers h and i have the same productivity in both departments j and k, worker i has greater desirability to work in j than h, and h has greater or equal desirability to work in k than i. The rationale is that the productivity provided to departments j and k will be exactly the same regardless of whether h is assigned to j and i assigned to k, or h is assigned to k and i is assigned to j; however, a superior contribution to desirability is afforded by the latter of these two options (i.e., h assigned to k and i assigned to j). Accordingly, there is no merit in pursuing the partial solution where h is assigned to j and i is assigned to k. A formal statement of the parameters is:βhijk= 1 if (h < i) ∧ (j ≠ k) ∧ (phj= pij) ∧ (phk= pik) ∧ (dij> dhj) ∧ (dhk≥ dik), and 0 otherwise, ∀ 1 ≤ h < i ≤ n and 1 ≤ j ≠ k ≤ m.Step 0. Initialize Pareto efficient set. Set κ = 0, gT= 0, and Γ = Ø.Step 1. Initialize parameters. Set λ = 0, fLB = 0, gLB = 0, ξ = 0, cj= 0 ∀ 1 ≤ j ≤ m, y(i) = 0 ∀ 1 ≤ i ≤ n.Step 2. Advance worker index. Set λ = λ + 1, k = 1, and y(λ) = k.Step 3. Update coverage and desirability sums. Set ck= ck+ pλkand ξ = ξ + dλk.Step 4. Pruning tests.Step 4a. Productive assignment. If pλk= 0, then go to Step 7.Step 4b. Dominance. If βiλjy(λ) = 1 for any i < λ, then go to Step 7.Step 4c. Desirability threshold. If ξ + ηλ < gT, then go to Step 7.Step 4d. Utility bound. Compute upper bound fUB as follows:(7)fUB=∑j=1mwjrj2−∑j=1mwj(max{rj−cj−δλj,0})2.Compare to lower bound: If fUB < fLB, then go to Step 7.Step 5. Complete or partial assignment? If λ < n, go to Step 2; otherwise proceed to Step 6.Step 6. Update incumbent. If [((fUB > fLB) ∧ (ξ ≥ gT)) ∨ ((fUB = fLB) ∧ (ξ > gLB))], then set fLB = fUB, and gLB = ξ, and defineX*=[xij*]:xij*=1if y(i) = j andxij*=0otherwise, ∀ 1 ≤ i ≤ n and 1 ≤ j ≤ m.Step 7. Dispensation. If k = m, then go to Step 9; otherwise proceed to Step 8.Step 8. Branch right on department index.Step 8a. Reduce sums for current assignment. Set ck= ck– pλkand ξ = ξ – dλk.Step 8b. Assign to next department (on right). Set k = k + 1 and y(λ) = k.Step 8c. Update sums for new assignment. Set ck= ck+ pλkand ξ = ξ + dλk.Step 8d. Perform pruning tests. Return to Step 4.Step 9. Depth retraction.Step 9a. Reduce sums for current assignment. Set ck= ck– pλkand ξ = ξ – dλk.Step 9b. Back up to previous worker. Set λ = λ – 1.Step 9c. Enumeration complete? If λ = 0, then go to Step 10; otherwise, set k = y(λ) and return to Step 7.Step 10. Update Pareto efficient set. If fLB = 0, then proceed to Step 11; otherwise, set κ = κ + 1, Γ = Γ ∪ X*, gT= gLB + 1, and return to Step 1.Step 11. Terminate. Return Γ as the complete Pareto efficient set.A flowchart of the algorithm is provided in Fig. 1. The algorithm begins in Step 0 with the initialization of an empty Pareto efficient set and the specification of a lower bound of zero for the desirability function. Step 1 initializes the parameters for the algorithm. Step 2 advances the pointer index, λ, and assigns worker λ to the first department. Step 3 increments the departmental coverage and assignment desirability sums for the current partial solution. Step 4 is the most critical step of the algorithm. Partial assignments are pruned if a worker has no productivity for the current department (Step 4a), if the current assignment could be favorably swapped with a previously made assignment (Step 4b), if the desirability threshold cannot possibly be attained (Step 4c), or if the current lower bound on the utility function cannot be achieved (Step 4d). Step 5 determines whether the current assignment is partial or complete and directs processing accordingly. Step 6 updates the incumbent solution if a complete assignment satisfies the desirability threshold and has a better utility function than the incumbent, or if the utility functions are equal and the desirability function is better than that of the incumbent. Step 7 determines whether a ‘branch right’ (i.e., assigning the current worker to the next department) should occur in Step 8, or if depth retraction (i.e., stepping back to the previous worker in the list) is needed in Step 9. If λ = 0 in Step 9, then enumeration is complete and control passes to Step 10. If fLB > 0, then the Pareto efficient set is augmented, the threshold for the desirability function is incremented, and control is passed to Step 1. If fLB = 0, then the algorithm terminates in Step 11 with the return of the complete Pareto efficient set. The rationale is that fLB is only updated from its initialized value of zero in Step 1 if a new incumbent solution is found at Step 6. However, if this is impossible because the minimum threshold on the desirability function cannot be achieved, then the resulting problem is infeasible and the Pareto efficient set is complete.For each cycle of the algorithm through Steps 1–9, the computational requirement in the worst-case scenario is complete enumeration of all possible assignments of workers to departments. Assuming that each of the n workers can be assigned to any of the m departments, the problem is one of partitioning n objects into m clusters. The number of partitions in the solution space can be computed as follows (see, for example, Brusco & Stahl, 2005, p. 18):(8)ϕ(n,m)=∑k=0m(−1)k(mk)(m−k)n.Generally, the expression on the right-side of Eq. (8) is multiplied by 1/m! to eliminate the redundancy associated with all m! possible ways to label the clusters. However, this is not appropriate here because the labels of the clusters are not arbitrary, but correspond to individual and distinct departments. As an illustration, in the case of n = 48 workers and m = 3 departments, there are ϕ(48, 3) ≈ 3.19066 × 1023 partitions. The pruning rules in Step 4 of the algorithm are designed to circumvent complete enumeration to the greatest extent possible. For example, pruning rule 4a eliminates the need to evaluate partitions where workers are assigned to departments for which they have no productivity. Rule 4b avoids assignments where an improved solution could be obtained by swapping one or more pairs of departmental assignments, and rules 4c and 4d prevent the pursuit of assignments that cannot satisfy thresholds for desirability and utility, respectively.The algorithm was implemented in Fortran 90 on a desktop microcomputer using a 3.4 gigahertz Intel Core i7-2600 processor with 8.0 gigabytes of RAM. Our experience is that the algorithm is computationally scalable for problems with up to n = 48 workers and m = 6 departments. Upon termination of the algorithm, the complete Pareto efficient set of assignments is provided. For purposes of evaluating the solutions in the Pareto efficient set, we have found it convenient to convert the raw objective function values to percentage deviations from the optimal objective function value for each criterion. For example, denoting f* and g* as the globally-optimal objective function values for the single-objective utility and desirability optimization problems, respectively, the percentage deviations for a given solution, X, would be (f* − f(X))/f* and (g* − g(X))/g* for utility and desirability, respectively. This enables a direct comparison of the objective criteria, as well as the computation of the distance of solutions from a (0, 0) origin.The small exampleproblem (n = 4 workers and m = 3 departments) in Table 1 will be used to illustrate the algorithm. The workers have been pre-ordered based on departmental workload and productivity as described in Section 3.1. The bicriterion algorithm was applied to the small test problem. The progression through the steps of the algorithm to obtain the first Pareto efficient solution is displayed in Table 2. Similarly, the steps to generate the second (and final) Pareto efficient solution are shown in Table 3. Table 3 also shows the final few steps that result in termination of the algorithm after the failure to find a third Pareto efficient solution. The leftmost column of Tables 2 and 3 contains the line number (line) to facilitate easier identification in the discussion. The remaining columns present κ, gT, λ, k, the assignment vector (y = [y(1), y(2), y(3), y(4)]), fUB, ξ, ηλ, fLB, gLB, and the steps of the algorithm that are performed to get to the next line. For continuity, the last step of the sequence for a line is repeated as the first step in the sequence for the next line.The algorithm begins with the initialization of κ = 0 and gT= 0 and, subsequently, begins the process of finding the first Pareto efficient solution. The first pruning operation, based on Step 4a, occurs at line 4 because y(4) = 1 is prohibited due the fact that worker 4 has zero productivity in department 1. The first feasible assignment, y = [1,1,1,2], is found in line 5, and this solution yields fLB = 4.81 and gLB = 16. Better assignments are found at lines 10 and 20. The latter of these, which corresponds to the assignment y = [1,2,3,2] with fLB = 6.24 and gLB = 18, is installed as the first Pareto efficient solution at Step 10 (see line 31). Also at Step 10, κ is incremented to 1, gTis set to gLB = 18 + 1 = 19, and processing then returns to Step 1 to begin the search for the second Pareto efficient solution, which is found at line 46 in Table 2. The assignment for the second Pareto efficient solution is y = [1,2,3,3] with fLB = 5.76 and gLB = 20. This solution is installed as the second Pareto efficient solution at line 50, κ is incremented to 2, gTis set to gLB = 20 + 1 = 21, and processing then returns to Step 1 where fLB and gLB are reset to zero and the search begins for the third Pareto efficient solution. However, achievement of gT≥ 21 is quickly identified as impossible by pruning rule Step 4c at lines 52 and 53, and line 54 shows pruning based on Step 4a. Therefore, when Step 10 is reached at line 55, the algorithm proceeds to termination at Step 11 because fLB = 0 as no solution has been found.An example of the pruning rule of Step 4b occurs at line 24, where y(1) = 2 and y(2) = 1. To explain the rationale for the pruning step, we first note that workers 1 and 2 have the same productivity for both departments 1 and 2. Moreover, workers 1 and 2 have the same desirability for department 1; however, worker 2 has a greater desirability (d22 = 5 > d12 = 3) than worker 1 for department 2. Accordingly, line 24 is dominated by line 12 where y(1) = 1 and y(2) = 2. Both lines 12 and 24 would make the same productivity contributions to departments 1 and 2. However, line 12 would yield desirability of 5 (d11 = 5 and d22 = 5) for both departments, whereas line 24 would yield desirability of 5 (d21 = 5) for department 1 but desirability of only 3 for department 2 (d12 = 3). Therefore, there is no need to pursue the partial solution at line 24 (with y(1) = 2 and y(2) = 1) any further because it cannot possibly lead to a better result than what was already explored when pursuing the partial solution at line 12.An example of pruning rule 4c occurs at line 34. The partial solution with λ = 3 and y(1) = y(2) = y(3) = 1 yields ξ = 5 + 5 + 3 = 13, and ηλ= 5. Therefore, ξ + ηλ= 18, which is less than gT= 19 and, accordingly, the partial solution is pruned. An example of pruning rule 4d occurs at line 28. The partial solution with λ = 3, y(1) = y(2) = 2 and y(3) = 3 results in a value of fUB = [1.72 + 1.62 + 1.22] – [max{1.7-0-0,0}2 + max{1.6-1.6-0.8,0}2 + max{1.2-0.8-0.6,0}2] = 6.89 − 2.89 = 4. Therefore, because fUB = 4 < fLB = 6.24, the partial solution is pruned.It should be noted that small test problems, particularly those with only two skill classes per worker, can often be solved more easily by using a direct search approach. One such approach is to begin with the solution on the Pareto efficient frontier with the maximum value of g(X). To illustrate, consider the raw data in Table 1 and observe that the maximum desirability assignments for workers 1, 3, and 4 are y(1) = 1, y(3) = 3, and y(4) = 3, respectively. Worker 2 could be assigned to either department 1 or department 2 to achieve maximum desirability. However, in terms of productivity, it is clear that the assignment of worker 2 to department 2 is preferable (otherwise, that department would have no coverage and a large squared shortage). Accordingly, the assignment y = [1, 2, 3, 3] with f(X) = 5.76 and g(X) = 20 is obtained, which corresponds to the second Pareto efficient solution found at line 46 in Table 2. Next, we seek to improve productivity at the expense of the smallest possible sacrifice in desirability (which here is a reduction of two from 20 to 18 because all the desirability values are either 5 or 3). We note that the assignment y = [1, 2, 3, 3] yields shortages of 0.7 in department 1 and 0.8 in department 2. To reduce the larger shortage in department 2, we move worker 4 from department 3 to department 2, thus eliminating the shortage in department 2 and creating a smaller shortage of 0.4 in department 3. The net improvement in f(X) is 0.82 – 0.42 = 0.48, which is realized for a reduction of two in the value of g(X) from the less desirable assignment of worker 4. This new assignment y = [1, 2, 3, 2] with f(X) = 6.24 and g(X) = 18 is recognized as the first Pareto efficient solution found at line 20 in Table 1. Any attempt to further improve productivity at the expense of a reduction in desirability will fail and, accordingly, the Pareto efficient set has been established in a more efficient fashion. An analogous approach is apt to be effective for conditions, where each worker has non-zero productivity in only two departments, but is likely to be less efficacious for the example in Section 4 where all workers can work in all departments.Campbell (1999) presented an instance of the nonlinear workforce assignment problem that consists of n = 20 workers and m = 4 departments (see also Campbell & Diaby, 2002 and Brusco, 2008). In the original example, each worker has the flexibility to work in exactly two of the m = 4 departments, but has zero productivity in the other two departments. It is quite realistic to observe this type of limited flexibility in practice for two reasons: (1) the potential adverse effects on quality due to excessive cross-training (Eitzen & Panton, 2004; Jordan et al., 2004; Nembhard, 2001; Pinker & Shumsky, 2000), and (2) the fact that limited cross-training is often sufficient to capture all (or nearly all) of the potential improvements in utility that could accrue from complete cross-training (Brusco & Johns, 1998; Campbell, 1999; Easton, 2011; Inman et al., 2005).The reasonableness of Campbell's (1999) example notwithstanding, it is true that the restriction that each worker has nonzero productivity in only two departments does simplify the bicriterion optimization problem considerably. To present a more formidable challenge for the bicriterion algorithm, we adapt and extend Campbell's (1999) example to enable each worker to have nonzero productivity in all m = 4 departments. We also augment Campbell's (1999) test problem by adding a matrix, [τij], for the target number of shift assignments for each worker in each department. Because the desirability measures, dij, are obtained directly from the τijparameters using Eq. (1), we refer to this matrix as the desirability pattern. The data for the modified version of Campbell's (1999) test problem are displayed in Table 4. Although it is debatable as to whether the modified test problem is more realistic than the original, there is no question that it is more difficult because of the expansion of the set of feasible solutions.The bicriterion algorithm was applied to the modified version of Campbell's (1999) test problem. The algorithm required 421 seconds to generate the Pareto efficient set (containing 25 solutions). A tabular presentation of the results is provided in Table 5, whereas a graph of the Pareto frontier is offered in Fig. 2.It is interesting to consider the changes in worker assignments that occur between adjacent Pareto efficient solutions in the far right hand column of Table 5. For example, when moving from solution 2 to solution 3, only one worker assignment changes (worker 12 moves from department 1 in solution 2 to department 2 in solution 3). However, when moving from solution 1 to solution 2, four workers (workers 7, 10, 12, and 18) change membership, which comprises 20 percent of the workforce. When moving from solution 17 to 18, six workers (8, 9, 10, 11, 17, 18) change membership, which represents 30 percent of the workforce. Across all 24 pairs of adjacent solutions, the average change in membership was 2.83 workers, and there were five instances where the change involved four or more workers.Moving from left to right (and top to bottom) in Fig. 2 reveals gaps between solutions 2 and 3, 4 and 5, 5 and 6, and 9 and 10. After solution 10, desirability improves at a uniform rate. Solution 10 yields f(X) = 189.29632, which is only 1.45 percent less than the optimal utility value of f(X) = 192.08076 for solution 1. However, a substantial 34.21 percent improvement in desirability, from g(X) = 76 for solution 1 to g(X) = 102 for solution 10, is realized for this small sacrifice in utility. The assignment of workers to departments corresponding to solution 10 is provided in Table 4 via the bold highlighting. For example, worker 1 is assigned to department 1, workers 2 and 3 are assigned to department 3, etc. The coverage values (cj) for each department associated with this solution are shown at the bottom of Table 4. The cjvalue for each department is obtained by summing the productivity values in bold type for that department. It is straightforward to apply the wj, cj, and rjvalues from Table 4 to the right-hand-side of Eq. (2) to compute f(X) = 189.29632. Likewise, g(X) = 102 can be obtained by computing the sum (across all workers) of (2τ − 1), where τ for each worker is the desirability value highlighted in bold in Table 4.Another key takeaway from this example is that the computational demand for the bicriterion algorithm depends on a variety of factors, which supports the findings of the simulation study in the article. Like most partitioning problems, the computational demand tends to increase as a function of n and m. However, for a fixed n and m, the number of secondary skill classes also has a profound effect on computation time. When we applied the bicriterion algorithm to Campbell's (1999) original test problem, which allowed workers only one secondary department (i.e., each worker has nonzero productivity in only two departments), the computation time was less than one second. Contrastingly, for the modified version considered herein, where workers have three secondary departments (i.e., each worker has nonzero productivity in all four departments), the result is a much more difficult optimization problem requiring roughly 7 minutes of solution time. Fortunately, situations where all workers can work in all departments is not the norm.A simulation experiment was completed by manipulating eight design features at two levels each. The first seven design features were selected by drawing from similar simulation experiments reported by Campbell (1999), Campbell and Diaby (2002), and Brusco (2008), whereas the eighth is unique to the inclusion of the desirability criterion. The first design feature, number of departments, was tested at levels of m = 3, and m = 6. The levels for the second design feature, number of workers per department, were 4 and 8. Together, the levels of the first two design features produce problems that range from n = 3(4) = 12 to n = 6(8) = 48 workers. This range of workforce sizes is not only comparable to problems encountered in earlier studies (e.g., Brusco, 2008), but is also sufficiently large to measure the computational performance of the branch-and-bound algorithm. The number of cross-trained (secondary) departments for each worker was the third design feature and was tested at levels of 1 and 2. The case of two secondary departments, in conjunction with the setting of m = 3 departments, results in a condition where each worker can be assigned to each of the three departments. It is not possible to have more than two secondary departments when m = 3. There are two other plausible reasons for considering only two secondary departments: (1) the adverse effects of forgetting and service quality reduction that can accrue from excessive cross-training (Jordan et al., 2004; Nembhard, 2001; Pinker & Shumsky, 2000), and (2) the fact that limited cross-training has been shown to yield productivity/utility benefits comparable to what can be achieved with full cross-training (Brusco & Johns, 1998; Campbell, 1999; Easton, 2011; Inman et al., 2005).The fourth design feature, minimum productivity in secondary departments, was tested at levels of 0.4 and 0.8. The minimum productivity level of 0.4 reflects a broader range of productivity levels of workers, which might be appropriate for a developing cross-training program. Contrastingly, a minimum productivity level of 0.8 produces less variability in the productivity coefficients and more ties among them, which should result in a greater computational challenge for the bicriterion algorithm. The levels for the fifth design feature, nominal shortage (i.e., the average shortage across all departments), were 10 percent and 20 percent. These levels, originally used by Campbell (1999), seem reasonable because a shortage level too far below 10 percent might dampen the value of cross-training, whereas a setting too far above 20 percent could yield catastrophic shortages that cannot be satisfactorily alleviated by any degree of cross-training. The coefficient of variation (CV) for departmental demand was the sixth design feature and was tested at levels of CV = 0.3 and CV = 0.6. This design feature controls the variation in departmental demand relative to the nominal shortage level. It is conceivable that settings far outside this range established by Campbell (1999) could result in either a lack of a meaningful distinction among the departments with respect to their shortages, or too much differentiation in the departmental shortages. The seventh design feature, departmental weights, was tested at two levels: equal weights (wj= 1 for 1 ≤ j ≤ m) and random weights drawn uniformly from the interval [0.5, 1.5]. The first level of this design feature is likely the typical default, whereas the latter would allow a situation where utility in one department was up to three times more important than utility in another department.The eighth design feature pertained to the distribution range for the desirability coefficients. Specifically, for each worker, and in each department for which the worker has nonzero productivity, the τijvalues were drawn as integers from a uniform distribution of either [0, 5] or [0, 50]. As there was no extant guideline in the literature for these design feature levels, the settings were selected to reflect different approaches that might be used to specify shift desirability. The [0, 5] setting could represent a situation where the number of desired shifts in a department was specified, whereas the [0, 50] measurement might suggest some type of worker point allocation to indicate desirability.A Fortran 90 program was written to generate the 28 = 256 test problems corresponding to the cells of the experimental design. The algorithm described in Section 3 was applied to each of these test problems. For each problem, the two primary performance measures of interest were: (1) total computation time for the algorithm, and (2) the total number of solutions in the Pareto efficient set.The 192 test problems consisting of m = 3 with 4 workers per department, m = 3 with 8 workers per department, or m = 6 with 4 workers per department were solved rapidly. The maximum computation time across these 192 problems was .05 seconds. The sizes of the Pareto efficient sets for these 192 problems ranged from 3 to 49, with a mean of 18.1.In light of the relative lack of difficulty associated with the 192 smaller test problems (n ≤ 24), we narrowed our focus to the 64 test problems with m = 6 departments and 8 workers per department (i.e., those problems with a total of n = 48 workers). In addition, the analysis was expanded by applying the branch-and-bound algorithm to each of these 64 problems for four additional times, each time disabling one of the pruning rules (Step 4a, 4b, 4c, and 4d). Because the exclusion of a pruning rule dramatically increases computation time in some cases, a computation time limit of 1800 seconds (30 minutes) was imposed.The number of solutions in the Pareto efficient set, along with the computation time for each implementation of the branch-and-bound algorithm, is provided in Table 6 for each of the 32 test problems with one secondary skill class. Similar results for the 32 test problems with two secondary skill classes are displayed in Table 7. Across these two tables, the sizes of the Pareto efficient sets vary dramatically, ranging from 17 to 165, with an average of 66.2. Likewise, there is a substantial disparity in computation times. For the complete algorithm using all pruning rules, the computation times ranges from 0.53 to 626.76 seconds, with an average of 79.45. This suggests that some 48-worker problems are hard to solve, and some are easy to solve. It is interesting to note that the correlation between computation time and the size of the Pareto efficient set is negative and significant (r = −.537, p < .01). In other words, the harder problems in the test suite tend to be those with fewer Pareto efficient solutions.The disparity between the computation times in Tables 6 and 7 reveals that the number of secondary skill classes was an important design feature for measuring problem difficulty. The average computation time for the one secondary skill class problems in Table 6 is 5.83 seconds (maximum of 19.70), whereas the average for the two secondary skill class problems in Table 7 is 153.70 seconds (maximum of 626.76). The minimum productivity, coefficient of variation for demand, and nominal shortage design features also profoundly affected computation times. The average computation time for the 0.8 minimum productivity condition (127.53 seconds) was more than four times greater than the average for the 0.4 condition (31.37 seconds). The average time for CV = 0.3 (118.11 seconds) was nearly three times greater than the average time for CV = 0.6 (40.79 seconds). Similarly, the average computation time for the 20 percent nominal shortage condition (113.98 seconds) was nearly three times greater than the average for the 10 percent condition (44.92 seconds). Computation time was not strongly affected by either the department weight or desirability coefficient distribution design features. The average computation times for equal and uniformly distributed departmental weights were nearly identical at 79.58 and 79.32 seconds, respectively. The average computation time of 83.09 seconds for problems with desirability coefficients on the interval [0,5] differed slightly from the average of 75.81 seconds for problems where the interval was [0,50]; however, this difference is not significant (at the .05 level) because of the large variation in computation times.The results in Tables 6 and 7 indicate that the elimination of either pruning rule 4c or pruning rule 4d dramatically increased solution difficulty, as their removal always increased computation time beyond 1800 seconds. When rule 4c is eliminated, only the productivity bounds are used, whereas when 4d is removed, only the desirability bounds are used. Clearly, the efficiency of the algorithm requires both rules. For 30 of the 32 test problems with only one skill class, the complete Pareto efficient set was obtained within the 1800-second time limit despite the elimination of pruning rule 4a. Nevertheless, for these 30 problems, the computation time when rule 4a was removed averaged 78 times greater than the computation time for the complete algorithm with all rules. The results in Table 7 reveal that the removal of pruning rule 4a precluded the generation of the Pareto efficient set within the 1800-second time limit for all problems with two secondary skill classes. The elimination of pruning rule 4b had little to no impact for some problems, yet a profound impact for others. Table 6 reveals that all 32 test problems with only one secondary skill class were solved within 100 seconds after removal of rule 4b. Moreover, the computation time when rule 4b was removed averaged only 1.56 times greater than the computation time for the complete algorithm with all rules. Contrastingly, the removal of pruning rule 4b was much more detrimental for the problems with two secondary skill classes in Table 7. For 16 of the 32 problems in Table 7, the removal of pruning rule 4b precluded the generation of the Pareto efficient set within the 1800-second time limit. For the remaining 16 problems in Table 7, the computation time when rule 4b was removed averaged 2.81 times greater than the computation time for the complete algorithm with all rules.

@&#CONCLUSIONS@&#
The assignment of a cross-trained workforce to daily shifts or tasks is a recurrent problem in a variety of service settings. The goals of the assignment process can include both operational and human resource criteria. This suggests the need for a bicriterion approach that can consider operational objectives related to service level (i.e., utility), as well as human resource objectives related to training or worker satisfaction (i.e., desirability). We have presented an algorithm for generating the complete Pareto efficient set for a nonlinear bicriterion workforce allocation problem that considers both utility and desirability objective functions. A critical advantage of this approach is that it spares the analyst from having to make an a priori determination of what percentage sacrifice in the utility function should be tolerated to get a sufficient improvement in the desirability function. The new algorithm was applied to a small numerical example, as well as an example based on a test problem from the cross-training literature (Campbell, 1999). A third example is provided in an online supplement. A key finding was that drastic improvements in desirability could frequently be realized at the expense of small (<1 percent) sacrifices in the utility objective function.The results of the simulation study revealed that the proposed algorithm efficiently generated the entire Pareto efficient set for problems with n ≤ 24 workers, regardless of the other experimental conditions. Computation times ranged from less than one second to roughly 10 minutes for test problems with n = 48 workers. The most difficult problems were those corresponding to conditions of two secondary skill classes, a higher nominal shortage (20 percent), a smaller coefficient of variation (CV = 0.3), and a larger minimum worker productivity (0.8). The greater scheduling flexibility afforded by two (rather than one) secondary skill classes increases computation time because it expands the number of feasible assignments. A larger nominal shortage (20 percent vs. 10 percent) also increases computation time because a greater shortage typically results in more possible solutions that do not completely rectify the shortage in any department. A greater coefficient of variation in demand produces greater variation in the shortage level across the departments and, therefore, there is often one or two departments with larger shortages that must be rectified by the assignment of cross-trained worker assignments. However, when there is less variation in the shortages, there is greater competition for their reduction and this increases computation time. When there is less variation in the worker productivity coefficients (i.e., either 0.8 or 1.0), there are more ties with respect to shortage reduction and, therefore, computation time increases because these ties must be pursued further into the search tree. Contrastingly, with greater variation in the productivity coefficients (i.e., 0.4, 0.6, 0.8, 1.0), there are fewer ties and pruning from rules 4b and 4d occurs more efficiently.The simulation study also showed that all of the pruning rules can be vital to the success of the algorithm, and that elimination of just one rule can greatly increase computation time. The removal of rules 4c or 4d was always damaging to the efficiency of the algorithm. Pruning rule 4a was also important. Pruning rule 4b was sometimes of no value at all (actually slightly increasing computation time in some cases). However, Table 7 clearly shows its merit for certain test problems (i.e., two secondary skill classes and minimum productivity level of 0.8). In summary, the algorithm (using all pruning rules) is viable for generating the complete Pareto efficient set for problems with up to n = 48 workers and m = 6 departments in our experiments under a broad range of conditions. However, the potential computational limitations of the method for larger problem instances and/or different objective functions must be acknowledged. Such limitations are typically inherent in branch-and-bound algorithms of the type described herein because they can tend toward complete enumeration in the worst case.Given the prominence of the utility function (relative to the desirability function) that is present in our examples, several questions arise: (1) Is consideration of a desirability component necessary at all? (2) Is generation of the entire Pareto efficient set necessary? and (3) What are some other options for measuring desirability? The premise of this paper is that the answer to the first question is “yes”. To support this position, it is noteworthy that several studies in the nursing literature illustrate the relevance of human resource issues in the assignment of float pool nurses (Dziuba-Ellis, 2006; Larson, Sendelbach, Missal, Fliss, & Gaillard, 2012; McHugh, 1997). For example, Larson et al. (2012) note the exposure to new medical technology and methods (improving nurse marketability), as well as the opportunity to interact with a broad spectrum of individuals, as behavioral benefits of float pools. There are also human resource advantages to nursing management, who sometimes use float pools as a resource for recruitment and training (Cavouras, 2002; Dziuba-Ellis, 2006). In light of these issues, and the criticality of maximizing utility notwithstanding, it seems appropriate to bring shift desirability criteria into consideration during the assignment process.Based on the results of our examples, the answer to the second question is, at least generally, “no”. It is likely that most service managers would not tolerate large reductions in service utility. Fortunately, however, we commonly observed that large improvements in desirability could often be realized at the expense of only small departures from the globally-optimal service utility. Although the generation of the entire Pareto efficient set might not be necessary, it is difficult to establish exactly how much of the efficient set to generate a priori. For example, if the generation of the Pareto efficient set is arbitrarily truncated based on a maximum 1 percent reduction in the globally-optimum utility function, then it is possible to miss a solution that provides a drastic improvement in the desirability function for a decrease of, say, 1.02 percent in the utility function. Therefore, if the generation of the curve is to be truncated, it should be accomplished at a degradation in utility that would clearly be intolerable.Regarding the third question, as noted in Section 2.3, the desirability measures may be gleaned from management, workers, or the combined input of both. The criteria for establishing the measures can be based on training/skill-learning, worker preferences, or some combination thereof. The desirability measure in our implementation was expressed in terms of a target number of assignments for each worker in each unit. This facilitates the dynamic updating of the desirability measures across the scheduling horizon, as described in the example in the online supplement. However, this particular type of specification of the desirability measures is not a prerequisite for use of the algorithm. For example, an alternative approach would be to use a constant-sum scaling method (see, for example, Warner, 1976) to establish the desirability measures and allow these to remain fixed (or static) for a prescribed period of time, such as a two- or four-week scheduling horizon. Moreover, although desirability has been expressed in terms of the favorability of a worker assignment to a particular department, it might also be possible to allow workers to establish their desirability of who they would like to be assigned with, rather than where they would like to be assigned.Extensions of the research presented herein could pursue several different directions. These include (but are not limited to) the following: (1) extension to workforce allocation problems with three or more objective criteria, (2) development of alternative methods for choosing solutions from the Pareto efficient set of bicriterion or multicriterion problems, and (3) the design of integrated scheduling and allocation methods that foster better utility and desirability at the allocation stage.Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.ejor.2015.06.009.