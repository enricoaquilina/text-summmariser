@&#MAIN-TITLE@&#
Enhancing non-compensatory composite indicators: A directional proposal

@&#HIGHLIGHTS@&#
We analyze the weighting phase of composite indicators construction process.We focus on the presence of an unbalanced preference structure among simple indicators.The preference structure is determined from the variability of each indicator projected onto principal components.Our penalty criteria, to incorporate in a BoD model, is based on the directional distance functions.We test our approach on both simulated data and on infrastructural endowment data in European regions.

@&#KEYPHRASES@&#
Composite indicators,Non-compensatory,Directional efficiency,,

@&#ABSTRACT@&#
The construction of composite indicators (CI) is useful to synthesize complex social and economic phenomena, but some underlying assumptions in “classical methods”, as in particular the compensability among indicators, are very strictly. The aim of this paper is to propose an original approach that enhance non-compensatory issue by introducing “directional” penalties in a Benefit of the Doubt model in order to consider the preference structure among simple indicators. Principal component analysis on simple indicators hyperplane allows to estimate both the direction and the intensity of the average rates of substitution. Under an empirical point of view, our method has been tested on both simulated data and on infrastructural endowment data in European regions.

@&#INTRODUCTION@&#
Interest in composite indicators (CI) as a tool to support decision-makers in policy analysis context, is rapidly growing thanks to their capability to summarize multi-dimensional issues, to rank countries in benchmarking analysis and to their ease of interpretation.On the other hand, the construction of a CI is a very complex process with multiple subsequent steps (for a complete explanation of each step, please see Freudenberg, 2003):1.the systematization of a theoretical framework for the identification of relevant analysis dimensions,the standardization of the simple indicators with the aim of transforming them into pure, dimensionless numbers and to invert possible opposite polarities/signs (e.g. air pollution in OECD Better Life Index) in order to allow comparisons,the imputation of missing data,the weighting of simple indicators,the succeeding sensitivity analysis on the robustness of the aggregation.A critical step of the entire process, focus of our paper, is how to assign unknown weights in order to aggregate simple indicators (Step 4)11For seek of simplicity and to focus the attention on this particular step, we do not explain in detail in Section 4.2 the other steps that have been carried out correctly in the standard way.. In this framework, the two main issues to be considered are: (i) How to find weights i.e. if in a subjective or objective manner. (ii) If exists a trade-off relation among simple indicators i.e. the possibility to compensate a disadvantage on some simple indicators with a sufficiently large advantage on the others ones or not.In order to answer to the first problem, a large number of researchers identify weights subjectively in cooperation with experts who know well the theoretical context (please see e.g.ONS, 2002; WMRC, 2001), others, on the contrary, use objective methods (please see Section 2 for details) in order to avoid arbitrariness problems.The second issue implies taking a position on the fundamental topic of compensability. In fact, a preference relation is compensatory if weights are considered as intensities or non-compensatory if weights are considered as importance coefficients (please see Munda and Nardo, 2005; 2009; Munda and Saisana, 2011; Munda, 2012a; 2012b, for recent discussion).From our point of view, opinion-based methods can often introduce distortions in CIs and compensability is not even appropriate in practical applications. For these reasons, in our paper, we propose a weighting method that takes into account an objective non-compensatory preference structure among simple indicators.The paper is organized as follows. In Section 2 we illustrate a literature review of the common methods for the construction and weighting of composite indicators, in Section 3 we describe our theoretical model, the Section 4 shows two empirical application on simulated data and on infrastructural endowment data in European regions. Conclusion and future perspective are reported in Section 5.In the construction of CIs, the first assumption to make is the functional form for the underlying aggregation rule (see e.g.Diewert, 1976) that is generally linear(Freudenberg, 2003) i.e.I=∑i=1Nwixi,where xiis a scale adjusted variable normalized in [0, 1] and wiis the related weight (usually∑i=1Nwi=1,0 ≤ wi≤ 1).This hypothesis is acceptable only under the condition of this theorem: “given the variables x1, x2, …, xn, an additive aggregation function exists if and only if these variables are mutually preferentially independent” (Debreu, 1960; Keeney and Raiffa, 1993; Krantz et al., 1971).Note that a subset of indicators Y is preferentially independent of Yc= Q (the complement of Y) only if any conditional preference among elements of Y, holding all elements of Q fixed, remain the same, regardless of the levels at which Q are held. The variables x1, x2, …, xnare mutually preferentially independent if every subset Y of these variables is preferentially independent of its complementary set of evaluators.Preferential independence is a very strong condition implying the independence between the trade-off ratio of two variables Sx, yand the values of the n − 2 other variables, i.e.∂Sx,y∂q=0,∀x, y ∈ Y, q ∈ Q(Ting, 1971). An additive aggregation function permits the evaluation of the marginal contribution of each variable separately and so the possibility to sum together the single contributions to obtain a total value.However, in empirical applications often exists collinearity among variables, in this case a linear aggregation could generate biased CIs and so is better to use nonlinear aggregation rules.Once chosen the aggregation rule, another important assumption in the construction of the CI is the choice of the weighting method. In literature two major fields have been proposed, based on expert subjective judgments or on statistical techniques.The first group includes budget allocation processes (BAP - Jesinghaus in Moldan et al., 1997) based on a subjective allocation of a “budget” of one hundred points to a set of indicators; analytic hierarchy processes (AHP - Forman, 1983; Saaty, 1987) in which weights are the trade-offs across indicators; conjoint analysis (CA - Green and Srinivasan, 1978; Hair, 1995; McDaniel and Gates, 1998) that studies the evaluations (preferences) given by the respondents on a set of alternative scenarios representing different values for the individual indicators.In the second group are included: principal component analysis (PCA - Manly, 1994) and factor analysis (FA) that groups collinear simple indicators with the aim to capture the common informations among them; however, weights cannot be estimated with these methods if weak correlation exists among indicators; unobserved components model (UCM - Kaufmann et al., 1999; Kaufmann et al., 2003) that assumes the dependence of the simple indicator on an unobserved variable plus an error term in order to individuate the relationship between the composite and its components; DEA models and in particular the benefit of doubt approach (BoD - Melyn and Moesen, 1991) based on the identification of an efficiency frontier.DEA techniques have been applied to various empirical applications as e.g. capital construction program choice (Cook and Kress, 1994), European labor market analysis (Storrie and Bjurek, 2000), social inclusion policies at EU level (Cherchye et al., 2004), internal market policies (Cherchye et al., 2005), human development index (HDI) (Cherchye et al., 2008; Despotis, 2005a; 2005b; Mahlberg and Obersteiner, 2001), evaluation of performance of national R&D programs (Lee et al., 2010), monetary aggregations (Sahoo and Acharya, 2010), evaluation of local police effectiveness (Verschelde and Rogge, 2012).In the following Section 2.2 we analyze in more detail the BoD approach since it determines the weights endogenously and consequently avoids the main critical remark on the subjectivity involved in the choice of the weights set.In a classical production framework we consider a decision making unit (DMU) i using p inputsx=(x1,…,xp)∈R+pto produce q outputsy=(y1,…,yq)∈R+qwith a production set Ψ such that:(1)Ψ={(x,y)|x∈R+p,y∈R+q,(x,y)isfeasible}satisfying the usual assumptions as in Shephard (1970) and in Färe et al. (1985).The basic BoD approach is a particular case of the CCR–DEA model (Charnes et al., 1978) where x is univariate and constant equal to 1 and y is a vector of k simple indicators in [0, 1] (from this point denoted by I).The BoD estimator of the output efficiency score λ for a given unit o is obtained by solving the following linear program:(2)maxλ,γ1,…,γnλs.t.λIo≤∑i=1nγiIiγi≥0This method inherits all the hypothesis and drawbacks of the DEA model:•Hypothesis: Preferential independence among simple indicators being a linear aggregation method, positive monotonicity and convexity of the aggregation function.Drawbacks: Weights are country specific, thus cross-country comparisons are not possible; without imposing constraints on weights we can have multiplicity of equilibria i.e. weights are not uniquely determined (multiple solutions have been proposed: please see Allen et al., 1997; Cooper et al., 2009; Estellita-Lins et al., 2007; Thanassoulis et al., 2004 for some methods that incorporate the “value judgment” of the specialists (bounds on the weights) in the classical DEA specification and Lauer et al., 2004; Mazziotta and Vidoli, 2009; Rogge, 2012; Takamura and Tone, 2003 in the case of BoD; or see e.g.Kao et al., 2008 for a method that introduce a priori weights); the frontier is sensitive to extreme values and outliers (please see Cazals et al., 2002; Daraio, Simar, and Rhodes, 2005 for a robust version of nonparametric frontier estimations).Moreover, the BoD model assumes the compensability among simple indicators, namely allowing lower values in some indicators to be compensated by higher values in the others, but this property is not even verified in the practical application, especially if they have to be interpreted as importance coefficients (Bouyssou, 1986; Bouyssou and Vansnick, 1986; Keeney and Raiffa, 1993; Munda and Nardo, 2005; Podinovskii, 1994; Vansnick, 1986).In the following Section 2.3 we focus our analysis on the way to avoid the latter drawback in order to take into account the preference structure among simple indicators.In the last years, multiple solutions have been proposed to avoid the compensability assumption introducing weight constraints, weighting each tensor that links the single point to the frontier (see e.g.Tsutsui et al., 2009) or including a penalty according to the different mix of simple indicators.In particular, considering the third approach, Vidoli and Mazziotta (2013) suggest to incorporate the method of penalties for coefficient of variation (MPVC - De Muro et al., 2010) idea in the basic BoD method in order to take into account the benchmark units on the frontier (as in BoD) and to penalize, in the case of non-compensatory issues, the presence of unbalanced data (as in MPVC).In the latter method, however, given the chosen penalty criteria, the aggregate function does not always satisfy the weakly positive monotonicity property (see e.g.Casadio Tarabusi and Guarini, 2013; Chakravarty, 2003):Property 1positive monotonicityLet CI = f(I) an unbalanced-adjusted aggregation function of k simple indicators I, f is weakly positive monotone if for each c > 0, f(I1, …, Ij, …, Ik) ≤ f(I1, …, Ij+ c, …, Ik).This means that f increases whenever any of the simple indicators increase and the others are left unchanged. Fig. 1shows how the BoD–PVC (solid line) modifies the BoD (dashed line) level curves; in some cases the BoD–PVC does not satisfy the monotonicity property (e.g. if the simple indicator I2 increases from point B to point A, the value of CI decreases).As discussed in Sections 2.2 and 2.3 a strong assumption of the model (see Eq. (2)) is the compensability among different simple indicators not verified when in practical application exists a preference structure on indicators. Moreover, in order to find an increasing non-compensatory CI we have to pay attention that the resulting aggregation function is monotone positive.Therefore, we suggest to include in the BoD model (Eq. (2)) a “directional” penalty using the directional distance function22The function satisfies the following properties (The proof of the results below may be found in Chambers et al. (1998).):(i)D→T(x,y;g)≥0⇔x∈Ψ(representation);D→T(x−αg,y+αg;g)=D→T(x,y;g)−αforα∈R+(translation).Given that in our model x is fixed, we consider a directional output distance function, where the directional vector is g = (0, g1, …, gk).As a consequence, following Bogetoft and Otto (2011), we evaluate the output distance of a specific unit o to the frontier in g-units as:(4)eo=e(1,Io;Ψ,g)=max{e∈R+|(1,Io+eg)∈Ψ}.The Directional BoD (D-BoD) estimator of the output distance e is obtained by solving the following linear program:(5)maxe,γ1,…,γnes.t.Io+eg≤∑i=1nγiIiγi≥0Finally, the Shepard output distance for the specific unit o function can be derived from the directional distance function as:(6)e(1,Io;Ψ)=1e(1,Io;Ψ,g)+1,∀oAgainst this background, in literature, a crucial question in a directional framework is the correct choice of the direction g in which inputs have to be contracted and/or outputs have to be expanded to reach the efficient boundary.Some authors (see e.g.Briec and Lesourd, 1999; Färe et al., 2005) suggest to choose g = (1, …, 1) which is mathematically equivalent to seeking the Chebyshev distance l∞ to the frontier of the technology. Bogetoft and Otto (2011) conversely propose four approaches: (i) use the direction of the actual value of input consumption (output production) i.e. gx= xo(gy= yo), (ii) fix a part of the input-vector (output-vector) i.e. gx= (1, …, 1, 0, …, 0) (gy= (1, …, 1, 0, …, 0)), (iii) use the potential improvements or multi-directional efficiency analysis based on the bargaining theory or (iv) consider the subjective user point of view.In the fourth approach, can be included, also methods able to identify a preference structure as the multi-criteria approach (please see e.g.Figueira et al., 2005; Munda, 2004; 2014; Roy, 1996) that evaluates economic, social or environmental issues by establishing objectives that could be translated into the direction vector.In our method all of above proposals could be used to determine the direction, but with the drawback, however, of assuming exogenous choices of the researcher. Therefore, we propose to find the direction vector directly from the data estimating the endogenous preference structure among indicators getting through to PCA.The preference structure estimated is hypothesized to be based on the variability of each indicator by following the Mazziotta and Vidoli (2009) idea. Following this criteria, a simple indicator with an high variability is more “important” than an indicator with a low variability in discriminating units.In order to strengthen the estimate, the variability is evaluated by calculating a robust kernel variance of all indicators projected onto all principal components. As matter of the fact, PCA allows to create a ranking in which the first principal component has the largest variance and each succeeding component has the highest variance possible under the constraint that it be orthogonal to the preceding components.In our framework, therefore, the slope of the first principal component gives the direction g and the ratio between the kernel variances of the indicators projected onto the principal componentsAPTARABOLDI^gives the intensity of the average rates of substitution among indicators i.e.:(7)g=(IPC1,IPC2·var(IPC2^)var(IPC1^),…,IPCk·var(IPCk^)var(IPC1^))where e.g. IPC1 is the original simple indicator most correlated with the PC1.This approach, consequently, allows to derive both the preference structure and the direction from the data avoiding subjective judgments of the researcher.For seek of simplicity, and in order to better visually illustrate our method, we consider the bivariate case of two simple indicators i.e.I = (I1, I2).Fig. 2compares the CI scores obtained with BoD (dashed line) and D-BoD (solid line) formulation in an hypothetical case in which the simple indicator I1 is the most important in discriminating units. The two straight lines represent the directions underlying the models: gBoD= (I1, I2) and gD − BoD= (I1, I2 · 0.5).Given this representation, points A, B and C lie on the same level curve (the red dashed line) in a BoD model, while in a D-BoD model points A and C have a lower level of efficiency than B.As a matter of fact, the D-BoD model rewards the combinations of I1 and I2 on the main direction (point B) and penalizes, in a different way, the combinations of low values of I1 and high values of I2 (point A) respect to combinations of high values of I1 and low value of I2 (point C).We can observe that on the main direction the BoD level curve coincides with the D-BoD one and that the two curves are overlaid on the frontier.The proposed model is, therefore, a more general formulation of the basic BoD model where I1 and I2 have the same importance i.e. gBoD= (I1, I2).Please note, finally, that this unbalance-adjusted function satisfies the property of weakly positive monotonicity emphasized in Section 2.3 on page 6, i.e. for each c > 0, since e(1, I1, …, Ij, …, Ik; Ψ, g) ≤ e(1, I1, …, Ij+ c, …, Ik; Ψ, g) as proven in Chambers et al. (1998).In order to test the model proposed in Section 3 we have firstly conducted a simulation on standardized unbalanced data set (Fig. 3) composed by two groups:•A major homogeneous group (G1) containing units that follow a specific direction, where I1 is a vector of 3000 multivariate normal random numbers i.e.N1…1000(0.5,0.3),N1001…2000(0.4,0.1),N2001…3000(0.7,0.1)and I2 is a multiple of I1 plus a noise term i.e.I2=0.1·I1+0.1·N(0,0.2);An isolated minor group (G2) containing units with a different preference structure, where I1 and I2 are two vectors of 100 multivariate normal random numbers i.e.I1=N3001…3100(0,0.05)andI2=N3001…3100(0.3,0.02).The first step of the analysis is intended to find the main preference structures between I1 and I2 through PCA. In this simulation we have obtained that the 98.39% of the total variance is explained by the first principal component given that most of the information is contained in the first eigenvalue. Fig. 4shows the two principal components PC1 and PC2.Afterward, we have calculated the robust bivariate kernel density of the rotated data points and the kernel variance of the projected values of I1 and I2 onto the principal components denoted byI1^andI2^. In this way, we have obtained the direction and the intensity of the rates of substitution between I1 and I2 from Eq. (7)i.e.g=(I1,I2·vark(I2^)vark(I1^))=(I1,I2·0.325).Fig. 5shows the kernel densities and the directions in the case of a simple BoD model where I1 and I2 have the same importance (blue line) and in the case of our D-BoD model where I1 is the most important in the construction of the CI (red dashed line).Finally, having estimated g we can calculate the CI score in Shepard formulation.Fig. 6compares BoD and D-BoD models results confirming that the directional approach rewards units nearby the main direction. For G2 group, in fact, we have obtained a reduction of the average efficiency from 83.46% to 63.76%. In addiction, we can observe that the biggest differences are detected, as expected, for the units with low values of I1 and especially in the units of the isolated group (G2) with low values in both indicators where the CI score falls from 65.40% to 38.17%.The D-Bod model outlined in Section 3 has been also applied to the terrestrial transport infrastructure endowment in European Regions following Vidoli and Mazziotta (2013) proposal.The data set33Source: Eurostat, Statistics by theme, 2012.includes information on two simple indicators44For variables and the method of construction of simple indicators, please see Vidoli and Mazziotta (2013).concerning roads (IRoads) and railways (ITrains) endowment for France, Germany, Italy and Spain.Fig. 7shows a similar path to the simulation in Section 4.1 with three departments (GE-BER – Berlin, GE-BRE – Bremen and GE-HA – Hamburg) with low values of IRoadsand high values of ITrains. Table 1and Fig. 8show results obtained with BoD and D-BoD methods. In particular, while the Spearman index between the two approaches is very high (equal to 0.938), the average CI score of the isolated departments falls (please see Table 1) from 55.86% to 14.19% in GE-BRE – Bremen and from 57.92% to 17.31% in GE-HA – Hamburg.Finally, we highlight that Berlin remains at the top of the ranking because on the frontier the BoD level curve coincides with the D-BoD one (please see Fig. 2).In this paper we have analyzed the weighting step of CIs construction process in presence of an unbalanced preference structure among simple indicators.Most of the methods proposed in literature for weighting CIs, do not consider the different importance of a simple indicator with respect to another ones, assuming, on the contrary, the compensability among them.In practical applications, however, the policy-maker or the researcher could be interested in penalizing the presence of unbalanced data. In this framework, in literature various solutions based on the introduction of weight constraints or penalties have been proposed. In particular, Vidoli and Mazziotta (2013) have suggested a method that taking into account the benchmark units on the frontier penalizes the presence of unbalanced data. This aggregate function, however, does not always satisfy the weakly positive monotonicity property due to the choosing penalty criteria.Our paper contributes to this literature by proposing another penalty criteria, based on the directional distance functions, to incorporate in the BoD model. More precisely, we have constructed a directional BoD model, satisfying the positive monotonicity property, in which the direction, and then, the preference structure, is determined from the variability of each indicator projected onto principal components.In this way, we reward combinations of simple indicators on the main direction (the first principal component) and, on contrary, penalize the combinations unbalanced with respect the main direction.In conclusion, we have proposed a method completely objective, in fact: (i) the use of the BoD allows to determine weights endogenously from the data; (ii) the inclusion of directional distance functions in the BoD allows to avoid weights restrictions or bounds; (iii) the use of PCA to find the direction eliminate others discretionary elements.However, this methodology presents some drawbacks that need to be overtaken, firstly CI scores are sensitive to extreme values and this can be improved by introducing more robust frontier estimation techniques (e.g.Cazals et al., 2002; Daraio, Simar, and Rhodes, 2005), secondly also the direction is influenced by outliers and in this case we can introduce a robust version of the PCA (e.g.Hubert et al., 2005; Li and Chen, 1985; Ruymagaart, 1981), thirdly our analysis is applied on cross-sectional data but it could be interesting consider the change of the index over the time (e.g.Caves et al., 1982).

@&#CONCLUSIONS@&#
