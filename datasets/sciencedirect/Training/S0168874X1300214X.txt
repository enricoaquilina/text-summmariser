@&#MAIN-TITLE@&#
Numerical simulation of continuous damage and fracture in metal-forming processes with 2D mesh adaptive methodology

@&#HIGHLIGHTS@&#
An h-adaptive methodology suitable for metal forming processes with damage is proposed.Mesh coarsening is performed inside inactive areas where no plastic flow occurs.We propose geometrical and diffuse approximation based physical error indicators.Field transfer procedure at integration points is based on diffuse approximation.Loading sequence is adapted with the size and number of fully damaged elements.

@&#KEYPHRASES@&#
Damage,Adaptivity,Error estimation,Field transfer,Forming processes,Numerical simulation,

@&#ABSTRACT@&#
An h-adaptive remeshing scheme dedicated to the simulation of macroscopic ductile cracks initiation and propagation during metal forming processes, is proposed. Cracks are represented using a procedure based on fully damaged elements deletion. Element size inside the domain and along the crack path, located inside highly localized zones, is driven by error indicators based on geometrical considerations and the derivatives of physical quantities calculated by diffuse approximation. Saw tooth effects along the crack are smoothed with the use of Bezier curves in order to reduce computational inaccuracy. The mesh can be refined and an important issue of this work is mesh coarsening in order to ensure a reasonable computational cost. Multiple domains can be handled. The procedure can be easily integrated in any standard nonlinear explicit finite element code. Specific fields transfer procedures and an automatic adaptation of the time loading sequences are also presented. The efficiency and robustness of the proposed strategy are validated through some examples which show a good agreement with experimentally observed ductile crack paths under large inelastic strains.

@&#INTRODUCTION@&#
The study of the initiation and propagation of cracks inside structures subjected to various monotonically increasing loading paths is of important concern in numerous industrial fields such as in metal forming processes. A number of authors [1,2] have proposed classifications of the different techniques used to simulate cracks growth. In a brief state of the art, we propose to place the emphasis on ductile cracks occurring inside zones where the plastic flow localizes and the associated discretization used to solve the problem in the scope of the finite element method (FEM). This excludes boundary [3,4] and also meshless methods in which integration problems [5] must be solved. The analysis of the literature shows that the numerical description of the initiation and growth of the cracks may be gathered into three main groups.The first group concerns nodal relaxation and cohesive elements: Crack initiation and propagation can be represented with minor modifications of the mesh [6,7]. The mesh may remain unchanged. In this case, the crack is represented by a geometric entity denoted as a discrete crack that propagates along existing edges of a background mesh with respect to appropriate criteria for handling nodal relaxation as well as the crack orientation. In order to reduce a mesh bias, the mesh may be updated. As an example, Tijssens et al. [8] have carried out studies with structured and unstructured meshes which point out that the use of a cohesive surface methodology exhibits a strong mesh alignment sensitivity and proposed coupling the approach with a minimal remeshing on the crack tip [9]. Bouchard et al. [10] focused their work on advanced remeshing procedures into triangles combined with nodal relaxation while the crack propagates based on a maximum normal stress criterion. In order to reduce the number of remeshing steps an inter-element propagation technique, albeit mesh dependent, is proposed. Mesh coarsening far from the crack tip can be obtained. In this way, various propagation criteria are studied [11]. A mesh bias [12] can also be observed in the context of smeared crack approaches in which the crack is represented by a stiffness loss. In order to eliminate mesh bias and stress locking effects, Cervera [13] has proposed a “mesh corrected crack model” inspired by the strong discontinuity approach [14] that integrates the effect of the displacement jumps in the strain field of the elements and in which the behaviour of the crack is established through a softening stress–total strain relationship. Cohesive elements can be used in the context of smeared crack approaches which appear with a loss of stiffness. de Borst et al. [7] present a cohesive segment method based on the partition-of-unity property. The crack is not seen as a unique entity but as several cohesive segments which may interact what enables to simulate the coalescence of distributed cracks at multiple locations.The second group gathers element deletion procedures[15,16]: A fracture criterion is defined inside each element and the element is removed whenever the appropriated criterion reaches a given threshold. This technique is usually associated with a critical damage criterion [17,18]. The size of the elements must be small enough in order to represent the crack with realism and to avoid mass loss what may alter the accuracy of the computation, a point we shall discuss. In addition, due to the removal of fully damaged elements, new boundaries are created with an undesirable and unrealistic saw-tooth effect which may impede the accuracy of the numerical solution especially in contact areas leading to an overestimation of the stresses along the crack lips. In order to coarsen the mesh, crack path lines must be smoothed, a point relatively less investigated in the literature. Indeed, a high number of elements can be found in damaged but non-active zones. Arguments against these techniques are principally localization problems together with a strong dependence to the mesh [1,2] due to the thermal or damage induced softening. As we shall discuss, an issue in this problem is introducing the mesh size as a “characteristic” length of the material behavior. Element erosion inside the active zones combined with a smooth remeshing of the boundaries in order to coarsen the mesh inside inactive zones has not yet been proposed.The third class of methods deals with enrichment techniques: Specific enrichment in order to accurately represent the fields at the crack tip may be obtained by a mesh refinement with specific patterns or by the use of extended finite elements. Moving mesh techniques [19] have been introduced in order to avoid frequent remeshing. Rashid [20] proposed an arbitrary local mesh replacement method based on a mesh around the propagation of a quadrangular patch mesh inside a background mesh. Compatibility at the interfaces between the two meshes including the boundaries of the domain is enforced using a weak form. A number of intersection patterns must be studied which makes its extension to 3D cases a difficult task. Kuutti and Kolari [21] have proposed a delete and fill local 3D remeshing procedure to simulate cracks in quasi brittle materials based on a fracture patterns independent of mesh topology well suited for implementation in commercial FE software. Khoei et al. [22] have proposed an automated 2D and 3D procedure based on mesh refinement and a modified superconvergent patch recovery (MSPR) for the simulation of crack propagation in mixed mode. The technique is based on the computation of stress intensity factors at the crack tip. The derivatives of the problem variables are obtained by the MSPR in which the weighting functions used for the fitting process at each integration points provides a smoother approximation than the finite element shape functions. The technique is associated with the computation of analytical asymptotic crack tip fields and collapsed quarter-point singular elements at the crack tip region. Clearly, this is only possible for problems where the singularity of the stress field at the crack-tip is known. This is not the case for the ductile fracture for which the stress field is not singular due to the large plastic flow which transforms the sharp crack tip to a notch with a small but finite radius. Among partition-of-unity based techniques, the extended finite element method (XFEM) based on the addition of an enriched basis into the existing finite element mesh is now widely used [23–25] to avoid frequent remeshing and to cope with the problem of mesh size dependency which alters crack path prediction. This mainly concerns the brittle crack propagation in which the crack is represented by distance level set functions which provide on each element the location of the plane of the crack and the boundaries of the crack. Depending on the geometry of the element, the surface crack (or line) is represented by a number of pre-calculated patterns as in a marching cube approach [26]. Note that in the case of partition-of-unity based techniques, no remeshing is needed provided the background mesh enables an accurate representation of the crack geometry. Recently, Moës et al. [27,28] have presented an approach between fracture and damage called thick level set (TLS) in which the damage variable is represented by a level set function. Damaged and undamaged zones are therefore separated which allows the use of a nonlocal formulation and takes into account internal size effects. Initiation, growth as well as coalescence of distributed cracks can be handled and the computational time can be noticeably reduced by mesh coarsening. Some published works [29] combine the advantages of the above discussed methods in order to describe cracks initiation and propagation in various kinds of materials.When a metallic part is formed by large plastic (or viscoplastic) strains, ductile damage is expected to occur inside zones where the plastic flow is highly localized. When ductile damage occurs, the propagation of macroscopic cracks induces severe changes of topology and frequent remeshing must be performed in order to avoid large mesh distortion or element entanglement encountered in a Lagrangian formulation. The present work deals with the prediction of ductile fracture in metal forming where large inelastic (plastic or viscoplastic) strains take place using a fully adaptive scheme combining h-adaptivity (refinement and coarsening), error indicators, field transfer operators and an adaptive loading sequences technique. In this spirit, various methods [16,17,30] have been proposed to predict the ductile fracture occurrence inside metallic parts formed by large plastic deformation based on damage-induced loss of stiffness together with mesh adaptation.The outline of this paper is as following: in a first part the thermo-elasto-viscoplastic constitutive equations are presented and their numerical implementation is briefly described. In Section 3 the proposed 2D adaptive numerical methodology is detailed. Finally, the efficiency of the proposed methodology is validated, in Section 4, through various examples including the simple tensile test as well as two examples related to the metal cutting processes.The fully coupled thermo-elasto-visco-plastic and damage behaviour is modelled in the framework of the thermodynamics of irreversible processes with state variables assuming the small elastic strain together with large plastic strain. The fully coupled constitutive equations are presented in the framework of small strain. The extension to the finite plasticity framework requires the use of rotated frame formulation in order to ensure the objectivity requirement (see [16] for more details).Following the first gradient theory, two external state variables are used namely: (ε, σ) the total strain tensor and the Cauchy stress tensor; (T, s) the absolute temperature and the specific entropy. The internal state variables and their conjugate forces are: (εe, σ) for small elastic strain tensor and the Cauchy stress tensor; (q→,g→=grad→(T)) for thermal flux vector and its conjugate force; (α, X) for back-strain and back-stress deviator tensors that describe the kinematic hardening (i.e. translation of the yield surface centre); (r, R) representing the isotropic hardening (i.e. variation of the yielding surface size) and (D, Y) for the isotropic ductile damage representing the homogeneously distributed micro-cracks and micro-voids.For the sake of brevity, this work is limited to the fully isotropic and anisothermal formulation including the mixed non-linear hardening (isotropic and kinematic), the thermal effect as well as the strong coupling with the isotropic ductile damage.The dual (or force-like) state variables(σ̲,R,X̲,Y,se)are derived from the state potential, classically taken as the Helmholtz free energyψ(ε̲,r,α̲,D,T), defined in the strain-like variables space, additively decomposed and written in the present isotropic case as:(1)ρψ(ε̲,r,α̲,D,T)=12(1−D)ε̲e:Λ̲̲:ε̲e−(T−T0)1−D(3λe+2μe)ξε̲e:1̲−ρCv(T−T0)22T0+13(1−D)Cα̲:α̲+12(1−Dω)Qr2whereΛ̲̲=2μe1̲̲+λe1̲⊗1̲is the fourth-rank symmetric elastic properties tensor of the material, defined here for the isotropic material where (λe,μe) are Lame's constants,ξis the thermal expansion coefficient, Cvis the specific heat at constant volume coefficient,ρis the material density and T0 is the reference temperature.CandQare the modules for the kinematic and the isotropic hardening, respectively, ω is a material parameter governing the effect of the ductile damage on the isotropic hardening.By introducing the above state potential into the basic Clausius–Duhem inequality, the following state relations are obtained(2)Cauchystresstensor:σ̲=(1−D)Λ̲̲:ε̲e−ξ(3λe+2μe)1−D(T−T0)1̲(3)Kinematichardeningtensor:X̲=23C(1−D)α̲(4)Isotropichardening:R=Q(1−Dω)r(5)Isotropicdamage:Y=νE2(1+ν)(1−2ν)<ε̲e:1̲>+2+E2(1+ν)<ε̲e>+:<ε̲e>+−E21−d(1−2ν)ξ(T−T0)<ε̲e:1̲>++13Cα̲:α̲+12ωDω−1Qr2(6)Specificentropy:se=1−D(3λe+2μe)ρξ(ε̲e:1̲)+Cv(T−T0)T0where E is the Young's modulus function of the temperature andνis the Poisson's ratio. We bring the reader's attention on the fact that only the positive part of the elastic strain tensor defined by<ε̲e>+=Σi=13〈εie〉e→i⊗e→iis used to define the thermodynamic force Y associated to damage, in whichεieis the ith eigenvalue ande→ithe associated eigenvector. This is the simplest way to disable the damage growth under the compressive phase of the loading, in order to account for the micro-defects closure [16].The second consequence arising from the Clausius–Duhem inequality defines the dissipation inequality under the additive form(7)Φ=σ̲:ε̲̇p−X̲:α̲̇−Rṙ+YḊ︸Φm≥0−q→T×g→︸Φth≥0≥0whereΦm≥0is the mechanical or intrinsic dissipation whileΦth≥0is the thermal dissipation taken separately positive as a particular case. In this inequality, the force-like variables (or state relations) are definite from the state potential through Eqs. (2)–(6) and the flux variables (ε̲̇p,α̲̇,ṙ,Ḋ,q→) have to be defined in such a manner that the inequality (7) is fulfilled. The framework of the so called generalised standard material is used to analyse the mechanical dissipation. This requires the definitions, in the stress space for example, of a yield functionf(σ̲,X̲,R;D,T)and the associated plastic potentialF(σ̲,X̲,R;D,T)as closed convex functions of the stress-like variablesσ̲, X and R with D and T in the role of simple parameters.Assuming initial isotropy of the plastic flow, the yield function and the plastic potential are chosen under the following form(8){f(σ̲,X̲,R;D,T)=J2(σ̲−X̲)1−D−R1−Dω−σy(a)F(σ̲,X̲,R;D,T)=f+3aX̲:X̲4C(1−D)+bR2Q(1−D)+S(s+1)(1−D)β〈Y−Y0S〉s+1(b)whereσyis the initial size of the von Mises yield function, a and b characterize the nonlinearity of the kinematic and isotropic hardening, respectively;Y0, S, s and β characterize the ductile damage evolution. S defines the plastic strain at fracture (ductility),Y0is a kind of threshold before which no damage occurs, while s and β define the nonlinearity of the ductile damage evolution (see Ref. [16] for more details).J2(σ̲)stands for any quadratic or non-quadratic stress invariant (or equivalent stress). Also, In this study and for the sake of simplicity, only the quadratic von Mises equivalent stress defined byJ2(σ̲)=(3/2)S̲:S̲in whichS̲being the deviatoric part ofσ̲, is considered. Note that the extension to any other quadratic or non-quadratic equivalent stress to account for initial anisotropy of the plastic flow is possible without any difficulty [16].The constitutive equations governing the evolution of the dissipative phenomena derive from the dissipation potential using the generalized normality rule. After some algebraic calculations one can obtain using the yield function (8) and the dissipation potential (8) (see [16] for more details)(9)ε̲̇an=δ̇∂f∂σ̲=δ̇n̲withn̲=∂f∂σ̲=3211−DS̲−X̲J2(σ̲−X̲)(10)α̲̇=δ̇∂F∂X̲=δ̇(n̲−aα̲)(11)ṙ=δ̇∂F∂R=δ̇(11−Dω−br)(12)Ḋ=δ̇∂F∂Y=δ̇(1−D)β(〈Y−Y0〉S)sThe deviatoric tensorn̲stands for the outward normal to the yield surface in the stress space. Note that the damage rate defined by Eq. (12) defines the ductile damage due to time-independent plasticity. This comes from the fact, that the metal forming processes concerned by this work are performed under high temperature condition giving rise to a viscoplastic (or time dependent plastic flow) deformation but under high loading velocity so that the damage is purely ductile (i.e. no creep damage).The constitutive equations defined by Eqs. (9)–(12) are valid for both time-independent plasticity and time-dependent plasticity or viscoplasticity. The difference come from the Lagrange multiplierδ̇which is defined by the consistency condition in the case of plasticity and from the viscous stress using defined here by hyperbolic sine viscous stress [16] as following:(13)δ̇={δ̇vp=K1sinh〈fK2〉inthecaseofviscoplasticflowδ̇pḟ=0iff=0inthecaseofplasticflowwhereK1andK2are material constants characterizing the material viscosity. Otherwise, if the equivalent plastic strain rateṗis calculated with the help of Eq. (9) the following relationship is easily obtained:(14)ṗ=23ε̲̇vp:ε̲̇vp=δ̇1−DFinally, the thermal flux vector derives itself from the Fourier potential leading to the well-known linear heat model:(15)q→=−kgrad→(T)wherekis the thermal conductivity for the isotropic thermal problem. This relationship leads to the heat equation using the energy conservation law or the first principle of thermodynamics [16].In this work, the following material parametersP∈{E,C,Q,S,Y0,K2}involved in all of the constitutive equations presented so far are assumed to be temperature dependent according to(16)P=P0[1−(T−T0Tf−T0)n]whereTfis the melting temperature,T0is the reference initial temperature,P0is the value of the parameter at the reference temperature and n is a temperature independent parameter.The fully coupled thermomechanical constitutive equations presented above have been implemented into ABAQUS/Explicit FE code using the user defined subroutine VUMAT. The dynamic explicit resolution procedure has been used in order to solve the thermomechanical evolution problem based on the two weak forms relative to the equilibrium and thermal equations. The local integration of the fully coupled constitutive equations is performed using an iterative implicit scheme based on the well-known elastic prediction—plastic correction radial return scheme applied to a reduced number of equations [16].On the basis of the generalized thermodynamics of irreversible processes, this kind of local formulation leads to constitutive equations (for elasticity, plasticity, mixed hardening, damage, friction) with material parameters having a clear intrinsic character. The strong coupling between the thermomechanical behavior and the ductile damage leads to an induced softening which generates inevitably mesh-dependent numerical solutions of the initial and boundary value problems (IBVP). In that case, the plastic flow with damage localizes inside narrow (shear) bands having a finite width which is highly mesh sensitive.The simplest way to control this mesh dependency, in this case of a fully local formulation, consists of assuming that all the damage material parameters (S, s, β and Y0) are identified by imposing a relevant minimal mesh size which provides the best fit of the reference (experimental) curve. This smallest mesh size becomes a kind of intrinsic material parameter. As a consequence, the whole h-adaptive process is controlled by this smallest mesh size imposed in the fully damaged zones. It is worth mentioning that this approximate way to trigger the mesh dependency may be replaced by a more straightforward nonlocal formulation as the micromorphic models [16].The FEM based numerical simulation of forming processes involving large inelastic (plastic or viscoplastic) deformations requires adequate spatial discretization of the deformed parts. Indeed, during Lagrangian-based numerical simulations of forming processes, frequent remeshing is needed during the computation in order to avoid large mesh distortion and also to control the errors caused by the approximation of the thermo-mechanical fields. The meshing or remeshing procedures become even more complex when severe changes in the topology of the part, due for example to the creation of new boundaries, occur. In this latter case both external boundary and inner domains have to be remeshed. The size of the mesh is then driven by appropriate error indicators based both on physical gradient fields (stress, plastic strain, temperature, damage ….) and also on the curvature of the external boundary of the domain allowing a better control of the contact interface. Finally, a crucial aspect of this work is performing mesh refinement inside active zones (plastic flow with damage) while coarsening the mesh inside inactive areas (where plastic or damage flow is no longer active) in order to reduce significantly the computational time.The efficiency of the adaptive methodology is based on a discretization of the parts using the h-method into bilinear quadrilateral “Q4” elements. To achieve this goal, the following methodology is carried out:○FEM software ABAQUS/EXPLICIT® is used to solve the initial and boundary value problem. At each integration point, the local constitutive equations presented in Section 2 are introduced using a VUMAT subroutine,Specific operators are developed to rebuild and smooth the new boundaries of the part after the deletion of the fully damaged elements while handling geometrical contact constraints and the curvature of the tools,Geometrical and physical error indicators are used to determine an “optimal” size map of the mesh,A quadtree based frontal mesh generator “DIAMESH-2D” is used to generate a new purely quadrangular mesh [31],The thermomechanical fields are transferred from the old to the new mesh based on finite element approximation for the nodal variables and on appropriate diffuse interpolation of the state variables defined at integration points [32],A procedure for adjusting the next loading sequence according to the size and number of fully damaged elements.A moving least square approximation denoted as diffuse approximation [33] is used in its interpolating form to calculate derivatives of quantities which are used to build error indicators and after remeshing to recover the various thermomechanical fields “Sphys” (plastic strain, stress, damage, isotropic hardening, …) located at the integration points of each element. The idea is to build for each scalar field Sphys, a Monge patch surface of equationSphys=S(x,y)whereS(x,y)is a polynomial expression. Our error indicators are based on 2nd order derivatives while a first order interpolation is used for the field transfer procedure. The technique has already been used in a different context [34] and a brief presentation is given here in the case of the second order of the polynomial base〈P(M)〉=〈1xyx2/2xyy2/2〉.In the vicinity of an evaluation pointM=(x,y)Teach scalar field Sphys is considered as a Taylor expansion whereM˜=(x˜,y˜)Tis expressed in the global system of coordinates.(17)S(x˜,y˜)=<1,x˜−x,y˜−y,(x˜−x)22,(x˜−x)(y˜−y),(y˜−y)22>{α(M)}=〈P(M˜−M)〉{α(M)}The vector of coefficients{α(M)}varies with the position of the evaluation pointMand is determined minimizing the following moving least square criterion(18)JM({α})=∑i=1i=npwi(Mi,M)×(〈P(Mi−M)〉{α}−Sphys(Mi,M))2Midenotes the point at which the quantity Sphys is given and np, the number of information points in the vicinity ofM. The contribution of each nodeMiis governed by decreasing weight functions. The domain of influence is centered at the evaluation point and we assume that the set of nodes is fully contained in a circle of radius Ra. Accordingly, Rais calculated for each node so that the number of neighboring nodes contained inside the influence domain are compatible with the rank of the polynomial base〈P(M)〉(see Ref. [51]). In our case, the determination of the neighborhood of an evaluation point is based on the underlying mesh before remeshing. First, we determine the element of the mesh in which the evaluation point can be projected, what a standard finite element recovery procedure would do. Elements sharing a node with this element are thereafter determined. In our case, integration points of this set of elements will constitute the support of interpolation. If the evaluation point is close to the boundary, the same procedure is used on the previous set of elements to determine an extended support of interpolation.The number of information points must be at least equal to the size of the polynomial basis (3 for a linear basis and 6 for a quadratic basis) and we have chosen an implementation in which the radiusRa(M)is locally adjusted to obtain the necessary number of information points strictly inside the compact support. In practical terms, a cubic polynomial function which is set to zero outside the domain of influence is chosen.(19)wi(Mi,M)=wi(d)=(1−d)2(1+2d)withd=||Mi−M||Ra(M)The diffuse approximation in its present form is not interpolating but the interpolation property can be obtained [34] if the weights are singular at the interpolated point what can be made by applying the following substitution(20)wi∞(Mi,M)=wi(Mi,M)1−wi(Mi,M)“Optimal” mesh size determination is an important issue of an adaptive methodology where the goal is to reduce the computational cost while controlling the accuracy of the computation. Global error estimators to quantify the error due to the discretization have been widely used. These a posteriori estimators are based on the difference between the finite element solution and a solution which has “better” properties. The contribution of each element over the whole domain is compared with a global quantity such as the energy and an energy norm is introduced. These estimators can be gathered into three groups.•The error estimates proposed by Zienkiewicz and Zhu [35,36] based on the recovery of the gradient of the finite element solution. These estimators can be easily developed and integrated in any finite element code. First introduced for linear problems, they have also been used for nonlinear mechanical problems [37,38].Estimators based on the residual of equilibrium and inter-element stress jumps introduced by Babuska and Rheinboldt [39]. The extension to highly nonlinear mechanical problems appears to be difficult.Estimators proposed by Ladevèze [40] based on the concept of error in constitutive relation which provide a bound of the error for linear problems. A statically admissible stress field, specific for each type of element must be first build. These estimators have been extended to plastic or viscoplastic solids [41,42].In the scope of our work, element size is mostly driven by plasticity and damage dissipation and we focused our work on physical error indicators based both on plastic dissipation inspired from Peric et al. [43] and damage dissipation in the continuity of Pires et al. [44]. Both authors propose to build powerful ZZ error estimators for solving nonlinear mechanics problems. In the present work, the information provided by the evolution of both quantities is used to coarsen the mesh when the plastic or damage rates go to zero (inactive zones).The different kinds of error indicators used to estimate a relevant map of element sizes for metal forming problems with crack propagation are detailed in the following.During the metal forming processes, contact occurs between the part and the tools as well as between different surfaces of the same deforming part (auto-contact). In order to improve the stability, the accuracy and the convergence of the analysis, the element size on contours into contact or which may come potentially into contact is adapted with respect to the curvature of the part and the tools and also to the gap between the facing surfaces. In practice, a minimum valueΔxgeomminis imposed.The size of the mesh is given by an empirical functions based on the assumption that the behavior of the plastically deformed part may be decomposed in a number of thermomechanical states: elastic, plastic homogeneous with low damage value, highly localized plastic zone with moderate damage, plastic zone with high damage value. We consider the behavior of a material point to be “homogeneous” if the value of the cumulated plastic strainp=∫0tṗdtis less than a threshold valuep⁎such thatJ2(σ̲(p⁎,….))=maxpJ2(σ̲(p,….))at the Considère point. Similarly, the difference between a slightly, moderately and severely damaged zones is characterized by two threshold values of the damage variable respectively Dmin and Dmax. In each zone, the evolution of the mesh size is described by a different formula and four mesh size parametersΔxmax>Δxmaxp>Δxminp>Δxmindamare needed to control the size map over the whole space-time domain (Table 1).A high number of elements can be created in areas likely to develop a macroscopic crack. As the crack propagates, the cost of a permanent refined mesh can be prohibitive. Therefore, the need to coarsen the mesh size inside the inactive zones where the plastic flow has stopped (ṗ=0) is crucial, and this may be achieved with the following expression linking the element size and the plastic strain rateṗ(21)Δx=Δxdam−(Δxdam−Δxp)exp(−κ2ṗ)in which the users' defined parameterκ2is used to ensure a smooth variation between the two mesh sizesΔxpandΔxdam.The values of these different parameters are defined as following: FirstΔxmaxare chosen according to the dimensions of the studied structure. SecondΔxmindamis determined with the help of the identification procedure in order to correlate the experimental results with the numerically predicted results for a given material taking into account the smallest size of the structure. Then the other mesh sizes are defined in such a manner that a progressive variation of the mesh size is obtained. Dmin is the value of damage before the Considère point and is taken around 0.005 while Dmax is the value of damage after the Considère point when the damage affects significantly the material behavior around 10 times the value of Dmin. Finallyp⁎is the accumulated plastic strain at the Considère point. Note that the Considère point corresponds to the maximum stress reached in the case of tensile test before the final fracture.Mesh size and mesh gradation are important issues to capture the stiff evolution of the state variables inside the highly localized zones. Therefore, we present an error indicator based on both the Hessian and the gap to the tangent plane of physical quantities entering the intrinsic dissipation. The calculation [39] of the optimal size of the element is then expressed as(22)ΔxH(C)=max(9εH2ζ,Δxminp)whereζis the largest eigenvalue of the Hessian of the intrinsic dissipation evaluated at the element centroidC→andεHis the prescribed error. The value of this prescribed error limits the smallest mesh size relative to the plastic zoneΔxminpwhen it is highly small. Its influence on the discretization error is examined in Table 3. The diffuse approximation is used to calculate the first and second derivatives of the Hessian required for evaluation of the intrinsic dissipation. According to the model used, the value of the intrinsic dissipation at each integration point is given by(23)Φm(C)=σ̲:ε̲̇vp−X̲:α̲̇−Rṙ+YḊThe diffuse approximation at pointM=(x,y)Tcentred atC→of the intrinsic dissipation is calculated using(24)Φm(M)=〈P(M)〉{α}with〈α〉=〈Φm∂Φm∂x∂Φm∂y∂2Φm∂x2∂2Φm∂x∂y∂2Φm∂y2〉The components of the diffuse Hessian matrix are computed as follows:(25)H̲̲u(Φm)=[∂2Φm∂2x2∂2Φm∂x∂y∂2Φm∂x∂y∂2Φm∂2y2]Macroscopic crack modeling is obtained by an element removal technique associated with a critical damage criterion. The element is removed when the damage value at all integration points exceeds a critical valueDc=0.99. The erosion process creates meshes which do not follow Euler's polyhedron formula [45], a problem which is solved by elimination of the all elements (damaged and not damaged) linked to the node. Some of these configurations are shown inFig. 1 on which damaged elements are colored gray.The size of the elements must be small enough in order to represent the crack with realism and to avoid a significant mass loss. The size of the totally damaged elements must be smaller than a threshold valueΔxmindamwhich therefore denotes the biggest size of a deleted element. In practice, the ratio between the mass of a deleted element and the total mass is below 10−5 and we experienced that mass loss has no significant effect on the crack propagation. In order to ensure mass conservation, we have experienced in a prior approach a remeshing algorithm denoted Moving Lagrangian Interface Remeshing Technique (MLIRT, [46]) to relocate nodes at the interface. The technique presented for the description of moving interfaces in fluid flows is based on a mass conservation constraint ensured by diffuse approximation. Since no changes in the crack propagation could be noticed, the procedure has not been used.The tools are supposed to be rigid and are represented by contour lines (segments). The 1D-mesh of the tools remains the same throughout the simulation and is adapted at the first loading step (i.e. at the beginning of the computation) based on curvature. The initial geometry of the part is provided by a surface mesh on which contour lines can be easily identified. The topology of the part and therefore the frontiers are changing drastically due to the large deformations and the crack formation. Prior to the use of an automatic mesh generator, contour lines must be discretized with respect to the prescribed size distribution provided by the geometrical and physical error indicators introduced before. During the remeshing process, some vertices of the geometry must be kept and therefore these singular points on the contours must be identified. These points denoted as sharp corners can be either provided by the user or automatically detected by an angle-based criterion. These points will be retained throughout the whole process. The deletion of the fully damaged elements creates new boundaries which have an unrealistic saw tooth wave shape. In order to coarsen the mesh along the crack lips, a smoothed representation of the crack has to be used otherwise the size of the smallest curve on the contour may impose the smallest element size. To our knowledge, element erosion combined with a smooth remeshing of the boundaries in order to coarsen the mesh in active areas has not yet been proposed. Bezier curves [47] have been chosen for their properties: the curve is contained in the convex polygon of points and has a smoothing effect on such saw tooth wave shape. The evaluation of a point on a curve is given by de Casteljau's algorithm [47]. de Casteljau's algorithm has been widely used to evaluate a point on a Bezier curve. This technique is based on a recursive linear division of line segments constituting a polyline. We consider a control polyline defined by n+1 control points and therefore n line segmentsPi0Pi+10. A pointPi1(t)=(1−t)Pi+10+tPi+10can be obtained by a linear division of the segment with the parameter t. Accordingly, n points and therefore n−1 line segments can be created. The process is iterated definingPik+1(t)=(1−t)Pi+1k+tPi+1kwith0≤i≤n−k−1and0≤k≤n−1.The process is repeated until a pointP0n(t)is created. The algorithm is easy to implement, very stable and accurate even when a high number of points is given. As shown inFig. 2, Bezier curves provide a simple but efficient technique to smooth the “saw tooth” effect induced by the element erosion technique. The extension of this technique into 3D context is not directly possible. A Bezier surface is defined by a set of Bezier curves containing the same number of points and it seems problematic to create such a net of curves on a complex polyhedral surface resulting from the deletion of tetrahedron elements.At the crack tip, the element size is equal to the size affected to critical damageΔxmindam. We experienced that smoothing of the boundaries in the vicinity of the crack tip may introduce a bias in the orientation of the propagation of the crack and therefore no smoothing is applied close to the crack tip.Techniques to provide a planar mesh from the data of contours constituted by segments have been widely discussed [31,48] and no particular emphasis is given to this subject in this paper. In the context of 2D adaptation, a full remeshing (including field transfer as well) of the structure can be performed at each step since its cost can be neglected compared to the nonlinear analysis. Nodes are created on a prior approach using a quadtree structure and are thereafter triangulated by an advancing front technique. The control of an accurate mesh size all over the domain has a major importance in this context and tree structures are well adapted to these requirements. Physical error indicators provide the size of the mesh at the integration points. The curvature is calculated at the contour points (part and tools) and a corresponding element size is calculated as detailed in Ref. [34]. Mesh size information is thereafter given to the mesh generator by the use of these points at which the size is imposed. These points are introduced one by one in the quadtree and each cell is divided until the size reaches the desired value. In order to generate a pure quadrangular mesh, the weight of each point used to create the tree is doubled. A hybrid mesh mostly composed of quadrangles and few triangles is created. Triangles are thereafter subdivided into 3 quadrangles and quadrangles into 4 elements in order to get a pure quadrangular mesh which respects the prescribed density.New nodes are created during the adaptation of the contour mesh. These nodes may penetrate artificially one of the tools what may at the restart of a new ABAQUS computation impede the convergence of the node-to-surface contact algorithm.Fig. 3a shows the mesh of both part and tools before remeshing. During the adaptation procedure, a new node has been added to the boundary of the part found inside the rigid tool as shown in Fig. 3b. A specific operator is used to project this node outside the tool surface to avoid the interpenetration (Fig. 3c). Finally, in order to enhance the contact conditions, nodes can also be created to follow the tool shape especially in the case of a sharp corner (Fig. 3d).For each new FEM calculation, a new mesh is generated and the whole state variables must be transferred from the old to the new mesh. The transfer of the state variables located at the integration points is based on diffuse interpolation as presented in Section 3.1. It is important to note that a visibility criterion has been added to the diffuse approximation so that no line connecting an evaluation point and a point inside the support of interpolation can intersect the free boundaries of the part. As an example, nodes located on different sides of the crack lips cannot belong to the same support of interpolation. Nodal variables (displacements, velocities, temperatures) transfer is based on a classical FEM shape function interpolation.An algorithm has been developed to manage the h-adaptive analysis methodology including the finite element software ABAQUS/Explicit. A global flowchart of this algorithm is presented inFig. 4. The total loading time denoted as ttotal is initially split into N loading sequencesΔtseqnaccording tottotal=Σn=1NΔtseqn. However, these loading sequences can be adjusted as explained in the following steps.Initial configuration: An initial mesh of the part is performed with an element size betweenΔxgeomminandΔxmaxaccording to our geometrical error estimator.Step no 1: ABAQUS/Explicit is used with a user defined VUMAT user subroutine in order to solve the problem for the first loading sequence and the final solution (displacement and state variables) at the end of the current loading sequence for the current mesh (ℳi) is obtained.Step no 2: Mesh distortion (elongation and angle criteria) occurring during the Lagrangian configuration is analyzed on the current mesh (ℳi) in order to ensure the accuracy of the analysis. The loading sequence is reduced whenever large distorted elements are found.Step no 3: If the number of fully damaged elements does not exceeds a given threshold and if all the fully damaged elements have the smallest mesh sizeΔxmindam, these fully damaged elements are removed and the sequence remains unchanged. New boundaries are then defined with respect to a new mesh size based on the error indicators. However, if the total number of the fully damaged elements exceeds the known threshold or if the size of any fully damaged element exceedsΔxmindam, the analysis is cancelled for this loading sequence and a new load sequence is carried out with reduced loading amplitude.Step no 4: A new map of mesh sizes is generated with respect to the error indicators.Step no 5: A new quadrangular mesh (ℳi+1) is generated.Step no 6: Field variables are transferred from mesh (ℳi) to the newly created mesh (ℳi+1).Step no 7: A new ABAQUS input file for the analysis is prepared for a new loading sequence and the analysis is restarted from step 1.A tensile test is first used to analyze the efficiency of the proposed 2D adaptive methodology in terms of the mesh adaptation with respect to the plastic flow and damage localization. The second example concerns the numerical simulation of 2D axisymmetrical blanking process. The last example deals with the numerical simulation of the machining by chip formation.The dimensions of the tensile specimen are shown inFig. 5. The initial mesh is a regular coarse mesh performed with 2D quadrilateral plane stress membrane elements with reduced integration (M3D4R) taken from ABAQUS® element library.This tensile specimen is made of DP600 steel defined by the material parameters given inTable 2.A reference set of variables Cref is defined and three others sets C1, C2, C3 are created (seeTable 3) by varying respectively the Diffuse Hessian error εH(Eq. (22)),Δxminpandκ1defined in Table 1.Fig. 6 illustrates the influence of the adaptive mesh size parameters on the distribution of the equivalent plastic strain at different displacement values U. For U=18.8mm, a similar diffuse necking is observed for the four studied cases. When U=19.5mm, two nearly symmetric shear bands are visible on Cref, C2, C2 and C3. When U=19.6mm, macroscopic cracks are formed inside one shear band while the mesh in the second is coarsened due to the plastic unloading (inactive zone). This is confirmed for U=19.65mm and U=21.0mm where mesh coarsening is clearly observed when the specimen is fully broken.Fig. 7 shows the effect of the parameters defined in Table 3 on the range of the adapted loading sequences only for the reference set of parameters Cref. It is worth noticing that the loading sequences increase linearly and drops at U=17.0mm when the number of fully damaged elements increases or when the size of a damaged element exceeds the given thresholdΔxmindam.Fig. 8 shows that the numerical and the experimental tensile force-displacement curves of the DP600 steel are in good agreement for the four sets of parameters. Clearly, the solution is independent from the remeshing parameters as long as the damage smallest mesh sizeΔxmindamis kept constant. This shows that imposing the smallest mesh sizeΔxmindamis a simple and reliable way to overcome the mesh dependency when local formulation is used.Based on the results of this uniaxial tensile test, we experienced that the parameters of the error indicators influence the crack initiation time while the crack path seems insensitive to those parameters.The adaptive analysis methodology is now validated through a blanking operation of a circular thin sheet made on DP600 still defined in Table 2. The axisymmetric sheet has an initial external radius R=200.0mm and a thickness e=1.2mm. Punch diameter is 12.0mm and the clearance between the fixed die and the moving punch is 0.12mm as shown inFig. 9.The sheet is discretized with quadrangular bilinear axisymmetric elements CAX4R from ABAQUS element library. Friction between the tools and the sheet is modelled by the classical Coulomb model with a constant friction coefficient η=0.15. The different element size parameters used by the remeshing adaptive procedure are:Δxmax=1mm,Δxmaxp=0.4mm,p⁎=0.22,Δxminp=0.1mm,κ1=5,Δxmindam=0.05mm,Dmin=0.005,Dmax=0.05, εH=0.1.Fig. 10 shows the first mesh adaptation performed using the geometrical error indicator. As expected, the mesh is refined in the neighborhood of the tool cutting edges, in order to enhance the accuracy of the contact algorithm between the tools and the sheet.Fig. 11 presents different adaptive meshes for different values of the punch displacement U during the blanking process. The 2D mesh adaptation proved to be quite efficient as mesh refinement follows the contact areas together with the zones with higher plasticity and damage. In addition, the mesh is clearly coarsened inside the inactive areas (no plastic flow).When the displacement of the punch reaches U=0.441mm, a crack is initiated near the fillet of the punch (Fig. 11c). At the same time a second crack is initiated in the region of contact with the die (Fig. 11e). When U=0.474mm, the two cracks join achieving the final sheet cutting (Fig. 11f). Finally, for U=0.563mm the sheet is completely cut and we can observe that the mesh is coarsened to save computation time.The experimental and the numerically predicted fracture surfaces are represented in Fig. 11h. The computed results are in good agreement concerning the convex zone, sheared zone, fracture zone and the bur.Fig. 12 shows the decrease of the total number of elements when the mesh coarsening procedure is used during the simulation. Clearly, the mesh coarsening inside the cracked zone leads to a strong decrease in the problem size. This decreases the CPU time by a factor 1.7 compared to the CPU time without mesh coarsening.The last example focuses on 2D orthogonal high speed machining with chip formation taken from Mabrouki et al. [49]. The geometry of the workpiece and the tool insert are represented inFig. 13. The velocity of the tungsten carbide tool remains constant at 100mmin−1. The cutting angle is −6°, the rake angle is 5° and the cutting depth is e=0.2mm. Both the tool and the part are discretized using the thermomechanical 2D plane strain element CPE4RT from ABAQUS element library. The mesh of the tool is adapted before the first step and remains unchanged as shown in Fig. 13. The initial mesh of the workpiece is performed with sizeΔxmax=1.5mm and Fig. 13 shows the first adapted mesh due to the contact with the tool. The other element sizes used by the adaptive procedure are:Δxmaxp=0.02mm,p⁎=0.6,Δxminp=0.006mm,κ1=4,Δxmindam=0.003mm,dmin=0.075,dmax=0.1,εH=0.1.The contact interface between the part and the tool is modelled by a Coulomb friction law with a constant friction parameter η=0.2 and the following thermal conditions are imposed along the same interface:•The heat flux due to radiation is assumed to be negligible.The heat conduction across the contact interfaceqcis defined by:qc=ςc(Ttool−Twpiece)whereςc=20.00104Wm−2°C−1 is the gap conductance.The heat generated by frictional slidingqfalong the contact interface is given byqf=ητ(Δγ/Δt), whereτis the shear stress,Δγis the incremental slip during the time stepΔtandηis the Coulomb sliding parameter.The tool is considered as a thermoelastic material. The properties of the tool and workpiece are given inTable 4.For two different values of the tool displacement u=0.47mm and u=1.04mm, the mesh, the temperature and the equivalent plastic strain rate are shown respectively inFig. 14a–f. A first highly localized shear band (HLSB) can be clearly observed for u=0.47mm (zone A) and a second one for u=1.04mm (zone B). The mesh is locally refined in these areas as shown in Fig. 14a and d what demonstrates the efficiency of the three error indicators based on local curvature at the contact interface, accumulated plastic strain and damage gradient. When a HLSB is created, thermomechanical fields are concentrated in this band and their values rise very quickly. Temperature and strain rates reach values as high as 1200°C and 10+5s−1, respectively.We have reproduced the 2D orthogonal machining configuration as proposed experimentally by Mabrouki et al. [49] and Belhadi et al. [50].Fig. 15 show the predicted chip for a displacement of 3.8mm and the experimental chip. The serration pitch of the experimental chip is 0.3mm and we have obtained a sufficiently close value of 0.24mm.Finally, we have studied the influence of cut depth on chip formation: morphology, segmentation and evolution of adiabatic shear bands based on the adaptation of the mesh. Three cutting depths e have been used: 0.1mm, 0.2mm and 0.4mm. For a displacement U=1.26mm, the meshes associated with the 3 cutting depth values are shown respectively inFig. 16a–c. For the depth e=0.1mm, the shape of the chip is smooth and curled. However, we can still observe the mesh refinement in the shear zone. For a higher depth of cut e=0.2mm and the same displacement, we noticed the appearance of two adiabatic bands forming two chip teeth while a third one is being created. At a further cutting depth e=0.4mm, the chip cannot be curled and breaks. We can conclude that in the case of this tool workpiece pair, the reduction of the cutting depth enables the creation of a smooth chip.Fig. 17a and b shows the mesh for a displacement U=6.75mm for two cutting depth of 0.1mm and 0.2mm. For e=0.1mm, the chip remains smooth while for e=0.2mm, several chip teeth are created. We observe that the mesh is refined in the HSLB and is gradually coarsened to reach a maximum size in the area where no longer plastic flow occurs.

@&#CONCLUSIONS@&#
