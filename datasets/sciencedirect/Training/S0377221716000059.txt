@&#MAIN-TITLE@&#
Global optimization using q-gradients

@&#HIGHLIGHTS@&#
Two global optimization methods based on the q-gradient are developed: q-G and q-CG.q-G and q-CG are q-analogs of the steepest descent and conjugate gradient methods.Convergence of q-G and q-CG with Gaussian perturbations is proved.The methods are compared with their classical versions and with other alternatives.q-G and q-CG are very competitive with the alternative methods on multimodal problems.

@&#KEYPHRASES@&#
Metaheuristics,Global optimization,q-calculus,q-gradient vector,Convergence,

@&#ABSTRACT@&#
The q-gradient vector is a generalization of the gradient vector based on the q-derivative. We present two global optimization methods that do not require ordinary derivatives: a q-analog of the Steepest Descent method called the q-G method and a q-analog of the Conjugate Gradient method called the q-CG method. Both q-G and q-CG are reduced to their classical versions when q equals 1. These methods are implemented in such a way that the search process gradually shifts from global in the beginning to almost local search in the end. Moreover, Gaussian perturbations are used in some iterations to guarantee the convergence of the methods to the global minimum in a probabilistic sense. We compare q-G and q-CG with their classical versions and with other methods, including CMA-ES, a variant of Controlled Random Search, and an interior point method that uses finite-difference derivatives, on 27 well-known test problems. In general, the q-G and q-CG methods are very promising and competitive, especially when applied to multimodal problems.

@&#INTRODUCTION@&#
Global optimization problems are present in many applications, especially in science and engineering, and thus, the development of effective methods capable of solving such problems with robustness and efficiency is important. Many local search methods, including gradient-based descent algorithms (e.g., steepest decent, quasi-Newton and conjugate gradient methods) and some direct search methods, are generally fast and precise. However, the presence of multiple optima makes global optimization difficult for these local optimizers unless the search is started sufficiently close to the global optimum or multiple starting points are used. Moreover, in many applications where the objective function is a black-box whose values are obtained via a computer simulation, the gradients of the objective function are typically not available. Metaheuristics such as evolutionary algorithms and simulated annealing are better suited for escaping local minima but sometimes may require too many function evaluations to converge to the global optimum.The conflict between robustness and computing efficiency, global versus local, led to the development of hybrid methods in an attempt to combine the best of two worlds. For example, Hedar and Fukushima (2006) and Chelouah and Siarry (2005) combine tabu search with well-known direct search methods. Moreover, scatter search (Herrera, Lozano, & Molina, 2006; Martí, Laguna, & Glover, 2006) and variable neighborhood search (Hansen & Mladenović, 1997) are well-established frameworks that effectively combine global and local search. For a review of some hybrid metaheuristics, see Blum, Aguilera, Roli, and Sampels (2008).In this sense, we develop novel metaheuristics that extend the search strategies used by gradient-based algorithms to continuous global optimization problems. These methods use the concept of a q-derivative from the theory of q-calculus (Kac & Cheung, 2002; Ernst, 2000) to balance local and global search. Here, q is a dilation parameter that is used to control the degree of localness of the search. The proposed methods do not really require gradients of the objective function so they can be used for black-box and derivative-free optimization. Instead, they compute a q-analog of the gradient of the objective function, which is then used to determine an appropriate search direction.The history of q-calculus dates back to the beginning of the last century when, based on pioneering works of Euler and Heine, Frank Hilton Jackson developed the q-calculus in a systematic way (Ernst, 2003). His work gave rise to q-analogs of series, functions and special numbers (Ernst, 2003; Chaundy, 1962). More importantly, he reintroduced the concept of the q-derivative (Jackson, 1909), which is also known as the Jackson derivative. Soterroni, Galski, and Ramos (2011, 2013a); Soterroni, Galski, and Ramos (2013b) then used the q-derivative to develop the q-gradient vector, which was applied to global optimization problems. The q-gradient vector is an extension of the classical gradient vector with the aid of the parameter q and with the property that it reduces to the classical gradient when q equals 1.In this paper, we present two metaheuristics based on the q-gradient vector: the q-G method, a generalization and q-analog of the steepest descent method, and the q-CG method, a generalization and q-analog of the conjugate gradient method (Fletcher & Reeves, 1964). Alternative versions of these methods appeared in Soterroni et al. (2013b) and Gouvêa, Soterroni, Scarabello, Sumida, Corrêa, Galski, and Ramos (2013) but this paper provides a version that uses Gaussian perturbations along with a convergence proof and more extensive numerical results. In both generalizations, the q-gradient of the objective function is used instead of the classical gradient when computing the search direction. The advantage of using q-gradients is that it allows the search to be performed in a more diverse set of directions, making it possible to escape local minima. The q-analogs are implemented so that the search process gradually shifts from global in the beginning to almost local search in the end, which is reminiscent of the cooling process in simulated annealing. Moreover, Gaussian perturbations are used in some iterations to ensure the convergence of the methods to the global minimum in a probabilistic sense. The standard deviations of these Gaussian perturbations are geometrically reduced whenever there is no progress to facilitate local search. To evaluate the performance of the q-gradient-based methods, we compare them with their classical versions and also with CMA-ES, a variant of Controlled Random Search, an interior point method, the Nelder–Mead simplex algorithm, and another evolution strategy on 10-D instances of 27 well-known test functions. In general, the q-G and q-CG methods are very promising and competitive, especially on the multimodal problems.This paper is structured as follows: the q-gradient vector and its properties are discussed in Section 2. In Section 3, the q-gradient-based methods are described. The convergence of methods based on the q-gradient vector are proved in Section 4. Section 5 presents the numerical results, and finally, Section 6 presents the conclusions.Given a differentiable function of a single variable f(x) and a parameterq∈R,the q-derivative (or Jackson derivative) of f(x) is defined as(1)Dqf(x)={f(qx)−f(x)qx−xifq≠1andx≠0f′(x)otherwiseNote that when x ≠ 0 and q is close but not equal to 1, Dqf(x) is a finite difference derivative at x. Next, given a differentiable function of n variables f(x), Soterroni et al. (2013a); Soterroni et al. (2013b) defined the first-order partial q-derivative of f(x) with respect to the variable xiby(2)Dq,xif(x)={f(x1,...,qxi,...,xn)−f(x1,...,xi,...,xn)qxi−xiifq≠1andxi≠0∂f(x)∂xiotherwise={f(x+(q−1)xie(i))−f(x)(q−1)xiifq≠1andxi≠0∂f(x)∂xiotherwise,where e(i) is the ith column of the identity matrix In. Moreover, given a parameter vectorq=(q1,…,qn)∈Rn,the q-gradient is defined in Soterroni et al. (2013a); Soterroni et al. (2013b) to be the vector of the n first-order partial qi-derivatives of f:(3)∇qf(x)=[Dq1,x1f(x)…Dqi,xif(x)…Dqn,xnf(x)]T.Note that the classical gradient ∇f(x) is recovered in the limit as qi→ 1, for alli=1,…,n.Although we defined the q-gradient for differentiable functions, we can also define it in the same manner for nondifferentiable or even discontinuous functions provided qi≠ 1 and xi≠ 0 for all i.The following proposition says that when f(x) is a linear function, the q-gradient is identical to the ordinary gradient. The proof is straightforward so it is omitted.Proposition 1Iff(x)=c0+cTx,wherec0∈Randc∈Rn,then for anyx,q∈Rn,∇qf(x)=∇f(x)=c.The q-gradient is a special case of the simplex gradient (Conn, Scheinberg, & Vicente, 2009; Regis, 2015), which is widely used in derivative-free optimization. Given a set ofn+1affinely independent pointsX={x(0),x(1),…,x(n)}⊂Rnwhere f has been evaluated, the simplex gradient of f with respect toXis the gradient of the linear model that interpolates the data points (x(0), f(x(0))), (x(1), f(x(1))),…,(x(n),f(x(n))). Givenq,x∈Rn,where qi≠ 1 and xi≠ 0 for all i, the pointsx,x+(q1−1)x1e(1),…,x+(qn−1)xne(n)are affinely independent and ∇qf(x) is the simplex gradient of f with respect to these points. Regis (2015) proved calculus rules for simplex gradients that are similar to those satisfied by ordinary gradients. Similar rules apply to q-gradients, including a product rule and a quotient rule. In the propositions below, f and g are functions fromRntoRanddiag(a1,…,an)denotes a diagonal matrix whose diagonal entries area1,…,an. The proofs when xi≠ 0 and qi≠ 1 for all i are found in Regis (2015).Proposition 2For anyx,q∈Rnand for any constant c,(a)∇q(f+g)(x)=∇qf(x)+∇qg(x),and∇q(cf)(x)=c∇qf(x).For anyx,q∈Rn,∇q(fg)(x)=f(x)∇qg(x)+diag(g(x+(q1−1)x1e(1)),…,g(x+(qn−1)xne(n)))∇qf(x),For anyx,q∈Rnfor whichg(x),g(x+(q1−1)x1e(1)),…,g(x+(qn−1)xne(n))are all nonzero,∇q(fg)(x)=diag(1/g(x+(q1−1)x1e(1)),…,1/g(x+(qn−1)xne(n)))[g(x)∇qf(x)−f(x)∇qg(x)g(x)].Finally, q-gradients satisfy an error bound similar to that for simplex gradients. The next proposition follows immediately from Theorem 2.11 in Conn et al. (2009).Proposition 5Letx(0)∈Rnand letq∈Rnsuch thatxi(0)≠0and qi≠ 1 for all i. Suppose f is continuously differentiable in an open domain Ω containing the closed ballB(x(0),Δ)={x∈Rn:∥x−x(0)∥≤Δ},whereΔ=max1≤i≤n|(qi−1)xi(0)|. Further, suppose that ∇f is Lipschitz continuous in Ω with Lipschitz constant ν > 0. Then for all x ∈ B(x(0), Δ)∥∇f(x)−∇qf(x)∥≤ν(1+n1/2∥L^−1∥/2)Δ,whereL^=1Δdiag((q1−1)x1(0),…(qn−1)xn(0)).One common optimization strategy employs the line search framework, which uses an iterative procedure that starts from an initial pointx(0)∈Rnand generates a sequence of iterates {x(k)} given by(4)x(k+1)=x(k)+α(k)d(k),where k is the iteration number,d(k)∈Rnis the search direction and α(k) is the step length or the distance moved along d(k) (Vanderplaats, 1984).Gradient-based line-search methods are characterized by how the search direction and the step length in Eq. (4) are computed. The steepest descent method, for example, setsd(k)=−∇f(x(k)),and the step length α(k) is usually determined by a line-search technique that minimizes the objective function along the direction d(k). The q-G method (Soterroni et al., 2013a; Soterroni et al., 2013b) is a q-analog of the steepest descent method where the search direction is the negative of the q-gradient of the objective function,−∇qf(x(k)),as defined in Eq. (3). The q-CG method (Gouvêa et al., 2013) is a q-analog of the Fletcher–Reeves conjugate gradient method (Fletcher & Reeves, 1964) where the first search direction is the negative of the q-gradient and the succeeding directions are linear combinations of the negative of the q-gradient with previous directions. Whenq≠[1,…,1]T,the search directions for the q-G and q-CG methods are not necessarily descent directions, and this makes it possible for the algorithms to escape local minima.The correct specification of the parameter q is critical to the performance of the q-gradient-based methods. Given a function of n variables f(x), a set of n different parameters qi≠ 1 (i=1,…,n) are needed to compute the q-gradient of f. As in Soterroni et al. (2011); Soterroni et al. (2013a); Soterroni et al. (2013b), we draw the values ofqi(k)from a Gaussian probability distribution such thatqi(k)xi(k)has a standard deviation σ(k) that decreases as the iterations proceed. This makes the algorithm gradually transition from stochastic global search during the initial iterations to a local and almost deterministic search close to the end of the optimization process. As σ(k) approaches zero, the values ofqi(k)tend to unity and the q-G and q-CG algorithms behave like their classical versions. Note that if σ(k) decreases too quickly, the algorithm may be trapped in a local minimum.As usual, the calculation of the step length α involves a tradeoff between the achievement of a sensible reduction in the objective function value and the number of function evaluations needed to obtain it (Nocedal & Wright, 1999). Generally, gradient-based methods perform a line search along the descent direction to determine the step length (Pillo & Palagi, 2002). Since the search directions generated by the q-G and q-CG algorithms are not necessarily descent directions, the step length at iteration k is computed simply via a geometric recursion:α(k+1)=β·α(k),where 0 < β < 1. For simplicity, β is also the same reduction factor used to update the standard deviation σ(k) that is used for generating the parameter vector q. As the step length decreases (and the values ofqi(k)tend to unity), a smooth transition to an increasingly local search process occurs.The main steps of the q-G and q-CG algorithms for solving a bound constrained global optimization problem are given below. In Step 0, the best point is set to the initial point. Then, in Step 1, we distinguish between two types of iterations: a regular iteration that uses the q-gradient and an iteration that uses Gaussian perturbations. If the algorithm is performing a q-gradient iteration, then the parameter vector q(k) is selected in Step 1 in such a way thatqi(k)xi(k)comes from a Gaussian distribution with meanxi(k)and standard deviation σ(k). Otherwise, it jumps to Step 8 to perform a Gaussian iteration. In Step 2, the q-gradient is calculated at the current point x(k). Next, in Step 3, the search direction d(k) is calculated depending on whether we are performing the q-G method or the q-CG method. In Step 4, the new iteratex(k+1)is calculated. Then, in Step 5, we use an absorbing transformationρDto ensure that the actual iterate is in the search space, and then evaluate the function there. In Steps 6 and 7, the current best point and the parameters σ(k) and α(k) are updated, and then it jumps to Step 10 to check if the stopping criterion is met.If the algorithm is performing a Gaussian iteration, then a series of r Gaussian perturbations are generated in Step 8. Then, in Step 9, the next iteratex(k+1)is set to be the best among the previous iterate x(k) and the outcomes of the Gaussian perturbationsy(k,1),…,y(k,r). Moreover, the standard deviation of the Gaussian perturbations is reduced by a factor 0 < η < 1 if the Gaussian iteration did not improve the previous iterate x(k). Finally, as before, we check if the stopping condition is met in Step 10.Algorithm (q-G and q-CG for Bound Constrained Global Optimization)Inputs:(1)f:D→R,whereD=[ℓ,u]⊆Rn(objective function)x(0)∈D(initial point)ρD:Rn→Dsuch thatρD(x)=xfor allx∈D(deterministic absorbing transformation for the trial iterates that fall outsideD)σ(0) > 0 (initial standard deviation of Gaussian distribution needed to generate the parameter q)α(0) > 0 (initial step size)0 < β < 1 (rate of decrease of step size and standard deviation of Gaussian distribution for generating the parameter q)θ(0), θmin> 0 (initial and minimum standard deviation of Gaussian perturbations)m > 1 and m is an integer (interval between Gaussian iterations)r > 0 and r is an integer (number of Gaussian perturbations within each Gaussian iteration; the default value we used isr=n+1)0 < η ≤ 1 (rate of decrease of the standard deviation of the Gaussian perturbations; the default value we used isη=1/2)ξ > 0 (step size for finite-difference derivatives)Step 0: Setk=0,xbest=x(0)andθ(m)=θ(0).Step 1: If k ≠ 0 andmod(k,m)=0,then go to Step 8 to perform a Gaussian iteration; Else, perform a q-gradient iteration and selectq(k)=(q1(k),…,qn(k))as follows: Fori=1to n,(1a)Ifxi(k)≠0,then drawqi(k)from a Gaussian distribution with mean 1 and standard deviationσ(k)/|xi(k)|; Else, setqi(k)=1.Ifqi(k)xi(k)∉[ℓi,ui],then setqi(k)xi(k)to the closer endpoint and update the value ofqi(k).EndStep 2: Fori=1to n,(2a)Ifqik≠1,sety(k,i)=x(k)+(qi(k)−1)xi(k)e(i); Else, sety(k,i)=x(k)+ξe(i). Here, e(i) is the ith column of the identity matrix In.Evaluate f(y(k, i)).If f(y(k, i)) < f(xbest), resetxbest=y(k,i).EndUsef(x(k)),f(y(k,1)),…,f(y(k,n))to calculate ∇qf(x(k)).Forq-G Method:Step 3: Computed(k)=−∇qf(x(k)).Forq-CG Method:Step 3: If k > 0, setδ(k)=∇qf(x(k))T∇qf(x(k))/∇qf(x(k−1))T∇qf(x(k−1)); Else, setδ(k)=0. Computed(k)=−∇qf(x(k))+δ(k)d(k−1).Step 4: Computex(k+1)=x(k)+α(k)·d(k)Step 5: Setx(k+1)=ρD(x(k+1))and evaluatef(x(k+1))Step 6: Iff(x(k+1))<f(xbest)setxbest=x(k+1)Step 7: Setσ(k+1)=β·σ(k)andα(k+1)=β·α(k)and go to Step 10.Step 8: Perform a Gaussian iteration: Fori=1to r(8a)Draw z(k, i) from a Gaussian distribution with mean 0 and covariance matrix (θ(k))2In.Sety(k,i)=ρD(x(k)+z(k,i))and evaluate f(y(k, i)).If f(y(k, i)) < f(xbest), resetxbest=y(k,i).EndStep 9: Seti^=argmin1≤i≤rf(y(k,i)). Iff(y(k,i^))<f(x(k)),thenx(k+1)=y(k,i^)andθ(k+m)=θ(k); Else,x(k+1)=x(k)andθ(k+m)=max(ηθ(k),θmin).Step 10: If stopping criterion is met, return xbestand f(xbest). Otherwise, incrementk=k+1and go back to Step 1.The stopping criterion for the algorithm could be the maximum number of function evaluations or a desired accuracy. The initial standard deviation σ(0) determines how global the search is. In this sense, it is reminiscent of the initial temperature in a Simulated Annealing algorithm. For multimodal functions, it must be high enough to allow the method to properly sample the search space. The reduction factor β controls the speed of the transition from global to local search. A β close to 1 reduces the risk of being trapped in a local minimum.Moreover, Gaussian perturbations are used in some iterations (Step 8) to guarantee the convergence of the methods to the global minimum in a probabilistic sense. The importance of the Gaussian perturbations is well illustrated in Fig. 1, which shows the contour lines of the functionf(x1,x2)=2+(x1−2)2+(x2−2)2if(x1−2)2+(x2−2)2≤1; elsef(x1,x2)=3, with initial point at(x1,x2)=(0.5,0.5)and the points sampled by the q-G algorithm.Note that the function f has a global minimum at(x1,x2)=(2,2). For Fig. 1a, where the q-G method does not use Gaussian perturbation, the points are sampled just at the initial point for this kind of function because the q-gradient at that point is always the zero vector. When we use Gaussian perturbation in the q-G method, the iterates can potentially reach any region of the search space, making it possible to find the global minimum (see Fig. 1b). The following section proves the convergence of the q-gradient-based methods that use Gaussian perturbations.Let f be a deterministic measurable objective function defined on a setD⊆Rn. We wish to find the global minimum of f overDif it exists. In this paper, we focus on the case whereD=[ℓ,u]⊆Rnis a compact box-constrained region. It is well-known that if f is continuous overD,then f has a global minimum point overD.Since the q-gradient-based optimization methods are stochastic and the objective function f is deterministic, the convergence of these methods will be established by showing that they follow the Generalized Adaptive Random Search (GARS) framework for deterministic functions (Regis, 2010) described below. The iterates of the q-gradient-based methods will be treated as n-dimensional random vectors whose realizations are inD⊆Rn.Consider a stochastic algorithm whose iterates are given by the sequence of random vectors {Y(k)}k ≥ 1 defined on a probability space(Ω,B,P),where the random vectorY(k):(Ω,B)→(D,B(D))represents the kthfunction evaluation point. Here, Ω is the sample space,Bis a σ-field of subsets of Ω, andB(D)are the Borel sets inD. This algorithm is said to follow the GARS framework if it has the following structure:Algorithm (GARS Framework (Regis, 2010))Inputs:(1)The objective functionf:D→R,whereD⊆Rn.A deterministic absorbing transformationρD:Rn→D,i.e.ρD(x)=xfor allx∈D.A collection of intermediate random elements{Λi,j:(Ω,B)→(Ωi,j,Bi,j):i≥0andj=0,1,…,ri}that are used to determine the trial random vector iterates. These Λi, j’s could be random variables, random vectors or other types of random elements defined on the same probability space(Ω,B,P).Step 0. Setk=0.Step 1. Generate a realization ofY(k):(Ω,B)→(Rn,B(Rn))as follows:Step 1.1 For eachj=0,…,rk,generate a realization of the intermediate random elementΛk,j:(Ω,B)→(Ωk,j,Bk,j)according to some probability distribution.Step 1.2 SetY(k)=Φk(Ek)for some deterministic function Φk, whereEk:={Λi,j:i=0,1,…,k;j=0,1,…,ri}is the collection of all intermediate random elements up to the current iteration.Step 2. SetX(k)=ρD(Y(k))and evaluate f(X(k)).Step 3. Incrementk=k+1and go back to Step 1.Regis (2010) proved several theorems that provide necessary conditions that guarantee the convergence of a GARS algorithm to the global minimum in a probabilistic sense. We use one of these theorems to prove the convergence of a q-gradient-based method that uses Gaussian perturbations. This theorem applies to GARS algorithms that use the elliptical distribution, which is a generalization of the Gaussian distribution.LetZ:(Ω,B)→(Rn,B(Rn))be a random vector that has an elliptical distribution. If Z has a density, then it has the form (Fang and Zhang, 1990)(5)g(z)=γ[det(V)]−1/2Ψ((z−u)TV−1(z−u)),z∈Rnwhereu∈Rn,V is a symmetric and positive definite matrix, Ψ is a nonnegative function over the positive reals such that∫0∞z(n/2)−1Ψ(z)dz<∞,and γ is the normalizing constant given by(6)γ=12π−n/2Γ(n/2)(∫0∞zn−1Ψ(z2)dz)−1.Elliptical distributions generalize widely used probability distributions, including the multivariate Gaussian distribution (Ψ(y)=e−y/2). The following result states that GARS algorithms that use elliptical distributions, where Ψ is monotonically nonincreasing and the eigenvalues of V are bounded away from 0, converge to the global minimum almost surely.Proposition 6Regis (2010)SupposeDis a bounded subset ofRnsuch thatψD(δ):=infw∈Dμ(B(w,δ)∩D)>0for all δ > 0, where B(w, δ) is the open ball centered at w with radius δ and μ is the Lebesgue measure onRn. Let f be a real-valued measurable function defined onDsuch thatf*:=infx∈Df(x)>−∞and assume that f is continuous at a global minimizer x* of f overD. Consider a GARS algorithm whose iterates are {Y(k) : k ≥ 0} and whose sequence of best iterates are {Y(k)* : k ≥ 0}. Suppose there is a subsequence {kt}t ≥ 1 such that for each t ≥ 1, we haveY(kt)=U(t)+Z(t),whereU(t)=Φt(E(kt)−1)for some deterministic function Φtand Z(t) is a random vector whose conditional distribution givenσ(E(kt)−1)is an elliptical distribution with conditional density given by(7)gt(z|σ(E(kt)−1))=γ[det(Vt)]−1/2Ψ(zTVt−1z),z∈Rn,where γ is defined in (6). For each t ≥ 1, let λtbe the smallest eigenvalue of Vt. Furthermore, suppose the following properties hold: [P1] Ψ is monotonically nonincreasing; and [P2]inft≥1λt>0. Thenf(X(k)*)⟶f*a.s.We now prove the convergence of the q-gradient-based methods that use Gaussian perturbations in the following proposition.Proposition 7Suppose q-G or q-CG with Gaussian perturbation is applied to a real-valued function f onD=[ℓ,u]⊆Rnsuch that f*=infx∈Df(x)>−∞. Moreover, suppose that f is continuous at a global minimizerx*of f overD. Then f(xbest) → f*almost surely (a.s.).First, it is easy to verify thatD=[ℓ,u]is a bounded subset ofRnthat satisfies the conditionψD(δ)>0for all δ > 0 in Proposition 6 (see Regis, 2010). Next, we use the notation in the descriptions of q-G and q-CG with Gaussian perturbation except we use the uppercase letters for some of the vectors to emphasize that they are random vectors (e.g., Y(k, i) instead of y(k, i)). For convenience, defineY(k,0)=X(k)for each k ≥ 0. Also, letrk=nfork=0and for all k such thatmod(k,m)≠0(iterations that use the q-gradient); else letrk=r(Gaussian iterations). Note that{Y(k,i):k≥0,i=0,1,…,rk}is the set of all points where the objective function is evaluated if the algorithms are run indefinitely. Here, k is the iteration number and i represents the index of a function evaluation point within each iteration. Moreover, letEk,ibe the set of all random vectors that were generated up to Y(k, i) (this includes the random vectors q(j), j ≤ k, and previous Gaussian random vectors). Let {kt}t ≥ 1 be the subsequence of Gaussian iterations, i.e.,kt=tmfor all t ≥ 1. From the algorithm description,(8)Y(kt,i)=Y(kt,0)+Z(kt,i),i=1,…,r,whereZ(kt,i)is a random vector whose conditional distribution givenσ(Ekt,i−1)(the σ-field generated by the random vectors inEkt,i−1) is a Gaussian distribution with mean vector 0n × 1 and covariance matrixVt=(θ(kt))2In. Hence,Z(kt,i)has conditional densitygt(z|σ(Ekt,i−1))=(2π)−n/2[det(Vt)]−1/2exp(−zTVt−1z/2),∀t≥1,i=1,…,r.In Eq. (8), note thatY(kt,0)=Φt(Ekt,i−1)for some deterministic function Φt. Moreover, note thatZ(kt,i)has an elliptical distribution whereΨ(w)=e−w/2in (5) is a monotonically nonincreasing function. Furthermore, note that(θ(kt))2is the only eigenvalue of Vt(and it has multiplicity n). Sinceinft≥1θ(kt)≥θmin>0,it follows from Proposition 6 (which is Theorem 6 in Regis, 2010) that f(xbest) → f* a.s.□We evaluated the performance of the q-G and q-CG methods on 10-D instances of twenty seven well-known test functions: fourteen test functions from the CEC-2005 benchmark (Suganthan et al., 2005), five multimodal functions that are widely used in the literature, and eight unimodal functions from Moré, Garbow, and Hillstrom (1981). The test problems from CEC-2005 consists of nine multimodal functions and five unimodal functions. In all, we used 14 multimodal problems and 13 unimodal problems. Table 1summarizes the characteristics of the test problems we used.The q-G and q-CG methods are compared with seven optimization algorithms: Steepest Descent (SD), Nonlinear Conjugate Gradient (CG) (Fletcher & Reeves, 1964), an interior point algorithm (IPOPT) (Wächter & Biegler, 2006), Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) (Hansen, Müller, & Koumoutsakos, 2003), Controlled Random Search with Local Mutation (CRS2-LM) (Kaelo & Ali, 2006), another evolution strategy (ISRES) (Runarsson & Yao, 2005), and the Nelder–Mead direct search method (Nelder & Mead, 1965). We implemented the q-G, q-CG, SD and CG methods in Fortran while we used publicly available software for the other methods. In particular, we run IPOPT, ISRES, Nelder-Mead, and CRS2-LM using Matlab through the OPTI toolbox (Currie & Wilson, 2012) and the NLopt software (Johnson). Since exact derivatives of the test problems are not used, the gradient-based methods SD, CG and IPOPT use finite-difference derivatives. Moreover, the local search methods SD, CG, IPOPT and Nelder–Mead are run from multiple starting points so they have the potential to find the global minimum. More precisely, they are restarted from a point in the search space that is as far away as possible from previously visited points every time they converged, provided the computational budget has not been exhausted.Thirty trials of all algorithms are performedx on all problems and each run of each algorithm is given a computational budget of 10,000 function evaluations. To ensure fair comparison, the different algorithms use the same starting point in each trial. Moreover, in the event that any algorithm terminates before 10,000 function evaluations, it is restarted from a new point in the search space of the problem.For q-G and q-CG, we set the values of the parameters as follows:α(0)=0.1×L,β=0.999andθ(0)=0.2×Landσ(0)=0.2×L,where L is the largest distance within the search spaceD=[ℓ,u]defined byL=∥u−ℓ∥. Moreover, Gaussian perturbations are utilized after everym=10iterations. For the other solvers, we use the default parameters settings. The optimal setting for algorithm parameters is typically problem dependent. However, for comparison purposes, we fixed the parameter settings to reasonable values for all test problems as recommended by Barr, Golden, Kelly, Resende, and Stewart (1995). In Section 5.4, we perform some sensitivity analysis of the performance of q-G and q-CG with respect to one of these parameters.We run the q-G, q-CG, SD and CG methods on an Intel(R) Core(TM) i5-2410M 2.30 GigaHertz 64-bit laptop with 6 GigaByte using the Intel Fortran Compiler Professional Edition for Linux version 12.04.4. We run the other methods using Matlab R2013b on an Intel(R) Core(TM) i7-4770 CPU 3.4 GigaHertz 3.00 GigaHertz 64-bit desktop with 16GigaByte RAM.The algorithms are compared in two ways. First, the algorithms are compared in terms of the best objective function values obtained after 10,000 function evaluations. Then the algorithms are compared using data profiles (Moré & Wild, 2009), which are particularly suitable when function evaluations are expensive. These comparisons are discussed in the next two subsections.Tables 2and 3provide the minimum (best), maximum (worst), median, mean and standard error of the best function values over 30 trials for q-G, q-CG and five alternative algorithms after 10,000 function evaluations for the multimodal and unimodal test problems, respectively. The best values for each statistic are enclosed in boxes. Because of space limitations, we do not present the statistics for the ISRES and Nelder–Mead methods since their performances are not as good as the other methods on the test functions in this study. However, these methods are included in the comparisons using data profiles in the next section.Table 2 shows that q-G and q-CG are better than their classical versions (SD and CG) on the multimodal functions. In particular, q-G is better than or comparable to SD on 12 of the multimodal functions (all except Griewank and F07) while q-CG is better than or comparable to CG on 11 of these functions (all except Griewank, F07 and F12). Moreover, q-G and q-CG are generally better than IPOPT and are competitive with CMA-ES and CRS2-LM on the multimodal problems.As for unimodal functions, Table 3 shows that IPOPT had generally the best performance and this is not surprising since it is a well-developed gradient-based solver for local optimization. As expected, q-G and q-CG do not perform as well as the gradient-based solvers IPOPT, SD and CG on many of the unimodal functions since they are intended for problems with multiple local minima. However, for the unimodal functions from the CEC-2005 benchmark, q-G and q-CG methods are generally better than IPOPT and the classical versions, and they are competitive with CMA-ES and CRS2-LM methods, except on F03.Finally, although the q-gradient-based algorithms are tested on 10-D problems, these algorithms can also be applied to higher dimensional problems. Moreover, we expect similar relative performance compared to the other methods on the higher dimensional instances of the same test problems. However, since a q-gradient is calculated before an actual iterate is obtained, the algorithm would take longer to yield improving solutions as the dimension increases. Hence, the computational budget would have to be increased to achieve the same level of performance on the test problems. A more thorough analysis of the performance of the q-gradient-based methods on higher dimensional problems is beyond the scope of this paper and will be the subject of future work.We also compare the performance of q-G or q-CG with alternative methods using data profiles (Moré & Wild, 2009), which are suitable when function evaluations constitute the dominant computational cost in running the algorithm. Such functions are found in many engineering applications. Although our test problems are not really computationally expensive, the results of algorithms on these test problems are expected to be similar to their results on truly expensive functions with the same structure as our test problems.LetPbe the set of problems where each problem p corresponds to a pair consisting of a particular test problem (e.g., Ackley) and a particular starting point. Since there are 27 test problems and 30 starting points (corresponding to the 30 trials), there are27×30=810problems for the data profiles. Moreover, letSbe the set of optimization solvers. In the comparisons involving q-G, q-CG and alternative methods, there are 9 solvers (q-G, q-CG, SD, CG, IPOPT, ISRES, NelderMead, CMA-ES and CRS2-LM).Data profiles require a “convergence test”, which we define first. When function evaluations are expensive, algorithms are compared given a fixed and relatively limited number of function evaluations. Given a computational budget of μffunction evaluations, let fLbe the best objective function value obtained by any of the solvers inSon a particular problemp∈Pwithin μfof function evaluations. Given a tolerance τ > 0, a point x obtained by a solver is said to satisfy the convergence test iff(x(0))−f(x)≥(1−τ)(f(x(0))−fL),where x(0) is the starting point corresponding to problem p. Here, x is required to achieve a reduction that is1−τtimes the best possible reductionf(x(0))−fL. For our numerical experiments, we useτ=0.05. Hence, an algorithm satisfies the convergence test on problemp∈Pif it achieves at least 95 percent of the best possible reduction by any of the solvers on problem p.Next, given a solvers∈Sand γ > 0, Moré and Wild (2009) define the data profile of a solver s with respect to γ byds(γ)=1|P||{p∈P:tp,s≤γ(np+1)}|,where tp, sis the number of function evaluations required by solver s to satisfy the convergence test on problem p and npis the number of variables in problem p. For a given solver s and any γ > 0, ds(γ) is the fraction of problems “solved” (i.e., problems where the solver generated a point satisfying the convergence test) by s withinγ(np+1)function evaluations (equivalent to γ simplex gradient estimates (Moré & Wild, 2009)).Fig. 2 shows the data profiles of the various algorithms on the 27 test problems we used. The data profiles are calculated up to 9900 function evaluations, which is equivalent to 900 simplex gradient estimates on 10-D problems. Moreover, Fig. 3shows separate data profiles for the multimodal and unimodal problems.The data profiles in Fig. 2 show that q-G and q-CG are much better than their classical versions (SD and CG), IPOPT, ISRES and Nelder–Mead. In addition, the profiles show that q-G and q-CG are competitive with CMA-ES and CRS2-LM for the functions in this study. In particular, both q-G and q-CG satisfy the convergence test in about 85 percent of the problems after 500 simplex gradient estimates. In contrast, SD, CG, IPOPT and NELDERMEAD satisfy the convergence test for only about 60–70 percent of the problems given the same computational budget. Moreover, the performance of ISRES is worse. It satisfies the convergence test for less than 50 percent of the problems after 500 simplex gradient estimates. Finally, CMA-ES and CRS2-LM satisfy the convergence test for about 80 percent and 75 percent of the problems, respectively, given the same budget.The separate data profiles for multimodal functions and unimodal functions in Fig. 3a and b shows roughly similar patterns of performance as the data profiles for all functions. On the multimodal functions, q-G and q-CG are competitive with CMA-ES and are generally much better than the other methods, especially in later iterations (after 300 simplex gradient estimates). On the unimodal functions, q-G and q-CG are competitive with CMA-ES and CRS2-LM and are better than the other methods after about 100 simplex gradient estimates. As expected, the data profiles of each algorithm for the unimodal problems are better compared to those for the multimodal problems. In particular, both q-G and q-CG satisfy the convergence test for nearly all problems within 100 simplex gradient estimates.The fact that the q-gradient-based methods are competitive with CMA-ES on a wide range of test problems is an indication of the effectiveness of these methods. CMA-ES is among the state-of-the-art in the evolutionary computation and numerical optimization communities. Variants of CMA-ES have consistently performed at the top in various benchmarking competitions.To analyze the robustness of the methods, we perform sensitivity analysis of the performance of q-G and q-CG by varying the parameter σ(0) (the initial standard deviation of the Gaussian distribution used for calculating the q-gradient). We set the other parameters of q-G and q-CG as follows:α(0)=0.1×L,β=0.999andθ(0)=0.2×L,where L is again the largest distance within the search space. As before, Gaussian perturbations are utilized after every 10 iterations. For purposes of analysis, we considered only 16 functions from Table 1.Fig. 4shows the data profiles for q-G and q-CG with different values of σ(0) and their respective classical versions (SD and CG), on all test problems. Figs. 5and 6show separate data profiles for 8 multimodal and 8 unimodal problems for the q-G and q-CG algorithms, respectively. These data profiles show that both q-G and q-CG are better than their classical versions, especially on the multimodal problems. From Fig. 4, the q-G and q-CG algorithms satisfy the convergence test in at least 80 percent of the problems after 400 simplex gradient estimates while SD and CG satisfy the convergence test for only about 65 percent of the problems within the same computational budget. Moreover, the performances of q-G and q-CG with different values of σ(0) are similar with somewhat better results in the long run for larger values of this parameter. The advantage of larger values of σ(0) is more pronounced on the multimodal problems as can be seen from Figs. 5 and 6. This is because for smaller values of σ(0), q-G and q-CG perform the search more locally, while for larger values of σ(0), the search tends to be more global. For the unimodal problems, the performances of q-G and q-CG do not appear to be sensitive to the choice of σ(0).Although these analyses show that the q-gradient-based methods are somewhat robust to the choice of σ(0), it is still important to properly select this parameter. The value of σ(0) should not be too small so that the algorithm does not behave like its classical version quickly. Also, it should not be too large so that the iterates do not escape the search space frequently. In this sense, we setσ(0)=0.2×Lfor all functions and for both algorithms and the data profiles show that this is a reasonable setting for the test problems. It may not be the best parameter setting for every test function, but it is good enough for a wide range of problems.The average run times (over 30 trials) for all algorithms on all test problems after 10,000 function evaluations are reported in Table 4. Note that the average run times for q-G and g-CG are consistently smaller than those for the classical versions SD and CG, which are also run on the same machine. Moreover, although direct comparison of run times with the other methods is not easy because of the different machines, the average run times for the q-gradient-based methods are of the same order of magnitude and are comparable, if not better, than the average run times for the other methods. Finally, we note that if these functions happen to be computationally expensive (e.g., each function evaluation takes at least a few minutes), then these run times would be small in comparison with the time spent on function evaluations. In this situation, what matters more is how well the algorithms perform given a fixed computational budget of function evaluations and this can be seen from the data profiles we reported.

@&#CONCLUSIONS@&#
In this paper, we presented two global optimization methods based on the q-gradient vector: the q-G and q-CG methods, which are q-analogs and generalizations of the classical steepest descent and conjugate gradient methods, respectively. The q-gradient, used by the q-G and q-CG methods to compute their search directions, provides these algorithms with an effective mechanism for escaping local minima. The search process gradually shifts from global search in the beginning to local search in the end. This transition from global to local search is controlled by four free parameters that balance the trade-off between exploration–exploitation. Moreover, Gaussian perturbations are used in a subsequence of iterations to guarantee the convergence of the methods to the global minimum in a probabilistic sense.Besides presenting a convergence proof for the methods based on the q-gradient, we also presented numerical results comparing q-G and q-CG with their classical versions (Steepest Descent (SD) and Conjugate Gradient (CG)) and also with widely used alternative methods such as the evolutionary algorithms CMA-ES and ISRES, a variant of Controlled Random Search called CRS2-LM, IPOPT with finite-difference derivatives, and the Nelder–Mead direct search method. The results show that q-G and q-CG are very promising for global optimization. They generally outperform SD, CG, IPOPT, CRS2-LM, ISRES and Nelder–Mead on 27 widely used test problems and they are very competitive with CMA-ES, especially on the problems with multiple local minima.