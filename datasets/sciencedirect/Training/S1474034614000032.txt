@&#MAIN-TITLE@&#
3D shape acquisition and integral compact representation using optical scanning and enhanced shape parameterization

@&#HIGHLIGHTS@&#
3D optical scanning point clouds are successfully parameterized into B-spline surfaces.Control point data-sets can be used for computational evaluation of scanned objects.Proposed enhanced parameterization algorithm provides better surface fitting.Enhanced parameterization can handle edges, local voids and minor scanning errors.Expert system provides compact but faithful representation of complex object shapes.

@&#KEYPHRASES@&#
3D shape acquisition,B-spline surfaces,Enhanced 3D parameterization,

@&#ABSTRACT@&#
An efficient computational methodology for shape acquisition, processing and representation is developed. It includes 3D computer vision by applying triangulation and stereo-photogrammetry for high-accuracy 3D shape acquisition. Resulting huge 3D point clouds are successively parameterized into mathematical surfaces to provide for compact data-set representation, yet capturing local details sufficiently. B-spline surfaces are employed as parametric entities in fitting to point clouds resulting from optical 3D scanning. Beyond the linear best-fitting algorithm with control points as fitting variables, an enhanced non-linear procedure is developed. The set of best fitting variables in minimizing the approximation error norm between the parametric surface and the 3D cloud includes the control points coordinates. However, they are augmented by the set of position parameter values which identify the respectively closest matching points on the surface for the points in the cloud. The developed algorithm is demonstrated to be efficient on demanding test cases which encompass sharp edges and slope discontinuities originating from physical damage of the 3D objects or shape complexity.

@&#INTRODUCTION@&#
Non-contact 3D shape sensing and especially 3D optical scanning methods and equipment have recently started to revolutionize some of the quality control and monitoring procedures in the industry. High resolution and high accuracy 3D optical scanning results in high density point clouds (typically in the range beyond 108 points) that capture and contain abundant global and local information about the shape of some object.Reverse engineering and design of technical objects offer many opportunities where computer-aided design (CAD) and artificial intelligence (AI) techniques can jointly be applied very efficiently to provide major benefits in the design or re-design process. As the discipline of design and related processes operate on geometric shapes, adequate 3D modeling is a major asset, which also introduces the need for efficient 3D geometric data acquisition, knowledge representation and storage. Intelligent evaluation of the acquired geometric knowledge (after processing of raw point clouds) should provide ground for shape-related reasoning, learning and eventually diagnostics, including feature recognition and classification.Many authors have dealt with individual aspects of geometric design in the generic sense of coupling shape and function. Optimization and optimum design are used along with different mathematical formulations and numerical methods [1–3]. Comprehensive surveys of different approaches in geometric modeling and parameterization in the context of optimization and shape modeling are found in literature [4,5]. Different methods of modeling shape have a strong and profound impact on the numerical analysis and simulation procedures which operate on those shapes in order to evaluate the corresponding functionality and performance. Hence there is a strong numerical relationship between geometric models and physical simulation models, as full analysis and synthesis encompass both.The procedure developed in this paper starts from 3D shape digitization by applying optical 3D scanning [6], including stereo-photogrammetry and triangulation [7,8]. There are many different digitization techniques and devices that can be used [9], and several procedures that can be adopted [6,10,11]. Essentially, stereo 2D images are combined for 3D reconstruction [8,12], resulting in large 3D point clouds representing the surface of the digitized object. Multiple scans at different locations are combined by applying coordinate transformation and registration in the common coordinate system [13], providing a well-balanced compromise between (i) accuracy in local detail capture and (ii) economy in large area coverage. This allows different measurement volumes (lens sets) to be combined within the same digitization procedure. Further steps such as averaging, thinning and repairing of meshes can be applied. In [14], the authors have applied an inexpensive stereo-vision system based on video frame streams for far-range scenes for the purpose of monitoring. The final format is usually the common STL standard containing the mesh of polygonal faces defined by corresponding vertices and unit normals. For any object, geometry representation using point clouds is typically huge in size and inconvenient for processing, as numerical shape operators need to be applied to the entire point clouds typically enclosing many millions of individual points.On the other hand, computer-aided-design techniques have evolved based on parametric representation, where standard geometric primitives represented by corresponding parameters are combined to provide overall geometries of objects. The CAD models are hence compact in terms of data storage and facilitate transformations and modifications as the corresponding operators manipulate the parameters only. The geometric component objects include simple spheres and cylinders but also complex mathematical curves and surfaces such as B-splines and NURBS [15,16], providing for high flexibility in modeling shape [17–19]. Recent developments in CAD technology have actually re-positioned it to upgraded functionality and significance. CAD systems have increasingly transformed to modeling tools that can generically encompass entities and their relationships, constraints, etc. Beyond the traditional shape primitives, tools for free-form entities and point clouds have also been integrated in terms of support for geometric modeling. CAD tools now support animations, assembly simulations, kinematic simulations for mechanisms and systems, functional modeling, customization and specialization, systems engineering. In many aspects, coupling with external simulation applications is feasible for additional functionality evaluations. Many CAD applications integrate advanced analysis methods, for example finite element analysis for structural applications using advanced materials, in some cases also basic optimization functionality. The design phase is augmented by production process simulation and integration. The CAD systems are increasingly seen as product lifecycle management (PLM) systems which include standard CAD, CAM (manufacturing), CAE (engineering), surfacing, reverse engineering, visualizations and other complementary activities.In order to combine the digitized as-is geometry with the parametric CAD geometry, parameterization of the resulting point clouds into mathematical surfaces is necessary, which can be accomplished by applying fitting procedures [20–23].One of the key aspects of the procedure developed in this paper is efficient 3D parameterization based on adequate mathematical surfaces. Many authors have contributed in the area of best-fitting 3D mathematical surfaces such as B-spline and NURBS surfaces to geometric data-sets acquired by measurement [22–27], typically in the context of reverse engineering. In [28], the authors have also applied directly chained Bezier surfaces in parameterizations for shape optimization.The existing approaches are described further in Sections 2.1–2.3. Section 2.4 outlines the proposed novel approach which includes the enhanced parameterization based on the modified fitting error measure and eigenvalue ratio distribution, whereby Section 3 illustrates the new procedure with real-world application cases.The main reason for combining 3D shape acquisition and shape representation in this paper is the fact that these two disciplines are complementary and frequently coupled in terms of the ‘enhanced reverse engineering’ procedure shown in Fig. 1by jointly providing the initial ‘shape solution’.Moreover, testing the performance of any shape representation algorithm is less biased if carried out using complex real-world objects rather than numerically generated surfaces or simple engineering objects. This is especially true if the real objects also encompass individual features such as damaged surfaces (gaps,cavities), like those acquired here by applying 3D acquisition. Even the other way around, storing shapes of engineering objects for later reference is far more efficient in parametric form than as raw point clouds, whereby highly efficient shape representation algorithms are needed.Parts of the overall procedure developed according to Fig. 1 can be applied both in reverse engineering and also in the detection of geometric discrepancy or change in shape.The overall procedure in Fig. 1 is centered at the notion of shape. The essential problems in dealing with geometries of real-world objects is the capacity to represent shapes, transform shapes and identify individual features of the shapes [29,30]. In this paper, enhanced reverse engineering refers to standard reverse engineering procedures [31] enhanced by engaging optimizers which will modify the resulting objects towards improved performance.As illustrated in Fig. 1, evolutionary optimization algorithms and other metaheuristics [32,33] are very suitable procedures to be employed in the enhanced reverse engineering workflow as presented here. Not being gradient-based, they can handle discontinuity in excellence and constraint function values and therefore also major change in shape and topology. Direct single- and multi-objective search methods [34], possibly using constraint penalization, are also adequate within this framework.The procedure starts by digitizing the 3D surface geometry of some object and proceeds with the parameterization of the geometry and subsequent representation of shape based on the chosen set of parameters. This is where the detection of geometric change or monitoring of difference in shape can take place, whereby the current set of values of the shape parameters is compared with the respective previous or reference values and algorithmically analyzed.If the shape is to be partially reverse-engineered aiming at accommodating the required increased performance of the object, an evolutionary shape optimizer (EO) should be invoked [1,3] accordingly. It operates on the selected sub-set of shape variables in order to modify the shape locally or globally. As the key sequence within this comprehensive process, the focus of this paper is aimed at the first part of the cycle in Fig. 1, shape digitization by means of 3D scanning and parameterization of geometry which maps the point clouds into parametric surfaces. This mapping should result in compact and efficient data-sets of the parametric entities while still providing for feature recognition and detection of change in geometric shape.Accordingly, the ambition of this paper is to develop an efficient numerical procedure generically presented in Fig. 2.The data acquisition aspect is in this case limited to generating the raw point clouds including some necessary processing such as polygonization.The knowledge representation entity referred to in Fig. 2 is a discipline within artificial intelligence which develops ways to formally represent knowledge and includes a logic system with symbols, operators and interpretation methodology that provides for efficient storing of knowledge, knowledge-based reasoning, and developing new knowledge. In terms of this paper, knowledge is related to actual 3D shapes and the logic system encompasses representation based on shape parameters. The parameters can be processed using different mathematical operators and can be mapped to shapes using parametric curves as the interpretation methodology. This framework leads to new knowledge (new shapes) based on associated reasoning operations (for example evaluation of shapes based on finite element analysis). Advanced operators of the logic system may also include feature recognition algorithms operating on the parametric data-set.Once the deviation data for a surface patch are available either in raw format (point cloud) or as parametric surfaces, adequate criteria and numerical tests can be established for automatic detection and classification of geometric features.This section demonstrates the acquisition of raw data for the procedure developed in this paper, which has been successfully applied with several examples in Section 3. The new contribution developed in this paper is the enhanced procedure presented in Section 2.4 which can be seen as a direct extension and upgrade of the methodology in Sections 2.1–2.3.In this paper we use the ATOS system which consists of a projector and two cameras [6] and Fig. 3, and provides for efficient 3D scanning with high resolution and accuracy. It is an optical system based on triangulation and stereo-photogrammetry which applies structured light patterns projection and uses time-based coding for addressing the positions of individual points.During scanning, light patterns in the form of stripes are projected onto the surface of the object such that a large number of points on the object surface can be uniquely identified and matched. Individual stripes projected on the object surface can generally be identified by respective counting or by projecting time-sequenced stripe patterns resulting in binary coding of stripes on the time axis (Fig. 3).The intensity of light of any point on the object surface varies with time according to some predefined function. These patterns provide for the phase shift needed for time-based coding of position, hence, if read in the time domain, the pixels receive a coding sequence based on their position. The optical resolution generally depends on the width of the stripes, which is limited by the resolution of the projector and the cameras, and procedures of phase-shifting the stripes in the sequence of projections for better resolutions.The scans originating from the two cameras are combined to provide the 3D model of the object surface. The procedure involves the spatial coordinate system of the object and both planar coordinate systems of the cameras. A mathematical model can be established based on geometric considerations which maps 3D coordinates of the object points into 2D points on the cameras. Given the 2D coordinates of the same point on the two cameras, the mathematical model provides the three coordinates of the respective spatial physical point.The simple camera model provides the necessary expressions to relate 3D entities and their 2D projections. Three coordinate systems (CS) exist (Fig. 4): the 3D world CS with originCw, the 3D camera CS with originCc, and the 2D image CS on the camera plane Π. If the position of some pointP(X,Y,Z) is given in the world coordinate system asPw(X,Y,Z), its coordinatesPc(x,y,z) in the camera coordinate system are obtained using the translation matrixT=Cw–Ccand rotation matrixRbetween the systems (Fig. 4a), Pc=R⋅(Pw−T) whereby the parameters contained inTandRare the extrinsic parameters of the camera.The projection pointp(px,py) on the camera plane Π of the physical pointP(X,Y,Z) follows from x=f⋅X/Z, y=f⋅Y/Z, z=f, with f as the focal length.The intrinsic parameters of the camera with the focal pointCcare the focal length f, the principal pointC(cx,cy) as the projection ofCcon Π, and the camera pixel dimensions (hx,hy). The mapping between the camera coordinatesPc(x,y,f) and the 2D image coordinates (px,py) is x=(px−cx)hx, y=(py−cy)hy.The final equation of the basic camera model is obtained by combining the expressions, yielding(1)P=M·PwhereMis the projection matrix which can be partitioned into separate matrices with intrinsic and extrinsic parameters. The parameters needed in Eq. (1) such as the focal length and other data are taken from the specifications of the respective lens set and system configuration and subsequently calibrated using certified calibration objects.In Fig. 4b,Prepresents the physical 3D point which by perspective projection on the two camera planes ΠL and ΠD gives the 2D projection pointsPL andPD. The focal pointsCL andCD are connected by the baseline LB and project onto the other image planes into epipolar pointsEL andED forming epipolar lines LEL and LED and the epipolar plane ΠE.If for some pointPthe left projection pointPL is known, then also the epipolar plane ΠE is known but also both epipolar lines, since they are the intersection of ΠE with ΠL and ΠD respectively. Consequently, the projection pointPD that corresponds toPL must lie on the right epipolar line and can hence be identified as the counterpart ofPL. This provides the epipolar constraint for the two projection points that correspond to the same 3D point. Therefore the search for a matching image of some point on the other camera only has to go through the corresponding epipolar line and not the entire image plane. Moreover, if both matching projection pointsPL andPD are known, their projection lines are also known and they intersect at the corresponding 3D pointPwhich can consequently be calculated (3D point reconstruction) based on triangulation.These constraint equations can be expressed in matrix terms and the 3D surface reconstruction can be carried out via a linear operatorL,(2)P=L(PL,PD)Polygonization is the process where huge point clouds containing points originating from multiple scans of partially overlapping regions are reduced to non-overlapping meshes of points of certain density, and polygonal surface patches joining them. Generally, the meshes consist of planar faces with C0 continuity, whereby meshes of triangular faces are used most frequently. The process involves thinning of the point cloud with least-square optimization in overlapping areas, adaptive size of the polygons (e.g. smaller size-higher density in edge regions with high curvature, etc.) smoothing of the mesh, regularization, etc.If necessary, local mesh repairs can be carried out in small void areas without scanned points which manifest as tiny holes in the object surface or areas hidden by reference points. These voids can be repaired by adding a few triangles to the mesh which fill the holes such that the surface continuity and surface gradient continuity with adjacent (successfully scanned) areas is preserved, also imposing curvature continuity if required.In many cases, different parts are scanned using different measurement volumes to provide both for large areas coverage and high-accuracy insight into local details. Different scans may be associated with different coordinate systems, which implies coordinate transformation before joining the point clouds or meshes. Where different scans cannot be merged via commonly recognizable reference points, best-fitting of clouds is necessary. Registration is used to combine multiple parts of geometry (CAD-generated meshes, scanned meshes or hybrid) defined within different coordinate systems.The rotation and translation of one of the coordinate systems (six degrees of freedom-best fit variables) are determined for best alignment based on the minimum total offset of the mesh points in the least-square sense. Frequently the iterative-closest-point algorithm is applied as described in Section 2.3.For many purposes it is necessary to replace the resulting point cloud with mathematical surfaces which are typically applied in computational geometry and CAD, thus enabling:–compact representation of geometric knowledge,non-demanding storage and exchange of geometric data,easy imposition of partial changes in geometry,parametric optimization of geometry,application of geometric operators modifying the shape locally or globally,detection of change and deviation of the shape,simulation and animation.Parameterization by fitting B-spline curves and surfaces is applied in this paper. The knowledge representation and storage of the shape are based on storing the matrix of control pointsQin Eqs. (3) and (4), which provides the indicated properties.A B-spline curve of degree d is defined for a set of (n+1) 2D control pointsQas(3)C(t)=∑i=0nNi,d(t)·Qi,t∈[0,1]and the B-spline surface is defined for a 3D array-gridQof control points, (n0+1)×(n1+1) by(4)C(u,v)=∑i0=0n0∑i1=0n1Ni0,d0(u)·Ni1,d1(v)·Qi0i1,u,v∈[0,1]Ni,0(t)=1,ti⩽t<ti+10,otherwise,0⩽i⩽n+dNi,j(t)=t-titi+j-tiNi,j-1(t)+ti+j+1-tti+j+1-ti+1Ni+1,j-1(t),1⩽j⩽d,0⩽i⩽n+d-jwhere d0 and d1 are the respective degrees of the surface, andNare the basis functions defined recursively using a non-decreasing sequence of scalars-knots ti, which can be chosen as uniform(5)ti=0,0⩽i⩽di-dn+1-d,d+1⩽i⩽n1,n+1⩽i⩽n+d+1or periodic.The resulting curve and surface, Eqs. (3) and (4), possess the property of local control since the support (non-zero value) of Ni,j(t) is the interval [ti,ti+j+1], therefore the curve is influenced only locally by a few adjacent control points inQ.A simple fitting method of a B-spline on (m+1) data pointsPassumes that they are ordered with increasing sample times sequence sk. Since the B-spline parameter t varies between 0 and 1, the sample times can be chosen to correspond to parameter values according to tk=(sk−s0)/(sm−s0).The curve fitting problem is defined as determining the control pointsQsuch that the least square error(6)E(Q)=12∑k=0m∑j=0nNj,d(tk)·Qj-Pk2is minimized. The minimum of this quadratic error function is obtained from the necessary conditions [26] for the extreme by differentiating with respect to the control points which yields(7)∑k=0m∑j=0nakiakjQj-∑k=0makiPk=0,i=0,n(arc=Nc,d(tr))A simple fitting method of a B-spline surface on (mo+1)×(m1+1) points assumes ordered and increasing sample times sequences rj0,sj1 of data pointsPj0j1. Since the B-spline parameters vary between 0 and 1, the sample times may be set to correspond to the parameter values uj0=(rj0−r0)/(rm0−r0), vj1=(sj1−s0)/(sm1−s0).With B-spline surface fitting, the unknown (no+1)×(n1+1) control pointsQare to be determined by minimizing the least-squares error function(8a)E(Q)=12∑j0=0m0∑j1=0m1∑i0=0n0∑i1=0n1Ni0,d0(uj0)·Ni1,d1(vj1)·Qi0i1-Pj0j12The minimum of this quadratic error function [27] is obtained from the necessary conditions for the extreme by differentiating with respect to the control points, ∂E(Q)/∂Q=0 which yields a linear system of equations that provides the control points values for the minimum least square error.The motivation for this research has emerged based on the state-of-the-art in this area. Free-form surface fitting is usually based on the ICP algorithm [13,35–38]. The Iterative Closest Point (ICP) algorithm tries to minimize the difference between two point clouds by transforming (translation and rotation) one of the coordinate systems relatively to the other. This is done by iteratively identifying the matching points in the two clouds (nearest neighbors) and aligning the neighbor points based on the mean square criterion, which typically converges provided a good initial ‘guess’.The first point cloud is some discretization of the initial (for example 3D-scanned) surface, while in the second point cloud corresponding points closest to individual points of the first point cloud need to be identified. During the initial phase of fitting with a relatively uniform distribution of control points, the problem is not very hard. However, as the fitting procedure has advanced and the control points aggregate in areas of significant change in shape, finding matching points on the second surface becomes very demanding and time-consuming. The reason for this is the fact that for many points of the first point cloud the matching points on the parametric surface are obtained with very small increments Δu, which leads to high algorithmic complexity.Paper [13] discusses the computational complexity of the ICP algorithm and develops the concept of subdividing the parametric surface into triangular partitions to accelerate the search for matching points Areas with major change of shape are locations where smaller partitions join and where multi-dimensional bisection could be applied. In [35], the authors describe the ICP algorithm as a method that does not converge globally, and change the topology of the initial surface as a preparatory step for the ICP algorithm. Monte-Carlo simulation has been introduced in [36] to upgrade the performance of the ICP algorithm. Several related numerical interventions are also presented in [37,38].The motivation of this paper is to improve the fitting accuracy of the existing methods such that improved shape representation is possible without increasing the number of shape parameters. This will be implemented by augmenting the variables in the fitting procedure by theuandvvectors and by redistributing the fitting points mesh to provide more impact to areas with significant change in shape, as follows in Section 2.4.The proposed enhanced parameterization approach is also based on B-spline surfaces, Eq. (4). However, the upgraded algorithm of fitting the parametric surface to the point cloud is developed based on the conception that additional best-fitting capacity of B-spline surfaces might be accomplished by having the fitting error between the point cloud and the fitted parametric surface defined and evaluated differently.With this scheme, the matching point on the fitting surface (Fij) used in error evaluation of any particular point (Pij) in the point cloud is not identified by simple assignment of the corresponding uiand vjparameters as defined in reference to Eqs. (6) and (8a), or by linearly interpolating the uiand vjparameters within the range [0,1] based on thePijcoordinates. Instead, the optimizer will be additionally engaged to determine the corresponding best uiand vjvalues in the course of minimizing E(Q). The price to be paid for the expected improvement in representation capability is however the fact that the best-fitting procedure is no longer linear. Specifically, E(Q,u,v) is quadratic inQand commonly higher-order non-linear inuorv, making the ∇E(Q,u,v)=0 conditions for the minimum of the respective surface fitting error generally non-linear. Moreover, the potential improvement of the fitting error E(Q) will only partly be due to better fitting. Part of the enhancement will also be due to the different definition and measurement of error as the assignment ofFijto eachPijin the proposed method is done differently than in common least-square fitting (Fig. 5).While the error e1 in Fig. 5 is obvious and adequate in approximating functions to experimental data (for example response surfaces), e2 seems more reasonable in approximating geometric shape. The error e1 is standard in least square fitting, while e2 is related to the ICP algorithm and matching closest points.In the enhanced best fitting scheme, the error will be evaluated on the point cloudPwith a different assignment of the matchingFijto eachPijin the point cloud in the error evaluation expression in Eq. (8a), Fig. 5. The redistribution variablesuandvwhich define the matchingFijpartners to thePijpoints in the cloud will constitute the augmented part of the best-fitting variables, in addition toQ. Hence the optimal values ofQwill emerge as a consequence of minimizing the fitting error in Eq. (8b) with respect toQalong withuandv. The latter are not needed any longer after obtaining the optimizedQvector of control points. In the standard best fitting procedures in Eq. (8a), the corresponding uiand vjparameters are simply allocated as defined in reference to Eqs. (6) and (8a), or by linearly interpolating the uiand vjparameters within the interval [0,1] based on thePijcoordinates relatively to the patch footprint range.The developed best fitting procedure is consequently upgraded according to(8b)E(Q,u,v)=12∑j0m0∑j1m1∑i0n0∑i1n1Ni0,d0(uj0)·Ni1,d1(vj1)·Qi0i1-Pj0j12where the fitting error E(Q,u,v) is made a function of CP (control point) coordinatesQand the locations of theFijpoints (matching points toPijon the best-fitting surface)uandv, withu=u0,…,um0,v=v0,…,vm1. The best fitting problem is now non-linear inuandv, and iterative gradient-based numerical minimization has to be applied.The scalar entities u and v as parameters in Eq. (4) indeed represent the position coordinates of a point on the B-spline surface. However, the bold entities (vectors)uandvas related to (8a) and (8b) represent the mapped coordinates of the matching points for individual points in the cloud in the least square error definition in Eqs. (8a) and (8b).The standard approach assigns the vectorsuandvof the matching points on the surface to those in the given cloud as sums of linear segments. The new definition in Eq. (8b) however lets the optimizer decide onuandvvalues and pick the matching points itself. For any pointPijin the cloud, the scalar values uiand vjwithin [0,1], for which we assumeC(ui,vj)=Pij, need to be identified, whereC(ui,vj)=∑i0=0n0∑i1=0n1Ni0,d0(ui)·Ni1,d1(vj)·Qi0i1is a point on the parametric surface. They are initially chosen asui=∑k=0i-1‖Pk+1-Pk‖∑k=0m0‖Pk+1-Pk‖,i=0,…,m0and analogously for vj. Nevertheless, solving Eq. (8a) with such initial pre-setting of uiand vjvalues need not necessarily provide the best solution, i.e. control pointsQ. Therefore, we consideru=[uo,…,um0]T,v=[vo,…,vm1]Tas additional variables of the fitting problem which leads to (8b).In fact, Eq. (8b) can also be seen as a mechanism to relocate the control points’Q(nCP×3) positions on the patch footprint embedded within best-fitting, where the re-positioning takes place automatically by virtue of minimizing E(Q,u,v) in Eq. (8b). This is different to some other enhanced fitting approaches where the fitting error is minimized with respect toQz(nCP×1) only, while the CP positionsQxy(nCP×2) are moved and adjusted towards the sharp edges contained within the point cloud. The latter is done in order to accomplish their higher population density in the vicinity of such edges, and an example of such a procedure is given in [28]. The latter procedure provides the benefit that the best-fitting procedure remains a linear procedure. However, it also adds complexity since edge detection algorithms external to the best-fitting procedure must be employed. This fact is very adverse for example in topology- and shape optimization, where the changes in shape imposed by the optimizer move and re-shape the edges of the target object. Sometimes the changes even enforce the elimination of some edges and initiate the genesis of new edges, all of which arise as a consequence of shape redesign.The term genesis of new edges implies that as a numerical optimizer operates on the shape parameters of some object, and the shape may change even topologically such that new edges arise at originally ‘smooth’ zones. As a radical visualization case, an initially spherical object might transform to a cube or the other way around. Changes in shape may map to changes in overall surface topology.The effect of relocating CPs in the proposed procedure based on Eq. (8b) also contributes significantly to shrinking the fitting error as demonstrated in Section 3.2.The Levenberg–Marquardt method (LM) was applied because of its advantages in unconstrained non-linear optimization. Essentially, it combines the 2nd order Newton method which converges fast when close to the optimum point with the 1st order gradient descent which converges in a robustly persistent manner for distant trial solutions. While the standard Newton method in each iteration (i) minimizes the function (in this case Eq. (8b), the fitting error) using the search directionS=-Ji-1·∇fi, the LM method replaces the HessianJby usingJ∼i=Ji+αi·I. Decreasing α from large to small values in fact changes the search strategy from steepest descent to Newton. In this expression,Iis the identity matrix and f is the error function in Eq. (8b), while αiis the LM damping factor. The gradient ∇f and the Hessian J are the gradient and the Hessian of this error function with respect to the fitting variables [Q,u,v] respectively.The initial solution applied in Eq. (8b) is the solution obtained by linearly minimizing E(Q) in Eq. (8a) with uniformly distributeduandvarrays, after which the LM non-linear gradient-based minimization algorithm is applied with Eq. (8b). The standard best-fitting procedure according to Eq. (8a) is typically a linear system with {(n0+1)×(n1+1)×3} variables inQ. The enhanced fitting procedure based on Eq. (8b) is generally non-linear with {(n0+1)×(n1+1)×3+(m0+1)+(m1+1)} variables as the values inuandvare assumed to apply as collective parameters to entire rows/columns in the grid on thePfootprint. Generally, eachPijmight have its own associated uijand vijvalues, but this would lead to an extremely high number of variables and excessive numerical effort.Therefore, we propose a modified best-fitting method with the objectives of (i) delivering improved best-fitting quality (reduced cumulative error), while (ii) preserving the relative spatial structure of the point cloud data-set. Such multi-objective optimal parameterization was obtained by lettinguandvvary within the range of the patch as resulting from Eq. (8b), but restricted to retain the initially given relative positions, hence the adjacency and connectivity matrix ofFijpreserve the same spatial structure. This is achieved asuandv(sized (m0+1) and (m1+1) respectively) apply to entire grids of matching pointsFij.Another enhancement of the procedure is also developed and introduced in the numerical procedure. The original point cloud data-set is redistributed according to the spatial eigenvalue distribution, providing for heaping-up of the point cloud in areas with significant geometric change. This provides a pondering effect for such regions in the overall best-fitting procedure by effectively assigning them heavier weight factors. The redistribution of the point cloud is implemented by changing the point locations within the patch and obtaining the relocated point coordinates from the planar tesselated triangular mesh that constitutes the surface polygonial faces (STL). This is essentially a linear interpolation operating on the original point cloud.This enhancement of the procedure is introduced along with Eq. (8b). The original points in the point cloud resulting from 3D scanning are redistributed (linear mapping fromPijtoPij′) to provide pondering in regions with significant geometric change, which should receive larger weighting factors in best-fitting. This is implemented by locally denser aggregation of the point cloud in those areas. The redistribution of the point cloud is implemented according to the spatial eigenvalue distribution. The new point coordinatesPij′are obtained by linear interpolation from the original planar polygonial mesh faces (Pij, STL format). This does not deteriorate the accuracy unless sections containing edges or significant curvature are skipped. The redistribution of the point cloud inPij′also needs to preserve the topology of the point cloud such that the adjacency and incidence matrices of the data-set are preserved.The term spatial eigenvalue distribution refers to the distribution of the ratio of the eigenvalues across the point cloud, where at each location only a partial point cloud in the local vicinity of that point is taken into account. The term pondering effect refers to the fact that by virtue of aggregating points in some region and reducing their number in other regions the impact of the former region with respect to the impact of the latter during the fitting procedure is effectively increased. Consequently, the former region is represented by a disproportionally larger number of points than the latter. The redistribution of the point cloud does not move the points out of the surface as the point cloud is essentially a network of planar (triangular) faces for which a linear interpolation within the faces provides new points which remain within the same faces.From the locality property of B-splines it is evident that a change of the control point Qihas a localized impact on the respective curve, only in the segment between the knots [ti,ti+d+1], Eq. (4). Similarly with B-spline surfaces, a change in Qi0,i1 only affects the interval[ti0u,ti0u+d0+1]×[ti1v,ti1v+d1+1]. This implies that the part of error in Eq. (8b) which can be attributed to Qi0,i1 is related to the redistributed points Pj0,j1 in that interval, uj0∊[ti0u,ti0u+d0+1], vj1∊[ti1v,ti1v+d1+1]. Consequently, if the objective is to have Qi0,i1 located in an area with significant change in shape and exhibit a strong impact on the local error, then the redistributed points should be located in that area.The essential novel elements of the proposed approach can be summarized by:–existing papers do not apply the approach of havinguandvas variables in the fitting procedure of 3D surfaces in addition to the control pointsP, which has been successfully developed here,this paper develops the novel approach of redistributing the fitting point cloud (thinning and aggregating the mesh according to the features such as edges) toprovide more relative weight to the areas with significant change in shape during the overall fitting procedure, as well asto provide a higher density of control points in such areas sinceuandvare used as augmented fitting variables.If geometrically complex shapes are to be scanned and captured in parametric form (for example edged surfaces), a single mathematical surface may not be fully adequate. In such cases, the overall domain should first be decomposed into mutually interconnected parametric patches, possibly linked by corresponding connectivity conditions such as slope and curvature constraints where applicable.This situation can also be automatically recognized by the geometry processing program based on the fact that without domain partitioning the error benchmark in Eqs. (8a) and (8b) may not be within acceptable limits. In a general case, the geometry of an object may be complicated and include arbitrary topological structure and regions separated by edges. In such cases, networks of surface patches may be adequate or even necessary. Generally, the overall surface is represented by a set of surfaces, their mutual connectivities and respective cross-continuities. The term segmentation implies the subdivision of the overall point set into subsets corresponding to natural surfaces, which can be implemented as an edge-based or face-based procedure. The former proceeds by scanning the points data and seeking for edges where the normals, estimated from the points data, change intensively or abruptly. The latter approach tries to expand some initially chosen region in terms of point data as long it keeps encompassing points that belong to the same type of surface, whereby the intersections of such surfaces identify edges. The positions of sharp edges can also be determined in different ways within the point cloud itself. For example, finite differences or related approximations can be employed on the point cloud after regularization and polygonization to yield estimates of the first and second derivatives which are conclusive in terms of slopes and curvatures contained in the point cloud, however measurement noise has to be filtered out and eliminated first. The detection of edges may be based on some threshold values of these estimates, providing a tool for feature detection in the raw data-scanned point cloud.In this context, regularization refers to deriving a structured mesh from the unstructured point cloud and adjusting the mesh size and density appropriately according to local geometric circumstances such as curvatures.Generally, networked partial surfaces are likely to perform better than overall-stretching surfaces. However, this dominantly applies to static shapes and invariant geometries.This paper actually uses single surfaces for the complex-shaped examples provided in Section 3. At first glance, it may not seem reasonable to use a single surface for the cylinder head and similar complex objects. However, the objective has been to expose the proposed method to very demanding tests of irregular geometries, as passing such tests will prove the procedure to be very adaptive and robust. The method can subsequently be expected to represent individual segments of partitioned surfaces in a trustworthy and efficient manner, as typically those possess much simpler shapes.The second reason for applying integral surfaces is the ambition to use the proposed representation within the framework of generic shape optimization. In such a capacity, holes and protrusions may appear during some iterations and disappear later. Generally, edges may arise, be eliminated or move across the shape in optimization iterations quasi-time.The proposed method was developed as one that could potentially cope with such scenarios of changing shapes and variable shape topologies with success.The particular test-objects in this paper, which will be used to demonstrate the developed procedure, are (i) several mechanical cast alloy components, (ii) blades of a small wind turbine, as well as (iii) numerically generated complex point clouds. The reference 3D shapes of the physical objects are digitized in high-definition before the start of exploitation.The basic features of the ATOS optical system which was used here are as follows:Measurement volume: 65×50×30–1000×800×800[mm3].Assembly of individual point clouds via reference points.Distance between scanner and objects: 650–1300[mm].3D scanning rate: approximately 1s for 1032×776Pixels.Spatial resolution: approximately 0.07–1[mm].Compatibility and calibration for VDI2634 norm.The choice of surface measurement technology is generally based on many factors such as accuracy, cost, robustness, flexibility and speed. Traditionally, surface measurement used to be implemented using tactile methods, which even nowadays provide somewhat higher accuracy than optical methods, typically in the μm range. However, they are very slow and touching the surface of an object may not be feasible or may cause problems in many cases. Non-contact technologies include the time-of-flight systems whereby a laser beam travels to the object and back resulting in signal delay related to distance. Nevertheless, contactless optical methods based on laser-beam triangulation tend to be more convenient. Photogrammetry-based systems provide wide area coverage within a short measurement time. Structured-light systems such as the ATOS system project light fringes onto the surface that appear distorted from the cameras’ viewpoints, which is used for 3D surface reconstruction. They offer high accuracy and resolution at an adequate expense and enable efficient combining of multiple scans using un-coded reference points.Fig. 6presents some elements of the implemented procedure. Fig. 6a shows one of the objects that were 3D scanned in order to provide the required high-accuracy 3D data for testing purposes of the different parameterization algorithm settings. Fig. 6b shows the partially completed 3D point cloud on one side of the object, along with the un-coded reference points needed to align individual scans. Fig. 6c presents the scanned model of the object after registration and alignment of the point clouds in the common coordinate system and merging of the partial point clouds.After the scanning procedure is completed, the polygonization process results in a regularized point cloud. This is shown on the example of a small wind turbine blade shown in Fig. 7a, presenting a large set of non-overlapping planar polygonial faces defined by individual points and normals in the STL format. Fig. 7b shows an enlarged view of a local detail, indicating a potential shape deviation.The STL model in Fig. 7a is parameterized into B-spline surfaces according to Eqs. (4) and (8a) or alternatively Eq. (8b). An example of a parameterized windowed partial point cloud is shown in Fig. 8along with corresponding control points.The procedure developed in Section 2 will now be tested on far more demanding objects, where the parametric surfaces need to represent point clouds which includeholes and localized voids in the scanning point cloud,sharp edges,slope discontinuities,very low local curvatures,and similar troublesome features. Such advanced level of shape modeling capacity and ability of capturing local details is necessary if the parameterized surface is to be subjected to feature extraction and shape deviation detection algorithms.In order to explore different options in extracting essential information relevant for the detection and classification of damage modes on the surface of some object, a point cloud representing a gap (Fig. 9) will be processed into parametric form by applying the approach developed in Section 2.4.Fig. 9a shows the 100×100 point cloud considered for this test which represents a surface with a gap. The best-fitted B-spline surface of order 2×2 and the corresponding 15×15 control points according to Eq. (8a) are shown in Fig. 9b, whereby the cumulative error in Eq. (8a) amounts to the value of 98.2227mm. Fig. 9c presents the same problem with the only difference being the degree of the B-spline surface, which is now 4×4. Unexpectedly, the latter case did not contribute to reducing the cumulative fitting error, which in fact increased to the value of 116.185mm.Fig. 9 demonstrates that the corresponding B-spline surface does not yield increased representation accuracy when the respective degree is augmented, hence the parameterization based on Eq. (8a) has been linear and fast, but also limited in modeling performance and accuracy. This fact has provided motivation towards developing the enhanced best fitting scheme with the modified fitting error definition and different allocation of the matchingFijto eachPijin the cloud according to Section 2.4, Eq. (8b).The method developed in Eq. (8b) leads to a significant decrease in cumulative error in this test-case (Fig. 11), from 98.2227mm to 5.20368mm, although only part of this enhancement may be acknowledged to the better best-fitting procedure. The remaining merit is attributed to the different error benchmark since thePij−Fijpairs are formed differently altogether, as symbolically shown in Fig. 5. In this case, if the optimum values ofQderived by minimizing Eq. (8b) are introduced back into the standard error definition in Eq. (8a), the total error value for the 100×100 point cloud increases to 1065.038mm. This is empirical evidence for the fact that the assignment ofFijto eachPijin the point cloud exhibits major impact on the generation of the best-fitting surface.The reduction of the total error value also shows that the allocation of the uiand vjparameters as defined in reference to Eqs. (6) and (8a), that is by linearly interpolating the uiand vjparameters based on thePijcoordinates within the patch, may not be adequate. It is based on projection ofPijon the patch footprint or on summation of linear segments connecting the control points. This may be a poor estimate of the curvilinear u and v coordinates of the parametric surface, especially if significant curvature is present. Releasinguandvand letting them be augmented fitting variables as in Eq. (8b) also contributes to letting the CPs relocate within the domain and inherently aggregate in the edge regions, thereby reducing the total fitting error.Yet another intervention was developed in the parameterization scheme in Eq. (8b), and it is the redistribution of the original point cloud. Fig. 10presents the spatial distribution of the covariance-matrix eigenvalues ratio on the patch, each point on the graph taking into consideration all points encompassed by a certain radius around the point’s location (r-vicinity).This intervention introduces the redistribution of the points in the cloud by performing linear mapping fromPijtoPij′to provide locally denser aggregation of the points in geometrically significant areas according to the spatial eigenvalue distribution, Fig. 10. The new pointsPij′are linearly interpolated from the original tesselated polygonial triangular mesh stretched overPij.This intervention along with best-fitting based on Eq. (8b) results in the surface in Fig. 11.The resulting parameterization surface in Fig. 11 can be the basis for different additional shape deviation diagnostics criteria that can operate as part of autonomous quality control expert systems. The re-distribution of the point cloud also contributes to filling the voids in the cloud at locations of sudden change in shape. The enhancement of representation accuracy by the developed parameterization procedure is demonstrated in Fig. 12.Fig. 13shows the isolated orthogonal z-error part of the total offset distance norm from Fig. 12.Such parameterization also enables the creation of 2D images of arbitrary resolution (such as Fig. 14) where different additional image processing algorithms can be applied (Edge detection, Corner detection, Gaussian convolution, Image binarization, Connected-component labeling, etc.). Consequently different features and their corresponding attributes can be extracted.Fig. 14 also indicates that the procedure developed here could also be applied to problems where a distribution of some physical quantity across a 2D domain may be given instead of a geometric z-coordinate. Such global interpolation functions could for example be used in numerically solving field problems using meshless methods. Such a distribution may also be represented by a parametric surface entity as developed in Section 2.4.The second case considered in testing the performance of the parameterization procedure developed in Section 2 is the case of a point cloud corresponding to a small-footprint deep local cavity located within the surface patch. It is also a very demanding test-case for parameterization due to steep changes in coordinate values orthogonal to the patch with an amplitude of 12.82mm, the shape of which closely resembles the localized mathematical spatial step function.The point cloud originating from high-resolution optical 3D scanning of the local cavity is presented in Fig. 15.Since it is very important to apply sparing parameterizations as compact-size control point data-sets are numerically less expensive to process, the initial setting is 10×10 CPs with the respective degree of the B-spline curve of 2×2. Fig. 16a and b demonstrate the parameterization according to Eq. (8a) to be inadequate in modeling the cavity since there is insufficient local shape control in the vicinity of the edges.However, if the fitting algorithm in Eq. (8b) with Levenberg–Marquardt (LM) non-linear minimization is applied, much better representation of the cavity points is accomplished, Fig. 17a and b. Much better local control around the steep edges could be achieved, even considering the given doubtlessly scarce CP data-set.A similar effect of the parameterization algorithm on the total fitting error norm can be observed in Fig. 18vs. Fig. 19, where 15×15 CP data-sets are applied. The former is based on linear best-fitting according to Eq. (8a), the latter on non-linear LM minimization of Eq. (8b). Again, the latter algorithm achieves much better local control in the steep edges region with much lower error function amplitudes and average values.Figs. 9–19 demonstrate the developed fitting procedure to be efficient in handling demanding 3D scanning problems where the point clouds include voids, edges, discontinuities and other problematic features potentially contained in raw point clouds obtained by optical 3D scanning. It proves that even if the surface parameterization data-set is humble in size, an efficient parameterization procedure as developed here can produce far better shape representation results without increasing the data-set size which standard approaches do. An expert system can thus be implemented to perform 3D data acquisition, shape knowledge representation, shape-related numerical processing and compact data storage autonomously and efficiently in industrial process real-time.To demonstrate the performance and representation capacity of the developed method even further, a real-world test case exhibiting a highly complex geometric shape was selected. This object is the cast cylinder head of a small gasoline engine propelling an electric generator, ‘Gude GS 950’. It is a 2HP (1.5kW) engine power, 63cm3 volume, single-cylinder, two-stroke engine driving a 50Hz–230V AC generator with 650W permanent output.Again, the objective is to parameterize the object using a single integral B-spline entity. The engine head was scanned in 3D using the high resolution and accuracy optical scanner Atos [5], whereby a large point cloud of approximately 108 points has been generated to serve as the raw data-set for parameterization.Subsequently, integral parameterization of the highly complex geometry in Fig. 20b was carried out using B-spline surfaces with 30×20 control points. Linear fitting based on Eq. (8a) resulted in the fitting surface shown in Fig. 21.The non-linear parameterization algorithm developed here based on Eq. (8b) and using Levenberg–Marquardt fitting error minimization has resulted in the integral surface shown in Fig. 22.As in Section 3.2.2, the aggregation of the point cloud towards the areas with edges or major dimensional change in some direction, identified based on the eigenvalue ratio in Fig. 20c, was also introduced in this case.The error distribution for the parameterizations shown in Figs. 21 and 22 respectively is shown in Fig. 23.The error improvement seems very satisfactory for this complex case. The error reduction factor is approximately 0.5 at the error peak locations, and the overall error reduction distribution in Fig. 23 is also significant.Non-linear fitting based on Eq. (8b), while providing a lower fitting error, inherently comes at a numerical expense. As an illustration, linear fitting based on Cholesky decomposition resulted in 0.65s of fitting run-time (generally, complexity of the order n3, where n is the order of the system, but in this case reduced since algorithms for sparse matrices can be applied). Using LM-based fitting and Eq. (8b), the fitting problem was solved in 17.4s on a standard PC.The numerical procedure developed in this paper is autonomous and self-navigated in terms of its ability to adapt efficiently to different shapes and features such as edges or peaks which may be contained in the geometric data-set. The number of control points can be automatically evaluated based on required cumulative fitting error across the overall shape as well as the spatial distribution of the fitting error in local zones. Of course, the proposed method (Section 2.4) is self-navigated itself and adjusts autonomously to demanding shapes as demonstrated in Section 3.2. Non-linear fitting involving theQ,uandvvectors as variables is performed by the LM optimizer and hence fully autonomous. The redistribution of the points according to the eigenvalue ratio distributions is also automatic, while the size of the neighborhoods where the ratios are evaluated can be pre-set as desired.While the individual execution times were given above, an additional comment should be provided here. Compared to the fitting procedure using the ICP algorithm, the re-distribution of the point cloud and introduction of the augmented set of variables into the now non-linear fitting procedure results in a significantly shorter computational time. The point redistribution is executed only once and does not introduce more complexity than an average ICP iteration. Moreover, the re-distribution of the point cloud causes the transformed solution space to have such local minima of the fitting problem which are all close and numerically acceptable.Solving individual iterations of the non-linear fitting procedure implies solving the linear system whose matrix is symmetric and positive definite, such that Cholesky decomposition can be applied (complexity O(n3)). It is also a banded matrix, hence banded Cholesky factorization can be applied O((k2+3k)×n), where k is the width of the band.

@&#CONCLUSIONS@&#
An enhanced autonomous and self-navigated procedure for automatic processing of 3D point clouds is developed for the purpose of faithful, yet compact, representation of complex 3D shape. The procedure includes best-fitting of B-spline surfaces as part of a numerical workflow. An upgraded B-spline fitting method is proposed based on an extended set of fitting variables and redistribution of the point cloud data, providing for more fitting accuracy at the numerical expense of non-linear fitting of the developed algorithm.Empirical evidence using demanding surfaces resulting from high-end 3D optical scanning was used to demonstrate the efficiency of the proposed method. These point clouds represent a narrow longitudinal gap and a deep local cavity on the surface of the test-object, as well as a complex-shaped engine cylinder head. All three cases provide evidence for a significant reduction of the surface fitting error without increasing the parametric data-set, the merit of which can be attributed both to the developed fitting procedure and proposed error metrics.An autonomous monitoring expert system can potentially be developed based on the developed procedure such that it operates on the compact control points instead on large point clouds.