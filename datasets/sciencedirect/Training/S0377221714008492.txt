@&#MAIN-TITLE@&#
Ranking and selection for multiple performance measures using incomplete preference information

@&#HIGHLIGHTS@&#
Ranking and selection with multiple performance measures evaluated through stochastic simulation.Two new procedures using a multi-attribute utility function with incomplete preference information on weights related to performance measures.Selection of pairwise and absolutely non-dominated designs based on optimal computing budget allocation.Elicitation of weights is facilitated and computational advantages are gained compared with existing procedures.

@&#KEYPHRASES@&#
Simulation,Ranking and selection,Multi-attribute utility function,Incomplete preference information,Optimal computing budget allocation,

@&#ABSTRACT@&#
This paper presents two new procedures for ranking and selection (R&S) problems where the best system designs are selected from a set of competing ones based on multiple performance measures evaluated through stochastic simulation. In the procedures, the performance measures are aggregated with a multi-attribute utility function, and incomplete preference information regarding the weights that reflect the relative importance of the measures is taken into account. A set of feasible weights is determined according to preference statements that are linear constraints on the weights given by a decision-maker. Non-dominated designs are selected using two dominance relations referred to as pairwise and absolute dominance based on estimates for the expected utilities of the designs over the feasible weights. The procedures allocate a limited number of simulation replications among the designs such that the probabilities of correctly selecting the pairwise and absolutely non-dominated designs are maximized. The new procedures offer ease of eliciting the weights compared with existing R&S procedures that aggregate the performance measures using unique weights. Moreover, computational advantages are provided over existing procedures that identify non-dominated designs based on the expected values of the performance measures. The new procedures allow to obtain a smaller number of non-dominated designs. They also identify these designs correctly with a higher probability or require a smaller number of replications for correct selection. Finally, the new procedures allocate a larger number of replications to the non-dominated designs that are therefore evaluated with greater accuracy. These computational advantages are illustrated through several numerical experiments.

@&#INTRODUCTION@&#
Ranking and selection (R&S) procedures in simulation-optimization are methods for selecting the best system designs from a set of competing ones (e.g., Goldsman and Nelson, 1998). The designs are compared based on performance measures that are estimated through stochastic simulation. The procedures allocate simulation replications among the designs such that more replications are allocated to promising designs and less to non-promising ones. Thus, the performance of the promising designs is evaluated with greater accuracy, and the best designs can be selected efficiently as well as with a high level of confidence.In this paper, two new procedures are presented for R&S problems where the best designs are selected based on multiple performance measures. The procedures extend the existing ones by aggregating the performance measures through a multi-attribute utility (MAU) function (e.g., Keeney and Raiffa, 1976) in which a decision-maker’s (DM’s) preference information regarding the weights that reflect the relative importance of the measures is incomplete (e.g., Hannan, 1981; Hazen, 1986; Kirkwood and Sarin, 1985; Salo and Hämäläinen, 1992; Sarin, 1977; Weber, 1987; White et al., 1984). The procedures maximize the probability of correctly selecting non-dominated designs under such information. They apply optimal computing budget allocation (OCBA) (Chen et al., 2000) as well as multi-objective OCBA (MOCBA) (Lee et al., 2004) which are originally designed for selecting the best design based on a single performance measure and the non-dominated designs based on multiple performance measures with a limited computing budget in terms of the number of simulation replications. OCBA and MOCBA have been previously extended in several ways (Lee et al., 2010) but not in the manner described in this paper.Existing R&S procedures mostly deal with a single performance measure. Surveys of such procedures appear in Bechhofer et al. (1995),Goldsman and Nelson (1998),Swisher et al. (2003),Kim and Nelson (2006),Kim and Nelson (2007). Surveys of simulation-optimization methods for multiple performance measures (Evans et al., 1991; Rosen et al., 2008), on the other hand, acknowledge only few R&S procedures. An approach is to combine the multiple performance measures into a single one based on preference statements given by the DM and apply the procedures for a single performance measure. For instance, in Morrice et al. (1998), and Butler et al. (2001), the performance measures are aggregated through a MAU function.An alternative to the aggregation of performance measures is to select non-dominated designs without taking into account the preference information of the DM. A design is dominated if its performance is no better than the performance of another design with respect to all measures and worse with respect to at least one measure. The R&S procedures currently available for selecting non-dominated designs are variants of MOCBA (Chen and Lee, 2010; 2009; Lee et al., 2007; 2004; 2010; Teng et al., 2010). In addition, one line of research considers R&S procedures for maximizing or minimizing a primary performance measure under constraints on a number of secondary performance measures (Andradottir et al., 2005; Andradottir and Kim, 2010; Batur and Kim, 2010; Hunter and Pasupathy, 2013; Morrice and Butler, 2006).The new procedures presented in this paper fall between the procedures that aggregate performance measures as well as the procedures that select non-dominated designs. In the new procedures, an additive MAU function is utilized. Thus, the utility reflecting the preferability of a design is calculated as the weighted sum of single-attribute utility functions describing the DM’s preference for the values of individual performance measures. The weights reflect the relative importance of the measures and represent the contribution of each performance measure into the utility. The new procedures additionally allow incomplete preference information on the weights. A set of feasible weights is obtained from preference statements that are given by the DM in terms of linear constraints on the weights. The designs are compared through dominance relations established based on the estimates for the expected utilities over the feasible weights. The first procedure, referred to as MOCBA-p, identifies the non-dominated designs according to pairwise dominance (Weber, 1987). Then, a design is dominated if its expected utility is lower than the expected utility of another design with all feasible weights. In this procedure, MOCBA is applied for maximizing the probability of correctly selecting the set of pairwise non-dominated designs with a limited computing budget. The second procedure, referred to as OCBA-a, identifies the designs that are non-dominated according to absolute dominance (Weber, 1987). Then, a design is dominated if its maximal expected utility over the feasible weights is lower than the minimal expected utility of another design. OCBA is used for maximizing the probability of correctly selecting the set of absolutely non-dominated designs with a limited computing budget. MOCBA-p and OCBA-a are considered because both procedures have their advantages. With MOCBA-p, a smaller set of designs is obtained since any pairwise non-dominated design is also absolutely non-dominated. OCBA-a, on the other hand, is a somewhat simpler procedure and more straightforward to implement. Moreover, OCBA-a can be extended such that a non-additive MAU function is used.MOCBA-p and OCBA-a do not require as strict preference statements as the existing procedures that aggregate performance measures using unique weights. The DM may not be able to provide the unique weights for the MAU function due to time pressure, lack of knowledge, fear of commitment or other reasons (Weber, 1987). Then, the existing procedures are not applicable whereas the new procedures are.MOCBA-p and OCBA-a also provide several computational advantages over the existing procedures that do not aggregate performance measures. First, by selecting pairwise and absolutely non-dominated designs, the new procedures allow to obtain a smaller number of designs that remain after the simulations than the existing procedures. Therefore, a smaller set of designs remains to be compared by the DM which makes the selection of the most preferred design easier. Second, the procedures identify pairwise and absolutely non-dominated designs correctly with a higher probability or with a smaller computing budget compared with an approach in which non-dominated designs are identified first and preference information is utilized after the simulations. Thus, MOCBA-p and OCBA-a either increase the confidence in correct selection or provide computational savings. Third, because MOCBA-p and OCBA-a concentrate on a smaller set of designs, they allocate a larger number of simulation replications to the designs that remain after the simulations and evaluate such designs more accurately than the existing procedures. These computational advantages are illustrated through numerical experiments in this paper. Moreover, the effect of the set of feasible weights as well as the effect of the number of performance measures on the advantages is examined in the numerical experiments in order to assess the applicability of the procedures.Two earlier R&S procedures utilizing MAU functions take into account incomplete preference information regarding weights using probability distributions (Branke and Gamer, 2007; Frazier and Kazachkov, 2011). In these procedures, the estimate for the expected utility of each design is calculated uniquely which leads to an R&S problem with a single performance measure. The weights of the MAU function are interpreted as the contribution of each performance measure into the utility of a design. However, there is no such interpretation for the probability distributions. Therefore, these distributions may be challenging to provide. In turn, constraints for the weights utilized in this paper can be determined based on this interpretation. Thus, they provide a more transparent representation of the incomplete preference information.The rest of the paper is organized as follows. Section 2 discusses existing procedures for R&S with multiple performance measures which are based on optimal computing budget allocation. This discussion helps to introduce the use of MOCBA and OCBA as well as the use of MAU functions in the new procedures. Section 3 describes the MAU function with incomplete preference information on weights as well as pairwise and absolute dominance relations. In Section 4, the new MOCBA-p and OCBA-a procedures are presented. The numerical experiments illustrating the computational advantages of the procedures are presented in Section 5. Finally, concluding remarks are given in Section 6.In this section, the MOCBA (Chen and Lee, 2010) procedure is summarized first. Second, a procedure in which performance measures are aggregated with a MAU function and the design with the highest expected utility is selected using OCBA is described (Chen and Lee, 2010).The R&S problem with multiple performance measures is formally described as follows. There are K designs and n performance measures. Xk= (Xk1, …, Xkn) denotes a vector of independent random variables where Xkirepresents the performance of the kth design with respect to the ith performance measure. Now, the designs that minimize the expected values E[Xki] of the performance measures are selected, i.e.,(1)mink∈{1,…,K}(E[Xk1],…,E[Xkn]).Moreover, E[Xki] are estimated by generating realizations of the measures through replications of a stochastic simulation model. Thus, the replications must be allocated among the designs such that the ones minimizing E[Xki] are selected correctly with high confidence and as few replications as possible are performed.Which designs are the solution of Problem (1) depends on how the multiple performance measures are handled. When using MOCBA, the solution includes non-dominated designs. Design k dominates design l if E[Xki] ≤ E[Xli] ∀i = 1, …, n and at least one of the inequalities is strict (e.g., Chen and Lee, 2010). For illustrative purposes, Fig. 1depicts an example problem with 10 designs and two performance measures. Designs 7–10 are dominated since for each of them there exists another design with lower expected values of the measures. Designs 1–6 are non-dominated and represent the solution of the problem. When applying a MAU function and OCBA, the design with the highest expected utility is the solution. Such a solution for the example problem is illustrated in Section 2.2.2. The example problem is also used throughout the rest of the paper for illustrating the new R&S procedures as well as for assessing their computational advantages.In MOCBA (Chen and Lee, 2010), Problem (1) is solved by maximizing the probability of correctly selecting non-dominated designs with a limited computing budget, i.e., a limited number of simulation replications. Each design is allocated a given number of replications that are used in the estimation of the expected values of the performance measures. The non-dominated designs are ultimately selected based on these estimates. Let m1, …, mKdenote the numbers of replications allocated to each design. Let T denote the computing budget, i.e.,∑k=1Kmk=T,and let PCS(m1, …, mK) denote the probability of correct selection with given m1, …, mK. The numbers of replications are obtained by solving(2)maxm1,…,mKPCS(m1,…,mK)s.t.∑k=1Kmk=T.Next, the calculation of PCS(m1, …, mK) and the solution of Problem (2) are considered. These tasks require the estimation of the expected values of the performance measures which is discussed first. Now, the estimator for E[Xki] is the average of the realizations of Xkiin mkindependent replications. In MOCBA, Xkiare assumed normally distributed and the estimator for E[Xki] is therefore a normally distributed random variable. The estimate for the mean of the variable, which is also the estimate for E[Xki], is(3)μ^ki=1mk∑j=1mkxkij,where xkijdenotes the realization of Xkiin the jth replication when the kth design is employed. The variance of the above random variable is estimated withσ^ki2/mk,whereσ^ki2is the estimate for the variance of Xkigiven by(4)σ^ki2=1mk−1∑j=1mk(xkij−μ^ki)2.Let l≻ik denote the event that design l dominates design k with respect to performance measure i, i.e., E[Xli] < E[Xki]. Since the estimators for the expected values are assumed normally distributed, the probability for such dominance, denoted with P(l≻ik), is calculated through(5)P(l≻ik)=Φ(μ^ki−μ^liσ^kimk+σ^liml),where Φ is the cumulative distribution function of the standard normal distribution. Moreover, the performance measures are assumed independent in MOCBA. Therefore, the probability that design l dominates design k, denoted with l≻k, is(6)P(l≻k)=∏i=1nP(l≻ik).Eqs. (5) and (6) are used when calculating two error probabilities. Type I error is defined as the probability that some designs regarded as dominated are actually non-dominated. Type II error is the probability that some designs regarded as non-dominated are actually dominated. Let S denote the set of non-dominated designs based on the estimatesμ^kifor the expected values of the performance measures andS¯the set of dominated designs. Further, let lkdenote the design that dominates design k with the highest probability and ikbe the performance measure for which design lkdominates design k with the lowest probability, i.e.,(7)lk=argmaxl≠kP(l≻k),(8)ik=argminiP(lk≻ik).Chen and Lee (2010) show that upper bounds for the probabilities of type I and II errors, denoted with pI and pII, are(9)pI=n|S¯|−n∑k∈S¯P(lk≻ikk),(10)pII=(K−1)∑k∈SP(lk≻ikk),where | · | is the cardinality of a set.The bounds (9) and (10) for the error probabilities allow to calculate an approximate lower boundPCS(m1, …, mK) for the probability of correct selection, i.e.,(11)PCS(m1,…,mK)≥1−pI−pII=PCS̲(m1,…,mK).Solving Problem (2), in which PCS(m1, …, mK) is replaced withPCS(m1, …, mK) given by Eq. (11), guarantees that the non-dominated set of Problem (1) is obtained correctly with high confidence.In MOCBA, Problem (2) is solved by applying allocation rules (Chen and Lee, 2010) that provide the optimal share of the computing budget allocated to each design as a function of the estimates (3) and (4) for the expected values and the variances of the performance measures. The allocation rules are presented in Appendix A for easy reference. They are applied during each iteration of MOCBA in order to calculate the number of additional replications for each design. After the replications have been performed, the estimates for the expected values and the variances of the performance measures are updated and a new iteration begins. The allocated replications reduce the uncertainty about the dominance between the non-dominated designs and the dominated ones and thus the probability of correct selection is maximized. The iterations of MOCBA are carried out until the entire computing budget has been consumed. Then, the non-dominated designs are selected based on the estimates for the expected values. The steps included in the iterations are described in detail in (Chen and Lee, 2010).OCBA (Chen et al., 2000) is developed for solving R&S problems with a single performance measure, i.e., problems of the form (1) with n = 1. Now, the design maximizing the expected value of this performance measure is selected. OCBA maximizes the probability of correctly selecting such a design. Letμ^kandσ^kdenote the estimates for the expected value and the variance of the performance measure when employing design k. These estimates are calculated following Eqs. (3) and (4). Further, let b denote the design for which the estimate for the expected value is the highest, i.e.,b=argmaxk∈{1,…,K}μ^k. The probability that the expected value of the measure is higher for design b than for design k is calculated according to Eq. (5). Utilizing the Bonferroni inequality, an approximate lower boundPCS(m1, …, mK) for the probability of correct selection is (Chen et al., 2000)(12)PCS(m1,…,mK)≥1−∑k≠bΦ(μ^k−μ^bσ^kmk+σ^bmb)=PCS̲(m1,…,mK),where mkdenotes the number of simulation replications allocated to the kth design.Similar to MOCBA, the lower bound for the probability of correct selection is maximized by allocating the computing budget among the designs according to allocation rules (Chen et al., 2000) that are presented in Appendix A. This guarantees that the best design is selected correctly with high confidence. The allocation rules indicate the additional number of replications for each design during each iteration as a function of the estimates for the expected values and the variances of the performance measure. After these replications have been performed, the estimates are updated and a new iteration begins. When the entire budget has been consumed, the estimates for the expected values of the performance measure are used for selecting the best design. Detailed description of the steps included in the iterations of OCBA is found in Chen et al. (2000).When applying OCBA to Problem (1), the multiple performance measures are aggregated into a single one by considering their relative importance in contrast to MOCBA in which the importance is not taken into account. Now, as suggested in Chen and Lee (2010), the aggregation is carried out with an additive MAU function, and the probability of correct selection of the design with the highest expected utility is maximized.The additive MAU function is of the form (e.g., Keeney and Raiffa, 1976)(13)U(Xk)=∑i=1nwiui(Xki),where ui, i = 1, …, n are single-attribute utility functions that represent the DM’s preferences for the values of each performance measure in the range [0, 1]. The values of U(Xk) and ui(Xki) are referred to as the utility as well as the single attribute utilities of design k, respectively. Moreover,wi∈[0,1],i=1,…,n,∑i=1nwi=1,are weights that indicate the increase in the utility when each performance measure moves from the least desired value to the most desired value. Thus, they reflect the relative importance of the performance measures. Using Eq. (13), design k is preferred to design l if the expected utility of design k is higher, i.e., E[U(Xk)] > E[U(Xl)]. When applying the MAU function in Problem (1), realizations of the performance measures in simulation replications are mapped into realizations of the utility through Eq. (13). Then, the expected utility and the variance of the utility are estimated based on the realizations and these estimates are used in the allocation rules of OCBA. In addition, the design with the highest expected utility is ultimately selected according to the estimates.The additive MAU function (13) is an appropriate way to aggregate the performance measures if an assumption called additive independence holds (von Winterfeldt and Edwards, 1986). In the context of R&S, such independence is defined based on preferential indifference between pairs of hypothetical designs with uncertain values of two performance measures. Alternative forms include multilinear as well as multiplicative MAU functions which are based on less strict assumptions and contain additional terms compared with Eq. (13) in order to take into account preferential interactions among performance measures. Detailed discussion on the assumptions behind the alternative MAU functions appears in Keeney and Raiffa (1976), and von Winterfeldt and Edwards (1986). It should be noted that although any one of the MAU functions mentioned above could be applied when solving Problem (1) with OCBA, the additive form (13) is applied in this paper.Single-attribute utility functions can be constructed based on preference statements given by the DM. The first step is to determine the least and most desired value of the performance measure in question denoted with xi* andxi*. They are assigned single-attribute utilities of 0 and 1, i.e., ui(xi*) = 0 andui(xi*)=1. Additional statements regarding the single-attribute utilities of intermediate values are then given. Based on these utilities, the single-attribute utility function is constructed by using a given functional form or a piecewise linear function. Weights are also determined based on preference statements given by the DM. The DM may, for instance, assess the ratios of the weights, i.e., wi/wj, i ≠ j. Then, the weights are normalized to sum up to one. The literature on decision analysis discusses several techniques for the construction of the single-attribute utility functions as well as for the elicitation of the weights (see, e.g., Keeney and Raiffa, 1976; von Winterfeldt and Edwards, 1986).Let us consider the example problem illustrated in Fig. 1 and assume that the least and most desired values for the ith performance measure are xi* = 25 andxi*=0. Furthermore, it is assumed that the DM only states that smaller values of the performance measure are regarded as better. Thus, the single-attribute utility function ui(x) = 1 − x/25 for both performance measures is obtained. This function is used for all performance measures in the rest of the paper when discussing the example problem as well as other test problems. Furthermore, assume that the DM specifies the ratio w1/w2 = 2.5 for the weights. After normalizing the weights, w1 = 0.71 and w2 = 0.29 are obtained.The expected utilities of the designs in the example problem are calculated using the single-attribute utility functions as well as the weights described above. Here, the calculation can be carried out analytically because the expected values of the performance measures are known (see Fig. 1) and the single-attribute utility functions are linear. Then,E[U(Xk)]=E[∑i=1nwiui(Xki)]=∑i=1nwiui(E[Xki]). The resulting expected utilities of the designs are given in Table 1. Since design 2 has the highest expected utility, it is the solution of the example problem. It should be emphasized that the expected values of the performance measures as well as the expected utilities of the designs are not available when dealing with an actual simulation model. In practice, the expected utilities are estimated based on realizations of the utilities in simulation replications as previously discussed.In this section, an additive MAU function with incomplete preference information regarding weights as well as pairwise and absolute dominance relations is discussed. Preference information is said to be incomplete when the DM is not able to provide unique weights. In such a setting, single-attribute utility functions are determined uniquely as described in Section 2.2.2. The interpretation of the weights remains the same as in the case of complete preference information, i.e., when unique weights are given. That is, the weight relating to a given performance measure indicates the increase in the utility when the measure moves from the least to the most desired value. Now, the DM gives preference statements that correspond to linear constraints on the weights. Park and Kim (1997) discuss several alternative statements that can be given. The DM may, for instance, provide an interval for the weight ratio wi/wjwhich implies two linear constraints. The linear constraints as well as the requirement that the weights sum up to one define the set of feasible weights.Under incomplete preference information, designs are compared through dominance relations established based on expected utilities over the feasible weights instead of through unique expected utilities used in Section 2.2. According to pairwise dominance, design k dominates design l if the expected utility of k is higher than the expected utility of l with all feasible weights (Weber, 1987). Let the utility of design k with given weights w be now denoted with Uk(w) and the set of feasible weights with W. Pairwise dominance appears if E[Uk(w)] > E[Ul(w)] ∀w ∈ W. Now, recall that the MAU function (13) is linear with respect to the weights. Furthermore, W is a bounded convex polyhedron because linear constraints are given for the weights and because the weights sum up to one. Therefore, dominance can be established by comparing the expected utilities of the designs at the extreme points of W(Hazen, 1986). Let the extreme points be denoted with {w1, …, wH}. Design k dominates design l according to pairwise dominance if E[Uk(wi)] > E[Ul(wi)] ∀i = 1, …, H.Absolute dominance is obtained as follows. Design k dominates design l according to absolute dominance if the minimal expected utility of k over W is higher than the maximal expected utility of l over W(Weber, 1987). Formally, absolute dominance appears whenminw∈WE[Uk(w)]>maxw′∈WE[Ul(w′)]. Alternatively, the extreme points of W can be considered. Then, dominance appears ifmini∈{1,…,H}E[Uk(wi)]>maxi′∈{1,…,H}E[Ul(wi′)].A pairwise non-dominated design is also absolutely non-dominated whereas the opposite is not necessarily true (Weber, 1987). Therefore, the pairwise non-dominated designs form a subset of the absolutely non-dominated ones. The numbers of pairwise and absolutely non-dominated designs depend on the set of feasible weights W. In practice, their numbers may be decreased by giving additional preference statements that imply tighter constraints on the weights.The utilization of the dominance relations in the new MOCBA-p and OCBA-a procedures requires the extreme points {w1, …, wH} of the set of feasible weights W. The extreme points can be determined through linear programming techniques (e.g., Taha, 2003). First, the constraints on the weights including the requirement that they sum up to one are written in matrix form as Aw = b, w ≥ 0. Inequality constraints are transformed into equalities by introducing slack variables into the vector of the weights w. A is a m × p -matrix of constraint coefficients where m is the number of constraints and p is the combined number of weights and slack variables. In addition, w and b are column vectors of length p and m, respectively. The extreme points of W correspond to basic feasible solutions of the system Aw = b, w ≥ 0. A basic solution is obtained by setting p − m components of w equal to zero and solving the m equations for the remaining m unknown weights and slack variables. In other words, m columns of A are selected. These columns form a basis B if they are linearly independent. Then, a basic solution wBcorresponding to B is obtained through wB= B−1b. If the resulting solution is feasible, it is an extreme point of W. In order to obtain all extreme points, each basis consisting of a combination of m columns of A is examined.The computational feasibility of the above approach depends on the number of weights and constraints. For instance, assume that there are 8 weights as in the test problems with the highest number of performance measures considered in Section 5. Moreover, assume that the order of weights is given which results in a total of 8 constraints when the requirement that the weights sum up to one is also taken into account. The combined number or weights and slack variables is p = 15 resulting in 6435 basis that must be examined. This number increases rapidly with increasing number of weights and constraints. However, it should be noted that the extreme points must only be determined once when applying the new R&S procedures. Moreover, the number of weights and constraints above cover a large majority of practical problems. Finally, if the number of weights and constraints is very high such that the enumeration of the basic feasible solutions is not computationally feasible there are alternative approaches. For instance, in Carrizosa et al. (1995), and Mármol et al. (1998) techniques are discussed for determining the extreme points when the components of the inverse matrix of constraint coefficients for the weights are non-negative. Matheiss and Rubin (1980), in turn, discuss the enumeration of the extreme points for general polyhedra. Here, the description of these alternative techniques is omitted for brevity.Let us reconsider the example problem discussed in Section 2. First, assume that the DM gives the interval w1/w2 ∈ [1.5, 4] for the ratio of the weights instead of the unique value used in Section 2.2.2. This statement implies the set of feasible weights W = {(w1, w2)|w1/w2 ≥ 1.5, w1/w2 ≤ 4, w1 + w2 = 1}. Writing the constraints in matrix form yields(14)(1100−11.5101−401)w=(100)where w = (w1, w2, s1, s2)Tincluding slack variables s1 and s2 . Setting s2 = 0, a basis consisting of the first three columns of the matrix of constraint coefficients is obtained. Solving for the remaining variables, i.e., w1, w2, and s1, gives w = (0.6, 0.4, 0, 1) which is a feasible basic solution since w ≥ 0. Thus, the extreme point (w1, w2) = (0.6, 0.4) is obtained. Another extreme point (w1, w2) = (0.8, 0.2) is obtained by setting s1 = 0 and by proceeding in a similar manner. These extreme points are the only ones because the remaining basic solutions turn out to be infeasible.Using the single-attribute utility functions described in Section 2.2.2, the expected utilities of the designs over W are illustrated in Fig. 2. Designs 1 as well as 4–10 are pairwise dominated since for each of them either design 2 or 3 has higher expected utility with all feasible weights. Thus, designs 2 and 3 are pairwise non-dominated. Designs 4–10 are absolutely dominated since their maximal expected utilities are lower than the minimal expected utility of design 3. Therefore, designs 1–3 are absolutely non-dominated. The same conclusions concerning the pairwise and absolutely non-dominated designs can also be made by examining the expected utilities of the designs at the extreme points of W. Either design 2 or 3 has higher expected utility than designs 1 as well as 4–10 with both (w1, w2) = (0.6, 0.4) and (w1, w2) = (0.8, 0.2). Thus, designs 2 and 3 are pairwise non-dominated and the rest of the designs are pairwise dominated. In terms of absolute dominance, design 3 is non-dominated because its minimal expected utility at either (w1, w2) = (0.6, 0.4) or (w1, w2) = (0.8, 0.2) is the highest. Designs 1 and 2 are also absolutely non-dominated because their maximal expected utilities at the extreme points, which occur with (w1, w2) = (0.8, 0.2), are higher than the minimal expected utility of design 3. The rest of the designs are absolutely dominated.In this section, the new MOCBA-p and OCBA-a procedures for selecting pairwise and absolutely non-dominated designs are introduced. The primary difference between the procedures is that they apply different dominance relations. The number of pairwise non-dominated designs obtained with MOCBA-p is smaller than or equal to the number of absolutely non-dominated designs obtained with OCBA-a. MOCBA-p is the preferred procedure in this respect because it eliminates a larger number of designs from consideration. OCBA-a, in turn, is more straightforward to implement. In addition, OCBA-a can be extended such that a non-additive MAU function is used whereas MOCBA-p requires the additive MAU function (13).In this paper, the additive MAU function is employed in both procedures because it is widely used in practice (e.g., Keeney and Raiffa, 1976; Park and Kim, 1997; von Winterfeldt and Edwards, 1986) and it has also been applied successfully in R&S procedures (e.g., Butler et al., 2001). The experiments conducted in Farmer (1987) also imply that the additive MAU function often indicates the best decision alternative, i.e., the design in the context of R&S, even if additive independence does not hold. If, however, a non-additive MAU function must be used, OCBA-a remains applicable.In MOCBA-p, an approximate lower bound for the probability of correct selection of pairwise non-dominated designs is calculated similarly to the lower bound (11) in MOCBA. Therefore, pairwise non-dominated designs can be selected using the allocation rules of MOCBA. The calculation of the lower bound is first described in order to show the similarity of the bounds in the two procedures. Then, the selection of parameters for MOCBA-p is discussed and the steps of the procedure are given.In MOCBA, the lower bound for the probability of correct selection is calculated through Eqs. (3)–(11). In particular, it is assumed that the performance measures are independent and the probability that a given design dominates another design is given by Eq. (6). In MOCBA-p, the utilities Uk(w1), …, Uk(wH) are considered instead of the performance measures. Recall that w1, …, wHdenote the extreme points of the set of feasible weights. These utilities are dependent because they are convex combinations of the single-attribute utilities, i.e.,Uk(w)=∑i=1nwiui(Xki). Lee et al. (2010) state that although dependencies affect the probability of dominance, they do not have a major impact on MOCBA because the allocation rules are based on the Bonferroni inequality. Here, the dependencies are taken into account by using an approximate upper bound for the probability of dominance as follows. Let the estimate for the expected utility E[Uk(wi)] be denoted withμ^kiand the estimate for the variance of the utility Uk(wi) withσ^ki. These estimates are calculated through(15)μ^ki=1mk∑j=1mkukj(wi),(16)σ^ki=1mk−1∑j=1mk(ukj(wi)−μ^ki)2,where ukj(wi) denotes the realization of Uk(wi) in the jth simulation replication. Because the estimator for E[Uk(wi)] is the average of such realizations, it can be treated as an approximately normally distributed random variable for sufficiently large mkaccording to the central limit theorem. Therefore, the probability that design l has higher expected utility than design k at the ith extreme point, denoted with P(l≻ik), is(17)P(l≻ik)=Φ(μ^li−μ^kiσ^liml+σ^kimk).The approximate upper boundP¯(l≻k)for the probability that design l dominates design k according to pairwise dominance is given by the minimum of the above probabilities, i.e.,(18)P(l≻k)≤mini∈{1,…,H}P(l≻ik)=P¯(l≻k).In MOCBA-p,P¯(l≻k)given by Eq. (18) is used instead of P(l≻k) given by Eq. (6) for determining design lkthat dominates design k most likely. Otherwise, the calculation of the lower bound for the probability of correct selection is unaffected by the dependencies and follows the description of Section 2.1. First, when determining the extreme point ikat which design lkdominates design k least likely, the probabilities of lkdominating k at each extreme point are compared with each other and the dependencies do not have to be taken into account. Moreover, the upper bounds for the probabilities of type I and II errors, i.e., the probabilities of incorrectly selecting dominated and non-dominated designs, are based on the Bonferroni inequality and they are not affected by the dependencies. To summarize, the expected utilities and the variances of the utilities are estimated through Eqs. (15) and (16), and the upper bound for the probability of dominance is calculated using Eqs. (17) and (18). Then, the lower bound for the probability of correct selection is given by Eqs. (7)–(11).The allocation rules of MOCBA-p used for allocating simulation replications among the designs are the same as the rules of MOCBA because the lower bounds for the probability of correct selection have the same form in both procedures. The estimates for the expected utilities and the variances of the utilities are used in place of the estimates for the expected values and the variances of the performance measures. They are applied in the iterations of MOCBA-p until the computing budget has been consumed. Then, the pairwise non-dominated designs representing the solution to Problem (1) are selected using the estimates for the expected utilities.Three parameters, the same as the ones in MOCBA, are included in MOCBA-p. First, Δ denotes the total number of replications allocated in one iteration. Second, δ is the maximum number of replications allocated to an individual design in one iteration. Third, m0 denotes the number of replications initially allocated to each design. The literature on MOCBA does not offer detailed advice for the selection of the parameters. However, Chen and Lee (2010) discuss some observations regarding the effect of the parameters which may be used as guidance in the selection for MOCBA-p as well. When Δ increases, the number of iterations, i.e., the number of times when replications are allocated, decreases with fixed computing budget T. Thus, it is advisable to not have too large Δ such that information obtained from the replications can be utilized in future iterations. On the other hand, decreasing Δ increases the computational overhead as new allocations must be calculated more frequently. Similarly, using a large value of m0 allows to evaluate the designs accurately in the beginning which may help when allocating additional replications. However, an unnecessarily large fraction of the computing budget may initially be allocated to poor designs. Finally, Chen and Lee (2010) state that δ is considered in order to avoid the allocation of too large a number of replications to an individual design due to a numerical approximation error.The steps of MOCBA-p when solving Problem (1) are as follows:0.Determine the single-attribute utility functions ui, i = 1, …, n corresponding to each performance measure as well as the set of feasible weights W and its extreme points {w1, …, wH} according to the guidelines discussed in Sections 2.2.2 and 3.Determine the computing budget T, i.e., the number of available simulation replications. In addition, determine the total number of replications Δ and the maximum number of replications δ for an individual design allocated in one iteration as well as the number of replications m0 allocated initially to each design. Set the iteration counter to j ← 0.Letmkjdenote the total number of replications performed for the kth design after the jth iteration.Perform m0 replications for each design, i.e.,mkj=m0,k=1,…,K.Calculate the estimatesμ^kiandσ^ki,k=1,…,K,i=1,…,Hfor the expected utilities and the variances of the utilities according to Eqs. (15) and (16).If∑k=1Kmkj≥T,go to step 4. Else, go to step 2.Let αkdenote the share of the computing budget allocated to the kth design. Determine the shares αkaccording to the estimatesμ^kiandσ^kiand the allocation rules of MOCBA described in Appendix A. Then, calculate the number of replicationsmkj+1throughαk(∑k=1Kmkj+Δ).Performmin(δ,max(0,mkj+1−mkj))additional replications for each design k. Moreover, updatemkj+1according to the number of replications performed for each design. Set the iteration counter j ← j + 1. Go to step 1.Select each design k, for which there does not exist another design l such thatμ^li>μ^ki∀i=1,…,H,as pairwise non-dominated.In OCBA-a, an approximate lower bound for the probability of correct selection of absolutely non-dominated designs similar to the lower bound (12) in OCBA is utilized. Therefore, the absolutely non-dominated designs can be selected by applying the allocation rules of OCBA. The similarity of the above probabilities is due to the definition of absolute dominance discussed in Section 3. With absolute dominance, the highest minimal expected utility over the designs and over the set of feasible weights is first identified. Then, absolute dominance for each design is established by comparing its maximal expected utility with the above minimum. Thus, the designs are essentially compared based on a single performance measure and the rules of OCBA, which are applicable with a single performance measure, are used. The calculation of the lower bound is described first in order to show that the bounds in OCBA-a and OCBA are similar. Then, the selection of parameters as well as the steps of OCBA-a are discussed.Letμ¯k=max{μ^k1,…,μ^kH}andμ̲k=min{μ^k1,…,μ^kH}be the estimates for the maximal and minimal expected utilities of the kth design whereμ^kiagain denotes the estimate for the expected utility corresponding to wi, i.e., the ith extreme point of the set of feasible weights. Moreover, let the estimates for the variances corresponding to the utilitiesμ¯kandμkbe denoted withσ¯k2andσ̲k2. The estimates are calculated according to Eqs. (15) and (16). Let b denote the design for which the estimate for the minimal expected utility is the highest, i.e.,b=argmaxk∈{1,…,K}μ̲k. The set of absolutely non-dominated designs based onμ¯kandμkisS={k|μ¯k≥μ̲b}and the set of absolutely dominated designs isS¯={1,…,K}∖S.Now, let P(b≻k) denote the probability that design b dominates design k according to absolute dominance andP(b¬≻k)the probability that b does not dominate k. The probability of correct selection PCSis the probability that each design in S is non-dominated and each design inS¯is dominated, i.e.,PCS=P((⋂k∈Sb¬≻k)∩(⋂k∈S¯b≻k)). Based on the Bonferroni inequality, it holdsPCS≥1−∑k∈SP(b≻k)−∑k∈S¯P(b¬≻k). Then, the approximate lower boundPCS(m1, …, mK) for the probability of correct selection with given m1, …, mKis(19)PCS(m1,…,mK)≥1−∑k∈SΦ(μ̲b−μ¯kσ̲bmb+σ¯kmk)−∑k∈S¯Φ(μ¯k−μ̲bσ¯kmk+σ̲bmb)=1−∑k≠bΦ(−|μ̲b−μ¯k|σ̲bmb+σ¯kmk)=PCS̲(m1,…,mK).The lower boundPCS(m1, …, mK) given by Eqs. (19) is of the same form as the one given by Eq. (12). Therefore, the allocation rules of OCBA presented in 6 can be applied for maximizing the probability (19) as well as for selecting absolutely non-dominated designs of Problem (1). When allocating replications among the designs according to the rules in OCBA-a, the estimates for the expected values and variances of the performance measure are replaced as follows. First, design b is determined as described above and the estimates for its minimal expected utility as well for the variance of such a utility are used within the allocation rules. For the rest of the designs, the estimates for the maximal expected utility as well for the variance of such a utility are used.The parameters of OCBA-a include the number of replications Δ allocated in one iteration as well as the number of replications m0 allocated initially to each design. Chen and Lee (2010) discuss observations regarding the effects of these parameters in OCBA which are similar to those described in Section 4.1 dealing with MOCBA-p. In addition, more specific guidelines are provided for the selection of the parameters. It is suggested that m0 is chosen between 5 and 20 whereas Δ should be larger than 5 but smaller than 10% of the number of designs. These guidelines can be utilized in the selection of the parameters for OCBA-a because the same allocation rules as in OCBA are applied.The steps of OCBA-a when solving Problem (1) are largely similar to the steps of MOCBA-p. Differences appear in Steps 0 and 3 where the parameter δ is omitted. Furthermore, in Step 2, the allocation rules of OCBA presented in 6 are applied. Finally, in Step 4, each design k, for whichμ¯k≥μ̲bis selected as absolutely non-dominated.The MOCBA-p and OCBA-a procedures are evaluated through numerical experiments in order to illustrate their computational advantages. MOCBA is used as a reference procedure such that it is first applied for determining non-dominated designs based on estimates for the expected values of the performance measures. Then, pairwise and absolutely non-dominated designs are determined by using the same MAU function as in MOCBA-p and OCBA-a. Thus, preference information is utilized posterior to simulations in the reference procedure.The example problem discussed in Sections 2 and 3 is treated first for illustrating the computational advantages with a tractable problem. Second, randomly generated test problems consisting of 50 designs are considered. On one hand, test problems with two performance measures are solved with varying sets of feasible weights. On the other hand, test problems with increasing number of performance measures are solved. By considering these test problems, it is evaluated whether the new procedures provide computational advantages with diverse real-world R&S problems. Moreover, it is assessed how the weights and the number of performance measures affect the extent of the advantages. The example problem is similar to problems used in (Chen and Lee, 2010) whereas the randomly generated problems are formulated as in (Frazier and Kazachkov, 2011). In the example problem and test problems, the performance measures follow the normal distribution. They are also assumed independent of each other as well as across the designs.Three types of performance indicators are used for illustrating the computational advantages. First, average numbers of pairwise and absolutely non-dominated designs as well as average numbers of non-dominated designs are examined. Although these numbers primarily relate to the characteristics of the R&S problem at hand, they indicate whether the new procedures provide a smaller number of designs compared with the application of MOCBA without preference information. The smaller the number of designs remaining after the simulations is, the easier it is for the DM to further compare the designs. Second, empirical probabilities of correct selection of pairwise and absolutely non-dominated designs are used as performance indicators. They are estimated by solving the problems several times and calculating the fraction of cases where correct selection occurs. Such cases can be identified since the expected values of the performance measures and the expected utilities of the designs are known. The empirical probabilities indicate whether MOCBA-p and OCBA-a offer increased confidence in correct selection as well as computational savings. That is, whether a higher probability is obtained with a given computing budget or whether a smaller budget is required for correct selection. Third, average numbers of simulation replications allocated to pairwise and absolutely non-dominated designs are observed. Such an indicator is of interest because the DM compares the remaining designs after the simulations on the basis of the expected utilities or the expected values of the performance measures which are estimated using the allocated replications. The larger the numbers of replications are, the more accurate are the estimates.The parameters of the procedures are selected according to the guidelines described in Sections 4.1 and 4.2. Δ and δ equal the number of designs in each problem. Moreover, m0 = 20 is used.The expected values for the performance measures in the example problem are presented in Section 2.1. A common variance of 9 is assumed for all measures and designs. The additive MAU function (13) includes the single-attribute utility functions described in Section 2.2.2. In addition, the set of feasible weights determined in Section 3 is used. The computing budget is T = 5000 simulation replications. Moreover, the example problem is solved 1000 times in order to calculate the performance indicators.The average number of non-dominated designs is considered as the first performance indicator. In the example problem, there are 6 non-dominated designs as well as 2 pairwise and 3 absolutely non-dominated designs as discussed in Sections 2 and 3. MOCBA, MOCBA-p, and OCBA-a identify these designs correctly in nearly all of the 1000 cases. Thus, MOCBA-p and OCBA-a concentrate on a smaller number of designs.The procedures are next assessed by examining the empirical probabilities of correct selection. Let these probabilities for pairwise and absolute dominance be denoted withP^CSpandP^CSa. Fig. 3a depictsP^CSpas a function of the computing budget T for MOCBA-p and MOCBA. Moreover, the computing budgets required to exceed a probability 0.9 of correct selection are pointed out. MOCBA-p exceeds the threshold with a computing budget of approximately T = 1500 replications. When MOCBA is used, the computing budget required is nearly three times as large. Fig. 3b depictsP^CSaas a function of the computing budget T for OCBA-a and MOCBA as well as the budgets required to reachP^CSa>0.9. OCBA-a exceeds the threshold with approximately T = 400 replications whereas a budget of nearly twice as large is required with MOCBA. Furthermore,P^CSpandP^CSaare overall higher for MOCBA-p and OCBA-a compared with MOCBA.As the third performance indicator, the average numbers of replications allocated to pairwise and absolutely non-dominated designs are calculated. These indicators are depicted for MOCBA-p and MOCBA in Fig. 4a. The average number of replications for each pairwise non-dominated design is clearly higher for MOCBA-p. The indicators with OCBA-a and MOCBA are depicted in Fig. 4b. OCBA-a allocates more replications to design 3 whereas MOCBA allocates more replications to designs 1 and 2.To summarize, the new procedures enable computational advantages over MOCBA in the example problem. MOCBA-p and OCBA-a concentrate on a smaller number of designs. Based on the empirical probabilities of correct selection, the new procedures offer increased confidence in correct selection or computational savings. The average numbers of replications allocated to the designs indicate that with OCBA-a as well as with MOCBA some of the absolutely non-dominated designs may not be evaluated accurately. In turn, each pairwise non-dominated design is evaluated more accurately with MOCBA-p than with MOCBA.The randomly generated test problems include 100 problems with two performance measures that are solved with different sets of feasible weights. Moreover, problems with increasing number of performance measures are examined by solving 100 test problems for each problem size. The test problems are generated by drawing the expected value of each performance measure for each design from the normal distribution with a mean of 15 and a standard deviation of 3. Furthermore, a common variance of 9 is assumed for all measures and designs. Similar to the example problem, the additive MAU function (13) is used with the single-attribute utility functions described in Section 2.2.2. The computing budget is again T = 5000 replications. Each test problem is solved 250 times in contrast to the example problem in order to lower the computational requirements of the experiments. The values of the performance indicators are calculated as averages over these cases and over each set of 100 test problems described above.Sets of feasible weights are constructed similar to Section 3 where an interval for the ratio of the weights w1 and w2 is given. That is, two constraints for the ratio are provided. Now, an interval is given directly for w1, and w2 is obtained by recalling that w2 = 1 − w1. Moreover, the length of the interval for w1 as well as its location in the range [0, 1] are changed. The resulting sets are listed in Table 2. They are organized into batches separated by horizontal lines. In the first batch, the intervals for w1 are located symmetrically around 0.5. They get narrower when moving down within this batch. The lengths of the intervals remain constant within each of the following batches whereas they are narrowed when moving down from one batch to another. The locations are changed within each batch such that they are gradually shifted closer to 1.The average numbers of non-dominated designs are depicted in Table 2. The average number of non-dominated designs obtained by using MOCBA without preference information is 4.2. Overall, there are fewer pairwise non-dominated designs. The number of absolutely non-dominated designs is smaller than the number of non-dominated designs when the interval for w1 is narrow. The difference in the number of remaining designs between the new procedures and MOCBA also increases as the interval gets narrower. Thus, MOCBA-p concentrates on fewer designs compared with MOCBA whereas this advantage is offered by OCBA-a when the interval for w1 is narrow, i.e., when relatively tight constraints for the weights are given.The empirical probabilities of correct selection are also depicted in Table 2. The probabilitiesP^CSpfor pairwise dominance with MOCBA-p are higher than the probabilities with MOCBA. The probabilities increase when the interval for w1 is narrowed. In addition, the difference in the values ofP^CSpbetween MOCBA-p and MOCBA remains approximately the same with all sets of feasible weights. OCBA-a produces higher probabilitiesP^CSafor absolute dominance than MOCBA. These probabilities increase when w1 is narrowed. In addition, the difference inP^CSabetween OCBA-a and MOCBA slightly decreases as the interval for w1 is narrowed. Overall, MOCBA-p and OCBA-a provide increased confidence in correct selection of pairwise and absolutely non-dominated designs. Therefore, the new procedures also require a smaller computing budget for identifying such designs correctly.Next, the performance indicator relating to the accuracy of evaluating pairwise and absolutely non-dominated designs is studied. In contrast to the average number of replications considered in Section 5.1, the average shares of pairwise and absolutely non-dominated designs that are allocated more replications with MOCBA-p and OCBA-a than with MOCBA are analyzed. These shares are listed in Table 2. With MOCBA-p, the majority of the pairwise non-dominated designs are allocated more replications. The share of such designs also increases as the interval for w1 gets narrower or when it is shifted closer to 1. With OCBA-a, the majority of the absolutely non-dominated designs are evaluated more accurately when the interval for w1 is narrow. The share increases as the interval gets narrower. The shares obtained indicate that MOCBA-p and OCBA-a allow to evaluate the majority of the designs that remain after the simulations more accurately. Thus, the new procedures facilitate further comparison of the designs.To summarize, MOCBA-p and OCBA-a provide the computational advantages over MOCBA. With MOCBA-p, the advantages are obtained with all sets of feasible weights whereas OCBA-a requires tight constraints on the weights. Overall, the advantages are emphasized with both procedures as tighter constraints on the weights are given.The effect of the number of performance measures on the computational advantages is finally examined. Here, randomly generated test problems in which the number of performance measures n varies between 3 and 8 are solved. The set of feasible weights with each value of n is determined by assigning the first performance measure as the primary one, i.e., w1 ≥ wi, i = 2, …, n.The values of the performance indicators obtained with the procedures are depicted in Table 3. The average numbers of pairwise and absolutely non-dominated designs as well as of non-dominated designs increase when the number of performance measures increases because the designs may perform well in terms of additional measures. OCBA-a identifies slightly fewer absolutely non-dominated designs on average compared with the non-dominated designs obtained by using MOCBA without preference information. The average number of pairwise non-dominated designs obtained with MOCBA-p is the smallest.The empirical probabilities of correct selectionP^CSpare higher for MOCBA-p than MOCBA. The probabilitiesP^CSpdecrease for both procedures as the number of performance measures increases. The probabilities for absolute dominanceP^CSaare higher for OCBA-a than MOCBA. These probabilities first decrease with the number of performance measures but then increase for the largest problem sizes as nearly all designs are absolutely non-dominated. Overall, the new procedures enable correct selection with a higher probability or a smaller computing budget with all problem sizes.The average shares of pairwise and absolutely non-dominated designs that are allocated a larger number of replications and that are evaluated more accurately with MOCBA-p and OCBA-a compared with the application of MOCBA are also depicted in Table 3. With MOCBA-p, the majority of the pairwise non-dominated designs are evaluated more accurately and the shares are not affected by the increasing number of performance measures. With OCBA-a, the shares constitute approximately half of the absolutely non-dominated designs. Thus, its performance is similar to MOCBA in terms of evaluating the absolutely non-dominated designs.To summarize, the computational advantages of MOCBA-p over MOCBA are maintained with the increasing number of performance measures even when preference statements regarding the weights imply only the primary performance measure. OCBA-a provides higher probabilities of correct selection for absolutely non-dominated designs than MOCBA. Otherwise, the performance of these procedures is similar. Greater computational advantages can possibly be obtained with OCBA-a by providing additional preference statements. However, the differences between the new procedures and MOCBA in terms of the performance indicators discussed above are mostly not affected by the number of the measures.

@&#CONCLUSIONS@&#
In this paper, the new procedures, MOCBA-p and OCBA-a, for R&S with multiple performance measures were introduced. They aggregate the performance measures using an additive MAU function with incomplete preference information regarding the weights related to the measures and select pairwise and absolutely non-dominated designs. By utilizing such information, challenges of eliciting unique weights, which are faced when employing the existing procedures aggregating the measures, are overcome. MOCBA-p and OCBA-a also yield computational advantages over the existing procedures used for selecting non-dominated designs based on the results of the numerical experiments conducted in the paper. By selecting pairwise and absolutely non-dominated designs, the number of designs remaining after the simulations is smaller. The remaining designs are additionally selected correctly with a higher probability or a smaller computing budget, and the majority of them are evaluated more accurately compared with the existing procedures. With MOCBA-p, these advantages are not affected by the set of feasible weights or the number of performance measures. With OCBA-a, the number of measures does not have an effect on the advantages whereas the advantages are only obtained when sufficiently tight constraints on the weights are provided. However, OCBA-a involves somewhat simpler allocation rules, and it can be modified in the future such that a non-additive MAU function is used. Overall, the new procedures present a novel and promising way for solving R&S problems with multiple performance measures.The procedures presented in this paper can be further improved by considering R&S settings where differences in expected utilities between some designs are small but must be resolved in order to identify non-dominated designs. MOCBA-p and OCBA-a may allocate a large share of the computing budget on such designs and little effort on the other designs when maximizing the probability of correct selection even if the probability cannot be increased significantly with such allocations. In the original MOCBA and OCBA, the issue of resolving small differences in expected values of performance measures has been addressed through an indifference zone (e.g., Teng et al., 2010). Then, differences that are smaller than the indifference zone are not resolved at all. A similar approach is suitable in MOCBA-p and OCBA-a as well but the indifference zone should be determined in terms of the utility instead of the performance measures. Butler et al. (2001) discuss how the indifference zone is obtained in terms of the utility when the weights of the MAU function are unique. The indifference zone for the case of incomplete preference information is a topic of future consideration.One could, on the other hand, study how to further assist the DM in the selection of the most preferred design. For instance, the possible rankings of the designs over the set of feasible weights could be examined. In this way, the DM is offered additional information on the designs that are among the top ones with all weights. Although the rankings can be determined based on the allocation of simulation replications obtained with MOCBA-p and OCBA-a, an R&S procedure designed for identifying the rankings could provide them correctly with a higher level of confidence.Supplementary data associated with this article can be found, in the online version, at 10.1016/j.patrec.2014.08.006.