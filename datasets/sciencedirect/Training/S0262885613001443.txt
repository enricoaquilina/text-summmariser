@&#MAIN-TITLE@&#
Visual tracking based on Distribution Fields and online weighted multiple instance learning

@&#HIGHLIGHTS@&#
We adopt Distribution Field (DF) layer as feature instead of traditional Haar-like one to robustly model the target.We derive an online weighted-geometric-mean MIL classifier to select the most discriminative layers.Our tracker is more robust while needing fewer features than the traditional Haar-like one and the original DFs one.The experiments show higher performance of our tracker than five state-of-the-art ones.

@&#KEYPHRASES@&#
Distribution Fields,Weighted-geometric-mean multiple instance learning,Discriminative classifier,Object tracking,

@&#ABSTRACT@&#
This paper presents an improved multiple instance learning (MIL) tracker representing target with Distribution Fields (DFs) and building a weighted-geometric-mean MIL classifier. Firstly, we adopt DF layer as feature instead of traditional Haar-like one to model the target thanks to the DF specificity and the landscape smoothness. Secondly, we integrate sample importance into the weighted-geometric-mean MIL model and derive an online approach to maximize the bag likelihood by AnyBoost gradient framework to select the most discriminative layers. Due to the target model consisting of selected discriminative layers, our tracker is more robust while needing fewer features than the traditional Haar-like one and the original DFs one. The experimental results show higher performances of our tracker than those of five state-of-the-art ones on several challenging video sequences.

@&#INTRODUCTION@&#
Object tracking finds wide applications such as automated surveillance, video indexing, traffic monitoring, human–computer interaction, etc. [1]. Difficulties arising from viewpoint and scale changes, illumination, occlusions and clutters make object tracking extremely challenging. Among various tracking methods, such as mean-shift based tracking [2,3], particle filter [4,5], active contour tracking [6,7] and point tracking [8], tracking-by-detection [9–13] becomes very popular. It obtains superior results by selecting few good features to best separate the object from the background via an online discriminative classifier.In the tracking-by-detection method, classifier designing and target representation are two important aspects. In [10] Avidan extends the optical flow approach with a support vector machine classifier for object tracking and later in [11] the boosting method was used to train a strong classifier for ensemble tracking. Collins et al. [14] propose an online boosting method to update discriminative features. However, the above mentioned discriminative methods [10,11,14] only utilize one positive sample (i.e. the tracking result in the current frame) and multiple negative samples. This might introduce errors when updating the classifier. These errors will be accumulated to degrade the classifier over time. Finally, this can lead to model drift or even failures. In order to alleviate the drifting problem caused by self-learning of classifiers, Grabner et al. [15] proposed an online semi-supervised approach. But this approach doesn't suit to change in appearance since it just labels the samples in the first frame and all the other samples are unlabeled. Due to the success of using Multiple Instance Learning (MIL) in face detection [16], Babenko et al. [9] organize samples in the form of positive bag and negative bag and use MIL to train the appearance classifier leading to more robust tracking.For target representation, the raw statistics pixel values on color, gradient, filter responses etc. have been used for many years in computer vision [17,18]. However, these features are not satisfactory in the presence of illumination changes and non-rigid motion. Recently, Haar-like feature is widely used to represent the target in tracking-by-detection because of its fast computing by integral image and strong ability to represent the spatial structure of the target. Many other features, such as rotated Haar-like features [19], census transform [20], sparse features [21], etc., are used to represent the target to obtain robust tracking. Especially, in order to avoid destroying image spatial information by common blur technique, Sevilla-Lara and Learned-Miller [22] using Distribution Fields (DFs) to build an image descriptor, able to smooth the objective function and keep the information about pixel values.Although the MIL tracker [9] has made a breakthrough in visual tracking, some problems remain. Firstly, Haar-like features using in the MIL tracker seem too simple, and the classifier often contains thousands of rectangle features for good performance. The large number of features leads to high computation costs in training and detecting phases. Furthermore, it will blur the image, destroy image information and cause the target lost. Secondly, the Noisy-OR model used in the MIL tracker [9] does not take into account any information about the importance of the positive samples, and therefore it may use less effective features (cf. Fig. 1). To alleviate this problem, Zhang and Song [23] proposed an online weighted-arithmetic-mean MIL tracker (called WMIL). However, the WMIL utilizing traditional Haar-like feature is not robust enough. Therefore, we adopt DF layers to model the target and weight a sample's contribution according its distance to the target to select most discriminative features.Because the DF layers contain more image spatial information than the classical Haar-like one, we believe that their specificity and landscape smoothness could better represent the target. In order to select most discriminative layers, we present a new bag probability function using the weighted-geometric-mean instance probability and construct an efficient method to optimize the bag likelihood function. The experimental results on 12 challenging video sequences demonstrate the superior performance of our method with regard to state-of-the-art methods in the literature in robustness, stability and efficiency.The rest of this paper is organized as follows. Section 2 recalls related basis of MIL tracking and Distribution Fields. Section 3 introduces our tracking method, i.e. target representation based on Distribution Fields and weighted-geometric-mean MIL classifier. Section 4 shows extensive experiments to compare our method with state-of-the-art ones. Section 5 concludes on our new proposed method.We briefly introduce the MIL tracking framework [9], basis of our work. Let l(x⁎) denote the location of tracking result at the frame t−1 where x⁎ represents the sample. Firstly, we crop out a set of image patches Xsnear the location l(x⁎) with a search radius s at tth frame, i.e. Xs={x:‖l(x)−l(x*)<s‖}. Secondly, we calculate the appearance model, a discriminative classifier h(x), which returns the posterior probability p(y=1|x)=σ(h(x)). Then we apply the MIL classifier to these samples Xsto find the one with maximum confidence aslt*=largmaxx∈Xspy|x. Thirdly, we randomly crop some positive samples from setXα=x:lx−lx*<αand some negative samples from setXγ,β=x:γ<lx−lx*<β. Finally, the appearance model based MIL classifier is updated with positive and negative bags.Besides the motion model described above, MIL tracking system also consists of a target representation, a discriminative classifier (also called appearance model) and a search strategy. Main focus of this work is the first two of them. For target representation, Haar-like feature is the most common used in tracking-by-detection. Haar-like features encode differences in average intensities between several rectangular regions and can be calculated rapidly through integral image [24]. But the complete Haar-like feature set is large, containing much redundant information, blurring the image and leading huge computation. For discriminative classifier, the Noisy-Or model used in MIL tracker gives the bag's positive probability by the following criterion: if a bag is labeled positive instance, it is assumed to contain at least one positive instance, otherwise the bag is negative. The shortcoming of this model is that it does not take into account of any information about the importance of the positive samples [23].Distribution Fields proposed by [22] preserve the spatial structure of the object by having a distribution at each pixel and can be viewed as a generalization of many previous image descriptors for different purposes. A DF is a matrix, represent as df, with (2+N) dimensions. The first two dimensions of the DFs are width and height of the image, and the other N dimensions index the feature space. In general, like in our work, the feature space is gray-scale intensity, so we get a 3D DF of size m×n×b of the image, where m and n are the width and height of the image, and b is the number of intensity of feature or bins. For a higher dimensional feature, the image yields larger DFs. For example, if the feature space is RGB colors, then the image yields five dimensions DFs containing a 3D distribution at each pixel. Each element in the matrix is a probability distribution, defining the probability of a pixel of taking each feature value.We can explode an image into DFs as below:(1)dfijk=10ifIij==kotherwisewhere i and j index the row and column of the image, and k indexes the possible values of the pixel. In addition, the k indexes the kth layer of the DFs. It is worthy of particular note that the sum of the components of each column in each DFs is 1, and this produces a probability distribution at each pixel.After getting the initial DFs containing exactly the same information as the original representation, we need to smooth it both in image and feature spaces. First, we use a 2D Gaussian filter to convolute with each layer of the 3D DFs. We can formularize it as:(2)dfsk=dfk∗hσswhere k indexes the kth layer of the DFs, andhσsis a 2D Gaussian kernel of standard deviation σs and * is the convolution operator. Second, for a grayscale image, we use a 1D Gaussian filter to convolute with the third dimension (so call feature space) of the DFs. We can formularize it as:(3)dfssij=dfsij∗hσfwherehσfis a 1D Gaussian kernel of standard deviation σf. It is worthy of particular note that, in order to keep the property that values of each column of the DFs integrate to 1, we should fill with uniform distributions in the missing information outside the boundaries. After that, we get a smooth Distribution Field in which “for any non-zero value in a layer L, there is a pixel of value L somewhere near this location in the original image” [22].Fig. 2is an example of Distribution Fields. The original image patch (A) was exploded to initial DFs (B) based on the formula (1). After smoothing both in the image and feature spaces, we get the smooth DFs (C).The comparison between DFs for two images is defined by L1distance between the two DFs df1 and df2 as:(4)L1df1,df2=∑i,j,kdf1ijk−df2ijk.A simple tracking based on DF target representation showed good performance on some challenge sequences [22]. However, when some layers between target's DFs and its adjacent background's DFs share some common characteristics, DFs based tracking method may perform poor. Therefore, it is useful to select fewer discriminative layers from whole DFs to distinguish the target from background.The Bayesian theorem [25] is used to represent the poster probability of a sample x which is a positive or negative sample as below:(5)py=1|x=px|y=1py=1∑y=0,1px|ypy=σHxwhereσx=11+e−xis the sigmoid function. Since we represent sample x by using DF layer feature vector dfx=(dfx(k),…,dfx(M))T, where k indexes the kth layer feature, the log-like discriminative function H(x) can be represented as:(6)Hx=logpx|y=1px|y=0=∑k=1Mlogpdfxk|y=1pdfxk|y=0=∑i=1Mhk.Thus we get the weak classifier:(7)hk=logpdfxk|y=1pdfxk|y=0.During the training phase, we crop n positive samples {x1+,x2+, …,xn+} and m negative samples {x1−,x2−, …,xm−}, then explode these samples into corresponding smoothed Distribution Fields {df1+,df2+, …,dfn+} and {df1−,df2−, …,dfm−}. In Fig. 3, we illustrate the difference between classical Haar-like feature and DFs to represent the target. Finally, we represent the target as follows:(8)dfmodel+=1n∑i=1ndfi+dfmodel−=1m∑i=1mdfi−.Similar to DF tracker which uses the L1 distance to compare two DF arrays, we also use it to compare two layers of samples' DFs df1 and target's DFs dfmodel, defined as:(9)L1df1k,dfmodelk=∑i,jdf1ijk−dfmodelijkwhere k indexes the kth layer of the DFs.In each frame, after cropping positive and negative samples and exploding them into corresponding smoothed Distribution Fields, we use the following updating rules:(10)dfmodel+←λdfmodel++1−λ1n∑i=1ndfi+dfmodel−←λdfmodel−+1−λ1m∑i=1mdfi−where λ is the learning rate.In practice, we firstly transform an image into DFs and then get out DFs of each sample patch from DFs directly. Our experience shows that it will effectively reduce both CPU and memory consumption.In order to compute the weak classifier hkin Eq. (7), we need to get two priori probabilities p(dfx(k)|y=1) and p(dfx(k)|y=0). In our algorithm, they are defined as:(11)pdfxk|y=1=1−L1dfmodel+k,dfxpdfxk|y=0=1−L1dfmodel−k,dfx.In original MIL tracker, after obtaining optimal tracking results l⁎(t) in current frames, one crops positive samples around the l⁎(t), which compose positive bag. These positive samples are assumed to contribute equally and independently to a bag's class label in the Noisy-OR based MIL model. This doesn't take into account the importance of the positive samples. However, the closer the location of a positive sample is to optimal location l⁎(t), the more important it is. We assume that the sample's weight obeys the Gaussian distribution with mean ℓ(x⁎) and variance σ. This means that when we crop a new positive patch at time t, its weight can be defined as following:(12)w=12πσe−lx−lx*22σ2.To simplify the problem, we let variance σ=1. Then the simplified formula is:(13)w=Ce−lx−lx*22whereC=12πis a normalization constant, and l(.)∈R2 is the location function. In addition, we take all the negative samples to independent negative bag, the weight for negative samples can be simply defined as a constant w.Given a bag Xiwith n instances xij∈Xi, we model the weighted instance probability by:(14)pyi=1|xij=11+exp−wijHxijpyi=0|xij=11+expwijHxijwhere wijis the weight of the instance xij, and H(.) is a strong classifier. So the bag probability p(y|Xi) is modeled using the weighted-geometric-mean model as below [26]:(15)py=1|Xi=∏jnpy=1|wijxij1/n∏jnpy=1|wijxij1/n+∏jnpy=0|wijxij1/n=exp1n∑j=1nwijHxij1+exp1n∑j=1nwijHxijpy=0|Xi=∏jnpy=0|wijxij1/n∏jnpy=1|wijxij1/n+∏jnpy=0|wijxij1/n=11+exp1n∑j=1nwijHxij.Based on weighted-geometric-mean model, we can represent the bag log-likelihood function as,(16)logLX=∑i=01yilogpyi=1|Xi+1−yilogpyi=0|Xi.In original MIL model, it maintains a weak classifier pool Φ={h1, …,hM} and greedily selects the most discriminative weak classifier by maximizing the bag log-likelihood:(17)hk=argmaxh∈h1…hMLHk−1+hwhere h is a weak classifier in the classifier pool and the strong classifier Hk−1=∑m=1k−1hm, where hmis the mth selected weak classifier.In our algorithm, we also maintain a pool of M weak classifiers, similar to the online MIL tracker, and select the K most discriminative weak classifiers from the pool. However, we present a new criterion to select the weak classifiers instead of directly maximizing the log-likelihood used in the original MIL tracker.The derivative of the bag log-likelihood function L with respect to xijis(18)∂logLX∂xij=1niyiwijpyi=0|Xi−1ni1−yiwijpyi=1|Xiwhere wijis sample's weight of sample xijbelonging to bag Xi.Let pi=p(yi=1|Xi), then p(yi=0|Xi)=1−pi. We can simplify the above derivative as:(19)∂logLX∂xij=1niwijyi−pi.Based on AnyBoost method [27], we approximate ℓ(Hk−1+h) by using the first-order Taylor expansion as:(20)lHk−1+h≈lHk−1+∇lH,h|H=Hk−1where(21)∇lH,h=∑i=01∑j=1nihxij∇lHxij.Combining Eq. (19) into Eq. (21), we get,(22)∇LH,h=∑i=01∑j=1ni1niwijyi−pihxij.Then we select our discriminative classifiers by maximizing the criterion (22) instead of using bag log-likelihood function in the original MIL tracker.(23)hk=argmaxh∈Φ∇lH,h|H=Hk−1.Our discriminative feature selection Eq. (23) is more efficient than Eq. (17). The latter directly maximizes the bag likelihood function similar to classical MIL tracker while our method need not compute the instance probability and bag probability M times after selecting one weak classifier. So it will save greatly much CPU computing time.Generally, similar to classical MIL tracker [9], our new MIL tracking method (called DFMIL) consists of the target representation with DFs and a weighted-geometric-mean MIL boost. The Algorithms 1 and 2 summarize respectively the process of the DFMIL tracker and its online weighted-geometric-mean MIL boosting.Algorithm 1DFMIL trackerIn order to verify the robustness of our algorithm, we tested it in twelve very challenging image sequences compiled by Babenko et al. [9]. These sequences challenge most trackers in numerous aspects including: heavy occlusion, motion blur, in-plane and out-of-plane rotation, large illumination change, scale variation and cluttered background. Furthermore, to compare weighted-geometric-mean MIL (WGMMIL) classifier and the arithmetic mean one (WMIL [23]), we use WGMMIL classifier to select discriminative Haar-like features in our feature selection criterion defined by Eq. (23). We also compared our algorithm with five state-of-the-art tracking algorithms including: Semi-supervised on-line boosting for robust tracking (SemiB) [28], visual tracking with online multiple instance learning (MIL) [9], real-time compressive tracking (CT) [29], Distribution Fields for tracking (DF) [22] and real-time visual tracking via online weighted multiple instance learning (WMIL) [23]. Our algorithm is implemented in MATLAB on Windows XP system, and runs on notebook computer with 2 cores CPU at 2.2GHz and 2GB RAM.We use the source or binary codes released by the authors with parameters described in the original paper if available on the same image sequences. We tune its parameters for best performance. Since the algorithms MIL, WMIL and CT involve some randomness, we run them 10 times on each sequence, and then take the average for comparison. The parameter setting in tracking method is an open problem. For our DFMIL, we mainly refer to classical MIL tracking [9] and DF tracking [22] to set parameter for best tracking. Generally, the parameters used in our algorithm follow. The search radius for drawing positive samples is set to α=4 except for tiger1 α=8, the inner and outer radios to crop negative are set to ξ=8 and β=30 respectively, then just 50 negative samples are randomly selected. In the tracking phase, the search radius for detecting samples is set to γ=25. To the important parameters σsand σf, which are the standard deviation of the Gaussian filters in feature space and feature space respectively, we make a similar setting to original DF [22] where the larger targets are better tracked with larger values of σsas well as σf. The covariance of the 2D Gaussian filter used to smooth DFs in image space, and that of the 1D Gaussian filter used to smooth DFs in feature space is 3 and 1 respectively except for tiger1 and coke11 (for Tiger1 it is 2 and 1; for coke11 it is 2 and 0.625). The learning rate in Eq. (10) is λ=0.9. Furthermore, our algorithm selects 5 discriminative layers from the feature pool of 16 layers. Both K and M are much smaller than that of MIL tracker, WMIL tracker and CT tracker. In fact, our proposed tracker can also get good tracking results for several sequences even using only less than 5 discriminative features.We use two criteria to quantitatively assess the performance of the trackers. One is the center location error, another is the percentage of frames correctly tracked defines as: ifG∩TG∪T>0.5, then a track result is considered correct, where G is the ground truth object location rectangle and T is the track result rectangle. Both the center location error (Table 1) and the percentage of frames correctly tracked (Table 2), show that our algorithm performs better than other five state-of-the-art algorithms in most image sequences and our own WGMMIL. Fig. 4presents the relative position errors (in pixels) between the center and the tracking results.Table 3presents the average tracking speed of seven tracking methods. For MIL tracker, its strong classifier is the combination of weak features selected by iteratively maximizing the log-likelihood function. It cost a lot of time to compute the instance probability and bag probability. This leads to its slowest speed among those methods. In comparison, DFMIL, WGMIL and WMIL do not need to compute the instance probability and bag probability M times after selecting one weak classifier. So their weak classifier selection criterions are more efficient than MIL tracking and lead to faster tracking speed than MIL tracker. Moreover, the Haar-like feature used in WMIL and WGMMIL tracker can be computed quickly by an integral image while the layer feature will cost a little more time. It causes DFMIL to run slower than WMIL and WGMMIL. In addition, the CT algorithm is simple and need not select feature, so that it gets the fastest speed. Finally, because the DFMIL has to choose features again in each frame, its tracking speed is slightly lower than that of DF.Figs. 5, 6, 7 and 8show some representative tracking results on twelve sequences for SemiB, MIL, DF, CT, WMIL, WGMMIL and DFMIL tracking methods.The main challenges in these two sequences are scale and pose change and illumination variation. In David indoor sequence, DF and our WGMMIL perform the best but poorly in the Sylvester sequence. But our algorithm DFMIL performs well for both sequences. When people move from the shadow to the light, the other 5 algorithms began a slight drift (see #58, #110). When illumination variation and rotation occur simultaneously, drift increases (#182 in David sequence). In Sylvester sequence, our algorithm achieves the best performance after pose change and illumination variation for a long time (see frames #617, #941, #997).We can see that MIL, WMIL, CT (all using traditional Haar-like feature) drift away from the target with the change of dollar note appearance (Frames #50, #180, #224, #282). Worse, the SemiB's tracking results drift from the target completely (see frames #180, #224, #282). But both DF and DFMIL track the object correctly. Our explication is because the layer features based on DF can capture more image spatial information.The two sequences exhibit many challenges (including: frequent occlusion, motion blur caused by fast motion) making numerous trackers drift away from the target (see frames #261, #347, #353 in tiger1 sequence). Although the DF tracker and ours both use DF layers, ours use less but more discriminative layers to achieve a better tracking (see frames #44, #199, #274 in tiger2 sequence).The two sequences were designed to test the ability of a tracking algorithm to response to occlusion with long time and large area. In the Occluded Face sequence, the algorithms using Haar-like feature will drift with the movement of obstructions. As shown by frames #52 and #69 of Occluded Face sequence, the tracking boxes of MIL, WMIL, CT move up and down with book moving up and down. The drifting is more and more serious after occlusion with long time (see #234, #650 and #681). The same problem arises in the Occluded Face2 sequence. These results highlight the advantages of using layer feature in tracking-by-detection.Extreme scale change and pose change caused by rotation exist in the girl sequence. Our method performs very well while all the other four algorithms dramatically drift (#119, #244 and #263). After several 360-degrees out-plane rotation, our algorithm successfully tracks the target. Complex backgrounds exist in both Girl and Cliff Bar sequences where most methods fail to accurately track the target (see #152, #158 of Cliff Bar; #442 of Girl).Several hard challenges (including completely obscured, blur caused by fast motion, rotation) make many method failed. All methods can track on the whole because all of them use an adaptive appearance model. However, our algorithm performs again the best (#32, #224 of coke11; #193, #218 of Twining).Three main challenges arise in this video sequence, including large-scale rotation, change in appearance and noise. The MIL track results shake all the time, while CT and our DFMIL perform very well. SemiB, WMIL and DF shift away after big change in appearance (see frame #209 and #307 of Surfer).

@&#CONCLUSIONS@&#
In this paper, we proposed a novel, effective and robust tracking algorithm based on the DF target representation and weighted-geometric-mean MIL classifier. Firstly, layer features based on DFs, which effectively keep image's spatial information, instead of traditional Haar-like features, were used to represent the target in our tracker. Comparing with the traditional Haar-like feature needing a big feature pool, the layer feature based on DFs needs a smaller pool size but can more effectively represent the target. Secondly, by integrating the sample importance into a weighted-geometric-mean MIL model, we derive an online approach to maximize the bag likelihood by AnyBoost gradient framework to select out a smaller amount of more discriminative features to distinguish target from background. Empirically, the MIL tracker selects 50 most distinctive features from the total of 250 and DF tracker uses all 16 DF layers to model the target, but we just need 5 layers from the total of 16. The experimental results on challenging video sequences demonstrated the superiority of our proposed method to five state-of-the-art ones in accuracy and stability.