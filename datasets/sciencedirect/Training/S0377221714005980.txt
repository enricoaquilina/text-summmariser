@&#MAIN-TITLE@&#
Quantifying uncertainty on Pareto fronts with Gaussian process conditional simulations

@&#HIGHLIGHTS@&#
We study the ability of Kriging-based algorithms to learn the Pareto front.Random sets theory is applied based on conditional Gaussian process simulations.Estimation and visualization of the uncertainty on Pareto fronts is provided.Uncertainty measures allow defining stopping criteria in a sequential framework.The interest of the proposed methodology is illustrated on two example problems.

@&#KEYPHRASES@&#
Multi-objective optimization,Attainment function,Vorob’ev expectation,Expected Hypervolume Improvement,Kriging,

@&#ABSTRACT@&#
Multi-objective optimization algorithms aim at finding Pareto-optimal solutions. Recovering Pareto fronts or Pareto sets from a limited number of function evaluations are challenging problems. A popular approach in the case of expensive-to-evaluate functions is to appeal to metamodels. Kriging has been shown efficient as a base for sequential multi-objective optimization, notably through infill sampling criteria balancing exploitation and exploration such as the Expected Hypervolume Improvement. Here we consider Kriging metamodels not only for selecting new points, but as a tool for estimating the whole Pareto front and quantifying how much uncertainty remains on it at any stage of Kriging-based multi-objective optimization algorithms. Our approach relies on the Gaussian process interpretation of Kriging, and bases upon conditional simulations. Using concepts from random set theory, we propose to adapt the Vorob’ev expectation and deviation to capture the variability of the set of non-dominated points. Numerical experiments illustrate the potential of the proposed workflow, and it is shown on examples how Gaussian process simulations and the estimated Vorob’ev deviation can be used to monitor the ability of Kriging-based multi-objective optimization algorithms to accurately learn the Pareto front.

@&#INTRODUCTION@&#
The interest in Multi-Objective Optimization (MOO) has been growing over the last decades, resulting in the development of numerous dedicated methods, especially in evolutionary MOO (Deb, 2008). These methods are able to cope with challenging problems occurring when few information about the properties of the objective functions is available (black-box optimization). In some situations, as for example in car crash safety design (Liao, Li, Yang, Zhang, & Li, 2008), another difficulty comes from a limited budget of evaluations, because of expensive experiments or high fidelity simulations.In this context, see e.g. (Santana-Quintero, Montano, & Coello, 2010) for a review, a common approach is to rely on a surrogate model or metamodel to alleviate the computational costs of the optimization process. In particular, Kriging metamodels have proven to be efficient because they not only give a response surface but also a quantification of prediction uncertainty. In mono-objective optimization, this property has been extensively used following the principles of the Efficient Global Optimization (EGO) algorithm (Jones, Schonlau, & Welch, 1998) where the Expected Improvement criterion is used to balance between exploitation and exploration. Extensions to MOO have been developed, from scalarization approaches (Knowles, 2006; Zhang, Liu, Tsang, & Virginas, 2010) to the use of multi-objective Expected Improvement criteria such as the Expected Hypervolume Improvement (Emmerich, Deutz, & Klinkenberg, 2011).While results about the optimality of solutions from aggregation approaches have been reported (see e.g. Miettinen, 1999), things are more difficult to analyze for MOO and even worse in metamodel based MOO, where an additional source of uncertainty due to surrogate modeling must be taken into account. Besides, the study of the convergence in evolutionary MOO is an ongoing subject of research (Wagner, Trautmann, & Martí, 2011).Inspired by what has been proposed for Kriging-based excursion sets estimation in Chevalier, Ginsbourger, Bect, and Molchanov (2013) and Chevalier (2013), we propose here to use notions from the theory of random sets (Molchanov, 2005) for quantifying uncertainty on Pareto fronts, through conditional simulations. The latter are used to estimate the probability that any given point in the objective space is dominated, which is known in performance assessment of multi-objective optimizers as the attainment function (Grunert da Fonseca & Fonseca, 2010). From this we obtain a metamodel-based estimation of the Pareto front using the Vorob’ev expectation (Molchanov, 2005), with a value of the associated uncertainty: the Vorob’ev deviation. At each stage of the sequential optimization process, an insight is provided to the practitioner about convergence and possibilities of further improvements. Furthermore, with two or three objectives the proposed approach makes it possible to visualize the variability around the estimation of the Pareto front in the objective space.The paper is organized as follows: Section 2 details notions in MOO and in Gaussian Process Regression upon which the proposed approach is based. In particular Section 2.4 is dedicated to conditional simulations. In Section 3, we propose an original definition of uncertainty using the Vorob’ev expectation and deviation. Finally, Section 4 is dedicated to applications of the proposed methodology to three different test cases, where the potential of the approach to quantify uncertainty and monitor convergence within a sequential MOO algorithm is illustrated.Multi-objective optimizers aim at optimizing (say minimizing) several objectives at once: f1(x), …, fm(x) with x = (x1, …, xd)Ta vector of decision variables in E (usuallyE⊂Rd) andf:E→Rmthe vector valued function whose coordinates are f1, …, fm. As the objectives are usually in competition, the existence of an optimal solution minimizing all objectives simultaneously cannot generally be taken for granted. This leads to the definition of compromise solutions following the Pareto dominance: a vector is said to be dominated if there exists another vector which is not worse in any objective and better for at least one of them. If a vector is not dominated by any other vector, it is said to be optimal in the Pareto sense.The set of optimal (or non-dominated) points in E is called Pareto set and the corresponding image by f, composed of non-dominated vectors, is called Pareto front. Multi-objective optimization algorithms aim at finding non-dominated objective vectors as close as possible to the true underlying Pareto front, creating a discrete approximation sometimes called a Pareto front approximation (Zitzler, Knowles, & Thiele, 2008).A common solution to perform optimization under a tight evaluation budget is to appeal to a mathematical surrogate of the objective function. Here we focus on a class of probabilistic metamodels relying on Gaussian random fields. Originating from geostatistics with a technique named Kriging (Matheron, 1963), predicting with such a metamodel is known in the machine learning community as Gaussian Process Regression (GPR) (Rasmussen & Williams, 2006). These Kriging/GPR metamodels have the property of interpolating the observations when noiseless data is considered (deterministic case). Furthermore, due to the probabilistic nature of these metamodels, they also provide a quantification of the prediction uncertainty.Without loss of generality, here we do not assume a priori any stochastic dependency between the responses f1, …, fmand we treat them separately since the use of dependent models is significantly more cumbersome and has not been shown to perform better in state of the art studies (Kleijnen & Mehdad, 2014; Svenson & Santner, 2010). Following the settings of Gaussian Process Regression (Sacks, Welch, Mitchell, & Wynn, 1989; Stein, 1999), each of the objective functions fiis supposed to be a sample path of a random field Yi:Yi(·)=giT(·)βi+Zi(·)1em0ex(UniversalKriging)where gi( · )Tis a vector of known basis functions,βia vector of unknown coefficient and Zi( · ) is a zero mean Gaussian process (GP) with given covariance function, or kernel, ki. With n evaluations at the same locations for the objectives{Yi(x1)=yi,1,⋯,Yi(xn)=yi,n,0.35em0ex1≤i≤m}denotedAn, the predictor (or Kriging mean) and the prediction covariance (also referred to as Kriging covariance) of Universal Kriging (UK) are expressed as:mi,n(x)=gi(x)Tβ^i+ki,n(x)TKi,n−1(yi,n−Gi,nβ^i)ci,n(x,x′)=ki(x,x′)−ki,n(x)TKi,n−1ki,n(x′)+(gi(x)T−ki,n(x)TKi,n−1Gi,n)(Gi,nTKi,n−1Gi,n)−1×(gi(x′)T−ki,n(x′)TKi,n−1Gi,n)Twhere yi, n= (yi, 1, …, yi, n), Ki, n= (ki(xs, xt))1 ≤ s, t ≤ n, ki, n(x) = (ki(x, x1), …, ki(x, xn))T,Gi,n=(gi(x1)T,⋯,gi(xn)T)Tandβ^i=(Gi,nTKi,n−1Gi,n)−1Gi,nTKi,n−1yi,n.Note that from a Bayesian point of view, assuming that the Yiare Gaussian conditionally onβiand putting an improper uniform prior onβi, it is known (Handcock & Stein, 1993) that the Universal Kriging mean and covariance coincide with the conditional expectation and covariance of YiknowingAn, respectively:mi,n(x)=E(Yi(x)|An)andci,n(x,x′)=cov(Yi(x),Yi(x′)|An).The covariance functions are chosen according to prior hypothesis about the unknown functions, such as regularity, sparsity, and possible symmetries (Ginsbourger, Roustant, & Durrande, 2013). While there exists a variety of admissible covariance functions, the most commonly used are the stationary “Gaussian” and “Matérn” kernels (Stein, 1999). Maximum likelihood estimation or cross validation techniques (Bachoc, 2013) are typically employed to estimate values for the kernel hyperparameters (Rasmussen & Williams, 2006). An example of a Kriging model with constant unknown trend and Matérn (ν = 5/2) kernel is depicted in Fig. 1a.Sequential approaches in MOO aim at adding new observations with a balance between exploration and exploitation. Similar to Jones et al. (1998), several extensions of the EGO algorithm have been proposed for MOO. The main idea is to derive criteria in the vein of the Expected Improvement by defining a generalization of the notion of improvement for multiple objectives. Popular methods include scalarization approaches like ParEGO (Knowles, 2006) or MOEAD-EGO (Zhang et al., 2010) or truly multi-objective methods based on the definition of improvement functions over the current Pareto frontPndefined by the current observations. Considered improvement functions are respectively based on Euclidean distance (Keane, 2006), Hypervolume (Emmerich, Giannakoglou, & Naujoks, 2006; Wagner, Emmerich, Deutz, & Ponweiser, 2010) or Maximin distance (Bautista, 2009; Svenson & Santner, 2010) i.e. respectively the distance to the closest point ofPn, the volume added overPnand an axis-wise distance toPn.In the applications of Section 4, we use the Expected Hypervolume Improvement to sequentially add points. This criterion has been successfully applied to problems with limited budget (Emmerich et al., 2011), enjoys some beneficial properties (Emmerich et al., 2011) and furthermore is related to the concept of attainment function which is of particular importance in what follows.From the Universal Kriging metamodels presented in Section 2.2, it is possible to generate samples interpolating the available evaluation results, called conditional simulations. They can be generated using a variety of methods, from matrix decomposition to spectral methods, as presented in Journel (1974), Hoshiya (1995), Diggle and Ribeiro (2007), Roustant, Ginsbourger, and Deville (2012). Examples of such conditional simulations are displayed in Fig. 1b.They have been applied in mono-objective optimization in Villemonteix, Vazquez, and Walter (2009) as a tool to estimate an information gain when no analytical formula is available, as opposed to the Expected Improvement. Until now, the computation of multi-objective Expected Improvement relies either on analytical formulas or on Monte Carlo estimation with draws of the posterior distribution at a single location x. In contrast, conditional simulations consist in drawing posterior realizations of the unknown function at multiple points, say Ep: {e1, …, ep}⊂E. Since exact methods essentially depend onp×pcovariance matrices, the number of simulation points is typically limited by storage and computational cost. Despite this limitation, conditional simulations (based on matrix decomposition) prove useful for Pareto front estimation, as presented in the next sections.In this section, we assume that a Gaussian process model (see Section 2.2) has been estimated for each objective function from a set of n observationsAn. These models allow us to generate conditional Pareto front realizations and further estimate the uncertainty on the Pareto front with concepts from random sets theory.Here we use conditional simulations to generate so-called conditional Pareto fronts (CPF). The first step is to simulate a finite number (say N) of vector-valued GP conditional simulations{Y1(1),⋯,Ym(1)},⋯,{Y1(N),⋯,Ym(N)}at some simulation points in the design space. Selecting the corresponding non-dominated simulation points and simulated responses then provides conditional Pareto sets and fronts as summarized in Algorithm 1 and illustrated in Fig. 2.Note that what we denote by CPF are actually approximations of conditional Pareto fronts, just like conditional simulations of Gaussian random fields are often approximated realizations relying on a finite number of points. Simulation points can be fixed for all the simulations or changed from one simulation to the other. Fixed simulation points accelerate the simulation generation but they may introduce a bias and lead to missing worthwhile areas. On the other hand, modifying the simulation points increases the computational burden but is more exploratory, which might be an asset in high dimensions. Besides, the procedure used to choose the location of simulation points may impact the results. Accordingly, two sampling strategies are investigated in Section 4.2.Algorithm 1Simulation of N conditional Pareto sets and fronts.fori=1,2,…,NdoChoose p simulation pointsEp=e1,…,epin E (fixed or different at each iteration).forj=1,2,…,mdoGenerate a conditional simulation ate1,…,epfor thejthobjective:Yj(i)=(Yj(i)(e1),…,Yj(i)(ep)).end forDetermine the Pareto set and front of{Yj(i),…,Ym(i)}.end forFrom now on we focus on the use of CPFs since the decision maker is mostly interested in visualizing results in the objective space. Each CPF is composed of non-dominated points in the objective space. They have been considered to assess the performances of MO optimizers (Fonseca, Grunert da Fonseca, & Paquete, 2005; Zitzler et al., 2008) under the term Random Non-dominated Point (RNP) sets: sets of random vectors inRm, non-dominated with respect to each other and with random finite cardinality (see e.g. Grunert da Fonseca & Fonseca, 2010). An alternative view is to consider the set of all objective vectors dominated by a realization of an RNP set, called an attained set. Realizations of RNP sets and the corresponding attained sets are presented in Fig. 3.In the mono-objective case, GP models provide analytical expressions of the expectation (Kriging mean) and uncertainty (variance of the pointwise prediction). It would be interesting to get their counterpart for the attained sets of simulated CPFs. Nevertheless, defining an expectation and/or an index of variability for sets is not straightforward and requires concepts from random sets theory (Molchanov, 2005).Before introducing related notions for CPFs, let us recall some general definitions. Set-valued random elements, in particular random closed sets (Molchanov, 2005) received attention in the probability literature over the last decades. There exist several candidate notions to define the mean of a random closed set, see Molchanov (2005, chap. 2). We choose a rather intuitive one, based on the notion of coverage function:Definition 1Coverage functionLetYbe a random closed set on a topological space D (hereD⊂Rmequipped with the topology induced by the Euclidean distance). The coverage functionpYis defined bypY:x∈D0.25em0ex↦0.25em0exP(x∈Y).This definition has been applied in the Kriging framework to estimate sets of critical input values (Chevalier, 2013; Chevalier et al., 2013). It uses the Vorob’ev expectation, based on the upper level setsQβ={z∈D,pY(z)≥β}, called β-quantiles.Definition 2Vorob’ev expectation and deviationDenoting by μ the Lebesgue measure onRmand assuming thatE(μ(Y))<+∞, the Vorob’ev expectation is the β*-quantileQβ*such thatE(μ(Y))=μ(Qβ*)if this equation has a solution, and otherwise it is defined from the conditionμ(Qβ)≤E(μ(Y))≤μ(Qβ*),0.35em0ex∀β>β*. The associated Vorob’ev deviation is the quantityE(μ(Qβ*ΔY)), where Δ denotes the symmetric difference between sets, i.e.Qβ*ΔY=(Qβ*∪Y)(Qβ*∩Y).The Vorob’ev expectation is a global minimizer of the deviation among all deterministic closed sets with volume equal to the average volume ofY(see Molchanov, 2005 for a proof): for any set M withμ(M)=E(μ(Y)),E(μ(Qβ*ΔY))≤E(μ(MΔY)).In the MOO literature, the study of distribution location and spread of an attained setXrely on the attainment functionαX(Grunert da Fonseca & Fonseca, 2010): the probability for a given point in the objective space to be dominated by an RNP set,αX=P(x∈Y).Attained sets are also closed1As a finite union of closed sets (hyper quadrants).1and unbounded subsets inRm. Hence, the attained sets obtained with the simulated CPFs can be considered as realizations of a random closed set and are denoted byYi, (i = 1, …, N). Looking again at Definition 1, one can see that the attainment function is in fact a coverage function. For proofs about the equivalence of the distribution of an RNP set and the corresponding attained set as well as for a definition of the attainment function in terms of coverage function, we refer to Grunert da Fonseca and Fonseca (2010). This reference establishes the link between optimization results and random closed sets, in a case where the attainment function is computed from several runs of optimizers. Their comparison is then performed based on statistical hypothesis testing procedures.In practice the attainment function is estimated by taking the proportion of RNP sets that dominates a given vector in the objective space:Definition 3Empirical attainment functionGiven a sample of attained setsY1,⋯,YN, the empirical attainment function is defined as:α^N:Rm0.25em0ex↦0.25em0ex[0,1],0.35em0exα^N(z)=1N∑i=1N1{z∈Yi}where1{z∈Yi}=1ifz∈Yi, 0 otherwise.An example of an empirical attainment function is presented in Fig. 4, showing where in the objective space there is a high probability to improve on the current Pareto front.Definition 2 requires thatYis bounded for its Vorob’ev expectation to exist. Hence it is necessary to define a reference point R to bound the integration domain. Since the Lebesgue measure of an attained set with respect to the reference point is the hypervolume indicator of the corresponding RNP set, denoted by IH(., R), the choice of R has a similar influence (see e.g. Auger, Bader, Brockhoff, & Zitzler, 2012). Unless there is previous knowledge about the range of the objectives, we choose R as the maximum of each objective reached by the conditional simulations.The Pareto frontier of the Vorob’ev expectation provides us with an estimate of the Pareto front, as illustrated in Fig. 4. The value of the Vorob’ev deviation gives an idea about the variability of the simulated CPF and can be monitored as observations are added, as will be shown in Section 4. The procedure to determine the value β* corresponding to the Vorob’ev expectation (Vorob’ev threshold) as well as of the Vorob’ev deviation is described in Algorithm 2.Algorithm 2General procedure for estimating the Vorob’ev expectation and deviation1: Generate N CPFs (see Algorithm 1).2: ifRis unknown then find the extremal values for the objectives over the RNP sets realizations:R=[maxi∈(1,⋯,N)Y1(i),⋯,maxi∈(1,⋯,N)Ym(i)]3: Define the integration domain:Ω=[APTARANORMALmini∈(1,⋯,N)Y1(i),R1]×⋯×[APTARANORMALmini∈(1,⋯,N)Ym(i),Rm]4: Determine the average volume of the attained setsYi:E(μ(Y))≈1N∑i=1N∫Ω1{z∈Yi}μ(dz)=1N∑i=1NIH(Yi,R)5: Find the value of the Vorob’ev thresholdβ*by dichotomy: seta=0,b=1:whileb−a<∈doifμ(Qa+b2)<E(μ(Y))thenb=a+b2elsea=a+b2end ifend while,β*=a+b26: Estimate the Vorob’ev deviation:E(μ(Qβ*ΔY))≈1N∑i=1N∫Ω1(z∈Qβ*ΔYi)μ(dz)=1N∑i=1N(2IH(Qβ*∪Yi,R)−IH(Qβ*,R)−IH(Yi,R))The last equality in Algorithm 2 comes from the following: ∫Ω1z ∈ AΔBμ(dz) = IH2(A, B, R) + IH2(B, A, R) where IH2(A, B, R) is the binary hypervolume indicator, defined for instance in Zitzler, Thiele, Laumanns, Fonseca, and Grunert da Fonseca (2003): the volume dominated by A and not by B, i.e. IH2(A, B, R) = IH(A∪B, R) − IH(B, R).The determination of the Vorob’ev threshold β* requires the volumes of β-quantiles:μ(Qβ)=∫Ω1α^N(z)≥βμ(dz)They can be estimated by numerical quadrature, i.e. by computing the values ofα^Non a grid when there are few objectives or relying on Monte Carlo schemes. The other integrations are performed using hypervolume computation procedures and their complexity is related to the difficulty of computing the hypervolume in general. Hence measuring the uncertainty with the Vorob’ev deviation would be possible with any number of objectives but would require approximating integrals to keep the computations affordable. Note that since we take the objectives separately, simulating with more objectives simply requires computing the additional conditional simulations corresponding to those objectives.Remark 2Grunert da Fonseca and Fonseca (2010) proposes the use of the Vorob’ev median (Q0.5) if no compact set is chosen for integration. While removing the problem of fixing the reference point, no equivalent of the Vorob’ev deviation seems available in this case.From a practical point of view, it is also useful for visualization purpose with few objectives to display the superposition of all the symmetric differences by defining an analog of the attainment function:Definition 4Symmetric-deviation functionThe functionδY:z∈Rm0.25em0ex↦0.25em0exP(z∈Qβ*ΔY)is called the symmetric-deviation function ofY.δYis the coverage function ofQβ*ΔY. It is estimated with the empirical symmetric-deviation function:δ^N(z)=1N∑i=1N1{z∈Qβ*ΔYi}.Fig. 5presents an example of a symmetric difference between two sets and an empirical symmetric-deviation function. This shows the variability around the estimated Pareto front: dark areas indicate regions where the estimation of the Pareto front is not known precisely.In this section, we illustrate the benefits of the proposed methodology for estimating Pareto fronts. We consider the following two variable, bi-objective optimization problems from the literature:(P1)The problem presented in Parr (2012), which has a convex Pareto front:f1(x)=(b2−5.14π2b12+5πb1−6)2+10[(1−18π)APTARANORMALcos(b1)+1]f2(x)=−(10.5−b1)(b1+5.5)(b2+0.5)−130(b2−5.14π2b12−6)2−13[(1−18π)APTARANORMALcos(b1)+1]where b1 = 15x1 − 5, b2 = 15x2 and x1, x2 ∈ [0, 1].The ZDT3 problem (Zitzler, Deb, & Thiele, 2000) which has a disconnected Pareto front.For each example, we start with a set of few observations that allow fitting initial Gaussian process models for the two objective functions. Then we add new points sequentially by maximizing the Expected Hypervolume Improvement, based on the formula detailed in Emmerich et al. (2011). At each step, the Gaussian process models are updated and their hyperparameters re-estimated. These models are then used to simulate CPFs, from which we compute the estimates of the Vorob’ev mean and the measures of uncertainty: Vorob’ev deviation and symmetric-deviation function. Since the integration domain varies as points are added, the values are displayed divided by the volume of this integration domain. The following test problems are fast to compute, so it is possible to compare the outcome of the proposed workflow to a reference Pareto front by using the volume of the symmetric difference.The results are presented in Figs. 6 and 7, showing the evolution of the estimated Pareto fronts with the corresponding uncertainty around it. For the problem (P1) the sequence is detailed, demonstrating the strength of the proposed approach for giving insights about the uncertainty on the Pareto front. In particular, the uncertainty measures are helpful for choosing a minimal number of observations for approximating the Pareto front: while 10 initial observations may not be enough (Fig. 6a) regarding the large symmetric-deviation, adding 10 more observations dramatically reduces the uncertainty (Fig. 6c).The conclusions are similar for problem (P2) Fig. 7, where the Pareto front is disconnected, starting this time with 20 observations and sequentially adding ten more observations by Expected Hypervolume Improvement maximization. This example makes clear that the Vorob’ev expectation refers to the area dominated by the Pareto front. When the latter is disconnected, the dominated area’s frontier is horizontal in the corresponding parts. The position of the cuts in the Pareto front depends on the model and simulations, resulting in an higher variation around cuts: a small change in the extent of a peak impacts the beginning of the next one (where the symmetric difference volume depends on the size of the disconnection).One can note that the approximations obtained are dependent on the model accuracy. In Fig. 6a the approximation is clearly too optimistic, due to an underestimation of the range parameters of the used Matérn covariance kernel (ν = 5/2). Similarly, for one objective, the expected value of the minimum would be misleading at the beginning.Finally, we propose the use of the Vorob’ev deviation as a stopping criterion when the Pareto front location is known. An empirical rule could be a threshold on the Vorob’ev deviation (e.g. expected volume of the symmetric difference less than 1% of the integration volume) and detection of stagnation (e.g. under the threshold for several evaluations). On the examples Figs. 6d and 7b, by considering the two last evaluations, the result would have been to stop for problem (P1) and continue for problem (P2). Note that this simple criterion would fail if the estimation of hyperparameters is misleading. A more robust version would be to integrate the uncertainty on the hyperparameters estimation in a full Bayesian framework (Diggle & Ribeiro, 2007). More sophisticated values could also be derived inspired from Wagner et al. (2011).The aforementioned methodology depends on the number and location of simulation points used to obtain the CPFs from the Gaussian process models (cf. Algorithm 1 and first step of Algorithm 2). As a first study, we have compared two sampling strategies: uniform sampling and space-filling sampling relying on a Sobol sequence, again with 2 variables. The objective functions are taken as sample paths of centered Gaussian processes with Matérn covariance kernel (ν = 5/2), with range parameters equal to0.3/3for f1, and0.5/3for f2.We compute the approximation error over the set of non-dominated points obtained from the two sampling strategies. To compare the results with a reference set obtained with an NSGA-II (Deb, Pratap, Agarwal, & Meyarivan, 2002) with archiving, three error indicators are used: hypervolume difference, epsilon and R2 quality indicators (Zitzler et al., 2003). The tests are repeated one hundred times. The results presented in Fig. 8show that space-filling sampling slightly outperforms uniform sampling to get an accurate estimation of the Pareto front. Additional tests performed showed a similar behavior with 3 variables but no difference for 10 variables, where the number of points considered was too small.Here, only the impact of the error introduced by discretizing conditional simulations is studied. Given a few hundred to a few thousands of simulation points, it should remain negligible considering a relatively low number of variables, as is usually the case in application examples up to six variables and six objectives (Svenson, 2011). Alternatively, resorting to approximate spectral simulation methods such as the truncated Karhunen–Loève expansion could be considered.We presented an original methodology to estimate and visualize the uncertainty of Pareto front approximations, based on Gaussian process conditional simulations. More precisely, the attainment function provides an estimation of the probability of dominating a given point in the objective domain. Then, a global uncertainty measure was defined relying on the theory of random sets through the concept of Vorob’ev deviation. It indicates the confidence of the model on the approximation of the attained set. The last tool is a visualization of the region of confidence for two or three objectives. Application on an higher number of objectives would be feasible, requiring the use of Monte Carlo methods for the computation of the various integrals. As illustrated on two bi-objective problems with convex or disconnected Pareto fronts, these measures can also be used as a basis to define stopping criteria in a sequential framework.Further work is needed to analyze the different kinds of uncertainty and biases that may occur when applying the proposed methodology. In addition, techniques for simulating efficiently over more points and updating simulations with new observations (Chevalier, Emery, & Ginsbourger, 2014) should be considered, as well as optimization of simulation points locations with re-interpolation or re-simulation (Oakley, 1999). Another direction for future research includes the integration of the proposed uncertainty estimate in a Stepwise Uncertainty Reduction (SUR) strategy (Chevalier et al., 2013) as an infill criterion.

@&#CONCLUSIONS@&#
