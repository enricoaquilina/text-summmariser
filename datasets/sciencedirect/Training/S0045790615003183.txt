@&#MAIN-TITLE@&#
A performance comparison among different super-resolution techniques

@&#HIGHLIGHTS@&#
Comprehensive survey of super-resolution algorithms.Performance comparison among different super-resolution algorithms.Super-resolution techniques applied to natural images.

@&#KEYPHRASES@&#
Super-resolution,Reconstruction,Learning-based,Example-based,Sparse representation,Interpolation,

@&#ABSTRACT@&#
Improving image resolution by refining hardware is usually expensive and/or time consuming. A critical challenge is to optimally balance the trade-off among image resolution, Signal-to-Noise Ratio (SNR), and acquisition time. Super-resolution (SR), an off-line approach for improving image resolution, is free from these trade-offs. Numerous methodologies such as interpolation, frequency domain, regularization, and learning-based approaches have been developed for SR of natural images. In this paper we provide a survey of the existing SR techniques. Various approaches for obtaining a high resolution image from a single and/or multiple low resolution images are discussed. We also compare the performance of various SR methods in terms of Peak SNR (PSNR) and Structural Similarity (SSIM) index between the super-resolved image and the ground truth image. For each method, the computational time is also reported.

@&#INTRODUCTION@&#
The computerized image resolution enhancement began in 1984 when Tsai and Huang [1] introduced a mathematical method for combining multiple low resolution (LR) images to obtain a single high resolution (HR) image. While initially there was little interest in this technology, over time with much theoretical and practical improvement, the technique led to the development of many tools currently available and was used in different fields such as security surveillance, biomedical applications, remote sensing, object recognition (such as face, finger print, iris, vehicle number plate and text) and video conversion [2,3]. Resolution enhancement is one of the most rapidly growing areas of research in the field of image processing. The term resolution refers to the ability of an imaging instrument in revealing the fine details of an object. The resolution of an imaging device depends on the quality of its optics as well as its recording (sensor) and display components. The spatial resolution of an imaging instrument can be improved by modifying the hardware (sensor) in two ways. The first approach is to increase the pixel numbers. However, this approach has rather limited applications since it decreases the Signal-to-Noise Ratio (SNR) and increases the image acquisition time, and therefore, it is challenging to balance the trade-off between resolution, SNR, and acquisition time [4]. The second approach is to increase the chip size; however, a chip size necessary to capture a HR image would be very expensive [5]. An interesting alternative to both of the aforementioned approaches is to use the super-resolution (SR) techniques. SR is an off-line approach for improving the resolution of an image. SR techniques are broadly divided into multi-frame SR (classic approach) and single-frame SR. In multi-frame SR techniques a set of LR images acquired from the same scene are combined to reconstruct a single HR image. LR images can be taken by the same imaging instrument or with different instruments. The goal is to find the information missing in one LR image in other LR images. By doing so, the information contained in all LR images is pooled to obtain a HR image [5]. Several multi-frame SR techniques have been investigated in medical imaging [4]. In single frame SR technique, the missing high frequency information in the LR image during the acquisition step is estimated from a large number of training set images and added to the LR image [2].In this paper, we present a survey of major SR techniques. Besides this, the MATLAB codes written and published by different groups of researchers were downloaded from their websites and the performance of various SR techniques were compared. The comparisons are made in terms of common image quality metrics such as peak SNR (PSNR) and Structural Similarity (SSIM) discussed in details in Section 5. We also report the execution time of the codes for each method. A number of review papers have also been published in this field [3,5–8]. While some of these papers provide a good overview of SR techniques, only [8] provides a comprehensive performance comparison in terms of image quality metrics. The survey paper [8] has provided the performance comparison in terms of objective quality metrics; however, it is limited to single-frame SR techniques. This paper is different from the previous review papers in that it provides performance comparisons of both single-frame and multi-frame SR techniques. The rest of the paper is organized as follows. Section 2 explains observation model that relates the HR image to the observed LR images. Several multi-frame SR techniques are described in Section 3. The single-frame SR techniques are described in Section 4. The image quality metrics are discussed in Section 5. Section 6 provides comprehensive performance comparisons of various SR techniques with natural images. A detailed discussion of the pros and cons of each technique is presented in Section 7, and the paper is concluded in this section.The observation model describes the way by which the observed LR images have been obtained. It models the parameters that degrade the original HR image to the observed LR images; therefore, it is also termed as forward model. A number of parameters contribute to the reduced image quality. These include: (a) the blur created either by defocus or motion of the camera; (b) sampling an object at a frequency less than the highest frequency contained in the object produces aliasing artifact on the image; (c) the inherent noise of natural images, as all the natural images contain some level of noise. These image degradation factors (i.e., blur, aliasing, and noise) can be incorporated into a mathematical model that relates the HR image to the observed LR image [5]. The schematic diagram of observation model is depicted in Fig. 1.Mathematically, let X be an original image degraded by motion blur (M), camera blur (B), and decimation effect (D). Suppose the image contains white Gaussian noise of standard deviation (η). Therefore, the forward observation model that relates the HR image to the observed LR image is [9]:(1)yk=DBkMkX+ηk;Y=HX+ηwhere k represents the number of LR images. A slightly different amount of blur and motion parameters are used to create different LR images. An example for creating simulated LR images from a HR natural image is described in Section 6. Once the model is known, an inverse process can be used to recover a HR image from a series of LR images. Mathematically speaking, it is an inverse problem that needs prior information from the HR image to find the reliable solution.As we discussed earlier, a HR image is reconstructed either from a single LR image or from a sequence of LR images. There are a number of different approaches for reconstructing a single HR image from LR image(s). This paper includes only the most common reconstruction approaches.Interpolation is the process of estimating new pixels within an image’s given set of pixels. It is one of the simplest ways of improving the resolution of an image. Interpolation methods have proven useful in many practical cases. Most commercial software such as Photoshop, Qimage, PhotoZoom Pro, and Genuine Fractals use interpolation methods to resize an image. The interpolation-based SR methods involve the following three intermediate steps: registration, interpolation, and restoration. Image registration is the process of geometrically aligning a set of LR images of the same scene with reference to one particular LR image called the reference image. LR images have different sub-pixel displacements and rotations from each other; therefore, it is very important to have accurate estimation of motion parameters before fusing them to create a HR image. Inaccurate estimation of motion parameters results in various types of visual artifacts that consequently degrade the quality of the reconstructed image. The registration is performed in either the frequency domain or the spatial domain. The frequency domain approaches for estimating motion parameters are described in more detail in Section 3.2. There are various techniques to estimate motion in the spatial domain as well. Keren et al. [10] proposed an algorithm based on Taylor expansion which estimates the motion parameters with sub-pixel accuracy. Bergen and colleagues [11] proposed a hierarchical framework for estimation of motion models such as planer and affine methods. Irani and Peleg [12] developed an interactive multi-resolution approach for estimating motion parameters. To estimate motion parameters, some algorithms map the whole image while others map only the features that are common among the LR images [13]. The HR image and motion parameters can be simultaneously estimated using Bayesian methods. Hardie et al. [14] explain one such approach. The Bayesian approaches are described in more detail in Section 3.3. Recently a gradient-based motion estimation method has been presented by Botella et al. [15].Besides registration, the interpolation also plays an important role in estimating a HR image. There are many different interpolation methods, yet the complexity of each method depends upon the number of adjacent pixels used to estimate the intermediate pixels. The most commonly used interpolation methods include: Nearest neighbor, bilinear and bicubic methods [16]. Nearest neighbor is the most basic interpolation method that simply selects the closest pixel surrounding the interpolated point. The disadvantage of nearest neighbor is the stair-step shaped linear features visible in the HR image. Bilinear takes a weighted average of the closest 2×2 neighborhood pixels to estimate the value of the unknown interpolated pixel. Similarly, bicubic takes the closest 4×4 neighborhood pixels to estimate the value of the unknown interpolated pixel. In both of the latter methods the closer pixels are given the higher weights [16]. Since the shifts among the LR images are unequal, non-uniform interpolation methods are required to fuse all LR frames into one HR frame. In 1992 Ur and Gross [17] developed a non-uniform interpolation method for a set of spatially translated LR images using generalized multi-channel sampling theorem. There are many other complex interpolation approaches which are used in resizing a single image, such as Cubic B-spline [18], New Edge-Directed Interpolation (NEDI) [19], and Edge-Guided Interpolation (EGI) [20]. In short, the cubic spline fits a piecewise continuous curve, passing through a number of points. This spline consists of weights and these weights are the coefficients on the cubic polynomials. The essential task of the cubic spline interpolation is to calculate the weights used to interpolate the data. NEDI [19] is a covariance-based adaptive directional interpolation method in which the interpolated pixels are estimated from the local covariance coefficients of the LR image based on the geometric duality between the LR covariance and the HR covariance. EGI [20] divides the neighborhood of each pixel into two observation subsets in two orthogonal directions. Each observation subset approximates a missing pixel. The algorithm fused these two approximate values into a more robust estimate by using linear minimum mean square error estimation. Other interpolation methods include Gradient-Based Adaptive (GBA) interpolation [21], Interpolation by Autoregressive model [22]. These complex interpolation methods are very efficient and preserve most of the image information; however, their processing time and computational cost is higher in comparison with the general interpolation methods.The registration, interpolation, and restoration steps in the SR method can be conducted iteratively to achieve a HR image from a sequence of LR images through the Iterative Back Projection (IBP) approach [12]. In this method the HR image is estimated by iteratively minimizing the error between the simulated and observed LR images. This approach is very simple and easy to understand; however, it does not provide a unique solution due to the ill-posed inverse problem. Another easily implementable SR approach is the Projection Onto Convex Set (POCS) approach devised by Stark and Oskoui [23]. In this method, a set of constraints are defined to restrict the space of HR image. The constraint sets are convex and represent certain desirable SR image characteristics such as smoothness, positivity, bounded energy, and reliability. The intersection of these sets represents the space of the permissible solution. Thus, the problem is reduced to finding the intersection of the constraint sets. To find the solution, a projection operator is determined for each convex constraint set. The projection operator projects an initial estimate of the HR image onto the associated constraint set. By iteratively performing this approach, a good solution can be obtained at the surface of intersection of the k convex constraint sets. The algorithm originally did not incorporate the observation noise [23]; therefore, it was subsequently expanded by many other researchers. Tekalp et al. [24] extended the method to incorporate noise. Patti et al. [25] further expanded the algorithm by including space varying blur, non-zero aperture time, non-zero physical dimension of each individual sensor element, sensor noise, and arbitrary sampling lattices.Another popular approach to increase the resolution of an image is the frequency domain approach [1,26,27]. In fact, the first SR technique developed by Tsai and Huang [1] for working on LR satellite images was based on the frequency domain. Many researchers have subsequently expanded this approach to formulate different SR methods. In frequency domain method, the LR images are first transformed into the Discrete Fourier Transform (DFT) domain and the HR image is estimated in this domain. The estimated HR image is then transformed back to the spatial domain.Tsai and Huang [1] assume that the satellite images are similar but globally translated and can be treated as undersampled images of a static and unknown scene. The shift and aliasing parameters are used to devise a set of equations which relate DFT of LR images to the continuous Fourier transform (CFT) of the unknown HR image (Fy=ΦFx; Fyis the DFT of LR image y and Fxis the CFT of HR unknown image x) [7]. The system matrix Φ is constructed from the motion information between LR images. Thus, the SR problem reduced to finding CFT of HR image with the help of DFT of multiple LR images and system matrix. This simplified SR problem is usually solved by using a Least Squares method [6]. The blur and noise during image acquisition were ignored in the study by Tsai and Huang. However, later Kim et al. [28] extended their work by considering additive noise and blurring effect. Correlation method is often used to find motion parameters in the frequency domain. The motion parameters are estimated based on the fact that spatially shifted images in the frequency domain differ only by a phase shift [26,27]. The phase shift between the two images can be obtained from their correlation. Using the phase correlation method both the image rotation and the scale can be converted into horizontal and vertical shifts. To minimize errors due to aliasing, only parts of the discrete Fourier coefficients that are free of aliasing are used [26]. After estimating the registration parameters, the LR images are combined according to the relationship between the aliased discrete Fourier transform coefficients of the observed LR images and the unknown HR image. The data, after fusion, are transformed back to the spatial domain and reconstructed a HR image. The advantage of the frequency domain method is that it is easy to apply and more suitable for removing aliasing than the spatial domain. The disadvantage of the frequency domain is that it is limited to global motion, and therefore it works only for planar shifts and planar rotations [26]. Lately, the Fourier domain is being replaced by Discrete Cosine Transform (DCT) [29] and Discrete Wavelet Transform (DWT) [30].Rhee and Kang [29] modified the Fourier transform based approach to perform regularized deconvolution techniques using DCT. This method works even for the ill-posed cases or cases with insufficient sub-pixel information. DCT uses only real coefficients; therefore, it is computationally less expensive than the Fourier domain. Recently, several researchers have investigated the use of wavelet transform to address the SR problem [30–37]. Nguyen and Milanfar [30] used wavelet interpolation followed by restoration method for SR. They first calculated the wavelet coefficients of LR images and then interpolated them for blurred values at the HR grid points. By deconvolving the interpolated values with the known blur, an estimation of HR image is possible. El-Khamy and colleagues [31] performed the registration of multiple LR images in wavelet domain. Wavelet coefficients were fused and denoised after registration using a regularization method. Interpolation methods were used to get HR wavelet coefficients, and finally an inverse wavelet transform was performed to get the HR image in spatial domain. Chappalli and Bose [32] further implemented soft thresholding techniques to remove the noise associated with the wavelet coefficients. Ji and Fermuller [33,34] used a multi-resolution scheme to decompose the wavelet coefficients into two channels; those coefficients were then upsampled, filtered, and fused to get the simulated image. The super-resolved image was obtained using iterative back-projection method with efficient regularization criteria at each iteration to remove the noise. Li [35] proposed image resolution enhancement by extrapolating high-band wavelet coefficients. Recently, researchers have started to use contourlet transform to address the SR problem [2,38]. The advantage of contourlet transform is that unlike wavelet transform which only captures the horizontal and vertical edges in an image, contourlet transform can catch edges oriented along any arbitrary direction [2].As already discussed in Section 2, SR is an underdetermined problem with many possible solutions. Another interesting approach for solving this ill-posed problem is utilizing a regularization term [39]. The regularization approach incorporates the prior knowledge of the unknown HR image to solve the SR problem. Deterministic and stochastic approaches are two different ways to implement regularization. The deterministic approach introduces regularization term that converts the ill-posed problem to a well-posed one [4]. The HR image X is estimated by minimizing the following cost function,(2)X=argmin∑k=1N∥yk−HkX∥2+λ∥RX∥2where R is the regularization term and λ is regularization constant. The constrained least square regularization method uses smoothness constraints as a priori. In this case R is the high pass filter that minimizes the amount of high frequency content in the reconstructed image. The regularization parameter λ controls the high frequency information. The larger values of λ may over-smooth the reconstructed image which is an appropriate choice if only a small number of LR images are available and/or there is a lot of noise. The smaller values of λ might result noisy solution which is applicable when a large number of LR images are available and the amount of noise is small [6]. The regularized Tikhonov least-square estimator uses l2-norm of the second order derivative of the HR reconstruction as a regularization term [4]. The l2-norm does not guarantee a unique solution. Farsiu et al. [40] exploited an alternative l1-norm minimization for fast and robust SR. Zomet and colleagues [41] described a robust SR method for considering outliers. Kim and Bose [28] proposed a weighted recursive least-square-based algorithm for SR. The weight depends on the prior knowledge of the image; the algorithm assigns higher weights to the LR images with higher SNR. With different weights, the problem simply reduces to the general least square estimate. At last, interpolation and restoration are used to obtain the HR image. Recently, Mallat and Yu [36] proposed a regularization-based SR method which uses adaptive estimators obtained by mixing a family of linear inverse estimators.The stochastic approach [42–57], especially the Maximum A-Posteriori (MAP) approach, is popular because it provides a flexible and convenient way to include an a priori information and builds a strong relationship between the LR images and the unknown HR image. The method proposes to find the MAP estimation of the HR image XMAPfor which a posteriori probability P(X|Y) is a maximum [5].(3)X^MAP=argminXP(X|Y)Using Bayes theorem, the above equation can be written as [5]:(4)X^MAP=argminX[logP(Y|X)]+logP(X)where P(Y|X) is the likelihood function and P(X) is a prior. Markov Random Field (MRF) is commonly used as the prior model and the Probability Density Function (PDF) of noise is calculated to determine the likelihood function. The HR image is computed by solving the optimization problem defined in Eq. (4).Several models such as TV norm [42], l1 norm [43] of horizontal and vertical gradients, Simultaneous Autoregressive (SAR) norm [44], Gaussian MRF model [14,45], the Huber MRF model [46], the discontinuity adaptive MRF model [47], the two-level Gaussian non-stationary model [48], and the Conditional Random Field (CRF) model [49] are used for the prior image model. A special case of MAP where prior information of the HR image is not given is called Maximum Likelihood Estimation (MLE). Tom and Katsaggelos [50] examined the application of MLE for the SR of an image; however, since the solution of the underdetermined system needs a priori information, MLE remains an uncommon method.In the multi-frame SR, multiple images are fused to set a single HR image. While fusing the LR frames, pixel averaging methods are used. These methods blur the image; hence, image restoration methods are also needed to remove the blur [5,6]. Estimation of the blur kernel has an important role in predicting a HR image; however, many SR approaches assume a known blur kernel for simplicity. The known blur kernel can help estimate a HR image from a set of simulated LR images; however, for real LR images, the motion blur and point spread functions may lead to an unknown blur kernel [58]. Many algorithms are proposed in Bayesian framework to estimate the blur kernel. Recently, Liu and Sun [58] proposed a Bayesian approach of simultaneously predicting motion blur, blur kernel, noise level and HR image. The blind deconvolution algorithm has been used when the information about the blur kernel and the noise level are unknown. The blind deconvolution methods recover the blurring function from the degraded LR images and estimate the HR image without any prior knowledge of the blur or the original image [59–65]. Sroubek et al. [59] proposed a multichannel blind deconvolution model for SR, where multiple LR images are combined to get a single HR image by minimizing regularized energy function E(X,h).(5)E(X,h)=argmin∑k=1k∥yk−DHkX∥2+αQ(X)+βR(h)The first term is the fidelity term, and the remaining two are regularization terms. The regularization Q(X) is a smoothing term, while R(h) is the PSF regularization term. The regularization is carried out in both the image and blur domain. Bai and colleagues [62] propose a wavelet approach of blind deconvolution that adaptively selects the parameter of the regularization term. In [63–65] combined blind deconvolution and MAP estimator methods have been used for estimating the blur and HR image, respectively.Although a number of multi-frame SR algorithms have been developed to enhance the resolution of an image, they highly depend on the estimation accuracy of the registration parameters [3]. The registration methods are restricted mostly to the global motion; however, different components in the same scene may have different or complex motion in the real world applications. In such cases, multi-frame SR methods do not give good results. Sometimes, LR images are better than the super-resolved image. Furthermore, the high frequency information lost during the acquisition period cannot be recovered using multi-frame SR approaches. An alternative approach is to use single image based SR algorithms [2].Most of the single image based SR algorithms use learning mechanisms and therefore are called leaning based SR algorithms. The learning mechanism extracts the high frequency information lost during the image acquisition process, from external sources (training set) and integrates this information with the input LR image to achieve a super-resolved image [2]. The training set includes a large number of HR images and their simulated LR version. The performance of the learning-based SR methods highly depends upon the training set data, therefore, the training set images are chosen in a way that they have high frequency information and are similar to the input LR image [2]. Fig. 2shows the flow chart of the learning based SR algorithms. The learning-based SR methods include the following three stages: feature extraction, learning, and reconstruction.In this stage the features of the test image and training set images are extracted separately. First, the images are divided into small patches. The patches are convolved with the filters to create their LR versions. The HR patches and their simulated LR version of the training set are stored as a pair. Now, the features of the training set patches are extracted. Similarly, the features of the test images are also extracted. A number of feature extraction models have been developed by several groups of researchers. For example, in [66–70] a bandpass filter is used to extract the features, while in [71] low and high frequency components of images are used. Similarly, extractions of Gaussian derivatives [72], Gradient derivatives [73], Laplacian pyramid [74], and Steerable pyramid [75] have also been proposed. Many researchers used luminance values as the key features in their work [76–83]. The coefficients of DCT [84], wavelet transform [37,85], contourlet transform [2,38], and Principle Component Analysis (PCA) [86] have also been used as the features in learning-based SR.The features extracted from the input LR patches and training set patches are matched using learning models. Similar to feature extraction models, a number of learning models have been proposed in recent years. The most common learning models are Best Matching [37,38,71,73,75,80], MRF [2,66,72,85], Neighbor Embedding [82,87–89], and Sparse Representation [68–70,76,90–96] models. Other methods such as Content-based Classification and Class-specific Predictors [74], Support Vector Regression [84], Locally Linear Embedding Construction [67], PCA Construction [78], Canonical Correlation Analysis [86], Position-patch Construction [79], and Learning-based Interpolation Method and Deconvolution [77] have also been used. Glasner et al. [83] introduced a unified method for combining both reconstruction-based and learning-based SR. The learning method matches the features of LR patches of the test image with the features of LR patches of training set images. Since the HR and LR patches in training set are in pair; thus, the features of HR patch corresponding to the features of the selected LR patch are chosen for SR. Fig. 3summarizes the various feature extraction and learning models available in the literature.The feature extraction and learning models estimate the HR features for the input LR patch. These features are integrated to the input LR patch to achieve a super-resolved patch. Finally, all super-resolved patches are combined to generate the HR image [2]. A detailed description of learning-based SR methods is shown in Fig. 2.There are many learning-based SR approaches; however, the example-based (EB) SR method proposed by Kim and Kwon [97,98] has outperformed several state-of-the-art algorithms in single image SR. This method is based on the framework of Freeman et al. [66] which collects pairs of LR and HR image patches in the training stage. In the learning stage, each LR patch of the input image is compared to the stored training set LR patches, and using a nearest neighbor search method a nearest LR patch and its corresponding HR pair are selected. However, Freeman et al. [66] approach often results in a blurred image due to the inability of nearest neighbor. Kim and Kwon [97] modified this approach by replacing nearest neighbor search with sparse kernel ridge regression. In their approach, kernel ridge regression is adopted to learn a map from input LR patch to training set’s HR and LR patch pairs. This method however also produces some blurring and ringing effects near the edges which can be removed using post processing techniques [97].Over the last century, there have been extensive studies on sparse representation algorithms. Sparse representation is the approximation of an image/signal with the linear combinations of only a small set of elementary signals called atoms. The atoms are chosen either from a predefined set of functions (analytical-based dictionary) such as Discrete Cosine Transform and Wavelets, or learned from a training set (learning-based dictionary). The main advantage of these algorithms is that the signal representation coefficients are sparse, i.e., they have many zero coefficients and a few nonzero coefficients. To be precise, consider a finite dimensional discrete time signal x ∈ RNand an over-complete dictionaryD∈RN×K; N < K. The aim is to represent signal x using dictionary D such that the signal representation error∥Dα−x∥2, where α is the sparse representation vector, is minimized. The sparse representation of a signal is obtained by solving the following optimization problem [69].(6)argminα∥α∥0subjecttox=Dα,Sparse representation has become a major field of research in signal processing. Utilizing this approach, several researchers have proposed learning-based SR algorithms [68–70,76,90–96]. Sparse representation based SR computes the sparse approximation of input LR patch and uses the coefficients of approximation to estimate a HR patch. In this method, two dictionaries Dhand Dlare jointly trained from HR and LR patches. There is a need to enforce the similarity of sparse coding between the LR (j=Dlβ)and HR patch(l=Dhα). The dictionary extracted from the HR patch Dhis applied with the sparse representation of the LR patch (Dhβ) to recover the super-resolved patch. Zeyde et al. [70] applied K-SVD dictionary learning algorithm for learning HR and LR dictionary-pair which increased the performance of this approach.In sparse representation based approach, the final super-resolved image patch is generated from the combination of sparse coefficients of the LR patch and the HR dictionary; the performance of the method depends on both the sparse coefficients of LR patch and the HR dictionary [99]. Many researchers have proposed new algorithms to better estimate the HR dictionary and sparse coefficients of the LR image. Zhang and colleagues [90] proposed a dual-dictionary learning method that consists of main dictionary learning and residual dictionary learning to recover the main HR and residual HR high frequency information. Additional details can be added to the LR image using the double-channel learning process. Since the final SR image is constructed from the sparse coding coefficients of the LR image and the learned HR dictionary, the performance of the method depends on both the coefficients and the dictionary. Yang et al. [93] reduced the execution time of the sparse representation based SR by learning a neural network model for fast sparse inference and then selectively processing only the visually salient features. Using both the analytical-based and learning-based models, Kanakaraj and Kathiravan [94] improved the dictionary learning method.Dong et al. [95] proposed a clustered based sparse representation model called Adaptive Sparse Domain Selection (ASDS) to improve the dictionary. In this approach, the image patches are gathered into many clusters and a compact subdictionary is learned for each cluster. For each image patch, the best subdictionary can be selected that can reconstruct an image more accurately than a universal dictionary. In another study Dong et al. [96] proposed sparse representation based image interpolation through incorporating the image nonlocal self-similarities to the sparse representation model. The term self-similarity refers to the similarity of image pixel values or structure at different parts of the image. The algorithm included nonlocal autoregressive model as a new fidelity term to the sparse representation model which reduces the coherence between the dictionaries, and consequently makes sparse representation model more effective. Dong and colleagues not only estimated better HR dictionary for each image patch, they also utilized the image nonlocal self-similarity to obtain good estimation of sparse representation coefficients of the LR image. Recently, Dong et al. have proposed two models for extracting sparse coding coefficients from a LR image as close to the original image as possible using nonlocal sparsity constraints. These are the Centralized Sparse Representation (CSR) [91] and the Nonlocally Centralized Sparse Representation (NCSR) models [92].To compare the performance of SR techniques, Peak-SNR (PSNR) and Structural Similarity (SSIM) between the super-resolved image and its original are calculated. The PSNR is calculated from the Mean Square Error (MSE), which is the average error between the original image and the super-resolved image. Given a super-resolvedm×nimageX^(i,j)and its original X(i, j), MSE and PSNR are defined as:(7)MSE=1mn∑i=0m−1∑j=0n−1[X(i,j)−X^(i,j)]2(8)PSNR=20log10(LMSE)The SSIM index computes the similarity between the original and super-resolved images [100]. The SSIM takes into account luminance, contrast, and structural changes between the two images. The SSIM index is defined as:(9)SSIM(x,x^)=(2μxμx^+c1)(2σxx^+c2)(μx2+μx^2+c1)(σx2+σx^2+c2)where μxandμx^are the means and σxandσx^are the standard deviations of the original and super-resolved images,σxx^is the covariance of X andX^, and c1 and c2 are constants. SSIM measures the similarity between the two images. When the super-resolved image is very similar to its original, the value of SSIM approaches to 1.MATLAB software (version R2008a) was used to code and/or to run the programs. The MATLAB codes were downloaded from the websites of respective authors, and the parameters of each method were set according to the values given in their corresponding papers. A computer with the operating system 64bit version of Windows 7, Intel (R) Pentium (R) CPU G620T 2.2GHz processor, and 4GB RAM was used to run the simulations. The screen resolution was 1920×1080. Natural images Barbara, Butterfly, Lena, Parrot and Peppers shown in Fig. 4were reduced to size 180×180 for faster simulations. SR approaches were applied to the simulated LR images. Simulated LR images are viewed as the shifted, rotated and downsampled version of a HR image. Four 90×90pixels LR images were created from these HR images. For each simulation the shift and rotation parameters were generated randomly. The downsample factor was set to 2. The first LR image is the reference LR image which is a downsampled version of the HR image, with the shift and rotation parameters of zero. We used these simulated LR images to recover the original HR image (resolution 180×180) using various SR methods.Frequency domain SR approaches [26] were first examined on the simulated LR images. These images were transformed into Fourier domain, and shift and rotation parameters between the LR and reference images were calculated based on their low-frequency, aliasing part. Shifts were estimated from the central low frequency components in which ten low frequency components were used and the rotations were estimated from a disc of radius 0.8. By incorporating these motion parameters on the simulated LR images, a HR image was reconstructed using cubic interpolation. Besides cubic interpolation, the performances of IBP [12], Robust Regularization [41], and POCS [23] were also examined by measuring the motion parameters in Fourier domain. We employed MATLAB software prepared by Vandewalle et al. [26] to implement these algorithms. For IBP, an upsampled version of the reference LR image was used as an initial estimate of HR image. The upsampling was performed using bicubic interpolation. The IBP created a set of LR images from the initial estimate of HR image using the motion parameters estimated in Fourier domain. The estimate was then updated by iteratively minimizing the error between the simulated LR images and test LR images based on the algorithm developed in [12]. Robust regularization further incorporates a median estimator in the iterative process to achieve better results. We implemented the robust regularization algorithm proposed by Zomet and colleagues [41]. The POCS algorithm [23] which reconstructs a HR image using projection on convex sets was examined only for the planer shift.Similarly, Bayesian SR methods were studied and their robustness on the LR images was tested for various prior models. For simulation we used algorithms and MATLAB software prepared by Villena et al. [44]. Total Variation (TV) [42], l1 norm of the horizontal and vertical gradients [43], and Simultaneous Auto Regressive (SAR) [44] were used as prior models. The motion and rotation parameters for creating LR imagers were generated randomly. The simulated four LR images were used as input. The algorithm utilized hierarchical Bayesian model where the model parameters, registration parameters and HR image were estimated simultaneously from the LR images. Variational approximation was applied to estimate the posterior distributions of the unknowns. The algorithm terminated when either a maximum number of iterations (k=100) or the criterion∥xk−xk−1∥2/∥xk−1∥2<10−4where xkis the kth estimated HR image, was satisfied. The Bayesian methods showed the highest PSNR value compared to the other multi-frame SR methods. However, the TV norm, l1 norm of the horizontal and vertical gradients and SAR norm prior model led to over-smooth non-edge regions of the image. Table 1shows the performance comparison of all of the aforementioned multi-frame SR methods. Figs. 5 and 6show the results of various reconstruction-based SR approaches applied to Lena and Peppers images, respectively.Single image interpolation methods were also studied on natural images. The input LR image was created by direct subsampling of the original image by a factor of 2. The LR image was upscaled to its double size 180×180 using nearest neighbor, bilinear and bicubic interpolations. The interpolated images were compared with the original image. The PSNR and SSIM indices for bicubic method were greater than those of the nearest neighbor and bilinear interpolation. The complex interpolation methods, Cubic Spline [36], NEDI [19], and EGI [20] were also applied to the downsampled LR images. A regularization-based SR with Sparse Maxing Estimators (SME) [36] was also examined. Since noise was not added to the LR image of single image interpolation methods they showed better PSNR and SSIM indices. Table 2compares the objective quality metrics (PSNR and SSIM) of various single image interpolation approaches.We examined EB method proposed by Kim and Kwon [97] on the natural images. We chose this method since it has outperformed many state-of-the-art algorithms and also because it removes blurring and ringing effects near the edges [97]. The input LR images were created by downsampling the original image by a factor of 2. Noise was not added to the downsampled image. The training set was created by randomly selecting HR generic images. The LR training images were obtained by blurring and subsampling HR images. Thus, the training set constituted a set of LR and HR image pairs. The algorithm was performed on image patches. In this method, the input LR patch was first interpolated by a factor of 2 using cubic interpolation. Next, kernel ridge regression was adopted to learn a map from input LR patch to training set image HR and LR patch pairs. The regression provided a set of candidate images. The super-resolved image was obtained by combing through candidate images based on estimated confidences. The artifacts around the edges of the reconstructed image were removed by utilizing image prior regularization term. Better PSNR and SSIM values were noticed in this method.Similarly, sparse representation based SR techniques were examined on the LR image. We extracted 5×5 patches with 1 pixel overlap between adjacent patches from the input image. The HR dictionaries and sparse coefficients were learned from both the training set HR images and LR test image. We used the method and software proposed by Yang et al. [69] to run the simulation. In addition, sparse representation based SR proposed by Zeyde et al. [70] was examined. In this method, LR and HR dictionaries were constructed from the LR and HR image patches, respectively, and learned using K-SVD dictionary learning algorithm. The learned HR dictionary was used to recover the HR patches by combining them with the sparse coefficients of the LR image. ASDS [95], sparse interpolation [96], CSR [91], and the most recent NCSR [92] methods proposed by Dong et al. were also implemented on LR images. The latter two methods introduced the centralized sparsity constraint by exploiting non-local statics. Both the local sparsity and nonlocal sparsity constraints are combined in this approach. The centralized sparse representation approach approximates the sparse coefficients of the LR image as closely as the original HR image does which results in better image reconstruction and hence better PSNR and SSIM indices. Figs. 7 and 8show the results of various single image-based SR approaches applied to Lena and Peppers images, respectively.

@&#CONCLUSIONS@&#
