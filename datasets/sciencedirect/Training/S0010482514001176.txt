@&#MAIN-TITLE@&#
Segmentation of colon tissue sample images using multiple graphics accelerators

@&#HIGHLIGHTS@&#
Our goal is to find all cell nuclei in a HE stained colon tissue image.We develop a GPGPU based data-parallel region growing.We can start more than one process in the same GPU parallel.We can use all CPU cores and more than one GPUs parallel.This method is 6× faster than the sequential algorithm (the accuracy is the same).

@&#KEYPHRASES@&#
Medical image segmentation,Cell nuclei detection,Data parallel algorithm,Distributed algorithm,GPGPU,CUDA,

@&#ABSTRACT@&#
Nowadays, processing medical images is increasingly done through using digital imagery and custom software solutions. The distributed algorithm presented in this paper is used to detect special tissue parts, the nuclei on haematoxylin and eosin stained colon tissue sample images. The main aim of this work is the development of a new data-parallel region growing algorithm that can be implemented even in an environment using multiple video accelerators. This new method has three levels of parallelism: (a) the parallel region growing itself, (b) starting more region growing in the device, and (c) using more than one accelerator. We use the split-and-merge technique based on our already existing data-parallel cell nuclei segmentation algorithm extended with a fast, backtracking-based, non-overlapping cell filter method. This extension does not cause significant degradation of the accuracy; the results are practically the same as those of the original sequential region growing method. However, as expected, using more devices usually means that less time is needed to process the tissue image; in the case of the configuration of one central processing unit and two graphics cards, the average speed-up is about 4–6×. The implemented algorithm has the additional advantage of efficiently processing very large images with high memory requirements.

@&#INTRODUCTION@&#
Nowadays, digital microscopes are becoming increasingly popular among pathologists. The processing of microscopic tissue images and the segmentation of tissue components are now done through digital imagery and special immunodiagnostic software products [1]. These are fast and accurate products and can serve several additional functions, like remote access, archiving [2,3], searching and tagging [4], semi-automatic diagnostics [5–7], registration [8], computer-aided tissue engineering [9], etc. This kind of processing offers a very promising way of using different segmentation techniques with the images received; this way, the different components of the tissues can be separated effectively. Appropriately, precise recognition of the tissue components would provide a safe background for automated status analysis of the examined patients, or at least promote the work of pathologists with this pre-processing.Our work focuses on the segmentation of images containing haematoxylin and eosin (HE) stained colon tissue samples. There are several procedures to identify the main structures in these images and many are based on a reliable cell nuclei detection method. There are several image processing algorithms for this purpose [10–13], but some factors could increase the challenge. The size of the images can easily reach 100MB; therefore, the image processing speed plays an important factor.In this paper, after the presentation of the technical background (related work, evaluation method, etc.), we propose a new cell nuclei segmentation algorithm implemented in a heterogeneous environment. This method uses all the available GPUs of the system for the most computationally intensive tasks (data-parallel cell nuclei segmentation), and all the available CPU cores for the less computationally intensive additional tasks (splitting and merging images, and controlling the GPUs).For comparison, we have to evaluate the accuracy of the different algorithms. We have 39 colon tissue sample images manually annotated by qualified pathologists (we will refer to these as the Gold Standard slides), therefore we can compare the outputs of the algorithms to these results. There are several available evaluation methods for this purpose, but most of them are not suitable for this task, therefore we designed a new methodology. We have to know the exact position and shape of cell nuclei for further diagnosis purposes, therefore the basic object-level comparison methods are not applicable (for example, just compare the number of cell nuclei, etc.); we need a pixel-level comparison method. The widely used confusion matrix gives very clear and easily understandable results, based on the below equation:(1)Accuracy=TP+TNTP+TN+FP+FNwhere•TP: Number of true-positive pixels (the pixel is correctly classified as part of a nucleus in both the reference result set and in the test result set).TN: Number of true-negative pixels (the pixel is correctly classified as not part of a cell nucleus).FP: Number of false-positive pixels (in the test result, the pixel is classified as part of a nucleus, but in the reference result it is not).FN: Number of false-negative pixels (the pixel is incorrectly classified as not part of a cell nucleus).Our specialized measurement number is not based only on the pixel-by-pixel comparison; instead it starts by matching the cell nuclei together in the reference and the test results. One cell nucleus from the reference result set can only have one matching cell nucleus in the test result set and vice versa. After matching the cell nuclei, we can compare the paired elements using the confusion matrix. There are some other improvements: for example, we use some weighting in the case of false-positive and false-negative pixels based on the distance from the nearest valid pixel, which is important for the appropriate results near the borders of the nuclei.The implementation of this evaluation method raises several problems. The pairing of the test-reference nuclei is a very resource-consuming step (in the case of several overlapping nuclei, the number of valid pairings can be billions); therefore we use a backtracking-based method to find the optimal result [14]. In this paper, we will use this evaluation method for every task where we need to check the accuracy of the nuclei detection algorithm (evaluation of algorithms, testing, parameter optimizing, etc.).The main purpose of these algorithms is the same: we have to select the pixels of the sample, which could belong to any nucleus. The first thought would be to use the colours of the pixels for this separation, but in practice, this causes many difficulties. In the case of a specific image, we can achieve good results because we can easily teach the program whether a given colour represents a nucleus pixel or not. However, our experiences show that the colours of the images pre-processed by different labs are significantly different. This problem can be solved with some profile files (one profile for each lab), since we can transform all images into a standardized colour space. However, in practice, it turned out that there are significant differences between results from the same laboratories as well. Even if the same tools and materials are used, a different amount of stain and processing time can cause different colours (in some cases, the nuclei are very strong dark areas, but in the case of some other images, these are significantly less contrasting).There are various automatic threshold based techniques to solve this problem. Several papers deal with segmentations using the K-means procedure [15], which produces very quickly and with impressive results. The main limitation of this method is the insufficient accuracy [16]. Further options are the texture based methods [17] and colour clustering [18]. It is easy to achieve the quick results initially with moderate accuracy, but further development is generally impossible. Nevertheless, it is worth considering these techniques as they are quite flexible in regard to various staining conditions. Therefore, these procedures can be used for fast pre-processing.Region growing is a more sophisticated technique [19]. This is because we can exactly define and fine-tune the iteration steps by choosing an arbitrary fitness function and stopping condition. Both of these may consider the colour of the pixels, the environmental conditions, the size of the increased region, their position, etc. Another important advantage of the region growing approach is that it provides information not only about the individual pixels (whether a given pixel belongs to a cell nucleus or not), but it gives detailed information about the whole cell nuclei objects (the result of the region growing is a list of cell nuclei). This information is essential by itself for the diagnosis (number of nuclei, density of nuclei, etc.), and it is useful for the further segmentation of the image (glands, surface epithelium, etc.).However, region growing has some disadvantages as well. First, the biggest problem is that this method is rather slow. The process is slow to the extent that practical use seems almost impossible, because the segmentation of large images (8192× 8192 pixels size or even greater) containing a moderate number of nuclei may require up to one hour to complete. However, because the process offers good accuracy, it is definitely worth dealing with this drawback, though, we have tried to speed up the process as much as possible (without loss of accuracy). For the implementation, we use the graphics hardware, because it is used in similar projects with good results [20,21].The implemented region growing algorithm iterates the following three steps until one of the stopping conditions is met. Due to space limitations, this paper contains only a brief description of parallel region growing. Detailed introductions can be found in [22].1.It checks the four possible directions in which the contour can be expanded. In case of the first iteration, this means the four neighbours of the starting point (seed point), in the latter iterations the pixels around the lastly accepted contour point (see below). We can check all directions at the same time; therefore, four threads examine the different neighbours, whether they are suitable for further expansion or not.In the next step, all contour points are evaluated to decide the direction in which the region should be expanded. The algorithm evaluates a fitness function for every point. Unfortunately, some parameters of this fitness function change at the insertion of every new point (centre of the region, average intensity of the region, etc.). So, they have to be re-calculated in every iteration for every contour point. However, this is a well parallelizable process; every thread calculates the fitness of a single contour point and all threads execute the same code on a different data. This is an ideal data-parallel task and is executable in the GPGPU (General-Purpose Computing on Graphics Processing Units [23]).At the end of each iteration, the algorithm selects the contour point with the highest fitness value. It can use the “atomicMax” function of the GPGPU to make the threads calculate the highest fitness. This point will expand the region in the next iteration.Data parallel region growing.1:function RegionGrowingseedpoint2:region←{seedpoint};last←seedpoint;best←∅;contour←∅3:while¬StopCondition(region,contour)do4:GetRegionProperties(region,refIregion,refRMAX,refcentre)5:parallel execution where threadIndex in (1,2,3,4)6:ifInsideImage(last+DthreadIndex)then7:new←last+DthreadIndex8:ifnew∉region∪contourandProcessable(new)then9:contour←contour∪new▹Contour expansion10:end if11:end if12:end parallel execution13:Cmax←014:parallel execution where threadIndex in(1,2,…,|contour|)15:CP←contour[threadIndex]16:C←|ICP−Iregion|+α⁎(d(CP,centre)/RMAX)▹Score17:CMAX←AtomicMax(C,CMAX)▹Maximal score race18:end parallel execution19:parallel execution where threadIndex in(1,2,…,|contour|)20:ifC=CMAXthen▹Who wins?21:last←contour[threadIndex]22:end if23:end parallel execution24:region←region∪last▹Expand region25:contour←contourâ§¹last▹Reduct contour26:ifbest=∅orScore(region)>Score(best)then27:best←region▹First or better score28:end if29:end while30:returnbest31:end functionVariables and functions of the pseudocode:•Iregion: The average intensity of the region.RMAX: Maximal radius of the region.centre: Mass centre of the region.D: The 4 directionsD1=(0,1);D2=(1,0);D3=(0,−1);D4=(−1,0).IP: Intensity of pixel P.InsideImage (P): Result is true if P is in the picture.Processable (P): Result is true if P is not part of any other regions.α: Weighting factor.d(a,b): The (Euclidean) distance between points a and b.Score(region): Fitness value of the region (based on size, intensity etc.).StopCondition(region,contour): Checks the stopping conditions of the region growing procedure (size, available points, etc.).As visible in the pseudo code (see Algorithm 1), the number of threads is equal to the size of the contour. This number is usually less than 500; therefore, if we want to utilize the whole processing power of the GPGPU, we need to start more threads. This is possible if we use a higher level of parallelism, and execute more than one region growing at the same time (in separate GPU blocks). The adjacent seed points can cause problems, since the parallelized search of those can result in overlapping cell nuclei, which is unacceptable. Fortunately, the maximum radius of a cell nucleus is known (it is an input parameter of the search procedure, called RMAX). Hence, we can presume that searches started from two or more seed points (where distances between these points are more than4⁎RMAX) can be considered as independent searches and can be launched in a parallelized way. Using this technique, we can use thousands of threads, leading to a very high GPU performance.The results of this new implementation are practically the same as for the original one, therefore the accuracy is the same. We ran several tests in different images using the CPU implementation (Intel Core-i5 2400 processor, with four cores) and the GPU implementation (Gigabyte GTX580, with 480 cores). The third and fourth columns of Table 1show the run-times. These depend heavily on the attributes of the tissue sample image (size, number of nuclei, etc.), therefore it would be better to use a relative measurement unit. The unit we used was that we calculated how long it took relatively to process one pixel of the image. The next two columns show these relative values, and the last column contains the difference between the CPU and the GPU run-times. As can be seen, the data-parallel version is usually two to three times faster than the original one. As it is also visible, the GPU implementation gives better results for large images. When using images of 1024×1024, 2048×2048 and 4096×4096 pixels, the average relative runtimes are 0.0154/0.009/0.008ms/pixel, respectively; meanwhile, the same values with the CPU implementation are 0.025/0.034/0.029ms/pixel, respectively.The region growing algorithm prepared this way has several parameters, and it is very sensitive to the appropriate settings. Fine-tuning of these is as important as the previously mentioned speed increase. We have 27 mutually independent parameters (details of the different pre-processing image filters, maximal contrast length and cell nucleus candidate size, parameters of intensity contrast dimensions, etc.) with predefined target sets, and our aim is to search for a set of parameters that gives the best possible accuracy. Due to the large number of parameters and their reasonably large target set, defining the values manually seems hopeless, so we have developed an evolutionary algorithm to find the optimal values. This evolution-based algorithm was used to successfully determine a set of significantly better parameters than the manually adjusted ones.Briefly, the main attributes of the genetic algorithm used were•Representation of chromosomes: We stored 27 genes inside a chromosome, where every gene actually represents one of the region growing parameters. Every parameter is separately encoded and the functionality of the different genes does not depend on their location inside the chromosome.Initial generation of genetic algorithm: The first generation was generated by randomly generated chromosomes. Some of the parameters naturally have upper and lower bounds (cell nuclei size, cell nuclei radius, cell nuclei circularity, average intensity, etc.). To determine these limits, we have done some statistical analysis on the annotated cell nuclei of the already presented Gold Standard slides. For example, regarding the sizes, 99.5% of the cell nuclei are between 34 and 882 pixels. Based on these results, the actual values of genes were chosen using Gaussian distribution within these intervals. Some of the parameters are downright technical; in these cases we use pure random numbers between the technically feasible intervals.Implementing selection operator: For parent selection, we used the well-known roulette wheel method where every chromosome has a slot that is sized proportionally according to its fitness value, based on Eq. (2) (where Piis the probability of selecting the ith chromosome, Fkis the fitness value for the kth chromosome, and Min(F) is the smallest fitness value for the generation)(2)Pi=Fi−Min(F)∑k(Fk−Min(F))Implementing crossover operation: We used uniform crossover, where we combine whole genes from the previously selected parents. For every gene, a random number determines which parent׳s gene is inherited. Genes from the parent with higher fitness value have a proportionally higher probability of being inherited.Implementing mutation operator: The probability of a mutation is 10%, and the size of the mutation can be small, medium-sized or large (with a 60%, 30% or 10% chance, respectively). The exact values of these mutations cannot be defined in a general form, because the values of the parameters are very different. Therefore every parameter has its own mutation range.To gain maximal performance, it would be better to use more than one graphics card [26]. We have developed two protocols for multi-GPGPU operations. The first is based on the requirement that we need the same result as with the single GPGPU version. This is possible when the main process itself remains unchanged. Only the previously mentioned independent parts are expanded, so that they are processed at the same time by not only one but all GPUs.This raises many problems. Fundamentally, this is because the GPGPUs work in independent memory areas. The trivial solution for this problem would be a full synchronization after every processing step, which makes a full copy between the independent memory areas. The naive implementation works as follows:1.The seed point search algorithm searches for the points from which the region growings can be started.Because the region growings that start from these points are completely independent, they can be distributed in any way among the available GPGPUs.We can start as many blocks in each GPGPU as the number of seed points that the given GPGPU has.All GPGPUs copy the processed memory regions into the global memory. Thanks to the seed point selection, all nuclei currently found are quite far from each other. Therefore, there are not any overlapping areas in the different GPGPUs. Thus, we do not expect any memory transfer conflicts.After each GPGPU is done, they have to wait on each other using a global synchronization.All GPGPUs refresh their private memory region using the data from the global memory.Then, the next iteration can be started.This method is easy to implement; however due to the large number of memory operations, it is expected to be correspondingly much slower than the next version (details can be found in our previous paper [27]).To achieve the fastest possible solution, we have to provide as great independence for the GPGPUs as possible. To this end, another option may be to simply divide the whole image into smaller slices (tiles) and to distribute these between the devices. Once processing is complete, we have to concatenate the results. The well-known name of this procedure is the split-and-merge method [28]. There may be problems near the edges of images, but we can use several techniques to manage the overlaying parts.We should ensure that the region growings started at the edge of the tiles do not affect the results of the region growings started in different GPGPUs. Fortunately, this is easily met because we know the maximum radius of any cell nucleus (RMAX). To determine this value, we can use the annotated cell nuclei of the Gold Standard images. We have done this earlier, in the phase of preparing initial generation for the parameter optimizing genetic algorithm. Based on the processing of 7889 nuclei, we set the value of RMAXto 30 pixels (in fact, there was one larger nucleus, whose radius was 31.9 pixels, but using this parameter value increases the number of false-positive hits, therefore it is better to use the 30 pixels limit).Hence, any two region growings can be started in parallel if the distance between the seed points is at least4⁎RMAX. Therefore we only have to split the entire image into smaller sub-images (as large as acceptable for the GPGPUs) using4⁎RMAXpixels wide overlapping areas. This area will be important later in the merge phase, as this can ensure that no cell nuclei start from non-overlapping areas of one GPGPU that has pixels in the non-overlapping area of another GPGPU.The main steps of the algorithm:1.Division of the whole image based on the previously mentioned overlapping technique and sending these image parts to the GPGPUs.Execution of the original region growing algorithm in all GPGPUs (processing all acceptable seed points).Copying the processed memory areas into the global memory. This is not an independent task for the GPGPUs, because the overlapping areas can contain overlapping cell nuclei (and based on the processing order of the GPGPUs, these overlapping results may be different).Filtering of the cell nuclei candidates. In the next step we have to select some of the remaining nuclei candidates, based on the following rules: (1) there must not be any overlapping nuclei in the result and (2) the accuracy of this result must be the maximal available accuracy.However, this approach promises several advantages. For our purposes, the most important benefit is the expected speed-up of processing. There are no synchronization steps between the GPGPUs. Therefore, all devices can work at their peak power. There are some additional costs (more than one GPGPU process the same overlapping area and the cost of the merge phase); however, these are not significant.Another benefit of this method (and that is the reason why we implement this) is the possibility to process the input image by smaller distinct parts. It is important because the high memory requirement is a huge disadvantage of the region growing. The full sized source images are quite large (more than 200MB by image), and during the processing several copies are needed (modified by some filters). This all leads to the inability to use traditional region growing for these full-sized images. There is not enough memory for the entire image and the copies (especially in the GPGPU memory). Compared to the previous procedure, this method can also be used to solve this problem. As the processing of each of the sub-images is completely independent, these are executable in any order (one-by-one or parallel). As a result, in case of large images and limited resources, region growing is also applicable. For all of these reasons, we have implemented this version of parallel region growing and have done several tests with this application.The method itself consists of two main parts, the division and the merge. In the first step, we have to decompose the whole image into smaller parts (with some overlapping areas), and we can process these through the GPGPUs. In the next step, we have to prepare the final solution by merging the results of the separate smaller images.The split phase contains two steps: the cutting up phase and the cell nuclei detection phase. The CPU processes the cutting up. The input is the whole tissue sample image and the output represents the overlapping parts. This is a simple operation; the only question is the size of the sub-images and the width of the overlapping section.The size of the tiles must be as large as possible. We have some hardware limitations because we have to store about ten copies of the image (several variations of the same image using filters for the seed point search, the region growing, score calculation, etc.). We need fast access to the pixels; therefore, we cannot use a compression method. Hence, we can easily calculate the memory requirements. We did several tests and the 2048×2048 pixels size looks like the best choice. It is not too large, so we can store the images in older graphics cards (with 1GB internal memory or less), but it is large enough for optimal processing (the ratio of the overlapping and the non-overlapping part is ideal). If we use smaller tiles, then we can use more parallel processing units, but in practice, we usually work with input images 8192×8192 pixels, only two GPGPUs, and one CPU. Therefore, the tile size mentioned above is acceptable.The next required parameter is the width of the overlapped area (see Fig. 1). It is worth choosing it as narrow as possible because this will cause less overlapping cell nuclei candidates. We know the maximum radius of a cell nucleus (RMAX=30 pixels) and it is obvious that two region growings that start from at least a4⁎RMAXdistance cannot have any effect on each other. Therefore, we use 120 pixel wide overlapping areas.The CPU creates all the required tiles and save them as separate files (in the future we can optimize this to use memory to memory transfers). The next step is the nuclei detection for all images. For this, we have to distribute the available tiles between the processing units. We have implemented a scheduler based on the common producer–consumer pattern [29]. This pattern is used in order to handle multiple client requests simultaneously. There are two main roles: those that produce data and those that consume the data produced. Data queues are used to communicate between the participants. In the current phase, we have only one producer. But, in the future, we would like to improve the implemented system to create a fully distributed architecture – a dedicated cell nuclei detection cluster (consumers) where the client applications can send the input images (producers).Technically, the implementation goes as follows: after loading the input tissue image, an algorithm starts to partition it into smaller tiles according to the above and puts these slides into a processing queue. In the meantime, several processes are running (one for all GPUs and one for the CPU) and waiting for the input in the queue. Each process gets one task from the queue and runs the already implemented region growing. The scheduler listens to the task completion signals and when each is finished, it starts the next step – the merging of the intermediate results.In the merge phase, we have to merge the intermediate results into the final result. The input is the set of the tiles and lists containing the detected cell nuclei candidates. There can be nuclei in the overlapping area; therefore, we cannot merge the images directly. We have to handle all nuclei as separate objects and make a decision to keep the given nucleus or reject it. The rules of the merge algorithm are the following:1.Processing the non-overlapping regions: We can accept those nuclei whose enlargement did not start from an overlapping area, without any further checks. It is obvious that the distance of the seed points must be at least4⁎RMAXand therefore these nuclei cannot meet in the most unfortunate cases. So these nuclei can be handled as independent from the others. Hence, these are immediately acceptable (see “Type a” and “Type b” in Fig. 1).Processing overlapping regions: We need some further checks in these cases. Usually there are several nuclei which are in the overlapping area but after the nuclei detection these are not overlapped with others from other tiles (see “Type c” in Fig. 1). In these cases, we can simply accept these nuclei. However, we need some additional calculations if there are some nuclei candidates from different tiles overlapping each other (see “Type d” in Fig. 1). If the pixels of these nuclei are perfectly identical (this is the ideal case), then we have to accept one of them and reject the other. Unfortunately, in most cases these nuclei partially overlap each other and in these cases we have to decide which one to accept and which one to reject. This decision is complicated by the fact that in several cases we have not just two but three or more overlapping nuclei. In practice, these nuclei often form a long chain and it is difficult to decide which ones to accept.After that, we have to sort out one set of nuclei from each cluster in which there are not any overlapping cell nuclei and the accuracy of the set is maximal, where the accuracy of the set is the aggregate value of the accuracy of all nuclei in the set (see Fig. 2).We have designed a score function to evaluate the nuclei candidates. The evaluation is based on the size (in pixels), radius, and circularity of the nucleus. To determine the appropriate weighting factors, we do an examination of the size, radius, and circularity of all nuclei in the already presented Gold Standard slides (colon tissue sample images manually annotated by pathologists). We have examined all nuclei in these images and calculated the values of size (Eq. (3)), radius (Eq. (4)) and circularity (Eq. (5)) for each, and have drawn the distribution into 100 equally sized intervals where every interval has the following values:(3)Tsize[i]=numberofnucleiintheithsizeintervalnumberofnuclei(4)Tradius[i]=numberofnucleiintheithradiusintervalnumberofnuclei(5)Tcircularity[i]=numberofnucleiintheithcircularityintervalnumberofnucleiAs expected, these values confirm the Gaussian distribution. We assume that the detected objects are as more like nucleus as many other nuclei exist with similar parameters. Therefore, we calculate this probability according to the following (Eq. (6)) (in the future we will replace this method with a fuzzy [31] based one):(6)Score(X)=Wsize⁎Tsize[Xsize]+Wradius⁎Tradius[Xradius]+Wcircularity⁎Tcircularity[Xcircularity]where•X: Nucleus candidate.Wsize,Wradius,Wcircularity: Weighting factors for size, radius and circularity.Tsize,Tradius,Tcircularity: Density tables for size, radius and circularity.Xsize,Xradius,Xcircularity: Size, radius and circularity of nucleus X.We have developed an algorithm based on the backtracking method [32] to find the best subset of non-overlapping nuclei. The number of subtasks equals the number of cell nuclei candidates in the examined cluster. Every subtask represents the decision that the corresponding nucleus is accepted or rejected. The backtrack search examines all potential solutions quite efficiently, and relies upon these searches to select the combination of nuclei with the largest aggregate accuracy (see Algorithm 2).Algorithm 2Backtracking algorithm for non-overlapping nuclei filtering.1:procedure Backtracking(level, ref R, ref Found, ref OPT)2:i←0▹0 – accept/1 – reject this nucleus3:whilei≤1do4:j←15:while(j<level)and(Rj=0or¬Overlap(NClevel,NCj)do6:j←j+17:end while8:ifj=levelthen▹Acceptable together9:Rlevel←i▹Store this result10:iflevel=Nthen11:if¬FoundorScore(R)>Score(OPT)then12:Found←true▹First or better result13:OPT←R14:end if15:else16:Backtracking(level+1, ref R, ref Found, ref OPT);17:end if18:end if19:i←i+120:end while21:end procedureVariables and functions of the pseudocode:•N: Number of cell nuclei candidates in the given cluster.NCi: The ith cell nucleus candidate.level: Index of the currently examined nucleus candidate (1≤level≤N). Initial value is 1.Overlap(NC1,NC2): Result is true if NC1 and NC2 overlap each other.R: Vector of N integers. Contains the actual solution (Riis 0 if the ith cell nucleus is rejected and it is 1 if the ith cell nucleus is accepted).Found: Becomes true when the algorithm finds the first valid solution. Initial value is false.OPT: Contains the optimal solution (format is the same as the format of R).In the case of overlapping nuclei, the outcome is always the best combination. We merge these sets with the already accepted nuclei and this leads to the final result of the whole merge task.It is worth noting that in the clustering phase, we create several clusters of cell nuclei for further processing. There are not any overlapping cells in two different clusters. Therefore, we can consider these as independent groups. Thus, we can do the non-overlapping cell nuclei selection parallel for each group. It is hard to create a backtracking algorithm for the GPU; therefore, we have only a CPU implementation. However, based on the independence of the clusters, we can use the multi-core capability of the CPU to process more than one cluster at the same time. This can easily decrease the required processing time.Using the split-and-merge method does not always give the same result as the normal sequential region growing, but this does not necessarily mean that it is less accurate. We can use the already mentioned Gold Standard images to check the accuracy. Unfortunately, we do not have any high-resolution annotated samples; therefore, we use smaller images with modified parameters: we set the tile size smaller than the recommended size (1024×1024 pixels instead the suggested 2048×2048 pixels). The widths of the overlapped regions are all the same (120 pixels).In these tests, we use one CPU core to measure the “original accuracy” and one CPU + two GPUs to measure the split-and-merge accuracy. We have used the evaluation method described in our previous paper [16]. The results indicate that the new technique does not cause significant degradation of the accuracy (Table 2).We do not have any large annotated images; therefore, we cannot measure the absolute value of accuracy in these cases. However, we can use the results of the already existing sequential CPU based application (verified by several tests and used by real-world applications for several years). As it is clearly visible in Table 3, the differences between the results are not significant and are usually less than 2%. It is worth noting that this does not mean lower accuracy. Sometimes the multi-GPU algorithm gives better results.It has been noted that the split-and-merge method has only one limitation: we cannot guarantee that the result of this new algorithm will be exactly the same as the original sequential one. However, that posterior tests have good results, the difference is not significant and the speed-up is very impressive.Developing GPGPU codes is usually expensive and unconvincing; it is worth doing only if the GPGPU based application is spectacularly faster. We do several speed tests to check the speed-up and the results are very promising. The details of our runtime measuring method are as follows: we have done five independent tests on the given tissue images (as the standard deviations show the values are reliable). According to real-world conditions, we take into consideration all operations between the start and the end of the algorithm (load image from file, splitting, distribution, region growing, result reporting, merging). We use three devices in different configurations: CPU1 – Core-i5 2400 processor (4 cores, 3.1GHz), GPU1 and GPU2 – Gigabyte GTX580 graphics cards (480 cores). It is hard to compare the speed of two algorithms running on different hardware, especially in this case since the CPU and GPU have drastically different architectures. We choose these two devices because (at the time of purchase) both represent the average quality/cost in their own market.Table 3 also shows the detailed runtimes of the split-and-merge implementation using only CPU. The split part consists of the following: load the image from the hard disk, split it into smaller overlapping tiles, and save these onto the hard disk (most of the elapsed time is required by the file operations). The region growing part is the runtime of the already existing nuclei detection algorithm. The merge part consists of the following steps: loading the region growing result from the hard disk, collecting overlapping nuclei clusters, and finding the optimal subset of non-overlapping nuclei. As it is visible, the required additional time for the splitting and merging does not cause significant increases in the full execution time.We have done some additional examinations, using multiple devices with the split-and-merge method. The tested configurations were as follows: only CPU, only GPU1, CPU + GPU1, GPU1 + GPU2, CPU + GPU1 + GPU2. We have run the image segmentation on 30 images of different resolutions (2048×2048, 4096×4096, and 8192×8192 pixels). The results (see Table 4) are promising. The processing time decreased drastically, and the CPU and the GPUs can work together very efficiently. Sometimes, in the case of 2048×2048 pixel size images, the CPU+GPU1+GPU2 version was slower than the GPU1+GPU2 version. However, this was only caused by some scheduling problems: GPUs are more than twice as fast as the CPU; therefore, until CPU finished the segmentation of Tile1, GPU1 finished with Tile2 and Tile4, GPU2 finished Tile3, and the GPUs have to wait for the CPU.As expected, configuration with more devices usually needs less time to process all the tiles. In the case of the GPUs, the speed-up is quite linear, which is not surprising because all the GPUs can work on the tiles independently. Therefore, these devices can use all of their processing power. This is not exactly true for the CPU, because it is slower than the GPUs. On the other hand, GPGPU implementations cause some load on the CPU too.Our preliminary tests showed that the advantage of the GPU is greater in the case of large images. Therefore, we expect larger tile size to lead to better performance. To demonstrate this, we did some additional tests using different tile sizes (2048×2048 pixels and 4096×4096 pixels) on two full-sized tissue sample images (8192×8192 pixels). The tested configurations were the same as before: only CPU, only GPU1, CPU + GPU1, GPU1 + GPU2, CPU + GPU1 + GPU2. Table 5shows the run-time values for both tile sizes, and the ratio of these values.As can be seen, the CPU implementation was not able to benefit from the larger tile size, and it became even slower. In fact, the CPU code operates at the same speed, but some adverse circumstances degrade its performance. For example, there are a lot of empty areas in these full-sized images, and in the case of large tiles, the CPU has to rescan these areas (in the seed point search phase) more times than in the case of small tiles. Obviously, the GPUs also have to deal with this problem, but the seed point search is very parallelizable, therefore it is extremely fast in the graphics cards.It can also be seen that GPUs need less time to process the whole image using larger tiles. On one hand, larger tiles mean more independently runnable region growing, fewer kernel launches, etc. On the other hand, the merge part is affected, because in the case of large tiles, the ratio of the overlapping areas is smaller. As expected, the GPU implementations are almost twice as fast in these cases. The best configurations are the 2GPU and the CPU+2GPU using the 2048×2048 pixels tile size (as was previously discussed, sometimes the CPU+2GPU version is a bit slower than the 2GPU version due to the unfortunate scheduling, but this is not general).

@&#CONCLUSIONS@&#
