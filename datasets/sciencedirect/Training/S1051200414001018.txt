@&#MAIN-TITLE@&#
Luminance adaptation transform based on brightness functions for LDR image reproduction

@&#HIGHLIGHTS@&#
Luminance adaptation transform is proposed for dynamic rendering of LDR images.Luminance thresholds is estimated based on visual brightness functions.Luminance adaptive visual gamma enhanced the local contrast.We evaluated and adopt a multi-scale method and various color spaces to optimize it.

@&#KEYPHRASES@&#
Retinex,MSR,Tone mapping,Brightness function,

@&#ABSTRACT@&#
Tone mapping algorithms are used for image processing to reduce the dynamic range of an image to be displayed on low dynamic range (LDR) devices. The Retinex, which was developed using multi-scale and luminance-based methods, is one of the tone mapping algorithms for dynamic range compression, color constancy and color rendition. Retinex algorithms still have drawbacks, such as lower contrast and desaturation. This paper proposes a multi-scale luminance adaptation transform (MLAT) based on visual brightness functions for the enhancement of contrast and saturation of rendered images. In addition, the proposed algorithm was used to estimate the minimum and maximum luminance and a visual gamma function for local adapted viewing conditions. MLAT showed enhanced contrast and better color representation than the conventional methods in the objective evaluations (CIEDE200 and VCM).

@&#INTRODUCTION@&#
A real world luminance range is much larger than those of digital cameras and display devices. The luminance of blue sky in the morning and shadows in an interior room is approximately 4600 cd/m2 and less than 10 cd/m2, respectively. The differences in these luminance levels can be recognized by human vision. On the other hand, there are limited dynamic range problems when real scenes are captured from a digital camera and displayed on television and monitors. Fig. 1shows the difference in the visual perception and captured image of a real scene. The digital camera needs to adjust its exposure time or shutter speed to capture the scene with a large dynamic range. Such capturing, however, causes saturation in the dark or light areas as well as changes the color appearance of the scenes. To solve these problems, tone mapping or compression methods for high dynamic range (HDR) image processing have been developed. HDR images are generally represented by different exposure images of the same scene [1] but making an HDR image is difficult when the scenes have a variation in the viewing conditions, such as tilting, shifting and moving objects. Therefore, effective methods that represent an HDR image only using a single LDR image have been developed.Tone mapping algorithms can be divided into two different methods. One is global tone mapping and the other is local tone mapping. Typical global tone mapping algorithms use logarithmic, power-law and sigmoid functions. Global mapping algorithms are spatially invariant methods that map the input pixel value to a display value. This can be applied easily to the global contrast enhancement of the image [2] but it is less effective for images with strong local contrast areas and details. Saturations are shown in the dark or light areas of images and noises are increased in the dark areas. On the other side, local tone mapping algorithms are spatially variant methods. They consider the relationships between the surround pixels and the input pixel value. Therefore, local tone mapping operators can enhance the local contrast and improve detailed visibility.Retinex, which is one of the local tone mapping algorithms, was developed by Land [3] as a model of lightness and color perception of human vision. This algorithm improves the brightness, contrast, sharpness and dynamic range compression of an image by compensating for the variations in illumination. The typical algorithm of Retinex is the center/surround method [4]. The center/surround method calculates the difference between each pixel and the weighted average value of its surrounds. Jobson et al. proposed a single-scale Retinex (SSR), multi-scale Retinex (MSR) and multi-scale Retinex with color restoration (MSRCR) [5]. SSR is based on the center/surround algorithm, which is suitable for gray-scale images. MSR was introduced to improve details rendering but it is unsuitable for color images. MSRCR is an enhanced method for correcting undesired color distortions in MSR [4]. On the other hand, MSRCR uses many parameters to compensate for color distortions and it is difficult to select the optimal value. Retinex in RGB space deals with R, G, and B signals separately, which can cause color artifacts like color shifts and desaturation [6]. Therefore, color space that can distinguish the luminance and chrominance components is needed to preserve the hue and saturation of captured images, such as HSV, YUV, PCA and CIELAB. HSV is often used in the computer graphic applications, YUV has been used in digital television and photographic applications [7]. Principal component analysis (PCA) is a statistical technique that reduces the correlation among the RGB channels of the input image [8,9]. CIELAB is an extension of the XYZ tri-stimulus of the human visual response [10]. These color spaces have the orthogonality among components and are more stable than the RGB color space for Retinex processing. The other problems of Retinex include scattered noise in dark areas and desaturation in bright areas due to the excessive enhancement for each area. Sun et al. [8] proposed a luminance-based MSR (LBMSR) for noise reduction but did not solve the desaturation problem in bright areas.This paper proposes a single-scale luminance adaptation transform (SLAT) to enhance the local contrast and desaturation in bright areas. SLAT has a local tone mapping processing part and a chrominance compensation part. In the local tone mapping processing part, the perceptible minimum and maximum luminance levels and visual gamma values are obtained according to the adaptation luminance level. These values have been formulated from the human visual characteristics. Human vision is adapted to the viewing conditions and is quite sensitive to a change in luminance level [10]. When the luminance changes from dark to bright light, the visual gamma is also changing easily. This variation of human vision can be found in both Stevens' brightness function and Bartleson–Breneman's brightness function [11,12]. The chrominance compensation part is used for the desaturation effect through local tone mapping processing. In addition, this paper proposes a multi-scale luminance adaptation transform (MLAT) to improve the details and color rendition of the image. MLAT has a weighted sum of several SLATs with the different surround images. This paper is organized as follows. Section 2 introduces Retinex-based algorithms. Section 3 provides a brief overview of Stevens' brightness function and Bartleson–Breneman's brightness function. Section 4 explains the proposed SLAT, MLAT, and introduces the local luminance estimation parameters. Section 5 contains the simulation results using the proposed MLAT and conventional methods and the conclusions are given in Section 6.Human visual system recognizes objects by surface reflectance not affected spatial illuminant distribution. The Retinex models eliminate the effect of the non-uniform illuminations. First, the local illumination is estimated from the input image blurred by a Gaussian linear low pass filter. Then, the reflectance is estimated by subtracting the illumination from the input image in log domain. The center/surround method uses the difference between each pixel and a weighted surround image in the logarithm domain. The basic equations of the SSR can be expressed as follows:(1)Ri=logIi(x,y)−log[F(x,y)⁎Ii(x,y)](2)F(x,y)=Ke−(x2+y2)/c2whereRi(x,y)is the Retinex output,Ii(x,y)is the image distribution in the ith spectral band, F is the surround function, and the symbol “⁎” is the convolution operation. c is the Gaussian surround space constant and controls the degree of blurring. If c is smaller, the details is improved but the quality of color rendition is lower. K is selected such that(3)∬F(x,y)dxdy=1The MSR gives a remarkable balance between local and global tonal rendition to the SSR. Three different scales of Gaussian surround represent narrow, medium, and wide surrounds and the weighted sum can provide both increased local contrast and tone rendition. MSR is represented as follows.(4)RMSRi=∑n=1NωnRniwhere N is the number of scales,Rniis the ith component of the nth scale,RMSRiis the ith component of the output of MSR,ωnis the weighting factor.Sun et al. introduced the LBMSR. The LBMSR algorithm was processed in the luminance channel, which is obtained by the PCA. They used the sum of the convolution term to reduce the noise of the image. The LBMSR equation is as follows:(5)RLBMSR=1N[logI(x,y)N−log(∑n=1NFn(x,y)⁎I(x,y))]whereRLBMSRis the output of LBMSR, N is the number of the surround function,Fnis the nth of the surround function that is equal to Eqs. (2)–(3), and I is the luminance channel of the input image.The Retinex-based local process has the dynamic range compression using log-shaped curve. The logarithmic conversion occurs the noise spreading in dark regions and the blurring and desaturation in bright regions. Fig. 2illustrates these artifacts in Retinex-based tone mapping. In bright regions, large signals are extremely compressed by the nonlinear curve and the differences between adjacent pixels are reduced and less contrast appears. Besides, human visual system is sensitive under bright conditions. So, contrast and saturation in bright regions should be enhanced. On contrary, noise is expanded in shadow regions. The details reproduction is an issue mainly in dark and bright regions.There is distinct change for brightness perception under different surround condition. So the assessment of brightness is necessary for more sophisticated control of image toning. The analysis of brightness functions which are formulated through visual experiments is useful and required for tone reproduction.Human vision is strongly dependent on the luminance intensity. Brightness is the attribute of a visual sensation according to which the area appears to emit more or less light [10]. The brightness increases with increasing luminance. On the other hand, the relationship between the luminance and brightness is nonlinear. This can be found in Stevens' brightness function and Bartleson–Breneman's brightness function.Stevens examined the relationship between the brightness and luminance [11]. The experiments were measured by magnitude estimation with one eye dark-adapted and the other light-adapted. As a result of the experiment, the brightness is related to the power function of the target luminance. Eq. (6) shows the brightness function in a simple field:(6)B=k(L−Lo)n,L>Lowhere B is measured in a unit of a psychological scale, called a bril, which is defined as the brightness seen under dark adapted conditions when the target has a luminance of 40 dB (0dB=3.183×10−7cd/m2). L is the luminance, andLois the absolute threshold. k is a proportionality constant and n is the power function exponent. Parameter values of k, n, andLoare given as a function of adaptation luminance levels. In the dark adaptation, k, n, andLoare 10, 0.333, and2.23×10−6[cd/m2] respectively, the function is sharply concave downward around a constantLo, and the change of brightness is perceived from approximately 0.1 bril in Fig. 3. This value can be conceived as brightness threshold for black level.Stevens and Stevens proposed the expression for relationship between brightness and luminance for simple targets, but the global brightness of an image is more complex. For the prediction of brightness in complex fields, Bartleson and Breneman examined the brightness perception in a complex stimulus configuration with luminance variations [12]. They showed that the brightness function in a complex scene does not coincide with Stevens' brightness function (simple power function). The brightness perception is changed by variations in the viewing conditions. The function can be described in a logarithmic form:(7)logB=2.037+0.1401logL−[λexp(δlogL)]where B is the brightness, L is the luminance. λ and δ are varied as a function of the adaptation luminance. Fig. 4shows the values of λ and δ according to adaption luminance.RGB color space has three chrominance channels (red, green, and blue), and each channel has a strong correlation. The separated processing for the R, G and B channels causes color distortion and it needs a color correction. On the other hand, color correction methods can cause color artifacts that exaggerate the color shift, or reduce color saturation. Therefore, another color space is necessary to separate the luminance and chrominance channels. For example, HSV color space is often used in computer vision because it can separate the luminance component (value) and chrominance components (hue and saturation). Fig. 5shows the center/surround SSR method in HSV color space. Only the V channel is used in this Retinex processing because it can reduce the computation time and preserve the hue and saturation of the original image. Fig. 6shows the MSR method in the HSV color space and MSR can enhance the details and color rendition of the image than the SSR. On the other hand, these Retinex-based algorithms increase the noise in dark areas and decrease the contrast and color saturation in bright areas. To solve these problems, this paper proposes a single-scale luminance adaptation transform (SLAT) algorithm. Fig. 7illustrates the SLAT.The SLAT has two main processing steps. One is a local tone mapping in the luminance channel of an image. The other is a chrominance compensation in the chrominance channel. HSV, PCA, YUV and CIELAB color spaces are implemented in SLAT. Each color space has a single luminance channel (Li) and two chrominance channels (Ci).Local tone mapping uses only the luminance channel. The luminance scaling block normalizes the luminance channel up to 100 because the local luminance estimation and tone mapping blocks are designed in the condition of the adaptation luminance under surround luminance, 100 cd/m2. In the case of regional white patches, local adaptation luminance closes to 100 cd/m2. This is a sufficient limitation for indoor situations. The low pass filter (LPF) block makes a surround image (Lan) that supposes the adaptation luminance condition and the local luminance estimation block calculates the luminance parameters, minimum luminance level (Lmin), maximum luminance level (Lmax) and visual gamma (γv) using the surround image.Bartleson and Breneman's brightness function produces the most comprehensive concept of what is required for tone reproduction in complex images. According to their experiments, the effect of a dark surrounding is to make an image appear brighter and to reduce their contrast. Conversely, a light surrounding makes an image appear darker and to have greater contrast [12].Human vision responds to changes or differences in luminance, rather than absolute levels of luminance [13]. The two most important factors of visual contrast are the adaptation luminance and the threshold luminance which are detectable for luminance changes [14]. First, the minimum brightness level is determined using Stevens' brightness function, which shows the threshold of brightness in dark adaptation [11]. The smallest threshold of the brightness change in Stevens' experiment is 0.1 bril. The visual system perceives the brightness change when the difference in the brightness variation extends to approximately 100:1 [15,16]. Therefore, the maximum brightness can be defined as 10 bril, which are 100 times that of 0.1 bril. Next, the variations of the luminance for 0.1 and 10 bril in Bartleson–Breneman's brightness function were calculated. Bartleson–Breneman's function is more useful for brightness analysis than Stevens' function because the images normally have complex scenes. Fig. 8(a) shows Bartleson–Breneman's brightness curves for five adaptation luminance levels. Fig. 8(b) shows the fitted curves at the points of 0.1 and 10 bril for each adaptation luminance. The solid line is the maximum luminance and the dotted line is the minimum luminance for the adaptation luminance. The equations of each line are as follows:(8)Lmin=0.0212+0.0185Lan1.0314(9)Lmax=25.83+30.82Lan0.6753whereLminis the minimum luminance level.Lanis the normalized adaptation luminance, which is derived from the Gaussian low pass image at each pixel location, and the maximum value is 100.Lmaxis the maximum luminance level.Fig. 8(a) shows that the lower adaptation luminance level is, the lower visual gamma and contrast should get. These properties are involved in modeled equations.Another major factor for visualizing scenes is visual gamma. The visual gamma is the tone reproduction gradient in brightness contrast [17]. The tone reproduction gradient shown in Fig. 8(a) illustrates changes in brightness contrast.In this paper, we investigated the visual gamma property for adaption levels of human vision using the variation of brightness contrast proposed by Bartleson–Breneman in complex scenes. The visual contrast ratio of each effective interval for adaption luminance was set to 100:1. The effective interval of Bartleson–Breneman brightness functions are limited to the interval between black level (Lmin) and white level (Lmax) which are estimated in Eqs. (8)–(9). In limited effective interval, the brightness functions represent relative brightness changed by variation of relative luminance. Each curve can be normalized into the range between 0.1 and 10 bril as in Fig. 9and it follows a power law function and each exponent in this power law is the visual gamma. The visual gamma can be estimated from relative Bartelson–Breneman curves. The markers of the right graph of Fig. 9 represent the normalized Bartelson–Breneman data points. These discrete data sets are used to make up the parameters of a visual gamma function for effective luminance range. Solid and dotted lines of right graph of Fig. 9 represent formulated gamma curves using Eq. (10). Fig. 10represents the values of fitted visual gamma.(10)γv=0.444+0.045ln(Lan+0.6034)whereγvis the visual gamma value. This equation is formulated by fitting the curve of Bartleson–Breneman's brightness functions for a simple gamma.Each pixel of the surround image has different luminance parameters according to the adaptation luminance level. In the tone mapping block, the output luminance image are composed as follows:(11)Lo(x,y)=Io_gainf(x,y)+Io_offset(12)f(x,y)=|Ln(x,y)−Lmin(x,y)Lmax(x,y)−Lmin(x,y)|γv(x,y)(13)Io_gain=Rcsfmax−fmin(14)Io_offset=−Rcsfminfmax−fminwhereLois the output image of the luminance channel andLnis the normalized input image of the luminance channel.Lmaxis the maximum luminance level,Lminis the minimum luminance level andγvis the visual gamma function.Rcsis the intensity range of the selected color space,fmaxis the maximum value off(x,y), andfminis the minimum value off(x,y).A canonical gain-offset control is applied to adjust the intensity range of the output image to the luminance of the display. Gain and offset values are adaptive to an image and convertLorange to the intensity range of the selected color space standard. The clipping function removes any extreme bright pixel or dark pixel. The image data from 1st to 99th percentile was used.The result of SLAT causes under-saturation when using other color spaces except for the HSV color space. Therefore, the chrominance channels are compensated as follows.(15)Co=Ci×Lo/LnwhereCoandCiare the output and input values of the chrominance channel, respectively.The rendering quality of SLAT depends on the standard deviation of Gaussian filter which determines the scale and affects the surround image. The narrower filter enhances the details, and the wider filter is superior at a tonal rendition aspect. As the multi-scale related methods, multiple surrounds are necessary for balance between local and global tone rendition in our SLAT. MLAT gives a weighted sum of SLATs using low pass filters of three scales. Fig. 11shows the input image, three surround images and SLAT rendering results. The filter scales of each image are 15, 80, and 250.To increase both the local and global rendering quality, the multi-scale method [5], which has usually been applied to other Retinex models, was adopted. The purpose of the multi-scale method is the combination of different scales of SLAT to provide both details and tonal rendition enhancement. The equation is represented as follows:(16)MLAT=∑n=1NωnSLATnwhere MLAT is the output of a multi-scale luminance adaptation transform, SLAT is the output of the nth single luminance adaptation transform andωnis the nth weighting factor. Fig. 12presents a flowchart of the process.Fig. 13shows the input images that were used to compare the results of the conventional and proposed methods. The conventional methods are MSR, LBMSR, HDR toning in Photoshop CS6, and iCAM06. The HDR toning enhances the image using local adaptation mode that controls Edge Glow, Tone and Detail, and Color options. The iCAM06 is designed for HDR image rendering and incorporates the spatial processing models in the human visual system [20]. The proposed method was evaluated in HSV, PCA, YUV and CIELAB color spaces to compare the results according to the different color spaces. Each method uses three types of Gaussian filters (filter size: 15, 80, and 250) based on MSRCR. The weighting factor (ωn) was 1/3 [5].Figs. 14–17show the representative images of test images. In Fig. 14(a), the image includes the strong different brightness between the color box and under the desk. In Fig. 14(b), the MSR in HSV increases the local contrast and compresses global tone well, but the noise in dark areas is emphasized and the color saturation and contrast in the light box areas are lower. The LBMSR method reduces the noise under the desk in Fig. 14(c) but the color saturation and local contrast in the bright areas are worse than the case of the MSR. Fig. 14(d) is HDR toning in Photoshop CS6 and shows improvement of global contrast but local contrast is lower in the light box area and under the desk. Fig. 14(e) shows the hue shift. Fig. 14(f) confirmed that the proposed method enhances the contrast and color saturation entirely and reduces the noise by as much as the LBMSR. In Fig. 15(a), the image also includes the high contrast between the inside and outside tree. In Fig. 15(b), the global contrast of the image is enhanced but the noises of the tree and grass region are increased. The details of the forest and the ground region are reduced. In Fig. 15(c), the noises in the dark areas are reduced but the details are still low, which causes a week edge around the bright areas. Fig. 15(d) shows a little improvement in the shadow areas of tree. Fig. 15(e) shows the local contrast enhancement of entire areas but it shows hue shift. In Fig. 15(f), the proposed method shows that the global and local contrast increases with a concomitant decrease in noise. Figs. 16 and 17 show the indoor and outdoor scenes. These pictures show strong contrast, such as the inside and outside of the tire in Fig. 16 and above and below the shelves in Fig. 17. In Fig. 16, conventional methods show the noise in the boundary of a child's head and low saturation in the bright areas and child's clothing. In Fig. 17, the noise increased in the dark areas above the shelves and low saturation was observed in the Macbeth ColorCherker below the shelves. A pattern of the chart above the monitor is rarely observed due to image saturation. Through the tests, the proposed method shows the improvements of local contrast, saturation, and details of images.Moreover, we used VCM and CIEDE2000 measurements in order to evaluate the MSLAT and existing methods objectively. The VCM is an internal, primary metric that the VS (Visual Servo of NASA) uses for “smart” control of MSR enhancement [18]. On the other hand, Jobson et al. partners suggested that the VCM can be used to determine the visual quality as a stand-alone external metric in their paper. This paper introduces this metric to evaluate the overall contrast of an image. VCM can be expressed as(17)VCM=100×Rv/RtwhereRvis the number of regions in an arbitrary image that exceeds a specific threshold for regional signal standard deviation, andRtis the total number of regions into which the image has been divided. Therefore a higher VCM score means the image has better contrast. On the other hand, the VCM score increases due to the increased noise in dark areas. Therefore, the area with a low average luminance level fromRtwas excluded.The CIEDE2000 was developed by members of the CIE Technical Committee 1–47. The formula provides an improved procedure for calculating industrial color differences. The CIEDE2000 formula is considerably more sophisticated and computationally involved than its predecessor color difference equations for CIELABΔEab⁎and CIE94ΔE94. The CIEDE2000 color difference formula is based on CIELAB color space and calculates the difference in light, chroma and hue given a pair of color values [19]. Therefore a lower CIEDE2000 score means that given a pair of color values are similar and the equation can be expressed as follows:(18)ΔE00=(ΔL′kLSL)2+(ΔC′kCSC)2+(ΔH′kHSH)2+RT(ΔC′kCSC)(ΔH′kHSH)whereΔE00is the CIEDE2000 color difference,ΔL′is the lightness difference,ΔC′is the chroma difference, andΔH′is the hue difference.kL,kC, andkHare parametric weighting factors of lightness, chroma and hue. The formulae of S andRTwere left out owing to its complexity. On the other hand, there was a huge difference in lightness between the rendered images and original image. Only the hue and chroma difference of the CIEDE2000 color difference were considered as follows:(19)ΔECH00=(ΔC′kCSC)2+(ΔH′kHSH)2+RT(ΔC′kCSC)(ΔH′kHSH)The VCM and CIEDE2000 color difference were used to compare the image quality of MLAT according to the different color spaces. Ten test images in Fig. 13 were used for the comparisons, and the HSV, PCA, YUV and CIELAB color spaces were adopted. Table 1lists the results for each image. The VCM score of the PCA, YUV and CIELAB color spaces were high (the higher score is the better in VCM scoring) and the CIEDE2000 score of the HSV and CIELAB were better than the other color spaces. CIELAB color space showed the best performance in MLAT (a lower score is the better in CIEDE2000 scoring). The conventional methods and proposed method were next compared. The candidate methods were MSR in HSV, MSR in YUV, LBMSR, HDR toning in Photoshop CS6, and iCAM06. The proposed method chosen from the test results was the MLAT in CIELAB, which showed good performance in the VCM and CIEDE2000 scoring. Table 2lists the results of the VCM and CIEDE2000 color difference for each method. The results are expressed graphically in Figs. 18–20. Fig. 18 shows the CIEDE2000 scores of the test images and Fig. 19 shows the VCM scores. Fig. 20 provides an overview of the performance results in terms of CIEDE2000 and VCM. The results show that the MLAT preserves the hue and saturation and improves the contrast of the original images after rendering with the smallest CIEDE2000 and highest VCM of the MLAT scores. Therefore, the superiority of the proposed method can be confirmed.

@&#CONCLUSIONS@&#
Present tone mapping algorithms, such as SSR, MSR, LBMSR, HDR toning, and iCAM06, cause several problems of color distortion, desaturation, sparse details and noises. This paper proposes the luminance adaptation transform using human visual characteristics to improve the problems for the enhancement of the contrast and color saturation of LDR images. In the proposed method, the minimum and maximum luminance and visual gamma were formulated according to the adaptation luminance level to determine the perceivable contrast of the image. Local tone mapping based on these vision parameters enhanced the color saturation, contrast and dynamic range properly. In addition, the multi-scale luminance adaptation transform for a balanced tonal mapping of global and local visuality confirmed the enhanced details and color rendition of the whole image effectively. This method was simulated using the images under a range of viewing conditions and compared with conventional models. The proposed method preserved the hue and saturation and enhanced the local contrast of the images better than the other models. The proposed method can be used in some fields requiring visual improvement of the dynamic range due to the changes in the viewing condition.