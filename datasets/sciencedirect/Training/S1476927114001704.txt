@&#MAIN-TITLE@&#
An improved poly(A) motifs recognition method based on decision level fusion

@&#HIGHLIGHTS@&#
Proposed a novel comparable PCA and SVM based poly(A) motif recognition method.Proposed a novel DS evidence theory based recognition method with higher accuracy.Proposed a novel basic probability assignment method used for DS evidence theory.

@&#KEYPHRASES@&#
Polyadenylation motifs,Support vector machine,Oligo string kernel,Increment of diversity,Evidence theory,

@&#ABSTRACT@&#
Polyadenylation is the process of addition of poly(A) tail to mRNA 3′ ends. Identification of motifs controlling polyadenylation plays an essential role in improving genome annotation accuracy and better understanding of the mechanisms governing gene regulation. The bioinformatics methods used for poly(A) motifs recognition have demonstrated that information extracted from sequences surrounding the candidate motifs can differentiate true motifs from the false ones greatly. However, these methods depend on either domain features or string kernels. To date, methods combining information from different sources have not been found yet. Here, we proposed an improved poly(A) motifs recognition method by combing different sources based on decision level fusion. First of all, two novel prediction methods was proposed based on support vector machine (SVM): one method is achieved by using the domain-specific features and principle component analysis (PCA) method to eliminate the redundancy (PCA–SVM); the other method is based on Oligo string kernel (Oligo-SVM). Then we proposed a novel machine-learning method for poly(A) motif prediction by marrying four poly(A) motifs recognition methods, including two state-of-the-art methods (Random Forest (RF) and HMM-SVM), and two novel proposed methods (PCA–SVM and Oligo-SVM). A decision level information fusion method was employed to combine the decision values of different classifiers by applying the DS evidence theory. We evaluated our method on a comprehensive poly(A) dataset that consists of 14,740 samples on 12 variants of poly(A) motifs and 2750 samples containing none of these motifs. Our method has achieved accuracy up to 86.13%. Compared with the four classifiers, our evidence theory based method reduces the average error rate by about 30%, 27%, 26% and 16%, respectively. The experimental results suggest that the proposed method is more effective for poly(A) motif recognition.

@&#INTRODUCTION@&#
Polyadenylation or Poly(A) is an essential step during pre-mRNA mature process. It contains two main steps: specific endonucleolytic cleavage and subsequent addition of a poly(A) tail to the 3′-end. Recent studies have found that poly(A) tail contributes to many aspects of mRNA, including localization, stability and translation efficiency (Andreassi and Riccio, 2009; Ji et al., 2011). In addition, many human diseases are also linked to the dysregulation of polyadenylation (Ozsolak et al., 2010). Consequently, it is necessary to fully characterize polyadenylation.The polyadenylation signal (PAS) is a kind of hexamer located ∼20nt upstream the cleavage site (Elkon et al., 2013). The PAS is one of the key regulatory elements in Polyadenylation. The canonical PAS consists of AAUAAA motif and its variants with base substitutions in this sequence. Most of these variants have significantly reduced efficiency, except the AUUAAA motif (Beaudoing et al., 2000; Legendre and Gautheret, 2003). The advances of experimental technologies have largely enhanced our ability to understand PAS (Hoque et al., 2013; Ozsolak et al., 2010; Shepard et al., 2011). However, these technologies have the limitation that the cost caused by the specificity of the experiment is expensive. In other words, these technologies could only detect the PAS of one tissue in one experiment. For different tissues or different species, a number of experiments are needed. Thus, computational methods are required as complements for the PAS identification.To date, plenty of PAS data have been identified and analyzed by both experimental and computational methods (Kalkatawi et al., 2012; Lee et al., 2007). Based on these data, a lot of efforts have been made to fulfill the recognition of PASs in human genome, and some computer tools have been developed for the prediction. These tools could be divided into two main groups: one group contains tools using expert-crafted features; the other group contains those tools implemented with string kernels. The tools in the first group include Polyadq (Tabaska and Zhang, 1999), Poly(A) Signal Miner (Liu et al., 2003), Polya_svm(Cheng et al., 2006), PolyApred (Ahmed et al., 2009), POLYAR (Akhtar et al., 2010), Dragon Poly(A) Spotter (Kalkatawi et al., 2012), etc. The extracted features used in these tools include Position Weight Matrix (PWM), k-gram nucleotide acid patterns, nucleotides frequency, thermodynamic and structural features, electron-ion interaction potentials and so on. The classifiers employed by them contain linear discriminant function, quadratic discriminant function, Support Vector Machine (SVM), Artificial Neural Networks (ANNs) and Random Forest (RF), etc. Specifically, Polyadq uses the scores of PWM derived from 100bp downstream sequence of a candidate Poly(A) motif as features, and quadratic discriminated function to represent the PAS. Several tools are developed by using SVM to recognize the Poly(A) sites. Poly(A) Signal Miner uses the k-gram (k=1,2,3) nucleotide acid patterns of 100nt flanking sequence surrounding the candidate Poly(A) signals to construct feature space. Polya_svm uses 15 identified cis-motifs represented by Position-Specific Scoring Matrixes (PSSM) as features. PolyApred uses mixed patterns as features by using different nucleotides frequency of 100nt upstream region combined with frequency of 100nt downstream PAS sequence. These three methods all apply SVM as classifier, which has been used widely in recognition of multiple functional sites (Cui et al., 2013; Lv et al., 2014a,b). A new linear discriminant analysis based tool POLYAR is also proposed for PAS prediction. Dragon Poly(A) Spotter employs two methods from the field of artificial intelligence, e.g. ANNs and RF, to achieve the recognition of the Poly(A) signal based on 274 extracted features. A hybrid model is proposed by employing Principal Component Analysis (PCA) and ANN to improve the performance of Dragon Poly(A) Spotter (Han et al., 2013). The tools in the second group include the spectrum kernel, weighted degree kernel, and HMM kernels, etc. A novel machine-learning method by combining HMM with SVM (denoted as HMM-SVM) is developed for poly(A) motif prediction recently (Xie et al., 2013). The prediction of alternative poly(A) sites based on these methods are also reported recently (Hafez et al., 2013; Zhang et al., 2014).The information fusion method could integrate data from different sources. The method can not only eliminate redundancy but also obtain more accurate result than single source (Zeng et al., 2008). Information fusion technology has recently been applied in many fields (Basir and Yuan, 2007; Jin and Davis, 2005; Xiong and Svensson, 2002; Zeng et al., 2008), and these applications imply that this method could reflect real state and obtain synthetically optimal estimation. However, there is no application in the field of poly(A) motif recognition. Due to the fact that Dempster–Shafer (DS) evidence theory employs the disparity of knowledge and combines cumulative new evidences, the studies and applications of DS evidence theory in decision level fusion have attracted many researchers’ interests (Fabre et al., 2001; Shafer, 1976). However, there are still challenges to integrate information with DS evidence theory, such as how to select the information sources and determine the Basic Probability Assignment (BPA) from evidence.In this paper, we first proposed two poly(A) motif recognition methods, i.e. a novel PCA and SVM (denoted as PCA–SVM) based method and a SVM based method with Oligo kernel (denoted as Oligo-SVM). Then we introduced the decision level information fusion technique into poly(A) motif recognition problem by employing the DS evidence theory. In addition to the two proposed methods, two state-of-the-art methods, i.e. RF and HMM-SVM, were used for decision level information fusion. In this paper, we extended the SVM to yield inputs in the frame of DS theory by calculating the posterior probability in binary classification case (Hastie and Tibshirani, 1998). The flow chart is shown in Fig. 1.The proposed methods were tested on the dataset proposed in Dragon PolyA Spotter (Kalkatawi et al., 2012). The dataset contains 14,740 sequences (7370 positive samples with true poly(A) motifs and 7370 negative ones with false poly(A) motifs) on 12 different variants of human poly(A) motifs (see Table 1for these variants and their respective sizes). For each variant, the numbers of positive sequences and negative sequences are equal. At the same time, each sample is a candidate 6nt poly(A) motif surrounded by 100bp upstream and downstream regions. For the poly(A) sites, however, not all experimentally known poly(A) sites contain, at least, one of these 12 poly(A) motifs (Akhtar et al., 2010). To acquire sequences that contain none of these 12 motifs, the annotation data from polya_DB2 was used (Lee et al., 2007). At first, the sites that are supported by at least 10 Expressed Sequences Tags (ESTs) were selected and sequences of 200bp in length surrounding the mapped sites located at position 101 were extracted. And then the sequences that do not contain any of these 12 motifs in the (−50, 10) regions were chosen. To select non-redundant sequences, the CD-HIT (Fu et al., 2012) tool was employed with default settings. We finally got 1375 positive sequences (denoted as PAS Less) and then we got 1375 negative ones by using the method mentioned before (Akhtar et al., 2010).An independent dataset used for the prediction of poly(A) sites was then constructed to further test the proposed model. The samples in the dataset were acquired from the polya_DB2. Only the sites that were supported by at least 5 ESTs were used and the samples used in the first dataset were eliminated. Finally, 23,813 sequences were acquired and each sample is 400bp in length surrounding the mapped poly(A) site at position 201 in the dataset. Among the positive samples, 22,358 sequences were with at least one PAS within 40bp upstream the poly(A) site. For the negative data, the method mentioned in the first dataset is used, and the same number samples with 400bp in length as the positive ones are obtained. And the number of samples containing PAS at the range (−40, 0) bp upstream the position 201 of the sequences was the same with that of the positive sequences.To evaluate and compare the proposed methods, 5-fold cross-validation was used on each of the 12 datasets. Each dataset was divided into five subsets randomly. Then four of these subsets were used for training and validation, and the remaining one was used for testing in each fold.The parameters for state-of-the-art methods were set by using the cross-validation method mentioned by their authors. Specifically, The parameters for RF models of each dataset were set as in Dragon PolyA Spotter (Kalkatawi et al., 2012). The parameters for HMM-SVM models of each dataset were set as mentioned in (Xie et al., 2013).The two proposed methods were all based on SVM classifier, and the parameters for SVM modeling were set by using grid search method.First, 380 features were generated to construct the original feature space. For each data in this feature space, a vector with 358 features was used to represent it. In addition to the 274 sophisticated domain-specific features used in Dragon PolyA Spotter (Kalkatawi et al., 2012), which includes sequential, structural, statistical, and thermodynamic properties, we added 84 new features including 76 scores from 2-mer PWMs in the upstream and downstream regions of the poly(A) motifs, and 8 increment of diversity (ID) values (Zhang and Luo, 2003) of different k-mers (k=1,2,3,4). All the features were listed in Table S1.To reduce the redundancy information and running time of classifier, the dimension of the data was first reduced. Eight methods were used to reduce the dimensions of the original data to a range (1,100). The chosen dimension reduction methods included PCA, probability PCA (PPCA), Kernel PCA (KPCA), Laplacian Eigenmaps (LE), ISOMAP, Locally Linear Embedding (LLE), Factor Analysis (FA), and Neighborhood preserving embedding (NPE).After that, the classifier with the best prediction performance was selected. The chosen classifiers included Regularized Least-Squares Classification (RLSC) (Rifkin et al., 2003), Mean Square Error classification (MSE) (Duda et al., 2012), k-Nearest Neighbor (KNN), SVM, Naïve Bayes (NB), Back Propagation network (BP), probability neural network (PNN), and RF. The implementation of this method was tested using 5-fold cross-validation. To get the reduced data, the dimension reduction method was first applied on the training data during cross-validation and then the test set subjected to the corresponding method. The best prediction performance of the combination of different dimension reduction methods and classifiers is listed in Table 2.In Table 2, it is shown that the PCA method could get the best average result. Then the performance of different classifiers based on the results of PCA was compared. Among these classifiers, the SVM classifier shows the best performance (Fig. 2). As is shown in Fig. 2, the prediction accuracy of SVM classifier reduces slightly. The prediction realizes the best result at 20 dimensions.A string kernel is a positive definite function that computes similarity between two sequences. The result of the function is then used in SVM to acquire a classifier. Generally, the kernel maps sequences into high-dimensional feature spaces, followed by computing inner products between two feature vectors.First of all, the prediction performance of different string kernels was compared. The string kernels used here include the spectrum (SPE) kernel (Leslie et al., 2002), weighted degree (WD) kernel, weighted degree with position shifts (WDP) kernel (Ratsch et al., 2005), fixed degree (FD) kernel, locality-improved (LI) kernel (Zien et al., 2000), and Oligo kernel (Meinicke et al., 2004). For two sequences x and y (of length L and L′, respectively), the definitions of the kernels (denoted as k(x,y)) are summarized in Table 3, where xt:t+k−1:=xtxt+1···xt+k−1 denotes a subsequences of x that starts at position t and has length k, and I{·} returns 1 if the condition is met, and otherwise 0.The parameters of all the kernels mentioned above were got by using the grid search method. The number of bp to combine for these alternative kernels was searched by using the cross-validation between 3 and 10. The shift values of WDP method and the σ values for Oligo method were also searched at the same range using the 5-fold cross-validation. The receiver operating characteristic (ROC) curves of the six kernels are shown in Fig. 3and Table 4. The performance evaluation indexes employed include sensitivity (SN), specificity (SP), accuracy (ACC), Mathew’s correlation coefficient (MCC), and the area under the ROC curve (AUC). Among the six kernels we compared here, the prediction result based on SVM with Oligo string kernel method could achieve the best results. The classifier with Oligo kernel achieves best result with five of these indexes, except the specificity, which is a bit less than LI kernel and WDP kernel.Four different kinds of classifiers were then used to acquire the prediction result. For the three SVM based methods, i.e. HMM-SVM, our proposed PCA–SVM and Oligo-SVM methods, the probabilistic outputs are described as follows.As the prediction result is only qualitative, the output of SVM cannot be used directly to obtain the posterior probability and it is necessary to get BPAs from the output of the SVM classifier to achieve the decision fusion by applying DS theory. Platt’s probabilistic SVM method (Platt, 1999) was employed in our implementation.For the probability output of Random Forest method, the proportion of the trees was directly used as BPAs. In other words, the probability of a sample labeled as +1 was assigned with the proportion of the trees that predicted the sample as positive, and the probability of a sample labeled as −1 was equal to the proportion of trees which predicted the sample as negative.DS evidence theory (Shafer, 1976) is a statistical-based data fusion algorithm. It combines different information sources to make a higher accuracy. In DS evidence theory, belief function is used as measurement to quantify the confidence of a particular observed event. Conditioning rule is employed by the identification system to integrate new information to provide a representation of the obviousness of the situation.According to the DS evidence theory, in our experiment, the focal elements were the prediction results of four classifiers. The BPA functions we used were the posterior probabilities outputs of the four classifiers. Then DSET method was employed. The belief functions were selected as the combining results, which represented the probabilities that elements must be positive. The poly(A) motif will be predicted as positive, if the output of the belief function was more than 0.5, otherwise, regarded as negative.

@&#CONCLUSIONS@&#
