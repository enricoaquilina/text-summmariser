@&#MAIN-TITLE@&#
Seeding-inspired chemotaxis genetic algorithm for the inference of biological systems

@&#HIGHLIGHTS@&#
A new seeding-inspired chemotaxis genetic algorithm (SCGA) is proposed.SCGA successfully identified a thirty-gene 1800-connection system by only three steps.A good initial start and a restricted search space are not necessary.Seeding-inspired genetic operations largely improve population competition.Winner-chemotaxis-induced population migration overcomes GA’s weakness.

@&#KEYPHRASES@&#
Reverse engineering,S-system modeling,Memetic algorithm,Structure identification,Evolutionary algorithm,

@&#ABSTRACT@&#
A large challenge in the post-genomic era is to obtain the quantitatively dynamic interactive information of the important constitutes of underlying systems. The S-system is a dynamic and structurally rich model that determines the net strength of interactions between genes and/or proteins. Good generation characteristics without the need for prior information have allowed S-systems to become one of the most promising canonical models. Various evolutionary computation technologies have recently been developed for the identification of system parameters and skeletal-network structures. However, the gaps between the truncated and preserved terms remain too small. Additionally, current research methods fail to identify the structures of high dimensional systems (e.g., 30 genes with 1800 connections). Optimization technologies should converge fast and have the ability to adaptively adjust the search. In this study, we propose a seeding-inspired chemotaxis genetic algorithm (SCGA) that can force evolution to adjust the population movement to identify a favorable location. The seeding-inspired training strategy is a method to achieve optimal results with limited resources. SCGA introduces seeding-inspired genetic operations to allow a population to possess competitive power (exploitation and exploration) and a winner-chemotaxis-induced population migration to force a population to repeatedly tumble away from an attractor and swim toward another attractor. SCGA was tested on several canonical biological systems. SCGA not only learned the correct structure within only one to three pruning steps but also ensures pruning safety. The values of the truncated terms were all smaller than 10−14, even for a thirty-gene system.

@&#INTRODUCTION@&#
Recent innovations in high-throughput biological technologies (for example, microarrays) challenge researchers to analyze time series data at a level beyond descriptive interpretations (clusters of genes). The first step is to reconstruct the underlying network architecture from the time series data. Voit (2013) noted that structure identification and parameter estimation are arguably the most difficult steps of biological-system analysis; clearly, the former is more difficult than the latter.Michaelis–Menten (MM) models (Michaelis and Menten, 1913) and S-systems (Savageau, 1976) are two popular nonlinear ordinary-differential-equation (ODE)-based models of biological systems. MM models describe local information of constitutes (proteins or metabolites) as rational functions, which are merged into one comprehensive dynamic model. MM modeling is a bottom–up approach. However, the MM model prototype becomes massive and its parameter estimation requires a large amount of experimental data when several substitutes are involved.S-systems (Savageau, 1976; Voit, 2000) not only capture the dynamic behavior of systems but also direct genetic interactions. Therefore, in this study, we used S-systems as our model prototype to infer the genetic networks of systems. We describe a biological system with n dependent species (variables, denoted by xi, i=1,…, n) and m independent species (denoted by xi, i=n+1,…, n+m) as a set of n coupled time-dependent ODEs. The rate change of the ith species xi(a dependent variable) at time t is the net influx minus the net efflux as shown in Eq. (1). Both fluxes are expressed as power-law functions:(1)x˙i=Vi+−Vi−=αi∏j=1n+mxjgij−βi∏j=1n+mxjhij,i=1…,n,where αi, βiare non-negative parameters that represent the rate constants of synthesis and degradation processes, respectively, and gij, hijare kinetic exponents (kinetic orders) that denote the influence of the xjspecies on the production of the xispecies. The gijand hijparameters determine the structure of a regulatory network and can have either positive (excitatory) or negative (inhibitory) values (excitatory). The ease of generalization of S-systems to large systems has largely increased its popularity (Wu and Wu, 2013).However, as the number of system states increases, the identification of highly coupled nonlinear systems becomes increasingly challenging (e.g., there are 2n(n+m) connections to be identified and 2n(n+m+1) unknown parameters to be estimated for a fully connected n-dimensional system with m independent variables). Three important review articles regarding recent developments in S-system modeling were published. Chou and Voit (2009) noted the challenges for inverse modeling, including data, models, and computational and mathematical problems. Chou and Voit (2013) discussed various optimization algorithms and the respective supporting techniques. Voit (2013) wrote a comprehensive review on biological-system-theory (BST)-based nonlinear canonical models and their related system identification technologies). He also discussed steady-state diagnosis, sensitivity and robustness. Sun et al. (2012) reviewed various metaheuristic technologies for parameter estimation of biological systems with S-system and Petri-net structures. Sun et al. noted important problems and possible research directions in reverse problems.The development of top–down modeling technologies has become a central theme in S-system modeling. Voit et al. decomposed an S-system into n decoupled subsystems, wherein these subsystems interacted with each other through the time course data. Voit et al. used alternating regression and eigenvector optimization to resolve the generated algebraic equations (Chou et al., 2006; Vilela et al., 2008). Kutalik et al. (2007) used Newton flow methods, which started at forty random points to approach to a hypothesized attractor and performed the algorithm again to obtain the optimal parameters. Noman and Iba (2007) introduced Akaike's information criteria (a statistical modeling index) and embedded local-search (LS) procedures (mutating the kinetic orders) into differential evolution (DE) to recall those possible connections that were deleted. Noman and Iba (2008) introduced adaptive-length simplex-crossover-based LS to solve the problems of memetic algorithms (MAs). Liu et al. (2012) estimated the rate constants and kinetic orders independently: the former was estimated through least square methods and the latter was estimated through genetic algorithm (GA)-based pruning strategies. Wang et al. (2010) considered two extreme cases of the flux ratio and derived the respective simplified S-systems to reduce the computational complexity. Wang et al. then determined the ranges and mean values of the parameters of the selected genes to infer exact S-systems. Kimura et al. used a decomposition strategy to resolve the high-dimensionality of a thirty-gene S-system. Kimura et al. (2005) further proposed a co-evolutionary algorithm to compensate for decomposition approach problems. Balsa-Canto et al. (2008) hybridized evolutionary algorithms and multiple shooting approaches. Various variants of differential evolutions and GAs have been widely used (Noman and Iba, 2005; Tsai and Wang, 2005; Wu et al., 2006a,b; Liu and Wang, 2009; Wang and Liu, 2010; Kikuchi et al., 2003; Voit and Almeida, 2004; Ho et al., 2007). Other approaches such as simulated annealing (SA) (Gonzalez et al., 2007), a hybrid of SA and GA (Chen et al., 2010), radial basis functions (Matsubara et al., 2006) and neural networks (Murata et al., 2008) have been proposed to achieve top–down modeling from time series data.However, the gap between redundant connections and true connections for the kinetic-exponent values remains too small to ensure pruning safety (see the pruning ratio in Table 2). Furthermore, current research methods cannot correctly identify weak interactions in a thirty dimensional biological system (30 genes). Both the exploration and the exploitation abilities of the current evolutionary technologies should therefore be significantly improved. Multi-objective memetic algorithms have successfully solved various optimization problems in other fields by introducing local-search methods to improve the performance of global-search methods. (Related literature review and references are in the Supplement file.) Most approaches use evolutionary computation to identify a suitable initial start for local-search learning.In this study, we propose a new optimization algorithm wherein random initial starts are used. The proposed SCGA is, in nature, an MA. SCGA possesses the ability to make a valid escape from a local minimum and then rapidly swim toward another attractor. SCGA was tested with three-, four-, five-, twenty- and thirty-dimensional genetic systems (3, 4, 5, 20 and 30 genes). S-system modeling obtains the net instead of the physical interactive information. S-systems can obtain the net relative interactive strengths of dominate constitutes for such a large system as cancer molecular mechanism (Wu et al., 2013). The search range should not be restricted to [−4, 4]. Therefore, we used a wide search space ([0, 100] for rate constants and [−100, 100] for kinetic orders). Evolutionary algorithms always fail to find global optimums when their learning approaches the boundary of a search space. (Learning always remains at that boundary point.) We allowed the learning to be implemented with a bad initial start to demonstrate the high chemotaxis performance of SCGA. (All parameters were initially set to the neighborhood of 80.)The novel SCGA with various advanced evolution operations is proposed in Section 2. Section 3 describes the performance of SCGA in parameter estimation and structure identification of five canonical biological systems. We successfully identified the structure of a thirty-gene system with 1860 unknown parameters. The truncated connection weights are all smaller than 10−14. The escaping performance and a comparison of the novel algorithm to state-of-the-art GAs and DEs are provided in Section 4. Section 5 summarizes the results of our research and suggests areas for future work.The inference of genetic networks that govern the interactions between species is an exciting challenge. To obtain the optimal solution in a limited time, not only the global-search ability of algorithms but also the convergent speed should be largely improved. The seeding-inspired training strategy is a way to obtain the optimal result with a limited budget: the chosen leaders, who behave as seeds, are not only trained but also responsible for training members such that the ability of members is comparable to that of their leaders. In this study, we mimic the strategy and add a novel aspect: the population is generated from a core individual and a subsequent seeds strategy is used for genetic reproduction, wherein the golden-section-based selection obtains a few diverse individuals (seeds). Additionally, we use two non-diverse stochastic operations for crossover and mutation (mixed inbreeding and backcrossing, and competition-based screen-sifting mutation). Moreover, to significantly improve the escaping ability and take vantage in local reach, we further introduce winner-chemotaxis-induced population migration, wherein the winner moves in a random-switch way (mobility) and in a tumbling way to form a premium population. The in-depth analysis in Section 4 discusses the performances of these operations. The results justify our decision for developing the SCGA algorithm.In short, a population is adaptively generated through a core proliferation operation. Seeding-inspired reproduction, crossover and mutation increase the exploitative and explorative abilities of the algorithm (see Fig. 7). Winner-chemotaxis-induced migration allows the algorithm to repeatedly tumble away from an attractor and swim toward another attractor (see Figs. S3–S5 of the Supplement file.) Random parameters are used in SCGA such that the phenomenon of moving back and forth between two local minima is avoided. We also allow the best-so-far individual pass from operation to operation such that the algorithm will not deviate from the true minimum.Real-value-coded representation of unknown parameters is used in this study such that the small changes in the variables correspond to small changes in the function. An S-system is composed of n coupled differential equations. If learning is based on the decoupled technology (Voit and Savageau, 1982; Varah, 1982), then all of the unknown parameters of the ith differential equation in Eq. (1) are encoded as an individual (a 2(n+m+1) vector):[αi,βi,gil,…gi(n+m),hil,…hi(n+m)]If learning is based on the entire S-system, then the individual is expressed as a 2n(n+m+1) vector. When learning is based on the decoupled technology, the individual vector is [α1,β1,g11,…,g15,h11,…,h15] for identifying the structure ofx˙1=20x3−0.8x5−10x10.5, and the individual vector is [α2, β2, g21,…, g25, h21,…, h25] forx˙2=2x10.5x5−1.44x20.5, wherein four dependent variables and one independent variable are involved (n=4 and m=1). A population is generated by a core proliferation operation. The core individual Icis a greedy point for the parameter estimation but is set to a random point at the neighborhood of zero for structure identification. The core individual is then proliferated to generate other individualsIcpias follows:, (2)Icpi={Ic+r1*(Imin⁡−Ic),r2≤λc,Ic+r1*(Imax⁡−Ic),otherwisewhereλc=|(Ic−Imin⁡)/(Imax⁡−Imin⁡)|, i=2,…,Np, Npdenotes the number of individuals in a population, r1 and r2 are random numbers between 0 and 1, and Imin and Imax are the lower and upper bounds of individuals, respectively. (Each element is zero for Imin and 100 for Imax)Seeding-inspired training strategy can pursue the overall maximum effectiveness on a budget. In this subsection, we describe the method for developing a seeding-inspired reproduction. Only a few individuals are selected as the seeds. The selected seeds (individuals) are trained and will train members such that the performance of the team improves largely. The seed strategy is a three-step operation (seed selection, seeding-inspired training and team generation).Individuals in a population are arranged in descending order according to their fitness values. The best individual is the first individual who has the best fitness (the smallest residual error): Ib=I1. The first n individuals are selected from the population using the golden section method: n=[τ×Np] for a small population (Np<10) and n=[(1−τ)Np] for Np≥10, where τ is a golden section constant and [•] denotes a Gauss mark (floor function, the greatest integer function) (Lin and Lee, 1996).The selected n individuals are further divided into l groups in Eq. (3). n1,n2,…,nlare the respective numbers of the first, the second,…, the lth groups. Fig. 1describes the division. Then, l individuals are chosen as seeds from the l groups. To ensure population diversity, we randomly choose one individual from each group instead of choosing the best l individuals in a population.(3)n1=[τ⋅n],,n2=[τ⋅(n−n1)],n3=[τ⋅(n−n1−n2)],⋮nl=n−n1−n2−…−nl−1.The chosen individuals (seeds) Iis, i=1,…,l take a series of training programs. During the training period, the seeds experience a two-stage adaptive update. In the early stages, everything is sufficiently fresh such that the seeds learn in a random direction. The random walk in Eq. (4) is used to denote the change resulting from wider learning.(4)Iis⟵Iis+r1×d1×(Iis−Ir1)+r2×d2×(Iis−Ir2)where d1 and d2 denote the size of a step (d1=d2=1 for our systems), r1 and r2 are random factors, andIr1andIr2are two randomly selected individuals.After a period of time, the seeds will follow those individuals with good performance, i.e., learning proceeds in the correct direction. The directional update in Eq. (5) indicates that the seeds follow the best three individuals (Ib, Is, and It).(5)Iis⟵Iis+r1×d1×(Ib−Is)+r2×d2×(Ib−It).The seeds are responsible for training individuals such that the ability (fitness) distribution of a new population follows a Gaussian functionN. The number of individuals in a team corresponds to a leader’s ability: a leader with better ability has more members. We introduce a standard-deviation (σ)-based division; for example, if l=4, then only [0.4σNp] individuals (I1s) are trained by the best leader, only [0.8σNp] individuals (I2s) are trained by the best two leaders, only [1.2σNp] individuals (I3s) are trained by the best three leaders, and only [1.6σNp] individuals (I4s) are trained by the best four leaders. To ensure diversity, other individuals are randomly generated from the entire search space. After training, the individuals' ability in a team is assumed to be equivalent to that of their leader: Iij=Iis+N(0, σ).Two children C and D are generated from two randomly selected parents A and B through a two-point crossover. Two of the four individuals are selected as the candidates for further crossover to generate the offspring E and F. The selection is based on the backcrossing probability rband the average relative coefficient fav (Wu and Wu, 2013; Wu et al., 2012): the selected candidates are C and D (close inbreeding, the mating of sisters and brothers) for rb≥fav,max (the maximum of fav). The candidates are B and C for rb≥fav,min (the minimum of fav) or A and D for rbbounded by these two extremes. Fig. 2describes the real-coded mixed crossover that is modified from the binary crossover in our previous paper (Wu et al., 2012). Fig. 3describes the selection.We here introduce a competition-based screen-sifting mutation, which is a real-coded operation modified from our previous paper (Wu and Wu, 2013; Wu et al., 2012). This operation generates the fine offspring or the offspring that distribute over a wide portion of the entire space.Inherent premature convergence and slow mountain climbing are two weaknesses of real-coding GAs. We further introduce population mobility and population emigration to avoid the former weakness and a winner-swimming operation to compensate for the latter weakness. A winner-takes-all strategy is used in this section. The population migrates over time because of the chemokinesis (mobility) and chemotaxis (tumble and swim) behavior of the winner.The bacterial chemokinesis movement is introduced to describe that the winner moves in a random-switch way. The winner Ibtakes several steps (ℓ' steps) to generate ℓ' individualsIbmi, i=1,…,ℓ': (The lower index bm denotes these individuals are generated from the mobility of the best individual.), (6)Ibmi={Ib+α(i)⋅ν⋅u,rand⁡(0,1)>0.5,Ib−α(i)⋅ν⋅u,otherwise,where u is the unit vector of Ib, ν is the size of a mobile-step and α(i) is a contraction factor. After the ℓ'-step mobility, the winner is updated once the generated individuals are better than the winner.We here introduce fuzzy-based population diversity (Wu et al., 2012),(7),η=|P˜α||U|where |U| is the number of elements under consideration and the cardinality|P˜α|denotes the number of individuals who are sufficiently far away from the best individual. Population emigration starts when the diversity η is smaller the threshold. The chemotaxis movement of an E. coli cell is adopted for the emigration operation. After the lth-step tumble movement, l new individuals are generated as follows:(8)Ibi=Ib+c(i)·⌊Δ(i)ΔT(i)Δ(i)⌋,i=1,2,…,lwhere с(i) is the size of the ith tumble step taken in a random direction and Δ(i) is a vector in a random direction. Thus, we have an augmented population P+with Np+l individuals (I1, …,INp, ,…,Ibl). The best Npindividuals are chosen from this augmented population to form a premium population, i.e., population emigration is induced by the tumble movement of the best individual. The winner-induced emigration continues to proceed until the tumble-threshold Ntumble or a valid escape is achieved.After the population emigration, the new winner will swim toward another attractor along the local-search direction, such as in quasi-Newton methods (variable metric methods that interpret the Hessian matrix as the changing rate of the gradients.) (Jang et al., 1997). The local-search approach has two responsibilities: to obtain a core point for an arbitrary initial state and to swim toward a new attractor when a valid escape is achieved. A valid escape is ensured by advanced genetic evolution (crossover and mutation) and winner-induced population migrations (mobility and tumble).SCGA was tested with several canonical biological systems: a four-gene genetic branch pathway (Voit and Almeida, 2004), a three-gene cascade pathway (Tsai and Wang, 2005), a five-gene small-scale genetic network (Kikuchi et al., 2003; Hlavacek and Savageau, 1996), a twenty-gene genetic network (Noman and Iba, 2006) and a thirty-gene genetic network (Kimura et al., 2005). Because of space limitations, the detailed descriptions of these systems are included in the Supplement file. A complete flowchart of SCGA for the estimation of unknown parameters in an S-type biological system is illustrated in Fig. 4. In short, SCGA is first attracted to a core (local minimum) through a local search. Then, SCGA escapes and tumbles away from this point through various exploration operations. Finally, SCGA swims toward an attractor through another local search. This type of chemotaxis movement continues until a global optimum is achieved.The cubic spline technology was used to generate the smooth evolution profiles of the data. The decoupled technology (Voit and Savageau, 1982; Varah, 1982) was used to generate the initial values for learning in a coupled S-system. We set the counter parameter K in Fig. 4 to be less than the NSCGA parameter. During the entire learning process, we observed that no stagnation occurred (see Figs. S3–S5 of the Supplement file), which implies that SCGA can escape from a local minimum each time. In this case, the value of NSCGA indicates the number of valid escapes. We here set NSCGA=100; we suggest using a larger value for large systems (for example, hundreds of genes).In an S-system, the unknown parameters of each equation are rate constants (only two) and kinetic orders (2(n+m+1) for structure identification and at most 2(n+m+1) for parameter estimation). For parameter estimation, the learning aims to obtain the optimal parameters such that the predictive state values fit the data. The performance is defined as the weighted mean-square error (an unfitness index) in Eq. (9), which shows the deviation of the estimated values from the data. Fso=0 for the case of perfect learning.(9)Fso=1nQ∑k=1Q∑i=1nta((xik−xi,exp⁡k)max⁡(xi,exp⁡k))2where tais a time-weighting factor, n and Q are the numbers of the species and the sampled data points, respectively;xi,exp⁡kandxi⁡kare the artificially experimental data and the estimated values of the ith species, respectively; andxi,exp⁡kis the maximum of the artificial data. Because of space limitations, the simulation results of these five systems are provided in Tables S1–S5 of the Supplement file. Row “True” in these tables lists the true parameters, and Row “Simulation” lists the estimated parameters. Learning starts at a poor random point in a wide search space. We observe that the estimated parameters are nearly identical to the respective true values. In the branch pathway system, the estimated parameters related to the rate change of the x3species are (α3,β3,g32,h33,h34)=(2.9998836, 4.9998884, 0.75001738, 0.50001115, 0.20000684) which are close to the true values (3, 5, 0.75, 0.5, 0.2). Table 1lists the data and estimated unfitness of these five systems. The largest unfitness is 2.5237847×10−8.For structure identification, the learning aims not only to obtain the optimal parameters but also infer a sparsely connected structure. Therefore, structure identification is a multi-objective optimization problem. Because a genetic network is sparsely connected (Thieffry et al., 1998), researchers have introduced the concentration error, slope error (Wu et al., 2012) and skeletal-structure penalty (Kikuchi et al., 2003) as pruning (penalty) terms. Wang et al. usedϵ−constrain to integrate these three penalties (Liu and Wang, 2008; Ko et al., 2009). Kimura et al. sorted kinetic orders in a descending order and allowed the penalty to act only on specific genes that are regulated by many genes (Kimura et al., 2005). Norman and Iba (2005) separated the penalty term into two terms to differentiate between excitatory and inhibitory effects [17]. All researchers face a real challenge in setting suitable weighting factors (Chou and Voit, 2009). Although a significant amount of effort has been exerted to solve this problem, a safe pruning action is not guaranteed. (The pruning ratios, which are listed in Table 2, are not small compared with the preserved terms.) In our previous paper (Wu et al., 2012), we examined the performance of twenty eight indexes and identified the concentration-error Jeand slope-error penalties Jdto perform well. We normalized the concentration errorJe_=Je/Jee, the slope errorJd_=Jd/Jdeand the skeletal-structure penalty Jobecause these three were on different scales. (Jee, Jde, and Joeare the expected concentration error, slope error and interaction measure (Wu et al., 2012). S-system identification is for Jeand Jdto approach zero and simultaneously obtain a nonzero minimum value of Jo. More precisely, the identification of the structure involves obtaining the minimum value of Jounder an allowable Jdand Je. We previously considered uncertainty and noise as two serious problems in a biological system. Thus, fuzzy relations and fuzzy functions were introduced to describe the dynamic behavior of the sub-process modules in Fig. S1, as shown in the Supplement file. After fuzzy-composition operations, we proposed the fuzzy-based self-interactive index to reconstruct biological networks from time series data (Wu et al., 2012):Jrec=max⁡{ηIIJd_,wIJd_,Jo}whereηII=wII×μ,μis an adaptive dynamic factor and wI, wII are weighting factors (wI=wII=1 for most systems). Fig. S2, as shown in the Supplement files, illustrates the logic flow of SCGA-embedded skeletal-network structure identification.Four biological systems (the genetic branch pathway, the cascade pathway, and the five-gene and thirty-gene genetic networks) were used to examine the performance of SCGA in structure identification. Learning was based on the super structure of an S-system with 2n(n+m) unidentified connections. The thirty-gene system has 1800 connections to be identified, wherein 1732 connections are redundant. Kimura et al.(Kimura et al., 2005) indicated that the correct inference of weak interactions is difficult. These researchers failed to infer interactions corresponding to g1,14, g24,18 and g26,28. Liu and Wang (2008) also failed to identify the connection structures of genes 8, 11, 24, 26 and 27.The correlations between genes are provided in the kinetic orders of the identified S-system. No correlation exists between genes i and j for the case that the estimated kinetic orders gij=0, hij=0 (The j gene is not associated with the production of the i gene.) and gji=0, hji=0. (The i gene is not associated with the production of the j gene.) Table 2 lists the assumptions, the number of data sets and the pruning thresholds that were used by the current research methods. Liu and Wang used the least amount of data sets (8 sets). The largest range used by these methods is [0,20] for rate constants and [−4, 4] for kinetic orders. These researchers also made the assumption: gii=0 and hii>0, which was not made in this study. Further, we do not need to do any data preprocessing for obtaining the rough correlations between genes. The kinetic order denotes the net interactive strength between two constitutes. If S-system models are used to describe the local dynamic behavior of biological systems, then the kinetic orders denote direct (explicit) interactions. The values of the kinetic orders are between 4 and −4. If the model describes the dynamic behavior of the dominant constituents of a large system, then the kinetic orders show net (explicit and implicit) interactions. Therefore, we allowed the kinetic-exponent values be in the range of [−100, 100] to denote that no prior information is available. All parameters were initialized at an undesirable point (the neighborhood of 80). The range of rate constants was [0, 100].We used the same data set for the structure and parameter identification of a genetic branch pathway, a cascade pathway and a small-scale genetic network. Tables 3–5, present the results that were obtained using our method for the identification of these three systems, respectively. Step 0 in these tables describes the true S-system. For example, the first row of Step 0 in Table 3 describesx˙1=20x3−0.8x5−10x10.5,wherein those empty boxes denote redundant connections (g12=0, the effect of x2 on the production of x1 is zero). Steps 1–4 show the identified results, with redundant connections underlined. For the branch pathway network (Table 3), the largest absolute value of the kinetic orders of the identified thirty redundant connections was 2.8860806×10−15 and that of the smallest preserved term was 1.9133848×10−1. A large gap exists between these two values. The estimated rate change isx˙1=20.000721x3−0.79995985x50.99994663−10.000665x1049996819,which is close to the true one. Similarly large gaps are observed in Table 4 (the gap between 4.8136050×10−2 and 1.3555906×10−15) and Table 5 (the gap between 1.4535674×10−2 and 7.5365436×10−15). The estimated optimal parameters, which are shown in the final step of these tables, are nearly identical to the true parameters (Step 0).For the thirty-gene system, which was analyzed to demonstrate the high performance of SCGA, the sample time was set to 0.1 (two-fold larger than the time that was set for the parameter estimation), and the data set size was reduced to one quarter of that used in the parameter estimation (eight sets of experimental data sampled from t=0 to t=5 with a sample time of 0.1). There are 1732 redundant connections to be identified from 1800 connections. We successfully identified all connections and the estimated parameters were nearly identical to the true ones. Because of space limitations, Table 6lists only the inferred interaction results for genes 24 and 26; the structure of both genes has not yet been correctly identified. For the 24 gene, there are 60 connections to be identified (including four true connections and fifty six redundant connections, denoted by g24,iand h24,i, i=1,…,30). The rate changex˙24=x15−0.2x18−0.1x190.3−x24.In the first run (results are provided in Step 1 of Table 6), 33 redundant connections (underlined, the absolute values of the kinetic orders are less than or equal to 1.2408360×10−16) and 27 possible connections (the absolute values of the kinetic orders are more than or equal to 2.1262455×10−4) were identified. We truncated those redundant connections and started the second run. In the second run, we identified 22 redundant connections (with absolute values less than or equal to 2.6325758×10−16) and 9 possible connections (with absolute values more than or equal to 4.0227974×10−3). In the third run, the last redundant connection was identified (a large gap between 9.8686301×10−2 and 3.5181933×10−17). The optimal parameters are given in Step 4. We obtainedx˙24=0.99974267x15−0.20011074x18−0.09987203x190.2998789−0.99973974x241.0001312.The complete results for this system are provided in Table S6 of the Supplement file.An obvious value gap exists between redundant and possible interactions for all of these systems. We subtracted the redundant interactions, which are underlined. The microarray data are always displayed in the log scale (log 2-scale). In some biological systems, the weak connections cannot be neglected, even the connection weights are down to 0.001 (−3 in log scale). A ratio of 3 to 5 denotes a much larger distance in the engineering field. To ensure safe pruning, the weights of redundant connections are 10−9 to 10−15 (−9 to −15 in log scale). Therefore, we truncated those connections with weights smaller than 10−14 to ensure the safeness of the pruning action. The pruned structure was further modified to obtain a more accurate result. All of the inferred structures are identical to the true structures, as shown in Step 0 of these tables. All of the parameter values are also nearly identical to those of the true systems. The simulation results demonstrate that only one- to three-step pruning actions were required for the identification of the thirty-gene system.To further realize the identified condition of each step, Tables 7–10list the number of connections, the number of redundant connections, the number of identified redundant connections of each step and the respective up-to-date identified percentage. Correct structures are obtained after one pruning step for three-gene and four-gene systems, as shown in Tables 7 and 8. Tables 9 and 10 summarize the identified conditions of each step for five-gene and thirty-gene systems, respectively. We observe that approximately 88% redundant connections were identified in the first step for these two systems. After two pruning steps, approximately 95% redundant connections were correctly identified.A wide search space ([0, 100] for rate constants and [−100, 100] for kinetic orders) was used to demonstrate the high escaping performance of this method. Significantly bad and general initial values were used for the comparison of this method with others, i.e., the values of the rate constants and the kinetic orders were set to the neighborhoods of 80 and 0, respectively. The plots of the unfitness with respect to the learning time (expressed by the counter parameter K in Fig. 4) for these five systems are shown in Figs. S3–S5 of the Supplement file. We drew one subplot for one gene such that the escaping conditions are clear. All results in Figs. S3–S5 demonstrate that the phenomenon of rapid swimming toward an attractor and the subsequent escape from the attractor is obvious in the solution of these five systems. Thus, we conclude that SCGA possesses two strong points. First, a good initial start is not necessary; we are not afraid of getting stuck in a local minimum because SCGA can escape from it. Second, a restricted search space is also not necessary because the algorithm can jump from one point to a distant point even in a wide space.Table 2 compares the data sets, assumptions, search spaces and pruning thresholds of SCGA with those of other methods. We further define the pruning ratio ρ as the ratio of the smallest preserved term to the pruning threshold. In SCGA, ρ=3.27×109 ensures that the pruning action is safe. In addition to mutation and crossover, SCGA introduces winner-induced population mobility and emigration to escape from local minima. A winner-swimming operation was used to accelerate the convergence. To demonstrate the global-search power of the algorithm, a bad random initial start with a very wide range was used.Figs. S6 and S7, as shown in the Supplement file, compare the convergence (speed) of SCGA with that of differential evolution (DE), hybrid differential evolution (HDE) (Tsai and Wang, 2005; Liu and Wang, 2009; Wang and Liu, 2010), simplex GA (SPXGA) (Kikuchi et al., 2003), intelligent GA (IGA) (Ho et al., 2007), and improved GA (GA+) (Wu et al., 2006a). HDE and GA+ possess migration and acceleration operations. IGA adaptively divides two parents into n pairs of parameter groups in which the orthogonal experimental design provides systematic reasoning. SPXGA uses gradual optimization strategy and simplex crossover. The simplex crossover (SPX) is an extension of the general BLX-α crossover, wherein the expand operator of the simplex search is introduced. (For a three-parent SPX, three individuals are randomly selected from the population as the parents. These parents Pi,i=1,…,3 form a simplex. This simplex is expanded in the direction of Pi−G, i=1,…,3 by a factor. G is the center of mass. Three offspring are generated by uniformly picking up three vectors from the expanded simplex (Kikuchi et al., 2003).) The three-, four- and five-gene systems with a wide search space ([0, 100] for rate constants and [−100, 100] for kinetic orders) and a bad initial start (80-neighbhorhood for all parameters) were used to obtain the results shown in Fig. S6. The five-, twenty- and thirty-gene systems with the same search regions and initial starting values as those that were used in a previous study (Ho et al., 2007) were used to obtain the results shown in Fig. S7; in this case, a nearby-midpoint initial value was used, and the search range was [0, 15] for the rate constants and [−3, 3] for the kinetic orders. We observe that SCGA converges much faster than these GA and DE variants.Table 11provides the comparison of the accuracy of SCGA with that of HDE (Tsai and Wang, 2005; Liu and Wang, 2008), SPXGA (Kikuchi et al., 2003), CCA (cooperative co-evolutionary algorithm) (Kimura et al., 2005), DE (Noman and Iba, 2005), IGA (Ho et al., 2007), SA (Gonzalez et al., 2007) and GA (Voit and Almeida, 2004). To ensure a fair comparison, the same ODE solver (modified collocation methods) and performance index,F=(1/nQ)Σk=1QΣk=1n((xik−xi,exp⁡k)/(max⁡(xi,exp⁡k))2, were used. All of the estimated concentrations were obtained from the inferred S-systems, which are described in previous papers (Kimura et al., 2005; Noman and Iba, 2005; Tsai and Wang, 2005; Kikuchi et al., 2003; Voit and Almeida, 2004; Ho et al., 2007; Gonzalez et al., 2007; Liu and Wang, 2008). The largest unfitness of the SCGA for these systems is 3.8796069×10−11, which is much smaller than all of the unfitness of the methods in Table 11. Therefore, the SCGA takes vantage in both speed and accuracy.We also analyze the effect of 10% external noise on the behavior of the algorithm. The data set size of the branch pathway system was further reduced to one quarter of that used before (5s for simulation time and 0.05s for sampling time). The results of this simulation are provided in Fig. 5, wherein solid lines denote the estimated data and the dot, square, circle, cross and diamond points denote data with 10% noise. We observed that SCGA can predict the dynamic behavior even in a noisy environment. (The initial condition for testing was set to 20% beyond the training range.)Additionally, we tested SCGA with real E. coli data (provided by Prof. Feng-Sheng Wang). E. coli are the most important host microorganism for recombinant protein production. We here consider the growth dynamics of l-aspartate ammonia-lyase-overproducing E. coli strain. Time series data were measured in batch experiments, wherein nutrient medium is composed of 57.5g/L yeast extract, 11.5g/L NaCl, 35g/L KH2PO4, 127g/L K2HPO4, 17.5g/L NH4Cl, 0.4g/L CaCl2, 0.9g/L MgSO4·7H2O, 0.8g/L FeSO4·7H2O, and 0.1g/L Vitamin B1. The variables, X1, X2, X3, X4, X5 are the concentration of cell mass, glucose, protein, lactate and acetate, respectively. The efficiency of SCGA for the real data is shown in Fig. 6wherein diamond, star, circle and square points denote the real data, and the solid lines denote the estimated values.Fig. 7and Table 12show the performance comparison of operations used in SCGA. In Fig. 7, the red solid line (-B) represents for learning without the seeding-inspired operation (Subsection 2.2). The green solid line (-C) denotes that the mixed inbreeding and backcrossing operation (Subsection 2.3) is replaced by two-point crossover. The black dash line (-D) denotes that the competition-based screen-shifting mutation (Subsection 2.4) is replaced by screen-shifting mutation. The magmata dash line (-E) is for learning without winner-chemotaxis-induced population migration (Subsection 2.5). Table 12 is the successful rate of the aforementioned methods (-B, -C, -D and -E) in ten independent runs. The results of Fig. 7 and Table 12 indicate two points: (1) Without B or E operation, SCGA fails to determine the global optimum. (2) By using general mutation or crossover, SCGA converges slowly but still has the chance to achieve the global optimum.SCGA allows algorithms to fall into a local minimum on purpose and then escape from it. Obviously, the spirit is totally different from that of stochastic approaches (for example, IGA, HDE and EEGA in our previous paper (Wu et al., 2012)). What we did was to increase the escaping ability of the algorithm as much as possible. For a shallow error surface we can obtain the global optimum through random parameters and core proliferation operation or by increasing the value of NSCGA. In our previous paper (Wu et al., 2012), we used a small search range ([0, 30] for rate constants and [−4, 4] for kinetic orders) for learning. In this study, a wide range was used. Therefore, comparing the performance of SCGA and EEGA using the simulation results in these two studies is unfair. EEGA tries to avoid local minima (such as most of evolutionary algorithms). SCGA intends to move toward attractors. Therefore, EEGA is supposed to possess better explorative ability, whereas SCGA takes advantage of exploitation. Fig. 8compares the performance of these two in the twenty-gene system (each line for one gene). The convergent conditions are clear when we zoom in this figure or subdivide it into four plots (Fig. S8 in the Supplement file). Although SCGA is faster than EEGA, both can determine the global optimal in a limited time, even when the search is in a wide range ([0, 100] for rate constants and [−100, 100] for kinetic orders). Both have comparable performance in systems with 20 or 30 dimensions. However, for large systems EEGA is potentially better than SCGA from the viewpoint of learning spirit.We now consider whether the cancel-off phenomenon (The effect of xjon xiis reduced when xjis in both influx and efflux.) occurs during our learning. The phenomenon was noted in Veflingstad’s paper (Veflingstad et al., 2004). Four types of approaches in Veflingstad’s paper are all based on the linearized models of S-systems, wherein the effect of xjon xiis determined by the kinetic order cij=gij−hij. For a small-genetic system, C32=g32−h32=(−1)−(−1)=0. Therefore, the effect of x2 on the production of x3 cannot be identified correctly when learning is based on the linearized model. Our learning is based on the original nonlinear S-systems, wherein gijand hijare learned independently. Therefore, such a cancel-off phenomenon does not exist. Moreover,|gij|+|hij|is also a penalty term, which is included in the performance index of structure identification. Therefore, the problem noted in Veflingstad’s paper (Veflingstad et al., 2004) is not present for our approach.

@&#CONCLUSIONS@&#
