@&#MAIN-TITLE@&#
The Clustered Orienteering Problem

@&#HIGHLIGHTS@&#
We introduce a new problem, the Clustered Orienteering Problem (COP), which has strong applications in practice.We propose a formulation for the COP and several valid inequalities.We developed heuristic and exact algorithms to solve the COP.

@&#KEYPHRASES@&#
Orienteering Problem,Branch-and-cut,Tabu search,

@&#ABSTRACT@&#
In this paper we study a generalization of the Orienteering Problem (OP) which we call the Clustered Orienteering Problem (COP). The OP, also known as the Selective Traveling Salesman Problem, is a problem where a set of potential customers is given and a profit is associated with the service of each customer. A single vehicle is available to serve the customers. The objective is to find the vehicle route that maximizes the total collected profit in such a way that the duration of the route does not exceed a given threshold. In the COP, customers are grouped in clusters. A profit is associated with each cluster and is gained only if all customers belonging to the cluster are served. We propose two solution approaches for the COP: an exact and a heuristic one. The exact approach is a branch-and-cut while the heuristic approach is a tabu search. Computational results on a set of randomly generated instances are provided to show the efficiency and effectiveness of both approaches.

@&#INTRODUCTION@&#
The class of routing problems with profits is composed by a wide variety of problems which share the same characteristic: in contrast to what happens in classical routing problems, not all customers need to be served. Instead, a profit is typically associated with each customer and the problem is to choose the right set of customers to serve satisfying a number of side constraints while optimizing a given objective function (maximize the total collected profit, minimize the traveling cost, maximize the difference among profits and costs, etc.). Among the routing problems with profits, the Traveling Salesman Problems with Profits (TSPPs) are problems where a single vehicle is available to carry out the service (see Feillet, Dejax, & Gendreau (2005) for an excellent survey on TSPPs). In Feillet et al. (2005), TSPPs are classified in three main categories, depending on the objective function and side constraints: the Orienteering Problem (OP), also known as the Selective Traveling Salesman Problem, where the objective is to find the vehicle route that maximizes the total collected profit in such a way that the route duration does not exceed a given threshold; the Prize Collecting TSP (PCTSP), which is the problem of finding the route that minimizes the traveling cost while ensuring that the profit collected is greater than or equal to a minimum requested amount; finally, the Profitable Tour Problem (PTP) which is the problem of finding the route that maximizes the difference between the total collected profit and the traveling cost. The OP is certainly the variant that has received more attention in the literature. It has been introduced in Tsiligirides (1984) and then studied in Golden, Levy, and Vohra (1987) as an application of the home fuel delivery problem. A number of heuristic algorithms have been proposed (see Chao, Golden, & Wasil, 1996; Chekuri, Korula, & Pál, 2012; Gendreau, Laporte, & Semet, 1998a; Golden et al., 1987; Golden, Wang, & Liu, 1988; Liang, Kulturel-Konak, & Smith, 2002; Tsiligirides, 1984; Wang, Sun, Golden, & Jia, 1995) and also efficient exact algorithms (see Fischetti, Salazar-González, & Toth, 1998; Gendreau, Laporte, & Semet, 1998b; Laporte & Martello, 1990; Ramesh, Yoon, & Karwan, 1992). The recent literature has been focused on variants or generalizations of the OP, especially on the multiple vehicle version, called Team Orienteering Problem (TOP). We do not survey here the literature related to this variants as it is quite wide. The reader is referred to Keller (1989), Vansteenwegen, Souffriau, and Van Oudheusden (2011) and Archetti, Speranza, and Vigo (2013) for excellent surveys on the OP and on routing problems with profits in general.In this paper we address a generalization of the OP which we call the Clustered Orienteering Problem (COP). In this problem, customers are grouped in clusters. A profit is associated with each cluster and is collected only if all customers in the cluster are served.The interest in studying the COP is motivated by the analysis of practical application problems that can be formulated as variants or generalizations of the COP. Examples of such applications are mainly related to the distribution of mass products, like in the case where customers are retailers belonging to different supply chains and contracts are made between the carriers and the chains. Thus, if a carrier agrees to serve a chain, he/she has to serve all retailers belonging to that chain. Another example is the case where products are divided in brands: the carrier stipulates contracts with product shippers; retailers (customers) require a certain amount of each product; in order to get the profit, the carrier has to serve all retailers requiring a certain amount of product of the brand for which he/she has a contract. Also, a different case arises when customers are clustered in areas and the profit is collected only if all customers in an area are served. This happens for example in the case of companies providing waste collection services: they can be engaged by municipalities to serve given areas and visit all customers there.The main contribution of the paper is the introduction and the study of the COP. We give a mathematical formulation of the problem and propose two solution approaches: an exact solution approach which is a branch-and-cut algorithm, and a heuristic algorithm based on a tabu search scheme. The exact solution approach is able to solve instances with up to 318 vertices and 15 clusters or 226 vertices and 25 clusters in one hour of computing time while, on the same classes of instances, the heuristic gives high quality solutions in an extremely short amount of time. Three variants of the heuristic have been implemented and tested also on larger instances which could not be solved by the exact algorithm. The variant based on a multi-start approach proved to be the best.The paper is organized as follows. In Section 2 we describe the problem and propose a mathematical formulation. Section 3 is devoted to the branch-and-cut algorithm, together with the valid inequalities and branching rules we propose to enhance the efficiency of the approach. In Section 4 we describe the tabu search algorithm. In Section 5 we present the computational tests we made in order to verify the effectiveness of both the exact and the heuristic algorithm and we discuss the computational results. Conclusions are drawn in Section 6.The COP can be represented by an undirected graphG=(V,E)where V is the set of vertices and E is the set of edges. SetV={v0,v1,…,vn}is formed by vertexv0which is the depot where the vehicle starts and ends its tour and verticesv1,…,vnwhich are the customers. A coverS={S1,S2,…,Sk}ofV⧹{0}is defined whereV⧹{0}=∪i=1kSi. In the following we call each elementSi∈Sa cluster. Each customer belongs to at least one clusterSi,i=1,…,k. Note that a customer can belong to more than one cluster. An integer valuepiis associated with each clusterSiand corresponds to the profit which is collected only if all customers inSiare served (visited) by the vehicle. A costteis related to each edgee∈Eand represents the time needed to traverse edge e. We assume that travel times satisfy the triangle inequality. A single vehicle is available and a maximum time limitTmaxis imposed on the duration of the vehicle route. Note that, it is not necessary that all vertices belonging to a cluster are visited consecutively, i.e., the vehicle can start visiting some vertices in a cluster, leave the cluster and visit vertices belonging to different clusters and then visit the remaining vertices of the previous cluster. The objective is to find the route that maximizes the total collected profit and such that the duration is lower than or equal toTmax. Note that, if all clusters are formed by single customers, the COP reduces to the OP.In order to give a mathematical formulation of the problem let us first introduce the following notation:•δ(U): set of edges with one endpoint in U and one endpoint inV⧹U. For the ease of notation, we will writeδ(j)for the set of edges adjacent to the single vertexvj.E(U): set of edges with both endpoints inU⊆V.zi: binary variable equal to 1 if all customers in clusterSi∈Sare served, 0 otherwise.yj: binary variable equal to 1 if vertexvj∈Vis served, 0 otherwise.xe: binary variable equal to 1 if edgee∈Eis traversed, 0 otherwise.The COP can then be formulated as follows:(1)max∑Si∈Spizi(2)y0=1(3)∑e∈δ(j)xe=2yj∀vj∈V(4)∑e∈Etexe⩽Tmax(5)∑e∈E(U)xe⩽∑vj∈U⧹{vt}yj,∀U⊆V⧹{0},∀vt∈U(6)zi⩽yj,∀Si∈S,∀vj∈Si(7)zi∈{0,1}∀Si∈S(8)xe∈{0,1}∀e∈E(9)yj∈{0,1}∀vj∈V.The objective function (1) aims at maximizing the total collected profit. Constraint (2) imposes to visit the depot while (3) establishes to traverse two edges adjacent to each served vertex. Inequality (4) imposes the maximum time limit on the route duration while (5) are the subtour elimination constraints. (6) imposes that all vertices belonging to a cluster must be served in order to get the corresponding profit. Finally, (7)–(9) are variable definitions.Note that this formulation is an adaptation of the formulation proposed in Fischetti et al. (1998) for the solution of the OP. The branch-and-cut algorithm proposed in Fischetti et al. (1998) is, to the best of our knowledge, the best exact solution approach proposed in the literature for the solution of the OP. Thus, we are confident that the formulation we propose will be also effective for the COP. The differences with respect to the standard OP formulation are related to the presence of the z variables indicating whether a clusterSiis served. As a consequence, while in the OP the sum of the profits of the served customers is maximized, in COP we maximize the sum of the profits of the clusters served. Moreover, constraints (6) and (7) are not present in the OP.In the following section we present a branch-and-cut algorithm for the exact solution of the COP.We implemented a branch-and-cut algorithm in order to solve model (1)–(9) which we call COP-CUT. At each node of the branch-and-bound tree we solve the linear relaxation of (1)–(9) where subtour elimination constraints (5) are originally removed from the formulation and inserted only once violated. In the following we describe the valid inequalities and the branching rules implemented in order to improve the efficiency of the algorithm, together with the separations algorithms which detect violated valid inequalities and subtour elimination constraints.In order to strengthen the formulation, we introduced different valid inequalities. The first class of valid inequalities, which we call logical constraints, is the following:(10)xe⩽yj∀vj∈V,e∈δ(j)and establishes the relation between the x and the y variables. They were introduced in Fischetti et al. (1998) for the OP and they proved to be effective.A second class of inequalities, called connecting inequalities, states that, if a cluster is served, then at least two edges must connect the cluster with vertices outside the cluster:(11)∑e∈δ(Si)xe⩾2zi∀Si∈S.A more general class of valid inequalities, called Generalized Subtour Elimination Constraints (GSECs), which consider all possible subsets of customers, was introduced in Fischetti et al. (1998). This class of inequalities was proved to be one of the most effective among the different classes proposed in Fischetti et al. (1998). We preferred to implement inequalities (11) instead of the more general GSECs in order to reduce the time spent to separate them.Moreover, we implemented a third class of valid inequalities, called cluster-set inequalities, which are based on the idea of identifying a setS′⊆Sof clusters which cannot be feasibly served altogether as this would violate the time constraint. The cluster-set inequalities are formulated as follows:(12)∑Si∈S′zi⩽|S′|-1∀S′⊆Ss.t.TSP(S′)>Tmax,whereTSP(S′)is the value of the optimal solution of the TSP over all vertices inS′∪{0}.Finally, the following two classes of valid inequalities are inserted each time a feasible solution or a new best solution is found, respectively.Each time a new feasible solution is found, the following inequality is inserted:(13)∑Si∉C,Si∈Szi⩾1where C is the set of clusters served in the feasible solution just found. The inequality establishes that at least one cluster not served in the current feasible solution has to be selected. Moreover, if the new solution improves the value of the current best feasible solution, let us denote aspbestthe value of the new solution and asC∼the set of all subsets of clusters such thatC∼={C⊆S|∑Si∈Cpi⩾pbest+1}. Finally, letΨ=minC∈C∼∑Si∈Cpi. Then, the following valid inequality is added:(14)∑Si∈Spizi⩾Ψ.Thus,Ψis the minimum profit greater thanpbestthat can be collected and inequality (14) imposes to choose a set of clusters such that the profit collected is greater than or equal toΨ. Note that lower boundΨmay be strengthened by considering constraints that exclude a set of clusters or supersets of a set of clusters which have been proved to be infeasible while separating inequalities (12).Subtour elimination constraints (5) and valid inequalities (10)–(12) are inserted only once violated, while (13) and (14) are inserted each time a new feasible or best solution is found, respectively. We look for the violation of valid inequalities (10), (11) and (12) up to the second level of the branch-and-bound tree, i.e., up to node 7 when performing a breath-first search (the root node is node 1). The order with which we insert cuts is the following: we first insert violated logical inequalities (10), followed by connecting inequalities (11), then subtour elimination constraints (5) and finally cluster-set inequalities (12). Every time we find at least one violated inequality, we insert the inequality and we return to the solution of the linear relaxation of the problem.Logical and connecting inequalities are separated by simple enumeration. For the subtour elimination constraints we instead implemented the standard separation algorithm based on the solution of a maximum flow problem from the depot to each vertex of the auxiliary graph (see Padberg & Rinaldi, 1991).Identifying violated inequalities (12) is a difficult task because of two main reasons: first of all, the number of inequalities is exponential in the number of clusters and thus enumerating all of them is not viable. Second, once a set of clusters is identified, in order to check if it can be feasibly served, it is necessary to solve a TSP on all vertices in the set of clusters (plus the depot). It is thus crucial to find a criterion to choose the set of clusters on which a TSP will be solved, in order to avoid to solve many TSPs in vain. To this aim, we designed a procedure that identifies a set of clustersS′which violates constraints (12) and on which we successively solve the TSP. LetLB(zi)andUB(zi)be the lower and the upper bound, respectively, on variablezidefined by branching constraints, respectively. We define:C1={Si∈S|LB(zi)=1in current node of the branch-and-bound tree}C0={Si∈S|UB(zi)=0in current node of the branch-and-bound tree}.The procedure we designed in order to identify violated constraints (12) consists in solving the following MILP problem:(15)max∑Si∈Spiαi(16)∑Si∈Szˆiαi⩾∑i=1kαi-1+ε(17)∑Si∈Sαi⩾1(18)αi=1,∀Si∈C1(19)αi=0,∀Si∈C0(20)αi∈{0,1}Si∈Swherezˆicorresponds to the value ofziin the current optimal solution of the linear relaxation of (1)–(9),εis set to a small constant (10-3) in order to guarantee non negligible degree of violation andαiis a binary variable equal to 1 if cluster i is inserted in set of clustersS′. The model aims at finding the set of clustersS′that violates constraint (12) while maximizing the total profit. In fact, if a feasible solution to problem (15)–(20) is found, then, thanks to constraints (16), the clusters whose associatedαvariable takes value 1 identify a set of clusters that violates constraint (12). Constraint (17) imposes to select at least one cluster, i.e., the solution with a null value is discarded.Different objective functions can be used for the identification of a set of clusters which violates inequality (12). For example, one may wish to find a set of clusters which satisfies constraints (16)–(20) and maximizes the violation of inequality (12) or maximizes/minimizes the number of clusters inserted.In order to identify a violated inequality we implemented different strategies based on iterated solutions of problem (15)–(20). The following rule is the one with the best performance.We first identify the set of clusters of maximum and minimum cardinality violating constraints (12) by solving the following problems:max∑Si∈Sαiandmin∑Si∈Sαisubject to constraints (16)–(20). Let us callCmaxthe value of the optimal solution when the cardinality is maximized andCminthe value of the optimal solution when the cardinality is minimized. We then solve problem (15)–(20) with the addition of the following constraint:∑Si∈Sαi=c¯.Initially we setc¯=⌊Cmax+Cmin2⌋. Then, if the solution of the TSP on the set of clusters identified by the optimal solution of (15)–(20) has a value greater thanTmax, the corresponding cut is added to the formulation. Otherwise, we setCmin=c¯+1, we compute again the value ofc¯as⌊Cmax+Cmin2⌋and we iterate. This rule for updating the value ofc¯is due to the fact that, if we do not find a set of clusters violating inequality (12) with a cardinality equal to the current value ofc¯, this is probably due to the fact that the value ofc¯is too low, and thus we increase it. If instead we find a violated inequality, we add it to (1)–(9) and we solve the corresponding linear relaxation. To calculate the optimal TSP solution on the identified set of clusters we use the Concorde library (Cook, 2010).Separating inequalities (12) is thus time consuming as it involves solving a TSP for each set of clusters identified by the solution of (15)–(20). In order not to solve many TSPs in vain, each time problem (15)–(20) is solved we add a set of inequalities to its formulation which limit the search for the following solutions. In particular, let us callS′the set of clusters for whichαi=1in the current solution of (15)–(20). Then, ifTSP(S′)⩽Tmax, inequality (13) is added to (15)–(20) withC=S′andzi=αi.The separation of inequalities (12) is stopped after finding 5 solutions of (15)–(20) without success, i.e., either (15)–(20) is infeasible or the setS′identified by the solution is such thatTSP(S′)⩽Tmax. The separation is stopped also whenc¯=Cmaxand (15)–(20) is solved without success.Finally, in order to identify the value ofΨin inequality (14), the following MILP is solved:(21)min∑Si∈Spiαi(22)∑Si∈Spiαi⩾pbest+1with the addition of all violated inequalities (12) found so far, whereαi=zi. Constraint (22) imposes to select a set of clusters whose total profit is higher thanpbestwhile the objective function (21) selects the set of clusters that minimizes the profit, in the set of those satisfying constraint (22).As far as the separation algorithm of inequalities (12) is used, i.e., up to the second level of the branch-and-bound tree, we implemented the following branching rule. If, in the current node of the branch-and-bound tree, while separating inequalities (12), we found a set of clusters C for which∑i∈Czi⩾|C|-1andTSP(C)⩽Tmax, then we generate two branches and set∑i∈Czi⩾|C|on one branch and∑i∈Czi⩽|C|-1on the other branch.When the separation algorithm of inequalities (12) is not used, since the objective of the COP is to maximize the total collected profit and this is related to clusters, we decided to give priority to the z variables when branching. In fact, the z variables are the only ones appearing in the objective function. The choice on which z variable to branch on is made on the basis of the default setting of the exact solver used.As will be shown in Section 5.2, the COP-CUT algorithm is able to solve small to medium size instances. In order to solve larger instances, we propose a heuristic algorithm for the solution of the COP, in particular a tabu search algorithm which we call COP-TABU. The general scheme of COP-TABU is the following.COP-TABUCompute an initial solutions0s∗←s0s←s0Whilea stopping criterion is not metdoGenerate the neighborhoodN(s)Choose the best solutions′∈N(s)s←s′Ifsis better thans∗thens∗←sEnd IfUpdate the tabu listUpdate the long-term memoryEnd WhileReturns∗In the following we explain in detail each step of COP-TABU. Procedures Update the tabu list and Update the long-term memory are explained before procedure Choose the best solutions′∈N(s)as they are needed to understand how we chooses′∈N(s).Compute an initial solutions0The initial solution is generated by first ordering all clusters randomly and then inserting them sequentially ins0, if the corresponding solution is feasible. The insertion is done as follows. We start from a solutions0visiting only vertex 0. Then, each time a cluster is added tos0, a new tour is generated on all vertices included ins0through the Lin–Kernigham algorithm (Lin & Kernighan, 1973). The procedure stops when all clusters have been considered for insertion.Generate the neighborhoodN(s)Given the current solution s, letC(s)be the set of clusters served in solution s andC‾(s)be its complement. The neighborhoodN(s)is made by two types of moves:•GivenSi∈C‾(s), insertSiin s if the corresponding solution is feasible.GivenSi∈C(s), removeSifrom s.The insertion of a clusterSiin a solution s is made by solving the TSP on all vertices belonging toC(s)∪Siwith the Lin–Kernigham algorithm (Lin & Kernighan, 1973). The removal of a cluster always leads to a feasible solution thus it does not require any TSP calculation. We simply remove each vertex of the cluster by joining its predecessor with its successor. Note that, when removing a cluster from s, we remove only vertices which do not belong to any other cluster inC(s).Update the tabu listEvery time a cluster is inserted (removed) from s, then it is tabu to remove (insert) it from s forαiterations.Update the long-term memoryLetηibe the number of iterations clusterSihas remained in the current solution.ηiis set to one each timeSiis inserted inC(s). At each iteration,ηiis set to 0 ifSiis removed from the current solution, otherwise it is increased by one.Choose the best solutions′∈N(s)In order to avoid to uselessly explore the entire neighborhood, we defined a rule which splits it into six different neighborhood sets which are explored on the basis of a rule that will be described in the following. Each neighborhood set is identified according to the move applied on the current solution s and to the fact that the tabu status is taken into account or not.1.Non-Tabu Insertion. Insert in s a non-tabu cluster fromC‾(s), if any.Old Removal. Remove from s a clusterSj∈C(s)for whichηj>β, if any.Non-Tabu Removal. Remove from s a non-tabu clusterSj∈C(s), if any.Tabu Insertion. Insert in s a tabu clusterSi∈C‾(s)whose insertion leads to a solution with a higher value than the aspiration level ofSi, if any. The aspiration level of clusterSiis defined as the solution value obtained the last timeSiwas inC(s).Random Removal. Choose randomly a cluster inC(s)and remove it from s. Consider also tabu clusters.Random Insertion. Choose randomly a cluster inC‾(s)and insert it in s. Consider also tabu clusters.Note that a move is applied only if it leads to a feasible solution. Also, the best move is implemented, where the best move is chosen on the basis of a criterion which considers, for each cluster, the profit and the overlapping with other clusters visited in the current solution. In order to avoid to calculate many TSPs and then choose the best move, when an insertion move is considered (either tabu or non-tabu), first clusters are ordered on the basis of an ordering criterion. The first cluster in the list which can be feasibly inserted in s is then considered. The ordering criterion is the following. LetηSj(s)be the number of customers inSjwhich are not already visited in s, for eachSj∈C‾(s). The ordering criterion is a non-increasing order of the ratiopj1+ηSj(s). The reasons for considering this criterion are twofold: on one side, we want to favor the insertion of a cluster with a high profit. On the other side, if a cluster which is not visited in the current solution has a high overlap with clusters which are already visited, meaning that a large portion of its customers belong also to clusters which are already visited, then its insertion is less expensive in terms of traveling cost. Note that the 1 at the numerator of the ratio is inserted to take into account the case where all customers in clusterSj∈C‾(s)are already visited in solution s. Similarly, for the non-tabu removal, we order the non-tabu clusters on the basis of a non-decreasing ratiopj1+νSj(s), whereνSj(s)is the number of customers inSj∈C(s)that belongs to other clusters visited in solution s. We then remove the first in the list.Given a neighborhood sets̃, a move is admissible fors̃if it belongs to the set of moves defining neighborhood sets̃and if the corresponding solution is feasible. Neighborhood sets are explored according the previous order and the first admissible move is implemented. This implies that, if there is at least one admissible move for Non-Tabu Insertion, then the best one is implemented. Otherwise, it means that no cluster inC‾(s)can be inserted, either because it is tabu or because its insertion leads to an infeasible solution. In this case, we remove a cluster fromC(s)with Old Removal which checks if there are clusters which have remained inC(s)for a high number of iterations (more thanβ) and remove the oldest one. Note that, in this case, the cluster removed is not tabu as many iterations have elapsed from its last move. If there is no clusterSi∈C(s)withηi>β, then we apply Non-Tabu Removal and remove the non-tabu cluster inC(s)with the lowest value of the ratiopj1+νSj(s). The reason why we decided to remove first the ‘old’ clusters is that typically they correspond to clusters with a high profit and thus they would rarely be removed. If no cluster is removed, it means that all clustersSi∈C(s)are tabu and haveηi<β. In this case Tabu Insertion is applied. Random Removal is applied only when no tabu cluster inC‾(s)beats its aspiration level while Random Insertion is applied only when solution s is empty.A final note has to be made on the TSP calculations. Each time a TSP is calculated on a setC∼of clusters, the information concerning feasibility of setC∼is stored in memory. Then, if setC∼is feasible, i.e.,TSP(C∼)⩽Tmax, COP-TABU will not calculate the TSP onC∼and on each setC∼′⊆C∼in the following iterations. If insteadTSP(C∼)>Tmax, then COP-TABU will not calculate the TSP onC∼and on each setC∼′⊇C∼in the following iterations.Note that in COP-TABU the value ofTSP(C)is calculated through the Lin–Kernigham algorithm and thus it is a heuristic value. This means that COP-TABU can discard feasible solutions.We implemented three variants of COP-TABU:•Basic: COP-TABU is stopped afterΓiterations.Multi-start: COP-TABU is restartedγtimes fromγdifferent random initial solutions. To have a fair comparison with the basic COP-TABU each run is stopped afterΓγiterations.Reactive: COP-TABU is stopped afterΓiterations. Moreover, each time we find a new best solutions∗,αis decreased by 25% of its current value. On the contrary, if 10 iterations have elapsed without improvings∗, the value ofαis increased by 1. In any case,αis always kept in the interval1,23k, where k is the number of clusters. The reason behind this rule for updating the value ofαis that, when a new best solution is found, we want to deeply explore the solution space around this solution thus we need to reduce drastically the value ofαto avoid to miss good solutions because they are classified as tabu. On the other side, when the best solution is not improved, we want to avoid to come back to the current solution and thus we increase the value ofα. However, in order to avoid to restrict too much the set of non-tabu solutions,αis increased gradually by a constant value equal to 1.A final observation is needed on the structure of COP-TABU. Even if we have defined different neighborhood sets, COP-TABU basically differs from a standard Variable Neighborhood Search (VNS) algorithm in that, in a VNS, the neighborhood sets are used to move to a different solution from the current one. Then, this solution is accepted only if it improves the current solution. If this is not the case, the new solution is discarded and a different neighborhood is applied. COP-TABU instead accepts also worsening solutions if they are not tabu. Thus, even if it uses neighborhood sets, the basic scheme inherits the standard rules of the tabu search. We have decided to combine tabu search with neighborhood sets in order to obtain an approach which can easily escape from local optima (with the tabu rule) and, at the same time, efficiently explore the solution space (with the neighborhood sets).In this section we describe the computational tests we made in order to verify the performance of both the COP-CUT and the COP-TABU algorithms. In Section 5.1 we describe how we generated the instances while Section 5.2 is dedicated to computational results.To the best of our knowledge, COP has never been studied previously in the literature. Thus, there are no benchmark instances and we had to generate them. To this aim, we take TSP benchmark instances from the TSPLIB95 library available at the following URL: http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95. We note that, in the instances of the TSPLIB95 library, vertices are numbered from 1. In our tests, the first vertex coincides withv0, the depot.We take all instances with a number of vertices ranging from 42 to 532 which are 57 in total. We keep the data concerning the location of the vertices and we generate the remaining data as follows:1.Clusters: the number k of clusters has been set to the following values: 10, 15, 20, 25. Clusters are generated by considering the vertices sequentially with respect to their number and inserting them in each cluster in such a way to obtain clusters of similar size and which are partially overlapping. In particular, we start by removing the first vertex (depot) from the list ofn+1vertices and obtain a list of n customers. Then, we compute the quotient q and the remainder r of the integer divisionn/k. The customers list is thus partitioned in k sublists where the first r sublists containq+1customers and the remainingk-rsublists contain q customers. Finally, we computed=max1,q10, and make each sublist to share its first d customers with the preceding sublist and its last d customers with the following one (last sublist is the preceding sublist of the first one and vice versa). As a final result, two consecutive sublists (clusters of customers) overlap for2dcustomers i.e., each cluster shares customers with other two clusters for a total of4dcustomers.pi: in order to generate the profit of each clusterSi, we first assigned a profit to each vertex, excluding the depot. The profit of a cluster is then given as the sum of the profits of the vertices in the cluster. The profits are generated according to two rules as done in Fischetti et al. (1998) for the OP. The first rule sets the profit of each vertex equal to 1. The second rule sets the profit of a vertex j equal to1+(7141j+73)mod(100)in order to obtain pseudo-random profits.Tmax: we set the value ofTmaxasθ·TSP∗whereTSP∗is the optimal value of the TSP over all vertices. We considered three values ofθ: 1/4, 1/2, and 3/4.Thus, we generated in total57×4×2×3=1368instances. The instances and the detailed results can be found at the following URL: http://or-brescia.unibs.it/.In this section we present the computational results of the tests we made in order to verify the efficiency of both COP-CUT and COP-TABU. We first analyze the performance of COP-CUT in Section 5.2.1 and then we focus on COP-TABU in Section 5.2.2. All tests have been made on an Intel Xeon W3680 six-core CPU 3.33gigaherts, Windows 7 Professional-64 bit operating system with 12gigabytes RAM. COP-CUT and the basic branch-and-cut algorithm, described in the next section, are implemented in Concert Technology with CPLEX 12.2. The implementation of the Lin–Kernigham algorithm used in COP-TABU is the one provided in the Concorde library (Cook, 2010). Computing times are expressed in seconds.COP-CUT has been tested on instances with up to 318 vertices as larger instances could not be solved within the time limit. In order to verify the performance of the algorithm, we compare it against the solution of formulation (1)–(9). The aim of our tests is to verify the efficiency of valid inequalities (12)–(14) and of the branching rule described in Section 3.3. As inequalities (10) and (11) were already proven to be effective in Fischetti et al. (1998), we did not focus our tests on their efficiency and we inserted them in the basic formulation. In the following, we call BASIC the branch-and-cut algorithm based on formulation (1)–(9) plus inequalities (10) and (11). A further notice on the BASIC branch-and-cut is that we set a priority on the z variables when branching. In fact, when using the default CPLEX parameter, we got extremely poor results. The maximum time limit of both algorithms is set to 1hour.We have 312 instances with less than 100 vertices, 600 instances with a number of vertices ranging from 100 to 199 and 288 instances ranging from 200 to 318 vertices. Results are shown for instances in the latter range. Instances with less than 100 vertices have been solved to optimality by both algorithms. However, on 241 instances, over 312, the BASIC algorithm finds the optimal solution in a lower computing time while COP-CUT is faster on 53 instances. The computing time is the same for the remaining instances. For the 600 instances with a number of vertices ranging between 100 and 199, the BASIC algorithm solved 524 of them while COP-CUT solved 455 instances. Moreover, when the optimal solution is found, the BASIC algorithm is faster on 402 instances while COP-CUT is faster on 116 instances. Thus, for instances with less than 200 vertices, COP-CUT does not compare favorably with the BASIC algorithm. However, as will be shown later, on instances with a higher dimension COP-CUT tends to outperform the BASIC algorithm. Thus, we conclude that the introduction of the valid inequalities, especially inequalities (12), is worthwhile only when the dimension of the instances is such that it pays off to spend a higher computing time in trying to improve the upper bound. For smaller instances, it is better not to separate these inequalities.We thus decided to present the detailed results for instances with at least 200 vertices where we can see the advantages of using COP-CUT instead of the BASIC algorithm. We also decided to discard instances withθ=1/4as they distort the average results obtained over all instances. This is due to the fact that, for many instances in this class, the branch-and-cut algorithms were not able to find any feasible solution with positive value. On the other side, these instances could not be solved to optimality and the algorithms gave a positive upper bound at the end of the computation. Thus, the optimality gap, which is calculated asz¯-z̲z¯wherez¯is the upper bound at the end of the computation andz̲is the value of the best feasible solution found by the algorithm, turned out to be 100% and this high value distorted the average results. In any case, even if the exact algorithms were not able to prove the optimality, we believe that no feasible solution with positive value exists for these instances, thus the null solution is the optimal one.Figs. 1–8report the results related to 192 instances: 12 TSP benchmark instances with a number of vertices ranging from 200 to 318, 4 different number k of clusters, 2 kinds of profit generation, 2 value ofθ. In particular, Figs. 1–4 report the results related to the optimality gap at the end of the computation. We report the results classified by number of vertices (Fig. 1), number of clusters (Fig. 2), kind of generation of profits (Fig. 3) and value ofθ(Fig. 4). This in order to detect which feature of the problem influences the performance of the algorithms the most. In Fig. 3, ‘g1’ stands for the instances where the profit of each vertex is set to 1 while ‘g2’ is the class of instances with random profits. In Fig. 4, ‘q2’ is the class of instances whereθ=1/2while in ‘q3’θ=3/4(remember that we discarded instances in ‘q1’ withθ=1/4).If we first focus on detecting which characteristic influences the performance of both branch-and-cut algorithms, we can see that there is no clear evidence from the figures. As far as the number of vertices (Fig. 1), the instances with 200 and 262 vertices seem to be the most difficult ones while the behavior of both algorithms is quite fluctuating. This is partly due to the instances where no feasible solution with a positive value has been found. In this case, the gap with the upper bound goes up to 100%. In fact, this happens also for some instances withθ>1/4and is due to the fact that the branch-and-cut algorithms are not able to find any feasible solution with positive value within the maximum computational time. On the other side, we also believe that the high gaps are due to the poorness of the upper bound, as will be confirmed by the results we will show in the next section. This enforces our statement on the need of good valid inequalities to strengthen the value of the upper bound. We have made a similar analysis also on the number of vertices per cluster but no remarkable highlight has emerged. In fact, while all instances with less than 10 vertices per cluster are easily solved by both algorithms, for more than 10 vertices the behavior is fluctuating and with no evidence of a trend. We notice that the maximum number of vertices per cluster in our instances is 38 (318 vertices and 10 clusters). Concerning the number of clusters there seems to be no influence on the performance of the algorithms as the average optimality gap is quite stable (Fig. 2). The class of instances ‘g2’ is more difficult than the class ‘g1’ even if the difference between the two is not substantial (around 2% on the average optimality gap for COP-CUT and 4% for BASIC). As far as the value ofθ, we see that ‘q2’ is the most difficult class. This is due to the fact that the value ofθis more binding in ‘q2’ than in ‘q3’. In fact, while in ‘q3’ the value ofθis3/4and thus a small number of clusters are not served in the optimal solution, in ‘q2’θ=1/2and nearly half of the clusters are not served. Thus, in ‘q2’ deciding which clusters have to be served or not is more complex than in ‘q3’ as there is a higher degree of choice of set of clusters that provide high quality solutions.If we now focus on the performance of the algorithms, Figs. 1–4 show that COP-CUT performs better than the BASIC algorithm. With the exception of instances with 226 vertices, the average optimality gap of COP-CUT is smaller than the one of the BASIC algorithm. If we look at the number of clusters or the kind of generation of profits, the average gap of COP-CUT is always lower than the one of the BASIC algorithm. Finally, if we concentrate on the value ofθ, COP-CUT performs better for both classes ‘q2’ and ‘q3’. Looking in more details at the results, it is possible to notice that the high average gaps are due, even for instances of classes ‘q2’ and ‘q3’, to instances where no feasible solution with a positive value is found within the maximum computing time. Thus, even if all the figures, and especially Fig. 1, show a high optimality gap, we believe that this is due to the characteristics of the problem and of the instances and our conclusion is that these results show that a big effort has to be spent in improving the upper bound, as done by COP-CUT. Finally, we made further experiments with different versions of the branch-and-cut algorithm in order to detect which is the attribute of COP-CUT which contributes the most to its performance. In particular, we made tests with a branch-and-cut algorithm which did not include neither inequalities (13) and (14) nor the branching rule described in Section 3.3. We obtained results which are very similar to the ones obtained with COP-CUT. This means that inequalities (12) are the most influencing attribute of COP-CUT.We perform the same analysis as before also on the computational time. The results are shown in Figs. 5–8.The figures show that on average COP-CUT requires a lower computational time, especially for class ‘g2’ (Fig. 7), 10 clusters (Fig. 6) andθ=3/4(Fig. 8). As expected, Fig. 8 shows that the class of instances which requires more computing time is the one withθ=1/2.A final observation is that the number of instances solved to optimality, over 192, is 53 for the COP-CUT algorithm and 56 for the BASIC algorithm. This have to be weighted up with the results related to the optimality gap and solution time illustrated previously. In fact, on 100 instances COP-CUT provides a better optimality gap than the BASIC algorithm while the opposite happens on 29 instances while, finally, the algorithms give the same optimality gap on 63 cases. This confirms that COP-CUT performs on average better than the BASIC algorithm for instances with more than 200 vertices. The separation of inequalities (12) is time consuming and this penalizes COP-CUT especially in the solution of smaller instances. However, these inequalities are fundamental to reduce the optimality gap when the size of the instances increases. In fact, the average optimality gap on this set of instances is equal to 39.25% for the BASIC algorithm while it decreases to 25.17% for the COP-CUT. This difference, which is quite substantial, is due to the introduction of inequalities (12).We now present the computational tests we made to verify the performance of COP-TABU. The three variants of the algorithm have been tested on all instances. To be coherent with the results presented in the previous section, we do not consider the instances withθ=1/4. For instances with up to 318 vertices we compared the solution with the optimal solution given by COP-CUT or the BASIC algorithm, if available, or with the best upper bound. Note that the number of these instances is much higher than the one considered in the previous section as we now include also the instances with less than 200 vertices. In particular, we compare COP-TABU with the best upper bound and the best feasible solution found by COP-CUT and the BASIC algorithm. In the following, we will use the term ‘branch-and-cut algorithm’ to indicate the best between COP-CUT and the BASIC algorithm. For larger instances, as branch-and-cut is not able to solve them, we make a comparison between the three variants of COP-TABU. The behavior of COP-TABU is strictly related to the number of clusters, whereas there seems to be no evident relation with the number of vertices, kind of generation of profits and value ofθ. Thus, we will present the results on the basis of the number of clusters. Preliminary tests showed that the following parameter values give the best results:Γ=1000,β=Γ10,γ=3,α=0.3|S|. Thus, we use these parameter values in the tests which are shown in the following.Figs. 9–13refer to the instances with up to 318 vertices for which we compare the three variants of COP-TABU with the results given by the branch-and-cut. In particular, Fig. 9 reports the average gap with respect to the upper bound while in Fig. 10 we focus only on instances which are solved to optimality by the branch-and-cut. In Fig. 11 we compare the solution given by COP-TABU with the best feasible solution found by the branch-and-cut. Fig. 12 refers to the iteration at which the best solution (which coincides with the final solution) has been found. For COP-TABU Multi-start, this number is cumulative over the three restartings. Finally, Fig. 13 reports the average computing time.Looking at Fig. 9 we can notice that the average gap with respect to the upper bound is below 4.8% for COP-TABU Reactive, 5.3% for COP-TABU Multi-start and 6.3% for COP-TABU Basic. Detailed results show that this gap goes up to 58% for COP-TABU Multi-start and COP-TABU Basic and to 55% for COP-TABU Reactive. This is due partly to the fact that the TSP is solved heuristically (thus, a feasible solution could be missed) and partly to the fact that we are comparing with the upper bound. When comparing the solution given by COP-TABU with the best feasible solution found by the branch-and-cut, we obtained that, for the instances where the error with respect to the upper bound is so high, COP-TABU finds a solution which is always not worse than the one found by the branch-and-cut. This induces us to conclude that these big errors are mostly due to the poorness of the upper bound.Among the 633 instances solved to optimality by the branch-and-cut (Fig. 10), COP-TABU Multi-start finds 532 optimal solutions, COPT-TABU Basic and COP-TABU Reactive find 486 and 582 optimal solutions, respectively. The average gap with respect to the optimal solution is always below 0.3% for COP-TABU Reactive, below 0.8% for COP-TABU Multi-start and below 2.4% for COP-TABU Basic. More in detail, the maximum error of COP-TABU with respect to the optimal solution is 14% for the Reactive variant, 33% for COP-TABU Multi-start 49% for COP-TABU Basic. Looking in detail at the average error on the basis of the number of vertices, we can see that the gap is always below 4.3%. Looking at the value ofθ, in ‘q2’ the average gap is 1.9% for COP-TABU Basic, 0.8% COP-TABU Multi-start and 0.1% for COP-TABU Reactive. In ‘q3’ the gap is 1.1% for COP-TABU Basic, 0.6% for COP-TABU Multi-start and 0.4% for COP-TABU Reactive. Having a look at the kind of generation of profits we can see that class ‘g1’ presents higher gaps than ‘g2’ for all algorithms but with no substantial difference. This allows us to conclude that all versions of COP-TABU are effective. COP-TABU Reactive is clearly the best one, performing better than the other two variants on all instances. This is confirmed by Fig. 11 which shows that COP-TABU algorithms are extremely efficient in providing high quality solutions: in fact, COP-TABU finds on average better solutions than the branch-and-cut on all classes of instances apart for the class with 10 clusters where the gap is below 1% for all variants. Moreover, the improvement increases with the number of clusters. A further consideration which highlights the efficiency of COP-TABU is that computational time is reasonable as shown in Fig. 13. The same figure also shows that the computational time is strictly related to the number of clusters. This is expected as the higher the number of clusters, the more the number of moves that have to be evaluated by COP-TABU. Finally, Fig. 12 shows that on average COP-TABU finds the best solution in less than 200 iterations. Given that COP-TABU stops after 1000 iterations, this means that we could remarkably reduce the computing time while assuring a high quality of solutions. We decided to maintain a stopping criterion of 1000 iterations as the computational time is still reasonable and we got slightly worse solutions on a subset of instances when reducing this value.If we now compare the three versions of COP-TABU, we can see that COP-TABU Reactive beats both COP-TABU Basic and COP-TABU Multi-start in terms of solution quality. From the computational time point of view, COP-TABU Basic is the fastest algorithm while COP-TABU Reactive is on average the slowest. Moreover, COP-TABU Reactive requires a higher number of iterations to find the best solution.For instances with more than 318 vertices we could not compare COP-TABU with the branch-and-cut, thus we decided to compare the three variants of COP-TABU. The results are summarized in Fig. 14which reports the average error with respect to the best solution found by the three algorithms. We do not report figures concerning the average number of iterations needed to find the best solution and the average computing time as they show a similar behavior as the one illustrated in Figs. 12 and 13. We simply note that the average number of iterations needed to find the best solution is always lower than 220 for all versions of COP-TABU on instances with 25 clusters. The average computational time increases when the number of clusters is higher, as shown in Fig. 13, and is slightly less than 800seconds for all versions of COP-TABU on instances with 25 clusters.The results confirm that COP-TABU Reactive is the best heuristic in terms of solution quality, requiring a computing time which is slightly higher than the other two algorithms. A final observation has to be made with respect to the computing time. The stopping criterion is the same for all versions of COP-TABU, i.e., 1000 iterations (999 for COP-TABU Multi-start). The difference in terms of computing time is due to the number of times the Lin–Kernigham algorithm is called. As mentioned before, each time a TSP is calculated, COP-TABU stores the information about the set of clusters on which the calculation has been made in order to avoid to repeat the calculation in the following iterations. Thus, a shorter computational time means that the algorithm has visited a higher number of identical solutions and thus is less effective, as proved by the results.Finally, as the previous results show that the computational time required by COP-TABU is strictly related to the number of clusters, we decided to make further tests to analyze the behavior of COP-TABU when solving instances with a very high number of clusters. In particular, we took the biggest instance from the set of previously tested instances, which has 532 vertices, and we generated three new classes of instances with 50, 75 and 100 clusters, respectively. Note that, for each number of clusters, we generated 4 instances by varying the value ofθand the kind of generation of profits. Results are summarized on Figs. 15–17, which refer to all instances with 532 vertices (thus also instances with less than 50 clusters). The figures clearly show that the computational time increases with the number of clusters. Also, the iteration at which the best solution is found has a similar behavior as the computational time. Finally, for the gap with respect to the best solution found, the results confirm that the best variant is COP-TABU Reactive while the worst is COP-TABU Basic with an average error which goes up to 5.8%.

@&#CONCLUSIONS@&#
In this paper we analyze a new variant of the Orienteering Problem, the Clustered Orienteering Problem, where customers are grouped in clusters and a profit is associated with each cluster and is collected only if all vertices of the cluster are served. This problem comes from the analysis of practical applications in supply chain management where products of specific brands have to be distributed to all customers belonging to the same supply chain.We present a mathematical formulation together with different valid inequalities and embed them in a branch-and-cut algorithm which is able to solve instances with up to 318 vertices in one hour of computing time. Computational results show that the number of vertices is not the main characteristic of the problem that influences the performance of our solution approaches. In fact, it depends also on other features such as how binding the maximum time constraint is. We notice that the performance does not seem to depend on the number of clusters (apart the computing time of the tabu search algorithm) and this is quite surprising.To solve larger instances, we develop a heuristic algorithm, in particular a tabu search algorithm. The main feature of this algorithm is its simplicity: the neighborhood is based on the simple addition and removal of a cluster. Despite its simplicity, the results prove that it can give high quality solutions in a short computing time.As a remark on our computational analysis, we can say that the problem seems to be more difficult to solve than the OP, especially when we want to solve it to optimality. In fact, while previous papers have proposed exact solution approaches which are able to solve instances with up to 500 vertices for the OP (see Fischetti et al., 1998), we were not able to solve instances with more than 318 vertices. The difficulty is probably due to the nature of the problem and to the characteristics of the instances. In particular, it seems that the constraint on the duration of the route plays an important role. In fact, the hardest instances seems to be the ones where it is difficult to find a feasible solution with a positive value. From a heuristic point of view, on one side it seems to be quite easy to design a solution algorithm based on a local search concept as the crucial decision is which clusters have to be included in the solution or not. Thus, it is natural to base the neighborhood search on the decision on whether to include or not each cluster. On the other side, the difficult part remains the routing, i.e., find the best sequence of serving the customers of the included clusters as this has a big impact on the ability of finding (or, better, not discarding) good solutions.Future research could be focused on the extension of the COP to the case of multiple vehicles considering also additional constraints like vehicle capacity or time windows. Both the solution algorithms presented in this paper could be adapted to deal with these extensions.The authors wish to thank three anonymous referees who helped them improve a first version of the paper.