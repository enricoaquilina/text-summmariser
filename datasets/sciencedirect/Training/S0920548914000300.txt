@&#MAIN-TITLE@&#
Software reference architecture for smart environments: Perception

@&#HIGHLIGHTS@&#
Software developing within Smart Environments is a complex task, and has to be driven.This paper proposes a Software Architecture for developing solutions for Smart Environments.Software Architecture involves two direct benefits: less time of developing, and cost reduction.

@&#KEYPHRASES@&#
Smart environment,Software architecture,Ambient intelligence,Perception,

@&#ABSTRACT@&#
With the increase of intelligent devices, ubiquitous computing is spreading to all scopes of people life. Smart home (or industrial) environments include automation and control devices to save energy, perform tasks, assist and give comfort in order to satisfy specific preferences.This paper focuses on the proposal for Software Reference Architecture for the development of smart applications and their deployment in smart environments. The motivation for this Reference Architecture and its benefits are also explained. The proposal considers three main processes in the software architecture of these applications: perception, reasoning and acting.This paper centres attention on the definition of the Perception process and provides an example for its implementation and subsequent validation of the proposal.The software presented implements the Perception process of a smart environment for a standard office, by retrieving data from the real world and storing it for further reasoning and acting processes. The objectives of this solution include the provision of comfort for the users and the saving of energy in lighting. Through this verification, it is also shown that developments under this proposal produce major benefits within the software life cycle.

@&#INTRODUCTION@&#
A smart environment (SE) can be defined as one that is able to acquire and apply knowledge about the environment and its inhabitants in order to improve their experience in that environment[1].Smart home technologies are an important part of ubiquitous computing. Mark Weiser [2] outlined the principles of Ubiquitous Computing: the purpose of a computer is to help someone do something. Nowadays, due to the popularisation of computational devices and applications, ubiquitous computing is recognised as a revolution in the development of smart environments.Nevertheless, software artefacts related to ubiquitous computing, together with the wide spectrum of computational devices (and the software needed to fulfil their missions) are too heterogeneous and hence difficult to compare or classify. Each piece of software evolves in an isolated way or only in relation to the hardware for which it has been developed. The problem addressed in this paper involves the orchestration of the architecture of a general software model for the development of SEs.This Software Reference Architecture would favour the development of a smart environment solution by increasing the reuse of components, promoting interoperability, and defining the competences of each part of the software.A good comparison for this could be the Open System Interconnection (OSI) model, which is a prescription for characterizing and standardizing the functions of a communications system in terms of abstraction layers.The ambitious goal of this architecture forces it to remain very general and to leave specific aspects until the implementation stage.The benefits of the approach include a better understanding of the issues that must be faced when developing each component of a smart environment solution. The Software Reference Architecture reduces the costs of the main cycles of software (design, development, deployment, and maintenance) and favours the interoperability between various solutions.The main goal of this work is the proposal of Software Reference Architecture for the development of SEs (see Section 3), where all the components can interact flawlessly and reach automatism objectives.To this end, the architecture proposed seeks to improve the modularity, reusability and extensibility of solutions, thereby allowing a more coordinated evolution of SEs, which currently remain under individual and isolated development. The architecture defines a middleware framework that connects the modules and establishes the responsibility of each module. The benefits for developers using a defined framework or standard architecture for the domain have been thoroughly studied by Fayad and Schmidt [28], and include: a reduction and focus of the effort involved, a soft learning curve, integrability, maintainability, easier validation, efficiency, and a higher level of standardization.As an example of the architecture usage, this paper presents the Perception process and provides an example of implementation by following the Software Reference Architecture proposed.Typical components of a SE have been thoroughly studied in the literature, although the approach of Cook and Das [20] deserves special mention since it is currently the most widely accepted approach. Fig. 1shows the general organization of these components. Components are divided into four layers: a) physical; b) communication; c) information; and d) decision. This approach joins hardware with software agents, and hence very heterogeneous elements, such as a decision maker and sensors or actuators, appear in the same component model.All these components must collaborate in order to achieve the goals of automatism that a SE requires. Which tasks belong to each component and how they should collaborate constitute the main motivation of the Software Reference Architecture proposed.The Software Reference Architecture proposed is divided into three main parts: Perception, Reasoning and Acting. This paper focuses on the definition of Perception, as the first step in the general process. Section 2 analyses related work in this area, and in Section 3, Reference Architecture is presented and the Perception process is explained. Finally, verification with a prototype of the Perception process is shown in Section 4, and conclusions are drawn in Section 5.This section explains the proposal of Software Reference Architecture to develop the software layer in SEs. The proposal is based on the goals of ubiquitous computing proposed by Weiser [2]. Taking this as a starting point, automation in SEs can be organized as a continuous interaction between three main processes: a) perception, b) reasoning and c) acting (see Fig. 2).As indicated in the Introduction, this work is centred on the Perception process of the Reference Architecture, which is explained below.The Perception process should be divided in order to split complex perception activity into several attainable tasks. The result of these tasks must be an accurate perception of the real world (see Fig. 3).Perception has to deal with low-level details to retrieve data from real world and to adapt it to a knowledge base, which must agree with the ontology of the SE. A simple information model for the SE used in the prototype scenario is proposed in Table 1. The process has to clear this retrieved data of any erroneous, insignificant, and redundant values in order to build an accurate representation of the real world, as required by the following process.Some of these tasks have common features with ordinary pre-processing of data such as normalization, adding attributes or replacing missing values. Pre-processing of data for SE has been studied by several authors. Stankovski and Trnkoczy's [34] proposal defines a table from the data collected in order to generate inputs for following processing, but does not cover error detection, reparation or the devices which perform this pre-processing. On the other hand, Elnahrawy [35] proposes two general processes•cleaning data (considering cleaning at sensor level or cleaning at database level) by applying probabilistic uncertainty models andquerying data.Moreover Wu and Clements-Croome [36] mention a Data preparation step where data miners create relevant subsets but do not list scopes, reparation or error detection proposals, like Zhang [37] which just mention that a pre-processing step is required for integration of low-level sensor data. The author's approach includes concepts presented by previous proposals and generalizes them.This is the lowest-level task, and its aim is to retrieve data from physical devices within the SE. The Data Collector usually has to deal with gateway devices of every type of sensor technique deployed in the SE.Data can be generated by numerous kinds of sensors such as temperature, pressure, optical, acoustic, mechanical, motion, vibration, flow, position, electromagnetic, chemical, humidity, and radiation, and therefore a crucial question that must be addressed concerning the task of the Data Collector is that of the unification of data types.In fact, only a small subset of the environment properties (Table 1) is necessary to perform a particular application or automation process (e.g. switching lights off when nobody is at home does not need conditioning information from the environment). Similarly, sensors must be deployed in an organized manner in order to prevent the processing of useless information.Regarding the execution of the data processing, it is important to consider where the processing should be performed since a number of devices allow internal programming while others are pre-programmed. The processing can be distributed, centralized, or even a combination of the two if both kinds of devices are present in the environment.Since the majority of devices are pre-programmed and cannot extend their basic functionality (e.g. X-10 motion sensors), the design of the SE has to be suitably adapted and developers have to adapt to them. On the other hand, a growing number of devices have now the ability to extend or modify their performance (e.g. Sentilla Tmotes).Programmable devices are much more flexible, and therefore pose a greater challenge to the designer, since they can be adapted to current needs for a specific application or circumstance. In this case, the task of the Data Collector must involve the use of daemons developed to retrieve information, and also small applications running on devices, and hence both elements have to agree on what information is sent, the periodicity of these requests, and so on.The main purpose of the Verifier task, as its name implies, is to verify that the data is being received by the Data Collector correctly. However the challenge here is how the Verifier can determine whether the data is correct or not. There is no unique solution for all possible environments, so the verification has to be adapted to each environment by taking into account the ontology used.In our proposal, Verifier maintains a rule engine where verification rules can be deployed, modified and checked in order to determine where data is right or wrong for the current environment. The rule engine has to offer programmers a flexible way to add, modify and delete rules, and therefore these should be human readable. The set of rules of the Verifier should evolve over time, as environment changes are produced.This task has to work side by side with the Repairer when incorrect data is received in order to fix invalid data. The mechanism of communication between the Verifier and the Repairer must be determined. Typical implementations of this mechanism include the publication of a repair service by the Repairer that is invoked by the Verifier.It can be concluded that the Verifier can be seen as a filter applied over all the data received, and it can be used to reject data for any reason (incorrect, redundant…) by using the aforementioned rule engine and based on the ontology model proposed in Section 3.2.5.The task of the Repairer is to fix incorrect data detected by the Verifier. The repair applied to the data must always consider the defined ontology and can be performed in a wide variety of ways, such as:•Ignore data. The first option is to ignore the data, which means setting it with an unknown value. The Ontologizer saves this value as required by the storage system (e.g. the Weka-arff‘?’ character, or the SQL null value).Adjust data. If a value is incorrect, but its distance from a correct value is less than a previously specified threshold amount, then the value could be adjusted to the nearest correct value.Replace data. Another option involves replacing data with previously correct data (e.g. if temperature sensor returns 100°C, and previous data is 25, then the current value can be replaced with 25).Reject data. If current values are not suitable for repair, then the Repairer will reject them.Once a set of data has been received, verified and repaired, it has to be sent to the Ontologizer to be organized and stored.Sometimes, not all the data received from the environment is necessary for the reasoning process, and hence the ontology dismisses this information. This is the objective of the filter: to prevent this superfluous information from being sent to the Ontologizer. The implementation of this filter, if present, should be based on the ontology defined for the representation of the environment.An ontology represents the knowledge about the world (or environment) as a set of classes, properties and relationships, within a domain. The reasoning is performed using the entities represented, and hence data retrieved from the environment should be organized before applying artificial intelligence techniques in order to have a solid knowledge base with which to work.The main goal of the Ontologizer is to organize, homogenize, synchronize and aggregate data to form a model of the real world supported by the ontology defined for the SE.It is necessarily an important effort for building a model of a SE which provides data interoperability and makes possible to realize inference, as suggested by Nucci [29] where an ontology framework is used to describe all relevant information of the environment: devices, services and context. It also tackled the further difficulty for device manufacturers because of the lack of standardization in semantic technologies within these scenarios. Energy is another key aspect to take into account for the ontology as proposed by Kofler [30], where ontology includes information not only related to the environment, but also about energy supply and provider.Some other studies like Cook [3], Das [21] and Li [22] have helped in the composition of the abstract model proposed, which has been arranged into four main categories as explained in Table 1. This model can help developers ascertain the main entities that need to be monitored in the environment.Device related — This category is the most obvious, and it is related with the main elements in a SE. Ambient intelligence algorithms should be aware of the following main fields:•Status. Algorithms must know the current states of devices installed in the SE. Obviously this is essential for these algorithms, and one of the prime factors for building of future predictions. Energy aware algorithms may also need information about energy needed by these devices to operate in order to apply any energy saving policy.Location. Devices usually remain at a location for a long time, and hence this information can be used by ambient intelligence algorithms. The model must also be able to handle mobile devices, such as motorized cleaner robots.Inhabitant-related — SE algorithms must be aware of the inhabitants' status to offer appropriate predictions for any user or for the whole group of inhabitants. Along this line, several of the necessary fields to infer inhabitant-aware predictions are discussed:•Personal data. This field includes all the data concerning a particular person, such as name, age, and gender.Location. Inhabitants can move between different spaces, so SE systems should be able to identify and locate each inhabitant.Physical state. This field is related with the illnesses and injuries that an inhabitant can suffer. SE technologies must adapt to these situations and offer appropriate responses.Mental state. The state of mind of a person can be defined as the temporary psychological state. The behaviour of a depressed inhabitant usually differs from that of a euphoric inhabitant, and hence SEs must be consistent with these circumstances.Environment-related — This category is probably the most diffuse since it covers heterogeneous and difficult-to-limit fields, as discussed in the following list:•Date, time, season. Obviously SE behaviour differs under each temporal condition. For example, the air conditioning policy is altered between summer and winter.Environmental conditions. This field is comprised of current environmental conditions (sunny, cloudy, rainy, among others). A SE should also request a weather forecast, which could be significant in the assessment of future decisions.Home background — This category must contain all the relevant items regarding inert entities and their properties and qualities. This category is the least relevant discussed, but could remain significant in certain specific applications. Two related fields are proposed in the following listing:•Furniture location and position. Furniture occupies space at home and can be moved. Location (room where the furniture is located) and position (place within the room) should be registered by the smart home systems since it could be useful in specific applications, such as robot movement-related algorithms, and presence detection-related algorithms.Home limits and properties. The texture of a floor, the colour of a wall, and the opacity of the windows could be significant in specific cases, such as temperature-adjustment applications.There are yet two more issues concerning the Ontologizer: Synchronization and Aggregation.Synchronization — The Ontologizer has to synchronize data from a world full of asynchronous devices, and events. Response time constitutes a major factor when reasoning about events. Automation applications usually need sets of data composed of values from multiple devices, captured at various moments. Data from a variety of devices must be synchronized for its latter aggregation, and hence this task has to define the logic to synchronize values from multiple and very heterogeneous sources. Implementations of the synchronization process vary depending on the goals of each specific smart application and on its type of data. However all implementations share certain common elements such as:•Data buffer, which stores received data that is waiting to be paired with other data.Garbage collector, which supervises the size of the buffer, and periodically cleans the buffer of data that cannot be paired.Aggregation — Once data is synchronized, it is aggregated in a set of data for a specific smart application that conforms to the SE model. When data is aggregated, it is ready to be stored in the knowledge base that feeds the reasoning tasks and learning process. The knowledge base format can take the form of any of the de facto standards, such as arff (Weka software format file for input data), or that of a relational database.There is a gap that needs to be covered between the modules defined by the Reference Architecture and the physical devices. One interesting initiative which solves this problem is Device Abstraction. This is the result of previous work by authors within the OSAmI project [23].In Device Abstraction a device abstraction layer is provided which describes a set of standards and conventions for controlling, configuring and accessing the data generated from all kinds of devices related to Ambient Intelligence. The integration of sensors and actuators is provided by following the Device Abstraction model in their control software.This hierarchical model, shown in Figs. 4 and 5, unifies criteria in order to facilitate the access to the devices, their functionality, and their generated data. In this way, the methods used are independent of the underlying protocols, and allow easier device switching. The use of Device Abstraction is a step towards standardization of SEs.The primary role of Device Abstraction is the classification of devices in sensors and actuators. Sensors are categorized as either meters or detectors, while actuators depend on their functionality as pulse, switch, dimmer and movement. Each device category provides a set of specific methods for control of the device actions.There is still another software artefact between Device Abstraction and the devices: the API which translates high-level methods invoked in protocol-dependent requests. These APIs are usually provided by device manufacturers.Reasoning processes in SEs can be separated into several tasks which interact to achieve three main goals: a) to learn, b) to reason, and c) to predict.Finally, in order to close the circle, SEs must act automatically to achieve a specific smart application. This is the main purpose of the Acting process. The decisions and specific tasks ordered by the Reasoning process, have to pass through three main taskmasters: a) policy manager, b) task scheduler, and c) task runner.In order to feed both Reasoning and Acting processes, an event-driven architecture paradigm (EDA) is proposed, in the form of a publishing-subscribe message system. Reasoning tasks are subscribers of data generated by Perception processes and Reasoning tasks are publishers of inferred knowledge. In this way, Acting tasks become subscribers of the knowledge generated by the Reasoning process.An example of the Perception process implementation, which follows the Reference Architecture proposed in this paper, is presented in this section as proof of its usefulness.The main objective of the application is the perception of a smart office. It retrieves data on the localization of workers, and on luminosity, temperature, and humidity (see Fig. 6). The purpose of the retrieval of this information is to acquire knowledge about inhabitants/workers regarding their habits with respect to lighting conditions, temperature, etc. in order to make smart use of artificial lighting for energy saving purposes.The hardware of the development environment is composed of:•a computer, which acts as the data receiver gateway,three Sentilla Tmotes (two in the office as shown in Fig. 6 and a third in another office), as sensor devices for the collection of data on the quantity of light, temperature, and humidity,an X10 motion sensor in order to determine whether the office is occupied,IEEE 802.15.4 (ZigBee) protocol bridge connected to the computer in order to communicate with the Sentilla Tmotes,X10 transceiver to communicate with actuators and the motion sensor.The software of the development environment is composed of: Sentilla Work, which is an Eclipse-based IDE for the creation, deployment, and debugging of ubiquitous applications; Weka, a tool suite which facilitates the use of machine learning techniques; and the developed software based on the proposed Reference Architecture and on the Device Abstraction Model as the software paradigm for the device management software.The software developed by the authors follows the Reference Architecture outlined in Section 3 and is focused on the Perception process detailed in Section 3.2. This software therefore follows the tasks proposed in the Perception process and is responsible for the low-level interaction with devices (Data Collector task), in the form of verification, repair and filtering of the data, and of the storage of the data by aggregating several data sources and by following the Device Abstraction Model. The software itself is distributed between various devices, and hence a number of these tasks are performed by the central computer while others are performed by the Sentilla Tmotes.Sentilla Tmotes implement a Java Virtual Machine (JVM) called Sentilla Point so that it can run Java applications. In order to access the hardware capabilities of the device, Sentilla offers a Java library which provides access to the data gathered by the sensors and other elements such as extension ports and leads. This low-level software constitutes the device API which is used by the software to access devices. The Java application run by Tmotes accesses sensor data and transmit it via the Zigbee interface. The sensors form a mesh network where motes act as repeaters. This type of network makes it possible to cover wide areas even though Zigbee protocol has a radio scope of a mere 10m.When developing this application, it was observed that the quantity of luminosity (measured in luxes) captured by its photosynthetically active radiation (PAR) sensor fluctuated if the fluorescent light of the office was left switched on. The reason for this behaviour is that fluorescent light is constantly switching off and on but it is not perceptible by the human eye due to its high frequency. However, this behaviour posed a problem with the software, so it had to be tackled and included as a part of the Repairer task (see Section 3.2.3) at this point. The solution is quite simple: instead of retrieving just one value, n values are retrieved and their average is computed and then sent to the central gateway.In order to receive all the information from the Sentilla motes, an application has been developed, which implements the appropriate interfaces in each case: MotionDetector, TemperatureSensor, BrightnessSensor, or HumiditySensor.Moreover, the authors have developed software for the central station called Mote Dashboard. This software shows the information that is being received from the motes in real time. This application carries out all the main tasks of the Perception process in Section 3.2. A summary of the classes and interfaces of the implementation is shown in Fig. 7:1.Data collector. This process is responsible for managing the reception of data from the motes, and for using the mote gateway supplied with the development kit, and an X10 controller developed by the authors.Verifier. Three simple verifiers have been developed and perform simple tests, similar to preconditions, over data received from TSR-PAR luminosity, humidity, and temperature sensors (e.g. luminosity≥0).Repairer. When the verifier task detects erroneous data, as mentioned above for luminosity, the Mote Dashboard software chooses between two options:Replace. If previously correct data was received a short time before, then specific erroneous values are replaced with previous values. The time difference is customizable. Note that the software developed by the authors and run in the Tmotes also repairs wrong values retrieved by the PAR lighting sensor in the class FluorescentLightRepairer, due to the fluorescence issue explained earlier.Reject. On the other hand, if previously correct data was received only a long time before, then current erroneous data is rejected.Filter. In this particular case, no superfluous information is received, and hence the Filter of this applications does not remove any data.Ontologizer. Finally, correct data is processed and stored by the Ontologizer task. This performs three operations:Synchronization. A buffer of data received from every mote in SensorsSynchronizer is retained. When information from outdoor and indoor motes is taken at approximately the same time, then it is synchronized by the aggregation subtask.Aggregation. Once data is synchronized, it is added to the same instance of the input defined in Section 4.2.4 Input and output.Store. Finally, the Dashboard software stores all instances in arff format and also in SQL in the relational database, since these are useful for machine learning tools, such as Weka [24].Mote Dashboard has other minor functionalities:•Show information. The information received from the motes is displayed in a Graphical User Interface (GUI) (Fig. 8), and a list of active motes is shown in the mesh network.Reset. Resets the Dashboard GUI. This does not affect stored data, but cleans buffers and GUI of all data received.A relational database has been chosen to store the data retrieved. It currently uses MySQL due to its simplicity and free cost, and since the specific application does not require a powerful database manager. MySQL organization also offers a Java Database Connectivity (JDBC) connector driver for free, which is a requirement of both the application and of Weka.Table 2shows the input variable X proposed and two sets of sample input data:•Outdoor lighting. This variable represents the quantity of light received from the outdoor Sentilla Tmote sensor. Continuous variables from 0 to 1.Indoor lighting. This variable represents the quantity of light received from the indoor Sentilla Tmote sensor. Continuous variables from 0 to 1.Indoor light state. This variable represents the state of the artificial lights of the room as received from the X10 appliance module. Discrete variables; 0 for lights off, and 1 for lights on.Blind state. This variable represents the state of the blinds or curtains. Continuous variables from 0 to 1; 0 for totally closed and 1 for totally open.Motion. This variable represents the detection of motion sent by the MS13A X10 device. Discrete variables; 0 for no motion, 1 for motion detected.Action over light. This variable represents the action carried out by the user regarding the indoor artificial lights. Discrete variables; −1 lights switched off, 0 no action, +1 lights switched on.Action over blind. This variable represents the action carried out by the user regarding the blinds/curtains. Continuous variables; −1 means the user closed it totally, 0 no action, +1 means the user opened it totally.Threshold. Represents the current user's lighting preference. Discrete variables;0 represents minimum room lighting, 1 represents maximum room lighting.Once the implementation of the prototype is presented, we analyse the benefits of the approach and the Software Architecture presented. In summary, the results are very satisfying due to the improvements achieved following the paradigms described above. These improvements and benefits were analysed in comparison to the development of this software following general software development architectures, such as OSGi Reference Architecture. The development team is composed of a Software Architect, a senior programmer and a junior programmer. Once the development was finished, another junior programmer added certain functionality to the software. During the development, the improvements that can be indentified include:1.Design time savings. Once the Software Architect studied the paradigms of the Software Architecture, then the essential issues that had to be tackled were understood, and future development problems were identified from the outset. For example, the synchronization and aggregation of perceived data were solved within the design itself.Development time savings. Since developers understood the architecture and could work independently from each other, both time and cost were minimized. In this case, one developer was in charge of programming solutions for Data Collector, Verifier and Repairer, since the other developer focused on Filter and Ontologizer. From the experience of the Software Architect, the developers worked more swiftly.Maintenance time decreased. Since the software was of a modular nature, changing, modifying or improving the software artefacts was child's play. Understanding code was also easier, since every artefact fulfils specific responsibilities.Modularity of development improved. The separation of responsibilities was delivered on separation of software artefacts. This constitutes one of the most obvious benefits.Reusability of software artefacts. Since development was separated by responsibilities, artefacts developed can be easily reusable for further developments. Some of them can also be distributed as components in order to be used by other developers such as data collectors, verifiers of lighting, humidity or temperature measurements, or the fluorescent light repairer.Ease of extension. When another developer, not previously involved in the original version of the software, had to make modifications and improvements, the ease of understanding of the software architecture proved very useful in order to ascertain why certain solutions were adopted, where they were applied, and which points of the Perception process were involved.Bug detection and identification improved. Related to reduced time of maintenance, searching for bugs in the source code was straightforward, since any malfunction in the software could be swiftly matched with the corresponding tasks of the Perception process.In short, benefits in the general cycle of software are realized since not only developers accomplish their tasks, but goals of the development are also achieved, which implies that this Software Architecture is highly recommendable. Let the reader notice these improvements.

@&#CONCLUSIONS@&#
In this work, a general Reference Software Architecture for a SE is presented, which identifies Perception, Reasoning and Acting as the most important areas involved in SE applications.The alternatives for the techniques used in the implementation of the perception process are presented, explained and referenced.The objective of this paper is to define the Software Architecture for the Perception process as a framework for SEs. This Architecture should be followed in order to accomplish successful solutions for the implementation of this kind of software. This Software Architecture is intended to produce benefits, as shown through verification with a prototype.Future work on this matter should advance in three ways. The first is to describe Reasoning and Acting processes in the same way as Perception has been described in this paper. Second, a framework based on this Software Reference Architecture could be implemented, which facilitates SE implementation solutions by providing common services and supporting several modules, as information, communication and control systems. And third, innovative techniques could be developed for each of these modules related to previously described processes.Other important areas which should be taken into account within the framework include user interface and security. Both areas are vital for a complete smart environment experience. Further challenges involve not only enabling the SE to fit user preferences, but also applying it to change behaviour in the individual which could, for example, arm the community with sustainability policies for future SEs, through teaching inhabitants to be more environmentally aware.