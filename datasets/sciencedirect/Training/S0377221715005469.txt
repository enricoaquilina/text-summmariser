@&#MAIN-TITLE@&#
Sensitivity analysis: A review of recent advances

@&#HIGHLIGHTS@&#
We review several sensitivity methods for operational research.Local sensitivity methods provide insights into a deterministic mindset.Global sensitivity methods provide insights under uncertainty.The methodological steps for rigorous application are addressed.

@&#KEYPHRASES@&#
Sensitivity analysis,Simulation,Computer experiments,

@&#ABSTRACT@&#
The solution of several operations research problems requires the creation of a quantitative model. Sensitivity analysis is a crucial step in the model building and result communication process. Through sensitivity analysis we gain essential insights on model behavior, on its structure and on its response to changes in the model inputs. Several interrogations are possible and several sensitivity analysis methods have been developed, giving rise to a vast and growing literature. We present an overview of available methods, structuring them into local and global methods. For local methods, we discuss Tornado diagrams, one way sensitivity functions, differentiation-based methods and scenario decomposition through finite change sensitivity indices, providing a unified view of the associated sensitivity measures. We then analyze global sensitivity methods, first discussing screening methods such as sequential bifurcation and the Morris method. We then address variance-based, moment-independent and value of information-based sensitivity methods. We discuss their formalization in a common rationale and present recent results that permit the estimation of global sensitivity measures by post-processing the sample generated by a traditional Monte Carlo simulation. We then investigate in detail the methodological issues concerning the crucial step of correctly interpreting the results of a sensitivity analysis. A classical example is worked out to illustrate some of the approaches.

@&#INTRODUCTION@&#
The solution of several managerial problems involves the creation of dedicated decision support models (models, henceforth). In supporting the solution of decision analysis problem, the model is typically an influence diagram, or a decision tree (Bielza & Shenoy, 1999). In the risk assessment of complex operational systems, the model takes the form of a Bayesian network, of a binary decision diagram or of a fault tree. Convex, linear or dynamic programming support decision making in production, inventory management, logistics (Bertsimas & Sim, 2004; Tan & Hartman, 2011; Wendell, 1985). Business plans help analysts in determining the financial viability of joint ventures and investment projects (Baucells & Borgonovo, 2013). The perspective becomes even broader if one regards this exercise in the context of scientific modeling. In this case, a scientific model reproduces the behavior of a certain system or portion of the real world. The model might be based on a theory which explains the phenomenon at hand. An important account of the role of sensitivity analysis in the broad scientific literature is given in Rabitz (1989). In the operational literature history, an outstanding (and early) example is represented by Ford W. Harris’ economic order quantity model (Harris EOQ, henceforth) (Harris, 1990). Harris applies the scientific method to the problem of determining the optimal lot size in a production system, obtaining the well known expression of the total system cost(1)T=1240M(CX+S)+SX+Cwhere S is the setup cost of an order, M is the number of units used per month (the movement of the stock(Harris, 1990, p. 947)), and C is the unit price of items in the stock, the number 240 is the interest charge per unit, per month, corresponding to a yearly interest rate of 10 percent (Harris, 1990, p. 948)). By manipulation, the well known economic order quantity (EOQ) is given by(2)X*=240MSCwhich leads to the optimized cost(3)T*=(S240M+C)2.We shall use Harris EOQ model throughout this work as an illustrative example. Harris EOQ has been generalized to include alternative aspects of the problem, in an important and still active research stream of subsequent operations research literature (Cárdenas-Barrón, Chung, & Trevi no-Garza, 2014). Harris himself was, however, well aware that the model does not exhaust the decision process: But in deciding on the best size of order, the man responsible should consider all the factors that are mentioned [...] Hence, using the formula as a check, is at least warranted (Harris, 1990, p. 947).Little (1970) in addressing the relationship between managers and models observes that, of course, it is not the task of the manager to build the model. However, Little notes that it is important for a manager to be able to correctly interrogate the model. In fact, it is through this questioning process that the manager becomes acquainted with the model behavior and confident in using the model for decision making. Conversely, using the words of Little (1970, p. B469), a manager “wants to know why. A process starts of finding out what it was about the inputs that made the outputs come out as they did ”.From a general, scientific perspective, sensitivity analysis is the set of methods that allow us to understand key insights of scientific codes: “The judicious application of sensitivity analysis techniques appears to be the key ingredient needed to draw out the maximum capabilities of mathematical modeling” (Rabitz, 1989, p. 221). The need to use sensitivity analysis methods emerges even more sharply in recent applications.The increase in computing power allows analysts to create mathematical models of increased sophistication. Given the complexity of the codes, it is not possible for the analyst to grasp the response of the model output to variations in the model inputs based on the sole intuition. Fürbringer (1996) asks rhetorically: “Sensitivity Analysis for Modelers: Would you go to an orthopedist who did not use X-Ray? ”, highlighting the need to look into the model black box. (Samuelson, 1941, p. 97) suggests: “In order for the analysis to be useful it must provide information concerning the way in which our equilibrium quantities will change as a result of changes in the parameters”.Aware of these issues, several institutions and agencies such as the (EPA, 2009, p. 19), the Florida Commission on Hurricane Loss Projection Methodology (Iman, Johnson, & Watson, 2005), the NRC (2009), health organizations as CADTH (2006), Cochrane (Higgins & Green, 2011) and NICE (2013) recommend the use of sensitivity and uncertainty analysis methods as part of best practices to ensure the overall quality of the modeling process.The variety of problems that have been addressed through scientific modeling and the wide set of interrogations which are possible for these models has led, over the past years, to the development of several sensitivity analysis methods. Some methods are quantitative and model free (Saltelli, 2002a), some methods are specifically tailored to the type of mathematical problem implied by the model (e.g., the tolerance sensitivity approach for linear programming).Here, it is worth to point the reader to previous reviews that either precede or complement our work. Earlier reviews of sensitivity methods in interdisciplinary contexts are offered also by Saltelli, Ratto, Tarantola, and Campolongo (2005) and Saltelli, Ratto, Tarantola, and Campolongo (2012). Aven and Nøkland (2010) review the use of global sensitivity methods in reliability applications. Filippi (2010), Tan and Hartman (2011), Kleijnen (2010), Borgonovo (2013) offer earlier reviews of sensitivity analysis in linear programming, discrete dynamic programming, simulation and decision-analysis respectively. A review on robustness analysis is offered in Rosenhead (2011), and on sensitivity analysis in dynamic programming in Gal and Greenberg (1997).We highlight that a crucial step for a meaningful sensitivity analysis is the clear statement of the insights that we wish to obtain from the model. We then carry out a systematic investigation about the questions that have been most widely asked in the literature. We review old sensitivity settings and propose new ones that help to make crisp the link between sensitivity methods and sensitivity insights.The remainder of this article is organized as follows. Section 2 discusses the sensitivity analysis jargon and notation. This section serves as a general reference for the remaining sections. Section 3 discusses local and derivative-based sensitivity methods. Section 4 offers an overview of different sensitivity strategies under a fully probabilistic setting. Section 5 discusses computational aspects and presents a common framework for several of the global sensitivity measures introduced in this work. Section 6 offers a view on the philosophy of sensitivity analysis. Section 7 provides a discussion on additional relevant aspects and uses of sensitivity analysis. Section 8 offers final considerations.The standard setup of sensitivity analysis is as follows. The model is regarded as a mapping between the model inputs and the model outputs. These model outputs are the quantities of interest for the decision-maker. Let us say that there are n model inputs and D model outputs. We denote them byx={x1,x2,⋯,xn}andy={y1,y2,⋯,yD}. Formally, we write(4)y=g(x)whereg:X→YwithX⊆RnandY⊆RD. We will callXthe model input space.As for terminology, we find alternative names for x and y depending on the field of application. For instance, in Economics they are called exogenous and endogenous variables, respectively. There, comparative static is a widely used synonym for sensitivity analysis, after the seminal article of Samuelson (1941). In Engineering studies, x is often called the vector of parameters. In Statistics, the term factors or covariates might be used for x. The model is the mapping that binds x and y. To illustrate, we consider Harris EOQ in a sensitivity analysis framework. The model output, y, is the optimal order quantity (X* in Harris EOQ), the model inputs are the units per month (x1, M in Harris EOQ), the unit price of items in the stock (x2, C in Harris EOQ), and the setup cost of an order (x3, S in Harris EOQ). We write:(5)y=240x1x3x2.In this case, it ism=1andn=3,because we have one model output and three model inputs. However, if we consider also the total order cost at the optimum (T*) as an output, we havem=2andn=3. In the reminder, we shall letα={i1,i2,⋯,ik}denote the subset of indices of a group of k model inputs (k ≤ n).xα={xi1,xi2,⋯,xik}denotes the vector of k model inputs with indices in α. To denote the complementary set of model inputs, we shall use the symbol ∼ α. The sensitivity of a model output with respect to xiis often synthesized in a number, which is referred to as the sensitivity measure of xi. When the sensitivity measure is used to rank model inputs based on their influence on then model output, it is called an importance measure.If one is interested in performing the analysis around a point of interest in the model input space, then one is performing a local sensitivity analysis. We call x0 the base case (or reference value) of the model inputs. To illustrate, we consider again Harris EOQ, with the reference point x0 of the copper connector example in Harris (1990). We havex1=1230pieces per month, a unit pricex2=$0.0135 per unit, a setup cost of $2.15 leading to the model outputy0=g(x0)=6856. Clearly, for consistencyx0∈X. A local sensitivity analysis is carried out in a deterministic framework, that is, no probability distributions are assigned to the model inputs.The simplest way to interrogate a model is to study the model output when we vary one model input at a time. This approach originates the so-called one-at-a-time (OAT) methods. The procedure is straightforward. We assign a base case (x0) and a sensitivity case (x+) to the model inputs. The corresponding vector of model input changesΔ+x=x+−x0=(Δ+x1,Δ+x2,⋯,Δ+xn). Then, we calculate the model by varying one model input at a time from the base case to the sensitivity case. The sensitivity measures are then the quantities(6)Δi+y=g(xi+Δxi+,x∼i0)−g(x0)where(xi+Δxi+,x∼i0)is the point inXobtained shifting xialone to the sensitivity case. From a general perspective,Δi+yare finite changes in y provoked by individual changes in the model inputs.The sensitivity measures in Eq. (6) quantify the effect of the shift in xifrom the base case to the sensitivity case. The insights delivered by these sensitivity measures concern both the magnitude of the impact and the direction of change. To illustrate, in our example, the base case isx0=(1230,0.0135,2.15). If we suppose that, in our sensitivity case, the model inputs undergo a 10 percent increase, the sensitivity case becomesx+=(1353,0.01485,2.365). If we consider the variation in x1 alone, we obtain the corresponding model output changeΔ+y1=y(1353,0.0135,2.15)−y0=335. That is, a 10 percent increase in x1 generates an increase of 335 units in the optimal order quantity. Similarly, for the remaining model inputs, we obtainΔ+y2=−319andΔ+y3=y(1230,0.01485,2.15)−y0=335meaning, respectively, that a 10 percent increase in x2 and x3 provokes a decrease of 319 units and an increase of 335 units in EOQ, respectively.The most successful graphical representation of one-at-a-time (OAT) results is represented by Tornado diagrams. In a Tornado diagram, we represent the sensitivity measures in Eq. (6) as horizontal bars, sorted from the largest to the smallest. The introduction of Tornado diagrams is due to Howard (1988). A detailed description of their implementation is provided for by Eschenbach (1992). Actually, in a Tornado diagram we represent two series of OAT sensitivities, hypothesizing a second sensitivity case (worst case),x−. We then have a second set of model input changes,Δ−x=x0−x−=[Δ−x1,Δ−x2,⋯,Δ−xn]. The sensitivity measures represented in a Tornado diagram are, then,Δi+yin Eq. (29) andΔi−y=g(xi−Δxi−,x∼i0)−g(x0). The computational cost of a complete Tornado diagram is, then,C=2n+1model runs.Graph (a) in Fig. 1 displays the sensitivity measures obtained with the two series of OAT variations for the Harris EOQ. We observe that the direction of change is reversed in the shift fromx0→x−,i.e., the shift from the base case to the worst case [the sensitivity measures areΔi−y; bars in lighter color in graph (a) of Fig. 1], with respect to the shift from the base case to the best case [the sensitivity measures areΔi+y; bars in darker color in graph (a) of Fig. 1]. Not only, but the effects are not symmetric and in the shiftx0→x−,the key driver becomes x2, which ranked after x1 and x3 in the shift fromx0→x+. This result shows that the conclusions about sign of change and key-drivers that we may infer from an OAT approach are limited to the specific pair of points under consideration.We conclude with the following observation. The overall value in Harris EOQ for the changex0→x+isΔy+=335. However, if we sum the sensitivity measures of the Tornado diagram we obtainΔ+y1+Δ+y2+Δ+y3=350≠335. The difference is due to the fact that the sensitivity measures of a Tornado diagram neglect interaction effects. These sensitivity measures have been generalized in subsequent literature, as we discuss in the next subsection.In several practical applications, managers (and scientists) explore scientific codes on alternative values of the model inputs, i.e., on alternative scenarios. It is common to find reports in which the results produced by a model are presented with the model inputs fixed at a base case, a worst case and a best case scenario. In assessing the model over these scenarios, the manager wishes to understand the response of the model to extreme variations of the inputs. However, scenario analysis in the operational research literature has also been studied from a broader perspective to guide strategic planning. According to Jungermann and Thuring (1988, p. 117), Scenarios are descriptions of alternative hypothetical futures: They do not describe what the future will be (i.e., they are not prognoses) but which alternative futures we might reasonably imagine. According to O’Brien (2004), they are different states of the world in presence of uncertainty. Scenarios are different possible future states of a system in Tietje (2005). Over time, scenario analysis has become a major decision tool in economics and strategic management. For general perspectives on scenario analysis, we refer the interested reader to the monograph of Schwartz (1996). We refer to O’Brien (2004) and Tietje (2005) for the methodological perspectives. In particular, according to Tietje (2005), scenarios must be consistent, diverse, in a small number, reliable and efficient.When we come to quantitative modeling, scenario analysis implies to fix the model inputs at two or more predetermined points in the model input space. To illustrate, the points x0,x+andx−can be seen as three possible scenarios. Then, in a scenario analysis we obtain the three valuesy(x+),y(x0) andy(x−). By this quantitative information, we get to know the new values of the model outputs and we can appreciate whether the model output has increased or decreased. However, we are not able to quantitatively explain what has caused the change.The methods we are to review in this section address this problem. Consider the generic change in model outputΔy=g(x+)−g(x0). A possible way to decompose this change in an exact fashion and through a finite number of terms is represented by using a finite differences approach (see Borgonovo 2010b for greater details on the mathematical aspects). One then writes(7)Δy=∑i=1nϕi+∑i<jϕi,j+⋯+ϕ1,2,⋯,nwhere(8){ϕi=g(xi+;x∼i0)−g(x0)ϕi,j=g(xi+,xj+;x∼i,j0)−ϕi−ϕj−g(x0)ϕi,j,k=g(xi+,xj+,xk+;x∼i,j,k0)−ϕi,j−ϕi,k−ϕj,k−ϕi−ϕj−ϕk−g(x0)⋯Eq. (7) decomposes the finite change in model output into the 2nterms given in Eq. (8). For the termsϕi,j,⋯,kone can use the term finite change sensitivity indices (Borgonovo, 2010b). They have the following meaning: ϕirepresents the individual effect of varying one model input at a time from the base case to the sensitivity case. Hence, we immediately have that(9)ϕi=Δi+ythat is, first order finite change sensitivity indices are the sensitivity measures of Tornado diagrams. ϕi, jrepresents the residual interaction effect due to the simultaneous variation of xiand xj. In fact,g(xi+,xj+;x∼i,j0)−g(x0)is the change in model output due to the simultaneous variation of xiand xj, from which we subtract the changes provoked by the individual variations. The higher order sensitivity indices possess a similar interpretation. To illustrate, let us compute ϕ1, 3 for Harris EOQ. We haveg(x1+,x3+;x20)−g(x0)=686from which we need to subtract the individual effects of x1 and x3 , obtainingϕ1,3=686−335−335=16. Thus, there is a positive interaction between x1 and x3. This means that the simultaneous change in these two model inputs amplifies their individual effects. Proceeding in a similar way, we obtain the remaining second order effects:ϕ1,2=ϕ2,3=−16. The residual effect ϕ1, 2, 3 can be computed from(10)ϕ1,2,3=g(x+)−g(x0)−ϕ1,2−ϕ1,3−ϕ2,3−ϕ1−ϕ2−ϕ3=335+16−16+16−335−335+319=0.Thus, there is no interaction term of order 3. One can define the total finite change indices for a generic model input as(11)ϕiT=ϕi+∑j=1nϕi,j+∑k=1n∑j=1nϕi,j,k+⋯+ϕ1,2,⋯,n.To illustrate, for Harris EOQ, we have(12)ϕ1T=335;ϕiT=350;ϕiT=335.If, from the total order indices, we subtract the indices of order 1, we obtain the interaction indices(13)ϕiI=ϕiT−ϕi=∑j=1nϕi,j+∑k=1n∑j=1nϕi,j,k+⋯+ϕ1,2,⋯,n.The interaction indices condense in one indicator the interaction effects of model input xiwith all the remaining model inputs and model input groups.One can conveniently represent this information in a so-called generalized Tornado diagram (Borgonovo & Smith, 2011). In the diagram, for each model input, we represent a triplet of bars, displaying ϕi,ϕiTandϕiI,that is, the first, total and interaction effects. That is, in each triplet, the first bar is the same as in a traditional Tornado diagram. By a generalized Tornado diagram, an analyst can rank model inputs based on their total effects and has a visualization of the relevance of interactions. The sign of interactions let us grasp whether the individual effects are amplified or dampened by interactions.To illustrate, we report the generalized Tornado diagram for the Harris EOQ in Fig. 1. In this case, we sort the model inputs based on the absolute value of the total order indices. The second model input, x2, now ranks as most important, followed by x1 and x3 . The reason is that the indices now include also interaction and not only individual effects. In fact, Graph b) in Fig. 1 shows that the only model input for which interaction effects matter is x2, which is associated with a non-nullϕiI≈−32. This interaction effect is the same for both model input shifts, from x0 tox+and from x0 tox−. Consider now thex0→x+shift. In this case, the individual effect of x2 is a negativeϕ2=−319,that, summed to interaction effects leads to a total effect ofϕ2T=−350,making x2 the most important input for the shiftx0→x+.Let us now come to computational cost. Computing the total and interaction effects by calculating the sensitivity indices of all orders is equivalent to performing a full factorial design with two levels. The associated computational cost is 2nmodel runs and makes the estimation infeasible for models with a large number of inputs. However, it is possible to estimate the first, interaction and total order finite change sensitivity indices at a cost of2n+2model runs [see Borgonovo (2010b) for the proof]. In particular, we obtain the total order finite change sensitivity indices starting atx+and shifting the model inputs one at a time fromx+to x0. Thus, (finite change) total effects are obtained at a cost ofn+1model runs. Because first order effects are obtained at the same cost, and the interaction effectsϕiIare obtained by subtraction, the cost of computing the triplet of sensitivity measures ϕi,ϕiIandϕiTis2n+2model runs. Then, if this operation is repeated twice (once for thex0→x+and once for thex0→x−shift), the overall cost is4n+3model runs.The sensitivity measures of Tornado diagrams foresee to register the values of the model output at the extremes of the variation ranges of the model inputs. An alternative approach is to register the values of the model output while the input varies over the entire predetermined range. In this case, the “sensitivity measure” is the function(14)hi(xi)=g(xi;x∼i0)hi(xi) is called a one-way sensitivity function. Sensitivity functions can be graphed either individually or condensed in the same plot. In this second case, we are dealing with a so-called spiderplot graph (Eschenbach, 1992) . In a spiderplot, one displays the functions:(15)hi*(xi)=hi(xi)−g(x0)=g(xi;x∼i0)−g(x0)over normalized ranges of the model inputs. Observe that the sensitivity functions of spiderplots are the sensitivity measures of Tornado diagrams evaluated at alternative values of xi, that ishi*(xi)=ϕi=Δ+y1(xi). Thus, a spiderplot can be also seen as providing the values of first order sensitivity indices as the model inputs vary in the predetermined ranges.One-way sensitivity functions are applied in several fields, but they have been particularly studied in association with Bayesian networks, where they convey information about systematically varying one of the network’s parameter probabilities while keeping all other parameters fixed (van der Gaag, Renooij, & Coupé, 2007, p. 104). Castillo, Gutiérrez, and Hadi (1996) and Castillo, Gutiérrez, and Hadi (1997) obtain analytic expressions for the sensitivity functions of Bayesian network polynomials, exploiting the inherent multilinear structure. One way sensitivity plots for influence diagrams solved through decision circuits are discussed in Bhattacharjya and Shachter (2008). The concept of one-way sensitivity functions can be extended to multiple ways sensitivity plots (called n-way sensitivity plots), which are a multidimensional version of one-way sensitivity plots. We refer to Kjaerulff and van der Gaag (2000) for further discussion on n-way sensitivity functions.An important class of sensitivity analysis methods is represented by differentiation methods. As stated in Kleijnen (2010, p. 1), local changes enable the estimation of the gradient which plays an important role in simulation optimization and, more generally, to the derivation of managerial insights. The rationale for differentiation methods consists in the Taylor series expansion of the model output. This is clearly formalized in Helton (1993). Here, Δy can be decomposed as:(16)Δy=g(x+)−g(x0)=∑i=1n∂g(x0)∂xi(xi+−xi0)+12∑i=1n∑k=1n∂2g(x0)∂xi∂xk(xi+−xi0)(xk+−xk0)+o(∥x+−x0∥2).If the variationsxi+−xi0are small enough so that second order terms can be neglected, thenΔy≈∑i=1n∂g(x0)∂xi(xi−xi0)and∂g(x0)∂xithen become natural sensitivity measures. Partial derivatives are the sensitivity measures we are probably most familiar with. These are the sensitivity measures of Samuelson’s comparative statics (Samuelson, 1947). They play an extremely important role in reliability analysis where they are given the name of importance measures. Reliability importance measures support decision makers in several operational settings: regulators in risk-informed decision-making, and plant managers in decisions concerning graded quality assurance programs, equipment prioritization for maintenance and inspections, etc. (Brewer & Canady, 1999; Cheok, Parry, & Sherry, 1998). Unfortunately, there is no room in this review to enter into a full fledged description of system reliability notation. Then, we will follow an intuitive approach. Consider that y represents the probability of system failure and that xiis the failure probability of a given component. Then, Birnbaum introduces the concept of a component being critical to a system as the probability that the component is in such a state that its failure causes the whole system to fail. Then, Birnbaum proves that, if failures are statistically independent, then the probability that component i is critical is equal to the partial derivative of y with respect to xi(Birnbaum, 1969). The Birnbaum importance measure is, historically, the first reliability importance measure. We recall the Fussell–Vesely, the risk achievement worth and the risk reduction worth importance measures, and refer to Fussell (1975), Vesely, Kurth, and Scalzo (1990), Cheok et al. (1998) for a thorough discussion. The work of Nøkland and Aven (2013) presents a systematic overview about the selection of reliability importance measures best suited to the application at hand. We also refer the reader to the monograph on importance measures by Kuo and Zhu (2012). Let us apply partial derivatives to Harris EOQ. We obtain:(17)∂g(x0)∂x1=2.787,∂g(x0)∂x2=−2.539·105,∂g(x0)∂x3=1.595·103.Note that if we were to consider the magnitudes of partial derivatives and utilize them to rank model inputs, we would conclude that x2 is by far the most important model input. However, the partial derivatives are not comparable, because they are denominated in different units. Thus, they cannot be used to rank the model inputs. A way to circumvent this limitation is to use the fraction of the differential (i.e., the entire term∂g(x0)∂xi(xi−xi0)) instead of just the rate of change∂g(x0)∂xi. A sensitivity measure that accounts for these facts is the differential importance measure (Borgonovo & Apostolakis, 2001):(18)Di=∂g(x0)∂xidxi∑j=1n∂g(x0)∂xjdxjwhich is the fraction of the differential change in the model output. Under the assumption of uniform perturbations [dxi=dxjfor all i and j], the differential importance measure produces equivalent ranking as partial derivatives [Borgonovo and Apostolakis (2001)]. Under the assumption of proportional perturbations, the differential importance measure produces the same ranking as elasticity Borgonovo and Peccati (2004). The elasticity of y with respect to xiis defined as(19)Ei=∂g(x0)∂xixi0g(x0)Then, if we assume proportional model input changes, we havedxixi0=dxjxj0for all i and j. Multiplying and dividing the numerator and denominator of Eq. (18) byxi0andxj0,respectively, we obtain(20)Di=∂g(x0)∂xidxixi0xi0∑j=1n∂g(x0)∂xjdxixj0xj0=∂g(x0)∂xixi0g(x0)∑j=1n∂g(x0)∂xjxj0g(x0)=Ei∑j=1nEj.In reliability analysis, the elasticity Eiis called criticality importance measure. To illustrate, in our running example, assuming proportional perturbations, we obtain the following differential importance measures for the model inputs:(21)D1=1,D2=−1,D3=1.The identical magnitudes of the sensitivity measures suggest that the model inputs are equally important, with x2 having, however, an opposite effects on Harris EOQ with respect to x1 and x3.A convenient property of the differential importance measure is additivity. One retrieves the importance of any group of variables as sum of the individual sensitivity measures of the variables in the group. We refer to Borgonovo and Apostolakis (2001) for further details.Now, consider the ratio between ϕiand Δxiand take the limit forxi+→xi0,we obtain(22)limxi+→xi0ϕiΔxi=limxi+→xi0Δi+yΔxi=∂y(x0)∂xi.Similarly, if we consider the ratioϕi∑j=1nϕjwe obtain(23)limxi+→xi0ϕi∑j=1nϕj=limxi+→xi0Δi+y∑j=1nΔj+y=Di.The above equations state the relationships among differentiation-based importance measures and finite change sensitivity indices for infinitesimal perturbations of the model inputs. They also show that partial derivatives and the differential importance measure do not account for interactions. The literature has then proposed several ways of extending differentiation based sensitivity measures to account for interactions, computing higher order derivatives. One is referred to the works of Hong and Lie (1993), Armstrong (1995) , Lu and Jiang (2007), Gao, Cui, and Li (2007), for extensions of partial derivatives to higher order sensitivity measures. In particular, the joint differential sensitivity measure of order k (called joint reliability measure of order k in reliability studies) is defined asJαk=∂kg(x0)∂xi1∂xi2⋯∂xikand provides that strength of the local interaction between model inputsxi1,xi2,⋯,xik. Zio and Podofillini (2006), Do Van, Barros, and Berenguer (2008), Borgonovo (2010a) propose extensions of the differential importance measure to higher order. Diis extended to order 2 in Zio and Podofillini (2006) and to order k in Do Van et al. (2008). Borgonovo (2010a) introduces the total order importance measure (DiT) which synthesizes all joint sensitivity measures of all orders in a unique index. For infinitesimal changes,DlT→Dl,that is, the total order importance tends to the differential importance. If the model is infinitely many times differentiable, then it can be proven thatDlTand total order finite change sensitivity indices provide identical information. Conversely, when the model is not smooth, information about the effects of finite changes is provided by finite change sensitivity indices alone, which remain defined also when the model presents discontinuities. If the model is differentiable once and changes are small, then finite change sensitivity indices and total order sensitivity provide identical information, and this information coincides with the information provided for by the differential importance measure. As for estimation, differentiation can be either performed through brute force algorithms or through automated procedures (Bischof and Bücker, 2000; Griewank and Walther, 2008, see also www.autodiff.org). In this respect, the availability of automatic differentiation codes allows us to obtain partial derivatives at a relatively low computational cost, making the analysis feasible in most practical applications for which the model output is smooth.The methods illustrated in Sections 3.1, 3.2 and 3.4 address the variation of a model around one point in the model input space. Thus, they do not permit a thorough exploration of the model behavior as the inputs vary at several locations inX. Screening methods, instead, foresee the evaluation of the model at a limited number of locations inX. The goal of a screening design is to identify the least important model inputs, while maintaining a parsimonious number of model evaluations. Several reviews on screening methods are available in the literature. We refer to Campolongo, Kleijnen, and Andres (2000, chap. 4); Kleijnen (2009); 2010); Kleijnen, Sanchez, Lucas, and Cioppa (2005). These reviews also show the strict link between screening methods and design of experiment (DOE). An application of DOE in the sensitivity analysis for investment evaluation models used in the energy sector is represented by van Groenendaal and Kleijnen (1997). It is not possible to enter into the details of the numerous screening designs that have been proposed. However, in the management science literature, particular attention has been devoted to sequential bifurcation which has been introduced in Bettonvil (1990) as a supersaturated sequential design of experiments (see also Bettonvil and Kleijnen, 1997). Sequential bifurcation works efficiently under the hypothesis listed in Kleijnen (2010). In particular, the main assumption in the original version of sequential bifurcation is that the model response is well fitted by a first order degree response surface, possibly containing interaction terms. A second assumption is that the direction of the influence that a factor has on the output is known (Bettonvil and Kleijnen, 1997, p. 183). Then, sequential bifurcation proceeds by first varying all model inputs from the base case to the sensitivity case and computing the corresponding effects. The model inputs are then split into two groups. One then repeats the analysis varying the model inputs in the first group from the base case to the sensitivity case. If the results of the analysis show that the group is unimportant, then the group is discarded from further analysis and attention is restricted to the second group. The works of Bettonvil (1990) and Bettonvil and Kleijnen (1997) have generated a stream of subsequent literature, making sequential bifurcation a successful method for sensitivity analysis in simulation. In particular, we recall the works of Wan, Ankenman, and Nelson (2006) and Wan, Ankenman, and Nelson (2010), which introduce the controlled sequential bifurcation procedure.A further successful screening method is the method of Morris (1991) that considers segmenting the model input ranges[xi−,xi+]in l levels. This segmentation generates a grid into the model input space which, for simplicity, is assumed to be the unit hypercube. Given l levels with n model inputs, we have a total of lnpoints in the grid, from which a subsample of r points is drawn at random. For each of the r points, the model is evaluated performing a series of OAT sensitivities. The sensitivity measures, called elementary effects in Morris (1991), are the difference quotients in Eq. (22). The elementary effects are then averaged over the r points in the trajectory. This discussion illustrates the main intuition of the method. Additional technical details about the design are found in Morris (1991), Campolongo et al. (2000), Campolongo and Saltelli (1997). The computational cost of a complete Morris design (in which model inputs are increased and decreased with respect to the base case value) isC=2n·rwhere r is the number of replicates. We estimated the elementary effects based on Morris design using a four level design with 32 replicates and the open source software SimLab (2011). One obtains sensitivity measures very much in agreement with partial derivatives, as in the original spirit of the method (see the discussion about the meaning of elementary effect at Morris (1991, p. 163)).Campolongo, Cariboni, and Saltelli (2007) propose an amelioration of the Morris method using a normalized version of the elementary effects. The normalization avoids cancellation effects making the identification of the most important model inputs more robust.The screening methods presented so far are using a deterministic framework. Adding a probabilistic setup, the randomized evaluation of partial derivatives is studied for derivative-based global sensitivity methods in Sobol’ and Kucherenko (2010) and Rakovec, Hill, Clark, Weerts, Teuling, and Uijlenhoet (2014).The methods that we have discussed upto now are intrinsically deterministic. The underlying mindset precludes the assignment of a probability distribution to the model inputs. In this respect, it is worth noting that several authors have argued both in favor and against the assignment of probability distributions for sensitivity analysis. van Groenendaal and Kleijnen (1997) maintain the usefulness of using a deterministic approach when the state of knowledge does not allow the analyst to confidently assign distributions to the model inputs. The trade-offs between using a deterministic method that has the advantage of not requiring the assessment of model input distributions, against the use of methods that require a full fledged probabilistic distribution assignment are discussed thoroughly in Wallace (2000). A comparison between deterministic design of experiments and probabilistic methods is offered in van Groenendaal and Kleijnen (2002). In all those situations where it is possible to assign a probability distribution to the model inputs, one can resort to the rich set of probabilistic (or global) sensitivity methods.The fundamental assumption of a probabilistic sensitivity analysis is that we assume to have information about the model inputs’ probability distribution, either joint or marginal, with or without correlation (Saltelli and Tarantola, 2002, p. 704). Then, we introduce the probability space(X,B(X),PX),wherePXis the probability distribution of the model inputs. Here, the model input spaceXcoincides with the support of the distributionPX. The model inputs become a random vector which is denoted byX=(X1,⋯,Xn),so thatx=(x1,⋯,xn)denotes one of the possible realizations. FX(x) denotes the joint cumulative distribution function of the model inputs. If the model inputs are absolutely continuous, fX(x) is the corresponding joint density.FXi(xi)andfXi(xi)denote the corresponding marginal cumulative distribution function and density, respectively. We denote by σithe standard deviation of model input Xi. If the inputs are independent, we can decompose the distribution viaFX(x)=∏i=1nFi(xi).Uncertainty in the model inputs makes y a random variable, which we denote byY=g(X). Its distribution and moments are obtained by propagating uncertainty in X through the map g,PY(·)=PX(g−1(·)). Ideally, this propagation can be performed analytically. The corresponding cumulative distribution function is FY(y) and fY(y) denotes the probability density, if Y is continuous. We denote the model output standard deviation by σYthe variance of the model output. However, in most practical situations, and especially when the closed form expression for g( · ) is not available, uncertainty propagation is performed numerically through Monte Carlo simulation. We generate a random sample of size N × n that follows the distribution of the model inputs and evaluate the model output in correspondence of each realization of X. We then obtain a sample of size N × D, representing N realizations of the model outputs. By this sample, it is possible to obtain the empirical cumulative distribution function (density) of the model output.To illustrate, for Harris EOQ with a support of plus/minus 10 percent and uniform distributionsXi∼U[0.9·xi0,1.1·xi0],withN=10,000Monte Carlo runs, we obtain the distribution and density in Fig. 2.If the probabilities assigned to the model inputs are representative of our degree of belief about X, then the distribution and density in Fig. 2 represent our degree of belief about Harris EOQ. The mean value of Y is 7027 and its standard deviation isσY=167.However, several methods have been developed to answer additional questions that help both decision makers and analysts to dig deeper into the obtained results, to extract insights on key uncertainty drivers, direction of change, relevance of interactions, etc., also in the presence of uncertainty. We shall detail the most used ones: non-parametric methods, variance-based, moment independent, value of information-based methods and Monte Carlo filtering.Non-parametric methods using linear regression techniques are, chronologically, the first class of global sensitivity methods which have been intensively investigated (Helton, 1993; Saltelli & Marivoet, 1990). One of the reasons of the success of non-parametric methods is the fact that these sensitivity measures can be directly estimated from a given Monte Carlo sample (Helton & Davis, 2003). Hence, the analyst can proceed with a Monte Carlo simulation and then estimate non-parametric sensitivity measures by post-processing the obtained input–output sample. No particular design is required in the estimation of non-parametric techniques. Their cost is equal toC=Nmodel evaluations, where N is the size of a Monte Carlo sample. The rationale for non-parametric methods is linear regression.Assume that the input–output sample is well fitted by a linear regression model. Then, the input–output mapping can be approximated by the response surface (see the monograph by Montgomery (2000))g(X)≈b0+∑i=1nbiXi. Then, as Helton (1993) and Kleijnen and Helton (1999b) underline, the standardized regression coefficient (SRC) becomes a natural sensitivity measure:(24)SRCi=biσiσYwhere σiand σYdenote the standard deviations of the model input Xiand the model output Y, respectively. A second widely used non-parametric sensitivity measure is Pearson’s product moment correlation coefficient(25)PEARi=ϱ(Y,Xi)=Cov(Y,Xi)σiσY=∑j=1N(xji−x¯i)(yj−y¯)∑j=1N(xji−x¯i)2∑j=1N(yj−y¯)2for a given sample{(xj1⋯,xjn,yj)|j=1,⋯,N}. If we assume that model inputs are independent then SRCiand Pearson’s correlation coefficient coincide. A related sensitivity measure is given by the explanatory power of the linear fit which is expressed by the coefficient of determination or goodness-of-fit (RY2).RY2is the fraction of the model output variance explained by the regression.For Harris EOQ with an input uncertainty of plus/minus 10 percent and uniform distributionsXi∼U[0.9·xi0,1.1·xi0]the regression hyperplane is given byφ(x1,x2,x3)=3.43·103+2.79x1−2.55·105x2+1.60·103x3. This yields standardized regression coefficients ofSRC1=SRC3=0.58andSRC2=−0.58. The goodness-of-fit here amounts toRY2=0.998. Let us now modify the example by assuming that x2 has an uncertainty range of ± 30 percent. The coefficients of the regression model change only slightly, however, the regression coefficients now yieldSRC1=SRC3=0.29,SRC2=−0.90withRY2=0.985.Further members of the non-parametric family are discussed in Helton (1993); Helton, Johnson, Sallaberry, and Storlie (2006b); Saltelli and Marivoet (1990); Storlie, Reich, Helton, Swiler, and Sallaberry (2013); Storlie, Swiler, Helton, and Sallaberry (2009). A comparison between non-parametric and screening methods is offered in van Groenendaal and Kleijnen (2002).In general, the ability of non-parametric methods to capture variability can be measured byRY2,the model coefficient of determination. If a too low value ofRY2is registered, then we have a poor regression fit. Under these conditions, Campolongo and Saltelli (1997) suggest that it might become unrealistic to assess influence of the input variables based on SRC’s. In general, when the input–output mapping is characterized by the presence of non-linearities and interactions (Saltelli & Marivoet, 1990), the regression fit tends to be weak.The use of rank transformation can improve the reliability of non-parametric techniques (see Iman and Conover (1979) for a discussion of the use of rank transformation in regression; see also Saltelli and Sobol’ (1995) on a more general perspective on the use of rank transformation in global sensitivity analysis). On the use of rank transformation for improving the performance of non-parametric methods, we refer to Helton et al. (2006b). If we replace the model output with the corresponding ranks and compute the Pearson correlation, we obtain the Spearman correlation coefficient (Spearman, 1904). This sensitivity measure allows for detecting nonlinear monotonic dependencies. In fact, the sign of the Spearman correlation coefficient suggests whether Y is (statistically) increasing in Xi. Moreover, ifY=g(X)is a univariate monotonically increasing function of the X, then Spearman correlation coefficient is equal to unity. More generally, one can consider linear regression coefficients derived from transformed variables. Optimizing over all suitable transformation leads to the maximum correlation coefficient,supφ,ψϱ(φ(Y),ψ(Xi))where φ, ψ run over functions with finite and positive variance (Rényi, 1959).The intuition that the robustness of the ranking induced by non-parametric methods is measured by the model coefficient of determination, can be seen as linking non-parametric methods with the class of variance-based sensitivity measures. In fact,RY2is a ratio of variances. Then, if one introduces sensitivity measures that are able to apportion variance to the contribution of each model input, one has, intuitively speaking, a class of sensitivity measures whose coefficient of model determination is unity. In the next section, we discuss variance-based sensitivity methods.Variance-based sensitivity methods assess the importance of a model input based on the expected reduction in the model output variance provoked by knowing the value of the model input with certainty. From a formal viewpoint, variance-based sensitivity methods are based upon the well known variance decomposition formulaV[Y]=V[E[Y|Xα]]+E[V[Y|Xα]]which separates the output variance into the explained variance due to the dependence on a parameter group Xαand the residual variance. These methods employ a non-linear non-parametric regression curve or surfaceφα(xα)=E[Y|Xα=xα]. The corresponding goodness-of-fit measure is given bySαgroup=V[φα(Xα)]V[Y]. As in the linear case,Sgroupαcorresponds to the fraction of output variance which is explained by a functional dependence on xα. Ifα={i},thenSi=S{i}groupis called the main effect or first order index (Saltelli, Ratto, Andres, Campolongo, Cariboni, Gatelli, Saisana, & Tarantola, 2008). Compared to a linear regression, we haveSi≥βi2. Indeed, Fréchet (1934) has shown thatSi=ϱ2(Y,E[Y|Xi]). Higher order effects are defined by the sole contribution of interactions between the factors of an index set α defined recursively bySα=Sαgroup−∑β⊊αSβ. The indexSiT=1−S∼igroupis called the total effect. This describes the fraction of output variance that is left unexplained if Xiand only Xiis allowed to vary in its range. The total effect supplies sufficient information to decide whether a factor is unimportant. For uncorrelated inputs, we haveSiT≥Si,∑i=1nSi≤1. In order to cope with further group effects, Liu and Owen (2006) introduce the notion of subset and superset importance measures. Group effects are used to determine the effective dimension of the model (Caflisch, Morokoff, & Owen, 1997; Owen, 2003). This information can be used to reduce the model complexity (Wang, 2006; Wang & Sloan, 2011).Historically, variance-based sensitivity measures have been defined in alternative disciplines. Variance-based sensitivity measures of order 1 (Si) have been defined by Pearson (1905) and are known under the name of correlation ratio. Pearson introduces them to overcome limitations of the linear regression coefficient in the presence of non-linearities. However, the estimation of Pearson’s correlation ratio is difficult without a computer and only with the rise of computing machinery and with the simulation revolution in applied sciences this measure has regained interest. The idea of using variance reduction to define sensitivity measures, in fact, becomes predominant in the early 1990s. In the field of Risk Analysis, Iman and Hora (1990) define variance-based sensitivity measures asIHi=V[E[Y|Xi]]. IHiis the numerator of Pearson’s correlation ratio. In the same years, Sobol’ (1993) defines variance-based sensitivity indices in the context of high-dimensional integration. The definition of Sobol’ assumes a product measure, i.e., independence among the model inputs. In Operations Research, Wagner (1995) introduces first and total order variance-based sensitivity measures, without relying on the independence assumption. We observe that Sobol’ (1993), Iman and Hora (1990) and Wagner (1995) arrive at similar definitions almost simultaneously but independently, as there are no cross-citations and, moreover these works do not cite Pearson’s original work. Nonetheless, if we wish to be even more historically accurate, all these works are preceded by the seminal work of Cukier, Fortuin, Shuler, Petschek, and Schaibly (1973), where variance-based sensitivity measures are used in the context of scientific modeling for the first time.Revisiting Harris EOQ with an uncertainty range of ± 30 percent forx20and of ± 10 percent for the other two factors, we estimate first order effects by computing the goodness of fit for the regression curves, see Fig. 3. We obtainS1=0.087,S2=0.826,S3=0.087. AsSi≈βi2and∑i=13Si≈1the model is essentially additive and linear. This is also supported by the scatterplots in Fig. 3. However, visual inspection of scatterplots might become cumbersome if the number of input factors is large. Kleijnen and Helton (1999a, 1999b) suggest the use of scatterplots to as an initial step (as a visual sensitivity screening exercise) of a broader sensitivity exercise that goes beyond simple visual examination, and foresees the use of non-parametric regression and correlation-based techniques [see also Helton et al. (2006b)].An all-in-one-method is the use of curves which show the contribution to the sample mean (csm) or the cumulative sum for reordered normalized output (cusunoro). The output permutation is given by increasingly ordering the input of interest (Bolado-Lavin, Castaings, & Tarantola, 2009; Plischke, 2012a). An example is the lower right plot in Fig. 3 showing curves for all three parameters at once. The curves for x1 and x3 coincide, again supporting the finding that their sensitivity is the same. A link to first order effects can be established via the averaged squared gradient of these curves. Variance-based sensitivity measures are intertwined with the functional ANOVA decomposition. The seminal result of Efron and Stein (1981) proves that a multivariate mapping g, integrable on(X,B(X),μ),can be decomposed as follows:(26)g(x)=g0+∑i=1ngi(xi)+∑i<jgi,j(xi,xj)+⋯+g1,2,⋯,n(x1,x2,⋯,xn)where(27){g0=∫…∫g(x)dμgi(xi)=∫…∫g(x)∏k≠idμk−g0gi,j(xi,xj)=∫…∫g(x)∏k≠i,jdμk−gi(xi)−gj(xj)−g0⋯In the broad context of scientific modeling, functional ANOVA is at the basis of the high dimensional model representation theory, which plays a fundamental role in global sensitivity analysis. This theory is developed in the works of Rabitz and Alış (1999), Li, Wang, Rosenthal, and Rabitz (2001), Alış and Rabitz (2001), Sobol’ (2003). Under independence, the gα(xα) functions in Eq. (26) are orthogonal (Sobol’, 1969). By orthogonality,V[Y]=E[(g(X)−g0)2]may be written as(28)V[Y]=∑αVαwithVα=∫Xα[gα(xα)]2fα(xα)dxα.By Eq. (28), the terms in the variance decomposition are the second moments of the gαfunctions. Thus, the ANOVA decomposition of the model input–output mapping, g( · ), is in one-to-one correspondence with the decomposition of its variance. As properly stated in Oakley and O’Hagan (2004, p.753), under independence, variance decomposition reflects the structure of the model itself. In the presence of correlations, however, the tidy correspondence between functional decomposition and variance-decomposition is lost. Technically, if the integration measure is not a product measure, orthogonality cannot be exploited to eliminate cross products, and we cannot obtain the variance decomposition from the functional ANOVA decomposition. Moreover, Bedford (1998) shows that, if correlations are present, Eq. (26) is no more unique. Oakley and O’Hagan (2004) and Saltelli and Tarantola (2002) offer examples in which correlations generate spurious terms in the functional ANOVA expansion that are not associated with a corresponding functional dependence in the model input–output mapping.In particular, Saltelli and Tarantola (2002) propose the following input–output mapping,y=x1+a23x2x3where a23 is a non-vanishing coefficient. Then, under the assumption that X1 and X2 are correlated, the first order variance-based sensitivity measure of X1 would register a contribution from the term a23x2x3. This dependence does not pertain to the model structure (and would not be registered if X1 and X2 were uncorrelated), in so far as the input–output mapping is additive with respect to X1. The study of variance-based sensitivity measures in the presence of dependencies among the model inputs is attracting increasing attention. Several authors have recently proposed alternative approaches and research is actively ongoing (Chastaing, Gamboa, & Prieur, 2012; Kucherenko, Tarantola, & Annoni, 2012; Li & Rabitz, 2012; Mara & Tarantola, 2012). The literature has also observed that a null value of Si(or Vi) does not reassure the analyst that the model output is independent of Xi. A family of functions for which this is observed is presented in Plischke, Borgonovo, and Smith (2013). This family generalizes the well known Ishigami test function, widely used in sensitivity analysis studies (Ishigami & Homma, 1990). We finally point out an interpretation issue that has appeared in association with variance-based sensitivity measures. Their popularity has led authors to interpret variance-based sensitivity measures as the expected reduction in uncertainty due to observing xi(Oakley & O’Hagan, 2004, p. 753). However, it is well known that uncertainty in a random variable cannot be summarized by one of its moments. In particular, variance is sufficient to characterize variability or risk either under the assumption of normal distributions or under the assumption that the utility function of the decision-maker is quadratic (Huang & Litzenberger, 1988). In general, electing a moment as representative of uncertainty may lead to misleading conclusions also in sensitivity analysis (see Borgonovo, 2006, for an example).Sensitivity measures that consider the entire distribution without reference to a particular moment are called moment-independent methods. The intuition is as follows. If we let all model inputs free to vary in accordance with the assigned distributions, we obtain the unconditional model output density fY(y). For the EOQ model, assuming uniform distribution over the plus 10 percent increase, we obtain the unconditional density in the left plot of Fig. 4 (continuous line; red). Suppose then, that we are informed that model input Xiis fixed at its base value,x10=1230. We obtain the conditional model output density represented by the dotted line in the left graph of Fig. 4. Then, one can measure the effect of fixing X1 atx1=1230by introducing a distance between these two densities. The works of Chun, Han, and Tak (2000); Park and Ahn (1994) use, respectively, the Kullback–Leibler distance and a Minkowski distance of order 2 to measure the separation between the unconditional model output density and the density conditional on fixing a model input at a sensitivity case. Alternatively, if one uses the L1 norm, one would measure the gray area enclosed between the two curves in Fig. 4 (Borgonovo, 2007). However, the valuex1=1230is not the only value that X1 can assume. Then, the definitions in Park and Ahn (1994), Chun et al. (2000) would lead to sensitivity measures whose value depends on the chosen sensitivity case. Conversely, one has as many conditional densities as there are possible values of Xi. To illustrate, the right graph in Fig. 4 plots the conditional densities of Harris EOQ obtained by fixing X1 at 10,000 randomly sampled values. This graph provides a visual intuition of the impact on the decision-maker’s degree of belief about Y provoked by fixed X1. Then, the sensitivity measure can be made independent of the sensitivity case by considering the expected distance over all possible values of the model input. This is achieved by averaging according to the marginal distribution of X1. The first representative of the class of density-based sensitivity measures is the δ-sensitivity measure, defined as (Borgonovo, 2007)(29)δi=12E[∫Y|fY(y)−fY|Xi(y)|dy].The definition of δ in Eq. (29) does not require independence between the model inputs. In Eq. (29), the quantityγi(xi)=∫Y|fY(y)−fY|Xi=xi(y)|dyis the area enclosed between the conditional and unconditional model output densities obtained for a particular value of Xi(left graph in Fig. 4). γi(xi) is called inner statistic (or inner separation). Eq. (29) suggests that δiis non-negative and normalized between zero and unity (0 ≤ δi≤ 1 ). Moreover, the joint δ of all model inputs is equal to unity. That is, removing uncertainty in all model inputs leads to the highest possible effect.Eq. (29) can be rewritten in symmetric form as (Plischke et al., 2013)(30)δi=12∫Xi∫Y|fY,Xi(y,xi)−fY(y)fXi(xi)|dydxi.Eq. (30) shows that δ measures the distance between the joint distribution of Xiand Y (fY,Xi(y,xi)) and the product of their marginal distributions (fY(y)fXi(xi)). In this respect, it has been ascertained that δiis a stronger measure of statistical dependence than Pearson’s linear correlation coefficient or correlation ratio (first order variance-based sensitivity measures). In fact, one can prove thatδi=0if and only if Y is independent of Xi. That is, δiis null if and only if Y (the model output) is independent of Xi[see Plischke et al. (2013)]. Thus, a null value of δireassures the analyst that the model output is independent of Xi.By its properties, δiis attracting increasing research attention, and especially its estimation has been the subject of investigation in several works. As for estimation, we recall the works of Castaings, Borgonovo, Morris, and Tarantola (2012); Liu and Homma (2010); Luo, Lu, and Xu (2014); Zhang, Lu, Cheng, and Fan (2014). Recently, Zhai, Yang, Xie, and Zhao (2014a) propose a generalization of δibased on the Minkowski distance of order p among cumulative distribution functions.Finally, δiis monotonic transformation invariant. This is a convenient property, especially in estimation, as we are to discuss in the next subsection.A second popular choice to obtain a transformation invariant global sensitivity measure is represented by using the Kullback–Leibler divergence to measure the discrepancy between the conditional and unconditional model output densities. In this case, one defines the inner separation as(31)γiKL(Xi)=∫YfY|Xi(y)(logfY|Xi(y)−logfY(y))dyto obtain the sensitivity measure(32)θiKL=E[∫YfY|Xi(y)(logfY|Xi(y)−logfY(y))dy]To our knowledge, the first work proposing a global sensitivity measure based on the Kullback–Leibler divergence is Critchfield and Willard (1986). The work discusses a medical decision making application. Later works, such as Auder and Iooss (2009); Krzykacz-Hausmann (2001); Liu, Chen, and Sudjianto (2006); Park and Ahn (1994); Tang, Lu, Jiang, Pan, and Zhang (2013), discuss the use of the sensitivity measure in Eq.(32) in different fields of application.The sensitivity measure in Eq. (32) possesses similar properties as the δiimportance measure. In particular,θiKL=0if and only if the model output Y is statistically independent of Xi, andθiKLis monotonic transformation invariant.The reason for this last result is that, as shown in Borgonovo, Tarantola, Plischke, and Morris (2014) (see also Da Veiga, 2015), bothθiKLand δiare based on inner statistics which are members of the family of Csiszar divergences:(33)γiCsiszar(Xi)=∫YfY|Xi(y)t{fY(y)fY|Xi(y)}dywhere t is, by definition, convex and such thatt(0)=1,giving rise to the class of sensitivity measures(34)θiCsiszar=E[∫YfY|Xi(y)t{fY(y)fY|Xi(y)}dy]Specifying alternative forms for the convex function t, one obtains alternative metrics which are all monotonic transformation invariant. For instance, settingt(s)=|s−1|(total variational distance), one finds the δiimportance measure (Borgonovo et al., 2014) or settingt(s)=(s−1)2,one finds the Hellinger distance (Da Veiga, 2015). Other specifications lead to the Pearson’sX2divergence, and the NeymanX2divergence (Da Veiga, 2015).A general viewpoint on transformation invariance is offered in the next section.The literature has shown that transformation invariance is a convenient property for a global sensitivity measure. In realistic applications, it is not infrequent that the model output is sparse or ranges across several orders of magnitude. In these situations, numerical convergence of global sensitivity estimators might not be at reach for reasonable sample sizes. Analysts then resort to monotonic transformations. As Iman and Hora (1990, p. 402) observe, The scaling problem most often can be overcome by performing uncertainty importance calculations based on a logarithmic scale.... Rank transformations (see Iman and Conover, 1979; Saltelli and Sobol’, 1995) are also typically used. In fact, transformations lead to an accelerated numerical convergence and improve estimation accuracy at a given sample size.We say that a functionU=u(Y)is a monotonic transformation of the model output if u( · ) is a monotonically increasing (or decreasing) function of its argument. For instance, in a logarithmic transformation, we haveU=log(Y). Clearly, this transformation applies for all random model outputs with support included inR+.From a sensitivity analysis viewpoint, performing calculations on a transformed model output (or, in general on a transformed random variable) introduces the problem of reinterpreting results back on the original scale, a problem already identified in Iman and Hora (1990). First, a transformation changes the structure of the input–output mapping. For instance, consider a product model(35)Y=X1·X2⋯XnThe model is clearly non-additive (it is, actually made of a unique interaction term). Then, consider the log-transformation of this model:(36)U=log(Y)=log(X1)+log(X2)+⋯+log(Xn),The input–output mapping is now additive and no interactions are present. Clearly, sensitivity analysis insights obtained for the transformed model are not directly transferable to the original model. Moreover, numerical experiments in Borgonovo et al. (2014) show that we are not guaranteed that the ranking of a model input is the same on the original and the transformed scales. However, in the case the adopted sensitivity measure were transformation invariant, then its results would be independent of the transformation. An analysts could then benefit from the accelerated numerical convergence, while avoiding the problems of transferring results back to the original scale.Let ξi(Y) [ξi(U)] denote the generic sensitivity measure of model input Xiwhen the model output Y [U]. As in Baucells and Borgonovo (2013), we say that a sensitivity measure is monotonic transformation invariant if(37)ξi(U)=ξi(Y)for all monotonic transformationsU=u(Y).Transformation invariant global sensitivity measures are obtained if one adopts an inner statistic which is transformation invariant. Baucells and Borgonovo (2013) introduce two sensitivity measures based on the Kolmogorov–Smirnov and Kuiper distances between cumulative distribution functions, defined as(38)βiKS=E[supy|FY(y)−FY|Xi(y)|]andβiKu=E[supy{FY(y)−FY|Xi(y)}+supy{FY|Xi(y)−FY(y)}]These sensitivity measures possess a managerial interpretation in terms of probability of success and failure, as discussed in Baucells and Borgonovo (2013). Alternative metrics lead to transformation invariant sensitivity measures. For instance, if one uses the Anderson and Darling (1952) and Mason and Schuenemeyer (1983) modifications of the Kolmogorov–Smirnov metric, or the modification proposed in Crnkovic and Drachman (1996) of the Kuiper metric, one obtains sensitivity measures which are transformation invariant (see Baucells and Borgonovo (2013) for further discussion on metric choice). In this respect, a general family of monotonic transformation invariant metrics is defined in Borgonovo et al. (2014) as:(39)z(P,Q)=supA∈Ah(|P(A)−Q(A)|)wherePandQare two probability measures on measure space(Ω,A)andh:R≥0→R≥0is a continuous and non-decreasing mapping such thath(0)=0andsupth(2t)h(t)<∞. The family in Eq. (39) encompasses the variational distance (Strasser, 1985),z(P,Q)=supA∈A|P(A)−Q(A)|,and the set of Birnbaum–Orlicz metrics whose main representative is the Kolmogorov–Smirnov metric (see Borgonovo et al. (2014) for the proof). One also obtains transformation invariant sensitivity measures using inner statistics based on divergences between densities, as we have discussed in the previous section. Historically, the first transformation-invariant sensitivity measure is the Spearman coefficient (Spearman, 1904). Clearly, ranks or empirical cumulative distribution functions are natural monotonic transformations. This idea directly leads to bivariate copulas. Now, copula theory is sometimes described as the study of transformation-invariant properties. In particular, the δ measure is discussed in a copula framework in Wei, Lu, and Song (2014).Monotonic transformation invariance has also notable decision analysis implications. In several applications, the preferences of a decision maker should be expressed not through model output Y itself, but through a utility function on Y, u(Y). It is well known that assessing the exact functional form of u(Y) might become a cumbersome task in complex problems. However, the traditional assumption that u( · ) is a monotonically increasing function of its arguments, can be exploited to obtain a notable simplification of sensitivity analysis. If we employ a monotonic transformation invariant sensitivity measure, the obtained results hold identical for Y and u(Y), provided that u( · ) is a monotonic function. In particular, results are unaffected by errors in the specification of u(Y) (Baucells & Borgonovo, 2013). We conclude this section observing that, to our knowledge, the literature has focused on transformation invariance within a global sensitivity analysis context. However, transformation invariance might be useful in a local sensitivity as well. Nonetheless, none of the local sensitivity measures discussed in this review possesses the transformation invariance property.The operational research literature has pointed out the distinction between value and decision sensitivity. The distinction is discussed in Felli and Hazen (1998). In a value sensitivity, the analyst is interested in quantifying the change in model output due to a change in the model inputs. In a decision sensitivity, the analyst is also interested in assessing whether the optimal plan (or strategy) changes. Thus, sensitivity measures such as variance-based, density-based and distribution-based are value sensitivity measures. However, in several decision-analysis problems the decision-support models explicitly consider the selection among a set of D possible choices. D can be a continuous or discrete set, however, we shall consider a discrete set of alternatives, for notation simplicity. Suppose that we are considering alternative inventory management policies. Then, we estimate the payoff for each policy through the dedicated model. We then select the policy that maximizes the payoff. In general, let yd(d=1,2,⋯,D) be the estimate produced by the model of the quantity of interest (payoff, loss, utility or whatever criterion the decision maker chooses to support her analysis) under policy d. Then, the model input–output mapping becomesYd=gd(X),d=1,2,⋯,D. Then, the problem solved by the decision-maker is(40)maxd=1,2,⋯,D{E[Yd]}=maxd=1,2,⋯,D{E[gd(X)]}.wheremaxd=1,2,⋯,D{E[Yd]}is the expected payoff.In this context, the effect of getting to know Xiis not only a change in the distribution of each of the Yd’s, but, also, a change in the optimal plan. The sensitivity measures we have discussed so far do not capture this change. The sensitivity measure that captures both decision and value sensitivity is the partial expected value of perfect information (Felli & Hazen, 1998; Oakley, 2009; Strong & Oakley, 2013). Value of information has been introduced in Howard (1966), as the difference between the expected profit that we shall obtain as a result of the clairvoyance and the expected profit that we would obtain without the clairvoyance on Xi. Formally, one writes(41)ϵi=E[maxj{Yj}∣Xi]−maxj{E[Yj(X)]}.Several properties of value of information have been discussed in the literature. We refer the interested reader to the monographs of Bernardo and Smith (2000) and Pratt, Raiffa, and Schlaifer (1995) and to the work of Hazen and Sounderpandian (1999). A notable property proven in Howard (1988) is that the joint value of information of two random variables is given by:(42)ϵi,j=ϵi+ϵj|i=ϵj+ϵi|jEq. (42) suggests that the joint value of information of Xiand Xjis the sum of the value of information of Xi(Xj) and the value of information of Xj(Xi) conditional on getting to know Xi(Xj). Value of information has been applied in the most diverse contexts. Properties of value of information in stochastic programming are discussed in Avriel and Williams (1970), and sharp bounds are obtained in Huang, Vertinsky, and Ziemba (1977). In these works, the total value of information for resolving completely uncertainty in the model inputs is addressed. Partial value of information is proposed as a sensitivity measure in Felli and Hazen (1998) in a medical decision making context. It is also suggested as a sensitivity measure for decision-making in reliability by Pörn (1997). Recently, the works of Oakley (2009), Strong and Oakley (2013), Strong and Oakley (2014) address the estimation of value of information for complex computational codes.Monte Carlo filtering (Rose, Smith, Gardner, Brenkert, & Bartell, 1991) is a method which allows us to sort out model runs that fail to meet some predefined performance criteria. In the engineering literature such an approach is discussed under the label of reliability methods for structural safety (Madsen, Krenk, & Lind, 1986; Rackwitz, 2001). Here, the failure domain is given byXfail={x∈X:g(x)≤0}and one is interested in the failure probabilityPX(Xfail)=E[g(x)≤0]=FY(0). In applications, the limit state function is composed of load and resistance parts,g(x)=R(x)−L(x)where the load function models external stresses and the resistance function is derived from internal material and design parameters. The FORM/SORM methods compute a most probable point of failure on the limit state surface and approximate the limit state function by a linear or quadratic curve through this point to estimate the failure probability. The coordinates of the most probable point of failure are used as parameter sensitivity measures. A link to value-of-information based sensitivity is established in Straub (2014).The regionalized sensitivity analysis of Hornberger and Spear (1981) is comparing the conditional input distributions Fi(xi|Y ≤ 0) and Fi(xi|Y > 0) using a Kolmogorov–Smirnov test. If instead of 0, the failure region is described by an output quantile, then a graphical tool to study Monte Carlo filtering is the conditional cobweb plot. Due to the symmetry property in Eq. (30), we can also interpret δ as MC filtering method reporting the average change in the input distribution when conditioning on the output.In this section, we discuss the computation of sensitivity measures. Variance-based, density-based and value of information-based sensitivity measures have a common trait. They can be seen as operators between probability distributions Borgonovo, Hazen, and Plischke (2015). LetPbe a generic distribution and letζ(P,P)an operator between distributions that satisfies the conditionζ(P,P)=0. Then, one can represent a global sensitivity measure as composed of an inner statistic(43)γi(xi)=ζ(PY,PY|Xi=xi)whose value depends on the value assumed by Xiand an outer expectation. The inner statistic as a function ofxi∈Xiprovides regional sensitivity information. To obtain a global sensitivity measure, one then needs to carry out an outer expectation over the marginal distribution of model input Xi:(44)ξi=E[γi(Xi)].Eq. (44) is the global sensitivity measure of Xibased on operatorζ(·,·). To illustrate, Table 1shows the inner statistics associated with several global sensitivity measures resting on this common rationale.This table reads as follows. If we select as inner operatorγiEI(Xi)=max{μY|Xi,0}−max{μY,0}and average, we obtain the value of information global sensitivity measure. If we selectγiCR(Xi)=σY−2(μY−μY|Xi)2,and average, we obtain variance-based sensitivity measures, etc. Based on this common rationale, it is possible to address the properties of global sensitivity measures from a general perspective. For instance, can prove that a sensitivity measure is transformation invariant if and only if the inner operator is transformation invariant (Borgonovo et al., 2015).A first implication of the common rationale is that it opens the way to considering global sensitivity measures as measures of statistical dependence. Recently, Da Veiga (2015) proposes measures of statistical dependence based on the distance correlation and on the Hilbert–Schmidt independence criterion. These measures are also discussed in Lozzo and Marrel (2014). Fort, Klein, and Rachdi (2014) discuss the definition of sensitivity measures as subordinated to the machine learning notion of contrast. A second implication is that all global sensitivity measures falling under the common rationale can be estimated through the same computational design. This observation then leads us to discuss computational aspects.Sensitivity analysis and design of experiment regard the computational code at hand as a black box. Then, sensitivity measures need to be estimated numerically. By Eq. (44), an algorithm following the brute force definition of global importance measures requires a double loop of Monte Carlo evaluations. In fact, we need to take an “outer” expectation according to the marginal distribution of Xiof the inner statistic. The inner statistic in Eq. (43), in turn, requires a set of Monte Carlo runs to obtain numerical estimates of the unconditional distribution of the model output and of the conditional distribution given that Xiis fixed at xi. Numerically, we first sample Next values from the marginal distribution of model input Xi. Then, for each sampled value of Xi, we run the model Nint times to estimate the inner statistic. Thus, the computational cost for a brute force estimation is, in principle,C=nNintNextwhere n is the number of model inputs and Nint, Next are the sample sizes needed for the inner and outer loops, respectively. Assuming thatn=100,and at least 500 Monte Carlo runs are needed to obtain accurate estimates of the inner statistic and outer expectation, one obtains a total cost ofC=25,000,000. Such cost would make the estimation of probabilistic sensitivity measures impossible. The literature has then addressed the problem proposing a series of ameliorations.Much of the focus has been on the estimation of variance-based sensitivity measures. Here, we need to distinguish estimation strategies based on whether they require a specific design or not. The reason is practical. In the latter case, the analyst can use the results of a simple Monte Carlo propagation or the dataset of the model input–output generated through any scheme. In the former case, she needs to run the model according to a specific procedure and cannot profit or reuse model runs generated using a different scheme. In the first category, for variance-based sensitivity measures, we find the design of Sobol’ (1993), Jansen (1999), the design of Owen (2013), the FAST design Cukier et al. (1973); Saltelli, Chan, and Scott (2000a) and the random balance design (RBD) (Tarantola, Gatelli, & Mara, 2006). The design of Sobol’ and Jansen, improved in Homma and Saltelli (1996); Saltelli (2002a); Saltelli, Annoni, Azzini, Campolongo, Ratto, and Tarantola (2010), reduces the computational cost for first and total order sensitivity measures toC=(k+2)N.The Fourier Amplitude Sensitivity Test (FAST) design requires a particular generation of the inputs, based on a space filling curve that needs the assignment of different frequencies to the model inputs. The resulting output signal is then screened for resonances of these frequencies. The magnitude of these resonances accounts for the sensitivity of the associated model input. The FAST method allows for the estimation of variance based sensitivity indices at a cost ofC=1+2Mmaxi=1,⋯,nωiwhere M is the number of harmonics to consider (usually 4 to 8) and ωiare the frequencies of the curve. For the choiceωi=ω0i−1withω0=2M+1,contributions from all interaction terms can be identified. There are algorithms available that produce suitable sets of incommensurable frequencies which ignore higher interaction terms so that the computational costs can be reduced further.RBD uses ωi≡ 1 but employs different permutations for different input factors. Applying the appropriate permutation on the output, one is able to detect the resonances due to the associate input factor. Hence this method allows for the estimation of first order effects at the cost ofC=N, which is the minimum computational cost for a probabilistic sensitivity measure, that is, the size of a single Monte Carlo sample.Recent findings have shown that it is possible to achieve this estimation cost without recurring to a specific design, and using a so-called given data approach. For variance-based sensitivity, the EASI method can be thought of a reverse-logic RBD: The permutations are constructed from the given data (Plischke, 2010). The COSI method (Plischke, 2012b) simplifies this approach by replacing the fast Fourier transformation with a discrete cosine transformation.The intuition behind a given data approach can be illustrated as follows. We consider the dataset(X,Y)∈RN×(n+1)generated through a single Monte Carlo run. As we mentioned in Section 2, this is the dataset produced in an uncertainty analysis and from which we obtain the unconditional distribution of the model output. Then, from this dataset, we can produce the scatterplot of Xiand Y. The horizontal plane in Fig. 5displays the scatterplot obtained by projecting Y against X1 for the Harris EOQ model. The dataset is produced using a quasi-random sequence with sizeN=500.Then, we partition the X1-axis of the scatterplot, on the horizontal plane. Formally, we partition the support of Xiin M mutually exclusive subsetsXim(m=1,2,⋯,M), such that⋃m=1MXim=Xi,Xim∩Xiq=∅(m ≠ q ). Then, we substitute the point conditionXi=xiwith the bin conditionXi∈Xim. Intuitively, instead of imposing that Xiis exactly equal to xi, we are asking that Xiis in a partition bin that surrounds xi. Formally, we consider the bin conditional distributionFY|Xi∈Xim(y),instead ofFY|Xi=xi(y)(vertical axis in Fig. 5). One obtains the generic given data estimator:(45)ξ^i=∑m=1M(N)NmNζ(F^Y,F^Y|Xi∈Xim(N))where the symbol M(N) denotes the fact that the choice of the partition size might vary with the sample size and Nmdenotes the number of realizations of Xifalling intoXim. To illustrate, a given data estimator for value of information is written as (Strong & Oakley, 2013):(46)ϵ^i=∑m=1M(N)NmNmaxa=1,2,⋯,A{1Nm∑ℓ:xℓi∈Ximyℓ,a}−maxa=1,2,⋯,A{1N∑i=1Nyi,a}where the expressionmaxa=1,2,⋯,A{1Nm∑ℓ:xℓi∈Ximyℓ,a}is an estimator of the posterior value of action given that Xiis contained in the mth bin, namely, an estimator ofmaxa=1,2,⋯,AE[Ya|Xi∈Xim]. Several properties of this estimator are discussed in Strong and Oakley (2013). For variance-based sensitivity measures, the given data estimator is the one defined by Pearson (1905):(47)υ^i=∑m=1M(N)NmN(1Nm∑ℓ:xℓi∈Ximyℓ−1N∑i=1Nyi)2.This estimator is used in Strong, Oakley, and Chilcott (2012) and Plischke et al. (2013) for the estimation of variance-based sensitivity measures. Recently, Zhai, Yang, and Zhao (2014b) discuss additional analytic properties of this estimator and discuss heuristics for the optimal partition size.Plischke et al. (2013) discuss the given data estimation of density-based sensitivity measures for a space mission risk assessment model with 827 inputs. Baucells and Borgonovo (2013) use a given data estimation approach to conduct the global sensitivity analysis of the well known Genzyme–Geltex pharmaceutical case study (Bruner, Bodily, & Jacquet, 1999), specializing Eq. (45) for transformation invariant inner statistics based on the Kuiper metric. As these recent references show, given data approaches are attracting increasing attention, because of the possibility of delivering sensitivity measures without a specific design and using directly the Monte Carlo sample produced in an uncertainty analysis.Indeed, recently, Borgonovo et al. (2015) show that, under the requirements that the inner statistic γ(Xi) is a Riemann–Stieltjes integrable function and that the inner operatorζ(·,·)is a continuous function of its arguments, as N tends to infinity, a given data estimator in Eq. (45) tends to the corresponding value of the probabilistic sensitivity measure. This result provides a general envelope for the estimation of probabilistic sensitivity measures using given data approaches.A further way to estimate global sensitivity measures at the minimal cost of N model runs is to fit a meta-model (or emulator) on the input–output sample and then use the emulator to replace the original model. The realm of model emulation is vast and outside the scope of our article. However, we refer the interested reader to the monograph of Santner, Williams, and Notz (2003), to the 2009 Technometrics special issue edited by Bayarri, Berger, and Steinberg (2009), and to the reviews in Oakley and O’Hagan (2004) for Gaussian process meta-modeling, in Ratto, Pagano, and Young (2007) for smoothing spline ANOVA meta-models, to Kleijnen (2008); 2009) for Kriging meta-models, to Sudret (2008) for polynomial chaos expansion, and to Buzzard (2012) for sparse grid interpolation. Provided that an accurate fit is obtained, given the very short running time of an emulator, one can then apply a brute force algorithm or can use specific designs. This approach is used extensively in the estimation of variance-based sensitivity measures, with works such as (Blatman & Sudret, 2010; Doksum & Samarov, 1995; Lewandowski, Cooke, & Duintjer Tebbens, 2007; Sudret, 2008) . Recently, it is used in Strong and Oakley (2014) for the estimation of value of information sensitivity measures using Gaussian Process meta-modeling. It is used in Borgonovo, Castaings, and Tarantola (2012) to estimate density-based sensitivity measures.Sensitivity analysis is essential to bridge the gap between decision makers (that often do not directly work or develop the model) and analysts (who work directly on the model). However, as (French, 2003, p. 229) states, ... sensitivity methods are used in many different circumstances for many different purposes; and the manner of their use in one context may be inappropriate in another.The literature has demonstrated that it is crucial to state up front the questions that we wish to answer through a sensitivity analysis (Saltelli, 2002b). If this is the case, then one can confidently identify the appropriate sensitivity analysis method for answering the stated questions. To illustrate, consider an analyst wishing to identify key-drivers of model response. If the question is answered under uncertainty, then a global sensitivity method is appropriate for the purpose. If the question is asked at a particular point in the model input space, then a local method is needed. The works of Saltelli and Tarantola (2002), Saltelli (2002b) formalize this aspect introducing the concept of sensitivity analysis setting. A setting is a formulation of the sensitivity analysis quest which is stated before the sensitivity analysis is carried out. Several insights can be sought by an analyst and sensitivity analysis settings have been introduced in the literature.The factor prioritization setting is associated with obtaining insights about the most important model inputs. Best practices recommend that, under uncertainty, these insights are obtained using a global sensitivity method. If the goal of the analysis if variance-reduction, then variance-based sensitivity measures should be used. If the goal is the determination of the effect of a model input on the entire distribution (density), then distribution (density) based method are appropriate for the task. Conversely, in a deterministic framework (i.e., in the absence of uncertainty), and if is considering finite changes in the model inputs, Tornado diagrams are the appropriate tools. Conversely, if infinitesimal perturbations are of concern, then differentiation-based sensitivity measures are appropriate.A second well known setting is factor fixing. In this case, the analyst is interested in receiving information about the least influential factors, which can be confidently fixed at their nominal value. Screening methods are the appropriate tools for this task (Saltelli et al., 2008). A further setting concerns model structure (Borgonovo, 2010b). This setting applies in all those situations in which analysts are interested in determining whether the model response is the sum of the individual model input changes or whether interactions play a relevant role. The sensitivity measures appropriate for this setting are finite change sensitivity indicesϕiI,if we are in a deterministic framework, or high-order variance based sensitivity indices, if we are in a probabilistic framework.Direction (or sign) of change is a crucial insight in several applications. As Samuelson (1941) states: This is a typical problem confronting the economist: in the absence of precise quantitative data he must infer analytically the qualitative direction of movement of a complex system. That is, a direction of change setting envelops all those applications in which analysts are interested to know whether an increase (decrease) in a model input provokes an increase (decrease) in model output. The question may be asked deterministically or under uncertainty. If infinitesimal perturbations are of concern—as in the original work of Samuelson—the sign of partial derivatives provides the desired answer. If finite changes are of concerns, then the sign of the finite change sensitivity indices provide indication about direction of change. If the analyst is interested in the behavior of the model output when one of the inputs varies in a predetermined range, then one-way sensitivity functions are of interest. Finally, the sign of change question can be also asked in a global way, i.e., under uncertainty. Then, the answer to this question is the plot of the first order terms of the functional ANOVA expansion, namely the functions gi(xi) in Eq. (26), provides the answer. In fact, if g(x) is monotonic, the first order effect functions gi(xi) retain the monotonicity of g(x), as proven in Beccacece and Borgonovo (2011). Anderson, Borgonovo, Galeotti, and Roson (2014) apply these findings in a climate change application.Besides these classical settings, additional questions have been stated in the literature, although possibly not formalized as a setting. In particular, we propose here to group several sensitivity studies in a stability11The setting could also be named robustness setting. However, this might create overlap with the use of the term robustness in optimization, where robust optimization refers to the solution of optimization problems characterized by uncertainty in distribution. The setting has not been officially named in the literature, yet, but it unifies several sensitivity questions and models of operations research.setting.This setting indeed comprises all those problems in which decision-makers are interested in determining the region of the model input space over which the optimal plan (or preferred alternative) does not change. It applies in sensitivity analysis of linear programming problems, where the analyst is interested in determining the ranges in the model inputs which leave the optimal plan unaltered. The method that delivers a consistent answer to this question is Wendell’s tolerance sensitivity approach (Ravi & Wendell, 1989; Wendell, 1985). We refer to Filippi (2005) and Filippi (2010) for thorough reviews. It applies as well in the sensitivity analysis of decision support models expressed in the form of decision-trees (influence diagram), that help analysts in selecting among a discrete set of alternatives. The work of Nielsen and Jensen (2003) addresses the problem of finding the variation ranges in utilities and probabilities (the model inputs) that reassure us that the preferred alternative is stable, and the same sensitivity question is answered also in the works of Bhattacharjya and Shachter (2010) and Bhattacharjya and Shachter (2008). Stability analysis for Bayesian networks is discussed in Chan and Darwiche (2004), Chan and Darwiche (2005) and Brosnan (2006). A further important class of problems to which a stability setting applies is dynamic programming. Tan and Hartman (2011) provide a thorough review of sensitivity methods used in discrete dynamic programming to address the sensitivity of the optimal solution to changes in the model inputs. Tan and Hartman (2011, Section 5) observe that several discrete dynamic models can be represented as linear programs. One can then exploit tolerance sensitivity approaches to obtain stability insights.

@&#CONCLUSIONS@&#
The development of a simulation or decision support model aids the solution of several problems in operational research. Numerical results of the codes inform decision makers in applications which might be crucial for the life of a corporation or might have strong societal and environmental impacts, especially when complex technological systems are of concern. We are then called to a systematic utilization of sensitivity analysis methods for: (a) making model builders fully aware of the response of the model to variations and uncertainty in the model inputs and, (b) providing decision makers with an enriched set of insights about the managerial problem at hand. We have focused on quantitative and model free methods, ranging from the widely used local techniques (from Tornado diagrams to finite change sensitivity indices, to differential operators), to more recently introduced global sensitivity methods, such as non-parametric, variance-based, moment independent and value of information-based sensitivity measures. We have presented recent advances in the theoretical framework and estimation procedures. These advances are capable of notably reducing computational burden, making the use of global methods at reach in an increasing number of applications. It then becomes crucial to improve communication of sensitivity analysis results to managers. Our second last section has then been devoted to an approach for systematically obtaining managerial insights. Our discussion section has concerned the interpretation of probabilities in a global sensitivity analysis and the role of sensitivity analysis in model building.