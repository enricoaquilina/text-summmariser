@&#MAIN-TITLE@&#
Cognitively-inspired representational approach to meaning in machine dialogue

@&#HIGHLIGHTS@&#
We propose a computational model for meaning representation in machine dialogue.It is aimed at robust processing of the user’s utterances without a preset grammar.It is inspired by neuroimaging studies on working memory and Broca’s aphasia.We show that it can be generalized over different interaction domains.We report on a framework for end-user programming of adaptive dialogue systems.

@&#KEYPHRASES@&#
Human–machine dialogue,Meaning representation,Cognition,Attention,Focus tree,Broca’s aphasia,

@&#ABSTRACT@&#
One of the most fundamental research questions in the field of human–machine interaction is how to enable dialogue systems to capture the meaning of spontaneously produced linguistic inputs without explicit syntactic expectations. This paper introduces a cognitively-inspired representational model intended to address this research question. To the extent that this model is cognitively-inspired, it integrates insights from behavioral and neuroimaging studies on working memory operations and language-impaired patients (i.e., Broca’s aphasics). The level of detail contained in the specification of the model is sufficient for a computational implementation, while the level of abstraction is sufficient to enable generalization of the model over different interaction domains. Finally, the paper reports on a domain-independent framework for end-user programming of adaptive dialogue management modules.

@&#INTRODUCTION@&#
This paper introduces a cognitively-inspired representational approach to meaning in machine dialogue. Since this approach is representational, it proposes a nonstatistical, computationally and analytically tractable model with explanatory power. In contrast to other well-known meaning representation languages cf. [29, pp. 545–547], this model is intended to address the research question of capturing the meaning of spontaneously produced users’ linguistic inputs (i.e., of different syntactic forms) without a preset grammar. The principle behind this requirement is that the users should not be forced to intentionally adapt their dialogue acts to a preset grammar. Instead, they should be allowed, as far as possible, to express themselves naturally. It is in line with a recent Wizard-of-Oz study reported by Gnjatović and Rösner [24, p. 141] showing that nonlinguistic context (e.g., a graphical display, etc.) shared between the subjects and the simulated system influences the language of the subjects to a high extent with respect to frequency of “ungrammatical” utterances, e.g., elliptical, minor, context-dependent utterances, etc. Hence, a dialogue system should be able to cope with such dialogue phenomena.The paper is divided in two main parts. The first part (Sections 2–5) introduces a cognitively-inspired model for meaning representation. We draw upon and integrate insights from behavioral and neuroimaging studies on working memory operations and language-impaired patients (i.e., Broca’s aphasics) in order to specify the storage and processing aspects of the model. In this respect, our approach contributes to the field of cognitive infocommunications [2,34]. The level of detail contained in the specification of the model is sufficient for a computational implementation, while the level of abstraction is sufficient to enable generalization of the model over different interaction domains. The second part of the paper (Sections 6 and 7) discusses the computational appropriateness and generalizability of the model, and reports on a domain-independent framework for end-user programming of adaptive dialogue management modules.This paper integrates and expands upon previous work on the research question of modeling attentional information in task-oriented human–machine interaction. The focus tree is a model of attentional state introduced by Gnjatović and colleagues [22,20,15] to address the problem of robust recovery of semantic information from the user’s commands without explicit syntactic expectations. Its various adaptations were successfully applied in several prototypical dialogue systems with diverse domains of interaction: supporting users while they solve problems in a graphics system [23], a verbal user interface for the visually impaired [21], linguistic encoding of motion events [16,18], a spatial context-aware interaction with the industrial robot [27,26], a conversational agent embedded in a mobile phone [25], and therapist-centered design of a robot’s dialogue behavior [14]. Although there are nontrivial differences among these interaction domains, the given prototype systems share a common foundation. This paper aims at capturing this common foundation and introducing a method for meaning representation in machine dialogue inspired by a particular cognitive model of working memory.The common point of the existing computational approaches inspired by the human memory system is that they tend to model the high-level cognitive modules and processes [13,12,3], and rarely address the fundamental questions of how information is represented, encoded or retrieved in human memory [35, p. 7]. In contrast to them, this paper proposes a representational approach. The underlying idea of the focus tree was to make a computationally appropriate representation of attentional information that imitates the function of the focus of attention in working memory [20]. Detailed overviews of different cognitive models of working memory are provided by Bledowski et al. [4], Unsworth and Spillers [36], Baddeley [1] and Shah and Miyake [35]. We focus on the particular cognitive model of working memory introduced in the theoretical context provided by Oberauer [32], Oberauer and Lange [33], Cowan [9]. In this model, working memory is conceptualized as a concentric structure of representations with three functionally distinct regions: the activated part of long-term memory, the region of direct access, and the focus of attention [32, p. 412]. This is illustrated in Fig. 1a. Nodes and lines represent a network of long-term memory representations. Black nodes represent activated representations. The region of direct access (i.e., nodes B, D, E, F) holds a limited number of activated representations that are available to be used in ongoing cognitive processes. Within this region, one representation is selected to be in the focus of attention (e.g., node B).It should be noted that this cognitive model neither specifies the topology of the network of the available memory representations, nor explains on which principles these representations are related. In addition, the processing aspect of working memory is underspecified. The basic cognitive functions that provide means for the flexibility of working memory (i.e., mnemonic selection, updating the focus of attention, and updating the contents of working memory) are specified at a high-level and in a declarative manner [4, pp. 173,177]. In contrast to this, Gnjatović et al. [20] introduce a technical and detailed approach to constructing the focus tree and implementing the algorithm for the transition of the focus of attention. Abstracting away from some implementation details, this paper proposes a more general, cognitively-inspired specification of concepts that underlie the storage and processing of attentional information in the focus tree model.We recall that our aim is to enable dialogue systems to capture the meaning of spontaneously produced linguistic inputs without explicit syntactic expectations. This raises some fundamental questions: To what extent is syntax distinguished from semantics? Is it possible, and in which cases, to recover semantic information without a complete syntactic analysis of the sentence? If we do not take syntactic information into account, what kind of information is needed to recover semantic information? The answers to these questions derive from separate but interrelated insights from neurolinguistics and cognitive linguistics.The current neurocognitive understanding of language is that it is a modularly organized neurological entity, in which syntax is anatomically distinguished from semantics and the lexicon [28, pp. 1–4]. At the level of linguistic behavior, this anatomical distinction can be observed in Broca’s aphasia, a specific language impairment caused by an injury to the part of the left anterior cortex called Broca’s area and its vicinity. Based on a number of behavioral and neuroimaging studies, it is now widely accepted that the role of Broca’s area in syntax is highly specific [6,28,5,11,10]. In terms of Grodzinsky [28, p. 2], Broca’s area and its vicinity are the neural home to receptive mechanisms involved in the computation of the relation between transformationally moved phrasal constituents and their extraction site. Therefore, Broca’s aphasics suffer a highly restricted receptive disorder1Broca’s aphasia is commonly characterized by overt problems in speech production (i.e., effortful, nonfluent, and telegraphic speech). However, for the purpose of this contribution, we focus on the less salient, although not less fundamental, comprehension deficit in Broca’s aphasia. For a more detailed account of this discussion, the reader may consult Gnjatović and Delić [17], Gnjatović [14].1of syntax that can be briefly summarized in the following points [28, pp. 3–5]:(i)Broca’s aphasics do not have impairment in their lexicon, i.e., they do not make lexical errors.Broca’s aphasics can comprehend basic syntactic trees for simple sentences that do not contain intrasentential dependency relations, e.g., canonical subject–verb–object structures in English, such as the active sentence “The girl pushed the boy”.Broca’s aphasics have difficulties in comprehending sentences involving syntactic movement out of the object position, such as the verbal passive sentence “The boy was pushed by the girl” derived from its active counterpart through the movement of the object.2At the surface level, the observed syntactic movement may by summarized as follows. In the canonical form “The girl pushed the boy”, the constituent that represents the subject precedes the constituent that represents the object, while in the derived form, the object precedes the subject [30, cf.]. However, it should be noted that comprehension difficulties are related to syntactic movement, and not to the passive morphology [28, p. 6].2The derived sentence contains two animate noun phrases, “the boy” and “the girl”, that are assigned the Theme and the Agent roles, respectively. However, the assignment of the semantic roles in this sentence is determined only by the underlying syntactic structure. If these phrases changed their positions in the sentence—and, thus, also their semantic roles—the new sentence (i.e., “The girl was pushed by the boy”) would still be semantically valid. Due to their deficit in receptive mechanisms of grammatical analysis, Broca’s aphasics cannot distinguish between these two semantically reversible sentences, and can only try to guess the Agent of the action, which results in chance-level performance.However, it should be noted that, despite the deficit in receptive mechanisms of grammatical analysis, Brocas aphasics can rely on their knowledge of the world when interpreting a given sentence.Broca’s aphasics are able to use lexical and semantic cues to get around their comprehension deficit. For example, although they cannot comprehend the syntactic structure underlying the sentence “The apple that the boy is eating is red”, they know from their general knowledge of the world that apples do not eat boys. Therefore, based on this semantic cue, they correctly assign the Agent role to the boy, and the Theme role to the apple, without performing a grammatical analysis of the underlying syntactic structure [6].It is interesting to note that these points are very much in line with an insight from cognitive linguistics provided by Chomsky. First of all, Chomsky [7, p. 25] also points to the distinction between the lexicon and the computational system (i.e., syntax) provided by Universal Grammar. The fact that Broca’s aphasics can comprehend canonical syntactic structures is in line with his notion of the kernel of language. According to Chomsky [8, p. 80], the kernel consists of a finite number of simple, declarative, active sentences that reflect basic grammatical relations such as subject–predicate or verb–object relations. Every sentence of the language either belongs to the kernel or can be derived from the strings underlying one or more kernel sentences by a sequence of one or more transformations [8, p. 45]. These transformations include syntactic movements. Finally, the fact that Broca’s aphasics use semantic cues to get around their comprehension deficit is in line with Chomsky’s observation that the association between assigned semantic roles and constituent positions is to a large extent predictable, rather than idiosyncratic [7, p. 30].It is clear that understanding the cognitive mechanisms that underlie the behavior of Broca’s aphasics may be valuable for researchers that aim at enabling dialogue systems to process spontaneously produced user’s linguistic inputs with no explicit syntactic expectations (cf. [17,14]). In our approach, the conceptual requirements for the storage and processing of attentional information derive from these insights. Points (i), (ii) and (iv) indicate that the lexicon, the canonical syntactic structures, and the general knowledge of the interaction domain should be stored in the knowledge base of the system. Point (iii) relates to the processing aspect. It implies that the interpretation of the user’s utterance whose syntactic structure does not belong to the set of canonical structures may be reduced to the mapping of the observed utterance to one or more canonical sentences. This is further elaborated in the next two sections.Recent research on computationally appropriate structures for representing human knowledge shows that human cognition is believed to have generally hierarchical properties [31, p. 68]. In line with this, the focus tree is a hierarchical structure. Fig. 1 shows a comparison between the concentric model of working memory (Fig. 1)) and the focus tree model of attentional state (Fig. 1b). The focus tree represents the activated part of the long-term memory (black nodes). Each node of the focus tree represents an activated memory representation, while nonactivated long-term memory representations are not included. At any moment, the current focus of attention is placed on exactly one node of the focus tree (e.g., node B). The region of direct access is a subtree in the focus tree determined by the current focus of attention as its root node (i.e., nodes B, D, E, F).For the purpose of illustration, let us adopt a rather simple spatial context that contains only two figures—a black square and a white square. These figures can be pointed to, or moved in two degrees of freedom, i.e., left/right and up/down. This general knowledge of the interaction domain is represented by the focus tree given in Fig. 2. The root node represents the entire interaction domain. We refer to all other nodes of the focus tree as to focus instances.Within the domain of meaning, each focus instance in the focus tree represents a semantic entity (e.g., figure, action, direction, etc.) that may come into the focus of attention during the interaction. However, relations between focus instances and semantic entities are not one-to-one. The principle that underlies the construction of the focus tree is that the semantic meaning of a node must encapsulate the semantic meanings of all its ancestors in the focus tree. For example, focus instances SHIFT1 and SHIFT2 (cf. Fig. 2) both relate to the action of movement. However, their meanings are not the same. The meaning of the first focus instance is “movement of the black square”, while the meaning of the latter focus instance is “movement of the white square”. This is summarized in the first two columns of Table 1.Within the domain of surface expressions, the lexicon comprises keywords and nonrecursive phrases that relate to the propositional content of the user’s commands. At the functional level, they may take one of the two distinct roles [20, p. 309]:•focus stimuli—parts of the sentence that refer to salient entities from the current interaction domain (i.e., entities that may be in the focus of attention),negative reinforcement stimuli—parts of the sentence that refer to entities from the current interaction domain that should not be in the focus of attention.The lexicon is organized in such a way that each node in a focus tree is assigned a set of focus stimuli. These sets do not have to be disjoint. For the given focus tree, the sets of focus stimuli are defined in the third column of Table 1. The negative reinforcement stimuli are defined as linguistic negation of the focus stimuli. In the following examples, the sentence parts that represent focus stimuli are given in bold, while the sentence parts that represent negative reinforcement stimuli are given in italics: “please move now the black square upward”, “show it”, “you should shift a figure, but not the black square”, “don’t move”.Another perspective on the focus tree is that it defines a set of canonical sentences. We recall that the kernel of language consists of a finite set of simple sentences that reflect basic grammatical relations. In the focus tree, each top-down path from the root node to a terminal node represents a kernel sentence. Let P be a set of nodes that belong to a top-down path from the root node to a terminal node, i.e.,P={n1,n2,…,nk}, wherek⩾1, and letfibe a focus stimulus assigned to focus instanceni∈P, where1⩽i⩽k. A terminal string that underlies kernel sentence P is defined as containing all focus stimulifi, where1⩽i⩽k, and no other focus stimuli. For example, the kernel sentence represented by the top-down path{▪,SHIFT1,↑}can be mapped to the following terminal strings: “shift the black square upward”, “move the figure up”, etc. We refer to these strings as to canonical sentences. On the other hand, sentences “move the square”, “shift it upward”, or “don’t move the black square up” are not canonical, because they do not contain a focus stimulus for each node in the given path. The next section considers how the system interprets such sentences.It can be observed that canonical sentences are defined as sets of keywords and phrases, with no further syntactic specification. This is in line with Chomsky’s observations that terminal strings underlying the kernel sentences are derived by a simple system of phrase structure [8, p. 61] and that phrase structure rules may be completely superfluous and thus eliminable, because they recapitulate information that is presented in the lexicon [7, p. 25].The processing aspect of the proposed model relates to the research question of mapping propositional content of the user’s command onto the focus tree. In a general case, the mapping of a command is context-dependent. For the purpose of easier representation, we use the following abbreviations:•CCURR—a current command uttered by the user,CPREV—a cumulative command containing propositional content of the previous user’s commands that are still not mapped,C—a command generated by concatenation of the overt linguistic forms ofCPREVandCCURR,f—a focus stimulus,F—a set of all focus stimuli in C,r—a negative reinforcement stimulus,R—a set of all negative reinforcement stimuli in C,n—a node of the focus tree,nFA—a node of the focus tree that carries the current focus of attention,n∼l—linguistic stimulus l is assigned to node n,P(n)—a top-down path starting at node n, i.e., a set of nodes that belong to a direct path from node n to a terminal node,℘(n)—a set of all top-down pathsP(n)that start at node n.When the user utters commandCCURR, it is not immediately mapped onto the focus tree. Instead, command C is generated by concatenation of the overt linguistic forms ofCPREVandCCURR, and then mapped onto the focus tree through the following steps:Step 1: Mapping onto the region of direct access. The system finds all top-down pathsP(nFA)whose nodes cover all focus stimuli in command C and do not cover all negative reinforcement stimuli in command C, i.e.:(1)PCAND={P|(P∈℘(nFA))∧(∀f∈F)(∃n∈P)(n∼f)∧((R=∅)∨(∃r∈R)(∀n∈P)(n≁r))}Each pathP∈PCANDrepresents a possible interpretation of the user’s command.Step 2a: Updating the focus of attention. If setPCANDcontains exactly one path P, command C is mapped onto this path. The focus of attention is placed on the terminal nodenˆcontained in P. This means that the user’s command is complete and that the system has all necessary information to perform it.Step 2b: Dealing with incomplete and ambiguous linguistic inputs. If setPCANDcontains more paths, it means that the user’s command can be interpreted in more than one way. The sets of nodes representing the paths inPCANDcannot be disjoint—each of them must, at least, contain the nodenFA. Let I be their intersection, i.e.:(2)I=⋂iPi|Pi∈PCANDand letnˆbe a node from set I that represents the most specific focus instance, i.e.:(3)(nˆ∈I)∧(∀n∈I)(n≠nˆ⇒nisantecedentofnˆ)We differentiate between two cases. IfnFA≠nˆ, it means that all interpretations inPCANDhave something in common. The user’s command may be mapped onto the top-down path that starts at nodenFAand ends at nodenˆ. Thus, the focus of attention is transited to nodenˆ. In this case, we refer to the user’s command as being incomplete. Otherwise, ifnFA=nˆ, the focus of attention remains unchanged, and we refer to the user’s command as being ambiguous.In both these cases, the system may respond in different ways: remain silent and wait for the user to provide additional information, inform the user that the command is incomplete or ambiguous, ask the user to select one of the possible interpretations fromPCAND, propose an interpretation fromPCANDaccording to some criterion, etc. The common point of all these responses is that the user is expected to provide the necessary information in his next command. The user can, but does not have to, adopt for himself this particular speech role. In general, he may provide the required information, or just a part of it, or utter a new command that is not related to his previous command. It is important to note that the system processes the ensuing user’s command in a uniform manner. The linguistic content of commandCCURRis concatenated to commandCPREV(i.e.,CPREV=CPREV+CCURR), and the new user’s command is loaded inCCURR. The mapping is then restarted from Step 1. If the user provides the required information, command C generated at the start of the new iteration of the algorithm will be mapped in Step 2a. Otherwise, if the user provides just a part of the required information, command C will still be incomplete or ambiguous. The user will be asked again, in Step 2b, to provide the missing information, and the algorithm will be again recursively called. Finally, if the user utters a new command that is not related to his previous command, command C will be semantically irregular in the given context. This situation is addressed in Steps 2c and 2d.Step 2c: Mnemonic selection. If setPCANDis empty, and the current focus of attentionnFAis not placed on the root node, it signals that command C cannot be mapped onto the region of direct access. Therefore, this region is extended by transiting the focus of attention to the parent of nodenFA. The mapping of the command is then restarted from Step 1.Step 2d. Dealing with semantically irregular linguistic input. If setPCANDis empty, and the current focus of attention is placed on the root node, then command C is semantically irregular in the given interaction domain. We recall that command C is generated by concatenation ofCPREVandCCURR. IfCPREVwas empty, the system infers that the current user’s commandCCURRis semantically irregular, and may inform the user. Otherwise, the only case whenCPREVis not empty is when it was initialized in Step 2b. Since C is irregular, it means that the user uttered, in Step 2b, commandCCURRthat is not related toCPREV. Therefore, the system deletesCPREV, and restarts the algorithm, trying to map justCCURRonto the focus tree.The previous section introduced a sketch of an adaptive task-independent dialogue strategy. To the extent that this strategy is adaptive, the system takes the current context of interaction into account in order to decide what to do. The context of interaction includes information on attentional state (setPCAND), the current user’s command (CCURR), and the propositional content of the previous user’s commands that are still not mapped (CPREV). To the extent that the strategy is task-independent, the proposed algorithm is not constrained to a particular structure of the focus tree or content of the lexicon, and does not take into account information on a specific task structure cf. [20, p. 318]. However, for any practical implementation, the focus tree and the lexicon must be specified, and this sketch of a dialogue strategy should be adapted to a specific task. An important guideline for our approach is that these adaptations do not have to be finalized at the moment of the system’s implementation. Here, we report on a prototype dialogue management system that gives the user3We differentiate between two groups of users of this prototype system that are not necessarily disjoint. The first group includes users that design the dialogue strategy of the prototype system. The second group includes users that take part in the conversation with the prototype system. Section 6 refers primarily to the first group, while Section 7 refers primarily to the second group.3a possibility to flexibly (re)define the focus tree, the lexicon, and the dialogue strategy (cf. also [14,19,21]).For a given task, the focus tree and the lexicon (i.e., focus stimuli) are defined in an external XML file, independent of the implementation of the prototype system. This means that changes of the structure of the focus tree or the content of the lexicon do not require a change of the implementation of the prototype system, but just a redefinition of the XML file. The prototype system can, at any moment, load this external definition, and apply the algorithm implementing the dialogue strategy cf. [20, p. 318]. On the other hand, the prototype system implements the basic dialogue strategy introduced in Section 5. It also allows the user to flexibly extend this dialogue strategy at any moment. The strategy can be extended in two respects. First, the context of interaction can be extended with additional, task-specific interaction features. And second, the decision-making aspect of the strategy can be further specified. For example, in Step 2b, we stated that the system may respond in different ways, but did not specify how it selects one of them.Users that design the system dialogue strategy may come from a variety of backgrounds, e.g., researchers that design and test dialogue strategies in human–machine interaction, human operators in Wizard-of-Oz simulations, language therapists that practice computer-aided therapy, end-users of social robots, etc. Giving the possibility for such users to define nontrivial adaptive dialogue strategies is an important issue with respect to the usability of the system. Since they are not necessarily experienced in programming, they should be provided with an intuitive, yet flexible way to define dialogue strategies. Thus, the reported prototype system provides:•the initial set of variables that model the minimal context of interaction (cf. Table 2),the initial set of primitive actions that may be performed by the system (cf. Table 3),the syntax for defining a dialogue strategy and extending the context of interaction, based on the Java programming language,the interface that enables the user to define, save and change the dialogue strategy of the system, and provides informative feedback on syntax errors (cf. Fig. 3).While the given interface provides a significantly broader set of features4This set includes all features available in the Java programming language for defining a method, introducing global variables, and importing packages.4for users with programming experience, here we focus on the nontechnical users. In its simplest form, an adaptive dialogue strategy is a sequence of if-else statements. Conditions in these statements are logical expressions that contain variables defined in Table 2, while bodies of these statements are sequences of primitive actions defined in Table 3. During the interaction, each time the user utters or types a command, the system applies its dialogue strategy. Fig. 4provides an example that shows how the user may extend the context of interaction (line 02), introduce a new context variable (line 05), and define an adaptive dialogue strategy (lines 08–40).The introduced dialogue strategy is to a great extent self-explanatory. If the user’s command is incomplete, ambiguous or irregular, it may signal that the user experiences problems in interaction. Thus, the system should support him. The introduced dialogue strategy differentiates between two manners of providing support: low intensity support, and high intensity support. To illustrate this, let us assume that the user instructed an ambiguous command for the first time in the course of the interaction. In this case, the system provides support of low intensity, i.e., it asks the user to be more specific (cf. lines 21–24). However, if the user again instructs an ambiguous command, the system will provide support of high intensity, i.e., it will explicitly ask the user to select one of the provided options (cf. lines 25–29) in order to resolve the ambiguity. For more examples of dialogue strategies, the reader may consult Gnjatović [14], Gnjatović and Delić [19], Gnjatović et al. [21], Gnjatović and Rösner [23].It should be noted that this dialogue strategy specifies a general dialogue behavior, i.e., it is task-independent. We recall that task-specific information (i.e., the focus tree and the lexicon) is encapsulated in an external XML file. For the purpose of the demonstration, we defined this XML file to contain information about the focus tree and the lexicon introduced in Fig. 2 and Table 1. The prototype system loads the external definitions of the dialogue strategy, the focus tree and the lexicon, and automatically generates a source code that implements a dialogue management module. We illustrate and discuss the functionality of the generated dialogue manager in the next section.The dialogue fragment given in Fig. 5illustrates the algorithm for processing the user’s commands introduced in Section 5, and the dialogue strategy introduced in Fig. 4. At the beginning of the dialogue fragment, the focus of attention is placed on the root node, and the intensity of support is set to low. According to the processing algorithm, command User1 is interpreted as ambiguous. There are two possible interpretations of this command, as indicated in Fig. 6a. According to the dialogue strategy, the system asks the user to be more specific (System2) and increases the intensity of support. When the user again instructs an ambiguous command (User3), the response of the system is more informative. It provides a list of options among which the user can choose in order to resolve the ambiguity (System4). The content of this list is contextually dependent. At the propositional level, the list of options is dynamically generated with respect to the current context of interaction, cf. specification ofPOPTin Table 2. At the linguistic level, the descriptions of nodes contained inPOPTare generated automatically from the lexicon, by means of string concatenation. The description of noden∈POPTis defined in a recursive manner:(4)desc(n)=emptystring,ifnisrootnodedesc(parent(n))+entry(n),otherwisewhereentry(n)represents the first focus stimulus assigned to node n. It can be noted that this way of generating a node’s description is not optimal. However, it was not our intention in the first place. Instead, following the guideline that the lexicon should be separate from the implementation of the prototype system, we just illustrate a procedure that is general enough to be applied for any focus tree and lexicon.In his turn (User5), the user responds in an indirect way, by eliminating one of the options provided by the system. This is realized by a constituent negation (cf. negative reinforcement stimuli in Section 4). Therefore, according to the processing algorithm, the system infers that the user wants to point to the black square. Following the dialogue strategy, it places the focus of attention on node POINT1 (System6), as indicated in Fig. 6b, and informs the user that the command is performed (System7).The next user’s command (User8) contains an anaphoric reference (i.e., pronoun “it”) to the black square. Following the processing algorithm, the system resolves the anaphora in an indirect manner. It considers this command as specifying only the keyword “move”. Since it cannot be mapped onto the subtree determined by the current focus of attention (i.e., node POINT1), this region is extended by transiting the focus of attention to the parent of node POINT1 (as specified in Step 2c in Section 5). The mapping of the command is then restarted, and the focus of attention is transited, in a top-down manner, to node SHIFT1. At this moment, the system infers that the user’s command is incomplete. According to the dialogue strategy, the system informs the user that it needs additional information, and again provides a contextually dependent list of options to help the user in completing the command (System9). Fig. 6c indicates the transitions of the focus of attention, and the nodes contained inPOPT.The user can, but does not have to, select one of these options. Thus, command User10 does not contain any phrase from the lexicon. According to the processing algorithm, the system interprets this command as semantically irregular. According to the dialogue strategy, the system informs the user that it did not understand him, provides the same options as in the previous dialogue act, and increases the intensity of support (System11). When the user again instructs a semantically irregular command (User12), the system’s reaction is slightly different. Since the intensity of support is set to high, it transits the focus of attention to the root node, and then provides a list of options determined by the new focus of attention (cf. System13, and Fig. 6d).It is clear that we could have introduced a more elaborated dialogue strategy than the one given in Fig. 4. However, this was not necessary. Our intention was not to introduce an optimal dialogue strategy, but to illustrate and discuss the domain-independent framework for end-user programming of adaptive dialogue management modules.

@&#CONCLUSIONS@&#
