@&#MAIN-TITLE@&#
A novel three-way decision model based on incomplete information system

@&#HIGHLIGHTS@&#
We induce the incomplete information to DTRS and build a three-way decision model.We use a hybrid information table to deal with the integrated information system.We list the key steps and algorithm of the proposed three-way decision model.

@&#KEYPHRASES@&#
Three-way decisions,Decision-theoretic rough sets,Loss function,Incomplete information system,Hybrid information system,

@&#ABSTRACT@&#
As a natural extension of three-way decisions with incomplete information, this paper provides a novel three-way decision model based on incomplete information system. First, we define a new relation to describe the similarity degree of incomplete information. Then, in view of the missing values presented in incomplete information system, we utilize interval number to acquire the loss function. A hybrid information table which consist both of the incomplete information and loss function, is used to deal with the new three-way decision model. The key steps and algorithm for constructing the integrated three-way decision model are also carefully investigated. An empirical study of medical diagnosis validates the reasonability and effectiveness of our proposed model.

@&#INTRODUCTION@&#
Three-way decisions (TWD), which were proposed by Yao in 2010 [59,60], have gradually became an important granular computing methodology and attracted many attentions in the nearly five years. The idea of three-way decisions is generated from decision-theoretic rough sets (DTRS) [66,68]. Intuitively, two thresholds α and β of DTRS can divide the universe into three pairwise disjoint regions (positive, negative and boundary regions) by considering the minimum expected overall decision risk. The positive decision rules generated by the positive region make decision of acceptance. The negative decision rules generated by the negative region make decision of rejection. With the different from the two-way decisions of acceptance or rejection, the boundary region lead to a third way of decision, namely, noncommitment or deferment [71]. For simplicity, the three types of decision rules generated from the three regions of rough sets, form three-way decisions. As we stated in [35], three-way decisions are the natural extensions of DTRS, and they are common problem solving methodologies and consistent with human’s real decision cognition.In view of the semantics of DTRS, Yao systematically investigated the notion of three-way decisions and its potential applications recently [66,68]. As well, Liu et al. [28] briefly reviewed the two decades’ researches on DTRS. Followed by their viewpoints, the existing studies of DTRS in three-way decisions can divide into three main aspects as follows.•The extended models, modified models and their corresponding approaches on three-way decisionsIn order to introduce the general binary relations, Abd El-Monsef and Kilany [1] constructed two new approximations (semilower and semiupper approximations) and proposed a generalization and modification of DTRS model. Herbert and Yao, Azam and Yao [3,12,13] systematically studied three-way decision-making in game-theoretic rough sets. Li and Zhou [18] considered the decision risks in DTRS, and further investigated the three-way decisions with optimistic decision, equable decision, and pessimistic decision. Yao and Zhou [67], Deng and Yao [6,7] utilized the Bayes theorem viewpoint and information-theoretic viewpoint to interpret the thresholds acquisition in probabilistic rough sets, respectively. Ma and Sun [38] extended the probabilistic rough set model to two universes by considering the Bayesian risk in decision making. In consideration of the multiple classifications, the multi-agents and the multi-granulation problems, Liu et al. [31] and Zhou [81] extended the three-way decisions from two-category to multi-category; Yang et al. [56] studied three-way decision-making with DTRS in the context of multi-agent systems; Qian et al. [47] introduced multigranulation method to DTRS and proposed multigranulation decision-theoretic rough sets. In consideration of the uncertainty decision environment in three-way decisions, Liu and Liang proposed a series of new three-way decision models, including three-way decisions with random sets [36], interval sets [24], linguistic assessment [27], fuzzy interval sets [33], triangular fuzzy sets [23], intuitionistic fuzzy sets [26], hesitant fuzzy sets [25], and they further proposed a three-way decision model with logistic regression [35], dynamic three-way decision model [34] and function based three-way decision model [37]. Hu [14] systematically investigated three-way decision spaces in rough sets. Salehi et al. [48] did the systematic mapping studies on granular computing. Ciucci and Dubois [4,5] discussed the dependencies among three-valued logics, and further compared three-valued representations of imperfect information. Yu et al. [72,73] and Lingras et al. [22] investigated the three-way decision approaches with clustering analysis. All the above stated work make soiled contributions on the theoretical researches of three-way decisions.•Attribute reduction on three-way decisionsAttribute reduction in rough sets is one of the most important issues, it provides an effective way to discover intrinsic knowledge hidden behind the data set by deleting the redundant information from the information system [45]. In DTRS model, the attribute reduction methods mainly focus on two scenarios, positive region based reduction and minimum cost based reduction. As to the first scenario, Yao and Zhao [64] analyzed various criteria for attribute reduction for probabilistic rough sets, such as decision-monotocity, generality and cost. Li et al. [19] further investigated the monotonicity of positive region in DTRS model, and presented a new definition of attribute reduction in DTRS model. For the second scenario, Jia et al. [15] discussed the minimum decision cost attribute reduction in DTRS model and proposed cost-based optimal reducts. Min et al. [41] proposed a test-cost-sensitive attribute reduction for rough set model. Zhao and Zhu [75] proposed an optimal cost-sensitive granularization method to address different sizes of the granule by considering variable test and misclassification costs. In addition, Ma et al. [39] investigated a decision region distribution preservation reduction in DTRS model. Ju et al. [16] considered δ-cut DTRS and discussed the attribute reductions of the new model. Zhang and Miao [79] discussed the region-based quantitative and hierarchical attribute reduction in the two-category decision theoretic rough set model. To sum up, the researches on attribute reduction in DTRS can be easily related to, and interpreted by, more practical notions such as costs, losses and benefits.•Different areas of application on three-way decisionsThe essential ideas of three-way decisions have been widely applied in many fields, such as management decisions (e.g., environmental management [10], government management [32], oil investment management [29,30,40,42,55,74], model selection [9]), information and engineering (e.g., email spam filtering [76,80], E-learning [2], products inspecting process [54]), medical management (e.g., medical clinic [43], medical decision support system [58]), three-way recommender systems [77], etc.As we stated above, the aforementioned literatures mainly consider the complete information of three-way decisions. The loss functions in their researches are directly given by the experts or dealt with as imprecise values (e.g., random numbers, interval numbers, fuzzy numbers, etc.), but the semantic relation between loss functions and information table are rarely discussed. Furthermore, in real-life applications, since some data could not be obtained for various reasons (e.g., capacity, technology, financing), missing data appears frequently in many information systems. In consideration of the information system with miss values, this paper introduces the incomplete information into DTRS and analyzes three-way decision approach based on the incomplete information system (IIS).The remainder of this paper is organized as follows. In Section 2, we review some basic concepts of three-way decisions, DTRS, and rough sets under IIS. In Section 3, a novel three-way decision model with incomplete information is proposed. A hybrid information table, which consists both of the incomplete information and loss function, is used to deal with the three-way decision model in IIS. Then, a case study of medical diagnosis is given to illustrate our method in Section 4. Section 5 concludes the paper and elaborates on future studies.The basic concepts, notations and results of rough sets [44–46,49–51,78,82], DTRS [59–65] and three-way decisions [28,30,66,68–71] are briefly reviewed in this section.The idea of three-way decisions in rough sets is generated by rough set approximations [59,60]. As we know, Pawlak approximation spaceapr=(U,R)is defined by a finite and non-empty set U and an equivalence relation R. A partition of U, which generated from the equivalence relation R, can be denoted as [x]Ror [x]. For ∀X⊆U, the lower and upper approximations of X can be defined as:(1)apr̲(X)={x∈U|[x]⊆X};apr¯(X)={x∈U|[x]∩X0.25em0ex≠0.25em0ex⌀}.In (1), the condition [x]⊆X in the lower approximation represents [x] is contained in X. As well, the condition[x]∩X0.25em0ex≠0.25em0ex⌀in the upper approximation means [x] has an overlap with X. The two conditions clearly indicate the qualitative relationships between [x] and X in Pawlak rough sets. However, the definition of Pawlak approximations in (1) does not allow any errors, and the degree of overlap is not considered [69]. Observed by the limitation of Pawlak rough sets, probabilistic rough sets utilize two parameters, α and β (α ≥ β), to extend Pawlak rough sets to a more generalized model. The two approximations of probabilistic rough sets can be rewritten as:(2)apr̲(α,β)(X)={x∈U|Pr(X|[x])≥α},apr¯(α,β)(X)={x∈U|Pr(X|[x])>β},where, the rough membership functionPr(X|[x])=|X∩[x]||[x]|is the conditional probability of the classification [46]. The two approximations of probabilistic rough sets can lead to three decision regions as (α, β)-probabilistic positive, boundary and negative regions:(3)POS(α,β)(X)={x∈U|Pr(X|[x])≥α},BND(α,β)(X)={x∈U|β<Pr(X|[x])<α},NEG(α,β)(X)={x∈U|Pr(X|[x])≤β}.According to (3), the three regions lead to three-way decisions, namely, decision of acceptance, deferment and rejection, respectively.Specially, if α < β, we set “γ=α=β”, (3) can be rewritten as:(4)POS(γ,γ)(X)={x∈U|Pr(X|[x])≥γ},NEG(γ,γ)(X)={x∈U|Pr(X|[x])<γ}.For simplicity and clarity, we denote (4) as the two-way decision model. Obviously, (4) is a special case of the three-way decision model whenα=β. In addition, if we set “α=1,β=0”, (3) converts to Pawlak rough set model; if we setα=β=0.5, (3) converts to 0.5 probabilistic rough sets [30].However, as Yao stated in [69], there are two semantic issues which should be drawn attention in probabilistic rough sets. The first issue is the interpretation and estimation of the required two parameters α and β; the second one is the interpretation and application of decision rules derived from the probabilistic three regions [69]. To interpret these two issues, DTRS model is proposed to obtain the two parameters by Bayesian theory [59,60]. We briefly review the concept of DTRS model in Section 2.2.The DTRS model is composed of 2 states and 3 actions [8,66,67]. The set of statesΩ={X,¬X}indicate that an element is in X and not in X, respectively. For simplicity, we use the same symbol to denote both a subset X and it’s complementary state. With respect to the three-way decision, the set of actions is given byA={P,B,N}, where P, B, and N represent the three actions in classifying an object x, namely, deciding x ∈ POS(X), deciding x ∈ BND(X), and deciding x ∈ NEG(X), respectively. The loss function regarding the risk or cost of three actions in two states is given by a3×2matrix:X(P)¬X(N)aPλPPλPNaBλBPλBNaNλNPλNNIn the matrix, λPP, λBPand λNPdenote the losses incurred for taking actions of aP, aBand aN, respectively, when an object belongs to X. In the same way, λPN, λBNand λNNdenote the losses incurred for taking actions of aP, aBand aNwhen the object belongs to¬X.The expected lossR(ai|[x])(i=P,B,N)associated with taking the three different actions can be calculated as:(5)R(aP|[x])=λPPPr(X|[x])+λPNPr(¬X|[x]),R(aB|[x])=λBPPr(X|[x])+λBNPr(¬X|[x]),R(aN|[x])=λNPPr(X|[x])+λNNPr(¬X|[x]).The Bayesian decision procedure indicates the following decision rules with minimum-cost criterion:(P)1em0exIf0.35em0exR(aP|[x])≤R(aB|[x])0.35em0exand0.35em0exR(aP|[x])≤R(aN|[x]),0.35em0exdecide0.35em0ex[x]∈POS(X);(B)1em0exIf0.35em0exR(aB|[x])≤R(aP|[x])0.35em0exand0.35em0exR(aB|[x])≤R(aN|[x]),0.35em0exdecide0.35em0ex[x]∈BND(X);(N)1em0exIf0.35em0exR(aN|[x])≤R(aP|[x])0.35em0exand0.35em0exR(aN|[x])≤R(aB|[x]),0.35em0exdecide0.35em0ex[x]∈NEG(X).Due toPr(X|[x])+Pr(¬X|[x])=1, we find the rules are only depended on the conditional probability Pr(X|[x]) and the loss functionsλ••(•=P,N,B). By considering a reasonable semantic interpretation of loss functions with λPP≤ λBP< λNPand λNN≤ λBN< λPN[66,67], we simplify decision rules (P)–(N) as follows.For the rule (P), the first condition is expressed as:(6)1em0exR(aP|[x])≤R(aB|[x])⇔λPPPr(X|[x])+λPNPr(¬X|[x])≤λBPPr(X|[x])+λBNPr(¬X|[x])⇔λPPPr(X|[x])+λPN(1−Pr(X|[x]))≤λBPPr(X|[x])+λBN(1−Pr(X|[x]))⇔Pr(X|[x])≥(λPN−λBN)(λPN−λBN)+(λBP−λPP).The second condition of rule (P) is expressed as:(7)1em0exR(aP|[x])≤R(aN|[x])⇔λPPPr(X|[x])+λPNPr(¬X|[x])≤λNPPr(X|[x])+λNNPr(¬X|[x])⇔λPPPr(X|[x])+λPN(1−Pr(X|[x]))≤λNPPr(X|[x])+λNN(1−Pr(X|[x]))⇔Pr(X|[x])≥(λPN−λNN)(λPN−λNN)+(λNP−λPP).Analogously, we can easily calculate the corresponding conditions for rule (B) and (N). In summary, the decision rules (P)–(N) can be expressed concisely with different criteria via Table 1.For simplicity, letα=(λPN−λBN)(λPN−λBN)+(λBP−λPP),β=(λBN−λNN)(λBN−λNN)+(λNP−λBP)andγ=(λPN−λNN)(λPN−λNN)+(λNP−λPP). In addition, as a well-defined boundary region, the conditions of rule (B) indicate α > β, namely,(λPN−λBN)(λPN−λBN)+(λBP−λPP)>(λBN−λNN)(λBN−λNN)+(λNP−λBP), which can be rewritten as11+(λBP−λPP)(λPN−λBN)>11+(λNP−λBP)(λBN−λNN)and(λBP−λPP)(λPN−λBN)<(λNP−λBP)(λBN−λNN). Because of the inequality(λBP−λPP)(λPN−λBN)<(λBP−λPP)+(λNP−λBP)(λPN−λBN)+(λBN−λNN)=(λNP−λPP)(λPN−λNN)<(λNP−λBP)(λBN−λNN), we have:0≤(λBN−λNN)(λBN−λNN)+(λNP−λBP)<(λPN−λNN)(λPN−λNN)+(λNP−λPP)<(λPN−λBN)(λPN−λBN)+(λBP−λPP)≤1, it implies 0 ≤ β < γ < α ≤ 1.Therefore, from the rules (P)-(N) in Table 1, the three regions in DTRS are given, respectively, by:(P1)1em0exIf0.35em0exPr(X|[x])≥α,0.35em0exdecide0.35em0exx∈0.35em0exPOS(X);(B1)1em0exIf0.35em0exβ<Pr(X|[x])<α,0.35em0exdecide0.35em0exx∈0.35em0exBND(X);(N1)1em0exIf0.35em0exPr(X|[x])≤β,0.35em0exdecide0.35em0exx∈0.35em0exNEG(X).From (P1) to (N1), the threshold parameters α and β in DTRS can be systematically calculated from the loss functions based on the Bayesian decision procedure with minimum-cost criterion, which gives us a solid theoretical basis to make three-way decisions.In this section, we focus on discussing the three-way decision model in IIS. First, we briefly introduce the basic concept of IIS and define a new similarity relation in IIS. Second, we combine the information table in IIS and loss function in DTRS together, and then propose a three-way based incomplete information system (TWIIS). Finally, we investigate the model and the algorithm to construct the three-way decisions in IIS.Definition 1[44]An information system (IS) is defined as a 4-tupleS=(U,A,V,f), where U denotes a non-empty finite set of objects, A stands for a non-empty finite set of attributes.V=∪a∈AVaand Vais a domain of the attribute a, andf:U×A→Vis an information function such that f(x, a) ∈ Vafor every x ∈ U, a ∈ A.An incomplete information system (IIS) indicates the precise attributes’ values Vafor some objects are unknown. In this paper, the IIS is still denoted without confusion byIIS=(U,A,V,f). Here,V=Va⋃{*}, the special symbol “∗” is used to indicate the unknown value. For instance, iff(x,a)=*, the value of object x is unknown on the attribute a.There are serval strategies to deal with incomplete information in rough sets. The early model to deal with incomplete data was presented by Kryszkiewicz under a tolerance relation [17]. In this case, all the unknown values are treated as “do not care” conditions, and the key point of this method is to assign a value of “null” as a value of “everything is possible” in IIS [20,57,21]. Following Kryszkiewicz’s definition, Stefanowski et al. [52] utilized a non-symmetric similarity relation to handle the incomplete information. In their definitions, objects are described “incompletely” due to human’s imperfect knowledge and definitely impossible descriptions of all their attributes [20]. In addition, Wang proposed [53] a limited tolerance relation to extend the limitation of aforementioned two definitions. Unlike the above three definitions, Grzymala-Busse [11] pointed out that there exists another explanation of missing value, namely, an attribute value is “lost”. In this case, the lost unknown value is a nonexisting one and it is not comparable with any other values in the domain of the corresponding attributes. Observed by the new explanation of incomplete information, Grzymala-Busse [11] proposed a characteristic relation by both considering the two semantic explanations (“do not care” and “lost” conditions) for IIS. Summarily, all the above mentioned methods give a reasonable interpretation of incomplete information with different perspective. In our following discussions, all the unknown values in IIS are considered as “do not care” conditions.Given anIIS=(U,A,V,f), suppose the IIS contains m objects and n attributes,U={x1,x2,⋯,xm},A={a1,a2,⋯,an}. For ∀x, y ∈ U, ∀ai∈ A, the relations between ai(x) and ai(y) can be treated as following four scenarios.•Consideration ofai(x)0.25em0ex≠0.25em0ex*andai(y)0.25em0ex≠0.25em0ex*,ai(x)and ai(y) are equally iffai(x)=ai(y);Consideration ofai(x)0.25em0ex≠0.25em0ex*andai(y)0.25em0ex≠0.25em0ex*,ai(x)and ai(y) are not the same ifai(x)0.25em0ex≠0.25em0exai(y);Consideration ofai(x)=*orai(y)=*, because of the unknown value “*” is treated as “do not care” conditions, it has the probability of1|Vai|to equal to one certain value ofVai(Vaiis a domain of the attributeai,|Vai|denotes the cardinality of ai).Consideration ofai(x)=ai(y)=*, both of ai(x) and ai(y) have the probability of1|Vai|to equal to one certain value ofVai, so the joint probability ofai(x)=ai(y)is1|Vai|2.With the above discussions, the similarity degree between x and y on aican be denoted in advance.Sim(ai)(x,y)={1ai(x)=ai(y)0.25em0ex≠0.25em0ex*;0ai(x)0.25em0ex≠0.25em0exai(y)∧ai(x)0.25em0ex≠0.25em0ex*∧0.35em0exai(y)0.25em0ex≠0.25em0ex*;1|Vai|ai(x)=*∨ai(y)=*;1|Vai|2ai(x)=*∧ai(y)=*.The similarity degree between x and y is calculated as:(8)Sim(x,y)=∑i=1nSim(ai)(x,y)nTable 2 gives an example to illustrate a car IIS [17]. In Table 2,U={x1,x2,⋯,x6}denotes six types of cars,A={a1,a2,a3,a4}describes the four attributes of these cars, namely, “Price”, “Mileage”, “Size” and “Max-Speed”. The domains of the 4 attributes are:Va1={high,low},Va2={high,low},Va3={full,compact},Va4={high,low}.According to Table 2 and (8), we easily get:Sim(a1)(x1,x2)=0,Sim(a2)(x1,x2)=0.5,Sim(a3)(x1,x2)=Sim(a4)(x1,x2)=1, andSim(x1,x2)=∑i=14Sim(ai)(x1,x2)4=(0+0.5+1+1)4=0.625. Similarly, we compute Sim(x, y) for ∀x, y ∈ U, which is outlined in Table 3.Based on (8), we define a new similarity relation to describe the similarity degree between any two objects x and y in U.Definition 3Given anIIS=(U,A,V,f). The L-level similarity relation, denoted bySRAL, is defined as:∀x,y,SRAL(x,y)⇔∀a∈A:Sim(x,y)=∑a∈ASim(a)(x,y)n≥L,For example, if we setL=0.5in Table 3, we have:[x1]SR0.5={x1,x2,x3,x4,x5},[x2]SR0.5={x1,x2,x6},[x3]SR0.5={x1,x3},[x4]SR0.5={x1,x4,x5,x6},[x5]SR0.5={x1,x4,x5,x6},[x6]SR0.5={x2,x4,x5,x6}.In the following, we define the two approximations and three decision regions of L-level similarity relation.Definition 4Given anIIS=(U,A,V,f). For ∀X⊆U, let 0 ≤ β ≤ α ≤ 1, the lower and upper approximations of L-level similarity relation can be defined as:(9)SRL̲(α,β)(X)={x∈U|Pr(X|[x]SRL)≥α},SRL¯(α,β)(X)={x∈U|Pr(X|[x]SRL)>β}.The two approximations of L-level similarity relation generate three decision regions as:(10)POS(α,β)L(X)={x∈U|Pr(X|[x]SRL)≥α},BND(α,β)L(X)={x∈U|β<Pr(X|[x]SRL)<α},NEG(α,β)L(X)={x∈U|Pr(X|[x]SRL)≤β}.The two key ingredients of previous studies on three-way models are the conditional probability and the two thresholds (α, β) [23,35,70]. The conditional probability of three-way decisions can be estimated from information table by using some machine learning methods [35,71,81]. Meanwhile, the thresholds of three-way decisions rely on the loss function, which is associated with decision makers [23–26,33,36]. Although, the aforementioned literatures make soiled contributions on the theoretical analysis of three-way decisions with different viewpoints, the integrated strategy by considering both information table and loss functions in three-way decisions, is rarely investigated. Motivated by these phenomena, we propose a hybrid information table, which consists both of the “information table” and “cost table”, to deal with the three-way decision model in IIS.Definition 5A three-way based incomplete information system (TWIIS) is defined asTWIIS=(IIS,CT),IIS=(U,A,V,f)is an information table andCT=(U,λ••)is a cost table. For x ∈ U, x in TWIIS can be represented by usingn+6vectors:f(x)=(Va1(x),Va2(x),⋯,Van(x);λPP(x),λBP(x),λNP(x),λNN(x),λBN(x),λPN(x)).As we stated in Section 2.2, the values of losses in DTRS model are precise real numbers. However, because of the IIS contains some null values “∗” for some attributes a ∈ A, it is reasonable to give rise an imprecise numbers to evaluate the loss functions in TWIIS. In consideration of interval is a common format to deal with imprecise issues, we utilize interval number to acquire the loss functionsλ••(•=P,B,N).In mathematics, an interval is a set of real numbers with the property that any number lies between two numbers in the set is also included in the set. The interval loss functions λ is denoted as:λ^=[λ−,λ+].λ^−,λ^+∈R. Given two intervalsλ1^=[λ1−,λ1+],λ2^=[λ2−,λ2+], then their interval operations are:λ1^+λ2^=[λ1−+λ2−,λ1++λ2+];λ1^−λ2^=[λ1−−λ2+,λ1+−λ2−];λ1^λ2^=[min(λ1−λ2−,λ1−λ2+,λ1+λ2−,λ1+λ2+),max(λ1−λ2−,λ1−λ2+,λ1+λ2−,λ1+λ2+)];λ1^/λ2^=[λ1−,λ1+]×[1/λ2+,1/λ2−],0.35em0exwhere0.35em0ex00.25em0ex∉0.25em0ex[λ2−,λ2+];kλ1^=[kλ1−,kλ1+],0.35em0exwhere0.35em0exk∈R,k≥0.With the definition and operations of interval numbers, we construct a new three-way decision model with incomplete information. The loss function regarding the risk or cost of actions in TWIIS is given by the following matrix:X(P)¬X(N)aPλPP^=[λPP−,λPP+]λPN^=[λPN−,λPN+]aBλBP^=[λBP−,λBP+]λBN^=[λBN−,λBN+]aNλNP^=[λNP−,λNP+]λNN^=[λNN−,λNN+]λ••−andλ••+are the lower bound and the upper bound ofλ••^(•=P,B,N).λPP^=[λPP−,λPP+],λBP^=[λBP−,λBP+],λNP^=[λNP−,λNP+]denote the losses incurred for taking actions of aP, aBand aN, respectively, when an object belongs to X. Similarly,λPN^=[λPN−,λPN+],λBN^=[λBN−,λBN+]andλNN^=[λNN−,λNN+]denote the losses incurred for taking the same actions when the object belongs to¬X. Obviously, the loss functions in TWIIS satisfy the following conditions:(11)λPP−≤λBP−<λNP−,λPP+≤λBP+<λNP+;λPN−≤λBN−<λNN−,λPN+≤λBN+<λNN+.The expected lossR(ai|[x]SRL)associated with taking the individual actions in TWIIS can be expressed as:(12)R(aP|[x]SRL)=λPP^Pr(X|[x]SRL)+λPN^Pr(¬X|[x]SRL)=[λPP−,λPP+]Pr(X|[x]SRL)+[λPN−,λPN+]Pr(¬X|[x]SRL),R(aB|[x]SRL)=λBP^Pr(X|[x]SRL)+λBN^Pr(¬X|[x]SRL)=[λBP−,λBP+]Pr(X|[x]SRL)+[λBN−,λBN+]Pr(¬X|[x]SRL),R(aN|[x]SRL)=λNP^Pr(X|[x]SRL)+λNN^Pr(¬X|[x]SRL)=[λNP−,λNP+]Pr(X|[x]SRL)+[λNN−,λNN+]Pr(¬X|[x]SRL).SincePr(X|[x]SRL)+Pr(¬X|[x]SRL)=1, (12) is further computed:(13)R(aP|[x]SRL)=[λPP−Pr(X|[x]SRL)+λPN−(1−Pr(X|[x]SRL)),λPP+Pr(X|[x]SRL)+λPN+(1−Pr(X|[x]SRL))],R(aB|[x]SRL)=[λBP−Pr(X|[x]SRL)+λBN−(1−Pr(X|[x]SRL)),λBP+Pr(X|[x]SRL)+λBN+(1−Pr(X|[x]SRL))],R(aN|[x]SRL)=[λNP−Pr(X|[x]SRL)+λNN−(1−Pr(X|[x]SRL)),λNP+Pr(X|[x]SRL)+λNN+(1−Pr(X|[x]SRL))].According to Bayesian decision procedure, the decision rules (P)-(N) in Section 2.2 can be re-expressed as:(P2)1em0exIf0.35em0exR(aP|[x]SRL)≤R(aB|[x]SRL)0.35em0exand0.35em0exR(aP|[x]SRL)≤R(aN|[x]SRL),0.35em0exdecide0.35em0ex[x]SRL∈0.35em0exPOS(X);(B2)1em0exIf0.35em0exR(aB|[x]SRL)≤R(aP|[x]SRL)0.35em0exand0.35em0exR(aB|[x]SRL)≤R(aN|[x]SRL),0.35em0exdecide0.35em0ex[x]SRL∈0.35em0exBND(X);(N2)1em0exIf0.35em0exR(aN|[x]SRL)≤R(aP|[x]SRL)0.35em0exand0.35em0exR(aN|[x]SRL)≤R(aB|[x]SRL),0.35em0exdecide0.35em0ex[x]SRL∈0.35em0exNEG(X).With respect to (P2)-(N2), one can directly make a decision by comparing the relation amongR(aP|[x]SRL),R(aB|[x]SRL)andR(aN|[x]SRL).During three-way decision procedure in (10), the decision maker need compare the conditional probabilityPr(X|[x]SRL)and the thresholds (α, β) of TWIIS to determine the decisions. On the one hand,Pr(X|[x]SRL)is depended on the L-level similarity class[x]SRL; on the other hand, the two thresholds α and β generated from the TWIIS are related to the loss functionsλ••. In our following discussions, we focus on investigating the strategies, the model construction process, and the key steps to construct the three-way decisions in IIS.First of all, it is necessary to clearly illustrate the difference between DTRS and our proposed model. In DTRS model [66,67], the conditional probability Pr(X|[x] is related to an equivalence class [x] ([x] is generated by a given object x), and the loss functions to evaluate all x ∈ [x] are the same precise numbers ofλ••. In TWIIS, as we stated in Section 3.2, the loss function is considered as an intervalλ^=[λ−,λ+]. Furthermore, the conditional probabilityPr(X|[x]SRL)is related to[x]SRL. Because of[x]SRLis not an equivalence class, different objects in a certain L-level similarity class (e.g., x2 and x6 in[x2]SR0.5, see Table 2) may have different loss functions. With the insightful gain from the above analysis, we propose two strategies to aggregate the different loss functions in TWIIS.Definition 6Given aTWIIS=(U,A,V,f,λ••),∀x∈U, we denote the loss function for x asλ••^(x)(•=P,B,N). The aggregated loss function for[x]SRLcan be defined as the following two scenarios:•Optimistic aggregated loss function:λ••Opt([x]SRL)=⋃x∈[x]SRLλ••^(x);Pessimistic aggregated loss function:λ••Pess([x]SRL)=⋂x∈[x]SRLλ••^(x).In Definition 6, the optimistic strategy utilizes the union of all individualλ••^(x)to generate the aggregated loss functionλ••Opt([x]SRL), it adopts all possible values ofλ••^(x). As well, the pessimistic strategy utilizes the intersection of all individualλ••^(x)to generate the aggregated loss functionλ••Pess([x]SRL), it only adopts the overlap values of allλ••^(x).Then, observed by the two types of aggregated loss functionsλ••Opt([x]SRL)andλ••Pess([x]SRL)are interval sets, we introduce the θ ranking method to transform an interval into a real number [24]. The transformed formula is described as follows:Definition 7Let an intervalλ^=[λ−,λ+],θ∈[0,1], the transformed formula ofλ^is:(14)fθ(λ^)=(1−θ)λ−+θλ+,In (14),fθ(λ^)is a real number. The risk-averters choose a higher θ because they hate the higher risk and put higher costs with wrong decisions. On the contrary, the risk-lovers search for high-risk and high-return and they put lower θ and lower costs with wrong decisions. Specially, ifθ=1,0.35em0exf1(λ^)=λ+, the risk-averters choose the upper bound offθ(λ^); ifθ=0,f0(λ^)=λ−, the risk-lovers choose the lower bound offθ(λ^);θ=0.5,f0.5(λ^)=λ−+λ+2represents the view point of a risk neutral. All the above situation are the three special cases offθ(λ^). Furthermore, supposeλ^1=[λ1−,λ1+],λ^2=[λ2−,λ2+], iffθ(λ^1)≤fθ(λ^2), thenλ^1⪯λ^2, and vice versa.Proposition 1On the basis ofDefinition 7and(11), we have:(15)fθ(λ^PP)≤fθ(λ^BP)<fθ(λ^NP);fθ(λ^NN)≤fθ(λ^BN)<fθ(λ^PN).According to Definition 7,fθ(λPP^)=(1−θ)λPP−+θλPP+,fθ(λBP^)=(1−θ)λBP−+θλBP+,fθ(λNP^)=(1−θ)λNP−+θλNP+. On the condition ofλPP−≤λBP−<λNP−andλPP+≤λBP+<λNP+, we have:fθ(λ^PP)≤fθ(λ^BP)<fθ(λ^NP). Analogously,fθ(λ^NN)≤fθ(λ^BN)<fθ(λ^PN)holds. □The θ ranking method is chosen as a representative certain method to elaborate three-way decisions. According to Definitions 7, (11) and (12), decision rules (P2)-(N2) in TWIIS can be further expressed as:(P3)1em0exIf0.35em0exfθ(R(aP|[x]SRL^))≤fθ(R(aB|[x]SRL^))0.35em0exand0.35em0exfθ(R(aP|[x]SRL^))≤fθ(R(aN|[x]SRL^)),0.35em0exdecide0.35em0ex[x]SRL∈POS(X);(B3)1em0exIf0.35em0exfθ(R(aB|[x]SRL^))≤fθ(R(aP|[x]SRL^))0.35em0exand0.35em0exfθ(R(aB|[x]SRL^))≤fθ(R(aN|[x]SRL^)),0.35em0exdecide0.35em0ex[x]SRL∈BND(X);(N3)1em0exIf0.35em0exfθ(R(aN|[x]SRL^))≤fθ(R(aP|[x]SRL^))0.35em0exand0.35em0exfθ(R(aN|[x]SRL^))≤fθ(R(aB|[x]SRL^)),0.35em0exdecide0.35em0ex[x]SRL∈NEG(X),where,fθ(R(aP|[x]SRL^))=(1−θ)(λPP−Pr(X|[x]SRL)+λPN−Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex2em0ex+θ(λPP+Pr(X|[x]SRL)+λPN+Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)((1−θ)λPP−+θλPP+)2em0ex2em0ex2em0ex2em0ex+(1−Pr(X|[x]SRL))((1−θ)λPN−+θλPN+)2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)fθ(λPP^)+(1−Pr(X|[x]SRL))fθ(λPN^),fθ(R(aB|[x]SRL^))=(1−θ)(λBP−Pr(X|[x]SRL)+λBN−Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex2em0ex+θ(λBP+Pr(X|[x]SRL)+λBN+Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)((1−θ)λBP−+θλBP+)2em0ex2em0ex2em0ex2em0ex+(1−Pr(X|[x]SRL))((1−θ)λBN−+θλBN+)2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)fθ(λBP^)+(1−Pr(X|[x]SRL))fθ(λBN^),fθ(R(aN|[x]SRL^))=(1−θ)(λNP−Pr(X|[x]SRL)+λNN−Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex2em0ex+θ(λNP+Pr(X|[x]SRL)+λNN+Pr(¬X|[x]SRL))2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)((1−θ)λNP−+θλNP+)2em0ex2em0ex2em0ex2em0ex+(1−Pr(X|[x]SRL))((1−θ)λNN−+θλNN+)2em0ex2em0ex2em0ex1em0ex=Pr(X|[x]SRL)fθ(λNP^)+(1−Pr(X|[x]SRL))fθ(λNN^).Based on (15), decision rules (P3)-(N3) of three-way decisions can be simplified as:(P3′)1em0exIf0.35em0exPr(X|[x]SRL)≥α^0.35em0exand0.35em0exPr(X|[x]SRL)≥γ^,0.35em0exdecide0.35em0ex[x]SRL∈POS(X);(B3′)1em0exIf0.35em0exPr(X|[x]SRL)≤α^0.35em0exand0.35em0exPr(X|[x]SRL)≥β^,0.35em0exdecide0.35em0ex[x]SRL∈BND(X);(N3′)1em0exIf0.35em0exPr(X|[x]SRL)≤β^0.35em0exand0.35em0exPr(X|[x]SRL)≤γ^,0.35em0exdecide0.35em0ex[x]SRL∈NEG(X).The thresholds valuesα^,β^,γ^are given by:(16)α^=(fθ(λPN^)−fθ(λBN^))(fθ(λPN^)−fθ(λBN^))+(fθ(λBP^)−fθ(λPP^)),β^=(fθ(λBN^)−fθ(λNN^))(fθ(λBN^)−fθ(λNN^))+(fθ(λNP^)−fθ(λBP^)),γ^=(fθ(λPN^)−fθ(λNN^))(fθ(λPN^)−fθ(λNN^))+(fθ(λNP^)−fθ(λPP^)).In addition, as a well-defined boundary region, the conditions of rule (B3) suggest thatα^>β^, that is,fθ(λBP^)−fθ(λPP^)fθ(λPN^)−fθ(λBN^)<fθ(λNP^)−fθ(λBP^)fθ(λBN^)−fθ(λNN^).It implies0≤β^<γ^<α^≤1. In this case, after tie-breaking, the following simplified rules are obtained:(P3′′)2em0exIf0.35em0exPr(X|[x]SRL)≥α^,0.35em0exdecide0.35em0ex[x]SRL∈POS(X);(B3′′)2em0exIf0.35em0exβ^<Pr(X|[x]SRL)<α^,0.35em0exdecide0.35em0ex[x]SRL∈BND(X);(N3′′)2em0exIf0.35em0exPr(X|[x]SRL)≤β^,0.35em0exdecide0.35em0ex[x]SRL∈NEG(X).Besides, we also can obtain another conditionα^≤β^, that is,fθ(λBP^)−fθ(λPP^)fθ(λPN^)−fθ(λBN^)≥fθ(λNP^)−fθ(λBP^)fθ(λBN^)−fθ(λNN^).It implies0≤α^<γ^<β^≤1. In this case, after tie-breaking, the following simplified rules are obtained:(P3′′)1em0exIf0.35em0exPr(X|[x]SRL)≥γ^,0.35em0exdecide0.35em0ex[x]SRL∈POS(X);(N3′′)1em0exIf0.35em0exPr(X|[x]SRL)≤γ^,0.35em0exdecide0.35em0ex[x]SRL∈NEG(X).With respect to (P3‴)-(N3‴), the three-way decisions in TWIIS convert to two-way decisions.In this subsection, we summarize four key steps to construct the integrated approach. The algorithm for deriving three-way decisions in TWIIS is outlined in Algorithm 1.Step1: Given aTWIIS=(U,A,V,f,λ••). For x ∈ U, we compute[x]SRL=⋃y∈U{y|Sim(x,y)≥L}with a certain L.Step2: For x ∈ U, we utilize the optimistic and pessimistic strategies to compute the two types of aggregated loss func- tionsλ••Opt([x]SRL([x]SRL))andλ••Pess([x]SRL([x]SRL)), respectively.Step3: Given a certain θ, we computefθ(λ••Opt([x]SRL))andfθ(λ••Pess([x]SRL))for each x ∈ U.Step4: Given a concept X⊆U, we use (16) to compute the three thresholdsα^,β^andγ^for each x, and generate it’s corresponding three-way decision rules.The algorithm for deriving three-way decisions in TWIIS.In this section, we utilize a didactic example of medical diagnosis to illustrate the proposed model. As we know, the medical diagnosis is the process of determining which disease or condition explains a person’s symptoms and signs. In our following discussions, we investigate the problem on diagnosis of common cold with three-way decisions.The criteria on judging a flu patient depend on a series of symptoms (such as temperature, cough, nausea, headache, nose snivel, excessive phlegm, dysentery, etc.). A medical diagnosis hybrid information tableTWIIS=(U,A,V,f,λ••)is used to explain the process of medical diagnosis in Table 4, and the data is collected by a hospital. In Table 4,U={x1,x2,⋯,x12}represents 12 different types of patients;A={a1,a2,⋯,a7}represents aforementioned 7 different symptoms;λ••denotes the loss function when one takes a certain action with it’s corresponding state. In more detail, the set of states is given byΩ={X,¬X}, which indicate whether a person get a cold or not, respectively. λPP, λBPand λNPdenote the losses incurred for receiving treatment, further observation and do not treatment, respectively, when a person catches a cold. Similarly, λPN, λBNand λNNdenote the losses incurred for taking the same actions when a person is normal. Furthermore, on consideration of the collected data may exist some missing values, the interval numbers are utilized to represent the loss functions in Table 4. As stated in Section 3.2, we assumeλPP−(x)≤λBP−(x)≤λNP−(x),λPP+(x)≤λBP+(x)≤λNP+(x);λNN−(x)≤λBN−(x)≤λPN−(x),λNN+(x)≤λBN+(x)≤λPN+(x)for each x ∈ U. The corresponding loss functions for each patient are carefully estimated by the doctor.In Table 4, the meaning of the values for every attribute (symptom) is explained as follows.Temperature (a1): 1=High; 2=A little high; 3=Normal, *=missing value.Cough (a2): 1=Yes; 2=No, *=missing value.Nausea (a3): 1=Yes; 2=No, *=missing value.Headache (a4): 1=Serious; 2=A little; 3=No, *=missing value.Nose snivel (a5): 1=Yes; 2=No, *=missing value.Excessive phlegm (a6): 1=Yes; 2=No, *=missing value.Dysentery (a7): 1=Serious; 2=A little; 3=No, *=missing value.First, we compute the similarity degree Sim(xi, xj) for all xi, xj∈ U. The calculating results of similarity degree Sim(xi, xj) are outlined in Table 5.In Table 5, because of the majority rule in decision making, letL=0.5+ɛ(ε is a positive infinitesimal number). We have:[x1]SRL={x1,x4,x7,x8,x9,x12},0.35em0ex[x2]SRL={x2,x6,x10,x11},[x3]SRL={x3,x4,x5,x6},0.35em0ex[x4]SRL={x1,x3,x4,x5,x7,x8,x9,x12},[x5]SRL={x3,x4,x5,x9,x12},0.35em0ex[x6]SRL={x2,x3,x6,x10,x11},[x7]SRL={x1,x4,x7,x8},0.35em0ex[x8]SRL={x1,x4,x7,x8,x9},[x9]SRL={x1,x4,x5,x8,x9,x12},0.35em0ex[x10]SRL={x2,x6,x10,x11},[x11]SRL={x2,x6,x10,x11},0.35em0ex[x12]SRL={x1,x4,x5,x9,x12}.Given a conceptX={x1,x4,x5,x7,x8,x9}(X means these patients have a higher probability to get a cold from history data in a hospital).The conditional probabilityPr(X|[x]SRL)for every x in Table 4 can be calculated as:Pr(X|[x1]SRL)=[x1]SRL⋂X[x1]SRL={x1,x4,x7,x8,x9,x12}⋂{x1,x4,x5,x7,x8,x9}{x1,x4,x7,x8,x9,x12}=0.833;Pr(X|[x2]SRL)=[x2]SRL⋂X[x2]SRL={x2,x6,x10,x11}⋂{x1,x4,x5,x7,x8,x9}{x2,x6,x10,x11}=0;Pr(X|[x3]SRL)=[x3]SRL⋂X[x3]SRL={x3,x4,x5,x6}⋂{x1,x4,x5,x7,x8,x9}{x3,x4,x5,x6}=0.5;Pr(X|[x4]SRL)=[x4]SRL⋂X[x4]SRL={x1,x3,x4,x5,x7,x8,x9,x12}⋂{x1,x4,x5,x7,x8,x9}{x1,x3,x4,x5,x7,x8,x9,x12}=0.75;Pr(X|[x5]SRL)=[x5]SRL⋂X[x5]SRL={x3,x4,x5,x9,x12}⋂{x1,x4,x5,x7,x8,x9}{x3,x4,x5,x9,x12}=0.6;Pr(X|[x6]SRL)=[x6]SRL⋂X[x6]SRL={x2,x3,x6,x10,x11}⋂{x1,x4,x5,x7,x8,x9}{x2,x3,x6,x10,x11}=0;Pr(X|[x7]SRL)=[x7]SRL⋂X[x7]SRL={x1,x4,x7,x8}⋂{x1,x4,x5,x7,x8,x9}{x1,x4,x7,x8}=1;Pr(X|[x8]SRL)=[x8]SRL⋂X[x8]SRL={x1,x4,x7,x8,x9}⋂{x1,x4,x5,x7,x8,x9}{x1,x4,x7,x8,x9}=1;Pr(X|[x9]SRL)=[x9]SRL⋂X[x9]SRL={x1,x4,x5,x8,x9,x12}⋂{x1,x4,x5,x7,x8,x9}{x1,x4,x5,x8,x9,x12}=0.833;Pr(X|[x10]SRL)=[x10]SRL⋂X[x10]SRL={x2,x6,x10,x11}⋂{x1,x4,x5,x7,x8,x9}{x2,x6,x10,x11}=0;Pr(X|[x11]SRL)=[x11]SRL⋂X[x11]SRL={x2,x6,x10,x11}⋂{x1,x4,x5,x7,x8,x9}{x2,x6,x10,x11}=0;Pr(X|[x12]SRL)=[x12]SRL⋂X[x12]SRL={x1,x4,x5,x9,x12}⋂{x1,x4,x5,x7,x8,x9}{x1,x4,x5,x9,x12}=0.8.Then, following the Definition 6, we utilize the optimistic and pessimistic strategies to calculate the two types of aggregated loss functions for all patients in Table 4. The calculating results are displayed in Tables 6 and 7, respectively.In addition, suppose the doctor is a risk neutral and fixesθ=0.5, we further calculate the three thresholdsα^,β^andγ^for every types of patient under both optimistic and pessimistic views. Table 8 lists the corresponding computing results, and the underlined values in Table 8 denote the valid parameters for the 12 types of patients.LetL=0.5+ɛ,θ=0.5. The three-way decision rules with the optimistic and pessimistic strategies, can be derived by comparing the conditional probabilityPr(X|[x]SRL)and three thresholds generated from Table 8. The decision results of each types of patients are displayed in Table 9.According to Table 9, we can easily get: {x1, x4, x5, x7, x8, x9, x12} ∈ POS(X), {x3} ∈ BND(X), {x2, x6, x10, x11} ∈ NEG(X) with the optimistic three-way decisions strategy; {x1, x4, x5, x7, x8, x9, x12} ∈ POS(X), {x2, x3, x6, x10, x11} ∈ NEG(X) with the pessimistic three-way decisions strategy. Compared with the three-way decision results and X, x3 was not catch a cold in history data, but it should be further diagnosis based on optimistic three-way decisions strategy; x12 was also not catch a cold in history data, but it should be diagnosed as catch a cold based on both optimistic and pessimistic three-way decisions strategy. Therefore, three-way decisions provide a way to rectify the misclassifications in real decision making procedure [35].In the following, we do some simulations and sensitivity analysis to illustrate our method. As we mentioned in Section 3.3.3 and Algorithm 1, the key steps for deriving three-way decisions in TWIIS are depended on the two parameters L and θ. In our experiments, we set L ∈ [0.6, 1] with step 0.1 and θ ∈ [0, 1] with step 0.25. For simplicity, we use a three dimensional vector(α^,β^,γ^)to describe the three thresholds in three-way decisions. The calculating results of conditional probabilityPr(X|[x]SRL)for x ∈ U are listed in Table 10 when L changes. Furthermore, when L and θ change, we take x1, x3 and x12 for examples. The three parameters(α^,β^,γ^)are shown in Tables 11–13.By comparison of Tables 10–13, one can derive three-way decision rules form TWIIS. For example, if we setL=0.6andθ=1, we have: x1 ∈ POS(X), x3 ∈ BND(X) and x12 ∈ POS(X) with the optimistic three-way decisions strategy; x1 ∈ POS(X), x3 ∈ NEG(X) and x12 ∈ BND(X) with the pessimistic three-way decisions strategy.In the following, we also take x1, x3 and x12 for examples, and do a serious of simulation experiments when L and θ change simultaneously. Our experiment’s strategy is using three dimensional vector groups(L,θ,,α^),(L,θ,β^)and(L,θ,γ^)to describe the variation trend of the three parameters with both optimistic and pessimistic perspectives. Figs. 1–3 outline the experiment’s results when L ∈ [0.5, 1] and θ ∈ [0, 1].From Figs. 1–3, one can directly get the three-way decision rules for all the patients by comparing the probabilistic evidencePr(X|[x]SRL)and the parameters(α^,β^,γ^). For simplicity, Table 14 displays the calculating results with different L and θ.In Table 14, the parameter L dominates the similarity degree between two different objects in an IIS. The value of L presents the tightness of the similarity relation SR, which is decided by the information system itself. However, the parameter θ describes the risk attitude of a decision maker, and it is man-made. To sum up, our method integrates the two scenarios together and provides a man–machine viewpoints on three-way decisions. The decision maker can directly acquire the corresponding decision rules with different values of L and θ via Table 14.

@&#CONCLUSIONS@&#
In this paper, we investigate the three-way decision procedure with incomplete information. Different from the existing researches on three-way decisions, we combine the incomplete information table and loss function table together, and further propose a hybrid information table to illustrate our ideas. Furthermore, in the view of the uncertain issues presented in incomplete information, we adopt the interval number to acquire the loss functions in our model. An illustrative example of medical diagnosis is utilized to illustrate the three-way decision procedure in IIS. We believe our researches can build a bridge to connect the rough sets and decision theory with three-way decisions. Our future research work will focus on the extension of the proposed method with group decision making and other uncertainty measures. The conflict phenomena in group decision making of three-way decisions should be further investigated.