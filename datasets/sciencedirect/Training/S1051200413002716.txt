@&#MAIN-TITLE@&#
Overview of Bayesian sequential Monte Carlo methods for group and extended object tracking

@&#HIGHLIGHTS@&#
An overview is provided of key sequential Monte Carlo methods for group and extended object tracking.Current achievements, trends and challenges are presented.Efficient implementations of sequential Monte Carlo algorithms in distributed and parallel ways.

@&#KEYPHRASES@&#
Sequential Monte Carlo methods,Group and extended object tracking,Markov chain Monte Carlo methods,Nonlinear filtering,Metropolis Hastings,Reasoning over time,

@&#ABSTRACT@&#
Graphical abstractIllustration of Tracking Groups/Extended Objects with the Bayesian approach. The peaks of the posterior state probability density function (shown on the top) correspond to the two groups G1 and G2 (visualized at the bottom). Based on the peaks one can deduce where the positions of the groups are.In recent years there has been an increasing interest in tracking a number of objects moving in a coordinated and interacting fashion. There are many fields in which such situations are frequently encountered: video surveillance, sport events, biomedicine, neuroscience, meteorology, situation awareness and search rescue operations, to mention but a few. Although individual objects in the group can exhibit independent movement at a certain level, overall the group moves as one whole, synchronously with respect to the individual entities and avoiding collisions.Terminology. Groups are structured objects, formations of entities moving in a coordinated manner, whose number varies over time because targets can enter a scene, or disappear at random times. The groups can split, merge, can be relatively near to each other or move independently of each other. What is typical for group formations is that they maintain certain patterns of motion. Some typical examples are: formations of aircrafts and ships, respectively, for air traffic control, sea, harbor or land surveillance [45,124], flocks of bird migration trajectories for ecological purposes, tracking groups of cells [38,107,149,127] (for in vitro purposes, stem cells, cardiovascular treatment and other medical diagnostics), a group of robots (for industrial tasks), a group of football players [152] in sport videos, convoys of vehicles and groups of pedestrians for traffic management [3]. Within this broad range of problems, one can distinguish two main classes: (1) tracking of multiple groups with only a few components per group, which is called small groups tracking, and (2) groups with a relatively large number of constituents whose individual members cannot be easily distinguished, termed large groups. Large groups are also often referred as to crowds or clusters.A related but distinct is the problem of tracking extended objects, such as a cyclist and maritime vessels [5]. Extended objects cannot be considered as points but instead have a spatial extent characterizing their size or volume [74]. They are usually modeled with simple geometrical shapes which are typically circles [111], ellipses [117], rectangles [10,11,51,55,56], closed contours or arbitrary shapes such as star-convex contours [9]. Other examples are tracking a cloud [69,122] of radio-active materials and a human face or hand in video [21]. Human body limb tracking is also often referred to extended target tracking.Challenges and differences. The challenges in solving the task for groups with a small number of components differ from those of groups with a large number of components. In small groups it is possible to model the interactions and interrelationships between the components within a group. The difficulties with groups of hundreds or thousands of objects (such as pedestrians and riots in video surveillance and radar based tracking of hundreds of aircraft) are mainly due to two reasons: (1) the individual objects cannot be distinguished/identified within the group, (2) the information and features extracted by the sensors are not sufficient to track those objects. Hence, one considers the aggregated motion of the whole group. In small groups one can estimate the states of each particular object and parameters characterizing the size or volume of the group. In large groups by contrast, one typically considers the group as a geometric shape and its centre coordinates.Similarities. Both groups of objects and extended objects give rise to a large, varying number of measurements and require a flexible framework able to deal with all these challenges. Although the methods for solving these two kinds of problems vary, there is a common approach in which both extended and large group of targets are seen as the same problem. The large group or extended object is surrounded with a shape (e.g. a circle) and the center and extent of this shape are sequentially computed based on the incoming data. Consequently, in this paper, the choice is made to classify the existing works in the literature into methods dealing with small groups and method dealing with large groups and for extended objects.This classification of extended/group objects is according to whether: (1) the group/extended object is rigid and unchanging in shape/size, (2) whether individual entities can be tracked dynamically and interact with one another.Examples of non-rigid extended objects are radioactive clouds. They can be spawn and also disappear. The group tracking and non-rigid extended object tracking lead to dynamic state and varying parameter estimation. Rigid extended targets such as submarines, ships, have fixed shapes and fixed size. This leads to dynamic state and static parameter estimation.The aim of this paper is to expose the reader to the various aspects of the problems of group and extended object tracking, underlying difficulties, and the key factors facilitating their solution in the context of Bayesian estimation. An overview of the state-of-the-art concepts and methodologies underlying contemporary Monte Carlo-based group and extended object tracking schemes is provided. The taxonomy of methods is given in Section 1.2 and background knowledge in Section 2. Methodologies for small group tracking are described in Section 3 and for large groups and extended objects in Section 4. The high dimensionality of the problem and the need of real time implementation calls for efficient algorithmic implementations, in a distributed and parallelized way, which are discussed in Section 5. Future avenues are summarized in Section 6.Over the past decade various methods have been developed for group and extended object tracking. These can be divided into two broad classes depending on the underlying complexities:1.Methods for a relatively small number of groups, with a small number of group components [51,109,76,6].Methods for groups comprised of hundreds or thousands of objects (normally referred to as cluster/extended object/crowd tracking): track before detect methods for extended objects [18,17], Poisson likelihood approaches [48,49,120,22], groups' extent parameter estimation and random matrix techniques [5,8,75,74,46], parametric level curves [69,122], and random finite sets [94,143,136,137,86,91], including the Bernouli random finite set filters [116,113].Figs. 1 and 2present the taxonomy of methods for tracking small groups and respectively large groups/extended objects. Details are given in the next sections.Results for small groups with a fixed number of targets are presented in [66,48,139,42]. These SMC algorithms exploit point process formulations for properly assigning measurements to their originating targets. As part of this, smart procedures are used to eliminate non-probable association hypotheses. Other SMC schemes adopt various approaches for dealing with the high dimensionality problem [121,77].An extension of the SMC technique to a varying number of targets is introduced in [141] and [73]. In [73,109] sequential Markov Chain Monte Carlo (MCMC) techniques are developed for tracking varying numbers of interacting objects. The MCMC approach has advantages over the conventional particle filter (PF) due to its efficient sampling mechanism [24,22,109]. Interacting population MCMC algorithms are presented in [16,15,14]. The approach proposed in [36] represents an extension of the MCMC method proposed in [73]. However, in [36] measurement clustering is combined with nonparametric prior information and the variational Bayes approach.The methods for tracking small groups can be further divided into: (1) methods that take into account the interactions between group components and (2) methods that ignore such interactions. The latter class of methods are the standard Bayesian techniques that track each object separately (e.g., generic particle filters, Extended Kalman filters, Unscented Kalman Filters, Multiple Hypothesis Tracking (MHT) filters [6] and others). These methods have been extensively studied in the literature [114,89].The former class of methods which consider object' interactions is much more compelling (see e.g. [71,72,7,73]). Although it has received attention in recent years, there is still a wealth of challenges most of which concern the group structure evolution and transitions [89,55].The predominant strategy consists in incorporating local interaction rules into the object state dynamics. Normally, individual objects are labeled [109] and tracked along with the group structure [51]. For a small number of objects, one obtains only a few likely group structures. The object states are updated at every time step using models for appearance (birth) of an object, or disappearance (death) of an object and spawning objects [89,29,108,94,93]. Analogously, the group structure is updated taking into account only a few admissible transitions which are determined from physical constraints such as groups' spatial extent and proximity. Interactions at the group level are subject to transitions in addition to the aforementioned ones. Thus, apart from birth and disappearance, two additional moves that are commonly attributed to groups are splitting and merging.Alternatively, group structure dynamics can be modeled by means of graph-theoretic approaches and evolving networks [51]. In this approach, group components take the role of vertices in a graph where edges embody interrelations among objects. As the group evolves over time, the graph is adapted to reflect the instantaneous structure. This essentially involves removing or adding nodes and updating edges accordingly. Markov random fields can be used in a similar fashion for modeling group interactions [71,72,7,73]. Other works use the multi-goal social force model [100,110] for pedestrian tracking which extends the social force model proposed in [62] or macroscopic models [28].Fig. 3illustrates the time evolution of a few groups depicted with distinct colors. The event of one group creating another group is called spawning or splitting. The opposite event when multiple groups are combined into a single group is called merging. At time stept1there are two groups: group 1 with three components (the upper group, indicated in red) and group 2, with three components (the lower group, indicated in blue). The empty circles correspond to noisy measurements (e.g. clutter11In radar applications clutter signifies signal reflected from the environment, instead of from the objects of interest.). Splitting and merging is demonstrated in the 2nd and 3rd time-steps, respectively. For clarity, objects' interrelations are mostly omitted in this depiction. They are, nevertheless, suggested for the last time-step in the right-hand-side ellipses.When the number of entities becomes excessively large it is impractical to track them all individually. Thus, instead of tracking separate components, large group techniques identify and track concentrations, e.g. the center of the group and its extent parameter. In this respect groups and extended object tracking are similar problems. The entities forming the concentrations may be objects, measurements or features. This strategy is applied in practice by utilizing extent variables which represent the spatial shape and dynamics of a group. In typical scenarios, groups are characterized by the location and velocity of the group center, their shape and shape deformation [9].Another promising approach for modeling large groups is based on the social force model [101,2].For large groups (and extended objects), the group density and shape are closely related. The posterior pdf of the joint state and extent parameter vector can, for example, be considered as a mixture of Gaussians [22]. This is primarily due to the convenient parametric representation which involves the first two statistical moments of the Gaussians, but other representations are possible. Here, the mean and covariance of the Gaussian mixture are, respectively, the center and shape of the group or extended object. Normally, the extent parameters are considered as both random and dynamic, and as such are governed by appropriate transition kernels. These approaches are capable of simulating complex dynamically evolving shape boundaries, and even compete with sophisticated contour tracking methodologies (see for example [69,122]).The measurement origin uncertainty in group and extended objects can be dealt with in an efficient way [48,49,120,22] if the numbers of received target and clutter measurements are considered Poisson distributed (implying that several measurements may originate from each target).A different, albeit related, modeling approach is considered in [5,8,75,74,46] where the group extent represents a parameter, estimated as part of an augmented state vector, jointly with the position coordinates of the group center. Except for [5], all other works in this group employ either Kalman filtering techniques [6] or random finite set approaches [89]. In general, the extent is considered as a random process and hence is normally assigned a respective prior (e.g., Wishart distribution [75,74,46]) and a transition kernel.The random finite set approach is a powerful tool that has been widely used in recent years [89]. Random finite sets are mathematical objects that can elegantly capture the subtleties involved in multiple object tracking and data fusion. It was not until recently that these methods have been employed for group and extended object tracking. The works [94,143,136,137] demonstrate the viability of the well-known Probability Hypothesis Density (PHD) filter in solving group tracking problems. These approaches are discussed extensively in the methodological part of this paper.Fluid dynamic models have also been shown to capture well aggregated vehicular traffic phenomena, in combination with SMC methods [103], for the purposes of freeway traffic tracking. A large body of work is devoted for modeling pedestrians flows in open and enclosed regions, e.g. [67,81,153] and weather forecasts [138].In what follows, we present the generic SMC framework followed by more sophisticated approaches.Consider the discrete-time nonlinear non-Gaussian motion model(1)xk=f(xk−1,vk−1),(2)zk=h(xk,nk),wherexkis the system state vector which has to be estimated in timek=1,2,…;zkrepresents the measurement obtained at time k;f(.)andh(.)are nonlinear system and measurement functions, respectively;vkandnkare mutually independent noise vectors, respectively, the system noise and the measurement noise. The state vectorxkcharacterizes the objects of interest and jointly withf(.)describe the motion interactions of the objects.The aim of SMC methods, known also as particle filters [54,41,43,61,119,39,27] is to represent with “particles” the posterior state probability density function given the sensor measurements,p(xk|Z0:k), whereZ0:k={z0,…,zk}is the observation history up to time k. Two major stages can be distinguished: prediction and update. During prediction, each particle (point mass representation of the probability density) is modified according to the state model, including the addition of random noise in order to simulate the effect of the noise on the state. In the measurement update stage, each particle's weight is re-evaluated based on the new data. Hence, during the prediction step the “cloud of particles” is usually spread/expanded due to the system noise, whereas the measurement update step contributes particles to concentrate around the system states. Hence, the weighted particles{xki,wki}i=1Nare propagated through the motion model (1) and updated next upon the measurement arrival, based on the measurement equation (2). An inherent problem with particle filters (PFs) is degeneracy, the case when only one particle has a significant weight and the others are close to zero. The sampling importance resampling (SIR) SMC avoids the degeneracy by adding an extra resampling step. An estimate of the measure of degeneracy at time k is given asNeff=1/∑ℓ=1N(wki)2[41]. If the numberNeffof efficient particles is below a user defined thresholdNthreshold, the resampling procedure introduces variety in the particles, and can help to avoid degeneracy by eliminating particles with small weights and replicating particles with larger weights.The algorithm of the generic PF is summarized in Table 1. The estimate of the variable of interest is obtained by a weighted sum of particles.Different proposal distributions have been used in the SMC framework – the most common transition prior or more advanced priors using the latest measurements, MCMC steps and others such as conjugate priors (e.g. inverse Wishart distribution [75,74,46]).Section 2.2 considers Markov Chain Monte Carlo (MCMC) methods.The Bayesian framework provides efficient ways of computing the desired posterior distribution. Unfortunately, in many applications, this distribution is analytically intractable. SMC methods such as particle filtering can be used to carry out the inference by sequentially approximating this posterior distribution as in [51]. MCMC methods are generally more effective than PFs in high-dimensional spaces. Their traditional formulation, however, allows sampling from probability distributions in a non-sequential fashion. Recently, advanced sequential MCMC schemes were proposed in [12,73,109,123]. These approaches are distinct from the Resample-Move scheme [50] where the MCMC algorithm is used to rejuvenate degenerate samples following importance sampling resampling. These methods [109,73,12] use neither resampling nor importance sampling.In attempting to circumvent the degeneracy problems that can possibly arise in PFs in high dimensions (e.g. with more than 20 states), the Markov Chain Monte Carlo (MCMC) framework [22,71,72,7,73] is investigated and is shown to be effective. The MCMC technique arise first in statistical physics [83,118]. The underlying principle consists in constructing a Markov chain whose long-term equilibrium is close to a desired probability distribution. The addition of the MCMC steps affords moving the “cloud of particles” into more likely regions which improves significantly the performance of the obtained sequential filters. The MCMC step also allows simulation of complicated systems that are difficult to deal with directly, including interactions between group components. Another advantage is that the MCMC step leads to flexibility and one can sample only a part of the state conditional upon the rest, thus facilitating efficient samples.There are many different ways to perform the MCMC steps. One of the most common MCMC algorithms is the Metropolis–Hastings (MH) move step, where first a likelihood ratio test is calculated (based on particles from two subsequent iterations) and the particle is selected if the likelihood exceeds a certain threshold. For small groups tracking the MH step was proposed in [109] and in [51] and shows efficient results. The method from [109] aims at sequentially approximating the following joint posterior distribution(3)p(Xk,Xk−1|Z0:k)∝p(Zk|Xk)p(Xk|Xk−1)p(Xk−1|Z0:k−1),where the state vectorXk22Note that we will denote the state vector in the reminder of the paper with a capital letter to emphasize that it contains both states and extent parameters.comprises the objects' instantaneous position, velocity and extent parameters at time k.Since the closed form expression of the distributionp(Xk−1|Z0:k−1)is generally unknown, the proposed scheme approximates it by usingNpunweighted particles(4)p(Xk−1|Z0:k−1)≈1N∑j=1Nδ(Xk−1−Xk−1(j)),whereδ(.)is the Dirac delta function and (j) is the particle index. Then, by applying this particle approximation to (3), an appropriate MCMC scheme can draw samples from the joint posterior pdfp(Xk,Xk−1|Z0:k). The converged MCMC outputs are then extracted to give an empirical approximation of the posterior distribution of interest at time k, thus seeding the next filtering step at timek+1.As shown in [109] and in [22], in high dimensional spaces the combination of Metropolis–Hastings with Gibbs sampling gives efficient results and can overcome possible degeneracy problems of PFs. The derived sequential MCMC algorithm has two steps, for drawing samples fromp(Xk,Xk−1|Z0:k):1.Make a joint draw for the pair{Xk,Xk−1}using a Metropolis–Hastings step,DivideXkinto P sub-blocks,Xk=[Xk,Ω1,…,Xk,ΩP]. Then each sub-block can be updated either via a random scan or a deterministic scan using a series of MH-within-Gibbs steps.The script for the MCMC algorithm is given in Table 2.Other methods such as the particle MCMC methods proposed in [4] have potential but still have not been studied in the light of the group and extended object tracking problems mainly because these algorithms are used to solve off-line problems.The next section presents methods for tracking small groups.Methods for small group tracking are part of surveillance and monitoring systems and are often meant to provide both state estimates and knowledge about their interactions and group behavior. We firstly describe the Bayesian formulation of the problem with a discussion on the group structure. Then, biologically inspired interaction models capturing interdependencies among objects are presented.The problem of tracking groups with a small number of components consists in estimating an augmented state vectorXkcontaining the states of all groups, at discrete time k, with their components, given a parameter vectorGkcharacterizing the structure of all groups. At time k when a measurement vectorzkis received, the measurement likelihood functionp(zk|Xk)can be calculated, and hence the state pdf for each group of objects.Under the Markovian assumption for the state transition, the Bayesian prediction and filtering steps can be written as follows:(5)p(Xk,Gk|Z0:k−1)=p(Gk|Xk,Z0:k−1)p(Xk|Z0:k−1)=∫p(Gk|Xk,Gk−1)p(Xk|Xk−1,Gk−1)p(Xk−1,Gk−1|Z0:k−1)dXk−1dGk−1,(6)p(Xk,Gk|Z0:k)=p(zk|Xk,Gk)p(Xk,Gk|Z0:k−1)p(zk|Z0:k−1),wherezkandZ0:kdenote the measurement at time k and the measurement history up to time k, respectively.The transition pdfp(Gk|Xk,Gk−1)of the group structure can be calculated in two ways. In [109] a prior transition matrix between the discrete possible group structures while in [51] the group structure model based on graphical network models is used. In this second approach the nodes of the graph correspond to the components of the group. The presence of an edge between two nodes reflects a link between these two objects. Merging, splitting, spawning and birth of groups are all modeled within the framework of evolving graphs and by taking into account geometrical distances between groups and within group components. Prediction is performed by an evolution model for the group/graph structure [51].Next, the transition pdfp(Xk|Xk−1,Gk−1)of the state of all targets is calculated knowing the previous time target states and group structure. With the assumption of independence between group motions, the pdfp(Xk|Xk−1,Gk−1)can be decomposed as(7)p(Xk|Xk−1,Gk−1)=∏g∈Gk−1p(Xkg|Xk−1g),wherep(Xkg|Xk−1g)is the transition density of the set of targets from the g-th group.The group structure can be represented in different ways. In [108],Gkrepresents a set of group's labels for each target. For example, with five targets,Gk=[11222]means that targets 1 and 2 are in group 1 and targets 3, 4 and 5 are in group 2.The group structure can be represented also as a random graph as shown in [51]. Consider N targets constituting the set of vertices{v1,…,vN}. Each vertexviis associated with the target state and with the target state's corresponding variance. The set of edges linking the set of vertices is denoted by E. The graph structure can then be denoted byG=({v1,…,vN},E). One edge, in E, between two nodesviandvjis denoted by(vi,vj). In order to characterize the presence or absence of a link (edge) between two nodes, the distance between these two considered nodes is calculated, e.g., by the Mahalanobis distance criterion. In the previous example discussed, with the graphical representation, one group structure is:Gk=({v1,v2,v3,v4,v5},{(v1,v2),(v3,v4),(v3,v5)})and the groups correspond to the connected components of the graphGk. The Mahalanobis distance is computed from the estimated positions and from the velocities of the separate objects. This estimated distance is thresholded and a decision is made about the connections. In this representation a group corresponds to a connected component of the graph structure. Note that, two nodes are in the same connected component if and only if a path between them exists. The Matlab code for the algorithm presented in this section is available on Matlab Central [98].Algorithms for group birth, death, splitting and merging are proposed in [51] by taking into account geometric distances and velocity distances between the groups and between the separate group components.The next subsection presents interaction models and results inspired by biological systems.Many of the group object tracking approaches are developed by seeking similarities with emerging behaviors in complex biological systems, such as flocking, swarming, herding and schooling. In such models [63,148,26], local interaction rules maintain coordination among individuals. This in turn gives rise to a collective behavior which may be qualitatively different from the superposition of the separate components. A common modeling conception, known as Boids, embodies the following set of local interaction rules [112]: separation, alignment and cohesion. For instance, a flock of birds tends to move in a way to avoid crowding local flockmates and keeps a certain distance between each other, which is an example of separation. The group constituents tend to steer towards the average heading of local flockmates and hence achieves alignment. Lastly, cohesion sustains a certain amount of coherence of the flock motion as individuals tend to move towards the average position of local flockmates. The flocks of birds usually have a leader. This has inspired the development of the so called leader–follower models. The leader–follower model describes a behavior in which each member of a group interacts with an aggregative, yet virtual object. In [109], this concept has been conveniently formulated in continuous time through a multivariate stochastic differential equation and then derived in discrete time without approximation errors, owing to the assumed linear and Gaussian form of the model. In particular, two different models are proposed. In the first, the basic group model and the group parameter are represented as a deterministic function of the objects. The second is a group model with a virtual leader. An additional state variable is introduced to characterize the group or bulk parameter. This second approach is closer in spirit to the bulk velocity model and virtual leader–follower model [89]. Such model provides a more flexible behavior since the virtual leader is no longer a deterministic function of the individual object states. Fig. 4gives a graphical illustration of the restoring forces towards the virtual leader for a flock of four birds.Hierarchical learning models for activities with multiple interacting objects are proposed in [95] and their potential is illustrated by experiments in sea navigation. A broad range of models for pedestrians and crowds tracking are proposed in [2].The spatio-temporal structure for the ith object in a group, as defined in [109], is given by:(8)dx˙t,i/dt={−α[xt,i−vt]−γ1x˙t,i−β[x˙t,i−v˙t]+ri}+dWt,i/dt,(9)dv˙t/dt=−γ2v˙t+dLt/dt.Herext,iis the Cartesian position in the x direction of the ith object of the group at continuous time t, withx˙t,iis the corresponding velocity;vtandv˙trepresent respectively the Cartesian position and the velocity both in the X direction of the unobserved virtual leader of the group;Wt,ixandLtxare two independent Brownian motion processes, withWt,ibeing assumed to be independently generated for each object i in the group, whereasLtis a noise component common to all members of a group. The parameters α and β are positive, and reflect the strength of the pull towards the group center. The termsγ1x˙t,iandγ2v˙tsimply prevent the velocities of the object and the virtual leader drifting up to very large values with time. Finally, to avoid colocation or spatial collision of group components, an additional repulsive forceriis introduced in (8) when objects become too close. The positive constantsγ1andγ2give different weights of the two terms in (8) and (9), respectively. The spatio-temporal model (8) and (9) can be used to define the prior transition of the objects in (6).The likelihood model for small groups is constructed in a way to deal with the measurement origin uncertainty. Since the likelihood calculation methods are similar to those for large groups and extended objects, efficient likelihood functions are presented in Section 4.1.Section 4 presents the key methodologies for large groups tracking and how the state pdf can capture group configurations. The Poisson likelihood model [48] is reviewed. The approach in which the extent of the group is considered as a random matrix is summarized next. The last part of Section 4 is devoted to the random finite set approach.Groups and extended objects give rise to multiple measurements. These can be useful for determining the shape, size, orientation and other characteristics of the groups/extended targets. However, multiple measurements require associating them, with the objects on the scene, a problem known as data association. In general, data association is an intractable combinatorial problem. The presence of environmental interferences, including unwanted returned echoes, called clutter (e.g. from ground, sea, rain) adds an extra level of difficulty. This, in turn, implies that the amount of observations per time step may be very large, and hence care must be taken for regulating these potentially massive data sets. Additionally, in a typical scenario, measurements often originate from closely spaced33In general this should be perceived as any well-defined mathematical metric rather than the mere physical meaning.objects, and in such cases standard data association techniques fail to disambiguate individual groups and group constituents.One of the most appealing solutions [48,49,120] allowing to avoid the data association problem are based on the assumptions: (i) the numbers of received target and clutter measurements in a time step are Poisson distributed (so several measurements may originate from the target), (ii) target extent is modeled by a spatial probability distribution and each target-related measurement is an independent ‘random draw’ from this spatial distribution (convolved with a sensor model).At each time step a set of sensor measurements is recorded. These measurements could come from either targets or clutter. The basic idea is to figure out how to assigns each measurements to the right target or identify it as a false alarm. The likelihood can then be calculated as derived in [48,49,120]:(10)p(Zk|Xk)∝∏i=1mk(ρ+λTp(zk(i)|Xk)),where ρ is the clutter density andλTis the mean value of the number of measurements originated from the targets,mkis the overall number of measurements received at time k andXkis the state of interest. The clutter distribution is typically assumed to be uniform, although non-uniform clutter can be incorporated (see [140]).This Poisson likelihood model (10) was further extended in [22] and below we describe this approach.Assume that at time k there arelkgroups, or extended objects at unknown locations. Each group may produce more than one observation yielding the measurement setZk={zk(i)}i=1mk, where typicallymk≫lk. At this point we assume that the observation concentrations can be adequately represented by a parametric statistical model.LettingZ0:k={Z0,…,Zk}be the measurement history up to time k, the group tracking problem can be defined as follows. We are concerned with estimating the posterior distribution of the random set of unknownθk, i.e.p(θk|Z0:k), from which point estimates forθkand posterior confidence intervals can be extracted. If we restrict ourselves to groups in which the shape can be modeled via a Gaussian pdf, then only the first two moments (the mean and covariance) need to be specified for each group. Under these assumptions, the group tracking problem is equivalent to that of estimating an evolving Gaussian mixture model with a variable number of components. Thus the unknown vectorθk={θkj}j=1nto be estimated is in the form(11)θkj={μkj,μ˙kj,Σkj,wkj,Bkj},whereμkj,μ˙kj,Σkjandwkjdenote the jth group's mean position vector (in x and y coordinates) and velocity of the group center, covariance and associated unnormalized mixture weight at time k, respectively. The additional setBkjconsists of any other motion parameters affecting the groups' behavior.The random set vectorθkcan be replaced by a fixed dimension vector coupled to a set of indicator variablesek={ekj}j=1nshowing the activity status of elements (i.e.,ekj=1,j∈[1,n]indicates the existence of the jth element where n stands for the maximum number of elements). The indicator variables reflect different group moves which generally account for birth, death, splitting and merging, i.e.,(12)(Birth)ek−1i=0⟶eki=1,(Death)ek−1i=1⟶eki=0,(Split)ek−1i=1,ek−1j=0⟶eki=1,ekj=1,(Merge)ek−1i=1,ek−1j=1⟶eki=1,ekj=0.Under the assumption that a single observationzk(i)is conditionally independent on the extent vector parameters(θk,ek), the likelihood can be represented in the form(13)p(Zk|θk,ek,mk)∝∏i=0mkp(zk(i)|θk,ek),where the pdfp(zk(i)|θk,ek)describes the statistical relation between a single observation and the cluster parameters. An explicit expression of (13) is derived in [48] assuming a spatial Poisson distribution for the expected number of observations.Following [48], the number of observations within the jth group can be assumed with Poisson distribution while the likelihoods for each of the measurementzk(i)are modeled via Gaussian pdfsN(zk(i)|μkj,Σkj), the likelihood (13) acquires the following form(14)p(Zk|θk,ek,mk)∝∏i=0mk∑j=0nekjw˜kjN(zk(i)|μkj,Σkj),wherew˜kj=wkj/(∑l=0neklwkl)is the jth normalized weight. The formulation (14) explicitly accounts for the clutter noise (known also as the bulk or null group [48]) for which the shape parameters arewk0,μk0,Σk0andek0=1.The underlying models governing the time evolution of the unknown(θk,ek)and observed variablesZk, respectively, can be represented using a dynamic Bayesian network (DBN). Thus, the state transitions are specified by the pdf(15)p(θk,ek|θk−1,ek−1)while the observations are related to the unknown states via the likelihood (14). The DBN corresponding to this process is depicted in Fig. 5where it is assumed that the DBN lacks the splitting and merging moves. The indicator transitionsek−1j→ekj→ek+1jand state transitionsθk−1j→θkj→θk+1jare shown in the top and bottom rows of Fig. 5, respectively and these are linked to the observation sequenceZk−1,Zk,Zk+1shown in the middle of this figure.In [22], the filtering pdfp(θk|Z1:k)is approximated by a variant of the sequential MCMC scheme described in Section 2.2. The respective Matlab code for [22] is available on Matlab Central portal [99].This algorithm presented in Section 2.2 and with a likelihood (14) as described above is called a Gaussian mixture MCMC algorithm. Its performance in tracking 4 groups using no more than 5000 particles is illustrated in Fig. 6. The top left panel shows the data (measured x coordinates, as a function of time). Four trajectories are merely distinguished on the background of the noise (depicted with dots). The upper middle figure shows the estimated x coordinates (of centers of the groups), obtained with the MCMC-PF. The actual trajectories are depicted via red squares whereas the corresponding estimates are shown as black crosses. The upper right panel provides contour map plots of the trajectories of the four groups, from the point of view of the sensor. The last two right rows of Fig. 6 present, respectively, the estimates of y coordinates for the centers of the four groups and the respective measurements containing a high level of clutter noise.The presented Gaussian mixture sequential MCMC technique has been also successfully applied to pollutant cloud tracking in [122]. The tracking of contaminant clouds can also be seen as an extended object tracking problem. The capability to monitor and track contaminant clouds is indeed a problem of great importance. Nowadays, the threat of pollution due to the release, either accidentally or deliberately, of Chemical, Biological, Radiological or Nuclear (CBRN) agents is high. Indeed, many rogue nations and terror groups seek to employ asymmetric warfare and some groups will be attracted by the use of chemical weapons to achieve major impact. As a consequence, rapid detection and early response to a release of a CBRN agent could dramatically reduce the extent of human exposure.In [122], the authors propose an inference algorithm within a Bayesian framework to track directly the contaminant concentration, instead of some contaminant boundary as in [69], thus providing more information about the actual situation. More precisely, the concentration of pollutant is expressed in this work using the following parametric function:(16)C(x,y,tk)=∑i=1Ntkwtk,i2π|Σtk,i|1/2e−12([xy]−μtk,i)TΣtk,i−1([xy]−μtk,i).This formulation of the concentration field of interest is motivated by two widely used dispersion models: the Gaussian Puff Model and the Gaussian Puff Particle Model. The parameters of each Gaussian shape, involved in Eq. (16) evolve independently over time as follows:(17)p(wtk,i|wtk−1,i)=ϕ(wtk,i|wtk−1,i,σw2),(18)p(μtk,i|μtk−1,i)=N(μtk,i|μtk−1,i+vτ,σμ2I2),(19)p(Σtk,i|Σtk−1,i)=W(Σtk−1,i+2Dτn,n),whereϕ(.|ν,σ2)is the truncated normal distribution with mean ν and varianceσ2defined on[0,+∞)to ensure the positivity of the weight variable. The mean vector transition probability is a random walk with a linear drift depending on the wind velocity v and the covariance matrix is assumed to be a Wishart random matrix with a scaling matrixDτ(D is the pollutant diffusion matrix) and a number of degrees of freedom n.τ=tk−tk−1corresponds to the sampling interval betweentkandtk−1. As in the previous example of large group tracking, the problem consists in estimating sequentially the evolution of a sum of dynamic multivariate Gaussian components. The only difference is in the likelihood function.For chemical, biological or radiological source term estimation, several sensors allow to measure the concentration in the atmosphere like the LCAD (Lightweight Chemical Agent Detector) and the MCAD (Mobile Chemical Agent Detector) but one of the most data rich sensors currently available is the LIght Distance And Ranging (LIDAR) sensor. The observations from sensors can be generally written as a nonlinear function of the concentration field and noises that take into account both the dispersion model uncertainty and the measurement error:(20)Zk=f(C(x,y,tk),vtk).In a Bayesian framework, the aim is thus to compute the posterior distributionp({wk,i,μk,i,Σk,i}i=1Ntk,Ntk|Z1:k)wherez1:kis the observation set from time 1 totkin order to give estimate of the parameters involved in the concentration field. The main challenging difficulty in this problem is the fact that we have to deal with unknown and time-varying number of Gaussian shapes for the concentration as well as nonlinearity and non-Gaussianity in the model. In [122], the authors propose algorithm to identify and track these multiple contaminant clouds based on a sequential Monte Carlo Markov Chain (MCMC) mechanization which approximates the filtering distribution of interest.To illustrate the results obtained by this sequential MCMC in this context, the scenario studied in this section consists of one cloud modeled by 3 Gaussian shapes then at timet=150s, an other cloud modeled by one Gaussian puff appears in the observation scene. The synthetic data are generated using the stochastic Gaussian puff model described by Eqs. (17)–(19).In the sequential MCMC algorithm used to track the contaminant clouds, all Gaussian shapes are initialized as inactive in order to allow the algorithm to identify all the Gaussian shapes necessary to model the actual contaminant clouds. The maximum number of Gaussian shapes in the algorithm is set toNmax=5. For each complete LIDAR scan, 4000 MCMC iterations are performed with burn-in of 1000 iterations. All 4000 MCMC output are kept as particle approximation to posterior distribution.Fig. 7illustrates true concentration of the cloud (on the left column), the results from the Gaussian mixture sequential MCMC technique (in the middle column) in time steps respectively 108, 307 and 557 and the measurements obtained with an LIDAR (in the rightmost column).From this figure it can be recognized that the filtering algorithm is able to adequately identify and track the contaminant clouds in a difficult scenario with heavy clutter.A common approach consists in decomposing the joint filtering pdf of groups' state and extent. Group extent has been modeled by means of symmetric positive definite (SPD) random matrices in [8,75,74,46,45,150]. Attributed to [74,75] it is called the random matrix approach as it considers an augmented state containing the kinematic states and the extent parameters, where the extent is modeled as a random matrix.In [22] the extent parameters are merely the covariance matrices in a Gaussian mixture representation of the groups' formation. In [8,75,74,46,45] the positive definiteness of the extent is preserved between consecutive time steps by sampling from the inverse Wishart distribution for which the mean is prescribed by the preceding covariance matrix.In particular, the propagated pdf of the jth group center,μkj, and extent (SPD matrix),Σkj, is expressed as(21)p(μkj,Σkj|Z0:k−1)=p(μkj|Σkj,Z0:k−1)p(Σkj|Z0:k−1)=N(μkj|μˆkj,Pk⊗Σkj)IW(Σkj|νk,Σˆkj),whereIWdenotes the inverse Wishart density with parametersνkandΣˆkj. Here,μˆkj,ΣˆkjandPk⊗Σkjare, respectively, the propagated group's mean and extent estimates, and an appropriate measure of state uncertainty. Eq. (21) can be shown to be a conjugate prior for the likelihoodp(Zk|μkj,Σkj)which thereby allows deriving a rather elegant filtering recursion for both cluster mean and extent [74,75]. Hence, (21) is known as Gaussian inverse Wishart (GIW) distribution [74,75].A combination of the random matrices approach [74,46,45] for the group extent and the PHD filter is reported in [58,59,55,60]. Considering also the Poisson clutter rate unknown, the likelihood of the filter proposed in [59,55] is gamma Gaussian inverse Wishart (GGIW) distributed. The gamma distribution is for the clutter term,44Remind that in Bayesian inference, the conjugate prior for the rate parameter of the Poisson distribution is the gamma distribution.and similarly to [74,75], the Gaussian term is for the kinematic state and the inverse Wishart for the extent. In [85] Cardinality PHD filter for extended targets is proposed which relaxes the Poisson assumptions of the extended target PHD filter in target and measurement numbers. A GGIW mixture filter is implemented and its efficiency in estimating the target extent and measurement rates together with the kinematic state of the target, is demonstrated.Apart from conjugate priors, other distributions have been recently used in few Bayesian nonparametric tracking methods. A promising trend is to avoid the often restrictive assumptions of parametric models by designing nonparametric models on infinite-dimensional spaces of functions (e.g. with Gaussian processes [105]) and/or probability distributions (e.g. Dirichlet processes [47]). In [78,79,134] irregular extended and group targets is considered by the random matrices approach.A different approach called Histogram Probabilistic Multi-Hypothesis Tracker with Random Matrices (H-PMHT-RM) is surveyed in [35,151]. A Wishart prior is applied to the inverse of the appearance covariance matrix. The initially proposed H-PMHT approach deals with Gaussian shaped targets and fixed or known extent.In the next subsection, we present the Random Finite Set Statistics approach which has been shown to be very powerful for the considered problems.In the Bayesian estimation framework the states and measurements are treated as realizations of random variables. In the random sets statistics (RSS), known also as Finite Set Statistics (FISST) [86] the targets states and the measurements are considered as random sets with unknown numbers. The number of elements in a random finite set is called the set cardinality. The FISST provides an elegant framework for statistical solutions to the group tracking problems. The FISST affords to detect, identify, track and classify groups of targets. It is a natural framework to deal with interval, stochastic and data association uncertainties. The FISST avoids the direct data association and hence the combinatorial problems due to data association which is one of its major advantages.For group tracking a hierarchical layer of objects is envisaged, with the lowest layer being the individual target. Such a random-set filtering approach for tracking groups of targets was proposed in [86]. In conventional tracking, the target state space is treated as a hidden layer, where the observation space is visible. For group tracking, the group targets are further treated as a doubly or twice-hidden layer, and each group target is a random collection of some of the targets in the first hidden layer.In FISST the PHD has the same meaning as the intensity function of a Poisson point process. It is the first moment in point process theory [89,87,146,142,113,116]. The PHD is also regarded as the first-order statistical moment, or expectation, of the multi-target posterior density. Similarly to the Kalman filter where the mean and variance of the posterior state are recursively propagated, the PHD filter propagates the PHD function by using similar steps prediction and update, however by means of a different and more complicated procedure. The integral over the PHD in a region gives the expected number of targets in that region. Hence, the estimated states of the targets can be inferred from the peaks of the PHD.The number of objects belonging to groups varies in time and the number of measurements at each time step does not necessarily match the number of targets due to missed detections and clutter. This is the rationale behind considering the states and the measurements as random finite sets. A random finite set [146] is simply a random variable which values are unordered random sets. The multi-target evolution and observation models are considered under the following assumptions: (i) Each target evolves and generates observations independently of one another; (ii) The birth random finite set and the surviving random finite sets are independent of each other; (iii) The clutter random finite set is of Poisson type and independent of target originated measurements; (iv) The prior and predicted multi-target sets are with a Poisson distribution.Instead of working with pdfs, the PHD filter updates recursively the intensities for the prediction and measurement update, respectivelyvk|k−1andvk|k:(22)vk|k−1(X)=∫pS,k(ζ)fk|k−1(X|ζ)vk−1(ζ)dζ+γk(X),wherefk|k−1(X|ζ)is the group transition density at time k,pS,k(ζ)is the group survival probability andγk(X)is the intensity of spontaneous birth. The update equation is given by(23)vk|k(X)=[1−pD,k(X)]vk|k−1(X)︸Non-detectedtargets+∑zk∈ZkpD,k(X)gk(zk|Xk)vk|k−1(X)κk(zk)+∫pD,k(ξ)gk(zk|ξ)vk|k−1(ξ)dξ︸Detectedtargets,wheregk(zk|Xk)is the group measurement likelihood,pD,kis the probability of group detection, andκk(zk)is the intensity of clutter measurements. The first part of (23) corresponds to non-detected targets and the second term of (23) to the detected targets. Practical implementations of the PHD filter include two main implementations: the SMC solutions [142] and Gaussian mixtures [144,86,57,30,29]. The SMC implementation of the PHD filter approximates the set integrals by propagating a large set of weighted particles over time. The sum of the weights of the particles represents the expected number of targets since the integral over the PHD is the expected number of targets. An improved SMC PHD approach is proposed in [115] which adapts the target birth intensity at each processing step using the received measurements.The alternative GM PHD implementation approximates the PHD with a mixture of Gaussian distributions and uses Kalman filters or their nonlinear variants such as Unscented Kalman filters [70].Various approaches are proposed to deal with the unknown number of targets within each group, such as using the birth–death model [109] and estimate the unknown number of targets within each group or the Cardinality PHD (CPHD) filter which estimates the number of targets jointly with the kinematic states. In [93] a step further is done where the cardinality number is estimated with the states, together with the clutter noise parameters and probability of detection. This is a general formulation affording to resolve state and parameter estimation problems simultaneously.The relation between the underlying group shape and entity concentrations is represented via intensity functions [89]. The intensity function indicates how entities are situated in the state space (i.e., the peaks correspond to the most dense regions in the state space). This is illustrated in Fig. 8. The top left and middle figures show the intensity functions of two and three groups, respectively, depending on x and y coordinates of the group center. The middle row figures show the groups, represented by ellipses. The last row shows the intensity function in which each peak corresponds to a group. Group splitting and merging are illustrated in the right panels. These are reflected in the changes of the number of peaks of the intensity functions.In [132,133,124,126] a different approach is proposed based on the Poisson Point Processes (PPPs). However, the algorithm in essence is similar to the PHD filter.FISST [89,143] and cluster point processes [33,131] are natural mathematical frameworks for analyzing group target motions and extended targets. In general, a cluster process is described as a superposition of point processes. The cluster centers can form parent point processes and their associated component points can form daughter point processes. This layering process can continue upwards, forming groups of groups. In principle such a formulation is general enough to deal with multiple layers of interactions. The multi-group multi-target multi-sensor density can then incorporate group dynamics and group likelihoods. While this is general, it will be a challenge to model the actual interactions between groups of groups.In [136] a first-moment approximation of group PHD filter is derived for group object tracking, which is similar to the original PHD filter for single targets. The target group is represented as a spatial cluster process, with the daughter process as an independent cluster process with a fixed distribution. In this group PHD filter, instead of using a typical Poisson observation process for the targets in a group, a more standard observation model of at most one measurement from a target is utilized. An analytical solution to a single group PHD filter is presented in [137], under linear Gaussian assumptions.The RSS approach for extended objects [89,90] and group targets modeling remains attractive due to the mathematical rigor offered by the framework. In [125] a box-PHD filter is developed and its computational efficiency shown compared with the PHD filter. However, producing suitable first-moment approximations for complex group target interactions and scenarios still continues to be a challenge [89,55,59].The parameters of the PHD filter such as probability of detection, survival probabilities and measurement noise parameters, can be estimated jointly with the object states as it is recently shown in [93,82]. The work [93] is an important step in dealing with parameter uncertainties which are commonly subject to tuning in each application.Another important class of the FISS framework is represented by the multi-target multi-Bernoulli filters [88,89,116,92,145,147]. Unlike the PHD and CPHD filters which propagate moments and cardinality distributions, the multi-Bernoulli filter propagates the parameters of a multi-Bernoulli distribution that approximate the posterior multi-target density [147]. An advantage of the multi-Bernoulli filter over the SMC PHD filter is that it does not require the additional clustering step for multi-target state estimation which the PHD filter has.We provide a performance comparison of three cluster tracking techniques. These refer to: (a) independent Sampling Importance Resampling (SIR) PFs, (b) an extended object PHD filter [136], and (c) a Gaussian mixture MCMC [22]. The first tracking approach is suggested in [73] for reducing the complexity associated with the joint filtering pdf of the multi-object state. It essentially involves employing an SIR-PF filtering algorithm individually for each target rather than a single joint tracker.The second tracking method considered here amends the PHD filter for extended objects. In virtue of its semi-analytical form, the extended target PHD filter, and in particular its Gaussian mixture implementation, requires significantly less computational resources than any MCMC-based tracking scheme.We have compared the performance of the above mentioned methods in a heavily cluttered environment similar to that in [22]. Their performance is illustrated in a typical run in Fig. 9. This figure shows the actual (black crosses) and estimated (red squares) cluster mean trajectories for the 3 different tracking methods. The MCMC approach exhibits the best tracking accuracy, essentially yielding the least number of false detections.In order to avoid the sensitivity of the PHD filter to parameters such as probability of detection, survival probabilities and measurement noise parameters, these can be estimated jointly with the object states as it is recently shown in [93]. The work [93] is an important step in dealing with parameter uncertainties which are commonly subject to tuning in each application.In the original formulation of the CPHD filter appearing objects are modeled by spontaneous birth only. Recently, in [84] conditions are derived for the CPHD filter when the process model also includes target spawning. Two types of birth models are considered: Bernoulli and Poisson distributions and it is demonstrated that this filter is computationally efficient.The next section summarizes concisely efficient SMC implementations, making them suitable for high-dimensional problems and real time.SMC algorithms become computationally excessive when applied to large-scale systems. One can identify two major directions for speeding up the algorithms: by hardware implementations [64,106,65,80], or algorithmically, with improved distributed and parallelized methods [135,104], including by carrying out the resampling step in a distributed fashion [19,102]. The [65] sequential MCMC is implemented on high performance Graphics Processing Unit (GPU) cards in an appropriate parallel fashion.Various approaches for parallelized and distributed particle filtering are proposed in the literature [96,128,31,68,128]. There are two main types of algorithms: (1) algorithms in which entire particle populations are exchanged amongst multiple processing units (PUs) and (2) others that communicate only statistical characteristics of the populations of particles (e.g. exchange the first and second order moments of the posterior state pdf). The methods exchanging statistical moments are more computationally efficient than the methods exchanging populations of particles and their weights. Most of these implementations have also the tendency to reduce the associated communication loads. Studies with a different number of particles are presented in [104] and marginalized particle filters in [130,129].In [31] two methodologies for distributed particle filtering in sensor networks are presented. The first algorithm relies on likelihood factorization and training of parametric models for approximating likelihood factors. The second algorithm adds a training step into a more standard particle filtering framework, allowing adaptive encoding of the measurements. Distributed initialization of the state probability distribution of multiple targets is considered in [20]. The decomposition of the state space into separate subspaces can lead to efficient representations of the complex state pdf as shown in [40,104] which reduces the computational complexity, with a different level of communications.We consider five potential future avenues which are based on synthesizing results from different fields:•A promising avenue is the combination of SMC methods with compressed sensing[44,34] and sparse representations [25] for online group and extended object tracking, with sensor scheduling and model determination. Models for objects with and without interactions can lead to different proposal distributions in the SMC and MCMC methods. These can be combined with the sparse data representation and bring novel techniques.Interval particle filtering and extensions to high dimensions: The recently emerged box particle filtering approach [1,52,53,97] relies on the concept of a box particle, which occupies a small and controllable rectangular region having a non-zero volume in the state space. Key advantages of the box particle filter (Box-PF) against the standard PF are in its reduced computational complexity and its suitability for solving high dimensional problems such as those emerging in tracking of groups of hundreds of targets. The Box-PF has a potential to solve group and extended object tracking problems with reduced computational complexity.Selective/attentive tracking and perception: Future tracking systems would have to cope with possibly a large number of moving objects, each of which is prone to produce more than a single measurement. The raw data from the scene would potentially be acquired simultaneously from many sensors. This amounts to massive data sets that would have to be processed efficiently. One direction for alleviating this problem relies on selective attention – a concept from neuropsychology and cognitive sciences [13]. Selective attention has long been studied in psychological research [32] and cognitive sciences [13]. This refers to the ability of a human observer to selectively track a specific visual information in puzzling scenarios. Selective attention comes into being via the identification of myriad traits, many of which are abstract and are extracted as part of cognitive and perceptual processes. Such particularities account for behavioral characteristics, motion as well as other visual and spatial features (e.g., color, shape deformations, trajectories). The application of selective attention to tracking of information (not necessarily visual) is referred to as selective or attentive tracking [32].SMC and MCMC methods have the potential of handling severe nonlinearities and complex dynamic network structures, which make them adequate for carrying out inference in selective tracking paradigms. In a recent study it has been shown how an MCMC-based scheme is capable of identifying and tracking dominant agents in highly complex scenarios involving many moving objects [23]. Causal networks can model interrelations between moving agents and then be used for identifying those agents which are prominent in shaping the collective group behavior. This information can be further used for selectively track only a small, however dominant, part of the object population. SMC samplers [37] could also provide better proposal distributions, especially between the interacting objects of groups.Intentionality prediction: Having the perceptual capabilities described above allows predicting the intentionality of either individual entities or the whole group.Joint decision making and tracking: Traditional inference schemes decouple these two tasks, namely, decision making and tracking. A performance gain is expected by integrating decision variables into tracking systems. Here one can consider integrated Bayesian decision making on the identity of the objects being tracked, including cost functions expressing the relative importance of different error types.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
