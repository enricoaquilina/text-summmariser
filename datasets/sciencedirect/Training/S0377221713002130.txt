@&#MAIN-TITLE@&#
A competitive magnet-based genetic algorithm for solving the resource-constrained project scheduling problem

@&#HIGHLIGHTS@&#
A new precedence-based crossover operator has been developed based on extensive research on related work.The operator can be applied to a variety of permutation problems.The procedure strikes a balance between diversification and intensification.The computational experiments show the effectiveness of the procedure.The operator is versatile, the procedure is robust, and the results are very promising.

@&#KEYPHRASES@&#
Genetic algorithms,Resource-constrained,Project scheduling,Precedence-based permutation,Crossover operators,

@&#ABSTRACT@&#
This paper presents a genetic algorithm for solving the resource-constrained project scheduling problem. The innovative component of the algorithm is the use of a magnet-based crossover operator that can preserve up to two contiguous parts from the receiver and one contiguous part from the donator genotype. For this purpose, a number of genes in the receiver genotype absorb one another to have the same order and contiguity they have in the donator genotype. The ability of maintaining up to three contiguous parts from two parents distinguishes this crossover operator from the powerful and famous two-point crossover operator, which can maintain only two contiguous parts, both from the same parent. Comparing the performance of the new procedure with that of other procedures indicates its effectiveness and competence.

@&#INTRODUCTION@&#
The Resource-Constrained Project Scheduling Problem (RCPSP) is an NP-hard problem which subsumes a number of complicated problems in scheduling like job shop, flow shop and assembly line balancing (Brucker, 2002). Despite being hard-to-solve, the RCPSP can be easily stated as the problem of minimizing the duration of a project in which there are n activities and K renewable resources. The examples of renewable resources are manpower, machines, and equipments.An activity j takes tjunits of time to be completed and once an activity starts, it cannot be stopped until it has been completed. A constant quantity of Rkunits of resource k is available at any time, and in each unit of time, when the activity j is in process, it requires rikunits of resource k. Each activity j also has a set of predecessors represented by Pj, and cannot start unless all the activities in Pjhave been completed. In effect, the starting of any activity is subject to two sets of precedence and resource constraints. Based on the precedence constraints no activity can start unless all of its predecessors have been completed. On the other hand, based on the resource constraints an activity can start only when its required resources are available.For solving the RCPSP, this paper presents a genetic algorithm that uses an innovative precedence-based permutation crossover operator, called Magnet-Based Crossover (MBX). This crossover operator performs structured exchange of information between two genotypes for the purpose of altering the place of the designated genes in the receiver genotype based on the same order and contiguity they have in the donator genotype. Through this process, the receiver genotype can keep its starting and ending contiguous parts, if possible.In this way, the offspring genotype can maintain up to two contiguous parts of the receiver genotype and one contiguous part of the donator genotype. For this purpose, first a series of contiguous genes in the donator genotype are designated and then not only does the order of these genes in the receiver genotype change but these genes are kept contiguous as well. Maintaining contiguity is aimed at generating offspring genotypes sharing the fitness of their both parents. The ability of maintaining up to three contiguous parts from two parents distinguishes this crossover operator from the powerful and famous two-point crossover operator, which can maintain only two contiguous parts, both from the same parent.The rest of the paper is organized as follows. Section 2 briefly reviews the previous work on the RCPSP. Section 3 has been devoted to the new procedure, GA-MBX, in general, and to its new crossover operator, MBX, in particular. The results of computational experiments have been presented in Section 4, and concluding remarks have been presented in Section 5.The RCPSP is a fundamental problem in the area of project scheduling that has many extensions ranging from multi-mode problems (Coelho and Vanhoucke, 2011), through problems with generalized precedence relations (Quintanilla et al., 2011) to stochastic problems (Deblaere et al., 2011). An excellent introduction to this problem which also introduces several expansions to widespread real-world problems like make-to-order production and batch production area as well as the utilization of minimal and maximal precedence relationships can be found in Neumann et al. (2003).Extensive surveys on the different heuristics presented for the RCPSP can be found in Kolisch and Hartmann (2006) and Kolisch and Padman (2001). These surveys show that one of the effective means of representation in prioritizing activities for execution is an activity list, in which no activity appears before any of its predecessors. In effect, any precedence-based permutation of activities can be considered as an activity list, and these two terms can be used interchangeably.Two schedule generation schemes play key roles in almost all heuristics presented for the RCPSP, namely the serial (Kelley, 1963) and parallel (Bedworth and Bailey, 1982) schedule generation schemes. Recently, a new adaptive schedule generation scheme that is a parameterized hybrid and can work between the serial and parallel schedule generation schemes has been presented in Zamani (2012). Indeed, serial and parallel schedule generation schemes are the building blocks of nearly all heuristics employed to solve the RCPSP. Unlike the serial schedule generation scheme which needs a precedence-based permutation as its input to produce a solution, the parallel schedule generation scheme can work with any arbitrary list of priorities of activities as its input. Using an arbitrary list of priorities increases the number of representations that can lead to the same schedule. In Debels et al. (2006), a modification has been performed on the representation of schedules presented in Valls et al. (2004) and Valls et al. (2003) and a framework has been obtained that guarantees each representation corresponds to a unique schedule.The other effective mechanism in providing solutions to the RCPSP is the iterative forward backward method (Li and Willis, 1992). Two major variants of this mechanism that have been called backward forward (Tormos and Lova, 2001) and double justification (Valls et al., 2005) have proved to be very efficient and have many similarities.Several effective genetic algorithms for the RCPSP can be found in Alcaraz and Maroto (2001), Chen and Weng (2009), Hartmann (1998, 2002), Mendes et al. (2009), and Valls et al. (2004). Genetic algorithms can also be embedded in hybrids. In effect, hybrids include all of the methods that use any combination of exact methods, point-based, population-based, or other innovative techniques. Several effective hybrids for the RCPSP are multi heuristic procedures (Boctor, 1990), genetic-based hybrids (Chen et al., 2010; Valls et al., 2008), and scatter searches (Debels et al., 2006; Mobini et al., 2009; Zamani, 2010).GA-MBX, as a genetic algorithm, starts with a pool of genotypes. In line with the representation used in Hartmann (2002), each genotype is composed of an activity list followed by two extra binary genes. The first binary gene indicates whether the serial or parallel schedule generation scheme should be used in the decoding of the genotype, and the second gene determines whether the decoding should be performed in the forwards or backward direction.After the genotypes has been initially decoded, based on the value of the second binary gene, the decoder further applies one iteration of the forward backward or backward forward improvement (Tormos and Lova, 2001) to the initial solution. If the second binary gene has forced the solution to be generated in the forward direction, then this improvement is made in the backward forward direction and otherwise it is made in the reverse direction.As is seen, serial (Kelley, 1963) and parallel (Bedworth and Bailey, 1982) schedule generation schemes as well as backward forward mechanism (Tormos and Lova, 2001) are the main components used in the decoder. In the following, the difference between the serial and parallel schedule generation schemes is discussed and the backward forward mechanism is briefly described.Both the serial and parallel schedule generation schemes are aimed at converting any priorities of activities to their starting times. Whereas the serial schedule generation scheme is based on incrementing an activity in an activity list and scheduling them one after another, the parallel schedule generation scheme is based on incrementing time and scheduling eligible activities with respect to their priorities.Assuming that the project has been scheduled in the forward direction, backward forward mechanism first schedules a project in the backward direction and then schedules it in the forward direction. For this purpose, it uses the starting and ending times of activities computed in each iteration as the priorities of the subsequent iteration. When the project is scheduled in the backward direction, the ending times of activities produced in the forward direction are used as priorities. On the other hand, when the project is scheduled in the forward direction, the starting times of activities produced in the backward direction are considered as priorities.The first pool of population is created through the regret-based biased random sampling mechanism (Kolisch and Hartmann, 2006). Then GA-MBX selects a number of unique random pairs of parent genotypes, from the current population, and uses MBX, as its crossover operator, to produce an offspring genotype from each parent. Considering the size of the pool as m, in each generation, GA-MBX selects totally m random pairs and generates m new genotypes. Then among the m parent genotypes and m offspring genotypes, the best m genotypes will be selected and placed in the pool of the next generation. The process of creating new generations continues until the number of schedules generated reaches a specified limit.To avoid premature convergence, instead of mutation, the generation of fresh offspring genotypes is performed. For this purpose, GA-MBX, first, in line with (Debels and Vanhoucke, 2007), adopts the sum of the absolute deviations between the priority values of two parents divided by the number of activities as a distance criterion. Then every time a pair is selected for crossover, their distance is measured and if it is smaller than the threshold-distance (δ), the genotype with the lower quality is replaced with a newly generated genotype. For generating these new genotypes, the same routine used in producing the initial pool will be applied.Having described nearly all the components of GA-MBX, we can now discuss its innovative part, which is the use of a new crossover operator. This crossover operator, MBX, to the best of our knowledge, has not been used elsewhere. Hence, first, the related crossover operators are discussed and, then MBX, in the context of these operators, is presented.In the framework of genetic algorithms, permutation crossover operators are used to tackle problems whose solutions are represented by a permutation of the numbers 1, 2, 3, … , n. An imperative category of permutation crossover operators preserves precedence relations existing in both parents. Here, preserving precedence relations means that if in both parents, the gene x has appeared before the gene y, then in any offspring generated, x should appear before y. Since the RCPSP is involved with precedence relations of activities, in solving the RCPSP, except precedence-based permutation crossover operators, no other permutation crossover operator is applicable.Precedence-based permutation crossover operators are mainly classified into uniform (Bierwirth et al., 1996), 1X (Davis, 1985) and kX (Djerid et al., 1996) categories. The uniform crossover operator acts based on a vector comprising of elements of 1’s and 2’s, with each element being determined randomly. Then, in creating a genotype, depending on 1 and 2, it takes each subsequent element from the first or second parent, respectively. Any element selected from one parent is deleted from the other parent so that no repeat can occur. Moreover, the order of selection from each parent is from left to right so that the precedence relations are preserved.For instance, consider a vector that starts with 2, 1, 1, and 2. In this case, the first element of the offspring will be selected as the first element of the second parent. Then this element is deleted from both parents. The second and third elements are selected as the first two undeleted elements of the first parent. After deleting these two elements from both parents, the fourth element is selected as the first undeleted element of the second parent. Since for a genotype of size n there are 2ndifferent vectors of 1 and 2’s, this crossover operator can be extremely disruptive. In other words, by not exploiting much useful information in the parents, it extremely favors diversification against intensification.As a one-point crossover operator, 1X preserves the genes at the starting part of the donator genotype and reorders the remaining genes of the donator based on their order in the receiver genotype. The other operator, kX, as a generalization of 1X, is a k-point crossover operator. It works by preserving the genes in k contiguous parts of the donator genotype and reordering the genes in middle contiguous part(s) of the donator based on their order in the receiver genotype.For the RCPSP, one- and two-point crossover operators, 1X and 2X, are the major operators used in the literature. Perhaps this is due to the very limited disruptiveness associated with kX when the value of k increases, and exponentially growing disruptiveness of uniform crossover operator.MBX has been designed to improve 1X and 2X in the direction that the offspring genotype can inherit the contiguous genes from both parents, and not just form one parent as 1X and 2X do. For this purpose, it starts with breaking the donator genotype into three different parts and designates the contiguous genes located in the middle part. Then it changes the order of the designated contiguous genes in the receiver parent. In effect, the designated genes in the donator genotype interact like magnetic particles and absorb one another in the receiver genotype. In this process, up to two contiguous parts of the receiver genotype may also be maintained; these parts include its starting and ending. The process is performed in five stages.First, a contiguous block of genes is specified in the first parent (donator). This is done by generating two random numbers as the boundaries of the locations to be considered. The activities located in these locations are specified as the contiguous block of genes needed for the next stage.Second, a location with minimum index in the second parent (receiver) is identified that includes one of the genes of the block, and the contents of all locations before this index is copied to the offspring genotype correspondingly. Up to this point, the precedence relations have been preserved because each activity has the same position it has had in the receiver genotype.Third, a location with maximum index in the receiver genotype is identified that contains one of the genes of the block. Then all the genes located between the minimum and maximum indexes are scanned one after another. For now, we assume that any scanned non-block activity is either the predecessor or the successor of a block-activity. This assumption has been made for proof simplification and will be relaxed later. Upon the scanning, each non-block activity, depending on whether it is a predecessor or successor of a block-activity, joins to one the two sequences called predecessors or successors, respectively. The key point to consider is that there cannot be any activity that is the predecessor of a block activity and the successor of the other block activity, otherwise such an activity in the receiver genotype should have been located inside the block and not outside it.In the fourth stage, the contents of all locations after the maximum index, in the receiver genotype, are copied into the offspring genotype, correspondingly. Since these new activities in the offspring genotype have the same position they have had in the receiver genotype, the precedence constraints cannot be violated.In the fifth stage, the unfilled positions of the offspring genotype are filled. MBX, in this stage, simply locates the predecessors sequence followed by the contiguous block followed by the successors sequence in the unfilled locations. In other words, it places the contiguous block between its predecessors and successors found in the third stage.In the fifth stage, based on the simplified assumption made in the third stage, the offspring genotype has still preserved the precedence relations. The reason is straightforward and can be stated in three parts. First, in the offspring genotype, the activities of the contiguous block have the same order they have had in the donator genotype and the donator genotype does not violate the precedence constraints. Second, the activities of the contiguous block have been located between their predecessors and successors. Third, neither the activities in the successors sequence, nor those in the predecessor sequence can violate the precedence constraints because they have same order they have had in the receiver genotype.However, the simplified assumption made in stage three is unrealistic in the sense that there can be activities that are neither the successor nor the predecessor of the contiguous block. Hence, we have to prove that the existence of these activities cannot violate the precedence constraints. For this purpose, we call these activities as free activities and treat them so that they can never violate the precedence constraints. This is done as follows.In the third stage, two sequences have been introduced, predecessors and successors, and each free activity has to be placed either in the predecessors or successors sequence. However, free activities can have a precedence relation with one another and this precedence relation in their rearrangement should be preserved. This implies that the placing of the free activities alternatively in one of the two predecessors or successors sequences is the main source of violating precedence constraints.This alternate replacement can be avoided if the list of free activities, based on their order in the receiver genotype, is randomly cut into two sections, with the first section joining to the predecessors and the second section joining to the successors. In this case, the free activities in the offspring genotype will have the same order they have had in the receiver genotype. With respect to this cutting, between zero and q first activities join to the predecessors sequence and the rest join to the successors sequence, representing q+1 ways to cut the list. This has been implemented through the following mechanism.In the third stage of MBX, first, it is decided that whenever a free activity is encountered, it joins to the predecessors sequence. Then as far as this decision has not been overturned, whenever a free activity is encountered, before permitting it to join the predecessors sequence, with the chance of p this decision is overturned. Consequently, from the point of overturning the initial decision, every free activity joins to the successors sequence. In this way, the only source of violating precedence constraints is removed and the proof is completed. It is worth mentioning that for q⩾4, by selecting p as 2/(q+2), a half of the free activities are expected to join to each of the sequences. That is why GA-MBX sets p adaptively to 2/(q+2), when q>1,and to 0.5 when q is 1.Fig. 1shows an activity network, two parent genotypes, and an offspring genotype generated by MBX. As is seen, the specified block is “3 4 6 7”, which have been scattered between locations 2, minimum index, and location 8, maximum index. Activities 3 and 4 are located in the minimum and maximum indexes, respectively. As well as block activities, activities 2, 5, and 8 have also been located between the minimum and maximum indexes. Among these three activities, activity 2 is the predecessor of a block activity, activity 4, and activity 8 is the successor of a block activity, activity 6. On the contrary, activity 5 is free, indicating that it can join to either the predecessors or successors sequence. It should be noticed that in the receiver genotype, activity 5 is scanned before activity 8 and after activity 2. Since activities are placed in the predecessors and successors sequences based on the order they have been scanned in the receiver genotype, activities 2, 5, and 8 maintain the same precedence relation they have had in the receiver genotype. As is seen, in the offspring generated, activity 5 has joined to the predecessors sequence, but with the chance of 0.5, it could join to the predecessors sequence, between activities 7 and 8.The uniform crossover operator, 1X, and 2X are three crossover operators to tackle the RCPSP. In particular, the disruptiveness of each of these three operators depends on the activity network of the project to which it is applied. However, it is a well known fact that among general (and not precedence-based permutation), 1-point, 2-point, and uniform crossover operators, the most disruptive operator is the third one and the less disruptive is the first. In effect, on two binary strings with Hamming distance H, uniform, 2-point, and 1-point crossover operators can produce 2H−1, H2−H, and 2(H−1) different offspring, respectively (Whitley, 1994). In the calculation of these three values, the original parent strings have not been counted.The reason is that by applying 1X, between 1 and H−1 bits of each parent can be replaced with those of the other parent, and this will lead to only H−1 offspring genotypes per each of two parents. On the other hand, by applying 2X, two different points should be selected in H(H−1)/2 ways, per each of two parents, and each of these selections can lead to a new offspring genotype. For the uniform crossover operator, the situation is entirely different because each different subset of H bits can be selected for replacement, leading to the exponential number of 2H−1 possible offspring genotypes.The potential number of offspring genotypes generated by MBX, in the context of binary strings, is at most H times greater than H(H−1)/2, per each of two parents. In effect, in the case of being no free gene, the number of possible genotypes is exactly equal to that of 2-point crossover operator. Now suppose that only one free gene exits. Depending on whether this free gene joins to the predecessors or successors, there are potentially H(H−1) offspring genotypes that can be generated. Now if the number of free genes increases to q, since their list can be cut in q+1 different ways, there will be (q+1) H(H−1)/2 potential offspring genotypes, q<H, per each of two parents.Whereas kX, in general, and 1X as well as 2X, in particular, preserve the contiguity of genes in only one parent, MBX may do it for both parents. This is because in MBX, the donator genotype forces the contiguity of its block activities and the receiver genotype forces the contiguity of the genes located before the minimum index as well as those after the maximum index, if any. This possibility leads to the effective exploitation of promising characteristics of both parents.To compare the functionality of MBX with those of 1X and 2X, an activity network with the precedence relations represented in Table 1has been used, and Table 2shows the results. As is seen in Table 2, each activity, as a gene has a location, and the locations have been numbered from 1 to 10. The break points for 2X and MBX are locations 4 and 6, and the break point for 1X is location 4. Bold values in Table 2 show the genes which absorb one another in the MBX.As is expected, in 1X, the activities before the crossing point, location 4, have been correspondingly selected from the donator genotype, and other activities in the donator genotype have been reordered based on their order in the receiver genotype. On the other hand, in 2X, the locations before the first crossing point, location 4, and those after the second crossing point, location 6, have been filled based on their corresponding values in the donator genotype. Then, other activities of the donator genotype, activities 6, 4, and 8, have been reordered based on their order in the receiver genotype and have been placed in locations 4, 5, and 6 of the offspring genotype.As is seen, compared to 1X, MBX operates quite differently. The concept of free genes is, however, what distinguishes 2X from MBX. In effect, in this example, activities 2 and 5 are free genes and, therefore, depending on the random number generated by MBX in partitioning (2 and 5), three cases can occur: (i) none of the free genes with the predecessors, (ii) only the first free gene with the predecessor, and (iii) both free genes with the predecessors. In Table 2, these three cases have been shown in the rows marked by MBX1, MBX2, and MBX3.For the uniform crossover operator, depending on any vector of 1’s and 2’s, a new genotype may be generated. That is why the uniform crossover has not been represented in Table 2. For instance, for the vector of (1, 2, 1, 2, 1, 2, 1, 2, 1, 2), which forces the activities to be selected alternatively from the donator and receiver, the offspring genotype (0, 1, 3, 4, 6, 2, 8, 7, 5, 9) is generated.GA-MBX has been coded in C++ and has been run under windows operating system on a DELL PC with 1.86GHz speed. The benchmark instances have been selected from Kolisch and Sprecher (1996), which include four different sets, namely J30, J60, J90, and J120, with projects of 30, 60, 90, and 120 activities, respectively. Each of the first three sets includes 480 and the fourth set includes 600 instances, with every 10 instances comprising a group. Hence, whereas the set J120 has 60 groups, each of the other three sets has only 48 groups of instances.In comparing the results with those of other procedures, since the optimal solutions of many instances in the sets J60, J90, and J120 are not available in the literature, the criterion of percentage deviation from the optimal solution, %Dev-OPTIMAL, cannot be employed and, instead, the criterion of percentage deviation from the CPM (Critical Path Method) lower bound, %Dev-CPM, has been adopted. A CPM lower bound is obtained by ignoring resource constraints and solving the simplified problem.To solve each benchmark instance, the limits of 1000, 5000, and 50,000 schedules have been set for the procedure. Setting a limit on the number of schedules makes it possible to compare the performance of GA-MBX with other procedures regardless of the speeds of computers on which they have been run.For preliminary tests related to finding an appropriate value for population and threshold-distance (δ), we used the groups of 45, 41, and 51 from the sets J60, J90, and J120, respectively, with each group including 10 benchmark instances. It is worth mentioning that based on the total gap existing between the latest lower and upper bounds of their 10 instances, in the PSPLIB, updated in year 2010, each of these three groups can be considered as the hardest group in its own benchmark set. After specifying these instances, several ad hoc tests were performed on these instances.For instance, based on limiting the number of schedules to 1000, Fig. 2shows the facades measuring %Dev-CPM for group 51 of the set J120 for different pool sizes (6, 8, 10, 12, 14) and different threshold-distances (δ) (1.5, 1.75, 2, 2.25, 2.5). This clearly shows that for the set J120, the population of 10, with the threshold-distance of 2 produces the best performance. Based on our preliminary experiments, regardless of the benchmark set and the limit of schedules, we set the threshold-distance to 2.For each of these three limits, however, different populations have been selected as follows. With respect to the limit of 50,000 schedules, the population size has been set to 80 for the set J120, and 160 for the other three benchmark sets. For both of the limits of 1000 and 5000 schedules, the population size for the set J120 has been set to 14. For these two limits, the population size for the other three sets has varied between 10 and 14. Based on this setting, the performance of the procedure is as follows.With the limit of 50,000 schedules, the procedure has been able to find the optimal solutions of all 480 instances of the set J30. Tables 3–5compare the performance of GA-MBX with that of six high performance procedures in the literature, for the limits of 1000, 5000, and 50,000 schedules, respectively. Bold values in these tables show the minimum value in each column. Since these procedures have not provided the result for the set J90, this set has not been represented in these tables. Based on the latest update made in the PSPLIB in 2010, Table 6presents the performance of GA-MBX with respect to the amount of %Dev-Best-Solutions for each of these four sets, with showing the average of execution times.Moreover, the performance of the procedure has also been tested on each benchmark instance based on three population sizes of 40, 80, and 160, and the best solution for each instance has been recorded. Based on these experiments, %Dev-CPM for the sets J60, J90, and J120 have been decreased to 10.54, 9.84, and 30.75, respectively. Note that the using of these three different populations, each with the limit of 50,000 schedules, is equivalent of increasing the limit of schedules to 150,000. As is expected, in this case, the average execution time for each instance, in the sets J30, J60, J90, and J120 increases to around 3, 6, 9, and 15 seconds, respectively. Interestingly, for the set J30, the population sizes of 80 and 160 both were able to produce the entire 480 optimal solutions.With respect to these higher average times, we can particularly compare the improved results with those provided with LSSPER (local search with subproblem exact resolution) (Palpant et al., 2004), which is a state-of-the-art procedure that for the first time has provided 14, 9, and 4 of the best solutions available in the literature for the sets J60, J90, and J120, respectively. %Dev CPM provided by LSSPER for the sets J60, J90, and J120 are 10.81, 10.34, and 32.45, respectively. These results have been obtained on average within 37, 58, and 111 seconds, respectively, on a PC with 2.3GHz speed.To compare the performance of MBX with that of 1X and 2X, we replaced MBX with these operators, and, by using the same generic framework, built GA-1X and GA-2X, respectively. As is expected, none of the three procedures can produce the best results for all instances, and each has different performance on different instances. However, compared to the other two procedures, GA-MBX for more instances can improve the results produced by both other procedures. In effect, out of all 2040 instances, for 131, 107, and 36 instances, GA-MBX, GA-2X, and GA-1X have been able to improve the results produced by both other procedures, respectively. Moreover, whereas for the set J30, GA-1X, and GA-2X have missed 3, and 2 optimal solutions, respectively, GA-MBX has been able to find the optimal solutions of all instances. Interestingly, for the set J30, both GA-1X and GA-2X have failed to find the optimal solution of the same instance (284).Table 7compares the performance of the three procedures with one another, indicating that for all the four sets, GA-MBX has outperformed GA-1X. For one set, J120, GA-2X has outperformed GA-MBX, and for one set, J90, GA-MBX and GA-2X have had equal performance. For the other two sets, GA-MBX has outperformed GA-2X. Table 8shows how many solutions produced by each procedure, for each set, are equal to, better, or worse than those produced by either of the other two procedures. As is seen for 167, and 287, out of the entire 2040 instances, GA-MBX has produced better results than those produced by GA-2X and GA-1X, respectively.The more effectively the promising characters of both parents are exploited, the more successfully a crossover operator can perform. However, genetic algorithms have multiple features and crossover operators comprise only one of these features, albeit the most important one. In general, it is the interplay among these features which determines the overall performance of a procedure. Hence, the suitability of any feature, like crossover type, mutation intensity, selection criteria, and population size, depends on the selection of other features. This indicates that GA-MBX has selected a proper combination of these features to properly interplay with one another. There are three directions in which GA-MBX can be extended.First, population-based searches, in general, and genetic algorithms in particular are intrinsically parallel. By devising a set of efficient message passing rules, an asynchronous environment can be developed in which various phases of the procedure can be performed simultaneously. In the parallelization direction, it is also possible that different threads of the GA-MBX can be run on different processors of the same machine with different initial pools.Second, depending on the activity network of a problem instance, different crossover operators can reveal different efficacy. By encoding the type of crossover operators into genotypes, the procedure can learn how to employ an appropriate operator. Changing the type of the employed crossover operator adaptively is expected to enhance the balance between exploration and exploitation.Third, as stated in Glover (1994), the development of scatter search, which has been originated from mathematical relaxation, is a piece of evidence that mathematical relaxation, including Lagrangean relaxation, can have considerable overlaps with GAs. In this regard, principles underlying heuristics employed in mathematical relaxation, similar to what has been proposed in Zamani and Lau (2010) can provide valid contribution to enhancing the performance of the procedure.

@&#CONCLUSIONS@&#
