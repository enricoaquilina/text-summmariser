@&#MAIN-TITLE@&#
List scheduling and beam search methods for the flexible job shop scheduling problem with sequencing flexibility

@&#HIGHLIGHTS@&#
Heuristic methods for the flexible job shop with sequencing flexibility are introduced.The problem has important practical applications in, e.g. the printing industry.Introduced methods are fully described and their implementations publicly available.Complete description of the results makes possible its usage for benchmarking.

@&#KEYPHRASES@&#
Scheduling,Flexible job shop,Makespan,List scheduling,Beam search,

@&#ABSTRACT@&#
An extended version of the flexible job shop problem is tackled in this work. The considered extension to the classical flexible job shop problem allows the precedences between the operations to be given by an arbitrary directed acyclic graph instead of a linear order. Therefore, the problem consists of allocating the operations to the machines and sequencing them in compliance with the given precedences. The goal in the present work is the minimization of the makespan. A list scheduling algorithm is introduced and its natural extension to a beam search method is proposed. Numerical experiments assess the efficiency of the proposed approaches.

@&#INTRODUCTION@&#
The classical job shop (JS) problem consists of scheduling n jobs on an environment with m machines. Each job is composed by several operations with a linear precedence structure and has a predetermined route through the machines. The flexible job shop scheduling (FJS) problem is a generalization of the JS problem in which there may be several machines, not necessarily identical, capable of processing each operation. The processing time of each operation on each machine is known and no preemption is allowed. The objective is to decide on which machine each operation will be processed, and in what order the operations will be processed on each machine so that a certain criterion is optimized.This paper considers the extended version of the FJS problem that allows the precedences between the operations to be given by an arbitrary directed acyclic graph instead of a linear order. Therefore, the problem consists of allocating the operations to the machines and sequencing them in compliance with all given precedences. An example of a job with this general type of precedences is presented in Fig. 1. This problem appears in practical and industrial environments, such as the printing industry (Zeng, Jackson, Lin, Gustafson, Hoarau, & Mitchell, 2010), where assembling and disassembling operations are part of the production process. Printing processes can be divided into three major tasks: prepress steps, printing, and postpress steps (Printers National Environmental Assistance Center, 2015). Prepress steps include composition and typesetting, graphic arts photography, image assembly, color separation, and image carrier preparation. Printing can be performed by six separate and distinct processes: lithography, letterpress, flexography, gravure, screen printing, and plate-less technologies. Postpress operations consist of four major processes: cutting, folding, assembling, and binding. There are many additional lesser postpress finishing processes such as varnishing, perforating, drilling, etc. In-line finishing may also be considered as a final step of the postpress operations. These three major steps of the printing process have an obvious precedence constraint. However, within each major step, there are operations with no precedence constraint among them. Pages of a book are divided into signatures (bunch of 8, 16, or 32 individual pages) that can be printed, cut, and folded in separate. The book cover is also an element that can be prepared in separate. Then, all printed and non-printed elements need to be gathered in order to continue the process. See Fig. 2. It is easy to see that this arbitrary-precedences issue of the printing process may be found in most of the practical industrial applications, making the considered problem a problem with a potential wide range of applications. The scheduling performance measure considered in the present work is the makespan minimization.The flexibilityof representing the precedences between the operations of a job with an arbitrary directed acyclic graph instead of a linear order is known as sequencing flexibility, while routing flexibility refers to the possibility of an operation to be performed by a subset of machines instead of a single machine (this is the flexibility that transform a JSP into an FJSP). Other types of flexibility exist, like producing the same manufacturing feature with alternative operations or sequences of operations, known as processing flexibility. The effects of sequencing flexibility on the performance of dispatching rules used to schedule operations in manufacturing systems was analyzed in Lin and Solberg (1991); Rachamadugu, Nandkeolyar, and Schriber (1993) (see also the references therein). In Sabuncuoglu and Karabuk (1998), a flexible manufacturing system with finite buffer capacities and that considers automated guided vehicles is tackled. Different performance criteria are considered (mean flow time, mean tardiness, and makespan) and an ad hoc filtered beam search method is developed. The results of the method are analyzed in order to investigate the effects in the performance of the manufacturing system of incorporating different types of flexibilities. A more recent study can be found in Joseph and Sridharan (2011).The extended FJS problem considered in the present work is NP-hard, since it has the JS problem (that is known to be NP-hard Garey, Johnson, & Sethi, 1976) as a particular case. Due to its complexity, the number of publications concerned with the exact solution of the FJS problem is very small. Fattahi, Mehrabad, and Jolai (Fattahi, Mehrabad, & Jolai, 2007) proposed a mixed integer linear programming (MILP) model for the FJS problem and used it to solve small and medium-sized instances with a commercial software. A more concise MILP model, that modifies an earlier one presented in Manne (1960) in order to incorporate routing flexibility, was introduced in Özgüven, Özbakır, and Yavuz (2010). More recently, a new MILP model for the extended version of FJS considered in the present work was presented in Birgin, Feofiloff, Fernandes, de Melo, Oshiro, and Ronconi (2014). This model was analyzed using instances from the literature and instances inspired by the printing industry. According to the numerical experiments, the software CPLEX produced better results with the new model than with the one presented in Özgüven et al. (2010).Several works from the literature proposed heuristic methods to address the makespan minimization in the classical FJS problem. Brandimarte (Brandimarte, 1993), one of the pioneers of this approach, applied dispatching rules to assign each operation of each job to a machine and, in a second phase, employed a tabu search heuristic to define the sequence of the operations on each machine. This kind of strategy is known as hierarchical approach. Tabu search (TS) based heuristics to solve this problem, but in an integrated way (i.e. considering simultaneously the assignment and schedule of the operations), were also developed in Dauzère-Pérès and Paulli (1997); Mastrolilli and Gambardella (2000). A recent literature also includes genetic algorithms (GA) to deal with the FJS problem in an integrated approach. The learnable genetic architecture (LEGA), proposed in Ho, Tai, and Lai (2006), provides an integration between evolution and learning methodologies within a random search framework. In this context, the learning module is used to influence the diversity and quality of offsprings. On the other hand, a traditional GA with improved components selected from the literature and a new mutation assignment operator named intelligent mutation was introduced in Pezzella, Morganti, and Ciaschetti (2008). According to the presented computational tests the proposed GA outperformed other known GAs from the literature and obtained solutions comparable with the ones obtained by the TS described in Mastrolilli and Gambardella (2000). A hybrid GA that follows the hierarchical approach can be found in Gutiérrez and García-Magariño (2011). First the algorithm uses GA to find the assignments and crude schedules (feasibility is not guarantee), and next it applies repairing heuristics. In Gutiérrez and García-Magariño (2011), a quantitative comparison with recent works of the literature, including (Mastrolilli & Gambardella, 2000) and considering benchmark problems from Brandimarte (1993), was presented to illustrate the performance of the proposed method. Aiming to join the best characteristics of different approaches Yuan and Xu (Yuan & Xu, 2013) proposed an integrated search heuristic composed by a hybrid harmony search (HHS) and a large neighborhood search (LNS). In first place, the HHS algorithm runs until a solution from which no significant improvement can be done is reached. Then, the operation-machine assignment information from the elite solutions is extracted. Finally, the LNS method is executed on the reduced space to further improve the best solution obtained by the HHS. The authors presented experiments with four different benchmarks from the literature and concluded that the HHS/LNS integrated search shows a competitive performance with respect to the state-of-the-art methods. Additionally, several works have considered the FSJ with multiple objectives that include the makespan criterion. See, for example, (Kacem, Hammadi, & Borne, 2002; Li, Pan, & Liang, 2010; Shao, Liu, Liu, & Zhang, 2013; Tay & Ho, 2008; Zhang, Shao, Li, & Gao, 2009), and the references therein.A few works, most of them inspired in practical applications, deal with the extension of the FJS in which precedences are given by an arbitrary directed acyclic graph. An environment coming from a glass factory, that requires an even more general variant of the FJS problem including, for example, no-wait constraints, is described in Alvarez-Valdés, Fuertes, Tamarit, Giménez, and Ramos (2005). The authors proposed heuristic methods based on priority rules and a local search to minimize a criterion based on earliness and tardiness penalties. A class of instances that includes arbitrary precedence relations among operations (with the constraint of having an ending assembling operation in each job) of a problem from the printing and boarding industry is also tackled in Vilcot and Billaut (2008). Considering the makespan and the maximum lateness criteria, TS and GA are applied with the aim of building an approximation of the Pareto frontier. A symbiotic evolutionary algorithm that considers routing, sequencing, and processing flexibility in a job shop scheduling problem was introduced in Kim, Park, and Ko (2003). Another extended version of the FJSP, inspired in real manufacturing environments, in which precedence constraints are arbitrary and can be of AND/OR type, is studied in Lee, Moon, Bae, and Kim (2012). A real scheduling problem in a mould manufacturing shop problem with several kind of flexibilities is described in Gan and Lee (2002). The considered problem possesses process planning flexibility that includes sequencing flexibility. In the proposed method, process planing and scheduling are tackled in an integrated way.Due to the limited amount of works that approach the extended version of the FJS problem and its practical applicability, the purpose of this paper is to contribute to the development of heuristic techniques able to produce reasonable results in acceptable time. First, a list scheduling algorithm is proposed, motivated by its simplicity and applicability to job scheduling in production environments (see, for example, Kim, 1995; Lee, Kim, & Choi, 2004; Mainieri & Ronconi, 2013). The natural extension of the list scheduling algorithm to a filtered beam search method is also investigated. The filtered beam search is a technique for searching decision trees that involves systematically developing a small number of solutions in parallel so as to attempt to maximize the probability of finding a good solution with minimal search effort (Ow & Morton, 1988). The evaluation process that determines which partial solutions are the promising ones is a crucial component of this method (Pinedo, 2008). The main idea of the presented filtered beam search method is to apply a customized version of the list scheduling algorithm to locally and globally evaluate partial solutions in an effective way. After the pioneer work of Ow and Morton (Ow & Morton, 1988), other authors addressed scheduling environments with this approach. Sabuncuoglu and Bayiz (Sabuncuoglu & Bayiz, 1999) tackled the JS problem minimizing the makespan and conducted several numerical experiments to analyze the influence of some of the filtered beam search parameters on its performance. Moreover, a comparison considering metaheuristic algorithms and dispatching rules was also conducted to expose the competitive performance of the proposed method. More recently, a filtered beam search approach for the flexible job shop minimizing the weighted sum of three objectives (the makespan, the total workload of machines, and the workload of the most loaded machine) was introduced in Shi-Jin, Bing-Hai, and Li-Feng (2008).Considering the component-based view of metaheuristics suggested in Sörensen (2015), it can be said the beam search method is a matheuristic that combines the search-tree strategy of branch-and-bound methods with a constructive heuristic used for potentially pruning apparently fruitless nodes of the search tree. Some of the highlights of the introduced methods are that they both have finite termination and that they depend on a very reduced set of parameters whose meaning is very simple to interpret. In fact, the list scheduling algorithm has no parameters while the beam search method has only three parameters. Other than the promising numerical results, additional main features of the heuristic methods presented in this work are (a) their precise description (all possible ties are decided with explicitly given rules) and (b) availability of their C/C++ implementation. Moreover, together with a complete description of the obtained solutions, these facts allow full reproducibility of the presented results and open the possibility of using them as a benchmark for future developments. The remaining of this work is organized as follows. Section 2 gives the description of the tackled problem by presenting its mixed-integer linear programming formulation. Section 3 presents a list scheduling algorithm while Section 4 introduces the proposed beam search method. Section 5 is devoted to numerical experiments. Section 6 presents some final remarks and lines for future research.A precise description of the considered problem can be given by the MILP formulation introduced in Birgin et al. (2014) that we reproduce in this section for completeness and to introduce the notation that will be used in the present work.Let n, o, and m be the number of jobs, operations, and machines, respectively. The number of jobs will not play any explicit role in the problem formulation. For each operation i (i=1,…,o), letFi⊆{1,2,…,m}(Fi≠ ∅) be the subset of machines that can process operation i and let pik(i=1,…,o,k ∈ Fi) be the corresponding processing times. Moreover, let A be a set of pairs (i, j) withi,j∈{1,…,o}such that, if (i, j) belongs to A, this means that operation i precedes operation j, i.e. operation j cannot start to be processed until operation i ends to be processed. This set of precedences A is the place where jobs are implicitly defined, since it is expected to exist precedences between operations of the same job but not to exist precedences between operations of different jobs. Moreover, it is assumed that if the elements of A represent the arcs of a directed graph with vertices labeled from 1 to o then this graph is a directed acyclic graph, i.e. there are no cyclic precedences and, in consequence, the problem is well defined. The problem consists in assigning each operation i to a machine k ∈ Fiand to determine a starting processing time sisuch that precedences are satisfied. Of course, a machine cannot process more than an operation at a time and preemption is not allowed. The objective is to minimize the makespan, i.e. the completion time of the last operation (or, equivalently, last job).The model uses binary variables xik(i=1,…,o,k ∈ Fi) to indicate whether operation i is allocated to be processed by machine k (in this casexik=1) or not (in this casexik=0). It also considers binary variables yij(i,j=1,…,o,Fi∩ Fj≠ ∅) to indicate, whenever two operations are allocated to the same machine, which one is processed first. Assume, for example, that there are two operations i and j such that k ∈ Fi∩ Fjand that both operations are allocated to machine k, i.e.xik=xjk=1. In this case, we must have exactly one between yijand yjiequal to 1. Ifyij=1andyji=0then operation i is processed on machine k before operation j. On the other hand, ifyij=0andyji=1then operation i is processed on machine k after operation j. Finally, the model uses variablessi(i=1,…,o),to represent the starting time of operation i (on the machine to which it was allocated) and a variable Cmax  to represent the makespan. With these variables, the MILP model of the extended flexible job shop problem introduced in Birgin et al. (2014) can be written as(1)MinimizeCmax(2)subjectto∑k∈Fixik=1,i=1,…,o,(3)pi′=∑k∈Fixikpik,i=1,…,o,(4)Cmax≥si+pi′,i=1,…,o,(5)si+pi′≤sj,i,j=1,…,osuchthat(i,j)∈A,(6)yij+yji≥xik+xjk−1,i,j=1,…,o,i≠j,andk∈Fi∩Fj,(7)si+pi′−(1−yij)L≤sj,i,j=1,…,oandi≠jsi+pi′−(1−yij)L≤sj,suchthatFi∩Fj≠∅,(8)si≥0,i=1,…,o.Constraint (2) says that each operation i must be assigned to exactly one machine k ∈ Fi. Constraint (3) defines the actual processing timepi′of each operation i (that depends on the machine to which it was assigned). In fact, there is no need to considerpi′in (3) as a variable of the model. It can be seen as an auxiliary value that simplifies the model presentation, while it can be avoided by removing constraint (3) and replacing each appearance ofpi′in the other constraints with the expression on the right hand side of (3). Constraint (4), together with the minimization of the objective function in (1) defines Cmax  as the makespan. Constraint (5) represents the precedence constraints. For every pair of operations assigned to the same machine, constraints (6,7) say that both operations cannot be processed at the same time and determine which one is processed first. If two operations i and j that could have been both assigned to a machine k (i.e. k ∈ Fi∩ Fj≠ ∅) are not then we have that at most one between xikand xjkis equal to 1. In this case, constraints (6,7) are trivially satisfied withyij=yji=0. In (7), L represents a sufficiently large positive constant (see (Birgin et al., 2014) for a suggested value that may be used in practice). Finally, constraint (8) says that the starting times of the operations must be not smaller than the beginning of the considered planning horizon that, without loss of generality, was set to 0.Model (1–8) was introduced in Birgin et al. (2014), where a comparison with a simple extension of the model presented in Özgüven et al. (2010) was given. Up to the authors acknowledge these two models are the only published ones that include the possibility of the precedences between the operations to be given by an arbitrary directed acyclic graph.In this section we describe a non-hierarchical list scheduling algorithm. It is non-hierarchical in the sense that, at each iteration, it selects an operation, assigns it to a machine, and determines a starting time. This is in contrast with hierarchical methods that in a first phase assign the operations to the machines and in a second phase determine the starting times. A similar but simpler heuristic (named EST) was very briefly described in (Birgin et al., 2014, p.1426), where it was used, in the context of evaluating an MILP model, to provide an upper bound on the solution (i.e. an initial feasible solution) to the exact solver CPLEX.The proposed list scheduling algorithm iterates o times and, at each iteration, selects an operation i, assigns it to a machine k ∈ Fi, and determines the starting time st of operation i on machine k. This process is guided by customized rules for the extended version of the FJS problem. The decision is recorded by setting s[i] ← st (starting time of operation i) and w[i] ← k (machine to which operation i was assigned). In the context of the algorithm, if the values of s[i] and w[i] were defined, we say that operation i was already handled (by the algorithm) or scheduled. Otherwise, if s[i] and w[i] are undefined, we say that operation i is still unhandled. At a given iteration, operations that are candidates to be handled are those that are still unhandled and such that do not have unhandled predecessors.Parameters n, m, o,Fi(i=1,…,o),pik(i=1,…,o,k∈Fi),and A, that determine an instance of the FJS problem, are the input data of the list scheduling algorithm. From them, some auxiliary instance data that aid to apply the algorithm can be computed. Those quantities, that are defined for each operationi(i=1,…,o),are(a)The predecessors and successors setsPiandSigiven byPi={j∈{1,…,o}|(j,i)∈A}andSi={j∈{1,…,o}|(i,j)∈A}.The average processing timesp¯igiven byp¯i=1|Fi|∑k∈Fipik.The remaining (or blocked) work RWigiven by the longest (directed) path from i to any other operation j in the digraph with set of arcs A, set of nodes{1,…,o},and nodes’ weightsp¯1,…,p¯o.To support, at each iteration, the selection of an operation (plus the machine that will process it and its corresponding starting time), the algorithm keeps track of the following information:s[i] that saves, for each handled operation i, its processing starting time. The value is undetermined if operation i is still unhandled.w[i] that saves, for each handled operation i, the machine to which it was assigned. The value is undetermined if operation i is still unhandled.Cmax  the maximum among the completion times of the handled operations, i.e. the makespan of the partial solution (where by “partial solution” we mean the solution, not yet complete, composed by the already handled operations).u[i] that saves, for each operation i, the maximum among the completion times of its handled predecessors.v[k] that saves, for each machine k, the maximum among the completion times of the handled operations that were assigned to it.L[k] that saves, for each machine k, the sum of the processing times of the unhandled operations that can potentially be assigned to it (this is an upper bound on the future load of the machine).η[i] that says, for each operation i, how many unhandled predecessors it has.Ω the set of unhandled operations that have no unhandled predecessors (i.e. operations that are natural candidates to be handled).A partial solution with ℓ handled operations is characterized by the 9-tuple (ℓ, s, w, Cmax , u, v, L, η, Ω) that carries all the information needed (by the list scheduling algorithm that will be presented below) to generate a new partial solution withℓ+1handled operations. For the particular case of the partial solution withℓ=0scheduled operations, we have that{s[i]undeterminedfori=1,…,o,w[i]undeterminedfori=1,…,o,Cmax=0,u[i]=0fori=1,…,o,v[k]=0fork=1,…,m,L[k]=∑{i|k∈Fi}pikfork=1,…,m,η[i]=|Pi|fori=1,…,o,Ω={i∈{1,…,o}|Pi=∅}.Let (ℓ, s, w, Cmax , u, v, L, η, Ω) be a partial solution with 0 ≤ ℓ < o. If an operation i ∈ Ω is assigned to a machine k ∈ Fiand scheduled to start its processing at time st, the 9-uple that characterizes the new partial solution withℓ+1handled operation is given by(ℓ+1,s′,w′,Cmax′,u′,v′,L′,η′,Ω′),where s′, w′,Cmax′,u′, v′, L′, η′, and Ω′ receive, respectively, the values of s, w, Cmax , u, v, L, η, and Ω and then are updated as follows:{s′[i]←st,w′[i]←k,Cmax′←max{Cmax′,st+pik},u′[j]←max{u′[j],st+pik}forallj∈Si,v′[k]←max{v′[k],st+pik},L′[r]←L′[r]−pirforallr∈Fi,η′[j]←η′[j]−1forallj∈Si,Ω′←Ω′∖{i}∪{j∈Si|η′[j]=0}.The list scheduling algorithm introduced in this section starts with the partial solution withℓ=0handled operations, handles a single operation per iteration and ends after o iterations with a feasible solution to the given instance of the FJS problem. We now describe the rules to choose, at each iteration, the operation to be scheduled, the machine to which the operation is assigned, and the operation’s starting time.At each iteration, the set of candidate pairs operation/machine Ψ0 is given by(9)Ψ0={(i,k)|i∈Ωandk∈Fi}.The three rules below are sequentially applied until a single pair operation/machine (i, k) ∈ Ψ0 is selected and a processing starting time st is determined for the schedule of operation i on machine k.Rule 1:Pairs operation/machine with the earliest starting time.In accordance with the minimization of the makespan, the first attribute used to select a pair (i, k) from Ψ0 is based on the earliest starting time stikfor operation i on machine k, given by the maximum between two quantities: (a) the maximum between the completion times of the (already handled) predecessors of operation i, given by u[i], and (b) the time at which machine k ends to process all the already handled operations assigned to it, given by v[k]. Thus, we have that(10)stik=max{u[i],v[k]}for all (i, k) ∈ Ψ0. Let(11)st^=min{stik|(i,k)∈Ψ0}be the smallest possible starting time among the candidate pairs (i, k) ∈ Ψ0. Only pairs (i, k) such thatstik=st^remain as a possibility for the iteration assignment (with the natural choices[i]=st^andw[i]=k), while the other pairs are discarded. Thus, let(12)Ψ1={(i,k)|(i,k)∈Ψ0andstik=st^}.Rule 2:Fastest machine for each operation.LetΨ1i={(j,k)|(j,k)∈Ψ1andj=i}fori=1,…,o,i.e.Ψ1iis the subset of pairs in Ψ1 that correspond to the same operation i (associated with different machines in Fi). The focus of this rule is on the operations i such that|Ψ1i|>1and the objective is to select, for each one of those operations, a single machine among the several possibilities.Let i be such that|Ψ1i|>1and let(i,k1),(i,k2),…be the elements ofΨ1i. Each machinek1,k2,…is associated with the processing timepik1,pik2,…and the upper bound on the machine loadL[k1],L[k2],…Consider the triplets(pik1,L[k1],k1),(pik2,L[k2],k2),…and letΨ1.5i={(i,kν)}be the singleton such that(pikν,L[kν],kν)is the smallest triplet in the lexicographical order. It means that, among all possible machines that can process operation i, we select the one with the smallest processing time. In the case of a tie, the smallest upper bound on the machine load is used as a tie-break and, in the case of a second tie, the machine with the smallest index is chosen with no purpose other than defining a deterministic rule. DefineΨ2={∪Ψ1i||Ψ1i|≤1}∪{∪Ψ1.5i||Ψ1i|>1}.We have that Ψ2 ⊆ Ψ1 contains no more than one pair operation/machine for each operation and, for the operations that had more than one possible machine, it preserves only the most promising one (fastest and, in case of tie, less loaded).Rule 3:Operation with the largest remaining or blocked work.The next attribute used to reduce the number of candidate pairs (i, k) ∈ Ψ2 is based on an estimate of the remaining (or blocked) work RWithat is associated with an operation i. Recall that RWiis defined as the longest path from i to any other operation j in the digraph with set of arcs A, set of nodes{1,…,o},and nodes’ weightsp¯1,…,p¯o. Note that if the longest path starting at operation i ends at an operation j thenSj=∅and i and j belong to the same job t. Moreover,stik+RWimay be seen as an estimate of the completion time of job t, computed from the perspective of the candidate pair (i, k). However, sincestik=st^for all (i, k) ∈ Ψ2, we simple consider the value of RWias an estimate of the remaining or blocked work associated with operation i.For the pairs(i1,k1),(i2,k2),…∈Ψ2consider the triplets(−RWi1,−L[k1],i1),(−RWi2,−L[k2],i2),…and let(−RWiν,−L[kν],iν)be the smallest triplet in the lexicographical order, associated with the pair (iν, kν). This means that a final selection was made and that it consists in assigning operation iνto machine kνwith starting timest^. In this way, we selected the operation with the largest remaining or blocked work as the one to be scheduled. The idea behind this choice is to rapidly handleoperations that impair the processing of a large amount of work . In the case of a tie, the upper bound on the future load of the machines is used as a tie-break, in order to assign as soon as possible operations to a machine that has a large expected future load (trying to minimize its idle time). Finally, in the case of a second tie, the operation with the smallest index is chosen with no purpose other than defining a deterministic rule.The computation of the auxiliary instance data (items (a–c) at the beginning of Section 3), the initialization of the empty partial solution (Section 3.1), and the iterative application of rules 1–3 (Section 3.2) plus the update of the partial solution characterization (Section 3.1) define the method introduced in this section, that is fully described in Algorithm 1.SetsPiandSiare computed in lines 2–3, the average processing timesp¯iare computed in lines 4–7, the remaining work estimates RWiare computed in lines 8–16 by Dijkstra’s shortest path method (Cormen, Leiserson, Rivest, & Stein, 2009, pp.655–658) (adapted to compute the longest path and to the case in which there may be several sources and several targets). The values of Cmax , u, v, L, η, and the set Ω are initialized in lines 17–21. The main loop, from line 22 to line 41, executes o times rules 1–3. The selected pair at each iteration is named (λ, θ) and the determined starting time is namedst^. The starting time s[λ] for operation λ is set at line 36, as well as the the machine θ to which operation λ is assigned is recorded, in the same line, in w[λ]. The quantities Cmax , u, v, L, η, and the set Ω are updated in lines 36–41.A few words regarding the worst-case time complexity of Algorithm 1 are in order. Initializations from line 2 to 7 and from line 17 to 21 areO(|A|+m+∑i=1o|Fi|). Dijkstra’s algorithm implemented in lines 8–16 has complexityO(|A|+o). It remains to analyze the main loop that goes from line 22 to line 41 and is executed o times. If we consider that at each iteration we have that |Ω| ≤ o then we have that the loop isO(o∑i=1o|Fi|+|A|). Thus, summing up, we have that Algorithm 1 isO(|A|+m+o∑i=1o|Fi|).On the other hand, a better bound for |Ω| can be given. Consider the directed acyclic graphD=({1,…,o},A). An antichain in D is a set of nodes, no two of which are included in any path of D. Noting that operations in Ω are operations that have no precedence constraints among each other, it is not hard to see that the number of elements in Ω is limited by the size of a maximum antichain in D (that can be computed in polynomial time Fulkerson, 1956). Let w be the size of a maximum antichain in D and let(13)q=|Fi1|+|Fi2|+⋯+|Fiw|,whereFi1,Fi2,…,Fiware the w largest sets among the setsFi,i=1,…,o. We can say that the main loop (from line 22 to line 41) isO(oq+|A|). Then, we have that Algorithm 1 isO(|A|+m+oq),that provides a tighter bound on the worst-case time complexity of the algorithm.At each iteration of the list scheduling algorithm described in the previous section, an operation is selected, assigned to a machine, and its starting time is determined. On the one hand, all decision are made based on heuristic rules. On the other hand, even if we were able to make a decision based on a local optimal strategy, it is well-known that greedy algorithms not necessarily provide good quality solutions. Therefore, paying the price of increasing the complexity of the method, it makes sense to select, at each iteration, not a single operation to be handled, but a small set of operations to be handled. In this way, a partial solution can be split into several partial solutions with one more handled operation. This strategy gives rise to a search tree and fits into the framework of a beam search method. In this sense, we say that the presented beam search method is a “natural extension” of the list scheduling method described in the previous section.The introduced beam search method is a filtered beam search method with approximately f(β) nodes at each level of the search tree, where β ∈ (0, 1] is a given real parameter and f: IR → IN is a function to be defined later. Each node at a given level ℓ of the search tree represents a partial solution with ℓ handled operations. From the point of view of the beam search method, we can say that the (simple, thus non-expensive) rules 1–3 described in the previous section place the role of the local evaluation used to choose the g(α) more promising operations that would be considered to add one more handled operation to a given partial solution (where α ∈ (0, 1] is a given real parameter and g: IR → IN is a function to be defined later). Therefore, a partial solution may be split into g(α) partial solutions with one more handled operation. Then, a global (and more time consuming) evaluation is considered in order to select one partial solutions among the set of g(α) partial solutions. As expected, the global evaluation consists in completing each partial solution by running to the end the list scheduling algorithm described in the previous section. The one with the smallest makespan is chosen as the child of the parent being considered and, in this way, a new level of the search tree is built. In this work, we adopted the strategy of keeping a single child for each node as suggested in Sabuncuoglu and Bayiz (1999).We now describe how rules 1–3 from the list scheduling algorithm are used to generate the children of a given node or partial solution. Consider a partial solution with ℓ < o scheduled operations, or, equivalently, a node at level ℓ of the search tree, given by (ℓ, s, w, u, v, L, Cmax , η, Ω). Rules 1–3 can be applied to select a pair (i1, k1) ∈ Ψ0 and a starting timesti1k1for operation i1 on machine k1; and the pair (i1, k1) with the starting timesti1k1can be used to generate a partial solution with an additional handled operation. We will say that the generated child is the most promising child from the point of view of the local strategy. Assume now that the pair (i1, k1) is forbidden and that rules 1–3 are applied again (to the node at level ℓ). Then, another pair (i2, k2) ∈ Ψ0 is selected and a starting timesti2k2for operation i2 on machine k2 determined. This pair can also be used to generate a second child. We will say that this second child is the second more promising child from the point of view of the local strategy.In the way described in the previous paragraph, several children may be generated. On the one hand, since a relatively expensive global strategy must be applied to all children in order to keep a single child, a limit on the number of generated children is imposed. This limit is a function of the input parameter α ∈ (0, 1] and, ideally, should be independent of the size of the instance. However, to avoid a degradation on the method’s performance for instances of increasing sizes, we considered a limit given byα^1≡⌈α|Ψ0|⌉. Note that Ψ0 (as defined in (9)) depends on the partial solution being considered and, therefore,α^1may vary from node to node. On the other hand, a second limit that depends on the input parameter ξ > 0 and aims to preserve the children’s quality is also imposed. Note that rule 1 constructs the set Ψ1 (see 12) picking up from Ψ0 (see (9)) the pairs (i, k) such thatstik=st^,where stikandst^are given by (10) and (11), respectively. This means that (in the list scheduling algorithm) only pairs operation/machine with the earliest possible starting time are candidates for producing a new partial solution with an additional handled operation. However, this may not be the case when rules 1–3 are applied iteratively to pick several pairs up from Ψ0. Therefore, it makes sense to impose an upper bound on the starting time of the selected pairs. Consider the set(14)Ψ0.5={(i,k)|(i,k)∈Ψ0andstik≤st^+ξp^}⊆Ψ0,where(15)st^=min{stik|(i,k)∈Ψ0}andp^=max{pik|(i,k)∈Ψ0}.By imposing that no more thanα^2≡|Ψ0.5|children can be generated, we guarantee that the children’s starting time will not be larger thanst^+ξp^. This means that the bound on the number of children is given byα^≡min{α^1,α^2}. This defines the function g(α) that depends on the node and determines how many children will be chosen by the local strategy.We aim at generating a single child for each node (or, in other words, keeping a single child open and closing or bounding all the others). Given the node (ℓ, s, w, u, v, L, Cmax , η, Ω), a natural way to do that would be to complete the partial solution that it represents in different ways by selecting every possible pair in (i, k) ∈ Ψ0 (associated with the earliest starting time of operation i on machine k) and then completing all those partial solutions, that haveℓ+1scheduled operations, using the list scheduling algorithm . Since applying the list scheduling algorithm to all the |Ψ0| children may be too expensive, the strategy described in the previous paragraph filters the children preserving only theα^more promising children.After having selected a small set of promising children, the so-called global strategy is used to pick a single child from the set. As already suggested, the global strategy consists of computing the makespan of a solution that can be obtained by completing each child using the list scheduling algorithm. Note that we are not interested in the completed solution, but only in its makespan. The completed solution has an associated makespan that we will nameCmaxest. Among all children, the one with the smallestCmaxestis the chosen one, while all the others are discarded, closed, or bounded. A few technical details related to tie breaks between children and some other minor details will be given below, when describing the pseudo-code of the introduced beam search method.The whole beam search method is described in Algorithms 2, 3, 4, 5. Algorithm 2 corresponds to the initializations and to the construction of the first level of the search tree that is slightly different from the construction of the other levels. Algorithm 5 is the core of the beam search method that iterateso−1times generating the successive levels of the search tree. Algorithm 4 consists of subroutine Select that receives a partial solution and implements rules 1–3 to select a pair operation/machine that can be used to expand the given partial solution. Algorithm 3 consists of subroutine CmaxEst that receives a partial solution and, by completing it using the list scheduling algorithm, computes an estimate of the completion time that could be obtained by completing the given partial solution. Algorithm 3 is a re-implementation of Algorithm 1 in the form of a subroutine that does not perform the initializations and receives a partial solution. Subroutine Select plays the role of the local evaluation while subroutine CmaxEst plays the role of the global evaluation.The input parameters of Algorithm 2 are the data that describes the instance (n, m, o,Fi(i=1,…,o),pik(i=1,…,o,k∈Fi),A) plus the scalar real values ξ > 0 and α, β ∈ (0, 1]. Parameter ξ is related to the tolerance for the earliest starting time stikof a candidate operation/machine pair (i, k) with respect to the minimum earliest starting timest^among all pairs in Ψ0, as described in (14,15). Parameter α is related to the number of children of a given node that are selected by the local strategy and to which the global strategy is applied in order to keep a single child per node. Parameter β determines the number of nodes that remain open at each level of the search tree.Lines 2 to 16 of Algorithm 2 initializes (in the same way it is done in Algorithm 1)Pi,Si,p¯i,andRWi(i=1,…,o). QuantitiesCmax′,u′, v′, L′, η′, and the set Ω′ associated with the partial solution with none scheduled operation (i.e. the root node of the search tree) are initialized in lines 17–21. Since the “quality” of the partial solutions at the first level of the search tree has a strong influence in the overall performance of the method, no filter is considered to construct the first level. It means that all possible pairs operation/machine will be evaluated by the global strategy and the most promising ones will constitute the first level of the search tree (partial solutions with a single scheduled or handled operation). Lines 22 to 34 are devoted to this task. All possible pairs operation/machine (i.e. the ones in Ψ0 as defined in (9)) are considered, the partial solutions are constructed, its estimated completion times are computed (see the call to subroutine CmaxEst at line 33), and the partial solutions are saved in the setN′. In lines 35 and 36, the fraction β of the most promising partial solutions inN′is saved into the setNthat turns out to be the first level of the search tree. Note that due to possible ties, the cardinality ofNmay be larger thanβ^≡⌈β|N′|⌉. In line 37 subroutine BeamSearch (implemented in Algorithm 5) is called. It receives the first level of the search tree, constructs the remaining of the tree, and returns the best leave.Algorithm 5 implements subroutine BeamSearch. It iterateso−1times (see the main loop in line 2). Each iteration starts with the setNcomposed by the nodes of the current level of the search tree. Nodes inNare temporary labeled (numbered from 1 to|N|) with the identifier nid (that stands for node identifier) (see lines 3 and 5) and a set of childrenDnidfor each node is constructed. The limit on the number of children of each node was already described in the previous subsection and is implemented in lines 6–16. Then, a single child for each node is selected and saved into the setN′. The iteration finishes replacingNbyN′. It means that no tree structure is in fact build, since only the nodes of the current level are needed as each node carries full information of the partial solution it represents.The set of childrenDnidof a given node identified by nid is build in lines 17–28. The setDnidis initialized as the empty set in line 17. Exactlymin{α^1,α^2}children are generated, whereα^1is the one computed in line 6 andα^2is computed in lines 12–16. A copy(s′,w′,Cmax′,u′,v′,L′,η′,Ω′)of the current solution (s, w, Cmax , u, v, L, η, Ω) is made at line 19. A pair operation/machine (λ, θ) is selected (at line 20) by calling to subroutine Select. The new partial solution with an extra handled operation is build (lines 21–26) and its estimated completion timeCmaxestis computed by calling to subroutine CmaxEst at line 27. The new partial solution, together with λ, θ, andCmaxest,is saved inDnid. To guarantee that a different pair operation/machine will be selected in the forthcoming calls to subroutine Select (to generate the siblings of the just generated partial solution), the selected pair (λ, θ) is added to the setFthat stands for “forbidden pairs”. Subroutine Select (see Algorithm 4) implements rules 1–3 with the only difference that the most promising pair is chosen fromΨ0∖F.It remains to explain how a single child for node nid is chosen from the setDnidfor nid=1,…,|N|. This selection is based on the value ofCmaxestand it uses (λ, θ) to solve tie-breaks. Other than that there is an additional task that requires to inspect allDnidsimultaneously: to avoid identical children of different partial solutions inN. Note that all nodes in the first level of the search tree are different (since they consist of partial solutions with a single handled operation coming from different pairs operation/machine). However, when expanded, by considering an additional handled operation, two different partial solutions may become identical. Moreover, if some level of the search tree has identical solutions, their expansions will continue being identical to the end, affecting the diversity of the leaves (complete solutions). To avoid this situation, before choosing a single child per node, identical partial solutions are removed from∪Dnid. If identical partial solutions exist, the one with smallest λ is preserved and, in the case of ties, the one with smallest θ. (This strategy solves all possible ties since identical partial solutions cannot have identical λ and θ. Otherwise, there must be identical parents, which is not the case.) This elimination of identical partial solutions is done in the loop that goes form line 30 to line 36, marking the solutions to be removed by settingCmaxestequal to ∞. Solutions are in fact removed in line 37. Finally, the best child of each parent is chosen in lines 38 and 39 and saved in the setN′that, at the end of the iteration, substitutes the current set of nodesN(see line 40).A few words regarding the complexity of the beam search method described by Algorithms 2, 3, 4, 5 are in order. Algorithm 3 isO(oq+|A|)while Algorithm 4 is O(q) with q given by (13), as already analyzed in Section 3.3. Algorithms 2 (disregarding line 37 where subroutine BeamSearch described by Algorithm 5 is called, i.e. considering initializations and construction of the first level of the search tree only) has a worst-case time complexityO(∑i=1o|Fi|+r+oq2+q|A|),wherer=|Fi1||Si1|+|Fi2||Si2|+⋯+|Fiw||Siw|,w is the size of a maximum antichain inD=({1,…,o},A),and the indicesi1,i2,…,ioare such that|Fi1||Si1|≥|Fi2||Si2|≥⋯≥|Fio||Sio|. To analyze Algorithm 5, we will first assume thatα^andβ^are constants that do not depend on the instance size. It implies that each level of the search tree has|N|≤β^and that|Dnid|≤α^for nid=1,…,|N|. Thus, we have that the worst-case time complexity of Algorithm 5 is given by(16)O(α^β^(o|A|+o2q)+α^2o).However, in practice, we considerα^=O(q)andβ^=O(q). Therefore, (16) becomesO(oq2|A|+o2q3).Summing up, the overal worst-case time complexity of the introduced beam search method isO(r+q|A|+α^β^(o|A|+o2q)+α^2o),ifα^andβ^are given constants orO(r+oq2|A|+o2q3),ifα^andβ^are O(q).We implemented the list scheduling algorithm (Algorithm 1) and the beam search method (Algorithms 2, 3, 4, 5) in order to be able to evaluate their efficiency and efficacy. Codes, fully written in C/C++ and available for download at http://www.ime.usp.br/~egbirgin/, were compiled with the g++ compiler of GCC (version 4.7.2, Debian 4.7.2–5) using the optimization option “-O3”. All tests were conducted on a 2.40GHz Intel(R) Xeon(R) E5645 with 132GB of RAM memory and running GNU/Linux operating system (Debian 7, kernel 3.7.6 SMP x86_64). Detailed descriptions of the numerical results (including a complete description of the obtained solutions) are also available for download together with the source codes of the implemented methods.In order to have a way to evaluate the behavior of the introduced methods when applied to small and medium-sized instances, we applied an exact solver to the 50 instances of model (1–8) introduced in Birgin et al. (2014). Instances YFJS01–YFJS20 correspond to instances composed by two independent sequences of operations followed by an assembling operation that joins the previously processed components (named Y-jobs in Birgin et al., 2014), while instances DAFJS01–DAFJS30 correspond to instances composed by jobs whose precedences are given by arbitrary directed acyclic graphs. Tables 1 and 2summarize the main characteristics of each instance. Figs. 3 and 4illustrate the kind of operations’ precedence constraints that are present in each set of instances. It is worth noting that other complicating issues of the instances (like the routing flexibility given by the fact that each operation can be performed by a subset of machines) are not being displayed in the pictures. As exact solver, we used the IBM ILOG CPLEX 12.1 solver with the following settings: 1 for the maximum number of threads and 2048MB for working memory. All other parameters were left at their default values. In a first run, the CPU time limit was set to 1 hour and, in a second run, considering only the instances for which the optimal solutions was not found in the first run, the CPU time limit was set to 10 hours. Tables 3and 4show the results for the sets of instances YFJS01–YFJS20 and DAFJS01–DAFJS30, respectively. In the tables, “mks” stands for makespan and “CPU(s)” stands for the elapsed CPU time in seconds. In the cases in which the exact solver achieved the CPU time limit without finding an optimal solution, the tables report the obtained lower and upper bounds and the relative gap (given by the difference between the bounds divided by the upper bound). It is worth noting (in Table 3) that the exact solver was able to find the optimal solution in 14 (YFJS01–YFJS14) out of the 20 instances YFJS01–YFJS20, while a gap smaller than 1% was also obtained in two other instances (YFJS15 and YFJS16). On the other hand, Table 4 shows that the exact solver found the optimal solution in only four instances out of 30 and a gap smaller than 1% in a single instance when considering the set of instances DAFJS01–DAFJS30. These results will explain the “improvements” obtained by the introduced heuristic methods when compared against the solutions obtained by the exact solver (with a CPU time limit).In a first set of experiments, we aim to evaluate the numerical performance of the list scheduling algorithm. Tables 5and 6show the results of applying the list scheduling algorithm to the sets of instances YFJS01–YFJS20 and DAFJS01–DAFJS30, respectively. For each instance, the tables display the makespan of the solution obtained by the list scheduling algorithm. A comparison with the makespan obtained by the EST heuristic presented in Birgin et al. (2014) and the makespan obtained by the exact solver with CPU time limits of 1 and 10 hours is also presented. In each case, if v1 is the value of the makespan found by the list scheduling algorithm and v2 is the value of the makespan found by the other method, “diff”, that stands for relative difference, is given by(v1−v2)/v2. This means that negative values of “diff” indicate that the list scheduling algorithm found a solution of better quality. Both tables show that the introduced list scheduling method improves the solutions obtained by the heuristic EST introduced in Birgin et al. (2014). When compared against the exact solver, we must consider the two sets of instances in separate. In the set of instances YFJS01–YFJS20 for which the exact solver found optimal solutions in most of the cases, the difference is approximately 35%. In the set of instances DAFJS01–DAFJS30, in which the exact solver was unable to find optimal solutions in most of the cases, the distance is approximately 7%. Needless to say, the list scheduling algorithm runs, for every instance, in less than a fraction of a second. In any case, it is not our intention to compare our heuristic method against the exact solver but simple to evaluate the quality of the obtained solutions.In a second set of experiments, we aim to evaluate the numerical performance of the introduced beam search method. As every heuristic method, it is also relevant to evaluate the influence of the method’s parameters in its performance. With that purpose, we considered all 80 combinations of α ∈ {0.25, 0.5, 0.75, 1}, β ∈ {0.25, 0.5, 0.75, 1}, and ξ ∈ {0, 0.25, 0.5, 0.75, 1}. For each combination of parameters, we run the beam search method and we computed the average difference against the solutions obtained by the exact solver running with a CPU time limit of 1 hour and 10 hours. Tables 7and 8show those average distances for the sets of instances YFJS01–YFJS20 and DAFJS01–DAFJS30, respectively. The same information is graphically presented in Figs. 5a and 5b, respectively. Additionally, Figs. 6a and 6b present the average elapsed CPU time (in seconds) of the beam search method for each combination of parameters.A few comments are in order. We will focus on the comparison against the solutions obtained by the exact solver with a CPU time limit of 1 hour (the other comparison is similar). Table 7 shows that the beam search method with the combination(α,β,ξ)=(1,1,1)achieves an average distance of 3.5% in the set of instances YFJS01–YFJS20. This is an interesting result if we recall that for that set of instances the exact solver found optimal solutions in most of the cases. On the other extreme of the table, with the choice of parameters(α,β,ξ)=(0.25,0.25,0),the difference is 8.86%. On the other hand, Fig. 6a shows that with the former combination of parameters the beam search method requires almost 2 650 seconds per instance in average, while with the latter combination it requires approximately 5 seconds per instance in average. Other than that the table shows that considering all the 80 combinations of parameters, the differences range from 3.5% to 9.03%, showing a nice feature: the performance of the method does not strongly depend on a precise choice of parameters. The relation between the choice of parameters and the performance of the method can be easily seen in Figs. 5a and 5b. For fixed values of α and β, the optimal value of ξ is always greater than or equal to 0.5. Moreover, as expected, the larger the value of α and β, the larger the search space and, in consequence, the better the solutions’ quality and the larger the required CPU time.If we nowfocus in Table 8, we can see that, in the set of instances DAFJS01–DAFJS30, for which the exact solver was unable to find optimal solutions in most of the cases, the beam search method improves the exact solver’s solutions displaying differences that range from−4.94%(for the combination of parameters(α,β,ξ)=(0.5,0.25,0)) up to−6.36%(for the combination of parameters(α,β,ξ)=(1,1,0.5)). In the former case, considering instances DAFJS01–DAFJS30 individually, differences ranges from 12.94% up to−17.18% with an average CPU time of 1.18 seconds per instance, while in the latter case, differences ranges from 8.95% up to−17.52% with an average CPU time of 115.04 seconds per instance. Recalling that this comparison is being done with the exact solver that run with a CPU time limit of 1 hour (that was achieved in most of the cases; see Table 4), this means the beam search method is able to find high quality solutions in a small elapsed time.In a final experiment, we evaluate the performance of the introduced beam search method (for the combination of parameters(α,β,ξ)=(1,1,1)) when applied to the classical FJSP (without sequencing flexibility). We considered the sets of instances introduced in Barnes and Chambers (1996); Brandimarte (1993); Dauzère-Pérès and Paulli (1997); Hurink, Jurish, and Thole (1994). Table 9reports the relative error (RE) of the makespan mks found by our beam search method with respect to the lower bounds mksLB available at http://people.idsia.ch/~monaldo/fjspresults/fjsp_result.ps2015 given byRE=100%×(mks−mksLB)/mksLB.In the table, “# inst.” is the number of instances in each set. If these results are compared to those associated with the state-of-the-art GA method introduced in Pezzella et al. (2008, see Table 7 on p.3210), it can be seen that the beam search method obtains competitive results; outperforming all the three GA methods whose results are reported in Pezzella et al. (2008) in the set “Dauzére-Pérés and Paulli” and the set “Hurink VData” that is the set in which instances present the largest machine flexibility. However, all possible warnings apply to this comparison: (a) the beam search method is a deterministic method, with no randomness and with finite termination, while the other methods are run five times and the best makespan is used in the comparison; (b) in order to obtain a comparison-at-a-glance, we run the beam search method fixing its parameters α, β, and ξ all equal to 1 (while 80 different combinations were evaluated when the numerical experiments with the FJSP with sequencing flexibility were done); and (c) methods being compared were run on different machines and the CPU times of the GA methods considered in Pezzella et al. (2008) were not reported.

@&#CONCLUSIONS@&#
An extension of the classical flexible job shop problem, in which precedences between the operations can be given by an arbitrary directed acyclic graph instead of a linear order, was considered in this work. A list scheduling algorithm that fully exploits the characteristics of the problem was introduced. Then, substituting the choice of a single operation to be scheduled and sequenced at each step of the method by a set of operations, a beam search method was naturally developed. Numerical results assessed the effectiveness and efficiency of both approaches. The precise description and full availability of methods and results allows them to be used as benchmark for future developments. There is vast range of extensions of the classical flexible job shop problem that might be considered in order to deal with more realistic situations. Redesigning the presented methods to deal with those extensions would be the subject of future research.