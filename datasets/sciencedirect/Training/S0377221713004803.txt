@&#MAIN-TITLE@&#
An iterative three-component heuristic for the team orienteering problem with time windows

@&#HIGHLIGHTS@&#
Developed an iterative three-component heuristic for the TOP with time windows.Inspired by two “no-worse-than” propositions when designing the algorithm.Combined local search, meta-heuristic and mathematical programming.Employed a dedicated neighborhood operator.Achieved best overall performance and new best solutions on the benchmark.

@&#KEYPHRASES@&#
Routing,Team orienteering problem with time windows,Heuristic,

@&#ABSTRACT@&#
This paper studies the team orienteering problem with time windows, the aim of which is to maximize the total profit collected by visiting a set of customers with a limited number of vehicles. Each customer has a profit, a service time and a time window. A service provided to any customer must begin in his or her time window. We propose an iterative framework incorporating three components to solve this problem. The first two components are a local search procedure and a simulated annealing procedure. They explore the solution space and discover a set of routes. The third component recombines the routes to identify high quality solutions. Our computational results indicate that this heuristic outperforms the existing approaches in the literature in average performance by at least 0.41%. In addition, 35 new best solutions are found.

@&#INTRODUCTION@&#
The aim of the team orienteering problem with time windows (TOPTW) is to maximize the total scores collected by visiting a set of locations, each of which has a score, a service time and a time window. The number of routes is limited, and each location can be visited at most once. A route is feasible if no time window for a visited location is violated, and if it begins and ends at the same given location. The TOPTW has numerous real-life applications (Golden, Levy, & Vohra, 1987; Souffriau, Vansteenwegen, Vertommen, Berghe, & Oudheusden, 2008; Tsiligirides, 1984). In this paper, we consider the vehicle routing application in which a shipper sends out a fixed number of vehicles from a depot to serve some of its customers with the aim of maximizing the total profit gained from successful service.The main contribution of this paper is an iterative three-component heuristic (I3CH) that is straightforward but every effective. The heuristic employs a local search procedure and a simulated annealing procedure as its first two components to explore the solution space. They store the discovered routes into a pool for future use. The third component then recombines these routes by solving a set packing formulation to obtain a high quality feasible solution. Embedded in an iterative structure, these three components cooperate and perform effectively. We conduct computational experiments on the TOPTW test instances in the literature, and find our heuristic to outperform the existing approaches in terms of average performance. Before these experiments, we classify the test instances with known optimal solutions into an “OPT” category and the remainder into an “INST-M” category. The average performance improvement for the “INST-M” instances is at least 0.49%, and 35 new best solutions are found. For the 66 instances in the “OPT category”, our heuristic found 55 optimal solutions, 16 more than the previous best approach in the literature. In addition, our approach runs efficiently.The remainder of this paper is organized as follows. Section 2, provides a clear definition of the TOPTW and a brief overview of the research literature addressing it. Section 3 describes the three-component heuristic and its components, and Section 4 extends the heuristic by constructing an iterative framework. Section 5 evaluates the effectiveness of our approach and compares it to the known approaches in the literature. Finally, Section 6 concludes that paper with closing remarks and possible directions for future research. The detailed solution values for each test instance are relegated to the appendix.The TOPTW examined in this paper is defined as follows. On a given network graphG=(V,A), there aren+1different locations denoted by the setV={0,1,2,…,n}and a set of arcs connecting these locations which is denoted asA={(i,j):i≠j∈V}. The travel time,tij, from location i to j is equal to the Euclidean distance,dij, from i to j. Let location 0 be the depot and each of the remaining location corresponds to one customer. The number of available vehicles is fixed at m. Each vehicle must begin and end its route at the depot within the depot’s time window[O0,C0]. Each customeri=1,…,nwith a profitpi, a service timeTiand a time window[Oi,Ci]can be visited at most once. The service delivered to the customer is successful if it begins within his or her time window. In the case of an earlier arrival, the vehicle has to wait until the time window begins. Profit is gained upon successful service. Note that owing to the limited number of vehicles, some customers may not be visited in a feasible solution. The objective of the TOPTW is to identify a feasible routing plan that ensures the maximization of total profit.The TOPTW is one of many variants of the widely studied Orienteering Problem (OP) (Chao, Golden, & Wasil, 1996a; Fischetti, Salazar Gonzalez, & Toth, 1998; Schilde, Doerner, Hartl, & Kiechle, 2009). Vansteenwegen, Souffriau, and Oudheusden (2011) published an excellent review of the OP and, its applications and variants, including the team orienteering problem (TOP) (Chao, Golden, & Wasil, 1996b; Tang & Miller-Hooks, 2005; Vansteenwegen, Souffriau, & Van Oudheusden, 2009), the OP with time windows (OPTW) (Kantor & Rosenwein, 1992; Righini & Salani, 2009) and the TOPTW. Given a set of locations with a score, OP seeks to determine one path that visits some vertices and maximizes the total score. The TOP extends the OP to identify multiple paths that maximize the total score. The OPTW and TOPTW extend the OP and TOP, respectively, by incorporating time windows constraints. All these problems have many applications (Golden et al., 1987; Souffriau et al., 2008; Tsiligirides, 1984), and are challenging because of their complexity. As the OP is NP-hard (Golden et al., 1987), the TOPTW must also be NP-hard. Therefore, solving the highly constrained TOPTW optimally in polynomial time is highly unlikely. Recent research shows heuristics and meta-heuristics to be the most popular techniques to solve this problem.The TOPTW has only recently become popular, and several state-of-the-art papers on the problem can be found in the literature. For example, Montemanni and Gambardella, in 2009, published a paper entitled “The team orienteering problem with time windows” (Montemanni & Gambardella, 2009). They designed an ant colony system (ACO) to solve the problem and achieved the best results on OPTW instances. In addition, they contributed the earliest test instances for this benchmark research. More recently, Montemanni, Weyland, and Gambardella (2011) and Gambardella, Montemanni, and Weyland (2012), extended the ACO and reported new best solutions. Vansteenwegen, Souffriau, Vanden Berghe, and Van Oudheusden (2009) subsequently proposed an iterated local search (ILS) algorithm for the TOPTW, an approach that runs significantly faster than the ACO requiring only a few seconds of computational time to solve an instance while maintaining competitive solution quality. In addition, the authors constructed a new set of test instances with known optimal solutions. Tricoire, Romauch, Doerner, and Hartl (2010) solved an even more complicated problem, the multi-period orienteering problem with multiple time windows, which is a generalization of the TOPTW. They obtained good-quality solutions when they tested their variable neighbor search (VNS) meta-heuristic on the TOPTW instances. Souffriau, Vansteenwegen, Berghe, and Van Oudheusden (2013) studied another generalization, the multi-constraint team orienteering problem with multiple time windows, and found its solution method also to perform well on TOPTW test instances. Concentrating on the TOPTW, Labadi, Melechovskỳ, and Calvo (2011) developed a hybrid meta-heuristic that combines the greedy randomized adaptive search procedure (GRASP) with the evolutionary local search (ELS) approach. This method improved several of the best known results on available benchmark instances at that time. In 2012, Lin and Yu developed two versions of simulated annealing algorithm for the TOPTW (Lin & Yu, 2012). The fast version computes a solution within only several seconds, while the slow version achieves better solutions at the expense of more computational time. Some current best-known solutions are obtained by the slow version (SSA). Most recently, Labadie, Mansini, Melechovsk, and Calvo (2012) provided new results for the TOPTW. They developed a VNS algorithm that explores granular neighborhoods (GVNS) based on linear programming.As we have seen, most of the existing approaches are neighborhood search approaches. When a neighborhood search approach solves a TOPTW instance, not only are new solutions are explored, but a set of routes is discovered. A feasible solution can be defined as a combination comprising m routes that satisfy route feasibility and the condition that each customer can be served at most once. Given a set of discovered routes, there exists a best combination that is always no worse than the explored solutions. We derive the two following straightforward “no-worse-than” propositions. The proofs are omitted.Proposition 1Suppose that a neighborhood search algorithm A solves the TOPTW. It searches N neighbors and obtains a solution S1. At the same time, it also discovers a set of mN routes. The best combination S2of these routes is no worse than S1.Suppose that two neighborhood search approaches, A1and A2, both solve the TOPTW. A1discovers a set of routes R1and obtains a solution S1. A2discovers a set of routes R2and obtains a solution S2. The best combination, S3, overR1∪R2is no worse than S1or S2.On the basis of these two propositions, we propose a heuristic that first employs two different neighborhood search approaches to search the solution space, then keeps the discovered routes into a pool, and finally recombines them to obtain the best combination. We call it a three-component heuristic. In our design, the first two components are local search and simulated annealing. They explore the solution space and store routes. The third component is route recombination which recombines the routes to produce the best combination. Fig. 1illustrates the heuristic’s structure.In the following subsections, we first introduce the representation of a solution, and then the neighborhood operator that will be used in the local search and simulated annealing. Finally, we demonstrate the three components.In the solution encoding, we use m lists to represent the m routes. Each list starts and ends with 0, which is the depot. Denote the routes byri,i=1,…,m. Customers who are not visited by any route are stored in another list u. For example, givenV={0,1,2,…,10}andm=2, a potential solution is represented byr1={0,1,3,5,0},r2={0,2,4,6,8,0}andu={7,9,10}(see Fig. 2).Both the local search and simulated annealing procedures are neighborhood search approaches. We propose a neighborhood operator called eliminator to produce neighborhood solutions. The eliminator first removes some customers from some routes, and then inserts the unvisited customers from u. If the newly added customers are more profitable, solution quality is improved. Such newly generated solutions are then further improved through a post-processing procedure.We say a solution is complete if no more customers from u can be inserted into any route, otherwise the solution is partial. A partial solution can be improved by inserting some customers from u while keeping the routes feasible.Given a solution A, theeliminatorrandomly removes some customers from some routes to obtain a partial solutionA′. Suppose thatri,i=1,…,mare routes ofA′and that u is the list of unvisited customers. We can then improveA′to obtain a complete solution B by iteratively removing a customer c0 from the head of u and attempting to insert c0 into any routeri. The insertion should be made at the first feasible insert position. If no feasible insert position exists, c0 is moved to the end of u. The procedure is terminated when no more customers can be inserted. The resulting solution B is one of the many neighbors of A. Since theeliminatoris stochastic, a set of solution neighbors can be produced by applying it to A multiple times.To enhance theeliminator, we set rules on how to remove customers. Letp¯be the average profit over all customers on m routes. Customer cjis eliminated with a probabilityPhifpj⩾p¯, and a probabilityPlifpj<p¯. ConsideringPh<Pl, it indicates thateliminatorprefers to retain customers that represent a higher profit. Therefore, with employment of theeliminator, the local search and simulated annealing are to find better neighbor solutions.We next apply the post-processing procedure to improve the newly generated solution B. This post-processing procedure iteratively invokes seven operators until further improvement is impossible. The seven operators are divided into three types: relocate, exchange and 2-opt.Relocate operators. Relocate operators insert a customer cjat a feasible insertion position on a routeri. As cjmay come from different routes or from u, relocate operators have three variants: 0-relocate, 1-relocate and 2-relocate. 0-relocate functions when cjcomes from u. For a successful operation, 0-relocate improves the solution by additional profitpj. If the relocation takes place on the same route, it is a 1-relocate operation. Finally, a 2-relocate operation is to relocate a customer from one route to another. Neither 1-relocate nor 2-relocate can increase the total profit, but they can reduce the travel distance. We believe that a solution with shorter travel distance has a more desirable structure, because it may provide greater opportunity for the other operators to improve the solution quality.Exchange operators. Exchange operators swap two customers in the solution. Similar to relocate operators, they also have three variants: 0-exchange, 1-exchange and 2-exchange. Of the three, 0-exchange is the only exchange operator to improve the objective value. The solution quality is improved when 0-exchange replaces an existing customer on one route with a more profitable customer from u. 1-exchange is an intra-route operator while 2-exchange is an inter-route operator. Both of them are used to improve the solution structure by reducing the travel distance.2-opt operator. 2-opt operator behaves in the same way that it does when used to solve the vehicle routing problem with time windows (VRPTW). It first selects two edges from two different routes. These two edges separate the two routes into four parts. After a crossover, the 2-opt might recombine them into two new feasible routes reducing the total travel distance.The seven operators are illustrated in Fig. 3. Only 0-relocate and 0-exchange contribute to improving solution quality. The remaining operators restructure a TOPTW solution. The restructured solutions can be desirable as it may provide opportunities for 0-relocate and 0-exchange operators to make improvements. Algorithm 1 illustrates the post-processing procedure.Algorithm 1Post-processing procedure (PP)Require: A solution S;1: Setimpr←1;2: whileimpr>0do3:  Invoke the 2-relocate, 2-opt and 2-exchange operators on S and obtainS′;4:  Apply the 1-relocate and 1-exchange operators onS′and obtainS″;5:  Run the 0-relocate and 0-exchange operators onS″and obtainS‴;6:  Setimpr←1if there is an improvement, otherwise setimpr←0;7:S←S‴;8: end while9: return the solution of S;The first two components of our heuristics are Local Search and Simulated Annealing. As previously noted, their objective is to search for a better solution in the neighborhood and then store the discovered routes during the exploration.The Local Search procedure (LS) iteratively explores the neighborhood of a starting solution X. In each iteration, LS generates N neighbors using the neighborhood operator eliminator. The solution of each neighbor contains a list of routes. LS caches these routes into a poolPOOL. At the end of each iteration, LS updates X with the best neighbor if there is one. Otherwise, X is replaced by the last explored neighbor. LetXLSbe the best solution found. If X is better thanXLS, there is an improvement and we updateXLSwith X. LetIls_no_imprbe the number of current consecutive iterations with no improvement. Once there is an improvement, setIls_no_impr=0. Otherwise, increaseIls_no_imprby 1.LS searches N neighbors and then decides which one to move to, whereas the Simulated Annealing procedure (SA) behaves in a different way: each time it produces only one neighbor and accepts it with a computed probability. Simulated annealing has been widely studied in the literature and employed in many applications. It is an attractive technique because of its ease of implementation, convergence properties and ability to escape from local optima. As one of the most popular approaches to solve the routing problems, it has been used to solve the traveling salesman problem (Malek, Guruswamy, Pandya, & Owens, 1989), the vehicle routing problem (Van Breedam, 1995), the vehicle routing problem with time windows (Chiang & Russell, 1996) and other routing problems (Lin & Yu, 2012; Lin, Yu, & Chou, 2009; Yu, Lin, Lee, & Ting, 2010). For a more in depth discussion of simulated annealing, we recommend Eglese (1990), Koulamas, Antony, and Jaen (1994), Suman and Kumar (2006) and Gendreau and Potvin (2010).We define three parametersT0,α, andIsa_no_imprin SA to denote the initial temperature, cooling speed and number of current consecutive iterations without improvement respectively. Let Y be the starting solution andYSAthe best solution found by SA. For each step, SA invokes the eliminator to obtain one neighbor of Y, denoted byY′. IfY′is better than Y, SA will move toY′directly. Otherwise, SA will accept this neighbor with a probabilityPsa, which is computed with Eq. (1). At the end of each step, we updateT=α*T. To be consistent with LS on the term of “iteration”, we redefine an iteration in SA as the whole of N consecutive steps: that is, SA runs N steps in an iteration, where N is exactly the same as in LS. We can then updateIsa_no_imprin a similar way. Once there is an improvement in an iteration, we setIsa_no_impr=0. Otherwise, we increaseIsa_no_imprby 1. SA reportsYSAat the end. It also caches all routes of the visited neighbors intoPOOL.(1)Psa=exp1TY′-YYSAThe heuristic’s third component, route recombination (RR), receives the routes fromPOOLand recombines them to obtain high-quality solutions.After taking overPOOL, RR solves a set packing formulation over the routes to produce the best combination, which is a feasible solution of the TOPTW. Providing a set of routes inPOOL={r1,r2,…,rSpool}, whereSpoolis the size ofPOOL. Forj∈V⧹{0}andk∈{1,2…,Spool}, letajk=1if customer j is visited by route k, andajk=0otherwise. The total profit of a routerkis computed asqk=∑j∈V⧹{0}pjajk. We definexk=1if routerkis selected in the final solution, andxk=0otherwise. Therefore, we derive the set packing formulation as follows.(2)RR:Maximize∑k=1Spoolqkxk(3)Subjectto∑k=1Spoolajkxk⩽1,∀j∈V⧹{0}(4)∑k=1Spoolxk⩽m(5)xk∈{0,1},∀k∈{1,2…,Spool}The objective (2) maximizes the total collected profit. Constraints (3) ensure that each customer can only be visited at most once. Constraint (4) guarantees that no more than m routes be combined into a new solution. This inequality equipped with “⩽” is reasonable as m can be so large for some test instances that all customers may already have been visited by fewer than m vehicles. The aim of the operation is to pack more profitable routes into the generating solution to maximize the total profit.IfPOOLis completed by including all feasible routes, then RR will compute an optimal solution for the TOPTW. However, the complete setRhas exponential elements which make it difficult to solve RR in practice. Our design allows us to set an upper limit onSpool. Following this capacity setting, RR loads only partial routes fromRand obtains an Integer Programming (IP) solution that may not be optimal for the TOPTW. Such a strategy constitutes a trade-off between solution quality and computational efforts. With a suitableSpool, commercial MIP solvers, such as ILOG CPLEX 12.2, are capable of solving RR within a reasonable amount of computing time.To further accelerate the RR component, we can make use of the upper bound obtained from its LP relaxation. BecausePOOLincludes only a limited number of routes, there is a possibility that the solution to be obtained by RR is no better than the best solution we already achieved. If that is the case, then the computational efforts of the MIP solver would be in vain. Thus, we first solve the LP relaxation of RR to obtain an upper bound. If this upper bound is no better than the best achieved solution, then the time-consuming computation for the IP model is skipped and RR returns an empty solution which consists of m empty routes and a random ordered list of all unvisited customers. This results in considerable computational efforts.When RR is solved by an MIP solver, the best combination of the routes inPOOLis obtained. We then construct a complete solution based this combination by attempting to insert all unvisited customers. In the implementation, the customers in u are sorted in non-ascending order of profit. LetZRRbe the final solution.ZRRis usually of high quality and can be used to assist LS and SA in escaping from a local optimum in the iterative framework introduced in the following section.To ensure better cooperation among the three components, we introduce an iterative framework as the entire algorithm described in Algorithm 2. The whole algorithm is called the Iterative 3-Component Heuristic (I3CH).Algorithm 2Iterative 3-Component Heuristic for the TOPTWRequire: maximum number of iterationsImax;Require: integer N;Require: route poolPOOL;1: Apply the Initialization to obtain starting solution A, and cache the routes intoPOOL;2: Seti←1;3: whilei⩽Imaxdo4:  Invoke the route recombination overPOOLand obtainZRR;5:  Apply the local search to explore N neighbors and cache the routes intoPOOL;6:  Run the simulated annealing with N steps and cache the routes intoPOOL;7:  Select the best solution B from the collection{A,ZRR,XLS,YSA}breaking ties arbitrarily, whereXLSandYSAare the best solutions of LS and SA respectively;8:A←B,i←i+1;9:  If all customers are served in A, then seti←Imax+1;10: end while11: return the solution of A;At the beginning of the proposed heuristic, we apply an initialization procedure to obtain a starting solution A. During initialization, it randomly enumerates3*Nsolutions and selects the best one to set A. Additionally, it stores the routes of the enumerated solutions intoPOOLfor future use. To enumerate a solution, the procedure first initializes m empty routes and a randomly ordered list u containing all customers. It then invokes the eliminator which can eliminate nothing but can choose customers from u for the routes before a complete solution is obtained. Applying the post-processing procedure in the third stage produces an improved solution. The routes from such solution are cached intoPOOL. At the end of this procedure, we set A as the starting solutions of LS and SA.The iterative framework significantly strengthens our approach. As introduced, LS and SA deliver their routes to RR such that RR can produce a high quality solutionZRR. On the other hand, RR contributes and assists LS and SA to escape from local optima. In this framework, the starting solution of LS is to be reset to the global best solution A once the number of consecutive iterations without improvement exceeds a numberIno_impr, i.e.,Ils_no_impr>Ino_impr. Similarly, the starting solution of SA is also updated by A. The difference is that the condition for SA isIsa_no_impr>Ino_impr. As previously observed, the best global solution A is frequently updated byZRR. In this sense, RR regularly brings improvements to LS and SA.The iterative framework highlights the management issues onPOOL. On the one hand, LS and SA repeatedly push routes intoPOOL. On the other, the efficiency of RR depends on the size ofPOOL. Setting pool sizeSpoolto a fixed number means that new routes cannot be immediately added when the capacity is full. This means that we have to remove some “old” routes out ofPOOLbefore adding new ones in an iteration. Furthermore, the routes inPOOLdetermine the quality of the solution found by RR. Hence, it is important to devise an appropriate strategy for managing the route poolPOOL. Our strategy is to adapt the least recently used (LRU) concept that discards the least recently used route in our application.By preserving the most recently used routes inPOOLand exchanging the least recently used routes with the newly discovered routes, the LRU strategy increases RR’s opportunities to improve solution quality. We define an attributeaprfor each route inPOOLto indicate its importance and set each new route included intoPOOLwithapr=0. Because ofPOOL’s capacity, we eliminate routes with the leastaprand reallocate the space to new routes. In the case of a tie, the more profitable routes are retained. Once RR is solved and returns a feasible solution, we update the attributes of the routes employed withapr=100. Theaprof the other routes inPOOLis reduced by 1.In computational experiments, our algorithm was implemented as a sequential algorithm in Java. The experimental results reported were obtained on a Linux server equipped with an Intel Xeon E5430 CPU clocked at 2.66gigahertz, 8gigabytes RAM and running CentOS 5.4. The IP solver used was ILOG CPLEX 12.2 (64-bit Linux edition). The detailed results can be found online at http://www.computational-logistics.org/orlib/toptw/.Vansteenwegen et al. (2011) summarized all existing test instances of the TOPTW in their review paper. The data sets can be accessed at http://www.mech.kuleuven.be/en/cib/op.Montemanni and Gambardella (2009) constructed the TOPTW instances that extend the OPTW instances by increasing the number of vehicles:m=2,3,4. The earlier OPTW instances were designed by Righini and Salani (2009) based on the 48 instances in Solomon (1987) VRPTW data set (c*_100, r*_100 and rc*_100) and 10 instances in the multi-depot vehicle routing problems (pr01–pr10) considered by Cordeau, Gendreau, and Laporte (1997). Montemanni and Gambardella (2009) developed another 37 OPTW instances, of which 27 instances are adapted from Solomon’s (1987) data set (c*_200, r*_200 and rc*_200) and 10 instances from that of Cordeau et al. (1997) (pr11–pr20). We classify these TOPTW instances into the aforementioned “INST-M” category which contains four subsets which are “Cordeau 1–10”, “Cordeau 11–20”, “Solomon 100” and “Solomon 200”.Vansteenwegen, Souffriau, Vanden Berghe, et al. (2009) constructed a new data set of TOPTW instances which were extensions of those in Solomon (1987) and Cordeau et al. (1997). The major feature of this new data set is that the optimal solution for each instance is known. This is due to the specific setting on the number of provided vehicles, which enables all customers to be visited. Hence, the optimal objective value is equal to the total profit on the network graph. We include these instances into the “OPT” category.To evaluate the performance of our algorithm, we considered the following state-of-the-art algorithms in our comparisons:•ACO: the ant colony system proposed by Montemanni and Gambardella (2009).ILS: the iterated local search algorithm developed by Vansteenwegen, Souffriau, Vanden Berghe, et al. (2009).VNS: the variable neighbor search approach proposed by Tricoire et al. (2010).GRASP-ELS: a hybrid metaheuristic combining the greedy randomized adaptive search procedure with the evolutionary local search, proposed by Labadie, Melechovský, and Wolfler Calvo (2011).SSA: slow version of the simulated annealing heuristic proposed by Lin and Yu (2012).GVNS: the LP-based granular variable neighborhood search algorithm by Labadie et al. (2012).Of these algorithms, only ACO was not tested on the new data set “OPT”. Also, ACO was executed in five runs for each instance whereas the VNS and GVNS were executed in 10. We considered their average performance in the comparisons. Moreover, as previously noted, Lin and Yu’s (2012) SA has fast and slow versions. The fast simulated annealing (FSA) which is given less computational time and the slow simulated annealing (SSA) which finds better solutions at the expense of more computational time. As we are more concerned with solution quality, we used SSA rather than FSA in the comparisons.To ensure fair comparisons, the solutions for each algorithm were compared with the best known solutions (BKS) among ACO, ILS, VNS, GRASP-ELS, SSA, GVNS and the improved best solutions from Gambardella et al. (2012) with the computational time adjusted to the speed of the computers used in those solutions. We summarize the experimental environment of each algorithm and compare their CPU speed in Table 1. As all of the algorithms are single threaded, it is reasonable to compare their CPU speed using the Super Pi benchmark.1Super Pi is a single-threaded program that computesπup to a specified number of digits using the Gauss–Legendre algorithm. It is commonly used as a crude estimate of CPU speed. See http://www.superpi.net/.1In Table 1, the Super Pi (seconds) column reports the number of seconds it took a processor to compute the first 1 million digits ofπ. Unfortunately, for ACO and VNS, the Super Pi scores of their processors are not available. Labadie et al. (2011) presents strong evidence to show the comparability of processors used by ACO and GRASP-ELS. As only limited information was available on the processor used by VNS method, as such we cannot estimate its speed by considering only the clock-rate. A review of all 2.40gigahertz processors found most to be slower than ours, and we therefore assumed that the processor used in computing the VNS was slower than ours. Finally, we estimated the single-thread performance of each processor by supposing the performance of our machine to be 1. The computational time was adjusted by the single-thread performance. For example, we multiplied the computational time of a solution obtained by GVNS by 0.33.The proposed approach I3CH has nine parameters:Imax,NandIno_imprin the iterative framework,PhandPlin the neighborhood operator eliminator,T0andαin the SA component,Spoolin the RR component and a random seed, denoted asseed, to ensure randomness. As appropriate settings on these parameters strengthen our algorithm, we designed the parameter tuning experiments.We carried out four experiments to tune the parameters, using a predetermined subset of 10 instances. The chosen instances are “c203”, “c207”, “pr02”, “pr07”, “pr12”, “pr16”, “r102”, “r105”, “rc107” and “rc204” consideringm=4. Our approach performed relatively worse on these 10 instances in the preliminary tests in which the parameters were set to preliminary values.We first performed tests to adjust the settings onPhandPlin the neighborhood operator eliminator. In our design, we invoked the I3CH procedure on the 10 chosen instances to test all probabilitiesPh∈{0.0,0.1,0.2,0.3,0.5}andPl∈{0.1,0.2,0.4,0.6,0.8,1.0}. The experiment was repeated five times with different random seedsseed∈{3,5,7,9,11}. For the remaining parameters, we setT0=1andα=0.92for the SA component, pool sizeSpool=300,N=20,Ino_impr=20andImax=1000. For each run, the percentage gap between the solution value achieved by the I3CH and the BKS is computed by:(6)gap=BKS-I3CHBKS×100%The results are summarized in Table 2in which we present the average gap over 50 runs (10 instances×5 random seeds) for each pair ofPhandPl. We can see that the I3CH performs worse whenPh=0which indicates that allowing more profitable customers to be eliminated affords greater flexibility and increases the opportunities to get a better solution. We finally decided to pickPh=0.1andPl=0.3as this pair resulted in the smallest average gap.A second experiment was carried out to tune parametersT0andαin the SA component. Similar to the first experiment, we invoked the I3CH procedure on the 10 instances and repeated it five times with different random seedsseed∈{3,5,7,9,11}. We testedT0∈{0.1,1,10,100},α∈{0.9,0.93,0.95,0.97,0.99,0.995,0.999}. The settings on the remaining parameters werePh=0.1,Pl=0.3,Spool=300,N=20,Ino_impr=20andImax=1000. We computed the average percentage gap between the solution value by I3CH and BKS over five different random seeds for each test instance. In Table 3, we present the average of this gap over the 10 test instances for eachT0andα. It is shown bothT0=0.1,α=0.995andT=100,α=0.999achieved the smallest gap 0.39%. Therefore, we picked the pairT0=0.1,α=0.995.The third experiment tunedSpoolin the RR component.Ph=0.1,Pl=0.3,T0=0.1andα=0.995were determined. We setseed∈{3,5,7,9,11},N=20,Ino_impr=20, andImax=1000and aimed to select the most appropriateSpool∈{100,200,300,400,600,800,1000,1500,2000}. Table 4reports the average performance for each setting ofSpool. We choseSpool=1000, which is a tradeoff between effectiveness and efficiency.The final experiment was designed to investigate the tuning ofN,Ino_imprandImax. These three parameters affect the performance of the I3CH from the outer iterative framework. We consideredN∈{10,20,50,100},Ino_impr∈{10,20,50,100}andImax∈{500,1000,2000,3000,4000,5000}. The other parameter settings had already been configured asPh=0.1,Pl=0.3,T0=0.1,α=0.995andSpool=1000. We repeated the experiment five times with differentseed∈{3,5,7,9,11}and computed their average performance.Fig. 4contains four subgraphs, each of which investigates the performance of the I3CH over different N andImaxby fixingIno_impr. In the subgraph for “Ino_impr=10”, we see that the curve marked “N=50” outperforms the other three over allImax. The three other subgraphs, also showed that one group of settings outperforming the others. We therefore selected the best four, the results of which are summarized in Table 5. The table shows thatIno_impr=20andN=50constitute the best choice with regard to solution quality. Column Avg. Time (seconds) shows that we choseImax=3000since 380 s for an instance is acceptable. This setting is also a tradeoff between effectiveness and efficiency.In this subsection, we discuss the results of experimental tests carried out to investigate the behavior of the proposed approach. As our approach is essentially component-based, it is important to investigate the performance of each component and their combinations. These experiments allowed us to analyze the effects exerted by the components.In the experiments, we considered both each component alone and their various combinations, namely, LS, SA, LS+SA, LS+RR, SA+RR and LS+SA+RR. All six methods are embedded in the iterative framework. Note that LS+SA+RR is actually the I3CH. To investigate their performance, we tested each of them on all the “INST-M” instances (m=1,2,3,4). The methods share the same parameter settings which arePh=0.1andPl=0.3for the neighborhood operator,T0=0.1andα=0.995for SA,Spool=1000for RR;Imax=3000,N=50andIno_impr=20for the iterative framework. The random seed isseed=3.We summarize the average performance of each method in Table 6. The performance is evaluated on solution quality by computing the percentage gap from BKS for each instance. Each column under a method gives the average performance on each instance set and the overall average performance on all instances. From the table, LS performed the worst with an average gap 1.50% from BKS. SA performed better than LS on each instance set. This is due to the superior convergence properties of SA and its capability to escape local optima. The combination LS+SA achieved better solution quality than both LS and SA, but the improvement is slight. However, RR brought improvements. After combining RR with LS, SA and LS+SA respectively, the average performance is significantly improved. For instance, we can see that LS+RR reduced the average gap obtained by LS by 0.45%.Fig. 5shows the average computational time of each component for the six methods. Both LS and SA took 90 s, on average, to compute an instance. Incorporation of the RR component increased the average computational time by about 40seconds. Given that this component also brought about an improvement in solution quality, this additional 40seconds well worth the slightly longer computing time.Furthermore, we also investigated the performance of the LS component by allowing it to compete with the solutions achieved by ILS and GRASP-ELS. The comparison results are presented in Table 7. Table 8compares the performance of FSA and SSA with our SA component. The columns headed AG (%) give the average percentage gap from the BKS, and those headed columns AT (seconds) show the average computational time in CPU seconds. The computational time of an approach was adjusted according to its computer’s speed. In Table 7, the solution quality achieved by LS is much better than ILS, but our method takes longer computational time. Compared to GRASP-ELS, LS performs worse. With the efforts from the RR component, LS+RR is able to achieve better solutions in average than GRASP-ELS.The approaches in Table 8 all apply the simulated annealing technique. From the comparisons in this table, our SA method achieves better solutions on the instance sets “Cordeau 1–10” and “Cordeau 11–20” with a similar amount of computational time. On instance sets “Solomon 100” and “Solomon 200”, SSA outperforms our SA method. The RR component recombines the routes from the SA solution and produces high-quality solutions. As a result, SA+RR outperforms the other three approaches in Table 8 in terms of overall performance.These experiments show that the RR component plays a key role in our approach. Integrating the RR component strengthens our approach considerably. In addition, the average computational time spent on the RR component is less than that for either the LS component or SA component.In this subsection, we compare the results of the I3CH with those of the ACO, ILS, VNS, GRASP-ELS, SSA and GVNS on all TOPTW instances in the “INST-M” and “OPT”. The I3CH was configured with determined parameter settings:Ph=0.1andPl=0.3for the neighborhood operator;T0=0.1andα=0.995for SA;Spool=1000for RR; andImax=3000,N=50andIno_impr=20for the iterative framework. Observing that the average performance varied little by random seed, we selectedseed=3for the final run. All of the detailed solutions obtained by the I3CH are presented in the appendix.Table 9summarizes the results for the instances in “INST-M”. It compares the average performance of I3CH with that of the ACO, ILS, VNS, GRASP-ELS, SSA and GVNS. Thenumcolumn gives the number of instances in a set, and the AG (%) column reports the average percentage gap with the BKS. A negative percentage gap indicates an average improvement. The AT (seconds) column reports the average computational time in CPU seconds. The computational times of the approaches were adjusted according to computers’ speed, as discussed in Section 5.1. For the I3CH, we add additional column#Imprto show the number of new best solutions it found.We can see from Table 9 that, on average, the I3CH improved the solution quality of 10 out of the 16 instance sets. For the OPTW instances, the performance of I3CH is not good enough. This is because the RR component degenerates to pick the route with the highest profit whenm=1. In this case, I3CH is equivalent to LS+SA. The table also shows that our LS+SA is not as competitive as SSA or VNS. As m becomes larger, our dedicated approach, I3CH, becomes quite effective in solving the TOPTW instances. Overall, it outperforms the other five approaches by at least 0.41% in terms of average performance over all instances from “INST-M”. Further, its average computational time is 200 s, which is acceptable. The I3CH also discovered 35 new best solutions which are summarized in Table 10.I3CH was also tested on the instances in the “OPT” category. Table 11reports the overall comparisons with ILS, GRASP-ELS, SSA and GVNS. In this table, the overall performance of each approach is given by three columns. The columns#OPTshow the number of optimal solutions achieved. The columns AG (%) and the columns AT (seconds) give the average percentage gap from the optimal and the average computational time in CPU seconds respectively.Table 11 shows that the I3CH achieved the smallest average gap over each of the seven instance sets. The average percentage gap over all “OPT” instances achieved by the I3CH was 0.15%, a 0.24% improvement over the best exiting result. In addition, the approach obtained 55 optimal solutions, 16 more than the previous best approach in the literature. Columnnumshows that there are only 66 OPT instances in total. Overall, the I3CH outperformed the existing approaches on the “OPT” instances, although it required more computational time.On the whole, our I3CH approach is rather competitive. It discovered new best solutions and achieved the best average performance. Although our approach may at first glance appear less efficient than some of the other approaches, requiring more computational time, this is not actually the case. We conducted comparison experiments in which the I3CH was set to the same computational time as the other approaches which had been adjusted by their computers’ speed. These experiments were carried out on the “INST-M” instances, with our approached compared with the two best known approaches, GRASP-ELS and SSA. We examined the solution quality obtained by I3CH when the total execution time was set to the computational time required by GRASP-ELS and SSA. Table 12a and b summarize the comparison results.Table 12a shows the I3CH approach’s execution time to be the same as GRASP-ELS. It outperformed GRASP-ELS on 9 of the 16 instance sets. GRASP-ELS performed quite well on the OPTW instances, whereas our dedicated approach achieved better performance in solving the TOPTW instances. Overall, the I3CH achieved an average percentage gap of 1.08%, which is 0.21% less than that of GRASP-ELS. Similarly, we set the execution time for the I3CH to the computational time for SSA for each instance. In comparing their average performance on the instance sets, we found the I3CH to display better performance on 10 of the 16 instance sets, and to largely outperform SSA on the TOPTW instances. Its overall average performance is 0.33% better than that of SSA. Our experimental results thus indicate that the I3CH approach proposed herein is both effective and efficient, and is well-suited to the TOPTW.

@&#CONCLUSIONS@&#
In this paper, we study the TOPTW and we propose an iterative framework that incorporates three components. This framework employs a local search procedure and a simulated annealing procedure as the first two components to explore the solution space. By tracing the neighborhood exploration, they discover a set of routes which are then recombined by the third component to obtain a high quality solution. Embedded in an iterative framework, these three components cooperate and work as an effective heuristic. Our computational results indicate that the heuristic outperforms the existing approaches in the literature in terms of average performance. Our iterative three-component heuristic found 35 new best solutions and improved solution quality, on average, by 0.41% over the “INST-M” instances. It also achieved 55 optimal solutions over the 66 “OPT” instances, which is 16 more than the previous best approach in the literature. In addition, results indicate our approach is both efficient and effective. The new results we reported herein can serve as benchmarks for future studies.The algorithm we propose in this paper is highly effective. The framework is robust and can incorporate additional components. If the components were adapted to accommodate new constraints, it would also be applicable to other routing problems. One potential avenue for further research would be to extend our approach to a parallel version. Either classical parallel computing or recent popular GPU computing techniques would be promising candidates to speed up the solution process and improve solution quality.