@&#MAIN-TITLE@&#
Breast cancer detection and classification in digital mammography based on Non-Subsampled Contourlet Transform (NSCT) and Super Resolution

@&#HIGHLIGHTS@&#
We propose a new algorithm for breast cancer detection and classification.Our system can accurately detect the probability of benign or malign breast lesion.We utilize NSCT transform and super resolution to improve the quality of the images.The results on MIAS database show significant performance of the proposed method.Our system achieves 91.43% and 6.42% as a mean accuracy and FPR, respectively.

@&#KEYPHRASES@&#
Computer-Aided Diagnosis (CAD) system,Breast cancer,Mammography,Non-Subsampled Contourlet Transform (NSCT),Super Resolution (SR),BI-RADS,

@&#ABSTRACT@&#
Breast cancer is one of the most perilous diseases among women. Breast screening is a method of detecting breast cancer at a very early stage which can reduce the mortality rate. Mammography is a standard method for the early diagnosis of breast cancer. In this paper, a new algorithm is proposed for breast cancer detection and classification in digital mammography based on Non-Subsampled Contourlet Transform (NSCT) and Super Resolution (SR). The presented algorithm includes three main parts including pre-processing, feature extraction and classification. In the pre-processing stage, after determining the region of interest (ROI) by an automatic technique, the quality of image is improved using NSCT and SR algorithm. In the feature extraction part, several features of the image components are extracted and skewness of each feature is calculated. Finally, AdaBoost algorithm is used to classify and determine the probability of benign and malign disease. The obtained results on Mammographic Image Analysis Society (MIAS) database indicate the significant performance and superiority of the proposed method in comparison with the state of the art approaches. According to the obtained results, the proposed technique achieves 91.43% and 6.42% as a mean accuracy and FPR, respectively.

@&#INTRODUCTION@&#
Breast cancer is known as one of the important diseases in medical science in which its early detection can reduce mortality rate and improve the survival rate of the patients. Mammography is the only broadly accepted and used screening test for early breast cancer detection. Two cases of the most prevalent symptoms of breast cancer are masses and calcifications. Since some calcifications are very small and the density difference between the healthy tissue and masses may be very low, diagnosis process will be difficult. Therefore, considering the importance of the accurate diagnosis, computer-aided diagnosis (CAD) techniques were presented in recent years [1–11] to help physicians and also reduce False Positive Rate (FPR) to perform diagnosis action faster, more easily and more accurately.CAD systems generally include three main steps containing pre-processing, feature extraction and classification. In the pre-processing stage, regions of interest (ROIs) which contain suspicious regions are usually detected and localized. Then, the quality of mammographic images is improved. Several techniques have been proposed for pre-processing such as thresholding [12–14], region-based techniques [15–17] and edge detection techniques [18,19]. In the feature extraction stage, the features are extracted from mammographic images so that the system can correctly classify benign and malign lesions. Among the proposed feature extraction methods, Gabor Filter [20], Zernike Moments [21] and Wavelet Transform [22–29] are more popular than the others. In the classification as a final stage, suspicious regions are classified to two groups of benign or malign lesions. There are several methods for classification such as Artificial Neural Networks [2,14,20,27], Nearest Neighbor [30], Fuzzy [25,31] and Support Vector Machine (SVM) [3,7,13,15,30,32].Timp and Karssemeijer [1], developed CAD techniques to study interval changes between two consecutive mammographic screening rounds. They proposed methods for the detection of malignant masses based on the features extracted from single mammographic views. They focus on improving the detection by including temporal information in the CAD techniques. Zhang et al. [2], presented a method for developing a fully automated CAD system to help radiologist in detecting and diagnosing micro-calcifications. The purpose of this research is to increase the effectiveness and efficiency of the screening procedures and also extract and analyze the characteristics of vary lesions in an objective manner and then improving the diagnostic accuracy. They used automatic segmentation, feature extraction, suspicious area detection and neural network for classification in their CAD system. Tzikopoulos et al. [3], also presented a CAD system for a fully automated segmentation and classification based on breast density estimation and detection of asymmetry. They firstly utilized image pre-processing and segmentation techniques. Then, the features for breast density categorization are extracted, including a new fractal dimension features and finally SVM is employed for classification. In addition, Miranda and Felipe [4] proposed a method based on fuzzy logic to improve the representation of the features corresponding to the image description in order to make it semantically more consistent. Moreover, they developed a CAD system for automatic categorization of breast lesions. The state of the art CAD techniques for breast cancer detection and classification are summarized in Table 1.Among the mentioned approaches, Wavelet Transform is one of the well-known methods in this research field which in addition to extract the features, is able to determine breast lesions [22–29] due to correspondence of the lesions on high frequency components [33]. Despite various applications of Wavelet Transform in image processing task, this transform has limitation in capturing directional information in images such as smooth contours and the directional edges. Contourlet Transform (CT) which has been presented by Do and Vetterli [34] is a developed version of Discrete Wavelet Transform for solving these problems. Contourlet Transform has further properties such as directionality and anisotropy in addition to properties of Wavelet Transform. Although Contourlet Transform is more powerful technique than Wavelet Transform in image representation, is not shift-invariant due to down-sampling and up-sampling. Non-Subsampled Contourlet Transform (NSCT) was presented by Cunha et al. [35] for compensating this limitation. Due to the beneficial properties of this transform, in [36] we used NSCT for determining the breast lesions according to its properties to improve the quality of the breast images.In this paper, by developing our previous study [36], a new algorithm is proposed for breast cancer detection and classification. In the presented method, NSCT is utilized for improving the quality of the images after determining the regions of interest (ROIs), then, Super Resolution (SR) algorithm is used to increase the resolution of the images and a high-pass filter is also utilized to highlight the desired regions. Afterwards, several features are extracted from the image components and skewness of each feature is calculated. Finally, AdaBoost algorithm is employed to classify the extracted features.The main contributions of our proposed algorithm are summarized as follows:1.Improvement of mammographic images: in the proposed method, unlike the previous techniques which have used Wavelet Transform for determining edges of images, NSCT is utilized due to its powerful capability in image representation. Moreover, fuzzy learning-based SR algorithm is used to properly predict the high-frequency components and remove distortions in the proposed method.Categorization of breast lesion characteristics: The characteristics of calcifications and masses are categorized based on size, shape, scattering and density and also the severity of abnormality is determined based on appearing symptoms in different categories. This kind of categorization leads to better description for mammographic images and extracting the suitable features from them.Feature extraction: in the proposed method, in order to distinguish normal and abnormal tissues, seven features based on regional, boundary and density descriptors are extracted from the objects in mammographic images and each feature is analyzed by calculating skewness of each feature to decide if they are malign or benign.Effectiveness investigation for the proposed algorithm is conducted using the standard MIAS database [37]. The system performance is compared with the performances of some popular CAD systems. Experimental results indicate that the proposed method outperformed other state of the art algorithms from the aspect of all the different evaluation criteria.In the following, Section 2 presents the proposed algorithm and its subsections in details. In Section 3 the proposed method is evaluated and compared with some popular CAD systems. Finally, the paper concludes in Section 4.The proposed algorithm includes 3 main stages including pre-processing, feature extraction and classification. Fig. 1shows structure of the proposed method. The following subsections will present the proposed algorithm in details.To obtain desirable results and distinguish between benign and malign lesions, pre-processing is performed in the proposed technique in two stages containing regions of interest (ROIs) detection and the quality improvement of mammographic images.The first stage of our pre-processing method is to remove additional margins, which makes images smaller and finally reduces computational burden. On the other hand, as shown in Fig. 2, some features of masses and calcifications are very similar to regions of tissue such as pectoral muscle or similar to some artifacts such as label that include information of the patient in corner of the images. These regions should be removed for reducing false positive rate to obtain ROIs in mammographic images. For this purpose, all images are aligned to the left side to place pectoral muscle for all images on the left side and label on the right side. To remove pectoral muscle and label, thresholding method and erosion morphological operator are utilized so that firstly, the aligned image is binarized using a thresholding technique and the label is removed. After negating the binary image, the result is subtracted from the aligned image. Also, if there is salt and pepper noise, median filtering is utilized for removing the noise. Finally, pectoral muscle is removed by applying thresholding method and erosion morphological operators. All the steps of pre-processing are shown in Fig. 2.Improvement of mammographic images is necessary for highlighting masses and calcifications in tissue of breast, because it causes the edges and regions of the image to be effectively extracted and studied. Since edges of the image are superposed with high frequency components, a method should be used in frequency domain to achieve them. For this purpose, NSCT is utilized on the images and then SR algorithm is used for increasing resolution of the images. Finally, a high-pass filter is employed for sharpening and highlighting the desired regions.In Contourlet Transform, the Laplacian Pyramid (LP) is first used to capture point discontinuities, and then followed by a Directional Filter Bank (DFB) to link point discontinuities into linear structures [34]. The overall result is an image expansion using basic elements like contour segments, and thus called Contourlet Transform, which is implemented by a Pyramidal Directional Filter Bank (PDFB) [34]. The LP decomposition at each level generates a down-sampled low pass version of the original image, and the difference between the original image and the prediction results in a band pass image. Due to down-sampling and up-sampling presented in both LP and DFB, Contourlet Transform is not shift-invariant. So, to achieve the shift-invariance property, NSCT was proposed by Cunha et al. [35]. The NSCT is built upon Non-Subsampled Laplacian Pyramids (NSLP) (Fig. 3) and Non-Subsampled Directional Filter Bank (NSDFB) (Fig. 4) which is fully shift-invariant, multi-scale and multi-direction image decomposition.The goal of SR is to achieve a high resolution (HR) image based on one or a set of low resolution (LR) images. Since SR technique is a way of increasing resolution without altering the existing imaging hardware, it can be suitable for medical images [38]. The goal of SR algorithm is to improve resolution of the images which firstly include high-frequency components and secondly aliasing and degradation have occurred in the images with high-frequency components. Therefore, SR can increase sampling rate by utilizing information of the high-frequency components and also reducing aliasing effects caused by application of NSCT [38]. In general, the SR image techniques can be classified into four classes [39] containing frequency domain-based approaches, interpolation-based approaches, regularization-based approaches and learning-based approaches. In this research, SR technique based on learning algorithms has been used among the SR techniques because it is suitable for single image problems and is able to predict high-frequency components.In the proposed method, after determining ROIs, dimensions of the image is decreased by half of the main dimensions due to largeness of the mammographic images and its high computational rate (Fig. 5(b)). Then, three-level NSCT decomposition is used and then, two sub-bands in the first level, four sub-bands in the second level, eight sub-bands in the third level and one low-pass sub-band which has low-frequency components are obtained. Among the obtained sub-bands, only sub-bands with high-frequency components are used. To achieve edges of the images, “prewitt” edge detector is used on each sub-bands and to obtain stronger edges of the images, the standard deviation of each sub-bands are calculated and utilized as a threshold in “prewitt” edge detector. After finding the edges in each sub-bands, a weight is given to some regions of sub-bands which include edges to highlight the mentioned edges. Then, the image is reconstructed after making changes in its high-frequency sub-bands. Results of this section can be found in Fig. 5(c). In the proposed method, after reconstruction of the image, to improve its quality and also increase its resolution, SR algorithm is used based on fuzzy learning algorithm [40] (Fig. 5(d)). All the steps of fuzzy learning algorithm are summarized in Algorithm 1. Finally, a high-pass filter is used for sharpening and highlighting the desired regions. The final improved image is shown in Fig. 5(e). It should be mentioned that the presented values for two parameters involved in Algorithm 1 (i.e., [3,3] for the window size and 0.8 for the standard deviation) are the tuned values which are stated in [40]. Since these values make our proposed method obtained its maximum performance, so, in our experiments, we also choose [3,3] as the window size and 0.8 as the standard deviation.Algorithm 1Super resolution algorithm based on fuzzy learning.Fuzzy Learning SR (ImprovedImageNSCT)1. Offline phase: generate a rule base system and tune the parameters of the system to have the better performing learned system.1.1 Collect the HR sharp images from “flickr” database.1.2 Generate LR versions corresponding to each of these HR images:a. BluredImage=GaussianFilter (HR, [3,3], 0.8).% [3,3] is window size for Gaussian filter and 0.8 is standard deviation.b. ResizedImage=DownSampling (BluredImage).c. LR=UpSampling (ResizedImage, bicubic).% bicubic is text string specifying interpolation method[End of step 1.2.]1.3 Divide the HR and LR images into overlapping patches of size (n×n).1.4 Normalized each patch.1.5 Concatenated LR and HR patch pairs: x*=(x;y).% x: feature patches in LR image and y: feature patches in HR image.% x*: comprising LR and HR feature patch pair.[End of the step 1.]2. Online phase: apply trained rule based system on the patches of LR image to have a HR version of LR ones.2.1. clusteredPatch=K-means (x*, c). % c: number of cluster.2.2. Analyzed clusteredPatch to extract fuzzy rules.2.3. Find the optimal membership functions using Expectation Maximization.2.4. LRTestPatches=Entry the LR test sample and extract feature from its overlapping patches.2.5. Repeat stage 2.2 and 2.3 for LRTestPatches.2.6. [selective patch processing]a. RoughnessPatches=Variance (LRTestPatches).b.IfRoughnessPatches is highThe LRTestPatches belongs to texture region.elseThe LRTestPatches belongs to smooth region.[End ofIfstructure.]c. Set a judiciously threshold to choose the texture or smooth regions for the LRTestPatches.i. 30% of all LRTestPatches belong to texture region so using SR based on fuzzy rule.ii. 70% of all LRTestPatches belong to smooth region so using SR based on bicubic interpolation.[End of step 2.6.]2.7. Generate HR version.[End of the step 2.][End of Fuzzy Learning SR]In the feature extraction stage, it is necessary to extract the information from mammographic images so that the system can correctly distinguish normal and abnormal tissues. Indeed, using variety information causes obtaining high dimensionality feature matrix that reduce accuracy and increase computation burden. So, taking apart some unhelpful information can lead to the better description from mammographic images and increase the accuracy. Hence, the characteristics are categorized based on size, shape, scattering and density. In this research, the characteristics of calcification and masses which are categorized in Tables 2 and 3have been provided based on two main Refs. [41,42] and also the knowledge of radiologist expert. It should be noted that there are not certain size and shape of masses.Since masses and calcifications have higher density than other tissues of the breast and are brighter than them, the histogram of the improved images is obtained and the highest value between the values that are bigger than 200 is selected. The selected value is a desired threshold value in the proposed method to produce binary images including masses and calcifications (Fig. 6). It should be mentioned that, to find the proper interval which the desired threshold value can be found in it, different intervals have been examined and finally the values that are bigger than 200 is empirically selected. After producing the binary images, the regions available in the images are labeled and objects of the images are obtained. At the end, features are extracted from objects of the images. Due to high importance of shape of the lesions in determination of benign or malign probability, the features which extract and study shape of the lesions are mostly used in this paper as a shape analysis. These features include Area [43,44], Compactness [43,44], Fractal [44], Central Moment [43], Eccentricity [43] and Spread [43]. In addition, another feature as an average gray level is extracted which can be described the density of objects.Shape analysis groups features by major categories; regional and boundary descriptors. The regional descriptors describe the object as a region and hence describe the morphology and include size measurements. Boundary descriptors describe the shape and the contour of an object [43]. Area, Compactness and Fractal are regional descriptors while Eccentricity, Central Moment and Spread that are moment-based features are boundary descriptors. Average gray level as final extracted feature describes the density of objects.Area of an object is the most trivial shape parameter that can be computed from a detected object on an image. It can be defined as the number of pixels contained within (and including) the boundary of a segmented object of interest. It is the most basic shape parameter but offers a suitable descriptor for describing the size of the objects available in the image.Compactness is a dimensionless quantity which provides a simple measure for complex counters. It is independent of translation, rotation and scale. It is one of the most common features used in pattern recognition and classification techniques. Compactness can be defined in a variety of ways and its definition may affect classification which has been elaborated elsewhere. In this research, the definition of Compactness that produced the lowest classification error for this application is chosen which is defined as Eq. (1):(1)C=P24πAwhere, P is perimeter and A is the area of the objects. According to this definition, a circle is theoretically the most compact object with the smallest C1. Elongated objects have a value of C>1. So, a larger value of this feature describes an irregular and elongated object while a smaller value is representative of a more symmetric and regular object.The perimeter of the object is measured using increasingly larger ‘rulers’. As the ruler size increases, decreasing the precision of the measurement, the observed perimeter decreases. As Fig. 7indicates, plotting these to values on a log scale and measuring the downward slope gives an approximation to the fractal dimension. As with all the shape features, a higher value corresponds to a less regular contour and so to a higher probability of malignancy [44].Micro calcifications are also small light local anomaly points which represent sharp local changes in contrast of the image from the fractal standpoint and rare events in global sense [45]. It should be noted that, the Hausdorff-Besicovitch and Box-Counting methods are used for fractal dimension [46]. The Hausdorff-Besicovitch and Box-Counting techniques can be expressed by the Eqs. (2) and (3) respectively:(2)FD=logNlog(L/U)(3)FD=limn→∞(log(Nn+1(U))−log(Nn(U)))log(1/(Un+1))−log(1/(Un))where, FD is the fractal dimension, N is the number of parts in each iteration and L is the initial length of the object U and the length of each segment. It should be noted that, Box-Counting technique is used in the proposed method.The theory of moments gives a number of useful and practical shape descriptors which can obtain some information about roughness of the shapes and can be used to distinguish between the different shape categories of calcifications. The central moment of order k of a real-valued random variable X is defined as Eq. (4):(4)mk=E[(X−E(X))k]where, E denotes the expectation operator. Since higher order moments are very sensitive to noise [43], k is set to 4. The range of values for this feature is also between 0 and 1. If this value is larger and close to 1, irregularity in the shapes will occur more.It measures the degree in which an object mass is concentrated along a particular axis. This feature is defined as Eq. (5):(5)ε=(m2,0−m0,2)2+4m1,12(m2,0+m0,2)2where, mpqis the moment of order p+q for an image f(x,y) and is defined as Eq. (6):(6)mpq=∑x∑yxpyqf(x,y)It should be noted that, the range of values for this feature is between 0 and 1. The closer value to 0 will give circular objects and the closer value to 1 will give linear objects.It measures how unevenly objects are distributed about their centroid and it is based on the central moments of the boundary pixels. This feature is also defined as Eq. (7):(7)S=μo,2+μ2,0where, μpqis the central moment of order p+q for an image f(x,y) and is defined as Eq. (8):(8)μpq=∑x∑y(x−x¯)p(y−y¯)qf(x,y)where,x¯=m10/m00andy¯=m01/m00are also the centroid coordinates of the image.The range of values for this feature is also obtained between 0 and 1. Also, a lower value represents a circular object while a large value defines a linear and non-uniform object.Since masses and calcifications are brighter than the background, therefore, average values of pixels of the image objects can be applied as a suitable feature.Considering the introduced features and their definition, skewness (SK) of each feature is calculated as Eq. (9):(9)SK=E(x−μ)3σ3where, x is a feature and μ and σ are the mean and the standard deviation of x, respectively. Also, E denotes the expectation operator. Skewness is a measure of the asymmetry of the data on which basis can find roughness or smoothness, regularity or irregularity, symmetry or asymmetry, circularity or linearity and brightness of the objects of the image and decide if they are malign or benign. Therefore, feature vector will be obtained for each image as Eq. (10):(10)F=[SK(A)SK(C)SK(F)SK(M)SK(E)SK(S)SK(S)SK(AGL)]In this paper, AdaBoost [47] is used for classification of the extracted features. American college of radiology (ACR) [48] classifies mammographic images using BI-RADS in 6 general categories considering breast lesions:•BI-RADS 0: Evaluation is not completeBI-RADS I: NormalBI-RADS II: Benign findingBI-RADS III: Probably BenignBI-RADS IV: Suspicious findingBI-RADS V: Highly SuspiciousHowever, in the proposed method, based on the available information of the existing database, we classify the mammographic images in 3 general categories including: normal (BI-RADS I), benign (BI-RADS II, III) and malign (BI-RADS IV, V) which findings in BI-RADS III have a very high chance of being benign while findings in BI-RADS V look like cancer and have a high chance of being cancer. BI-RADS for number of the images in MIAS database [37] are shown in Table 4. The mentioned original images in Table 4 are shown in Appendix.

@&#CONCLUSIONS@&#
