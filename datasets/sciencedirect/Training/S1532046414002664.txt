@&#MAIN-TITLE@&#
Evaluating semantic similarity and relatedness over the semantic grouping of clinical term pairs

@&#HIGHLIGHTS@&#
Objective: develop a method to quantify the similarity and relatedness of biomedical and clinical term pairs.Semantic similarity and relatedness measures exploit information extrapolated from the Unified Medical Language System.Evaluates the performance of similarity and relatedness measures over term pairs from various semantic groups.Evaluates combining semantic similarity and relatedness measures.

@&#KEYPHRASES@&#
Natural language processing,NLP,Semantic similarity,Semantic relatedness,

@&#ABSTRACT@&#
IntroductionThis article explores how measures of semantic similarity and relatedness are impacted by the semantic groups to which the concepts they are measuring belong. Our goal is to determine if there are distinctions between homogeneous comparisons (where both concepts belong to the same group) and heterogeneous ones (where the concepts are in different groups). Our hypothesis is that the similarity measures will be significantly affected since they rely on hierarchical is-a relations, whereas relatedness measures should be less impacted since they utilize a wider range of relations. In addition, we also evaluate the effect of combining different measures of similarity and relatedness. Our hypothesis is that these combined measures will more closely correlate with human judgment, since they better reflect the rich variety of information humans use when assessing similarity and relatedness.MethodWe evaluate our method on four reference standards. Three of the reference standards were annotated by human judges for relatedness and one was annotated for similarity.ResultsWe found significant differences in the correlation of semantic similarity and relatedness measures with human judgment, depending on which semantic groups were involved. We also found that combining a definition based relatedness measure with an information content similarity measure resulted in significant improvements in correlation over individual measures.AvailabilityThe semantic similarity and relatedness package is an open source program available from http://umls-similarity.sourceforge.net/. The reference standards are available at http://www.people.vcu.edu/∼{}btmcinnes/downloads.html.

@&#INTRODUCTION@&#
Semantic similarity and relatedness measures quantify the degree to which two concepts are similar (e.g., liver-organ) or related (e.g., headache- aspirin). Relatedness encompasses many kinds of relations, but generally shows how associated two concepts are with each other. For example, a headache can be treated with aspirin. Similarity is a specific relation that is a subset of relatedness, and is based on the degree to which two concepts are connected through hierarchical is-a relations. For example, organ could be an ancestor of liver in an is-a hierarchy, and would therefore have a high similarity score. Headache and aspirin, on the other hand, are not closely connected by any is-a relations, and so would have a low similarity score. However, since they may be connected by other kinds of relations (e.g., treated by) they could have a very high relatedness score.The automated discovery of groups of semantically similar or related concepts and terms is critical to improving the retrieval [1] and clustering [2] of biomedical and clinical documents, and the development of biomedical terminologies and ontologies [3]. As such, a number of different similarity measures have been developed for the biomedical domain. These have been evaluated intrinsically via comparisons to various human reference standards [4,5], as well as extrinsically depending on how well they contribute to the performance of secondary applications [6,7]. However, to date there has been little work that considers the type of concept being evaluated. Our objective is to evaluate how measures of similarity and relatedness perform depending on the semantic groups of the concepts involved.Similarity measures find paths between concepts in an is-a hierarchy. Concept pairs from different semantic groups may well be in different hierarchies and therefore not be connected by is-a relations. In addition, these different hierarchies may have different levels of granularity and coverage. Given these considerations, our hypothesis is that there will be a large degree of change in the correlation of similarity measures with human reference standards when the concepts in a pair are from different semantic groups. Our results support this hypothesis. We found that no single measure performed best over all the different semantic group pairs.In this work, we also combined measures based on the hypothesis that measures of similarity and relatedness will be complementary, and may result in more robust measures that more closely correlate with human judgments. Our goal is to identify pairs of measures that provide complementary information that will improve our ability to quantify the degree of similarity and relatedness between two terms. Bill et al. [8] showed that a linear combination of the similarity measures proposed by Resnik [9] and Lin [10] increased the accuracy of identifying similar terms. The results, here in this paper, show that combining relatedness and similarity measures improved correlation scores overall. However, these results varied depending on the reference standard used and so no single pair of measures was found to always improve correlation.This article is organized as follows. Section 2 provides an overview of the Unified Medical Language System (UMLS), which is our main source of data on concepts and their relations. Section 3 reviews the measures of semantic similarity and relatedness used in this study. Section 4 describes resources used beyond the UMLS for formulating some of the measures. The reference standards used in our evaluation are introduced in Section 5, and the details of our experiments on these standards are summarized in Section 6. Our results are presented in Section 7, and the article closes with our conclusions in Section 8.The UMLS is a data warehouse containing three knowledge sources: the Metathesaurus, the Semantic Network and the SPECIALIST Lexicon. The Metathesaurus contains approximately 2 million biomedical and clinical concepts from over 100 different terminologies that have been semi-automatically integrated into a single source. One such source is the Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT), which is a comprehensive clinical terminology created for the electronic representation of clinical health information. The concepts in SNOMED CT are organized in a hierarchical structure in order to permit searching at various levels of specificity. The concepts are connected by two main types of hierarchical relations: parent/child (PAR/CHD) and broader/narrower (RB/RN). The PAR/CHD relations are strictly is-a relations while the RB/RN relations contain part-of relations.The Semantic Network consists of a set of broad subject categories called semantic types in which each concept in the Metathesaurus is assigned one or more semantic type. For example, the semantic type of C0206250 [Autonomic nerve] is Body Part, Organ, or Organ Component. Currently, there exist 135 semantic types in the Semantic Network.The SPECIALIST Lexicon contains terms that are used in the biomedical and health-related domain along with linguistic information such as spelling variants.Included in the UMLS is also a categorization of semantic types referred to as semantic groups. A semantic group is a coarse grained grouping of the semantic types in the UMLS developed by [11] to provide a coarse-grained distinction between UMLS concepts based on their semantic validity, parsimony, completeness, exclusivity, naturalness, and utility. Examples of semantic groups include: Anatomy, Phenomena, Disorders and Chemicals & Drugs. There currently exists 15 semantic groups.1http://semanticnetwork.nlm.nih.gov/SemGroups/.1Each CUI in the UMLS can be categorized by their semantic group.This section describes the similarity and relatedness measures used in this work.We classify the similarity measures into two broad categories: path-based and information content (IC)-based. The path-based similarity measures provide information about the co-location of the terms in a taxonomy. The IC measures use the taxonomy information but also include additional information about the concept with respect to its relationship with the other concepts. There are two methods used to calculate IC: corpus-based which uses the probability of the concept occurring in an external corpus, and intrinsic-based which uses the informativeness of a concept based on its placement within the taxonomy. The remainder of this subsection describes the various measures and how they are calculated.Rada et al. [1] introduce the Conceptual Distance measure, which is the length of the shortest path between two concepts (c1andc2) in MeSH using RB/RN relations. Caviedes and Cimino [12] later evaluated this measure using the PAR/CHD relations. The path measure is a modification of this and is calculated as the reciprocal of the length of the shortest path as defined in Eq. (1).(1)simpath=1spath(c1,c2)Wu and Palmer [13] extend this measure by incorporating the depth of the Least Common Subsumer (LCS). The LCS is the most specific ancestor two concepts share. In this measure, the similarity is twice the depth of the two concepts’ LCS divided by the product of the depths of the individual concepts as defined in Eq. (2).(2)simwup=2∗depth(lcs(c1,c2))depth(c1)+depth(c2)Leacock and Chodorow [14] extend the path measure by incorporating the depth of the taxonomy. Here, the similarity is the negative log of the shortest path (spath) between two concepts divided by twice the total depth of the taxonomy (D) as defined in Eq. (3).(3)simlch=-logspath(c1,c2)2∗DInformation content (IC) is formally defined as the negative log of the probability of a concept. Resnik [9] modified IC to be used as a similarity measure. He defined the similarity of two concepts to be the IC of their LCS as shown in Eq. (4).(4)simres=IC(lcs(c1,c2))=-log(P(lcs(c1,c2)))Jiang and Conrath [15] and Lin [10] extended Resnik’s IC measure by incorporating the IC of the individual concepts. Lin defined the similarity between two concepts by taking the quotient between twice the IC of the concepts’ LCS and the sum of the IC of the two concepts as shown in Eq. (5). This is similar to the measure proposed by Wu & Palmer; differing in the use of IC rather than the depth of the concepts.(5)simlin=2∗IC(lcs(c1,c2))IC(c1)+IC(c2)Jiang and Conrath defined the distance between two concepts to be the sum of the IC of the two concepts minus twice the IC of the concepts’ LCS. We modify this measure to return a similarity score by taking the reciprocal of the distance as shown in Eq. (6).(6)simjcn=1IC(c1)+IC(c2)-2∗IC(lcs(c1,c2))The information content of a concept can be calculated using information derived from a corpus (corpus-based) or information derived from a taxonomy (intrinsic-based). In this section, we describe both techniques.As previously stated, IC is defined as the negative log of the probability of a concept. For corpus IC, we calculate the probability of a concept, c, by summing the probability of the concept,P(c), occurring in some text plus the probability its descendants,P(d), occurring in the same text as seen in Eq. (7).(7)P(c∗)=P(c)+∑d∈descendant(c)P(d)The initial probability of a concept,P(c), and its descendants,P(d), is obtained by dividing the number of times a concept is seen in the corpus,freq(d), by the total number of concepts, N, in the corpus as seen in Eq. (8).(8)P(d)=freq(d)/NThe challenge with probability calculations for concepts is that a large number of annotations are required in order to provide sufficient coverage of the underlying taxonomy to achieve reasonable estimates. Intrinsic IC seeks to alleviate this problem while still capturing the generality and concreteness of a concept. It assess the informativeness of concept based on its placement within the hierarchy by looking at its incoming (ancestors) and outgoing (descendant) links.In this work, we use the intrinsic IC calculation proposed by Sanchez et al. [16] defined in Eq. (9).(9)IC(c)=-log|leaves(c)||subsumers(c)|+1max_leaves+1where leaves are the number of descendants of concept c that are leaf nodes, subsumers are the number of concept c’s ancestors andmax_leavesare the total number of leaf nodes in the taxonomy.Lesk [17] introduces a measure that determines the relatedness between two concepts by counting the number of overlaps between their two definitions. An overlap is the longest sequence of one or more consecutive terms that occur in both definitions. When implementing this measure in WordNet, Banerjee and Pedersen [18] found that the definitions were short, and did not contain enough overlaps to distinguish between multiple concepts, therefore, they extended this measure by including the definitions of the related concepts.Patwardhan and Pedersen [19] extend this measure using second-order co-occurrence vectors. In this method, a vector is created for each word in the concept’s definition containing terms that co-occur with it in a corpus. These word vectors are averaged to create a single co-occurrence vector for the concept. The similarity between the concepts is calculated by taking the cosine between the concepts’ second-order vectors. Liu et al. [5] modify and extend this measure to be used to quantify the relatedness between biomedical and clinical terms in the UMLS.This section describes the data sources used in formulating the information content and vector measures. These sources are not a part of the UMLS and so are discussed here separately.The IC similarity measure data is used to calculate the probability of a concept occurring in a corpus. We use the UMLSonMedline dataset created by NLM which consists of concepts from the 2009AB UMLS and the number of times they occurred in a snapshot of Medline taken on 12 January, 2009. The frequency counts were obtained by using the Essie Search Engine proposed by Ide et al. [20] which queried Medline with normalized strings from the 2009AB MRCONSO table in the UMLS. The frequency of a CUI was obtained by aggregating the frequency counts of the terms associated with the CUI to provide a rough estimate of its frequency. The IC measures use this information to calculate the probability of a concept.The relatedness measure data is used by the vector measure to build the second-order co-occurrence matrix. We use the vector matrices, developed by Liu et al. [5], that are included in the UMLS::Similarity package. These matrices were created using the inpatient clinical reports that were collected from 2003 to 2008 at Fairview Health Services. These semi-structured reports consist of admission history, physical operation, discharge summaries, and consultation notes. These reports contain on average 500 words; after pre-processing (e.g. removal of stop words, numerals and punctuation), each note contained approximately 300 words. The total size of the resulting reports consisted of approximately 208.7 million words.We use four reference standards2http://www.people.vcu.edu/∼btmcinnes/downloads.html.2to evaluate the semantic similarity and relatedness measures: the UMNSRS tagged for similarity, the UMNSRS tagged for relatedness, the MayoSRS tagged for relatedness and the MiniMayoSRS tagged for relatedness. In this section, we describe the reference standards and then briefly discuss some of their differences.MayoSRS, developed by Pakhomov et al. [21], consists of 101 clinical term pairs whose relatedness was determined by nine medical coders and three physicians from the Mayo Clinic. The relatedness of each term pair was assessed based on a four point scale: (4.0) practically synonymous, (3.0) related, (2.0) marginally related and (1.0) unrelated. We evaluate our method on the mean score of the physicians and medical coders as provided by Pakhomov et al. [21].MiniMayoSRS is a subset of the MayoSRS and consists of 30 term pairs on which a higher inter-annotator agreement was achieved. The average correlation between physicians is 0.68. The average correlation between medical coders is 0.78. We evaluate our method on the mean of the physician scores and the mean of the coders’ scores in this subset in the same manner as reported by Pedersen et al. [22].UMNSRS, developed by Pakhomov et al. [23], consists of 725 clinical term pairs whose semantic similarity and relatedness was determined independently by four medical residents from the University of Minnesota Medical School. The similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch a bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness. The Intraclass Correlation Coefficient (ICC) for the reference standard tagged for similarity was 0.47, and 0.50 for relatedness. Therefore, as suggested by Pakhomov and colleagues,we use a subset of the ratings consisting of 401 pairs for the similarity set and 430 pairs for the relatedness set which each have an ICC equal to 0.73.As stated in Section 2, a semantic group is a coarse grained grouping of the semantic types. Each CUI in the UMLS can be categorized by their semantic group. Table 1shows a breakdown of the semantic groups for the concepts in each of the reference standards.We conducted our experiments using the freely available open source software package UMLS::Similarity [24] version 1.13.3http://search.cpan.org/dist/UMLS-Similarity/.3This package takes as input two terms or concepts and returns the similarity between any two concepts using the path information in any of the sources available in the UMLS, including SNOMED CT, for each of the measures discussed in Section 3.These experiments were conducted using the 2013AB version of the UMLS. We use the SNOMED CT taxonomy located in the UMLS Metathesaurus for the similarity measures and the entire UMLS (Level 1+SNOMED CT) for the relatedness measures. Correlation between the results of the similarity measures and human judgments were conducted using Spearman’s Rank Correlation (ρ). Spearman’s measures the statistical dependence between two variables to assess how well the relationship between the rankings of the variables can be described using a monotonic function. We used Fisher’s r-to-z transformation [25] to calculate the significance between the correlation results.As previously stated, the goal of combining the measures is to capitalize on each of the measures strengths in hopes that their combination provides complementary information for quantifying the degree of similarity/relatedness between the two terms. The path-based similarity measures provide information about the co-location of the terms in a taxonomy; the intrinsic IC measures provide information about the concept in relation to the other concepts in the taxonomy; the corpus IC measures provide probability information regarding its occurrence in an external corpus; and relatedness measures provide contextual information about the term. We combined the similarity and relatedness measure by first standardizing the individual scores to place them on the same scale and then averaging the standardized scores. We standardize the scores by subtracting the score by the sample mean and then dividing it by the standard deviation as shown in Eq. (10) wherescore‾is the mean andstddev(score)is the standard deviation.(10)standardized(score)=score-score‾stddev(score)

@&#CONCLUSIONS@&#
In this paper, we analyzed the correlation of semantic similarity and relatedness measures to human judgments over various semantic groupings of the term pairs. The results show that no one measure performed best over all of the semantic grouping pairs analyzed in this article. The results also indicated that using similarity measures on term pairs across disparate semantic groupings does not result in high correlation because there is little taxonomy information connecting them; relatedness measures are a better choice for these term pairs. In the future, we would like to analyze additional semantic groupings in order to determine if this is the case across all semantic groups.We also analyzed the results of combining various measures to determine if they are complementary. The results showed that combining relatedness and similarity measures improved the correlation scores; specifically we found that using lesk and the i-jcn measure obtained the highest overall correlation over the datasets; although vector with lch or i-jcn also performed well. In the future, we plan to explore and develop additional measures that incorporate aspects of semantic similarity and relatedness measures into a single measure.In the future, we also plan to evaluate what constitutes a high correlation and at what level do the measures need to correlate with human judgments to be practically useful. In an intrinsic evaluation, such as this study, it is difficult to pick out a particular correlation level and say ‘this is good enough’. Therefore, we plan to conduct an extrinsic evaluation by analyzing the measures with respect to their correlation in a secondary application.