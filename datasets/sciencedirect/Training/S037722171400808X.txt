@&#MAIN-TITLE@&#
A bidirectional building approach for the 2D constrained guillotine knapsack packing problem

@&#HIGHLIGHTS@&#
We combine two well-known methods into a coherent algorithm.We place a block instead of a single rectangle in each step.We divide the input sheet into successively smaller sheets at each step.We outperform all existing approaches on standard benchmark instances.

@&#KEYPHRASES@&#
Cutting and packing,Guillotine-cut,2D knapsack,Block-building,

@&#ABSTRACT@&#
This paper investigates the 2D guillotine knapsack packing problem, in which the objective is to select and cut a set of rectangles from a sheet with fixed size and maximize the total profit of the selected rectangles. The orientation of the rectangles is fixed. And the guillotine cut, in which the cut must be parallel to the sides of the sheet to divide it into two completely separated sheets, is required. Two well-known methods, namely the top-down and bottom-up approaches, are combined into a coherent algorithm to address this problem. Computational experiments on benchmark test sets show that the approach finds the optimal solution for almost all moderately sized instances and outperforms all existing approaches for larger instances.

@&#INTRODUCTION@&#
The 2D knapsack packing problem (2DKP) is a fundamental problem in the cutting and packing literature. It starts with a rectangular sheet of width W and height H, and m types of rectangles with dimensions wi× hi, i = 1, …, m. There are uipieces of rectangle of type i with a profit pifor each piece. Thus, the total number of available rectangles isn=∑i=1mui. The objective is to select and orthogonally pack a set of rectangles into the sheet and maximize the total profit of the packed rectangles. In addition, the size of the sheet and the input rectangles are assumed to be both integer, and the orientation of each rectangle is fixed. A guillotine cut is required in many cutting applications, in which the cut must be parallel to the sides of the sheet to divide it into two completely separated sheets. Given a packing pattern, it is called a guillotine pattern if all the rectangles can be cut off the sheet using a series of guillotine cuts. The 2D knapsack packing problem with the guillotine-cut constraint is called the 2D guillotine knapsack packing problem (2DGKP), which can be referred as 2D guillotine single large object placement problem (SLOPP) according the typology of Wäscher et al. (2007).Following the classification of Fayard et al. (1998), four versions of 2DGKP can be distinguished based on the properties of the available number of each type of rectangle and its associated profit:•The unconstrained unweighted version (UU-2DGKP): For each rectangle i, the number available uiis unlimited (i.e., uiis equal to ⌊W/wi⌋ × ⌊H/hi⌋, the maximum number of piece i that could be packed into the sheet) and the profit piis equal to its area wi× hi. The objective is to maximize the total occupied area, which is equivalent to minimizing the waste.The unconstrained weighted version (UW-2DGKP): For each rectangle i, the available number uiis unlimited and the profit piis independent of its area. The objective is to maximize the total profit of the packed rectangles.The constrained unweighted version (CU-2DGKP): For each rectangle i, the available number uiis limited (i.e., at least some uiare strictly lower than ⌊W/wi⌋ × ⌊H/hi⌋) and the profit piis equal to its area.The constrained weighted version (CW-2DGKP): For each rectangle i, the available number uiis limited and the profit piis independent of its area.In this paper, the constrained case C*-2DGKP including CU-2DGKP and CW-2DGKP is studied.Two general techniques have been widely used to find an exact solution to solve the C*-2DGKP problem: the top-down and the bottom-up approach. The top-down approach generates all feasible packing patterns by repeatedly cutting a sheet into two smaller sheets. Christofides and Whitlock (1977) introduced the first top-down approach, in which all possible packing patterns are enumerated by a tree search. In the search tree, the branches correspond to all possible cuts on some sheet. Christofides and Hadjiconstantinou (1995) presented an improved tree-search algorithm that limits the size of the tree search by using a tighter upper bound for each node. Hifi and Zissimopoulos (1997) presented an improved version based on new high-quality lower and upper bounds for each internal node.The bottom-up approach generates all the feasible cutting patterns by combining two patterns horizontally or vertically. Wang (1983) first proposed the bottom-up concept, based on which improved versions were presented by Vasko (1989),Oliveira and Ferreira (1990) and Amaral and Wright (2001); Daza et al. (1995) suggested a generalization of these methods. Viswanathan and Bagchi (1993) developed a best-first branch-and-bound algorithm based on the bottom-up concept. Hifi (1997) improved this method by using tighter lower and upper bounds. Cung et al. (2000) improved its efficiency further by enhancing the initial lower bound and the upper bound at each internal node and suppressing certain types of redundant symmetrical patterns. Recently, Vasko and Bartkowski (2009) used the bottom-up approach to optimally solve some difficult instances. de Armas et al. (2012) presented a set of dominance/duplication rules to reduce the solution search space of the best-first algorithm and combined the rules with parallel approaches for best-first search methods. Yoon et al. (2013) presented an improved best-first branch-and-bound algorithm and obtained the best results for the C*-2DGKP. Dolatabadi et al. (2012) presented a recursive exact procedure, which can also be regarded as a bottom-up approach.Besides the exact approaches, a few heuristic algorithms have been introduced to solve the 2DGKP. Fayard et al. (1998) presented an efficient heuristic method for approximately solving 2DGKP. Alvarez-Valdés et al. (2002) developed several heuristic algorithms including a greedy randomized adaptive search procedure (GRASP) and a tabu search algorithm. Hifi (2004) proposed a hybrid approach that combines a depth-first search using hill-climbing strategies and dynamic programming techniques. Recently, Morabito and Pureza (2010) presented a heuristic approach based on dynamic programming and an and/or-graph search. Chen (2008) developed a recursive algorithm and Bortfeldt and Winter (2009) presented a genetic algorithm. Cui and Chen (2012) presented a simple recursive heuristic. He et al. (2012) proposed a deterministic heuristic for the two-dimensional rectangular packing problem to maximize the filling rate of a rectangular sheet.Many researchers have used the bottom-up approach to solve the C*-2DGKP. The bottom-up approach can be easily combined with the best-fit branch and bound algorithm, and a well-designed upper bound for each node can reduce the search space dramatically. Since the seminal paper by Wang (1983), most papers based on the bottom-up approach have focused on the enhancement of the upper bound and the technique of neglecting unnecessary duplicated patterns. The drawback of the bottom-up approach is that it tends to need a lot of memory to store the packing pattern generated in the process. The number of feasible packing patterns also grows exponentially as the number of rectangles increases; hence, it is generally impractical to use the bottom-up approach to solve larger sized instances. The best-known bottom-up approach, by Yoon et al. (2013), can only solve moderately sized instances.To overcome the drawback of the bottom-up approach, we combine the top-down and bottom-up approaches into a coherent algorithm for the C*-2DGKP case. Similar to the bottom-up approach, the rectangles are first arranged into blocks, in which a block is a set of rectangles enclosed by its minimum bounding rectangle. Only a limited number of blocks that are likely to be part of high-quality solutions are generated. The packing process is carried out in a top-down fashion. Starting with the input sheet and the list of blocks; it first selects a block and places it in a corner of the sheet. The un-occupied region is then divided into two smaller sheets. At each subsequent step, it selects a smaller sheet and repeats the packing process until all remaining sheets are too small to accommodate any rectangles.Using blocks instead of rectangles, it can pack the sheet in far fewer steps, which essentially compresses the height of the search tree. Such compression dramatically reduces the size of the search tree, which grows exponentially as the height of the search tree increases. As Zhu et al. (2012) demonstrated, although using blocks reduces the number of nodes in a search tree, it does not reduce the search space associated with a problem instance. Recent algorithms for 3D rectangular packing problems (Fanslau and Bortfeldt, 2010; Wei et al., 2012; Zhu et al., 2012; Zhu and Lim, 2012; Zhu et al., 2012) and 2D strip packing problem Wei et al. (2014) have shown the effectiveness of using blocks.Although the proposed algorithm is not an exact approach, experiments on test sets show that the algorithm finds the optimal solutions for most moderately sized instances and obtains better solutions for larger instances than the existing algorithms.In the bidirectional building approach for the C*-2DGKP, rectangles are first arranged into blocks, and each step involves placing a block of rectangles instead of a single rectangle. It starts with the input sheet and a list of candidate blocks. In the first step, a block is selected and placed in the bottom-left corner of the sheet. Then two new free spaces are generated by dividing the sheet horizontally or vertically. In subsequent steps, it selects the free spaces with the smallest area and one of the available blocks, and then places the selected block in the bottom-left corner of the selected space. Once the block is placed, the list of free spaces and available blocks are updated. This process is repeated until the list of free spaces or the list of available rectangles is empty, which means the packing is complete.During the packing process, a partial solution is represented by a state with the following attributes:•rectList: a list of available rectangles;blockList: a list of available candidate blocks;spaceList: a list of free space;packedRectsList: a list of the rectangles already packed; andpackedProfit: the total profit of the packed rectangles.A packing is called complete if either the list of available rectangles rectList is empty or the list of free space spaceList is empty. A free space is a rectangular region R described by the following four attributes:•x,y: the coordinates of the bottom-left corner of R; andw,h: the width and height of R.The bidirectional building approach, BidirectionalBuilding, is given in Algorithm 1and works as follows. It first creates a free space R to represent the empty sheet and an initial state S in which the spaceList only contains the space R (lines 4–6). Then, the packing process starts. At each iteration of the packing process (lines 9–24), it first obtains the space R with the smallest area from the space list in the current state S, then tries to select the block b that fits R the best, places b in the bottom-left corner of R and moves to the next step.To evaluate the fitness of a block b with respect to a space R, It first places b in the bottom-left corner of R, then considers two possible ways of dividing the remaining space, as illustrated in Fig. 1. To obtain a complete packing from a partial packing, a greedy heuristic GreedyPack (line 18) is used. The partial packing that leads to the best complete packing is recorded (line 20) and selected as the next state (line 24). The greedy packing heuristic GreedyPack is introduced in Section 2.2.The PlaceBlock(S, b, R) procedure places a block b so that its bottom-left corner is at the coordinate (R.x, R.y) and updates the state accordingly. For each rectangle in block b, it is first appended to the end of S.packedRectList (line 3) and its profit is added to S.packedProfit (line 4), then the number of that rectangles available in the list S.rectList (line 5) is updated. As the available rectangles in S.rectList decreases, some of the blocks become invalid because they consist of more rectangles than available. Such blocks are deleted from the S.blockList (line 6). Finally, the modified state is returned.Given a partial packing S, GreedyPack generates a complete packing iteratively as follows. In each iteration, it first finds the space R with the smallest area from the free space list of the current state. Then, it tries to find the first block b in the block list that fits into R. If a block b is found, it places b in the bottom-left corner of the region R using PlaceBlock and adds the new space generated using GenerateSpace (described in Section 2.3) to the free space list. The above process is repeated until either the space list or the available rectangle list is empty, at which point a complete packing is found. The pseudocode of the greedy packing procedure GreedyPack is given in Algorithm 2.After placing a block b in the bottom-left corner of a region R, there are two possible ways to divide the remaining space in the given region, as illustrated in Fig. 1. The process GenNewSpace(S, R, b) is used to select the dividing method and generate new spaces, where S is a state representing a partial packing. The process works as follows. If both the remaining width Δw and the remaining height Δh are too small to accommodate any unpacked rectangle, it does not generate any new space. If either Δw or Δh is too small to accommodate any unpacked rectangle, it divides the remaining space horizontally (vertically) if the Δh (Δw) is too small. Otherwise, for each method of generating space, it uses the area of the generated space with a larger area to evaluate it. The method that generates the largest evaluated value preferred.Blocks are recursively defined and generated. Every individual rectangle is a block, and any two blocks can be joined either along the x-axis as in Fig. 2or along the y-axis, as in Fig. 2, to form a larger block. A block has the following attributes:•MBR: the minimum bounding rectangle that encloses all rectangles inside the block, and which defines the dimensions of the block.w, h: the width and height of the block, which is defined by its MBR.rectList: a list of rectangles inside the MBR of the block.profit: the total profit of the rectangles in rectList.profitUB: the upper bound of the profit of any packing pattern that uses this block.The process GenerateBlocksOnProfit (W, H, Rects, maxCount, minProfit) is used to generate blocks, where maxCount is a number used to control the total number of blocks generated and minProfit is a threshold to control the profit upper bound of the generated blocks. The process works as follows. First, it generates blocks consisting of one rectangle. Then, it iteratively combines smaller blocks along the x- and y-axis to generate larger blocks, until sufficient numbers of blocks are generated. The maximum number of blocks generated is controlled by the input parameter maxCount. As the objective is to maximize the profit of the packed rectangles in the sheet, only blocks whose profitUB is not below a user-defined threshold minProfit are generated. The method of calculating the profitUB for a block is described in Section 2.6. Of course, blocks that are too wide or too tall to fit into the sheet are useless and hence are not generated. Furthermore, blocks that consist of more rectangles of a certain type than available in the input are not generated either. Finally, two blocks with the same MBR and consisting of the same set of rectangles, even if the positions of the rectangles differ, are equivalent for our purpose. Therefore, if a generated block is equivalent to an existing block, it is discarded.Clearly, the number of blocks generated by GenerateBlocksOnProfit is a decreasing function of minProfit. However, it is hard to predict the exact number. To control the actual number of blocks generated, a binary search is used to find the maximum value of minProfit, in which the number of generated blocks is not less than maxCount. The binary search procedure, GenerateBlock, is given as Algorithm 5. Assume the maximum profit so far is maxFoundProfit, then any block whose profit upper bound is equal to or less than maxFoundProfit is useless as the profit of any packing using such a block will not be larger than maxFoundProfit. Before conducting the binary search, it first tries to generate blocks using GenerateBlocksOnProfit based on the value maxFoundProfit + 1. If the number of blocks generated is less than maxCount, it merely returns. Otherwise, it starts the binary search. Initially, the search range is set to [lb, ub], where ub is the upper bound of profit based on the relaxed one-dimensional knapsack problem (described in Section 2.6) and lb is set to maxFoundProfit + 2. In each iteration, the block list is generated using GenerateBlocksOnProfit based on the middle value in the range ⌊(lb + ub)/2⌋. If the number of blocks generated is not less than maxCount, the search range is set to [ ⌊(lb + ub)/2⌋ + 1, ub]; otherwise, the search range is set to [lb, ⌊(lb + ub)/2⌋ − 1]. The process is repeated until the search range is empty.The solution produced by BidirectionalBuilding is entirely determined by the list of candidate blocks blockList. The approach calls this procedure several times using different lists of candidate blocks, and records the best solutions found (Algorithm 6). Because the number of all possible blocks grows exponentially with the number of input rectangles, it is simply too huge for any input of reasonable size. Therefore, the variable maxCount is used to limit the total number of blocks generated. In the first iteration, maxCount is set to the types of input rectangles in Rects. To construct a solution based on the block list, we sorts the blocks generated by calling GenerateBlock in descending order of profit and call the process BidirectionalBuilding. In subsequent iterations, maxCount is doubled to allow more blocks to be considered. The above process is repeated until a solution that equals the upper bound 1DKP is found, as described in Section 2.6, or the time limit is reached.The overall relationship between the six algorithms described previous is shown as Fig. 3, where the arrow means calling relationship.The 2D guillotine knapsack packing problem can be formulated as follows:(1)2DGKP(W,H):max∑i=1mpixi(2)s.txi∈{0,1,⋯,ui}(3)∑i=1mwihixi≤W×H(4)xiAPTARANORMALcopyofrectangletypeiAPTARANORMALcouldbeguillotinecutfromthesheetwithsizeW×HIf constraint (4) is deleted, the results is the relaxed one dimensional knapsack problem:(5)1DKP(A):max∑i=1mpixi(6)s.txi∈{0,1,⋯,ui}(7)∑i=1mwihixi≤Awhere A is the capacity of the knapsack (i.e., A ← W × H for an instance of 2DGKP). Hence, for any instance of 2DGKP, the value of the relaxed one-dimensional knapsack problem is an upper bound of the original problem. This upper bound is used in line 1 of Algorithm 6.For a given block b, we can calculate the profit upper bound of a packing that uses block b as follows. As b occupies a space with an area of b.w × b.h, the area of the remaining space in the input sheet is leftArea ← W × H − b.w × b.h. The maximum profit that can be obtained from the remaining space will not exceed 1DKP(leftArea), which is the maximum profit can be gotten from the relaxed one dimensional knapsack problem. Therefore, the profit of any packing using b will not exceed b.profit + 1DKP(leftArea).This upper bound can be further improved by calculating the remaining space more accurately. As the size of the sheet and the rectangle are assumed to be integer, the input sheet can be divided into W vertical strips of size 1 × H. For any packing solution using b, block b occupies a total of b.w strips. For any one of such strip, the total occupied height of the strip must be a combination of the height of b and the height of the input rectangles, which will not exceed(8)maxH=max{∑i=1mhixi|b.h+∑i=1mhixi≤H,xi∈{0,1,⋯,ui}APTARANORMALfori=1,2,⋯,m∑i=1m}Thus, at least H − maxH units of area will be wasted in such a strip, resulting in a total waste of vWaste ← b.w × (H − maxH). Follows as a similar argument, the sheet can be divided into horizontal strips to establish the minimum waste hWaste. Therefore, the minimum waste due to block b is vWaste + hWaste. The total useful area in the remaining sheet after b is placed is given by leftArea ← W × H − b.w × b.h − vWaste − hWaste, and the profit upper bound of any packing using b is given by b.profit + 1DKP(leftArea), which is denoted as u1(b).Consider a solution using block b. As Viswanathan and Bagchi (1993) states, there is an equivalent solution (the used rectangles are the same) S with block b placed in the bottom-left corner of the sheet. As shown in Fig. 4, to find an upper bound for S, we need to know the upper bound of the profit we can obtain from region P. We first relax the limitation on the number of each type of rectangle (i.e., we set uito ⌊W/wi⌋ × ⌊H/hi⌋ for each i ). Let F(x, y) be the maximum profit we can get from a sheet of size x × y after the relaxation. Gilmore and Gomory (1966) proposed a method to solve F(x, y) using dynamic programming and the recursive function is given as(9)F(x,y)=max{F0(x,y),F(x1,y)+F(x2,y),F(x,y1)+F(x,Y2)},where(10)F0(x,y)=max{0,pi:wi≤x,hi≤y,APTARANORMALfori=1,2,⋯,m}(11)x1+x2≤x,x1≤x2;y1+y2≤y,y1≤y2(12)x1,x2=1,2,⋯,x;y1,y2=1,2,⋯,yBased on the function F(x, y), Viswanathan and Bagchi (1993) defined the following function u(x, y) and proved that the profit can get from region P for any block b will not exceed u(b.w, b.h):(13)u(x,y)=max{h(x,y),v(x,y)},where(14)h(x,y)=max{h(x+t,y)+F(t,y):1≤t≤W−x}(15)v(x,y)=max{h(x,y+t)+F(x,t):1≤t≤H−y}We denote b.profit + u(b.w, b.h) as u2(b).Yoon et al. (2013) proposed another profit upper bound for region P based on the relaxed knapsack problem. The area of region P is W × H − b.w × b.h. For any block b, assume that the number of used rectangles i in b is b(i). Then, the profit can get from P will not exceed(16)up(P):max{∑i=1mpixi}(17)s.t.∑i=1mwihixi≤W×H−b.w×b.h(18)0≤xi≤ui−b(i),fori=1,2,⋯,mwhere xiis the number of rectangles i selected from the remaining rectangles. Note that the xiis not required to be integer. It is easy to calculate up(P) using greedy once the rectangles have been sorted by the decreasing of unit profit, which is defined as pi/(wihi). The upper bound b.profit + up(P) is denoted as u3(b).The final profit upper bound for a block b is defined as the minimum of u1, u2 and u3; that is, b.profitUB = min {u1(b), u2(b), u3(b)}.Seven test sets are used to test the performance of our approach. The characteristics of these test sets are summarized in Table 1, where the original papers proposing these data are also listed for reference. The first four sets belong to the unweighted case:•Set1 consists of 46 instances used by Hifi (2004) to test their tabu search.Set2 consists of 13 instances used by Dolatabadi et al. (2012) to test their exact algorithm.Set3 consists of 21 instances generated by Hopper and Turton (2001). These instances are generated by successively cutting a large rectangle into smaller rectangles. They are divided into seven groups with three instances in each group. For the first two instances in each group, the known optimal solutions follow guillotine-cut constraint, whereas the optimal solution for the remaining instance may not follow the guillotine-cut constraint.Set4 consists of 450 instances generated by Morabito and Pureza (2010). These instances are classified as three classes based on the characteristic of the available number for each rectangle type.The other four sets belong to the weighted case:•Set5 consists of 36 instances used by Hifi (2004).Set6 consists of 21 small instances used by Bortfeldt and Winter (2009) to test their genetic algorithm.Set7 consists of 630 larger instances, which were introduced by Beasley (2004). In these larger instances, m ranges from 40 to 1000 and n ranges from 40 to 4000.Set8 consists of 60 larger instances introduced by Cui and Huang (2012).In this section, we report the performance of the approach on the eight sets of benchmark data and compare the approach with the following leading algorithms in the literature:•H2004: a hybrid approach that combines a depth-first search using hill-climbing strategies and dynamic programming techniques proposed by Hifi (2004).C2008: a recursive algorithm proposed by Chen (2008).B2009: a genetic algorithm proposed by Bortfeldt and Winter (2009).M2010: a heuristic approach based on dynamic programming and and/or-graph search by Morabito and Pureza (2010).C2012: a heuristic algorithm for constrained T-shape patterns by Cui and Huang (2012).D2012: an exact algorithm proposed by Dolatabadi et al. (2012).The iterative block-building algorithm (IBBA) is implemented as sequential algorithms in C + + and compiled by GCC 4.1.2, with no explicit use of multi-threading. It is executed on an Intel Xeon E5430 clocked at 2.66 GHz (Quad Core) with 8 GB RAM running the CentOS 5 linux operating system. In the IBBA, the timeLimit is set to 120 seconds for each instance. The only exception is instance gcut13 in set2 and all instances in set8. For guct13, it takes 245 seconds to calculate the upper bound, thus the timeLimit for it is set to 365 seconds. For the instances in set8, it takes about 120 seconds to calculate the upper bound, thus the timeLimit is set to 240 seconds. The computational environments for these approaches are summarized in Appendix A in the online supplements. The detailed computational results presented in this section and the test data are available online at Wei (2013).The comparisons between the IBBA and the other algorithms on the eight sets are summarized in Table 2, where #opt is the number of optimal solutions found by each algorithm. The relative gap is calculated as the percentage gap between the found solution and the optimal solution/upper bound. Let the profit of the found solution be p and the optimal solution/upper bound be ub, then the relative gap is calculated as 100 × (ub − p)/ub. For instances where the optimal solution is known from the literature, ub is set to the optimal value, otherwise, ub is set to the value of the relaxed one-dimensional knapsack problem. The only exception is for set4, where the ub is taken from the paper by Morabito and Pureza (2010).For set1, the optimal solutions for all the instances are known based on the results of Yoon et al. (2013). The IBBA finds the optimal solution for all instances.For set2, the optimal solutions for all the instances except guct13 are found by D2012. The IBBA finds the optimal solution for all instances except guct13, although its solution is better than those found by all of the previous approaches.For set3, the IBBA finds the optimal solution for seven instances, which is better than B2009, and the IBBA produces an average relative gap that is smaller than that of B2009.For set4, IBBA produces an average relative gap that is smaller than that of M2010. Note that Morabito and Pureza (2010) only reported the average upper bound for each group, the individual upper bound for each instance cannot be identified, so we do not compare the number of optimal solution between IBBA and M2010.For set5, the optimal solutions for all of the instances except ATP42 and ATP43 were found by Yoon et al. (2013). The IBBA finds the optimal solution for all instances except ATP42 and ATP43, and is the best among all of the compared heuristic methods. The solution found by IBBA for instance ATP42 is better than the best solution found by previous approaches.For set6, the IBBA finds the optimal solution for all 21 instances, while B2009 found the optimal solutions for 14 instances.For the larger instances in set7, the IBBA finds the optimal solution for almost half of the instances, which is much better than B2009. The IBBA produces an average relative gap smaller than that of B2009.For the larger instances in set8, the IBBA finds the optimal solution for 17 instances while C2012 fail to find anyone. The IBBA produces an average relative gap smaller than that of C2012.The detailed results for each set are given in Appendix B in the online supplements.The instances in set3 are used to analyze the convergence behavior of the approach. This set is selected because the number of rectangles in this set is range from small to large and the IBBA fails to find the optimal solution for most of the instances. IBBA is executed for 1024 CPU on each instance and the best solution at the end of 1 second, 2 seconds, 4 seconds, ..., and 1024 seconds is recorded. The set is then divided into three groups according to the total number of input rectangles n: small (n < 50), medium (50 ≤ n < 100) and large (n ≥ 100). The average relative gap for each group by time is shown in Fig. 5, where the x-axis represents the CPU time in seconds and the y-axis represents the average relative gap.As shown in Fig. 5, the IBBA converges after 4 seconds for small instances and 32 seconds for medium instances. For large instances, the IBBA continues to find better solutions when it is allowed more CPU time. However, the curve becomes flatter after 128 seconds, indicating that the return is achieved at a diminishing rate as the CPU time increases. Therefore, the time limit is set to 120 seconds when reporting the final results.For a given instance, let f(p) be the number of blocks whose profit upper bound is not less than p. To find the relationship between f(p) and p, the GenerateBlocksOnProfit is used to calculate f(p) for different p. Assume ub is the value of 1DKP and lb is the profit found by the IBBA. Ten value of p is used which is defined as lb + (ub − ib) × i/9 for i = 0, 1, …, 9. The instances ATP40, ATP41, ..., ATP49 in set4 are moderate in size and the IBBA fails to find the optimal solution for two of the instances. These instances are used to test the function f(p), and the results are given in Table 3. Note that the parameter maxCount is set to 1,000,000 when using GenerateBlocksOnProfit.We can see from the table that the numbers of available blocks for instances APT42 and ATP43 are much larger than those for other instances, which makes it difficult to find the optimal solution for these two instances. During the process of calculating f(p) for these two instances, any block with a profit greater than the solution found by IBBA is not found. For instance APT42, f(p) starts to exceed 1,000,000 for p = (8ub + lb)/9), thus, we can conclude that the optimal solution must be less than (7ub + 2lb)/9, which is 33,709. For instance APT43, f(p) starts to exceed 1,000,000 for p = (5ub + 4lb)/9), thus, we can conclude that the optimal solution must be less than (4ub + 5lb)/9, which is 218,780. Note that Chen (2008) reported that C2008 found a solution with a profit 34,015 for instance APT42, which contradicts the assertion that the optimal solution must be less than 33,709. However, as Dolatabadi et al. (2012) proved, the solution found by C2008 for instance ATP45 is not achievable, hence, we believe that the solution found by C2008 for instance APT42 must be incorrect.Note that three upper bound have been used to calculate the profit upper bound of a block. In order to test the effect of these three upper bounds on f(p) with different p values, instances ATP42 and ATP49 are selected to test it. For each p value, it first calculates f(p) using all three upper bounds, and let this value be f0(p). Then, it selects two of the upper bounds and calculate the f(p) based on the same p. The increase in the number of blocks compared to f0(p) using only two of the upper bounds for different p values is shown in Fig. 6. We can see from Fig. 6 that the highest increases occur when only use u1 + u2 for instance ATP42 and u1 + u3 for instance ATP49. Furthermore, the increased number of blocks grows exponentially as the profit upper bound decreases for two selected upper bounds.

@&#CONCLUSIONS@&#
This paper studies the 2D constrained guillotine knapsack packing problem. While existing algorithms use either top-down or bottom-up approach, the algorithm combines both. A solution is constructed in top-down fashion by dividing the input sheet into successively smaller sheets at each step. We leverage the benefit of the bottom-up approach by combining rectangles into blocks and progressively combining smaller blocks into larger ones. We place blocks instead of rectangles. The computational results on well-known test sets show that the approach finds the optimal solution for almost all of the instances of moderate size and find the best results for the larger instances compared with existing algorithms. Thus, this paper shows that the top-down and bottom-up approaches can be combined into a coherent algorithm to harness all of their benefits.