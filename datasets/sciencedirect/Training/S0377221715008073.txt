@&#MAIN-TITLE@&#
Network-flow based algorithms for scheduling production in multi-processor open-pit mines accounting for metal uncertainty

@&#HIGHLIGHTS@&#
A variant of the open-pit mine production scheduling problem is considered.A mathematical formulation of this variant is proposed.A heuristic based on network flow techniques is developed to solve the formulation.Numerical results indicating the efficiency of the proposed approach are provided.Comparisons with other methods from the literature are also presented.

@&#KEYPHRASES@&#
Scheduling,Heuristics,Open-pit mining,Metal uncertainty,Network-flow algorithms,

@&#ABSTRACT@&#
The open-pit mine production scheduling problem (MPSP) deals with the optimization of the net present value of a mining asset and has received significant attention in recent years. Several solution methods have been proposed for its deterministic version. However, little is reported in the literature about its stochastic version, where metal uncertainty is accounted for. Moreover, most methods focus on the mining sequence and do not consider the flow of the material once mined. In this paper, a new MPSP formulation accounting for metal uncertainty and considering multiple destinations for the mined material, including stockpiles, is introduced. In addition, four different heuristics for the problem are compared; namely, a tabu search heuristic incorporating a diversification strategy (TS), a variable neighborhood descent heuristic (VND), a very large neighborhood search heuristic based on network flow techniques (NF), and a diversified local search (DLS) that combines VND and NF. The first two heuristics are extensions of existing methods recently proposed in the literature, while the last two are novel approaches. Numerical tests indicate that the proposed solution methods are effective, able to solve in a few minutes up to a few hours instances that standard commercial solvers fail to solve. They also indicate that NF and DLS are in general more efficient and more robust than TS and VND.

@&#INTRODUCTION@&#
Scheduling production for open-pit mining operations is a key factor in determining returns on investments of hundreds of millions of dollars. In scheduling mine production, the mineral deposit is represented as a three-dimensional array of blocks, each of which represents a volume of material that can be mined. Each block has a weight and a metal content interpolated using information obtained from exploration drilling.In practice, an open-pit mine has multiple ore processing streams (henceforth referred to as processors for simplicity) operating simultaneously. Each processor has a limited capacity, involves specific recoveries and costs, and requires blocks with a grade above a specific threshold value (the grade being the proportion of metal to rock). A block is processed in the processor that gives the highest recovered economic value, defined as the revenue from selling the metal recovered minus the processing cost. Blocks that do not contain enough metal content to make them profitable when processed in any of the processors are discarded as waste. In addition, the discount factor makes the early periods more profitable, such that it is preferable to process the blocks with the highest grade as early as possible. However, the blocks with the highest grade might be found at the bottom of the pit, and thus the overlying blocks (their predecessors) might have to be mined faster than they can be processed due to the limited capacity of the processors. Therefore, blocks with a grade sufficiently high to allow for profitable processing are stockpiled and saved for processing during later periods, when there is spare capacity, while the higher grade blocks are processed as early as they can be, given the limited extraction capacity, so as to maximize the net present value (NPV) over the life of the mine. Any material sent to or taken from the stockpiles incurs additional costs, so material is stockpiled if and only if there is more ore mined in a given period than can be processed.Decisions on block scheduling are thus subject to various types of constraints. The production schedule not only must respect the limits on extraction capacity (mining constraints), the capacity of the processors (processing constraints), and the availability at the stockpiles (stockpiling constraints) at each period of the life of the mine, but also must take into consideration the order in which blocks can be removed from the orebody to ensure that a block is not mined before any of its predecessors (slope constraints). Additionally, any block can be mined only once (reserve constraints). The problem is to determine which blocks to extract and when to extract them (mining sequence), as well as where and when to process the ore mined in order to maximize the net present value (NPV) of the mine while respecting the various constraints.The open-pit mine production scheduling problem (MPSP) has been considerably studied since the 1960s (Johnson, 1969). Several studies have addressed its deterministic version, which assumes that all the problem parameters are known, including the interpolated metal content of the blocks. One of the first exact methods for the deterministic MPSP was developed by Dagdelen and Johnson (1986). It is based on Lagrangian relaxation. Caccetta and Hill (2003) introduced a branch-and-cut approach to solve the problem to optimality. Other exact approaches that exploit the structure of the problem have been proposed by Ramazan (2007) and Boland, Dumitrescu, Froyland, and Gleixner (2009). However, as most realistic instances involve typically tens to hundreds of thousands of blocks and thus cannot be optimized in a reasonable amount of time, heuristics and metaheuristics have been designed to deal with such large-scale instances (Chatterjee, Lamghari, & Dimitrakopoulos, 2010; Ferland, Amaya, & Djuimo, 2007; Gershon, 1987). Tolwinski and Underwood (1996) and Sevim and Lei (1998) combine heuristics with dynamic programming techniques, while Chicoisne, Espinoza, Goycoolea, Moreno, & Rubio (2012) combine heuristics with mathematical programming techniques.As noted in recent reviews about the different solution approaches for the MPSP and other optimization problems that arise in the mining context (Newman, Rubio, Caro, Weintraub, & Eurek, 2010; Osanloo, Gholamnejad, & Karimi, 2008), the direction of research in the mining industry is oriented towards developing efficient methods to solve more detailed and realistic models, such as the MPSP accounting for metal uncertainty and considering multiple destinations for the blocks mined, including stockpiles.Metal and in general geological uncertainty is addressed through the generation of multiple equally probable scenarios of the mine considered using spatial stochastic simulation methods. These methods explicitly account for spatial correlations between measurements from exploration drilling and the change of volume-scale between data available and the mining blocks considered (Godoy, 2003; Goovaerts, 1997; Remy, Boucher, & Wu, 2009). Accounting for metal uncertainty in the optimization process thus involves an increased complexity, but it is more realistic and presents other benefits. These benefits were first discussed by Ravenscroft (1992) and Dowd (1994, 1997), and more recently by Dimitrakopoulos, Farrelly, and Godoy (2002), Godoy and Dimitrakopoulos (2004), Menabde, Froyland, Stone, and Yeates (2005), Whittle and Bozorgebrahimi (2005), Kent, Peattie, and Chamberlain (2007), Boland, Dumitrescu, and Froyland (2008), Osanloo et al. (2008), Albor and Dimitrakopoulos (2010), Ramazan and Dimitrakopoulos (2013), Marcotte and Caron (2013), and Behrang, Hooman, and Clayton (2014). The authors showed that the stochastic approach could provide major improvements in NPV, in the order of 10–30 percent, compared to the solution obtained by solving a deterministic MPSP. They also showed that the stochastic approach substantially reduces risk in meeting production forecasts and finds larger pit limits, contributing to the sustainable utilization of mineral resources. For a review of stochastic approaches in the context of mine scheduling and the value of the stochastic solution over the deterministic solution, see Dimitrakopoulos (2011).Table 1summarizes the variants of the MPSP that account for metal uncertainty studied in the literature. The variants are grouped according to the nature of the objective function and the number of processors and stockpiles considered. For each variant, we give the references, and for each reference, we outline the approach used to handle metal uncertainty, the solution method used to solve the stochastic model, and the size of the instances solved. This table shows that few studies have considered multiple destinations for the material mined. Goodfellow and Dimitrakopoulos (2013) consider multiple processors, but they do not consider stockpiling as an option. To solve the problem with multiple processors, they extend the simulated annealing based approach proposed by Godoy (2003). To the best of our knowledge, the only published articles considering the stockpiling option are the ones by Ramazan and Dimitrakopoulos (2013) and Behrang et al. (2014). They consider one processor and one stockpile and solve their formulation using the mixed integer programming solver CPLEX (IBM, 2010). This solution approach is limited by its inability to solve instances of realistic size in a reasonable amount of time. Table 1 thus shows a lack in the existing literature of studies that propose efficient solution methods to solve large instances of the variant of the MPSP involving metal uncertainty, multiple processors, and multiple stockpiles. This paper proposes such a study.The main contributions of the paper are threefold. First, a mathematical formulation of the problem, which is an extension of the formulation in Lamghari, Dimitrakopoulos, and Ferland (2014), is introduced. This formulation is different from the one in Ramazan and Dimitrakopoulos (2013). Their objective function includes an additional term that minimizes deviations from production targets to manage geological risk, which is not considered here. In this paper, we consider that the surplus in ore production is the amount sent to the stockpiles. Since sending ore material to the stockpiles incurs costs (cost of sending the material to the stockpiles, cost of reclaiming it from the stockpiles later on, as well as loss of profit because the ore blocks are not processed at the period in which they are mined), deviations from ore production targets will implicitly be minimized. Second, four heuristic methods for solving the problem are developed. These heuristics are a tabu search heuristic incorporating a diversification strategy (TS), a variable neighborhood descent heuristic (VND), a network-flow based heuristic (NF), and a diversified local search heuristic (DLS). The first two heuristics are adaptations of the methods previously developed by Lamghari and Dimitrakopoulos (2012) and Lamghari et al. (2014) for the variant of the problem with a single processor and no stockpile. The third heuristic is a novel solution approach that extends some of the ideas in Lamghari et al. (2014). It can be seen as a very large-scale neighborhood search heuristic using network flow techniques to efficiently search for improving solutions in a very large neighborhood (Ahuja, Ergun, Orlin, & Punnen, 2002). The fourth heuristic is also a new heuristic in that it combines the second and the third heuristics (VND and NF) to overcome some of their weaknesses. It alternates between a diversification phase that provides a new solution to the following local search phase that intensifies the search in the region of this solution. The four proposed heuristics are improvement heuristics and require an initial solution. The initial solution is obtained in a first phase of the solution procedure (initialization phase) by using one of three constructive heuristics based on a time-decomposition approach. Third, extensive computational results to evaluate the performance of the proposed solution methods are provided. The proposed solution methods are also compared to the commercial solver CPLEX.The remainder of the paper is organized as follows: In Section 2, the approach used to deal with metal uncertainty is outlined, and a mathematical formulation of the stochastic MPSP studied in this paper is introduced. The following sections present the heuristics used in the initialization phase and the improvement phase, respectively. Computational results are reported and discussed in Section 5. Finally, conclusions are drawn in Section 6.Consider an open-pit mine to be exploited over T periods. The mine contains N blocks, and each block i has a weight wiand a grade gi. Recall that the grade is the proportion of metal to rock and hence, the metal content of block i is equal to giwi. The grade giof block i is a realization of a random fieldGiinR3. It is not known by the decision maker who realizes the actual value of giwhen block i is mined. Thus, in the first stage, the decision maker decides which blocks to extract and when to extract them so as to satisfy the reserve, the slope, and the mining constraints. Extracting blocks incurs a unit mining cost,c¯. Once the first decisions are made, and the grade of the blocks becomes known, in the second stage, the decision maker must decide where and when to process the mined material to satisfy all the other constraints (processing and stockpiling constraints). The latter decisions can be seen as recourse actions taken once a specific realization of the uncertain parameters (i.e., the grade) has been observed (Birge & Louveaux, 2011). To properly formalize these actions, let us define how the grade influences the destination of the mined blocks.For a given realization or scenario s, the grade of block i is fixed to gis. To recover the metal, the mine employs P processors. A unit processing cost cpis incurred by processing ore in processor p, and processor p has a recovery of αpand a capacity ofΘptduring period t. The recovery determines the amount of metal obtained if block i is processed in processor p (metal recovered = recovery × metal content). Selling a unit of the recovered metal costs ξ and generates a revenue of μ. Thus, the profit associated with a mined block i if processed in processor p under scenario s is:(1)rips=αpgiswi(μ−ξ)−cpwi.Eq. (1) allows the decision maker to determine where each mined block i must be processed to maximize the profit. More specifically, letGp=cpαp(μ−ξ)denote the grade of ore below which processing is not profitable in processor p (i.e., if gis≤ Gpthen rips≤ 0). Without loss of generality, assume that the P processors are indexed in such a way thatG1<G2<G3<⋯<GP<GP+1=∞. If gis≤ G1, then block i is not valuable. It is not processed and is discarded as waste. Otherwise,gis∈]Gp,Gp+1](1 ≤ p ≤ P), and the most profitable processor where i can be processed is p. Let θipsbe a parameter indicating the most profitable processor for block i under scenario s: θipstakes value 1 ifgis∈]Gp,Gp+1]; otherwise, it is equal to 0. Clearly,∑p=1Pθipsis equal to 0 if i is a waste block under scenario s, and it is equal to 1 otherwise. The highest profit associated with a mined block i under scenario s can then be expressed as follows:ris=maxprips=∑p=1Pθipswi[αpgis(μ−ξ)−cp].Recall that each processor has a limited capacity, and due to that, it might be impossible to process i in p immediately (i.e., during the period it is mined) and generate the profit risabove. In this case, i is not lost, but it is sent to the stockpile associated with p. Blocks in the stockpile associated with p are mixed homogeneously, and an amount of the resulting mixture is sent to p for processing when there is spare capacity. A unitcp+cost is incurred when sending material to the stockpile associated with p. Reclaiming material from the stockpile associated with p also incurs a cost,cp−. The reclaimed material is processed in p and generates a unit profit of:r˜ps=αpG˜ps(μ−ξ)−cpG˜psbeing the grade of material in the stockpile associated with p under scenario s.To summarize, once the first stage decisions are made (i.e., the mining sequence is fixed), and the grade of the blocks becomes known, in the second stage, the decision maker decides where to send the mined blocks. A first type of recourse consists of sending each block to the most profitable processor. A second type of recourse arises whenever a processor capacity is exceeded: the surplus ore is sent to the corresponding stockpile. A third type of recourse arises whenever each mined block is sent to the most profitable processor and there is still spare capacity in some processors: these processors are filled from the corresponding stockpiles (maximum possible such that neither the capacity of the processor nor the amount available in the stockpile is exceeded). The first and third types of recourse yield a negative recourse cost (a positive profit), while the second type yields a positive recourse cost. The MPSP studied in this paper consists of identifying a first stage solution that minimizes the expected cost of the second stage solution; i.e., a schedule that minimizes the cost of the first stage solution (the mining costs), minus the expected recourse costs. This is equivalent to maximizing the expected profit from the ore processed immediately when mined plus the expected profit from the ore reclaimed from the stockpiles and processed minus the costs of mining and the expected costs of sending ore to the stockpiles. All costs and profits are discounted to give their present value.Metal uncertainty is modelled through a finite set of scenarios, each scenario representing a possible realization of the grade and having an associate probability of occurrence (S equally probable scenarios in this paper). On the other hand, at a given period and for a given scenario s, the grade of the material in the stockpile associated with processor p,G˜ps,used to compute the profit from the stockpile is an unknown variable because it depends on the blocks extracted and sent to the stockpile in earlier periods (a decision variable). However, it can be approximated by the following expression:(2)G˜ps=∑i:θips=1wigis∑i:θips=1wi.The numerator of (2) is equal to the metal content of all blocks to be processed in processor p if scenario s occurs, while the denominator is the total weight of these blocks. Note that using the approximation (2) can underestimate or overestimate the true profit from the stockpile, but it allows us to bypass the non-linearity of the problem that stems from the use of the stockpiles. Moreover, preliminary tests indicated that, in terms of net present value, the differences between the schedules generated using the approximation and the schedules using the true profit from the stockpiles are not significant.The notation used to formulate the extensive form of the two-stage stochastic model is presented below. First are listed the indices and parameters. Second the variables are presented. Some of the notation has already been introduced, but we present it again for the sake of clarity.•N: the number of blocks considered for scheduling.i: block index,i=1,…,N.T: the number of periods over which blocks are being scheduled (horizon).t: period index,t=1,…,T.P: the number of processors. Note that since a stockpile is associated with each processor, the number of stockpiles is equal to the number of processors.p: processor index,p=1,…,P.S: the number of scenarios used to model metal uncertainty.s: scenario index,s=1,…,S.πs: probability that scenario s occurs, with∑s=1Sπs=1. Recall that in this paper, the scenarios are equiprobable and thusπs=1S.Pred(i)⊆{1,…,N}: the set of predecessors of block i; i.e., blocks that have to be removed to have access to block i.wi: the weight of block i in tonnes.Wt: maximum amount of material (waste and ore) that can be mined during period t (mining capacity in tonnes).c¯: undiscounted cost of mining a tonne of rock.cp: undiscounted cost of processing a tonne of ore in processor p.θips: a parameter indicating the processor in which block i is processed if scenario s occurs. Recall that a block is processed in the processor that garners the highest profit.θips={1ifiisprocessedinpunderscenarios,0otherwise.Θpt: maximum amount of ore that can be processed in processor p during period t (processing capacity of p in tonnes).ris: undiscounted revenue of an already mined block i if sent immediately for processing (i.e., during the same period it is mined), and if scenario s occurs. Recall thatris=0if i is a waste block under scenario s.cp+: undiscounted cost of sending a tonne of ore to the stockpile associated with processor p (transportation cost). As mentioned earlier, it is assumed that when a block arrives at the stockpile, it is mixed with the other material already there. The cost of this operation is included incp+.cp−: undiscounted cost of taking a tonne of ore from the stockpile associated with processor p (transportation cost plus loading cost).r˜ps: undiscounted revenue to be generated if a tonne of ore in the stockpile associated with p is processed, and if scenario s occurs.d: the discount rate per period for cash flows.The variables used to formulate the problem are as follows:•A binary variable is associated with each block i for each period t:xit={1ifblockiisminedbyperiodt,0otherwise.This means that if block i is mined in period τ, thenxit=0for allt=1,…,τ−1andxit=1for allt=τ,…,T. If i is not mined during the horizon, thenxit=0for allt=1,…,T. To simplify the notation in the rest of this section, we introduce a set of N dummy decision variablesxi0(i=1,…,N), each having a fixed value equal to 0.ypst+is a continuous variable measuring the surplus in the amount of ore mined during period t that can be processed in p if scenario s occurs (i.e., the amount to send from the mine to the stockpile associated with p).ypst−is a continuous variable measuring the amount of ore to take in period t from the stockpile associated with processor p, if scenario s occurs (i.e., the amount to send from the stockpile to the processor).Finally, the continuous variablesypstdenote the amount of ore in the stockpile associated with processor p at the end of period t under scenario s. It is assumed that the stockpile is empty at the beginning of the first period but might not be empty at the end of the planning horizon.The proposed model is given below:(3)max−∑t=1T1(1+d)t∑i=1Nwic¯(xit−xit−1)+∑t=1T1(1+d)t∑i=1N∑s=1Sπsris(xit−xit−1)−∑t=1T1(1+d)t∑p=1P∑s=1Sπs(r˜ps+cp+)ypst++∑t=1T1(1+d)t∑p=1P∑s=1Sπs(r˜ps−cp−)ypst−(M)Subjectto(4)xit−1≤xit∀i,t(5)xit≤xjt∀i,j∈Pred(i),t(6)∑i=1Nwi(xit−xit−1)≤Wt∀t(7)∑i=1Nθipswi(xit−xit−1)−ypst++ypst−≤Θpt∀t,p,s(8)ypst−1+ypst+−ypst−=ypst∀t,p,s(9)xit=0or1∀i,t(10)xi0=0∀i(11)ypst+,ypst−,ypst≥0∀t,p,s(12)yps0=0∀p,s.The objective function (3) maximizes the expected NPV of the mine. It includes four different terms:1.The first term (−∑t=1T1(1+d)t∑i=1Nwic¯(xit−xit−1)) evaluates the total discounted cost of the extraction (discounted cost of the first stage solution).The second term (∑t=1T1(1+d)t∑i=1N∑s=1Sπsris(xit−xit−1)) gives the total expected discounted profit generated if all the ore mined is sent immediately for processing during the period in which it is mined (first type of recourse). Note that waste blocks do not contribute to this term because, as mentioned earlier, if i is a waste block under scenario s, thenris=0.The third term (−∑t=1T1(1+d)t∑p=1P∑s=1Sπs(r˜ps+cp+)ypst+) gives the total expected discounted cost of sending ore to the stockpiles, including both the revenue lost because the ore is not processed in the period when it is available and the cost of transportation to the stockpiles (second type of recourse).The fourth term (∑t=1T1(1+d)t∑p=1P∑s=1Sπs(r˜ps−cp−)ypst−) represents the total expected discounted profit to be generated from processing ore taken from the stockpiles; that is, revenue minus loading and transportation costs (third type of recourse).Constraints (4)–(6) are scenario-independent. Constraints (4) guarantee that each block i is mined at most once during the horizon (reserve constraints). The mining precedence (slope constraints) is enforced by constraints (5). Constraints (6) impose an upper bound Wton the amount of material (waste and ore) mined during each period t (mining constraints).Constraints (7) are related to the requirements on the processing levels (processing constraints) and therefore are scenario-dependent. They stipulate that for each scenario s and each processor p, if the total weight of ore blocks mined during any period t is greater than the processing capacity at that period,Θpt,then the surplusypst+is sent to the stockpile associated with the processor p, inducing a cost equal to(r˜ps+cp+)(1+d)typst+. If it is smaller thanΘptand there is material in the stockpile, then an amount equal toypst−(maximum possible such that neither the capacity of the processor nor the amount available in the stockpile is exceeded) is taken from the stockpile and added to feed the processor, generating a profit equal to(r˜ps−cp−)(1+d)typst−. Finally, constraints (8) balance the flow at each stockpile (stockpiling constraints) and are also scenario-dependent. They ensure that for each scenario s, at the end of any period t, the amount of ore in the stockpile associated with each processor p is equal to the amount that was in the stockpile at the end of the previous period (t−1) plus the amount added to the stockpile during t minus the amount taken from the stockpile during t (i.e., the amount sent from the stockpile for processing, if any). The initial amount in the stockpile,yps0,is assumed to be equal to 0. Note that it is not necessary to add constraints to ensure that the amount taken from any stockpile should not exceed the amount available in this stockpile. Indeed, in an optimal solution, during any period t, we will not both take ore from the stockpile and send ore to it since these operations induce costs (see objective function (3)). Hence, at most one of the two variablesypst+andypst−will take a positive value. Assume thatypst−>0(i.e., under scenario s, the amount of ore mined during period t that can be processed in p is less thanΘpt,the capacity of processor p during that period), thenypst+=0(i.e., no ore will be sent to the stockpile associated with p). Constraints (8) imply then thatypst−1−ypst−=ypst≥0and consequently,ypst−1≥ypst−.The two-stage stochastic model (3)–(12) is NP-hard since it contains the constrained maximum closure problem as a special case (Bienstock & Zuckerberg, 2010; Hochbaum & Chen, 2000). If the instance size is not large, it can be solved exactly, but this is not typically the case in real-world applications, justifying the use of heuristic-based methods. In this paper, we propose four different heuristics for solving the problem where an initial solution is first generated and then it is improved. The methods used in the initialization and improvement phases are described in the following sections.The initial solution is obtained by using one of the three constructive heuristics described in this section. The three heuristics follow the general decomposition approach described in Lamghari et al. (2014), in which the complexity of the problem is reduced by dividing it into smaller, easier-to-solve sub-problems. Each sub-problem is associated with a period t (t=1,…,T). The sub-problems are first solved sequentially in increasing order of t, then their solutions are combined to form the initial solution. In this paper, while the procedure to reduce the size of sub-problems is similar to the one in Lamghari et al. (2014), the formulation of the sub-problems is different because it considers multiple stockpiles and multiple processors.The sub-problem associated with period t is characterized by the following three decision variables:•The blocks to mine, X.The amount of ore to send to the stockpiles,Y+.And the amount of ore to take from the stockpiles,Y−.Y+depends on X.Y−depends on X as well as on the amount on hand in the stockpiles at the beginning of t. The latter is known when the sub-problems are solved sequentially. Therefore, the main decision consists of determining a set of blocksBtto be mined in period t. These blocks are chosen, as in Lamghari et al. (2014), inRt,the set of blocks not mined yet and such thatwi+∑j∈Niwj≤Wt,Nibeing the set of blocks that are predecessors of i and not mined yet. The sub-problem associated with period t can then be summarized as follows:(13)max−∑i∈Rtwic¯xi+∑i∈Rt∑s=1Sπsrisxi−∑p=1P∑s=1Sπs(r˜ps+cp+)yps++∑p=1P∑s=1Sπs(r˜ps−cp−)yps−(SPt)Subjectto(14)xi≤xj∀i∈Rt,j∈Pred(i)∩Rt(15)∑i∈Rtwixi≤Wt(16)∑i∈Rtθipswixi−yps++yps−≤Θpt∀p,s(17)yps−≤Sps∀p,s(18)xi=0or1∀i∈Rt(19)yps+,yps−≥0∀p,swhere:•xi={1ifblockiisincludedinthesetBt,0otherwise.yps+andyps−are continuous variables indicating respectively the amount sent to and taken from the stockpile associated with processor p if scenario s occurs.Sps: a constant representing the content of the stockpile associated with processor p at the beginning of the current period (t) if scenario s occurs. The value ofSpsis initially set equal to 0 (when solving the first sub-problem (SP1)). It is updated each time a sub-problem is solved as follows: Let the optimal solution to (SPt) be (xi*,yps+*,yps−*). ThenSps:=Sps+yps+*−yps−*.Constraints (17) guarantee that for each scenario s, the amount of ore taken from the stockpile associated with any processor p does not exceed the amount available in this stockpile. The rest of the formulation is self-explanatory given the previous discussion in Section 2. Note that the discount factor1(1+d)tin the objective function (13) is omitted because the same factor appears in all of the four terms and thus does not affect the optimal solution.As noted previously, the initial solution is generated by sequentially solving the sub-problems (SPt) in increasing order of t. To solve the sub-problems, one can use any exact method. Because the sub-problems are of reduced size, they will not take as much time to solve as the original problem would. The other alternative is to use a heuristic, which might be faster. In this paper, we investigate the two alternatives.The exact method that we use is the branch-and-cut algorithm (BC) implemented in the mixed integer programming solver CPLEX. For the heuristics, we use two simple ones that select fromRta block or a number of blocks to be inserted inBt(Recall thatRtdenotes the set of blocks not mined yet and such thatwi+∑j∈Niwj≤Wt,whereasBtis the set of blocks to be mined in t). The selection-insertion process is repeated until some stopping criterion is satisfied. The details of the two heuristics are as follows:1.Random heuristic (RH): This heuristic was proposed in Lamghari and Dimitrakopoulos (2012). At each iteration, a block having no predecessors or having all its predecessors already mined is randomly selected. The process continues until the total weight of blocks mined at t (∑i∈Btwi) reachesWt2. The main purpose of this heuristic is to quickly generate an initial solution that satisfies the slope and the mining constraints.Look-ahead heuristic (LAH): This heuristic is inspired by the greedy heuristic (GH) developed in Lamghari et al. (2014). Like GH, LAH aims to select an inverted cone formed by a “base” block inRtand all its predecessors not mined yet, rather than a single block as RH does. Indeed, selecting blocks along with their predecessors allows a look ahead feature generating better solutions than the myopic approach of selecting blocks one by one. But, there are some important differences between GH and LAH, which are listed below:•List of candidates: GH considers all inverted conesΥi={i}∪{j:j∈Ni}formed by a “base” block i inRtand all its unmined predecessors j. LAH, in contrast, restricts the list of candidates to cones that if mined in the current period t lead to an improvement of the objective function value, and that are more profitable to mine in the current period than to leave for the next period. More formally, the list of candidates consists of the following set:A={Υi:i∈Rt,Δfi≥0,andΔfi(1+d)t≥ρi(1+d)t+1}where, Δfirepresents the change in the objective function value induced by inserting inBtblocks in ϒi(Δfiis set to a large negative value if this insertion leads to a violation of the mining constraints), andρi=∑υ∈Υi(−wυc¯+∑s=1Sπsrυs)is the total expected profit of blocks in ϒiif all ore blocks in this cone are sent directly for processing once mined. Hence, GH might select a cone even if the insertion of this cone does not lead to an improvement of the current solution, while LAH will not. In addition, LAH discards cones such thatΔfi(1+d)t<ρi(1+d)t+1,as opposed to GH, which does not consider this criterion. This is an advantage of LAH, for by leaving these cones until a later period when they will generate more profit, LAH introduces a long-term vision of the scheduling process. Note that this second criterion is dropped when dealing with periodt=Tbecause it is the last period of the horizon, and therefore no revenue can be generated if the blocks are left behind. LAH selects to insert inBtblocks inΥi*,wherei*=argmaxi∈AΔfi.Stopping criterion: LAH stops when the list of candidatesAis empty; that is, when no cone if inserted improves the current solution, while GH terminates when the mining constraints are approximately satisfied in period t; i.e., when∑i∈Btwi≤δWt,where δ is a random number in the interval [0.9, 0.95]. Thus, LAH should be faster than GH.Because LAH includes a long-term vision of the scheduling process, it is expected to generate better initial solutions than GH, and it is also expected to be faster. Numerical tests (not reported in this paper for the sake of brevity) corroborate these statements.In the improvement phase, the initial solutions from the previous phase (initialization) are improved by applying one of the four heuristics described in the next sections.The first heuristic is an extension of the tabu search method (TS) in Lamghari and Dimitrakopoulos (2012). The method is described in detail in the aforementioned paper, and it is briefly summarized here.TS generates a neighbor solution by moving a block i currently mined at period t to another period τ ≠ t as long as the slope constraints are not violated. Infeasible solutions violating the mining constraints can, however, be visited during the search, and this constraint violation is penalized in the objective function. When performing a move (i, t, τ), the pair (i, t) is included in the tabu list, meaning that it is forbidden to move i back to t for a number of iterations randomly chosen in the interval [θmin, θmax]. At each iteration, the best non tabu solution is selected. A tabu solution may also be selected if it satisfies the classical aspiration criterion. It is worth noting that one cannot evaluate the change in the value of the objective function associated with a candidate move as quickly as in Lamghari and Dimitrakopoulos (2012). Indeed, due to the presence of the stockpiles, moving a block not only affects the profit in the two periods involved in the move (periods t and τ), but also has a propagating effect on the profit of all periods from min (t, τ) to T.The tabu search stops after a maximum number of consecutive iterations without any improvement. Then, a diversification strategy that exploits a long-term memory of the search history is applied to generate a new initial solution to be optimized by the tabu search. The algorithm terminates when the total CPU time spent exceeds some value timemax.This heuristic is an extension of that proposed in Lamghari et al. (2014). It uses three neighborhood structures that preserve feasibility. These neighborhoods are defined by the three following moves:•Exchange or swap: Let i and j be two blocks currently mined in two adjacent periods t and(t+1),respectively. A swap-move consists in moving i from t to(t+1)and j from(t+1)to t. Moves that violate either the slope or the mining constraints are not allowed.Shift-after: This move is more general than the previous one. Not only does it move a block i from t to(t+1),but it also moves all the successors of i currently mined in t since leaving any successor of i in t would lead to a violation of the slope constraints. The application of a shift-after move might, however, produce an infeasible solution if the total weight of i and its successors exceeds the residual mining capacity in(t+1)(the mining constraints will be violated). Such moves are not performed.Shift-before: This move is similar to the previous one (Shift-after) except that a block is moved along with its predecessors mined in the same period, rather than its successors, to the period immediately before its current period; that is, from t to(t−1)instead of from t to(t+1). A shift-before move which leads to a violation of the mining constraints is not performed.The three neighborhoods are embedded within a variable neighborhood search framework (VND). They are explored in the order given above, using a best-improvement descent. Whenever a neighborhood produces a new incumbent solution, the search restarts from the first neighborhood (Exchange). The search stops when none of the three neighborhoods improves the incumbent solution.A drawback to VND is that it restricts the search to the feasible space. It is well-known that this approach can restrict the search process, especially if the constraints are tight, making it inefficient (Gendreau, 2003). This issue can be addressed by enlarging the search space to allow infeasible solutions, in which case simple neighborhood structures can be used, as in the tabu search (TS) method described in Section 4.1 (recall that in TS, the mining constraints are dropped from the search space and a penalty is added to the objective function for their violations). Another alternative is to use large neighborhood structures based on complex and powerful moves to allow a thorough search of the solution space, as in the network-flow based heuristic described in the next section.This heuristic (NF) uses two new neighborhood structures that are derived from the Shift-after and Shift-before neighborhoods introduced by Lamghari et al. (2014) and described in Section 4.2. The moves used in tabu search (TS) and variable neighborhood descent (VND) deal only with adjacent periods (t and(t+1)or t and(t−1)), while NF considers solutions derived by moving multiple blocks in multiple periods. More specifically, the neighborhoods used in NF are defined by the following moves:1.Forward: Let i be a block currently mined in the first periodt=1. Block i is first moved tot=2(its extraction is delayed). To respect the slope constraints, all its successors currently mined int=1are also moved. This move will probably violate the mining constraints in periodt=2,so another cluster of blocks (a block and its successors) is moved fromt=2tot=3to make room for the new blocks. This second move entails moving another set of blocks from periodt=3to the subsequent period, and so on.Backward: This move is similar to the forward move except that it allows advancing the extraction of blocks. It involves moving an unmined block and its unmined predecessors to the last period T, another block and its predecessors from T toT−1,and so on.Forward and backward moves are therefore defined by T compound sequences of shift-after and shift-before moves, respectively. In this sense, they can be seen as ejection chains of length T (Glover, 1996). Clearly, the new neighborhoods defined by these moves are larger than the neighborhoods in TS and VND and thus have the advantage of allowing a more thorough search of the solution space. However, a complete evaluation of these large neighborhoods would be computationally very expensive. To overcome this shortcoming, we solve a longest path problem (LPP) to find the best improving neighbor solution more quickly. The LPP is defined on a directed acyclic graph and thus can be solved efficiently.In what follows, the notation to be used throughout this section is first introduced and the graph structure is defined. Then, a formulation of the LPP to be solved is given. This is followed by a description of how the NF heuristic works and by some implementation details.To define the graph, we need to specify the set of nodes V and the set of arcs E and introduce some extra notation. First consider the forward case. Recall thatBtdenotes the set of blocks mined in period t (t=1,…,T). Let i be a block inBt,and let Γibe the set including i and its successors mined in the same period (t). For eacht=1,…,T,defineVt=Bt.The set of nodes V includes∑t=1TVtnodes, each associated with a block i ∈ Vt. We add to V a source node σ and a sink node τ. The source node has |V1| outgoing arcs. Each arc (σ, j) (j ∈ V1) corresponds to the decision of whether or not to move blocks in Γjfrom period 1 to period 2, and it has a length lσjequal to the change in the first three terms of the objective function (3) resulting from the corresponding move. Each node i ∈ Vt(t ≠ T) has|Vt+1|outgoing arcs, where each arc (i, j) (j∈Vt+1) corresponds to the decision of whether or not to simultaneously move blocks in Γito and remove blocks in Γjfrom(t+1). The length lijof arc (i, j) is set equal to a large negative value if the corresponding move results in a violation of the mining capacity constraint at(t+1). Otherwise, lijis equal to the change in the first three terms of the objective function (3) due to simultaneously adding blocks in Γito and removing blocks in Γjfrom(t+1). Finally, all nodes in VTare connected to the sink node τ with arcs of length 0, and each arc (i, τ) corresponds to the choice of whether or not to remove blocks in Γifrom the schedule.Considering the definition of arcs as various alternatives of moving blocks from one period to the next and their length as the change in the first three terms of the objective function (3) resulting from the corresponding moves, every path from the source σ to the sink τ defines a new solution of the problem, and the difference between the value of the new solution and the value of the current solution is the length of the path. This correspondence shows that finding the combination of blocks to delay that most improves the value of the first three terms of the objective function reduces to solving a longest path problem on the graph described above and illustrated in Fig. 1.Note that, it might not be profitable to delay the extraction of any block mined in a certain period t. An additional feature is thus required to ensure that we allow the possibility of not moving blocks from the periods. For this purpose, we add to each set Vt(t=1,…,T) a node ftassociated with a fictitious block, having neither predecessors nor successors, and whose weight and profit for each scenario are equal to zero. The source σ is connected to the node f1, each node ft(t ≠ T) has|Vt+1|outgoing arcs, and finally fThas one outgoing arc (fT, τ). The lengths of these arcs are defined in a similar manner as above, considering that the nodes ftare associated with fictitious blocks. Note also that when defining the length lijof any arc (i, j) ∈ E, we do not account for the fourth term of the objective function (3), which is the revenue generated by taking ore from the stockpiles. The reason is that this revenue cannot be evaluated independently for each period. Since it depends on the amount available in the stockpile at the beginning of period(t+1),it is affected not only by the blocks added to and removed from(t+1),but also by the moves made in periods1,…,t(all arcs preceding (i, j)).The discussion above concerns the forward case where the extraction of some blocks is delayed. Now let us consider the backward case that identifies blocks to extract earlier. The way the graph is constructed is very similar to what has been described above, with the following differences:(i)An additional fictitious period(T+1)is considered to identify blocks that are not mined and that can be inserted into the schedule. To simplify the presentation, we will refer to a block not mined during the horizon as a block mined in period(T+1). We associate with this fictitious period an infinite mining capacity (WT+1=∞), and obviously, any block mined in(T+1)neither incurs costs nor it generates revenue.Γiis defined as the set including i and its predecessors mined in the same period rather than i and its successors.V1={f1}because blocks mined in the first period cannot be extracted earlier.For the other periodst=2,…,T+1we defineVt=Bt.While the set of nodes is defined in a similar manner as above (a source node, a sink node, and a node associated with each block i ∈ Vt,t=1,…,T+1), the set of arcs E is defined slightly differently. It now consists of all possible connections between two nodes i ∈ Vtandj∈Vt−1,t=2,…,T+1. We add to E arcs connecting the source node σ to nodes inVT+1and arcs connecting nodes in V1 to the sink node, τ.The length lijof any arc(i,j)∈Vt×Vt−1(t=2,…,T+1) is set equal to the change in the first three terms of the objective function (3) due to simultaneously adding blocks in Γito and removing blocks in Γjfrom period(t−1)if this move does not violate the mining capacity at(t−1),and it is equal to a large negative value otherwise. The length of the remaining arcs is equal to 0.Once the graphG=(V,E)is constructed, a longest path problem (LPP) defined on G is solved to find the best neighbor solution, evaluated with the first three terms of the objective function (3). We associate a binary variable zijwith each arc (i, j) ∈ E. This variable takes value 1 if arc (i, j) is present in some valid path, and takes value 0 otherwise. For each node i ∈ V, we denote by I(i) and O(i) the set of incoming and outgoing arcs at the node i, respectively. The LPP can be formulated as follows:(20)max∑(i,j)∈Elijzij(LPP)bjecttoaSubjectto(21)∑(σ,j)∈O(σ)zσj=1(22)∑(i,j)∈O(i)zij−∑(j,i)∈I(i)zji=0∀i≠σ,τ(23)∑(i,τ)∈I(τ)ziτ=1(24)zij=0or1∀(i,j)∈E.To solve the LPP formulation, we take advantage of the fact that G(V, E) is an acyclic direct graph, and use an efficient algorithm, namely the pulling algorithm that runs in O(|E|) (Ahuja, Ergun, Magnanti, & Orlin, 1993). Let the optimal solution of (LPP) bez*=(zij*). Consider first the forward case. For each arc(i,j)∈Vt×Vt+1(t=1,…,T),ifzij*=1and i ≠ ft, then i and all its successors mined in the same period are moved to the next period(t+1). Now let us consider the other case, the backward case. For each arc(i,j)∈Vt×Vt−1(t=2,…,T+1),ifzij*=1and i ≠ ft, i and all its predecessors mined in the same period are moved to the previous period(t−1). Thus a new solution of the original problem (a new schedule) is obtained.There is no guarantee that this new solution will be better than the current solution x. It might be similar to x (that’s the case when all the blocks in the optimal path are fictitious) as it might have a value less than or equal to the value of x, if we consider all four terms of the objective function (3) because, as mentioned in the previous section, when computing the lij, we do not account for any revenues generated from processing ore taken from the stockpiles (the last term of the objective function (3)). Note, however, that the way the coefficients lijare defined allows us to minimize the surplus of ore production. This should allow us to minimize the use of the stockpiles and will implicitly minimize the costs incurred whenever the stockpiles are involved.The algorithm proposed to improve the initial solution x0 is described in this section. To simplify the presentation, we will say that we perform a backward pass if we try to delay the extraction of the blocks, and that we perform a forward pass if we try to advance the extraction of the blocks. A full pass means that we perform two consecutive backward forward passes or conversely two consecutive forward backward passes. A forward (respectively, backward) pass can be seen as exploring the neighborhood defined by the forward (respectively, backward) moves.Denote by xbest the best solution found so far. The same notation as in the previous section is used for the current solution (i.e., x). Set x ≔ x0 and xbest ≔ x0. A forward pass is first performed. At each iteration, the appropriate graphG=(V,E)is constructed, the corresponding (LPP) is solved, and the so-obtained optimal path is used to obtain the new solution, as described in the previous section. If the new solution is better than xbest, then it replaces xbest. This process is repeated with the new solution, and terminates when the new solution is similar to the current one (i.e., if all the blocks in the optimal path are fictitious). Then, backward passes are performed in a similar manner using the same stopping criterion. When it is not possible to advance any blocks further, thus terminating the step, forward passes are performed again. The algorithm switches between forward passes and backward passes and terminates when in one full pass it finds that the current solution has not changed or when the number of successive iterations without improvement reaches a maximum number maxIter. The latter criterion is used to avoid long computational times for large and difficult instances.In preliminary tests, we observed that one of the most time-consuming parts of the algorithm described above is constructing the graph G(V, E). Hence, to speed up the algorithm, an OpenMP parallel implementation is used. It is based on a simple master-worker strategy. The master operates as a central memory, which manages the search. Each worker processor deals with a subset of arcs (in the forward case, arcs(i,j)∈Vt×Vt+1,and in the backward case arcs(i,j)∈Vt×Vt−1). It computes their lengths, and communicates the results to the master. When the lengths of all arcs have been computed, the master solves the LPP, deduces the new current solution, updates the nodes and the arcs, and sends the arcs to the worker processors to compute their lengths. In our tests presented in Section 5, the parallel implementation uses five slave processors.The last heuristic (DLS) is a hybrid method that combines the VND heuristic and the NF heuristic described in Sections 4.2 and 4.3, respectively. It alternates between a diversification phase that provides new starting solutions and a local search phase that tries to improve these solutions. The three neighborhoods of VND (swap, shift-after, and shift-before) are used at the local search phase to intensify the search in the region of the new starting solution, while the two neighborhoods of NF (forward and backward) are used at the diversification phase to reach a solution that could not be reached by VND, thereby helping to escape from the local optimum found by VND and allowing a more extensive search of the solution space. The procedure is summarized below (Algorithm 1). It terminates when the number of iterations without improvement reaches a maximum number maxIter.It is expected that DLS will be more efficient than VND and NF because it combines the strengths of these two methods. Indeed, the two search strategies of VND and NF are complementary and combining them will allow overcoming their weaknesses:•The weakness of VND is that it might get trapped in a local optimum. The diversification phase, using the two neighborhoods of NF based on complex and powerful moves, will overcome this issue, providing new starting solutions different from those obtained using VND (i.e., during the local search phase).The weakness of NF is that it does not account for the revenue from the stockpiles when evaluating the neighborhoods, although, as noted previously, minimizing the surplus of ore production should allow us to minimize the use of the stockpiles and will implicitly minimize the costs incurred whenever the stockpiles are involved. Using VND as a local search technique will allow overcoming this issue since the revenue from the stockpiles is accounted for when evaluating the moves.This section presents results of extensive numerical experiments performed to assess the efficiency and the robustness of the heuristics described in this paper. The heuristics have been tested on three different sets of benchmark instances including 23 instances whose sizes range between 4273 blocks and 3 periods and 48,821 blocks and 14 periods. To model metal uncertainty, 20 scenarios are used in 22 instances and 25 scenarios are used in one instance. In all instances, each scenario has an equal probability of occurrence; thus,πs=1S,S being the number of scenarios. In what follows, the instances and the parameters used in the experiments are first described. The numerical results are then presented. All algorithms were coded in C++. The experiments were run on an Intel (R) Xeon(R) CPU X5675 computer (3.07 gigahertz) with 24 GB of RAM operating under Linux.As mentioned earlier, experiments were performed using three benchmark datasets. Instances in these datasets are described in detail in Appendix A, and we give only a brief overview of them here, outlining the main differences between them:•The first set of benchmark instances, S1, consists of 10 small to large size instances from a copper and a gold deposit that all contain one processor and one stockpile. The 10 instances are the same as those used in Lamghari and Dimitrakopoulos (2012), except that a stockpile has been added. Each period is one year long, and it is assumed that the production capacities are identical in all periods. For each instance, it is possible to extract a total ofWt=⌈1.20∑i=1NwiT⌉tonnes per year, of which the waste is sent to the waste dump (having an unlimited capacity), and the ore is sent to a processor p (having a capacity ofΘpt=⌈1.05∑i=1N∑s=1SπsθipswiT⌉; i.e.,1.05ExpectedamountoforeNumberofperiods).The second set of benchmark instances, S2, consists of three instances representing three different actual deposits: two copper deposits and a gold deposit. The size of these instances is larger than those in the first benchmark set. Furthermore, the instances in this set contain two processors and two stockpiles (as opposed to one processor and one stockpile in the first set). Finally, the processing capacities are set to a value 5 percent smaller than for the instances in the first set so as to make the satisfaction of the processing constraints more difficult and thus force the use of the stockpiles. For this reason, these instances are expected to be more difficult to solve than the instances in the first set.The third set of instances, S3, consists of 10 medium-size instances from a copper deposit with two processors and two stockpiles. They are similar to those in the second set, S2, except for the mining capacities, which are much tighter here. They are set to a value 20 percent smaller than for the instances in the first and second sets (i.e.,Wt=⌈∑i=1NwiT⌉).An overview of the benchmark instances as well as the economic parameters used to compute the objective function coefficients are presented in Tables 2 and 3, respectively.Recall that, to generate the initial solution, we propose three heuristics that are all based on a time-decomposition approach but differ in the way they solve the sub-problems (SPt) associated with the periods; i.e., the mathematical model (13)–(19) introduced in Section 3. One of these methods (BC) consists in using an exact method, the branch-and-cut algorithm implemented in the mixed integer programming solver CPLEX. Version 12.5 of CPLEX was used. The predual parameter of CPLEX was set to 1; that is, the dual linear programming problem is passed to the optimizer. This setting gives better results for problems with more constraints than variables, such as the sub-problems (SPt). All other CPLEX parameters were set to their default values. The other two methods used to generate the initial solution, the random heuristic (RH) and the look-ahead heuristic (LAH), do not have any parameters.The initial solution is improved using one of the four heuristics described in Section 4; namely, TS, VND, NF, and DLS. For TS, we have used the same parameter setting as in Lamghari and Dimitrakopoulos (2012). VND does not have any parameters, while NF and DLS are controlled by one parameter, which is the number of iterations without improvement used to specify the stopping criterion. This number was set to 2T and T (T representing the number of periods) for NF and DLS, respectively.In this section, we examine how the four proposed improvement heuristics (TS, VND, NF, and DLS) perform on the 23 benchmark instances described in Section 5.1.1. In order to investigate the impact of the initial solution on the final results of these heuristics, we have used the three heuristics in Section 3 to obtain the initial solution (RH, LAH, and BC). Thus, a total of3×4=12solution methods are compared. In what follows, a summary of the results is presented; detailed results are presented in Appendix B. The presentation of the results is organized according to the heuristic used to generate the initial solution.Because the methods involve random choices, we have applied them to each instance five times. For each method, five measures averaged first over the five runs and then over each benchmark set are reported:•The initial gap calculated with respect to the upper bound provided by CPLEX:%Gapinit=ZLR−ZinitZLR×100,where Zinitand ZLRare respectively the value of the initial solution and the linear relaxation optimal value (obtained by relaxing constraints (9) and solving the mathematical model (3)–(12) in Section 2.2 with CPLEX 12.5). This measure is used to assess the quality of the initial solution.The final gap also calculated with respect to the upper bound provided by CPLEX:%Gapfinal=ZLR−ZfinalZLR×100,where Zfinalis the value of the final solution obtained after applying the improvement heuristic and ZLRis as defined above. This measure is used to assess the quality of the final solution.The value of the final solution in dollars: Zfinal(as defined above). This measure is reported in addition to the previous one (%Gapfinal) because, for some instances, ZLRis not known, as CPLEX was not able to solve the linear relaxation within four weeks. Therefore, the value of %Gapfinalis not known for these instances and cannot be used to compare the methods.The percent difference between the value of the solution produced by DLS and that produced by each improvement heuristic X (NF, TS, and VND): %Diff. This measure allows us to compare NF, TS, and VND to DLS, which was found to give the best results in terms of solution quality in preliminary tests.The total CPU time required to generate the initial solution and to improve it. It is given in minutes.In this section, results obtained when the initial solution is generated using the random heuristic, RH, are reported. Table 4 provides a comparison of the criteria used to assess the quality of the solutions; that is, %Gapinit, %Gapfinal, Zfinal, and %Diff, while Table 5 provides a comparison of the solution times and also includes, in the last column, the solution time required by CPLEX to solve the linear relaxation. In both tables, we indicate in bold the best results obtained for each set of instances. A dash (“–”) indicates that CPLEX was not able to solve the linear relaxation of the instances in four weeks.As can be seen from Table 4, the value of %Gapinitis on average greater than 80 percent, indicating that the initial solutions generated with RH are of bad quality. For the 23 tested instances, all improvement heuristics succeed in improving the initial solution, but DLS performs best on average, providing final solutions of excellent quality, as can be seen from the small values of %Gapfinal. The values of %Diff indicate that, except for the instances in S3, for which NF produced slightly better solutions than DLS, the gain resulting from the use of DLS ranges between 0.41 percent, and 29.81 percent. TS exhibits a poor performance and the quality of the solutions it produces is far from the quality of the solutions obtained by the other three improvement heuristics. Note that TS was not successful in obtaining results better than those reported in Table 4 even when given additional computational time. We think that the main reason that explains the success of VND, NF, and DLS over TS is that they use larger neighborhoods compared to the simple shift neighborhood used within TS. As expected, DLS outperforms VND and NF. This is due to the fact that DLS combines the strengths of VND and NF, as is explained in Section 4.4. When comparing VND and NF, one can observe that for the first set of benchmark instances, S1, VND provides good solutions, in some cases slightly better than those obtained by NF, but in general, the improvement provided by VND decreases on the larger and more difficult instances, for which NF produces better solutions (cf. detailed results in Table B.1, Appendix B). For the instances in the second set, S2, NF also outperforms VND. Considerable economic gains ranging between 1 and 23 million dollars are achieved if NF is used instead of VND (cf. detailed results in Table B.7, Appendix B). Finally, for the instances in the third set, S3, when NF is used, the gap is improved by 46 percent on average. This shows that the use of Forward and Backward moves, where multiple blocks in multiple periods are moved simultaneously, provides a significant improvement when the constraints are tight. It allows a more thorough search of the solution space and helps escaping from local optima.With respect to CPU time (cf. Table 5), NF is in general the fastest (except for the instances in S1 where VND is faster), while DLS is the one that requires the most computational effort. VND is faster than DLS, since the latter applies VND at each major iteration as a local search mechanism to improve the new starting solution generated in the diversification phase. It is worth mentioning though, that the CPU times of NF and DLS remain reasonable given the large size of the instances and the quality of the solutions obtained. They are much smaller than the time required by CPLEX to solve the linear relaxation of the problems, as can be seen from the last three columns of Table 5.The results when the initial solution is generated using the look-ahead heuristic, LAH, are summarized in Tables 6 and 7, which have the same structure as Tables 4 and 5, respectively.A number of observations can be made from these tables. First, the initial solutions provided by LAH are better than those provided by RH. This result was expected since LAH is based on greedy rules with look-ahead features rather than random choices. It can also be seen that, among the four improvement heuristics, TS is the one that provides the smallest improvement. This was also the case in the results presented in the previous section, indicating that TS is not competitive with VND, NF, and DLS whether the search starts with a good or a bad quality solution. When comparing VND to NF, VND slightly outperforms NF on the instances in the two benchmark sets S1 and S3, but it is the opposite for the instances in S2. The performance of VND is significantly improved when combined with NF; that is, when DLS is used. Finally, note that, in general, the four improvement heuristics provide better solutions when the initial solution is generated with LAH than when it is generated with RH (the differences being more pronounced for TS). The computational times are also smaller when LAH is used (except for TS, where they are similar because the algorithm stops when the maximum allowed time is reached). On average, they are reduced by a factor of 44, 6, and 6, respectively, for VND, NF, and DLS. The computational times are higher when RH is used due to the low quality of the initial solution. A large number of iterations are thus needed to improve it.Finally, we compare TS, VND, NF, and DLS when the initial solution is generated using BC. Tables 8 and 9 summarize this comparison. As expected, for all instances, BC produces initial solutions of excellent quality because it combines the solutions of optimally solved sub-problems. It can be seen that NF fails to improve this solution in some cases, while TS is able to improve it slightly in all cases (cf. columns %Gapinitand %Gapfinalin Table 8). VND and DLS provide the best results. Their performances are quite similar, but on average, DLS improves the initial solution more than does VND, as was the case in the experiments discussed in the previous sections (i.e., when the initial solution is generated using RH or LAH). It should also be noted that the differences between the four heuristics are less pronounced when BC is used because all heuristics were able to improve the initial solution only slightly. Regarding the solution time (cf. Table 9), TS is the most time consuming and VND is the one that requires the least computational effort. NF is faster than DLS.The numerical results presented in Section 5.2 indicate that among the four improvement heuristics considered in this paper, TS is the worst. Its performance depends largely on the quality of the initial solution, and it is far inferior to the other heuristics when the initial solution is generated using RH. The comparison between VND and NF shows that, for the instances in the first benchmark set, the performance of VND is slightly better than that of NF when the instances are of small size, but for larger instances, it is the opposite. NF is able to reach better solutions than VND although it requires longer computational times. For the more difficult instances in the second and third benchmark sets, it seems worthwhile to use NF rather than VND because it generally provides better solutions. The numerical results also indicate that it pays off to combine VND and NF (i.e., to use DLS). Although the computational time is higher when DLS is used, this heuristic is significantly better than the other ones. In terms of solution quality, the results indicate that the quality of the initial solution has almost no impact on the performance of DLS. DLS always provides high quality solutions. In terms of solution time, the results suggest starting DLS with a solution generated with LAH. To conclude, both new network-flow based heuristics (NF and DLS) outperform TS and VND in terms of efficiency and robustness. They are less sensitive to the initial solutions and provide consistent results on the three benchmark sets considered in this paper. As expected, all four improvement heuristics significantly outperform CPLEX in terms of solution time.The conclusions drawn above about the differences in performance rely on average values. To assess whether these differences are statistically significant or not, we carried out, on each pair of improvement heuristics, statistical tests; namely Wilcoxon signed-rank tests with a 5 percent level of confidence (see the website http://www.R-project.org). The 1380 results obtained (12 methods × 23 instances × 5 resolutions) were considered for these tests, and the results confirm the conclusions drawn above. More specifically, in terms of solution quality, they indicate that DLS outperforms NF, VND, and DLS, that NF and VND are not statistically different, and that both NF and VND are statistically better than TS. With respect to solution time, the results of the Wilcoxon tests indicate that VND would rank first, NF second, DLS third, and TS last.

@&#CONCLUSIONS@&#
This paper deals with a variant of the open-pit mine production scheduling problem that accounts for metal uncertainty and considers multiple destinations for the mined material, including stockpiles. A two-stage stochastic formulation of this variant has been developed, as well as four heuristic methods to solve it. These heuristics are a Tabu search heuristic incorporating a diversification strategy (TS), a variable neighborhood descent heuristic (VND), a network-flow based heuristic (NF), and a diversified local search heuristic (DLS). The first two heuristics are extensions of existing methods recently proposed in the literature for another variant of the problem, while the third heuristic is a novel solution approach that can be seen as a very large-scale neighborhood search heuristic using network flow techniques to efficiently search for improving solutions in a very large neighborhood. The fourth heuristic combines the second and third heuristics (VND and NF) to overcome some of their weaknesses.Numerical results indicate that the computational times of the proposed heuristics are reasonable and significantly shorter than the time required by CPLEX to solve only the linear relaxation of the problem. The comparison of the heuristics shows that both new network-flow based heuristics (NF and DLS) outperform TS and VND in terms of efficiency and robustness. They are less sensitive to the initial solutions and provide consistent results on the three benchmark sets considered in this paper. The success of NF and DLS seems largely due to the large neighborhood structures that allow moving multiple blocks in multiple periods and that are searched in a very efficient manner. When comparing DLS and NF, the results indicate that DLS dominates in terms of solution quality. For all tested instances, DLS can reach solutions with an average optimality gap of less than 2 percent independently of the quality of the initial solution.DLS and NF are flexible enough to handle other constraints. Future research will be devoted to adapting them to solve more complex versions of the problem that include additional operational constraints and other sources of uncertainty.