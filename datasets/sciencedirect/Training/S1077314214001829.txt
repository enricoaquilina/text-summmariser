@&#MAIN-TITLE@&#
Augmenting analytic SFM filters with frame-to-frame features

@&#HIGHLIGHTS@&#
An approach to incorporate frame-to-frame features within online SFM estimators.Like inertial measurements, such features further constrain the camera velocity.The proposed approach can be easily retrofitted within existing SFM estimators.The computational complexity is reduced from cubic initially to linear.

@&#KEYPHRASES@&#
Structure from motion,Filtering,Complexity reduction,Frame-to-frame features,

@&#ABSTRACT@&#
In Structure From Motion (SFM), image features are matched in either an extended number of frames or only in pairs of consecutive frames. Traditionally, SFM filters have been applied using only one of the two matching paradigms, with the Long Range (LR) feature technique being more popular because of the fact that features that are matched across multiple frames provide stronger constraints on structure and motion. Nevertheless, Frame-to-Frame (F2F) features possess the desirable property of being abundant because of the large similarity that exists between closely spaced frames. Although the use of such features has been limited mostly to the determination of inter-frame camera motion, we argue that significant improvements can be attained in online filter-based SFM by integrating the F2F features into filters that use LR features. The main contributions of this paper are twofold. First, it presents a new method that enables the incorporation of F2F information in any analytical filter in a fashion that requires minimal change to the existing filter. Our results show that by doing so, large increases in accuracy are achieved in both the structure and motion estimates. Second, thanks to mathematical simplifications we realize in the filter, we minimize the computational burden of F2F integration by two orders of magnitude, thereby enabling its real-time implementation. Experimental results on real and simulated data prove the success of the proposed approach.

@&#INTRODUCTION@&#
Two categories of image features can be used in recovering the 3D motion and/or scene structure from video images (Fig. 1):1.Long Range (LR) features which are tracked over an extended number of frames: this type of feature introduces 3D-to-2D constraints linking the scene structure and the 2D motion to the projection of the features in the images. These constraints allow the recovery of both the 3D motion and the scene structure and most of the approaches use this category of features [4,20,21,14,3,24].Frame-to-Frame (F2F) features that are matched between only each two consecutive frames: this type of feature is generally not robust enough to be used for the estimation of the structure of the scene because those features provide, for a given 3D point, only two image projections in two spatially close frames. It is for this reason that such features have traditionally been used mostly to pose constraints on the motion between the two corresponding frames. Such constraints constitute a measurement of the differential motion (velocity or incremental change of motion) in contrast to LR features that provide an “absolute” measurement of the motion and structure. The reliability of this type of differential measurement stems from the large number of F2F features that can be matched between consecutive frames.F2F features have been used in some analytic recursive filters for the purpose of motion estimation such as the essential filter of Soatto et al. [27] using the epipolar constraint as a measurement equation. Soatto and Perona also introduced the subspace filter [26] using the subspace method of Jepson and Heeger [10] based on optical flow as a measurement mechanism. However, such approaches suffer from two major limitations. First, the translation magnitude between different frames cannot be estimated relative to a common gauge, and hence the obtained estimates cannot be integrated together in order to determine the absolute motion. Second, only the motion can be estimated reliably. Furthermore, such filters have cubic computational complexity in terms of the F2F features and hence are not able to run in real-time with a large number of features. We postulate here that F2F information is the most beneficial if used to augment multiple-frame tracking systems which should result in better estimates for both structure and motion. In fact, F2F features have been used in this fashion in the context of offline Bundle Adjustment (BA) by Zhang and Shan [33] and also in Particle Filters by Eade and Drummond [3] but only for the sake of weighting the particles.In the context of analytic SFM filters (i.e., filters using an analytic representation of the distribution of the state vector as opposed to particles), we are not aware of any approach that augments filters using LR features with F2F features. This is mainly due to two obstacles. First, adding F2F measurements to an SFM system results in one additional measurement equation for each F2F feature. This is somehow problematic as the additional equation is an implicit one meaning that it is defined as an non-linear expression containing both measured and unknown variables instead of the standard explicit form, where the measurement variables are expressed in terms of the unknown variables. As a result, the solution of SFM would require a treatment that is dependent on the type of filtering that is adopted. For instance, with the Extended Kalman Filter (EKF) a linearization solution (such as a first order Taylor series expansion about the measurements) is required, while the Unscented Kalman Filter (UKF) [8] and Particle Filter (PF) [20] can handle the implicit measurements directly. Second, the real benefit of F2F features lies in involving as many of those features as possible, however, as the computational complexity is cubic in the number of F2F features, incorporating a large number of those features in an online filter is computationally prohibitive.This paper presents a solution to the two aforementioned obstacles. To overcome the problem of the dependency on the type of filter, we propose to incorporate the F2F features in an extra filtering iteration that is performed immediately after every iteration of the main-filter. In theory, given two independent sets of observations, performing filtering using both sets simultaneously is exactly equivalent to filtering using one of the sets then filtering using the other. The numerous benefits of having a separate filtering include:•The separate filtering stage can easily augment any estimator as long as it maintains a mean vector and a covariance matrix. It can be added to existent implementations with minimal changes to existing code. In fact, it can be coded as a generic function taking as arguments the state vector, its covariance and the F2F features. Then, augmenting any filter with F2F features would amount only to calling this function with the appropriate arguments after every iteration of the main filter. The experimental results section shows how the proposed approach can be used to straightforwardly augment Davison et al.’s EKF SLAM system [2].The results of the filtering can be accepted or rejected based on some criteria such as the epipolar error of the F2F features, the number of outliers or the extent of change in the state vector. This helps avoid performing the update in the case where, for one reason or another, the F2F features are contaminated with a large number of outliersThe separate filtering stage can be divided into several independent steps, which allows the use of robust estimation techniques such as RANdom SAmple Consensus (RANSAC) [5].As one of the problems of F2F features is a significant number of outliers in some situations, carrying out the F2F filtering as an extra step provides an opportunity to use the motion estimates output by the LR filter to prune the F2F outliers before performing the F2F filtering.Most importantly, the measurements in the separate filtering stage (F2F features) provide only a partial observation of the state vector. In this paper we show that this fact can be exploited in order to reduce the cost of the F2F filtering by two orders of magnitude.The cost of the extra filtering is initially cubic in the number of added F2F features and in the size of the filtered state vector. Two aspects are exploited to reduce this cost. First, the noise vectors in different F2F features are assumed to be statistically independent and hence their covariance matrix is block diagonal (this assumption is usually taken by most SFM techniques and is considered to be realistic enough even if it is not a very accurate model of the real noise). Second, the F2F features provide a partial observation of the state vector and hence affect directly only a small part of this vector, which is the camera velocity and its global rotation. Their effect on the other components of the state vector comes about only through the covariance matrix of the state vector. To capitalize on this fact, the proposed system first updates only the velocity and global rotation estimates using F2F features, then spreads the update to the other components of the state vector using the covariance matrix of the state vector. By using the Sherman–Morrison–Woodbury formula for inverting sums of matrices [7], the update of the velocity can be performed with linear cost in the number of F2F features. The propagation of the update to the other components of the state vector is independent of the number of F2F features.It is important to mention here the relation to another category of SFM approaches based on parallel tracking and mapping [12,13,17,30]. Those approaches use two processing phases often performed in two concurrent threads, a front-end used to track the camera between key-frames and a back-end used as global optimizer, mostly via some kind of bundle adjustment over a fixed number of frames. Those approaches have been shown [29] to outperform filter based approaches especially when the camera stays most of the time in the same environment and when the computational resources are not scarce. However, in many scenarios, filter based approaches are the better choice. Examples of such scenarios are in tracking applications when the computational resources are scarce such as on embedded systems and when integrating with other sensors or with already existent systems. Furthermore, filter based approaches could be used as the front end tracking system in parallel tracking and mapping approaches.Another related approach that uses both short and long baselines and exploits the fact that matching across frames taken from very close viewpoints leads to a large number of good matches, is the Dense Tracking and Mapping (DTAM) [18] approach. This approach uses a number of frames in the vicinity of a key-frame to build a dense map. All the pixels in those frames are matched and the reliability is achieved by the large number of frames considered within the short baseline and via spatial regularization performed with the aid of a GPU. The tracking between key-frames is performed by determining the motion that minimizes the difference between the projected map and the next key-frame.The remainder of this paper is structured as follows. Section 2 introduces the problem, notations and formulations. Section 3 presents a high level description of the proposed solution. Section 4 addresses the problem of complexity reduction. Finally, Section 5 highlights the improvements obtained by applying the proposed approach via corresponding experimental results.Consider a 3D camera moving in a scene and making repetitive observations of a set of 3D points (features). As shown in Fig. 2, some of the features,Pi,i=1,…,N, are assumed to be observed by the camera at every time step (LR features), while others,Qj,j=1,…,K, are only observable in two adjacent positions.The following notational conventions are assumed in formulating this estimation problem. The transpose of a column vectorVis written asV′and its corresponding normalized version asV^. The covariance matrix of a vectorVis denoted asΣ(V). The Jacobian of a functionh(V)with respect to the vectorVis represented asJ(h,V). The notationI(N)is used to denote an N-dimensional identity matrix.Two coordinate frames of reference are used. A fixed world coordinate frame and a camera-tied frame. Vectors represented in the world coordinate frame are superscripted by a w (for exampleTw). Similarly vectors represented in the camera frame are superscripted with ac(for exampleTc). The camera pose in the world frame consists of a rotation represented by a quaternionqw(unit 4-vector) and a translation vectorTw. The rotation matrix corresponding to the quaternionqis denotedR(q)and is given by:(1)R(q)=1-2q22-2q322q1q2-2q0q32q1q3+2q2q02q1q2+2q0q31-2q12-2q322q2q3-2q0q12q1q3-2q2q02q2q3-2q0q11-2q12-2q22.The velocity or instantaneous motion of the camera consists of an angular velocity vectorωw(angle-axis representation) and a translational velocity vectorVw(Fig. 3). The rotation matrix corresponding to the angular velocity vectorωis denotedR(ω)and is given by Rodrigues’ formula:(2)R(ω)=I+sin(|ω|)[ωˆ]×+(1-cos(|ω|))(ωω′-I),where[ωˆ]×is the skew symmetric matrix corresponding toωˆ. The relation between the camera velocity (Vw,ωw) in the world frame and in the camera frame is expressed as follows:(3)Vc=R(qw)′Vw,andωc=R(qw)′ωw,where the prime on the Rotation matrix stands for its transpose.A 3D pointPwin the world frame is transformed into camera frame by the equation:(4)Pc=R(qw)′(Pw-Tw).A point observed by the camera at positionQtcat time t will be observed at positionQt+1cat timet+1:(5)Qt+1c=R(ωtc)′(Qtc-Vtc)=R(R(qtw)′ωtw)′(Qtc-R(qtw)′Vtw).Note that the last equation involves not only the velocities(Vw,ωw)but the global rotationqwlikewise. Assuming a calibrated camera and a pin-hole perspective projection model, the camera observes the projections on the image planepcandqcof the LR featurePcand the F2F featureQcrespectively. Those projections are given by:(6)pc=P0cP2cP0cP2c1,and(7)qc=Q0cQ2cQ0cQ2c1.The goal of the SFM problem is to estimate the motion of the sensorTw,qw,Vwandωwin addition to the 3D positions of the LR featuresPiwfrom the projectionspicandqjc.The measurement model describes how the observed values (picandqjc) are related to the 3D unknown parameters.For the LR features, substitutingPicin Eq. (6) by its value from Eq. (4), gives directly an expression ofpicin terms of the 3D parameters.For the F2F featuresQtcandQt+1cat times t andt+1, only their projections are observed and matched. Therefore, the unknown depth of these features has to be eliminated in order to obtain a constraint that links the incremental motion between t andt+1to the F2F correspondences. The choice of the approach taken to get rid of the depth is crucial for the correctness of the estimation. For example, using an error measure based on the simple epipolar constraint(qt+1c)′Eqtc=0, whereEis the essential matrix, introduces a bias in the estimates because the error(qt+1c)′Eqtcis an algebraic error whose value depends on the actual values ofqt+1candqtcin contrast to the true geometrical error which depends only on how far away from their true valuesqt+1candqtcare. To alleviate that, many approaches have attempted to provide an approximation of the true geometrical error. For instance, Torr and Murray [32] used Sampson’s approximation to obtain a first-order approximation of the geometric epipolar error. Kanatani and Sugaya [11] pointed out that Sampson’s approximation is so good that the difference is only in insignificant digits. Oliensis [19] derived an optimal expression of the exact geometrical error that is exactly equivalent to the full error equation without depth elimination. UsingV,R,q0andq1to refer toVc(T),R(ωc(t)),qtcandqt+1crespectively, the Oliensis optimal error can be expressed as:(8)e=a2-a24-b,a=qˆ0′(I(3)-V^V^′)qˆ0+qˆ1′R(I(3)-V^V^′)V′qˆ1,andb=(V^′(qˆ0×R′qˆ1))2.Note that b in the above expression is the same as the regular epipolar error. Combining this error function with (3) leads to an expression of the error in terms of the camera motion in world coordinates of the form(9)e(qw,Vw,ωw,qtc,qt+1c)=0.Stacking all the F2F features at time t in the vectorZtf2fresults in an multi-dimensional measurement equation of the form:(10)h(qw,Vw,ωw,Zf2f-nf2f)=h(S,Zf2f-nf2f)=0,whereSis the state vector of parameters to be estimated:(11)S=[Tw;qw;Vw;ωw;P1w;…;PNw],andZtis the vector of observations at time t:(12)Z=[P1,tc;…;pN,tc;q1,t-1c;q1,tc;…;qK,t-1c;qK,tc].nf2fis a Gaussian vector representing the noise in the observation vectorZf2f.The estimation of structure and motion can be cast within a dynamic system framework formulated as follows:(13)St+1=f(St)+nts,h(St,Zt-ntz)=0.The function f expresses the time evolution of the state vector:(14)Tt+1w=R(ωtc)Ttw+Vtc,qt+1w=q(R(ωtc)R(qtw)),Vt+1w=R(ωtc)Vtw,ωt+1w=R(ωtc)ωtw,andPi,t+1w=Pi,tw.The functionhrepresents the relation between the state vectorSand the measurement vectorZand can be derived by stacking the measurement equations of the LR and F2F features described in Section 2.1. Note that the measurement equation is written ash(St,Zt-ntz)and not in the more common formZt=h(St)-ntz. This is because Eq. (9) has this form which is often referred to as implicit form [25] and has important implications on the filtering as will be discussed below. Finally,nsis random zero mean Gaussian vector that represents the uncertainty in the evolution of the system andnZis Gaussian zero mean vector that represents the noise in the sensor observation.The dynamic system in Eq. (13) can be solved recursively starting from an initial state at time 0 and then using some recursive filter in order to obtainSt+1andΣ(St+1)fromStandΣ(St). The de facto Extended Kalman Filter (EKF) cannot be used directly in such a case because the measurement equation is implicit as mentioned earlier. Therefore, a modification of this filter has to be performed to account for this fact. The regular EKF equations to updateSare as follows:(15)Λ=J(h,S)Σ(S)J(h,S)′+Σ(nz),L=Σ(S)J(h,S)′Λ-1,Γ=I-LJ(h,S),S+=S+L(Z-h(S)),Σ(S+)=ΓΣ(S),where (Z-h(S)) is called the innovation (or residual),Λis called the innovation covariance andLis the gain. When the measurement equation is implicit as in (13), the above equations cannot be used directly any longer. Implicit equations arise in many sensing applications. Soatto et al. [25] derived a solution for the Extended Kalman Filtering with implicit measurements based on a first order Taylor expansion of the implicit equation. Steffen [28] used a similar expansion to derive an iterative filter which is essentially equivalent to linear least squares. Adopting a similar first order linearization technique, the following changes are to be made in order to maintain the correctness of the filter:1.The innovation is expressed ash(S,Z)instead of(Z-h(S)).The effect ofΣ(nz)on the innovation covariance is no longer additive but acts via the non-linear equationh. Therefore its contribution to the innovation covariance can be approximated asJ(h,Zz)Σ(n)J(h,Z)′.The gainLexpression needs to be multiplied by-1becauseZandSare on the same side of the equation.In fact, the covariance update equation in (15) is a reduced form of the following equation:In the implicit case, the reduction can no longer be done as in this caseΣ(nz)has to be replaced byJ(h,Z)Σ(nz)J(h,Z)′.The modified equations can be applied to the dynamic system in Eq. (13) to provide an estimate ofStat each time step t.Applying the IEKF filtering as presented in Section 2 induces two problems: first, because (10) is implicit, the procedure of adding F2F features is different for different filtering techniques. Second, the computational cost is too high for real-time processing. This paper proposes to solve these two problems by separating the filtering with the F2F features from the main filter using the LR features (Fig. 4). Such a scheme allows the use of IEKF filtering for the F2F features regardless of the type of filtering used for the LR ones. Furthermore, it provides more potential for the reduction of the computational cost as will be shown later. In the remainder of the paper, the notationsS1andS2will be used to represent the following sub-vectors ofS.(17)S=[S1;S2],S1=[Tw;Piw,…,PNw],andS2=[qw;ωw;Vw].The dimension ofS1is3N+3(3 parameters for the translation and3Nfor the structure). The dimension ofS2is10. The covariance matrixΣ(S)would then consist of the following sub-matrices:(18)Σ(S)=Σ(S1)Σ(S1,S2)Σ(S2,S1)Σ(S2).Separating the LR filtering from the F2F filtering (Fig. 4) relieves us from any concerns regarding the nature or mode of operation of the LR filter. The only assumption made about the LR filter is that it should output at every time step a mean vector and a covariance matrix for the state vector. No restriction is even placed on the order of the parameters in the state vector or on the representation of the rotations in it. The first step of the proposed F2F filter, re-orders the 3D parameters and their covariance matrix to ensure they are in the form[S1;S2]described above.The outliers in the LR filtering are assumed to be the responsibility of the LR filter. For the F2F features, the outliers are detected using the estimates ofVcandωcand their covariance matrix that can be derived from the output of the LR filter using Eq. (3). For each feature, the error expression (8) and its variance are evaluated using the mentioned estimates ofVcandωcand their covariance matrix. If the error is greater than 1.5 times the variance, the feature is considered to be an outlier and not used in the filtering.WhileStandΣ(St)represent the output of the main filter at time t, the output of the extra F2F filtering step will be superscripted with a+. The implicit filtering is applied only to the F2F measurement equations (Eq. (10)) and the update equations can be written as follows:(19)Λ=J(h,S)Σ(S)J(h,S)′+J(h,Zf2f)Σ(nf2f)J(h,Zf2f)′,L=-Σ(S)J(h,S)′Λ-1,Γ=I(N)-LJ(h,S),S+=S+Lh(S,Z),andΣ(S+)=ΓΣ(S)Γ′+LΣ(nf2f)L′.In the remainder of this paper the matrixJ(h,Zf2f)Σ(nf2f)J(h,Zf2f)′which represents the uncertainty in h due to the uncertainty in the F2F features will be referred to byΣh(nf2f).The expressions ofJ(h,S)andJ(h,Zf2f)are:(20)J(h,S)=∂hS,Zf2f∂S,J(h,Zf2f)=∂hS,Zf2f∂(Zf2f).The matrixJ(h,S)has a dimensionality ofK×(3N+13)where K is the number of F2F features. It consists of two parts: the first one with sizeK×(3N+3), corresponds to the Jacobian of h with respect toS1and is all zeros; the second part is the Jacobian matrix of h with respect toS2and which is aK×10matrix. Therefore only this non-zero part needs to be computed and stored and its derivation is done using the chain rule:(21)J(h,S2)=∂h∂S2=∂h∂([Vc;ωc])∂([Vc;ωc])∂([qw;Vw;ωw]),wherehis the vector of errors defined in (10). The individual Jacobians in the above formula are computed using Maple software. The matrixJ(h,Zf2f)is block-diagonal where every block is a1×4row vector containing the 4 elements of∂h∂[x(t);x(t+1)]. The matrixΣh(nf2f)=J(h,Zf2f)Σ(nf2f)J(h,Zf2f)′is aK×Kdiagonal matrix representing the uncertainty in h due to the uncertainty inZf2f. Its computation can be done inO(K)time since bothJ(h,Zf2f)andΣ(nf2f)are block-diagonal matrices, and only corresponding blocks are multiplied together.The computational cost will be reported as the number of FLoating-Point Operations (FLOPS). It is assumed that the computations are performed on Pentium 4 or Pentium M generation of processors on which a division is carried out in 8 FLOPS and the log operation 20 FLOPS. Also, it is assumed that the LU method is used for matrix inversions. Under these assumptions, the inversion of aK×Kmatrix requires3K3+125K2+0.5K-8FLOPS. Also in this section, the notation N is used to represent the total number of parameters in the state vector (i.e., forNtLR features, the total number of parameters in the state vector would beN=3Nt+13). The reported processing times are achieved on a linux machine with a Pentium M 1.6GHz processor and 3GB of RAM.The cost of directly evaluating (19), denotedc0(N,K), will be used as a baseline for comparison. The breakup of the total number of FLOPS involved in evaluating (19) is shown in Table 1. Note thatLis computed using the sameΣ(S(t))J(h,S(t))′that is determined when evaluatingΛ. The total costc0(N,K)is not only cubic in the number of added F2F features(K)but also in the number of parameters in the state vector N and its computational complexity isO(K3+N3+KN2+K2N). Two aspects of the system (19) can be exploited to reducec0(N,K):1.The noise vectors in the F2F features are statistically independent which means that their covariance matrix is diagonal. This allows the use of matrix inversion identities to manipulate the update equations in such a way that most of the costly operations such as matrix inversions and multiplications involve mostly diagonal matrices and matrices with lower dimensions (N instead of K). This leads to significant computational savings especially in the case where the state vector dimension is much smaller than the number of F2F features such as when performing the update of the velocity vectors only.The partial observability of the state vector given the F2F features: since the F2F features measurement equation involves only the partS2ofS, the Jacobian of h with respect toSis aK×Nmatrix with only the last 10 columns non-zero. This aspect can be capitalized on in one of two ways. (1) Algebraically, which involves analytically evaluating all the implications of the zero blocks in the computations and skipping the explicit evaluation of the pertinent operations. It also involves rearranging the expressions in such a way that the effect of skipping the zero-blocks operations is maximized. This procedure will be referred to as Zero-blocks Skipping. (2) Statistically, by updating at first only the translational and rotational velocities to incorporate the F2F information, then the rest of the state vector is updated based on its correlation with the velocities.The two considerations above can be therefore exploited in three possible ways:1.Algebraically manipulate the filtering equations to capitalize on the statistical independence of the features – referred to subsequently as Procedure I – followed by the zero-blocks skipping procedure (Section 4.1).Algebraically manipulate the equations to capitalize on the statistical independence of the features while simultaneously taking into consideration the zero-blocks – referred to subsequently as Procedure II – (Section 4.2).Update in a first step, only the 10 observable elements (S2) of the state vector. This partial filtering can be performed very efficiently and in time linear in K using Procedure I with the special case of N=10. Afterwards, propagate the update to the other non-observable elements (S1) of the state vector (Section 4.3).Table 2recapitulates those three possibilities along with the computational complexity of each one. The approach based on partial filtering followed by update propagation possesses the lowest computational complexity and is thus adopted in this paper. The remainder of this section starts with a description of Procedure I since it is used in the adopted approach. Then the computational performance of Procedure II, whose description is provided in Appendix A for the interested reader, is discussed. Finally, the partial filtering/update propagation approach is presented.The method presented here is general enough to be applied to any Kalman filtering system where the dimension of the state vector is smaller than the dimension of the measurement vector, and where the noise vectors in the elements of the state vector are statistically independent. As the K F2F features are independent observations, updating the state vector using the K features at once is equivalent to performing K consecutive updates using one feature at a time. Hence, the update procedure can be modified to be linear in K. However, resorting to a series of single-feature updates is not a good strategy for that purpose as the cost would still be computationally intensive since it would involve anO(KN3)term. Nevertheless, as shown in the following, through using the inversion of sum of matrices identities and capitalizing on the fact thatΣh(Zf2f)is diagonal, the filtering can be performed with a computational cost that is linear in K and that involves an11N3term instead ofKN3. Central to this reduction procedure is the Sherman–Morrison–Woodbury identity [7]:(22)(A+UBV)-1=A-1-A-1U(I-1+VA-1U)-1VA-1,whereA,U,BandVall denote matrices of the correct size. Using this identity the expression of the matrixΛ-1can be modified as follows:(23)Λ-1=(Σh(Zf2f)+J(h,S)Σ(S)J(h,S)′)-1=[Σh(Zf2f)]-1-[Σh(Zf2f)]-1J(h,S)I(N)+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)-1Σ(S)J(h,S)′[Σh(Zf2f)]-1.Note that this inversion is useful only because the measurements are independent and henceΣh(Zf2f)is diagonal and can be inverted in only K divisions.Lcan hence be re-written as:(24)L=-Σ(S)J(h,S)′[Σh(Zf2f)]-1-[Σh(Zf2f)]-1J(h,S)I(N)+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)-1Σ(S)J(h,S)′[Σh(Zf2f)]-1=-Σ(S)J(h,S)′[Σh(Zf2f)]-1+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)I(N)+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)-1Σ(S)J(h,S)′[Σh(Zf2f)]-1.LetG0andG1be the two matrices:(25)G0=Σ(S)J(h,S)′[Σh(Zf2f)]-1,andG1=Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)=G0J(h,S).Σ(S)J(h,S)′is a multiplication of aN×Nmatrix by aN×Kmatrix and can be done in2N2K-NKFLOPS. Multiplying the resulting matrix by[Σh(Zf2f)]-1requires only NK FLOPS as[Σh(Zf2f)]-1is diagonal. The inversion ofΣh(Zf2f)requires8KFLOPS. Therefore,G0can be evaluated in2N2K+8KFLOPS.G1can then be carried out in2N2K-N2FLOPS.With the above notations,LandLJ(h,S)can be re-written as:(26)L=(G1(I(N)+G1)-1-I(N))(G0),andLJ(h,S)=(G1(I(N)+G1)-1-I(N))(G1).The reason for writingLJ(h,S)this way is that it can be computed much faster than multiplyingLbyJ(h,S). The numbers of FLOPS of each of the operations involved in the update before and after considering the zero-blocks in the matrices are shown in Table 3.To evaluate the computational speedup, the ratioc0(N,K)c2(N,K)is evaluated for different values of N and K. Fig. 5shows the corresponding results. When K is high relative to N a considerable speed-up is achieved. For the case of K=500 and N=88 (corresponding toNt=25LR features), the speed-up is32.3times and the computation takes about 165ms. However the speed-up tapers off quickly as the ratio K/N decreases. For example, for 50 LR features (N=163) andK=200F2F features the speed-up is only3.2times. The efficiency increases cubicly when K increases for constant N. The increase is more pronounced when N is small, for example forN=6andK=200the speed-up is about188.36times.Another way to exploit the zero-blocks in the Jacobian of h with respect toSis to consider the effects of these zero-blocks simultaneously while performing the algebraic manipulation of the update equations that is carried out to capitalize on the features independence aspect. The details of such procedure are provided in Appendix A and the reduced computational cost isc3(N,K)=25N2+2KN2+94NK-19N+800K+17177. For the case of K=500 and N=88 (corresponding toNt=25LR features), the speed-up of Procedure II is39.4which is slightly higher than the speedup ofc2. However, for 50 LR features (N=163) andK=200F2F features, the speed-up is6.86which is more than twice the speedup ofc2.Instead of skipping the operations involving zero-blocks, this section introduces a totally different approach to capitalize on the partial observation aspect. The F2F features only affect directly the sub-vectorS2ofS. The other parameters are only affected through their covariance withS2. Therefore,S2can be updated first, then the covariance matrix ofScan be used to propagate the update toS1. The flowchart of the proposed filtering method is shown in Fig. 6and three steps involved are described in the following.The dimension of the state vector in this case (S2) is only 10. Therefore, Procedure I presented in Section 4.1 is adopted as it results in a cost linear in K and quadratic in the dimension of the state vector which is just 10. This results in a filteredS2+that can be computed with a cost of11887+818KFLOPS.Since the F2F features do not provide an observation of the magnitude ofVw, the F2F filtering should not change this magnitude. Therefore, any offset that might occur to the magnitude ofVwduring the update must be eliminated. Letρrepresent the ratio of the magnitudes ofVwandVw+:(27)ρ=‖Vw‖‖Vw+‖,then, after the update,Vw+is multiplied byρ,Σ(Vw)byρ2andΣ(Vw+,[qw+;ωw+])byρ. The total cost of this operation is 1140 FLOPS.After updatingS2, the information acquired from the F2F features is propagated toS1. This is done using the covariance matrixΣ(S)which acts as a string probabilistically connectingS2andS1, through the covarianceΣ(S1,S2). Schurr complement and conditional probability identities allow to determineS1+and its covariance as follows (See Appendix E in [15]):(28)W=Σ(S1,S2)Σ(S2)-1,S1+=S1+W[S2+-S2],Σ(S1+,S2+)=WΣ(S2+),andΣ(S1+)=Σ(S1)-W[Σ(S2)-Σ(S2+)]W′.The cost of this update can be evaluated as11N2+391N-500FLOPS given thatΣ(S1,S2)is anN-10by 10 matrix.The costs of the all the operations involved in the partial filtering/update propagation approach are shown in Table 4. The total cost is linear in K and quadratic in N. The speed-up with respect toc0is shown in Fig. 7. This figure shows that the speed-up is dramatically larger than the methods presented in the previous sections. For the case(K=500,N=88)the speed-up is909.43times. For the case of 200 F2F features and 50 LR features(K=200,N=163), the speedup is187.44times and the time required is about 7ms. Another important thing about this method is that starting from a moderate value of N (for Example130 which is equivalent to 39 features) the main computational cost would be due to the N terms. Hence, K can be increased significantly while incurring a low increase in the total cost. Fig. 8shows the increase of the cost for N fixed to 130 while increasing K from 100 to 2000. The cost for includingK=1000F2F features is only 3.47 times larger than the cost needed for 100.The purpose of this section is threefold. Firstly, it aims to show that F2F features can improve SFM estimation in real world situations while taking care of outliers and such. Secondly, it illustrates how easy and straightforward it is to augment an already existent filter with an implementation of the proposed approach. And thirdly, it confirm the validity of the cost reduction results presented in Section 4.3. Towards this, two sets of experiments are performed. First a set of simulation experiments are conducted to validate that the proposed partial filtering approach does work and the linear cost. Then, the proposed approach is integrated within the SceneLib1.0 software, which is an implementation of Davison et al.’s monocular SLAM system [2]. The improvement achieved is assessed on real data with ground truth camera and via comparison against the results of KinectFusion [9] as implemented in PCL [23].This subsection provides simulation results that compare the results of a straightforward implementation of an EKF SFM filter, with the results that can be obtained by the addition of the F2F extra update step performed as in Section 4.3 to the same filter. The simulation data was created as follows. 50 3D points are generated randomly within a cube of size4m3centered at(0,0,5m)(the units are not really relevant but “meters” are used to better illustrate the extent of the errors in the results). Then a sequence of random motions are applied to a virtual camera in such a way that it is always fixating at the centroid of the cloud. For every motion in the sequence, zero-mean Gaussian noise with different variances is added to the projections of the 3D points on the corresponding camera frame to obtain the LR measurements. Also, at every frame another random cloud of K points with the same dimensions is generated, and its projections on the last two frames (augmented with noise) are used to simulate the F2F features.The results presented below correspond to the average of 50 runs with different levels of noise and different LR and F2F data. On an Intel Pentium M 2.13GHz with a C++ implementation, the average time required to perform the update given 200 F2F features is about 8ms. For 900 features the average time is about 32ms and for 1700 features about 46ms. This is in line with the theoretical linear cost discussed earlier.The error in the translation and translational velocity is determined as the angle in degrees between the true and estimated directions. The error in rotation is taken asRR^′-I(3)whereR^is the estimated motion andRis the true rotation. This error combines both the error in the axis of rotation and in the magnitude of rotation. In the case where the two compared rotations are about the same axis, this error represents the difference in radians between the two rotations. That is why radians is used as a unit for this error. The error in rotational velocity and 3D feature positions is taken as the Root Mean Square (RMS) error between the true and estimated vectors. We also look at the re-projection errors of the last estimate of the 3D features in all the previous images. The mean values of those errors for the 50 runs are shown in Figs. 9–14respectively.Both the rotation and translation errors are reduced by almost half when using the F2F features. For the translational and rotational velocities, not only are the errors in general smaller, but the error profiles are smoother and exhibit fewer spikes. This is due to the fact that with LR features only, the system infers the values of the velocities from the differences in translation and rotation estimates between successive states. With F2F features, the system uses actual incremental measurements. Having better velocity estimates is very important for many applications such as autonomous vehicles and others. The depth error as well is significantly reduced. The improvement in the3Dparameters accuracy is reflected in a reduction of the re-projection error as shown in Fig. 14.In this section, the F2F update procedure as described in Section 4.3 is used to augment Davison et al.’s SceneLib1.0 Monoslam system [2]. The F2F filtering was coded in a separate package with a single interface that can be used as follows in any filter that maintains a state vector “V” and its covariance “Cov” (assumed to be as -or convertible to- float pointers).F2FFilter*f2ff=newF2FFilter(Cx,Cy,fx,fy,width,height,max_num_f2ff);f2ff→filter(V,Cov,image).The max_num_f2ff parameter is the maximum number of F2F features that the system should attempt to detect and match between every two consecutive frames. Note that the number of actual features used at each frame is always lower than this because many of the features are pruned as outliers.To use this F2F interface to add F2F filtering capabilities to SceneLib1.0, a little additional coding has been done in order to have an extra button in the graphical interface to toggle the F2F filtering ON and OFF as shown in Fig. 15.In a first set of experiments, test sequences from the RGB-D SLAM Dataset of the CVPR group at TUM [31] are used to evaluate the improvement that the proposed approach can bring about to the SceneLib1.0 system. This Dataset consists of sequences of RGB and depth images captured with a handheld Kinect sensor. The ground-truth trajectory of the sensor was obtained from a high accuracy motion capture system with eight high-speed tracking cameras (100Hz). Static and indoor sequences from this Datasets were selected. Fig. 15 shows a frame from one of the used sequences inside the graphical interface of the modified SceneLib1.0 software.The F2F features are detected with the FAST feature detector [22] and tracked using the opencv pyramidal implementation of the KLT tracker [1]. Davison et al.’s Monoslam system requires 4 known world points to be used as anchor points to fix the world reference frame. For each experiment performed, 4 anchor points were selected from the sequence used in that experiment. The depths of those points were determined from the Kinect depth view of the first image and then projected to the world coordinate frame using the ground-truth of the first camera pose. Davison et al.’s system uses active feature matching and attempts to keep at least 12 LR features visible per frame. Whenever the number of visible features drops below 10, new features are automatically initialized using the Particle Filtering approach presented in [2]. The total number of LR features was 20 on average.In each experiment the original and the F2F augmented filters were run on the corresponding sequence until the anchor points disappear from the field of view. Each experiment spanned between 150 and 300 frames. On the mentioned computer system, for 100 F2F features, the feature detection and matching takes about 10ms. Out of the 100 features, the average number of selected inliers was around 70. The computation of the Jacobian matrices for the average case takes about 4ms and the F2F filtering about 3ms. Therefore, the total cost incurred by the F2F augmentation is less than 20ms.The performance of the F2F augmentation exhibited many variations. Table 5shows the average and standard deviation of the rotation and translation errors with the respect to the ground truth. The rotation errors are computed as in Section 5.1.1. Figs. 16 and 17show the translation and rotation errors for a typical experiment. Fig. 18shows the ground truth and estimated trajectories.The following observations were noted. In almost all the sequences, the filtering with F2F features lead to more accurate results than the original system. In rare cases, adding the F2F features resulted in slightly lower accuracy. This happens mostly in scenes where a significant portion of the frames in the sequence exhibit the two-frames bas-relief ambiguity situation [16]. A way to cope with this is to randomly divide the F2F data at each frame into multiple sets and perform the partial filtering step Section 4.3.1 on each set individually. If the change in the camera velocity across the different sets is above a certain threshold, the F2F filtering at the concerned frame is dropped.Another important observation is related to the number of the F2F features employed. In general, a trend of increased accuracy with increased number of F2F features was observed. However, this trend was not very consistent. One explanation for this is that the KLT implementation employed ranks the matched features in order of best matching score. Therefore, for a given frame, the first K returned F2F features by this matcher have a higher likelihood of being inliers and are “higher quality” matches than any further features obtained by this matcher.In another set of experiments, KinectFusion [9] was used to track the motion of a Kinect camera and reconstruct the scene from a set of RGB-D images. The resulting camera motions were used as a pseudo-ground truth to further assess the effect of F2F filtering. Two sequences of 2100 frames each were reconstructed using KinectFusion. Fig. 19shows a snapshot of the reconstructed scene corresponding to the first sequence.Figs. 20–23show the errors of the Monoslam estimation, in both LR only and LR+F2F modes, versus the estimates of Kinect Fusion for the two considered sequences. In the first sequence, the camera repeatedly moves away from the anchor points (known features) used in Monoslam and then comes back which explains the zigzag pattern in the error. In the second sequence, the camera sees the anchor points only at the beginning of the sequence and then moves away from them which explains the increasing error pattern. An important thing to notice in those plots is that, whenever the LR error increases, the F2F augmented filter manages to keep a significantly lower error. Similarly in the second sequence, error accumulates at a much slower rate with the F2F filtering. When the LR filter error is low, the estimates with and without F2F filtering are similar. This is a natural and expected behavior because in this case, the F2F features do not carry a lot of extra information about the motion over what’s obtained from the LR features.The bottom line observation is that the increase in accuracy obtained, combined with the low computational cost and the ease of integration with different implementation, makes the use of the proposed approach well worth it in any analytic filter.

@&#CONCLUSIONS@&#
This paper presented an approach to efficiently incorporate the information from F2F features in analytical SFM filters. The approach can be applied to any filter as long as it maintains a mean vector and a covariance matrix of the estimates. Furthermore, the filtering is accomplished through an extra filtering step that requires virtually no coding change in the filter to which the F2F information is added. It is computationally economic with the ability to accommodate hundreds of F2F features in real time. The presented experimental results showed a significant increase in the accuracy of the structure and motion estimates.The presented approach, although designed for filter based SFM, can be also used to augment non-filter based approaches such as the Parallel Tracking and Mapping (PTAM) approach [12] since this latter performs a non-linear optimization and maintains a Gaussian distribution of the estimates.The presented solution also extends naturally to any types of F2F measurements other than point-wise features. For example, curves and edges can be used as long as one can formulate a measurement equation relating those F2F measurements to the camera velocity. Determining what type of features is suitable for every situation is a subject of future work.Also another extension of this work is to consider features spanning three frames instead of F2F features. In this case, an algebraic three frames constraint such as the trifocal constraint is used. A main advantage of using three frames is that the relative translation magnitude would be observable.Going back to the expression ofLas determined in (24), letG3andG4represent the two matrices:(A.1)G3=[Σh(Zf2f)]-1J(h,S),andG4=Σ(S)J(h,S)′=[Σ(S1,S2);Σ(S2)]J(h,S2)′.G3has both the same structure and dimension asJ(h,S). Therefore, only the non-zero block of it which is equal to[Σh(Zf2f)]-1J(h,S2)needs to be computed. We refer to this part asG2. The computation ofG2requires only10KFLOPS sinceΣh(Zf2f)-1isK×Kdiagonal. The computation ofG4can be carried out in19NKFLOPS. With the above notation,I(N)+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S)-1in the expression ofLcan be written as:(A.2)I(N)+Σ(S)J(h,S)′[Σh(Zf2f)]-1J(h,S))-1=I(N)+[Σ(S1,S2);Σ(S2)]J(h,S2)′(G3)-1.The idea here is to manipulate the equations so that costly operations such as inversions and matrix multiplication are performed mostly on10×10matrices and diagonal matrices. Using another variant of the Sherman–Morrison–Woodbury formula which was introduced in [6] and which expresses the inverse of a matrix of the form(A+UBV)as:(A.3)(A+UBV)-1=A-1-A-1U(I+BVA-1U)-1BVA-1,(A.2) becomes(A.4)I(N)+[Σ(S1,S2);Σ(S2)]J(h,S2)′(G3)-1=[I(N)]-1-[I(N)]-1[Σ(S1,S2);Σ(S2)]I(10)+J(h,S2)′(G3)[I(N)]-1[Σ(S1,S2);Σ(S2)]-1J(h,S2)′(G3)[I(N)]-1=I(N)-[Σ(S1,S2);Σ(S2)]I(10)+J(h,S2)′(G3)[Σ(S1,S2);Σ(S2)]-1J(h,S2)′(G3).Recalling thatG3has the same form asJ(h,S)′with its non-zero block equal to[Σh(Zf2f)]-1J(h,S2), the matrixG3[Σ(S1,S2);Σ(S2)], referred to subsequently asG5, can be written in the form:(A.5)G5=G3[Σ(S1,S2);Σ(S2)]=[Σh(Zf2f)]-1J(h,S2)Σ(S2)=G2Σ(S2).G5is aK×10matrix whose computation usingG2requires190KFLOPS. SubstitutingG5by its value in (A.4) and usingG6to represent the matrixJ(h,S2)′(G5)which is a10×10matrix that which can be computed in200K-100FLOPS, (A.4) becomes:(A.6)(I(N)+[Σ(S1,S2);Σ(S2)]J(h,S2)′(G3))-1=I(N)-[Σ(S1,S2);Σ(S2)]I(10)+G6-1J(h,S2)′(G3).NowLcan be written as:(A.7)L=-G4[Σh(Zf2f)]-1-G3I(N)-[Σ(S1,S2);Σ(S2)](I(10)+G6)-1J(h,S2)′(G3)(G4)[Σh(Zf2f)]-1=-G4[Σh(Zf2f)]-1-G3-G3[Σ(S1,S2);Σ(S2)](I(10)+G6)-1J(h,S2)′(G3)(G4)[Σh(Zf2f)]-1=-G4[Σh(Zf2f)]-1-G3-G5(I(10)+G6)-1J(h,S2)′(G3)(G4)[Σh(Zf2f)]-1.J(h,S2)′(G3)can be expressed as:(A.8)J(h,S2)′(G3)=[010×(3N+3)J(h,S2)′(G2)]=[010×(3N+3)G7],withG7=J(h,S2)′(G2)which is a10×10matrix and010×(3N+3)is a zero matrix of size10×(3N+3).G7can be done in200K+100FLOPS. Therefore,G5(I(10)+G6)-1J(h,S2)′(G3)can be written as:(A.9)G5(I(10)+G6)-1J(h,S2)′(G3)=[010×(3N+3)G5(I(10)+G6)-1(G7)],and sinceG3=[010×(3N+3)G2]then(A.10)L=-G4[Σh(Zf2f)]-1-010×(3N+3)G2-G5(I(10)+G6)-1(G7)(G4)[Σh(Zf2f)]-1,and we have:(A.11)010×(3N+3)G2-G5(I(10)+G6)-1(G7)(G4)=[010×(3N+3)G2-G5(I(10)+G6)-1(G7)][Σ(S1,S2);Σ(S2)]J(h,S2)′=G2-G5(I(10)+G6)-1(G7)Σ(S2)J(h,S2)′,hence,Lcan be re-written as:(A.12)L=-G4[Σh(Zf2f)]-1-G2-G5(I(10)+G6)-1(G7)Σ(S2)J(h,S2)′[Σh(Zf2f)]-1.Note thatΣ(S2)J(h,S2)′[Σh(Zf2f)]-1is equal to(G5)′, andLcan be expressed finally as:(A.13)L=-G4[Σh(Zf2f)]-1-G2-G5(I(10)+G6)-1(G7)(G5)′.The sequence of operations to computeLis summarized as follows:G2=[Σh(Zf2f)]-1J(h,S2),G4=[Σ(S1,S2);Σ(S2)]J(h,S2)′,G5=G2Σ(S2),G6=J(h,S2)′(G5),G7=J(h,S2)′(G2),andL=-G4[Σh(Zf2f)]-1-G2-G5(I(10)+G6)-1(G7)(G5)′.The computation ofLrequires41NK-10N+200K+16977FLOPS. Table A.6shows the computational cost of all the operations involved in the update.