@&#MAIN-TITLE@&#
Efficient k-class approach for face recognition

@&#HIGHLIGHTS@&#
A novel k-class approach system for accurate face recognition is introduced.The system is fully automatic: every step in the system is automatically performed.The system does not take long time to recognize a picture from a large database.The system achieves high recognition rates of 96.9% for Rank 1 and 99.5% for Rank 10.

@&#KEYPHRASES@&#
Face detection,Face recognition,Recognition rate,Self-organizing-maps,

@&#ABSTRACT@&#
In this research work, a new k-class approach for efficient and accurate face recognition called kCAFRe is established. The kCAFRe system has three stages: preprocessing, training, and testing. In the training phase, four reference pictures (classes) are constructed for each person. During testing, the correlation coefficient (CC) is calculated between the picture under test and each of the reference pictures. For each person, one accredited class is chosen. Subsequently, the accredited class for the person with the highest CC is selected. Results were given for four image databases. A recognition ratio of 97% has been obtained for the Libor Spacek’s set.

@&#INTRODUCTION@&#
Face recognition is an important branch of biometrics, which does not need the cooperation of the test subjects to work properly. It is important for police and military purposes involving national and international security. For example, in pervasive computing, face recognition is used to support human memory like smart eyeglasses and wearable face recognition systems [1–3].Although face recognition has greatly advanced in the last few years, it still faces many challenges, such as dealing with faces in low-quality pictures or with inadequate lighting. Ideally, face recognition systems should address the following issues: (i) to deal with non-controlled environments, (ii) to consider databases containing multiracial faces, and (iii) to take into account aging effects [4]. Surface deformations caused by facial expressions represent another challenge in 3-D face recognition [5]. Therefore, more research efforts are still needed to leverage the realm of face recognition to higher levels. Recently, researchers have shown more interest in face recognition (aka identification) than face verification (aka authentication) [4].This work briefly reviews some of the most recent studies in the literature on this topic in order to help interested researchers find ongoing research on 2D and 3D face recognition and verification. Many studies have relied on Gabor-based methods for face biometrics including recognition and verification. Serrano et al. [4] divided Gabor-based methods for face biometrics into two categories: analytical and holistic. The graph-based [6–8] and non-graph-based [9–12] in addition to enhanced methods (using optimal Gabor parameters as well as Gabor and Adaboost) [13–16] are the most famous analytical methods. On the other hand, the holistic methods include downsampled Gabor [17,18] and [15], PCA/ LDA [19,20], kernel PCA/LDA [19] and [21], Gabor 2D methods [22–25], local binary patterns [26–28] and [8], and no downsampling methods [22,23].The authors of [29] represented each set of images as a subspace, applied a locally orthogonal method for subspace-to-subspace matching to improve accuracy along with online learning to reduce the computational cost. In the experiments of [29], a small video database was used and the achieved recognition rate was only 93.4%. In [26], the authors performed face identification and face verification on various databases including FERET, CAS-PEAL, CMU-PIE, Extended Yale B, and FRGC. Their proposed method for face recognition used local derivative pattern (LDP) based on high-order local derivative variations to encode directional pattern features. The reported recognition rates in [26] ranged from 78.9% to 97.9%. Nevertheless, the achievement of 97.9% recognition rate was only possible with the aid of manual alignment and cropping. The human face recognition proposed in [30] combined fast discrete curvelet transform (FDCT) and two-dimensional principal component analysis (2DPCA). The authors used FDCT as a feature extractor, while 2DPCA was applied to reduce the computational complexity. Complex wavelet moments (CWMs) can describe local and global characteristics of images, and therefore have been used by Singh and Sahan [31] as image descriptors for real-time face recognition. In their work, the authors used very large image sizes, performed experiments in part on a small database, and manually aligned and cropped images. The face recognition framework proposed in [32] integrates a local feature-based approach and a holistic approach.The authors of [33] proposed to use a margin-based between-class scatter and a regularization process based on the support vector machine (SVM) margins for feature extraction. The recognition rates of [32,33] were relatively not very high. Furthermore, manual alignment and cropping have been employed. In [34], particle swarm optimization (PSO) was proposed to simultaneously optimize the parameters of support vector machine (SVM) for face recognition. The authors of [35] proposed a locality Weighted Sparse Representation based Classification (WSRC) method for face recognition, where they considered the Sparse Representation based Classification (SRC) as a generalization of Nearest Neighbor (NN) and Nearest Feature Subspace (NFS). The authors of [36] enhanced face recognition by using image pre-processing techniques like resolution conversion, histogram equalization, and edge detection and proposed a method called Accelerated Binary Particle Swarm Optimization (ABPSO) for feature selection. As another approach, super-resolution (SR) methods can be used to reconstruct a high resolution image from single or multiple low-resolution images. In [37], a method based on dictionaries in high frequency wavelet subbands was proposed using super resolution for enhancing face recognition. The authors in each of the papers [34–37] relied on manual alignment and cropping in their work in addition to using very large image sizes.In [38], the authors used pseudo Zernike moments to extract features in their face recognition system. In [39], chain codes of face contours have been used for feature extraction. Lastly, the authors of [40] proposed combining Chi square and entropy for feature extraction and Chi square and entropy for classification. The authors in [38–40] relied on a small sample size (by using only part of the Libor Spacek’s database) and the reported recognition ratios were not very high.This paper is organized as follows: Section 2 introduces the proposed face recognition system, which consists of preprocessing, training, and testing. Next, in Section 3, the experimental results are provided and discussed. Finally, Section 4 concludes this paper.The proposed face recognition system is called k-Class Approach Face Recognition (kCAFRe), which is able of tackling k-classes. It consists of three major components (as illustrated by the block diagram of Fig. 1): the preprocessor, the trainer, and the tester. The details of each of these components will appear later in the coming subsections.The first step in kCAFRe is preprocessing. In this step, the faces of the images (if exist) are detected and cropped automatically. The output of this face detection sub step is usually faces with different sizes. Therefore, the next sub step of the preprocessor is resizing the detected faces to a common size. Then, all images are converted to gray images and divided into two subsets; training subset, and testing subset.The second step in kCAFRe is training. In this step, the training subset of the images is used to train a Self Organizing Maps (SOM) classifier, where there is a classifying model of certain number of classes for each person. All people models are used to test images in the testing subset in the next step.The final step of kCAFRe is testing. In this step, the testing subset of the images is tested for recognition using the classifying models created in the previous step. For each image under testing, there are different classes for each person in the database. The main feature that is used to decide the similarity to the testing image is the correlation. Therefore, the subclass that has the highest correlation value with the testing image is decided to be the recognition output.The preprocessor prepares input images for the next two steps: training and testing. For this, the preprocessor performs the following tasks using a MATLAB implementation:•Face detection: The face of the person in the input picture can be located anywhere inside that picture. This step locates and extracts faces from input pictures using the Viola and Jones face detection algorithm (VJFDA) for face cropping [41,42].Image size reduction: The training and testing steps need the subregion of the picture that contains the face (face cropping). The output of the previous step is the part of the original image (a rectangle) that contains the face after resizing to produce a picture of a standard size.Color-to-gray picture conversion: For the sake of portability, kCAFRe works on gray-scale pictures. Therefore, regardless of the color system of the input picture, the preprocessor always produces gray-scale pictures.The three main characteristics of a successful face recognition system are high recognition rates, high computational performance, and simplicity (which leads to an efficient implementation). kCAFRe has these characteristics as will be shown shortly. The image size reduction done by the preprocessor produces a fast face recognition system, because the trainer and the tester will operate on a lower number of pixels and, therefore, perform fewer processing operations. The size of an input picture i in pixels is (please refer to Table 1, that lists the symbols used in this study and their meanings):(1)Size(Picturei)=Wi×Hi.The output of the preprocessor is a picture of standard size given by(2)Picture size=Ẃ×H́,whereẂ≪WiandH́≪Hi. The reduction factor between the input picture i and the standardized image is(3)Reduction factor=Wi×HiẂ×H́.Assuming thatẂ=H́=A, Eq. (3) becomes(4)Reduction factor=Wi×HiA.In the jargon of neural networks, there are two techniques to train a network. The first one is the supervised training where each input pattern has a target and the network learns (changes its weights) to represent the relation between the input and the output patterns. The second training technique is the unsupervised training, where the network learns (changes its weights) to classify the input patterns without prior information [43].In this paper, our interest is in the unsupervised neural networks and especially in those which are based on competitive learning, where neurons compete to activate so that only one neuron (winning neuron) is activated at any time [43]. By this activation process, neurons organize themselves. Therefore, this kind of network is named “Self Organizing Map” (SOM). Fig. 2shows the two dimensional SOM structure [44].The main goal of a SOM is to adaptively perform a nonlinear transformation or mapping of data onto a one or two-dimensional map. In order to do so, the network has to train (change its weights) based on the following steps [43]:(1)Initialization: In this step, the connection weight vectors {wj, j∊[1,M], M is the number of neurons} of all neurons are initialized randomly.Sampling: In this step, an input pattern x is applied.Matching: In this step, the winning neuron i(x), is decided. The winning neuron is the one that has the weight vector closest to the applied input pattern. For this purpose, Euclidean distance is calculated.Updating: In this step, the weight vectors of the winning neuron and its neighbor neurons are updated based on the following equation:(5)Continuation: Return to step 2 and repeat until weights stop changing.Assuming thatNrepresents the total number of people in the database andPirepresents the number of available pictures forPersoni. If all persons have the same number of images i.e.(7)P1=P2=⋯=PN=P.Then, the total number of pictures available in the database can be calculated by(8)Database size=N×P.The set ofN×Ppictures is divided into two subsets: the training subset and the testing subset. The size of training subset is(9)Tr=f×N×P,wherefranges between 0% and 100%. The remaining pictures are used for testing, where the size of the testing subset is(10)Ts=(1-f)×N×P.In this work,f=65%; which means, 65% of the total images was used for training, and 35% was used for testing. The proposed kCAFRe face recognition system adopts a k-class approach. Therefore, the trainer builds for each person a number of reference pictures (classes)R, whereR⩽Tr. The total number of classes in the system is(11)C=N×R.The construction of each of the reference pictures is discussed next. TheTrpictures for each person are classified into R classes using SOM. In this work, the optimal value of R was found to be 4 empirically; for this number of classes, the recognition rate was found to be the highest. After classification, each class can have any number of pictures with the restriction that each class should have at least one picture. The reference picture of classkis the average picture of all the pictures that belong to classk. That is, the value ofPixeli,jwhere i andj∈[1,A]of referencekis(12)Pixeli,j(Reference Picturek)=∑l=1mPixeli,j(Picturel)massuming that classkcontainsmpictures. IfPixeli,j(Reference Picturek)is a non-integer value, then rounding toward nearest integer is applied.The reference pictures are constructed offline and kept in a separate database to be used in the testing phase.Given a test picture, the tester goes over each reference picture and calculates the CC featureφbetween the test picture and the reference picture using(13)φ=1A∑i=1A(IR(i)-mIR)(IT(i)-mIT)σIRσIT,whereIR(i)andIT(i)are the intensity values for pixel i in the lexicographically ordered vectors representing the reference and the test images, respectively. A is the number of pixels in the image,mIR,mIT,σIRandσITare the mean and standard deviation of the reference and test images, respectively.For each person, only one class is chosen (the class that has the highest correlation value). The chosen class is called accredited class. Finally, the person that has the highest correlation value of its accredited class is decided to be the recognition output. The operation of the tester is explained by Algorithm 1.Algorithm 1Testing a pictureThe specifications of the computer used in the experiments are as follows: PC with Intel Core 2 Duo CPU at 2.1GHz, 4GB RAM, and 64-bit Microsoft Windows 7 OS. The Libor Spacek’s Facial Images database [45] was used to evaluate kCAFRe. Libor Spacek’s set contains four databases with pictures of 395 female and male distinct multiracial people of different ages: faces94, faces95, faces96, and grimace, where the difficulty increases in order in these databases in terms of background and scale, and variation of expressions. For each person in these databases there exist 20 pictures of different poses and with various face expressions for a total of 7900 pictures. Some people in the database wear eyeglasses and some have beards. It should also be pointed out that these 7900 pictures have different lighting conditions. In this work, 7240 pictures have been used for 362 individuals from the databases. The purpose in this research is to propose a fully automated face recognition system. Therefore, any manual cropping has been avoided. The reason for not using all the available pictures is VJFDA for face detection and cropping. The total number of pictures that VJFDA was able to detect and crop was 7240 pictures for 362 individuals. Table 2lists the values of the various parameters used by the experiments that evaluate kCAFRe results.As shown in Table 2,f=0.65, therefore, for each person, 13 pictures will be used for training and the remaining 7 pictures are for testing. The pictures used in the training phase are picked at random. The 13 training pictures for an example person are shown in Table 3. These pictures are in their original format (before cropping or preprocessing), with an equal size 180×200 pixels. In Table 4, the pictures of Table 3 are shown in corresponding order after face detection using VJFDA and after automatic cropping. It is natural that these pictures differ in size because the location and size of the face varies from picture to picture. It has been noticed that the average face size captured by VJFDA was around 100×100 pixels. Table 5shows the pictures of Table 4 after resize to 25×25 pixels in the corresponding order. The four SOM class pictures calculated for this example person are shown in Fig. 3.In Table 6, the seven test pictures for the example person are shown. The first column depicts the picture’s name as shown originally in the database. The second column shows the original picture before preprocessing. The third column displays pictures after face detection using VJFDA and after cropping. The fourth column shows the picture after resize to 25×25 pixels. The fifth column shows the accredited class when testing that specific picture. The sixth column shows the number of the accredited class, and the last column shows the CC value between the picture under test and the accredited class. It can be noticed that for this example person the accredited class for all these seven test pictures happened to be class 4.The total time required to accomplish each of the major phases of this work is shown in Table 7. These times represent the elapsed times to process all the pictures in the database.As shown in Table 2, the total number of pictures used in the testing phase was 2534. kCAFRe was successful in correctly recognizing 2457 faces, which means a recognition rate of 97%. The time to test all the images was 28,733.72s. Which means the system would need about 11.3s to recognize any image among 2534 images. This time is quite comparable to other systems as will be shown in Section 3.The achieved identification rates of kCAFRe are shown in Fig. 4for Ranks 1–10. The achieved identification rates lie in the range 97–99.5%. Fig. 5shows the achieved verification rates of kCAFRe using false acceptance rates ranging from 0.001 to 1. The achieved verification rates range between 83% and 100%.In this part, kCAFRe is further investigated using another two similarity measures. The first one is Structural SIMilarity (SSIM) [46,47] and the second one is based on Fast Fourier Transforms. Below, a brief description of each of the two measures is provided with the achieved recognition rates when applying kCAFRe based on them.SSIM index is a metric used to measure the similarity between two images. It is a modified metric of the universal image quality index [48,49]. SSIM takes two images and compares the local patterns of pixel intensities. These patterns have to be normalized for luminance and contrast. The following equations show how this index is calculated to measure the similarity between two images (x and y) [47].(14)SSIM(x,y)=(2μxμy+C1)(2σxy+C2)μx2+μy2+C1σx2+σy2+C2,where(15)C1=(K1L)2,(16)C2=(K2L)2,andK1is the a small constant (0.01);K2the a small constant (0.03); L: dynamic range of pixel values (255 for grayscale images);μxthe mean of image x;μythe mean of image y;σx2the variance of image x;σy2the variance of image y;σxyis the covariance between images x and y.In this paper, the SSIM index was used to measure the similarity between the images under investigation and all people classes in the database. SSIM values ranges between ‘0’ and ‘1’. SSIM value of ‘0’ means no similarity between the two images, while SSIM value of “1” means images x and y are similar (identical). As mentioned before, the total number of pictures used in the testing phase was 2534. This similarity metric was successful in correctly recognizing 2464 faces, which means a recognition rate of 97.23%.The second metric is based on FFT. If we have two images x and y, this metric is based on finding the distance (D) between X and Y, where X and Y are the 2-dimensional FFT representation of x and y, respectively as shown below [50].(17)X(u,v)=∑r=0H́-1∑c=0Ẃ-1x(r,c)e-j2πurH́+vcẂ,(18)Y(u,v)=∑r=0H́-1∑c=0Ẃ-1y(r,c)e-j2πurH́+vcẂ,whereu=0,1,2,…,H́-1,v=0,1,2,…,Ẃ-1,H́is the number of rows in the image, andẂis the number of columns in the image.(19)D=∑u=0H́-1∑v=0Ẃ-1(X(u,v)-Y(u,v))·(X(u,v)-Y(u,v))∗1/2In this paper, the distance D was calculated to recognize the images under investigation. If we have two images x and y and their FFT representations is X and Y, respectively. If the two images are very similar to each other, then the distance D between X and Y will be close to “0”. On the other hand, if the two images are very different, then the distance D between X and Y will be far from “0”. Therefore, the image under investigation was recognized based on calculating the distance between its FFT representation and the FFT representation of all the other classes. The person who has the smallest distance of its accredited class is decided to be the recognition output. This similarity metric was successful in correctly recognizing 2469 faces, which means a recognition rate of 97.43%.In summary, three similarity measures have been tried in this paper. The results shown earlier are based on the CC similarity measure because it is the simplest. The other two measures got almost the same recognition rate ∼97%.In this section, an extra experiment was carried out. All the misrecognized pictures were given to 213 people. Each participated individual was asked to decide between two choices which one is closer to the misrecognized picture. The first choice was what the proposed model recognized the image as, and the second choice was the picture of the person that should have been recognized as. Participants were not told which choice is the true choice. The participants’ recognition rate for the misrecognized images was 81.1%.It is worth mentioning that in this experiment, the participants (humans) were put in circumstances that make the recognition task easy. In the experiment, the participants were asked to decide between only two choices instead of finding a match in a large database. In spite of this, a large portion of the participated individuals chose the wrong answer. It is important to point out that only 3 out of 213 persons were able to correctly recognize all the images.In this subsection, kCAFRe is compared with the state-of-the-art methods. It is in fact a tough matter to fairly compare between two or more face recognition methods. Let us illustrate this by raising the following situation: let us assume two recognition methods, Method 1 achieved a recognition rate of 99% on a database of size 100 pictures, while Method 2 achieved a recognition rate of 96% on a database of size 1000 pictures. Which method is better? In light of this, the authors think a “good” face recognition method should posses the following features:1.Be fully automatic: the good face recognition method should not need any human intervention like for example manual cropping.Work on a large database consisting of large number of individuals: the larger the number of pictures used to test a face recognition method, the better the method.Achieve high identification rates.Achieve high verification rates.Use off-the-shelf components.Be fast: in real-life applications, a fast face recognition method is highly desirable. Preprocessing, training, and testing should take minimal delay.Use the minimal picture size: the larger the picture size, the better the chance to correctly recognize the person. However, the larger the picture size, the slower the method is because it operates on a greater number of pixels.A comparison between the most relevant most recent state-of-the-art face recognition methods and kCAFRe is shown in Table 8. By investigating Table 8, it can be seen that none of these state-of-the-art methods provided verification results. Moreover, it can be noticed that many of state-of-the-art methods worked on a small-sized database, did not mention timing requirements, used large pictures sizes, or invoked manual face detection and cropping. The following shows detailed comparison between kCAFRe and those methods:–In Zhang et al. [26] (FERET database): the time to test an image was 0.054s. This time looks small. However, it was measured as the time for one-to-one image matching, which means if all the test images during the test were included in the testing phase, this time would increase exponentially. It is worth mentioning that the recognition rate of this algorithm is around 90% even though the image size was 88×88 pixels, which is much larger than the image size used in kCAFRe (25×25 pixels). Nevertheless, kCAFRe achieved higher recognition rate (97%).In Zhang et al. [26] (Extended Yale B database): few high resolution images were used to test the method. There are 38 subjects to be recognized, each has 9 images. Each image has a resolution of 84×96 pixels. The method achieved a high recognition rate (97.9%), but all the images that were used to test and train the system were manually aligned and cropped which leads to high recognition rates. Similar scenarios happened in Wei et al. [34] (FERET database), Aneesh et al. [36] (Yale B database) and Lu et al. [35] (Extended Yale B database), where the number of images was small and the images were manually aligned and cropped with high resolution. This explains the achieved high recognition rates.In Singh and Sahan [31] (JAFFE and UMIST databases): the algorithm achieved very high recognition rates (99.9% and 97.6%, respectively). But what helps the algorithm to get these values was the very high resolution images used in the training and testing phases. The images that were used have at least 100 times more resolution than the images used in this paper. This leads to a longer time to recognize any image. A comparison between these two algorithms with the proposed one would raise the following points:•The images in these two methods have at least 100 times more resolution than the images used in this paper.The number of images used in training and testing in kCAFRe is 35× greater than the numbers used in these two methods. This would give the proposed method better generalization and better knowledge.kCAFRe used more images than what the two methods used, where more time is needed to process a large database. Nevertheless, the timing of the proposed method is not far from theirs.It is important to emphasize that the Libor Spacek’s database is categorized into four categories: Face94, Face95, Face96 and Grimace. These categories are sorted from the easiest to recognize to the hardest, with Face94 being the easiest and Grimace the hardest category of faces to recognize.It can be seen from Table 8 that the Libor Spacek’s database has been used in [38–40]. However only part of the Libor Spacek’s database has been in these papers (in fact the easiest categories of the Libor Spacek’s database). In [38], only Face94 and Face95 have been tested and the reported recognition rates were 97.51% for Face94 and 91.73% for Face95. In [39], the simplest category of the Libor Spacek’s database (that is Face94) has been used, where they scored a recognition ratio of 95%. Likewise, only the Face94 category has been experimented in [40], where a recognition ratio of 94% was achieved.In this study, a novel k-class approach for efficient and accurate face recognition called kCAFRe is introduced. The kCAFRe system consists of three stages: preprocessing, training, and testing. In the training phase, four reference pictures (classes) are constructed for each person. During testing, the correlation coefficient is calculated between the picture under test and each of the reference pictures. For each person, one accredited class is chosen. Then, the accredited class for the person with the highest CC value is chosen. Results were given for the Libor Spacek’s facial image database. A recognition ratio of 97% has been obtained for this set. kCAFRe has the following properties:1.It is fully automatic: every step in the proposed method is automatically performed.It was tested on four large databases consisting of 7240 pictures for 362 individuals.It achieves high identification rates of 96.9% for Rank 1 and 99.5% for Rank 10.It achieves high verification rates ranging between 83% and 100% using false acceptance rates ranging from 0.001 to 1, respectively.It uses off-the-shelf components: VJFDA implementation in MATLAB for face detection and cropping.It is fast. As shown in Table 7, it takes only 11.3s to test and recognize a picture from a large database.It requires small picture sizes of only 25×25 pixels.

@&#CONCLUSIONS@&#
