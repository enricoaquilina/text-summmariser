@&#MAIN-TITLE@&#
Modeling and optimization control of a demand-driven, conveyor-serviced production station

@&#HIGHLIGHTS@&#
We model the demand-driven CSPS with both production and sales centers as a SMDP.We examine the case of random part/customer arrival, limited buffer/bank capacity.A model-free learning optimization algorithm is effective to search the policy.We can design the optimal capacities of both buffer and bank by using the model.Given the bank state, the emptier the buffer is, the longer the look ahead rang is.

@&#KEYPHRASES@&#
Production,Random customer demands,Look-ahead control,Semi-Markov decision process,Q-learning,

@&#ABSTRACT@&#
This study investigates the look-ahead control of a conveyor-serviced production station (CSPS), viewed as a production center, which is connected to a sales center. The production station is equipped with a buffer to temporarily store the parts that will flow into the product bank of the sales center after processing. The whole two-center system is characterized by random parts arrival, random customer demand, random processing time and limited buffer or bank capacities. Thus, the decision-making on the look-ahead range of such demand-driven CSPS is subject to the constraints of production and sales levels. In this paper, we will focus on modeling the stochastic control problem and providing solutions for finding the optimal look-ahead control policy under either average- or discounted-cost criteria. We first establish a detailed semi-Markov decision process for the look-ahead control of the demand-driven CSPS by combining the vacancies of both the buffer and the bank into one state, which can be solved by policy iteration or value iteration if the system parameters are known precisely. Then, to avoid the curse of dimensionality and modeling in the numerical optimization methods, we also propose a Q-learning algorithm combined with a simulated annealing technique to derive the approximate solutions. Simulation results are finally presented to show that by our established model and proposed optimization methods the system can achieve an optimal or suboptimal look-ahead control policy once the capacities of both the buffer and the bank are designed appropriately.

@&#INTRODUCTION@&#
In many real-world manufacturing enterprises, there is usually a type of production station situated along a constant-speed conveyor, by which some parts are randomly conveyed to the station for necessary processing. Generally, the station is equipped with a finite-capacity buffer to store temporarily the parts to improve flexibility. This production model is called a conveyor-serviced production station (CSPS), which originates from Ford’s assembly line (Matsui, 1993; 2005; 2009). It can be viewed as an abstract model of present-day automated manufacturing processes such as robotic assembly lines (Matsui, 2009; Tang and Arai, 2009) and is usually associated with job-shop scheduling in real production (Matsui, 2009; Sadrzadeh, 2013; Zuo, Xue, Zhou, and Guo, 2013). In fact, as an intellectual production model, CSPS has received wide use in most world-famous and advanced enterprises, such as in the mobile-phone (LCD) assembly line of Fujitsu and the HDD production line of Toshiba. Therefore, the optimal control of such type of production model has practical significance and is an important issue in the field of industrial engineering.For the control of this traditional single-station CSPS, Matsui has already established a semi-Markov decision processes (SMDP) model and given the calculation equations for some of the performance values (Matsui, 1993; 2005; 2009). He has also summarized all of the different control modes and given a physical theory on CSPS models (Matsui, 2005; 2009). Based on this work, Tang and Arai developed a potential-based online policy iteration for the optimal look-ahead control of this system (Tang and Arai, 2009). Among these studies, the production of the station is independent from the sale. Today, as an effect of economic development in the age of supply chain management (SCM), real-time production may be greatly influenced by the markets (Mikuriya and Nakade, 2013; Yamada, Satomi, and Matsui, 2006), which implies that the production scheduling of a production center should be combined with the inventory management of a sales center under the circumstance of uncertain customer demands. So the related optimization control is becoming important and attractive in the SCM age. For instance, Ventura et al. presented a multi-period inventory lot-sizing model for a single product in a serial supply chain, where the demand is known and may change from period to period (Ventura, Valdebenito, and Golany, 2013). In addition, Ioannidis has considered a single-product and make-to-stock manufacturing system facing random demand from two customer classes with different quality cost and profit parameters (Ioannidis, 2013). Further, Hussain et al. proposed a probabilistic assessment of loss in revenue generation in demand-driven production (Hussain, Dillon, Hussain, and Chang, 2012) and Bertrand and Van Ooijen have studied the capacity investment decisions of make-to-order manufacturing firms where the demand rate can be controlled by increasing or decreasing their sales effort with a fixed capacity (Bertrand and Van Ooijen, 2012). Similarly, for modern production in many manufacturing industries, a CSPS viewed as a production center is sometimes connected to a sales center, which is equipped with a product bank to store the processed parts moved from the station and meet random customer demands. In previous studies related to traditional CSPS, the limitation of the bank capacity and the real-time inventory level are usually not considered (Matsui, 1993; Tang and Arai, 2009). In practice, the bank capacity is definitely finite and the customer demands may be stochastic, diverse and unpredicted, which will dynamically affect the inventory level and thereby, the production of the station. Thus, we term this two-center model as demand-driven CSPS that is obviously characterized by random parts arrival, random customer demands, random processing time and limited buffer or bank capacities. Therefore, coping with the model and the look-ahead control of the demand-driven CSPS is a key challenge and more complex than that of the traditional CSPS.So far, only a few studies of a demand-driven CSPS system have been carried out, although this production model is important in the context of SCM. It was first discussed in a job-shop model with order selection by Matsui (1988) and has been developed to a management game model (Matsui, 2002; 2009). In this paper, we consider the case of a demand-driven CSPS system with limited buffer and bank capacities, which is an extension of our previous work (Chen, Tang, Zhou, and Ma, 2010). Our goal is to formulate the system by a mathematic model and provide solutions to find an optimal or suboptimal look-ahead control policy. In view of this and without loss of generality, we make some assumptions: (i) the conveyor runs at a constant speed; (ii) parts arrive at the production center in a Poisson process; (iii) customers also arrive at the sales center in a Poisson process that is independent of the parts arrival, and each customer takes one processed part away from the bank; and (iv) the time for unloading a part from conveyor to the buffer and the time for moving a processed part from the production center to the sales center are ignored. We first establish a detailed model of the demand-driven CSPS as a semi-Markov decision process (SMDP), which can be solved by policy iteration or value iteration if the system parameters are known precisely. Unlike traditional CSPS, vacancies of the buffer and the bank are jointed to be viewed as the system state, which implies that random customer demands are eventually taken into account to decide the look-ahead range of the production station. Due to the system complexity and especially the random dynamics, the numerical optimization methods will be subject to the so-called “curse of dimensionality” and “curse of modeling”. Therefore, we also propose a model-free reinforcement learning method (i.e., Q-learning algorithm) to search for an optimal or suboptimal look-ahead control policy by introducing simulated annealing to construct the exploration scheme to avoid a local extreme.The remainder of this paper is organized as follows: In Section 2, we describe the demand-driven CSPS system and establish its detailed SMDP model. In Section 3, we introduce the optimization solutions including numerical methods and reinforcement learning methods. We then provide some simulation results in Section 4, and conclude the paper with some brief comments in Section 5.The physical model of a demand-driven CSPS is illustrated in Fig. 1and introduced as a two-center model consisting of production and sales centers. The production center has a finite-capacity buffer storing the parts unloaded from the conveyor, and the sales center has a finite-capacity bank storing the processed parts moving from the production center and satisfying customer demands. The agent of the production center will dynamically judge if a part is arriving within a certain range along the conveyor and derive its location information such as the position and orientation. The look-ahead range is viewed as the control or decision variable. Because the conveyor runs at a constant speed, hereafter any range along the conveyor (e.g., the look-ahead range) will be represented by units of time. The demand-driven CSPS works as follows: at a decision epoch, the agent will look ahead some range according to the current vacancies of both the buffer and the bank. If there is at least one part in the look-ahead range, the agent will wait until the first one arrives at the pickup position and then unload it into the buffer. Otherwise, he/she will immediately take one reserved part out of the buffer to process and during which time, all arriving parts will be lost; after the service is finished, the processed part will be moved into the bank of the sales center. Concurrently with either operation, customers arrive at the sales center randomly, and each customer will take one production away from the bank. In addition, we assume that if the bank is vacant, the customer will be lost.In this work, a look-ahead action usually leads to various costs such as waiting cost, reserving cost for buffer or bank, service cost and so on. Thus, our interest is finding a look-ahead control policy to optimize the general performance, such as expected average cost per unit time or long-run expected total discounted cost. For clarity, the following system parameters and variables are collectedλaPoisson arrival rate of parts to the flowPoisson arrival rate of customers to the sales centercumulative distribution function of the service (processing) time, tdensity function of the service (processing) time corresponding to S(t)average service time for processing each partcapacity of the buffercapacity of the bankvacancies of the buffervacancies of the banklook-ahead range, represented by timethe minimum/maximum value of the look-ahead rangeevery unit-time reserving cost for each part in the bufferevery unit-time service (or processing) costevery unit-time waiting costimmediate cost just after a service is finished, which is negative or zero representing the reward of producing a productimmediate cost for looking ahead (or sensing) every unit rangeevery unit-time reserving cost for each processed part in the bankimmediate cost after a customer demand is satisfied, which is negative or zero representing the reward of selling a productWe let k be the bank state in space Φ1 = {0, 1, …, K} and let n be the buffer state in space Φ2 = {0, 1, …, N}. Sk, nis defined as jointed state of the two-center system in space Φ = Φ1 × Φ2. In addition,vSk,nis assumed to be an action (i.e., the control variable) at state Sk, n. Then, a stationary look-ahead policy, denoted by v, is represented by(1)v=[vS0,0vS0,1⋯vS0,n⋯vS0,NvS1,0vS1,1⋯vS1,n⋯vS1,N⋮⋮⋱⋮⋱⋮vSk,0vSk,1⋯vSk,n⋯vSk,N⋮⋮⋱⋮⋱⋮vSK,0vSK,1⋯vSK,n⋯vSK,N]with Ω being the set of all such policies.In demand-driven CSPS, there are some special operating cases as followsCase 1: Both the buffer and the bank are full. The agent will wait until one customer arrives at the bank and takes one processed part away from the bank; thereafter, the agent of the production center begins to make a new decision. Under this case, there is no need to look ahead, and thus,vS0,0≡0.Case 2: Only the buffer is full. The agent has to serve a part, sovSk,0≡0for k = 1, 2, …, K.Case 3: Only the bank is full, whereas the buffer is not empty. We assume that the agent will not serve a part and wait until one part arrives at the station or one customer arrives at the bank. So we letvS0,n≡∞for n = 1, 2, …, N − 1.Case 4: The buffer is empty. The agent will wait until one part arrives at the station and unload it into the buffer. ObviouslyvSk,N≡∞for any k ∈ Φ1.The action for any other state belongs to the compact set D = [lmin , lmax ]. We assume that the system is controlled by policy v and starts from the initial decision epoch T0 = 0. At the decision epoch Tm, suppose the state process, denoted by Xt, t ≥ 0, is at state Sk, n, written asXTm=Xm=Sk,n,and actionvSk,nis taken. If Sk, ncorresponds to Case 1, the agent will wait until one custom arrives at the bank. If it corresponds to Case 3, the agent will wait until one part arrives at the station or one customer arrives at the bank. For these two cases, writing the waiting time as ϖm, the next decision epoch, denoted by Tm + 1, will be Tm + 1 = Tm+ ϖm. For all other cases, if there is at least one part within the time range determined byvSk,n,the agent will wait until the first part arrives at the station and unload it into the buffer. During this waiting time, denoted also by ϖm, some customers may arrive at the sales center and each of them takes one processed part away from the bank. After that, the system transitions to stateXm+1=Sk′,n−1,k′∈{k,k+1,…,K}and turns immediately to the next decision epoch, which satisfies Tm + 1 = Tm+ ϖm. The timeline of such process is shown in Fig. 2(a).In contrast, if there is no part withinvSk,n,the agent serves one of the reserved parts in the buffer. The service time is written as τm. Then, to keep the memory-less property of the decision process, we set the corresponding waiting time to beϖm=max{vSk,n,τm}−τm=max{vSk,n−τm,0},and the next decision epoch to be(2)Tm+1=Tm+max{vSk,n,τm}=Tm+τm+ϖmFig. 2 (b) shows the timeline of such a process. During the service, some customers may also arrive at the sales center. So the system transitions to stateXm+1=Sk′,n+1,k′∈{k−1,k,…,K}at decision epoch Tm + 1. As we know, the probability of a customer arriving at the sales center at the same time a processed part was put into the bank is zero; however, there may be customers arriving within period [Tm+ τm, Tm+ τm+ ϖm] due to the possibility of ϖmlarger than zero. Therefore, the bank may turn to full vacancy at Tm + 1, although a new processed part is moved into the bank; that is, the system has the possibility of transitioning to state Xm + 1 = SK, n + 1 at Tm + 1. Now, the control of the demand-driven CSPS can be modeled as a SMDP , with Xt, t ≥ 0 being a continuous-time state process and {X0, X1, …, Xm, …} being an embedded Markov chain (Cao, 2007).Obviously, as the state process is stationary, a typical productive cycle will include one-time unloading and one-time processing to maintain the production balance. So the waiting time of a productive cycle, also termed the delay time by Matsui (2009), includes two parts: one is the agent waiting to unload the part from the conveyor and the other is the time from the service being finished to the beginning of the next productive cycle. In other words, the delay time corresponds to the transfer time of parts, which does not happen if the agent is busy processing. In fact, it is an important criterion in designing the buffer and bank capacities (Matsui, 2009) and also for optimizing the look-ahead control policies. We denote the average delay time as w. Then, the average cycle time is the sum of the delay time, w, and the average service time, μ. A typical productive cycle is shown in Fig. 3.The SMDP model of demand-driven CSPS at a stationary policy v can be expressed by a 5-tuple X = 〈Xt, Φ, D, Qv(t), fv〉. We will discuss it in detail for the remainder of this section.We writeFv(t)=[FSk,nSk′,n′(t,vSk,n)]Sk,n,Sk′,n′∈Φas the distribution matrix for sojourn time under policy v. Here,FSk,nSk′,n′(t,vSk,n)denotes the time distribution of sojourning at state Sk, nunder actionvSk,n,conditioned that the next state isSk′,n′. We write the corresponding density function ofFSk,nSk′,n′(t,vSk,n)asfSk,nSk′,n′(t,vSk,n). Then, according to the above mentioned four special cases, we first have(3)fS0,0S1,0(t,vS0,0)=λce−λctfSk,NSk′,N−1(t,vSk,N)=λae−λat,0≤k≤k′≤KfSk,0Sk′,1(t,vSk,0)=s(t),0≤k−1≤k′≤KfS0,nS0,n−1(t,vS0,n)=(λa+λc)e−(λa+λc)t,n=1,2,…,N−1fS0,nS1,n(t,vS0,n)=(λa+λc)e−(λa+λc)t,n=1,2,…,N−1where the last two lines correspond to Case 3.In addition, for 1 ≤ k ≤ k′ ≤ K and n = 1, 2, …, N − 1, we have(4)fSk,nSk′,n−1(t,vSk,n)={E(t)−E(t−vSk,n)}λae−λat/(1−e−λavSk,n)and for 0 ≤ k − 1 ≤ k′ ≤ K and n = 1, 2, …, N − 1, we have:(5)fSk,nSk′,n+1(t,vSk,n)=S(vSk,n)δ(t−vSk,n)+E(t−vSk,n)s(t)where δ( · ) and E( · ) are the impulse function and the step function, respectively. Eq. (4)represents the probability density of a part arriving at time t conditioned that there is at least one part withinvSk,n,while Eq. (4) denotes the probability density conditioned that there is no part withinvSk,n. For all other elements,fSk,nSk′,n′(t,vSk,n)=0.Obviously, we can calculate the distribution function by equationFSk,nSk′,n′(t,vSk,n)=∫0∞fSk,nSk′,n′(t,vSk,n)dtfor anySk,n,Sk′,n′∈Φ. According to Eq. (3), we have(6)FS0,0S1,0(t,vS0,0)=1−e−λctFSk,NSk′,N−1(t,vSk,N)=1−e−λat,0≤k≤k′≤KFSk,0Sk′,1(t,vSk,0)=S(t),0≤k−1≤k′≤KFS0,nS0,n−1(t,vS0,n)=1−e−(λa+λc)t,n=1,2,…,N−1FS0,nS1,n(t,vS0,n)=1−e−(λa+λc)t,n=1,2,…,N−1By Eq. (4), we obtain(7)FSk,nSk′,n−1(t,vSk,n)={1−e−λat1−e−λavSk,n,0<t<vSk,n1,t≥vSk,nand corresponding to Eq. (5), we get(8)FSk,nSk′,n+1(t,vSk,n)={0,0<t<vSk,nS(t),t≥vSk,nThe transition matrix of the underlying embedded Markov chain under control policy v is denoted by the stochastic matrixPv=[PSk,nSk′,n′(vSk,n)]Sk,n,Sk′,n′∈Φ,wherePSk,nSk′,n′(vSk,n)denotes the probability of transitioning from state Sk, nto the next stateSk′,n′under actionvSk,n. Clearly, by Case 1 and Case 3(9)PS0,0S1,0(vS0,0)≡1PS0,nS0,n−1(vS0,n)=∫0∞e−λctdFS0,nS0,n−1(t,vS0,n),n=1,2,…,N−1PS0,nS1,n(vS0,n)=1−∫0∞e−λctdFS0,nS0,n−1(t,vS0,n),n=1,2,…,N−1It is easy to understand that, for a given actionvSk,n,the transition of the bank state is independent from that of the buffer state. The latter is determined by the random parts arrival, whereas the former is determined by the random custom arrival, and these two processes are independent. Now we consider them separately. First, the transition probability of the buffer state from n to n′ under actionvSk,nis denoted byp^n,n′(vSk,n). Obviously, according to Case 2 and Case 4(10)p^01(vSk,0)=1,k∈Φ1∖{0};p^NN−1(vSk,N)=1,k∈Φ1In addition, for k = 1, 2, …, K and n = 1, 2, …, N − 1(11)p^n,n+1(vSk,n)=exp(−λavSk,n),p^n,n−1(vSk,n)=1−exp(−λavSk,n)For other transitions (n, n′), we setp^n,n′(vSk,n)=0,as k ≠ 0.Then, we denote the transition probability of the bank state from k to k′ under actionvSk,nbyp¯k,k′(vSk,n). If the agent of the production center takes the operation of unloading, then for n = 1, 2, …, N, we obtain(12)p¯k,k′(vSk,n)={∫0∞(λct)k′−k(k′−k)!e−λctdFSk,nSk′,n−1(t,vSk,n),0<k≤k′<K∑i=K∞∫0∞(λct)i−k(i−k)!e−λctdFSk,nSk′,n−1(t,vSk,n),k∈Φ1∖{0},k′=Kand for other transitions ((k, n), (k′, n − 1)), we setp¯k,k′(vSk,n)=0,as k ≠ 0. Under this circumstance, we have(13)PSk,nSk′,n−1(vSk,n)=p^n,n−1(vSk,n)p¯k,k′(vSk,n),k∈Φ1∖{0},n∈Φ2∖{0}Obviously,PSK,NSK,N−1(vSK,N)≡1. Otherwise, if the agent of the production center takes the operation of processing, then for n = 0, 1, …, N − 1, we obtain(14)p¯k,k′(vSk,n)={∫0∞(λct)k′−k+1(k′−k+1)!e−λctdFSk,nSk′,n+1(t,vSk,n),0≤k−1≤k′<K∑i=K∞∫0∞(λct)i−k+1(i−k+1)!e−λctdFSk,nSk′,n+1(t,vSk,n),k∈Φ1∖{0},k′=Kand for other transitions ((k, n), (k′, n + 1)), we also setp¯k,k′(vSk,n)=0as k ≠ 0. Under this circumstance, we have(15)PSk,nSk′,n+1(vSk,n)=p^n,n+1(vSk,n)p¯k,k′(vSk,n),k∈Φ1∖{0},n∈Φ2∖{N}Then, by Eqs. (6)–(9) and Eqs. (13) and (15), we can construct the semi-Markov kernel, which is defined asQv(t)=[Q(Sk,n,vSk,n,Sk′,n′,t)]Sk,n,Sk′,n′∈Φ=Pv⊙Fv(t)(Cao, 2007). Here we use the symbol “⊙” to denote an operator that is similar to array multiplying, namelyQ(Sk,n,vSk,n,Sk′,n′,t)=PSk,nSk′,n′(vSk,n)FSk,nSk′,n′(t,vSk,n)(Tang and Arai, 2009).Suppose we have a sample transition〈Xm,vXm,Xm+1,ωm,τm〉derived by observing or simulating the practical system under actionvXm. Here, τmis the service time and ωm= Tm + 1 − Tmis the interval time between Tmand Tm + 1. Some coefficients that represent possible cost types have been introduced previously. The cost types for the production center are illustrated in Fig. 4as the agent takes the operation of processing.As shown in Fig. 4, a transition resulting in serving a part may lead to various costs that come at some point or accumulate during a time interval. For instance, the look-ahead cost and the production reward come at Tmand Tm+ τm, respectively, while the service cost and waiting cost are accumulated within [Tm, Tm+ τm] and [Tm+ τm, Tm + 1], respectively. For convenience and to use the optimization theory of continuous-time SMDP (Cao, 2007), we synthesize and convert all of these costs into an expected cost that the system pays every unit time during the entire time period [Tm, Tm + 1], written asf(Sk,n,vSk,n,Sk′,n′). Now let the performance matrix befv=[f(Sk,n,vSk,n,Sk′,n′)]Sk,n,Sk′,n′∈Φ,withf(Sk,n,vSk,n,Sk′,n′)denoting the expected cost that the system pays every unit time at state Sk, nunder actionvSk,nbefore transitioning to the next stateSk′,n′.Then, according to Cao (2007), the infinite-horizon expected cost criteria for our established SMDP takes the following form(16)ηαv(Sk,n)=E[limM→∞∑m=0M−1∫TmTm+1αe−αt×f(Xm,vXm,Xm+1)dt|X0=Sk,n],Sk,n∈ΦHere, α > 0 denotes a discount factor andηαv(Sk,n)represents the expected total discounted cost of the two-center system starting from Sk, nunder policy v. We write the corresponding vector asηαv. As α goes to zero, each of its elements reduces to a special case (i.e., infinite-horizon expected average cost per unit time), independent of the initial state (Cao, 2007). We write the limitation asη0vwhich satisfiesη0v=eηvwith e being the all-one vector and(17)ηv=E[limM→∞1TM∑m=0M−1∫TmTm+1f(Xm,vXm,Xm+1)dt]Then, our goal turns to selecting an optimal look-ahead policy v*, subject tov*∈argminv∈Ωηαv,from the policy set Ω for any given α ≥ 0.Now we demonstrate the details in establishing the cost functionf(Sk,n,vSk,n,Sk′,n′). First, for any x ≥ 0 and discount factor α ≥ 0, we writeTα(x)=∫0xe−αtdt=1−e−αxαand obviously T0(x) = x. As a special case, the look-ahead cost is assumed to be zero when Xm= Sk, N, because the agent needs not to look ahead as the buffer is vacant and waits for a part to arrive at the pickup position. As Xm= S0, 0 (i.e., under Case 1), the agent also needs not to look ahead and just waits for a customer to arrive at the sales center and take one part away from the bank, leading to next state Xm + 1 = S1, 0. So, the expected cost that the system pays every unit time at state S0, 0 under actionvS0,0before transitioning to the next state S1, 0 is(18)f(S0,0,vS0,0,S1,0)=k1N+k3+k6K+k7φ1(S0,0,vS0,0,S1,0)Here, φ1( ·, ·, ·) is an equivalent function related to k7, which corresponds to an immediate reward of selling a product at a discrete time point, so we have the following conversion functionφ1(Sk,n,vSk,n,Sk′,n′)=∫0∞e−αtdFSk,nSk′,n′(t,vSk,n)∫0∞Tα(t)dFSk,nSk′,n′(t,vSk,n),1≤k≤k′≤KIn addition, according to Case 3, for any n = 1, 2, …, N − 1(19)f(S0,n,vS0,n,S1,n)=k1(N−n)+k3+k6K+k7φ1(S0,n,vS0,n,S1,n)and(20)f(S0,n,vS0,n,S0,n−1)=k1(N−n)+k3+k6KNow, corresponding to a transition(Sk,n,vSk,n,Sk′,n−1)that resulted from taking the operation of unloading and for 1 ≤ k ≤ k′ ≤ K, n ∈ Φ2∖{0}, we have(21)f(Sk,n,vSk,n,Sk′,n−1)=k1(N−n)+k3+k5χN(vSk,n)φ2(Sk,n,vSk,n,Sk′,n−1)+k6(K−k)+k7(k′−k)φ1(Sk,n,vSk,n,Sk′,n−1)where, under Case 4 (i.e., if Sk, n= Sk, N,χN(vSk,n)=0); otherwise,χN(vSk,n)=1. In fact, Eq. (21)can also be applied to the transition(S0,N,vS0,N,S0,N−1). Notice that we assume the rewards for selling products to customers are acquired at the subsequent decision epoch, as showed in the last term of Eq. (21). Because φ2( ·, ·, ·) corresponds to the cost of looking ahead, which is yielded immediately at the decision epoch as illustrated in Fig. 4, we can define the following conversion functionφ2(Sk,n,vSk,n,Sk′,n′)=vSk,n∫0∞Tα(t)dFSk,nSk′,n′(t,vSk,n)Then, corresponding to a transition(Sk,n,vSk,n,Sk′,n+1)resulting from taking the operation of processing and for 0 < k − 1 ≤ k′ ≤ K, n ∈ Φ2∖{N}, we have(22)f(Sk,n,vSk,n,Sk′,n+1)=k1(N−n−1)+k2φ3(Sk,n,vSk,n,Sk′,n+1)+k3φ4(Sk,n,vSk,n,Sk′,n+1)+k4φ5(Sk,n,vSk,n,Sk′,n+1)+k5φ2(Sk,n,vSk,n,Sk′,n+1)+k6(K−k)+k7(k′−k+1)φ1(Sk,n,vSk,n,Sk′,n+1)Here, φ3( ·, ·, ·), φ4( ·, ·, ·), φ5( ·, ·, ·) correspond to the service cost, waiting cost, and immediate reward of producing a product, respectively. As shown in Fig. 4, the service cost is accumulated just from Tmto Tm+ τm. Ifτm<vSk,n,a waiting cost will be accumulated from Tm+ τmto Tm + 1. Moreover, the reward of producing a product is acquired at Tm+ τm. Therefore, we have the following conversion functionsφ3(Sk,n,vSk,n,Sk′,n′)=∫0∞Tα(t)dS(t)∫0∞Tα(t)dFSk,nSk′,n+1(t,vSk,n)φ4(Sk,n,vSk,n,Sk′,n′)=∫0∞(∫τ∞e−αtdFSk,nSk′,n+1(t,vSk,n))dS(τm)∫0∞Tα(t)dFSk,nSk′,n+1(t,vSk,n)φ5(Sk,n,vSk,n,Sk′,n′)=∫0∞e−ατdS(τm)∫0∞Tα(t)dFSk,nSk′,n+1(t,vSk,n)Finally, it is easy to prove that the limitation off(Sk,n,vSk,n,Sk′,n′)as α goes to 0 just denotes the performance function for average criteria.From Eqs. (13) and (15), it is easy to infer that the embedded Markov chain is time-homogeneous, aperiodic and irreducible. So the chain {Xm, m ≥ 0} controlled by any look-ahead policy v, having a finite state space, is ergodic. Consequently, it possesses a unique stationary distribution,{πSk,nv,Sk,n∈Φ},which is shown in Appendix A to serve the conciseness of this paper’s main body.Now, we define a functionh(Sk,n,vSk,n,t)satisfying(23)h(S0,0,vS0,0,t)=e−λcth(Sk,0,vSk,0,t)=1−S(t),k∈Φ1∖{0}h(Sk,N,vSk,N,t)=e−λat,k∈Φ1h(S0,n,vS0,n,t)=1−e−(λa+λc)t,n∈Φ2∖{0,N}and for n = 1, 2, …, N − 1, k = 1, 2, …, K(24)h(Sk,n,vSk,n,t)={e−λat,0≤t<vSk,ne−λavSk,n(1−S(t)),t≥vSk,nThe mean sojourn time at state Sk, nfor a transition(Sk,n,vSk,n,Sk′,n′)is defined ash0v(Sk,n,vSk,n),which is the solution to the equationh0v(Sk,n,vSk,n)=∫0∞h(Sk,n,vSk,n,t)dt. We denote the mean delay time at state Sk, n∈ Φ under actionvSk,nbyw(Sk,n,vSk,n). Then, according to Eq. (23), we obtain(25)w(S0,0,vS0,0)=1λcw(Sk,0,vSk,0)=0,k∈Φ1∖{0}w(Sk,N,vSk,N)=1λa,k∈Φ1w(S0,n,vS0,n)=1λa+λc(1−e−(λa+λc)vS0,n),n∈Φ2∖{0,N}Similar to Matsui (1993), for other states Sk, n∈ Φ,w(Sk,n,vSk,n)satisfies the following equation(26)w(Sk,n,vSk,n)=h0v(Sk,n,vSk,n)−e−λavSk,n∫0∞ts(t)dt=h0v(Sk,n,vSk,n)−μe−λavSk,nBy Eq. (24), we conclude that Eq. (26) is equivalent to(27)w(Sk,n,vSk,n)=1λa(1−e−λavSk,n)−μe−λavSk,nS0(vSk,n)whereS0(vSk,n)=1μ∫0vSk,n(1−S(t))dt.It is not difficult to understand that, as the stochastic process is stationary, one typical production cycle includes two steps, which are one-time unloading followed by one-time processing. So the cycle time, written as Y, is composed of the waiting time (also termed the delay time) and service time. Combined with Eqs. (25) and (27), the mean delay time per step can be calculated byE(w)=∑Sk,n∈ΦπSk,nvw(Sk,n,vSk,n). Therefore(28)Y=2E(w)+μThe production rate per unit time (hereafter referred to as production rate) of the system is defined as r = 1/Y, which is the inverse of cycle time.As mentioned in the last section, the demand-driven CSPS is modeled as a SMDP X = (Xt, Φ, D, Qv(t), fv), which can be converted into an equivalent continuous-time Markov decision process (MDP) expressed as(Xt,Φ,D,Aαv,fαv)through an equivalent infinitesimal generatorAαvand an equivalent performance matrixfαv(Cao, 2003; Yin, Xi, and Zhou, 2004). Here we omit details of the transformation process, so please refer to Yin et al. (2004) and Cao (2003).A performance potential vector of policy v, denoted bygαv,is the solution of the following Poisson equation(29)(αI−Aαv+ραeπαv)gαv=fαvwhere ραis a constant related to vectorhαvthat is shown in Tang and Arai (2009), Yin et al. (2004), and Cao (2003). Moreover, I is the identity matrix, andπαvis the stationary distribution of the equivalent MDP. According to Cao (2007) and Puterman (1994), we haveηαv=fαv+Aαvgαv. For any α ≥ 0, there is an optimal policy v* with(ηαv*,gαv*)satisfying the following Bellman optimal equation(30)0=minv∈Ω{fαv+Aαvgαv*−ηαv*}So during a policy iteration process, given a policy vk, a new policy vk + 1 can be derived by(31)vk+1∈argminv∈Ω{fαv+Aαvgαvk}In other words, the policy iteration is composed of the policy evaluation by Eq. (29) and the policy updating by Eq. (31); its convergence has been proven by Tang and Arai (2009), Yin et al. (2004), and Cao (2003).As we know, in a policy iteration algorithm, we must calculate the stationary distribution and solve Eq. (29) for each improving policy. For a large-scale system, the computation will be too time-consuming and require too much storage space; however, value iteration can avoid such difficulties.To introduce briefly the value iteration, for any α ≥ 0 and arbitrary vector g, we define an operator Γ, which satisfies(32)Γg=minv∈Ω{fαv+(Aαv+ραI)g/(ρα+α)}In addition, let Γmg = Γ(Γm − 1g) and Γ0g = g, then the value iteration can be expressed as limm → ∞Γmg initiated from arbitrary vector g. In fact, if we defineP˜α=Aα/λ+Iandf˜=fαv/λ,Eq. (31) is equivalent to the formula (27) in Tang, Xi, and Yin (2003), which implies that the value iteration based directly on Aαis equivalent to that in Tang et al. (2003), so the convergence can also be ensured.Obviously, the demand-driven CSPS is characterized by random part arrival, random customer demands, random processing time and limited buffer or bank capacities. From the last section, we can see that the establishment of the mathematic model by formulating the look-ahead control problem as a SMDP is a challenging, more complex work than that of the traditional CSPS. Due to the system complexity, the numerical optimization methods such as the policy iteration and value iteration will be subject to the so-called “curse of dimensionality” and “curse of modeling”, so we can also refer to a policy gradient method (Li and Cao, 2013; Xu, Hu, and Lu, 2007), or model-free reinforcement learning methods to search an optimal or suboptimal look-ahead control policy.As we know, Q-learning is a representative method, which evaluates the expected utility of the available actions without requiring a model of the environment. It can effectively handle problems with stochastic transitions and rewards, without requiring any adaptations. Additionally, it can be implemented by simulating or observing a running system and just learning the state-action value to solve the related problem. It has been proven that for any finite MDP, Q-learning can eventually find an optimal policy (Bertsekas and Tsitsiklis, 1996; Sutton and Barto, 1998). Our established SMDP model for the demand-driven CSPS provides a theoretical foundation for developing a Q-learning algorithm. Similar to Tang and Arai (2009), we will give a Q-learning algorithm for both average- and discounted-cost criteria by using the concept of performance potential. First, we discretize the compact action set D into a discrete set D′ by a small constant Δ. Then, given a sample transition〈Xm,vXm,Xm+1,ωm,τm〉,the unified temporal difference under either average or discounted criterion takes the following form(33)cm=f′(Xm,vXm,Xm+1)−Tα(ωm)ηm+e−αωmmind∈D′Qα(Xm+1,d)−Qα(Xm,vXm)Here, Qα( ·, ·) is the state-action value under discount factor α and ωmwas as discussed previously. Moreover,f′(Xm,vXm,Xm+1)denotes the discounted cost accumulated from Tmto Tm + 1. Corresponding to Eqs. (18)–(22), we have(34)f′(S0,0,vS0,0,S1,0)=Tα(ωm)(k1N+k3+k6K)+e−ατmk7(35)f′(S0,n,vS0,n,S1,n)=Tα(ωm)[k1(N−n)+k3+k6K]+e−ατmk7(36)f′(S0,n,vS0,n,S0,n−1)=Tα(ωm)[k1(N−n)+k3+k6K](37)f′(Sk,n,vSk,n,Sk′,n−1)=Tα(ωm)[k1(N−n)+k3+k6(K−k)]+k5vSk,nχN(vSk,n)+e−ατmk7(k′−k)(38)f′(Sk,n,vSk,n,Sk′,n+1)=Tα(ωm)[k1(N−n−1)+k6(K−k)]+k2Tα(τm)+k3[Tα(ωm)−Tα(τm)]+k4e−ατm+k5vSk,n+e−ατmk7(k′−k+1)Moreover, ηmis the estimated value of average cost ηv, satisfying(39)ηm=SfSωwhere Sfand Sωare iterated, respectively(40)Sf:=Sf+βm[fα=0′(Xm,vXm,Xm+1)−Sf](41)Sω:=Sω+βm[ωm−Sω]Here,fα=0′(Xm,vXm,Xm+1)is equal to the limit off′(Xm,vXm,Xm+1)as α goes to zero (i.e., the practical non-discounted cost accumulated from Tmto Tm + 1) and βmis a learning step size. Hence, the Q-value is(42)Qα(Xm,vXm):=Qα(Xm,vXm)+γ(Xm,vXm)cmwhereγ(Xm,vXm)is the learning step size that usually degrades slower than βm.In general, an ɛ-greedy scheme is used in Q-learning to tradeoff exploration and exploit so that the algorithm will not fall into local optimum. Obviously it is important and difficult to set the value of ɛ because an unsuitable ɛ still has the possibility of leading the local optimum. To overcome such difficulty, we introduce the ideal of simulated annealing into the Q-learning algorithm. An important part of the simulated annealing technique is the Metropolis criterion, which can improve the possibility of finding an optimal or suboptimal policy. The detailed algorithm is depicted in Table 1.Suppose the service time of each part follows an L-order Erlang distribution, which can be viewed as this case: there are L sequent service phases and the service time of each part in each phase is exponential with service rateλ¯. So the distribution of the total service time isS(t)=1−e−λ¯t(1+λ¯t+λ¯22!t2+⋯+λ¯L−1(L−1)!tL−1)The total service rate isλL=λ¯/Land the average service time isμ=L/λ¯. Some physical parameters and algorithm parameters for our simulation are shown in Table 2. It is not difficult to understand that, since the capacities of buffer and bank are both finite, statistically one part processed will followed by one production sold. That is to say, maximizing the reward of producing a product is equivalent to maximizing the reward of selling a product. So, we set k7 = 0 as k4 is nonzero. In addition, lmax  is here equal to μ.In the demand-driven CSPS system, managing the buffer reasonably can efficiently reduce the waiting time and inversely increase the processing time during a production cycle. As the expected service time of one part is fixed, it is easy to understand the total processing rate (same as the production rate) of the entire system. Regarding the sales center, with limited bank capacity, it conforms to the practical circumstance of real-time production. In the concerned model, the decision of look-ahead range depends on the real-time inventory level of buffer and bank, which are affected by the random parts arrival and random customer demands. If the bank capacity or the buffer capacity is too large, it will be resource-wasting and increase the investment cost of the sales center or the production center; whereas, if they are too small, production will be restricted. Therefore, a suitable design of buffer and bank capacities is of great importance. The relations among optimal average cost, buffer capacity and bank capacity are shown in Figs. 5and 6, respectively. Here we assume λa= 1, λc= 0.8. The optimal average cost is derived by using theoretic iteration methods given specified permutations of buffer and bank capacities.Fig. 5 shows that for each plot, except the top one, the optimal average cost converges with the increase of buffer capacity. Obviously, the smaller the buffer capacity, the faster the average cost decreases. When the capacity is large, the increase in the capacity will not lead to a significant decrease in the cost. The top plot shows that when the buffer capacity is small, the average cost decreases as the buffer capacity increases and turns to increasing as the buffer capacity exceeds 4. For example, when N = 7, the average cost is − 2.0341 in between those with N = 2 and N = 3. The reason for this is the bank capacity being 1 will block up the production, which means that more unprocessed parts are blocked in the buffer, leading to more related reserving cost and waiting cost. Such phenomena are clearly showed when the bank capacity is 1 in Fig. 6, which indicates that the optimal average cost is also sensitive to the bank capacity as it is small. Similar to Fig. 5, the average cost decreases with the bank capacity when keeping the buffer capacity fixed. In fact, when the bank capacity is large enough, it will reduce to the case of the traditional CSPS model (Matsui, 2009; Tang and Arai, 2009). All of these phenomena are also illustrated in Fig. 7(a), which can be viewed as a combination of Figs. 5 and 6. We see that the surface slope is sharp when both N and K are small, whereas the surface is rather flat when they are large. The optimal average cost decreases from − 1.5198 to − 2.8041 in this figure and the latter number is very close to the optimal average cost of the traditional CSPS. Above all, how to design reasonable buffer and bank capacities is important.In addition to the average cost, buffer and bank capacities also have a great effect on delay time, cycle time and production rate, as illustrated by other plots in Fig. 7. First, from Fig. 7(b) and (c), we see that, when N = 1 and K = 1, the delay time and cycle time are relatively large being 0.6086 and 2.2172, respectively. Obviously, as N and K increase, the delay time and cycle time decrease and converge. For example, as N = 5 and K = 6, they are 0.2446 and 1.4892, respectively. According to the definition of production rate, it is obvious that Fig. 7(d) is an inverse of Fig. 7(b) and the production rate under N = 5 and K = 6 is 0.6715, which is close to that of the traditional CSPS. According to the above analysis and figures, we set N = 5 and K = 6 in our experiments.To further illustrate the rationality of our design on the buffer and bank capacities, we summarize the reserving cost, waiting cost, service (or processing) cost and look-ahead cost as operating cost. In addition, we assume the immediate reward after a service is finished as service reward. Then, the main problem in our demand-driven CSPS is similar to maximizing the marginal profit economics (Matsui, 2009) (i.e., net profit = service reward − operating cost). Fig. 8shows that, given K = 6, the service reward and operating cost are both increasing as buffer capacity N increases. When N is over 5, the increasing of buffer capacity has a very slight effect on the operating cost and service reward. Correspondingly, the system profit is increasing and converging. Fig. 9is another case of fixing N = 5 and varying bank capacity K, which has a similar phenomenon to what is shown in Fig. 8. It is clear that, as the bank capacity is over 6, all three curves have no significant changes. So we can conclude from Figs. 8 and 9 that, as N = 5 and K = 6, the service reward and operating cost can be well balanced and the system acquires relative good profit.In this section, we discuss the optimization algorithms, conditioned that the buffer and bank capacities are designed reasonably as mentioned above.Figs. 10and 11show the optimization curves derived by policy iteration and value iteration, respectively. The red solid lines in both figures are for the average-cost case and the others are for the discounted-cost case as α = 0.01. Here, the three special states are defined as follows:State 3: Buffer vacancy is 2 and the bank is full.State 7: The buffer is full and bank vacancy is 1.State 9: Buffer vacancy is 2 and bank vacancy is 1.By observing Figs. 10 and 11, it can be seen that under the discounted-cost criteria, the optimization curves of different states are separated from each other and distributed in both sides of the curve of average cost. Note that when the bank is initially full at State 3, the production is first suspended until one customer arrives at the sales center and takes one processed part away from the bank, leading to a larger reserving cost for the buffer and waiting cost. So the corresponding curve is at the top. Moreover, as the buffer is initially full at State 7, the agent will not look ahead and just serve one part, so a production reward will initially be yielded and thereby, the total accumulated cost is decreased. This explains why the optimization curve of State 7 is at the bottom.We also see that the optimization results in Figs. 10 and 11 are almost equivalent. However, the policy iteration converges faster than the value iteration, usually in 2 or 3 steps. As mentioned in the previous section, for the policy iteration, we must solve some equations corresponding to each improving policy, which will be time-consuming for a large-scale system. In contrast, the value iteration will take more steps to converge, while each iteration takes much less time because there is no need to solve the potentials. In general, the value iteration establishes the superiority in avoiding the curse of dimensionality. Here, we acquire the following optimal policy(43)v*=[00.37760.48230.62040.8453inf00.35190.48790.61890.8459inf00.38230.51570.65650.8537inf00.39050.51910.64780.8407inf00.36900.48880.61850.8320inf00.32280.46940.62770.9999inf00.40010.52450.70030.9999inf]withηv*=−2.8041and “inf” denoting infinity. From each row of (43), it is easy to see thatvSk,0*<vSk,1*<vSk,2*<⋯<vSk,N−1*<vSk,N*,k=0,1,2,…,K. This means that the look-ahead range becomes bigger as vacancies of the buffer increase, which is easy to understand in practice and has been proven theoretically by Nawijn (1985).Figs. 12and 13are derived from our proposed Q-learning algorithm combined with a simulated annealing technique under average case and discounted case, respectively. Hereafter we term it as the SA-Q algorithm. Each curve is derived as follows: the learning is composed of 1000 fragments and each fragment includes 100 learning steps; for each fragment, we derive a greedy policy according to the current Q-table and then evaluate the policy by numerical methods. We see that each curve fluctuates significantly at the beginning and tends to be stable in the end.By the proposed SA-Q algorithm, we finally obtain the following sub-optimal policy(44)v¯*=[00.30000.50000.60000.8000inf00.30000.50000.60000.8000inf00.40000.50000.60000.8000inf00.40000.50000.60000.8000inf00.40000.50000.60000.8000inf00.30000.40000.60001.0000inf00.40000.50000.70001.0000inf]withηv¯*=−2.7102,which is very close toηv*. So we can conclude that the SA-Q algorithm is effective in solving the optimization problem of the demand-driven CSPS system. In fact, it performs better than traditional Q-learning with the ɛ-greedy exploration scheme for learning speed and obtained performance.There is no doubt that the reserving cost for the bank will influence the average cost of the concerned demand-driven CSPS. Now, we investigate such phenomenon by considering a different bank capacity, K, and coefficient, k6. As illustrated by each column in Table 3, with the increase of k6, the average cost increases apparently under the fixed bank capacity. Table 3 also suggests that the average costs derived by SA-Q and value iteration (VI for short) are very close to one another.Thus far, we have only discussed the case of both λaand λcbeing fixed. However, in real-time production, the customer arrival rate or part arrival rate may vary during different periods. So we use Fig. 14to show the relations among production rate, λaand λc, where the rightmost bar is the production rate of the traditional CSPS (not taking into account the sales center) (Matsui, 2009; Tang and Arai, 2009). Obviously, when λais small, the production rate has a slight improvement with the increase of λc. For example, as λa= 0.2, it only changes from 0.1465 to 0.1917 when λcincreases from 0.2 to 1.0. As a result, the customer loss rate (per unit time) changes apparently from 0.0535 to 0.8083, as shown in Fig. 15. From Fig. 15, we also see that when λais far less than λc, many customers’ needs will not be satisfied. The fact is that when λais relatively small, the supply of the part is not adequate for the production and, in turn, for demand.In addition, with λaincreasing, the production rate is rising obviously, and correspondingly the customer loss rate has a larger decrease. Note that, when λcrises equal to or greater than λa, the production rate will have no significant increase and finally approach the case of traditional CSPS. For example, as λc= 1.2, the production rate of the concerned demand-driven CSPS is almost same as that of traditional CSPS.Finally, we provide the values of the average cost, relative productivity and relative customer loss rate for different λaand λcin Table 4. As we see, when λais as small as 0.2, the average cost is as large as − 0.1681. If λaincreases from 0.2 to 1, then the average cost decreases significantly. Additionally, if given λa, the relative productivity is sensitive to λcand the difference may attain or even exceed 40 percent. Note that when λais equal to or greater than λc, the average cost and the relative customer loss rate are comparatively smaller, whereas the relative productivity is larger. For example, (λa, λc) being (1, 0.8) is one of such cases.

@&#CONCLUSIONS@&#
