@&#MAIN-TITLE@&#
A compound control chart for monitoring and controlling high quality processes

@&#HIGHLIGHTS@&#
A control chart (CC) for monitoring high quality processes is proposed.The Run Length distribution of this CC is studied using an appropriate Markov Chain.Numerical calculations are carried out to investigate the performance of the new CC.The performance of the new CC is compared to alternative CCs.

@&#KEYPHRASES@&#
Quality control,Applied probability,High quality processes,Run length distribution,Markov chain impedance,Conforming run length,

@&#ABSTRACT@&#
In the present article, we propose a new control chart for monitoring high quality processes. More specifically, we suggest declaring the monitored process out of control, by exploiting a compound rule couching on the number of conforming units observed between the (i−1)th and the ith nonconforming item and the number of conforming items observed between the (i−2)th and the ith nonconforming item. Our numerical experimentation demonstrates that the proposed control chart, in most of the cases, exhibits a better (or at least equivalent) performance than its competitors.

@&#INTRODUCTION@&#
Attribute data arise regularly in the context of Statistical Process Control (see for example Wu, Zhang, & Yeo (2001), Liu, He, Shu, & Wu (2009), Quinino, Colin, & Ho (2010), and Haridy, Wu, Lee, & Bhuiyan (2013)). A typical example of data of this type arises when a product is classified as conforming or nonconforming. In such cases, the most popular chart used by practitioners for detecting whether the fraction of defective (nonconforming) products has shifted away from its nominal value is a p or an np chart (see for example De Araújo Rodrigues, Epprecht, & De Magalhães (2011)). For an extensive review of research on control charts for attribute data the interested reader is referred to Woodall (1997) while excellent introductory material on this topic may be found in the monographs of Duncan (1986) and Montgomery (2005).The continuous effort on improving the quality of manufactured products has offered efficient tools to set up processes with very small number of non-conforming items (Xie & Goh, 1992, 1993). Such processes are typically called high quality processes (or zero-defects processes). Paradoxically, although the p and np charts have been proven quite effective in the course of time, they are incapable of monitoring high quality processes (see for example Wang (2009)). This is mainly due to the fact that the rules used in these charts are couched on the fraction of non-conforming items (or defects) appearing in the sample under inspection; hence, if a small or moderate shift occurs in a zero-defect process, the out-of-control fraction of non-conforming items will still be very small, and as a consequence, it is highly probable, that no defective items will be observed in the inspected sample. Therefore, for small or moderate shifts, standard p or np charts fail to diagnose a change in a high quality process.For this reason, in case of processes involving small fractions of non-conforming units, the use of standard p or np charts may require that the practitioner enlarge dramatically the sample size or consider up to 100% inspection (Bourke, 1991).Another practical drawback of the standard p or np charts is the intuitively meaningless lower control limit, which in most of the cases takes on a negative value and it is therefore set equal to zero; in this case the chart does not have the potential to detect process improvement.The aforementioned shortcomes of the standard Shewhart p or np charts, when applied in high quality processes, motivated extensive research interest towards establishing alternative controlling schemes that avoid the use of the number of non-conforming items in the sample under inspection. We recall that, when very small fractions of non-conforming items (small values of p) are observed, the number of defective items can be approximated by an appropriate Poisson distribution, while the number of non-defective items between these defective items may be described by an appropriate exponential distribution. Charts based on such approximations have been introduced and studied by Nelson (1994).A similar idea, initially launched by Calvin (1983) and further studied by Goh (1987a, 1987b) is to use the exact distribution of the number of non-defective items between consecutive defective items. This approach gave birth to a new control chart, which exploits the cumulative count of conforming items between two successive non-conforming items in order to construct the rule that initiates the out of control signal; the name used for this chart is CCC1 (Cumulative Count Conforming) control chart.A direct modification of CCC1 chart, is the so-called CCCrchart which exploits the number of inspected items until r nonconforming items are observed (Bourke, 1991; Ohta, Kusukawa, & Rahim, 2001; Chan, Lai, Xie, & Goh, 2003). The CCCrchart is more sensitive to small upward shifts as r increases. However, when large values of r are used, CCCrbecomes very ineffective in detecting large upward shifts and requires a larger number of items to be tracked down, a fact that results in a substantial cost upsurge.Tang and Cheong (2006) introduced a modified Cumulative Count Conforming chart for monitoring high quality processes when inspection is carried out in groups while Niaki and Abbasi (2007) dealt with the problem of monitoring multi attributed high quality processes. Albers (2010) studied the problem of optimal design of negative binomial charts, Chen, Chen, and Chiou (2011) presented a CCC chart with variable sampling intervals and control limits while Albers (2011) introduced a class of nonparametric control charts for high quality processes. All the charts mentioned so far require 100% inspection. For an approach allowing for periods when no inspection is exercised see Reynolds and Stoubos (1999).Besides the Shewhart-type control charts reviewed above, CUSUM and EWMA control charts have also been suggested in the quality control literature for monitoring high quality processes, see Yeh, Mcgrath, Sembower, and Shen (2008) and Szarka and Woodall (2012). However, in most of the cases they are too complicated for the practitioners.A reasonable question arising from the foregone discussion is how one could monitor the stability of a high quality process, by exploiting simple to apply detection schemes that will work efficiently for both moderate and large shifts.Motivated by this observation, in the present article, we propose a control chart that uses a simple to apply compound rule for monitoring high quality processes. In Section 2, we review the CCCrcontrol charts which are the basic ingredient of our compound rule. In Section 3, we provide the necessary notations and introduce the new control chart while in Section 4, we suggest a technique for assessing the run length distribution of the new control chart by exploiting a Markov Chain imbedding method. A comparative study of the performance of the suggested monitoring scheme against other competing techniques is given in Section 5. Finally, in Section 6 we present two real data examples followed by some conclusions.As already mentioned, in the case of high quality processes it is difficult to identify even large shifts since only a few defects occur. To address this problem, it seems plausible to couch our decision on the cumulative count of conforming items (CCC1 rule) between two consecutive nonconforming ones. Apparently, small values of the cumulative count of conforming items correspond to increased number of nonconforming products and this is an indication of a possible shift in the process. On the contrary, if large values of cumulative count of conforming items are observed one may conclude that the process is in control.Let Y1 denote the number of conforming units till the appearance of the first nonconforming unit and Yi, i=2,3,… the number of conforming units between the (i−1)th and the ith nonconforming items. Apparently, if we assume that consecutive products are serially independent (this is the typical case in most process control applications) and denote by p the fraction of nonconforming items of the monitored process, then the random variable Yi+1 (number of items inspected after the occurrence of the (i−1)th nonconforming item to the ith nonconforming item) will follow a standard geometric distribution with probability mass functionP(Yi+1=n)=p(1-p)n-1,n=1,2,….When a false alarm level at most a is set, the exact probability limits LCL, UCL for CCC1 should satisfy the inequalitiesUCL⩾ln(a/2)ln(1-p),LCL⩽ln(1-a/2)ln(1-p)It is worth mentioning that, in most publications, these formulae are given in the form of equalities; however if we wish LCL, UCL to be positive integers, we should identify them by the aid of the aforementioned inequalities. The use of exact probability limits is quite popular in the quality control literature, see e.g. Calvin (1983) and Wetherill and Brown (1991). For a discussion of control charts associated to the geometric distribution see Kaminsky, Benneyan, Davis, and Burke (1992).In a CCC1 chart, the observed values of Yi+1, i=1,2,3,…, are plotted against i and an out of control signal is issued at time min{i:Yi+1⩾UCL or Yi+1⩽LCL}. If a plotted point falls below LCL it seems reasonable to conclude that the process has deteriorated (i.e. an increase in the value of p has occurred) while should a point be plotted above UCL it may be inferred that a possible improvement in the process has occurred.A straightforward generalization of the CCC1 chart principle arises if, instead of looking at the cumulative count of conforming items between two consecutive nonconforming units, we couch our decision on the total number of conforming items between r⩾1 consecutive nonconforming units. The resulting control chart will be called CCCrchart.In order to describe the underlying probability model in a CCCrchart, let us denote byYr,i=∑j=0r-1Yi-j,i=r,r+1,…the number of conforming units between the (i−r)th and ith nonconforming items. If p stands for the fraction of nonconforming items in an in-control process, then Yr,i+r, i=r, r+1,… will follow a standard negative binomial distribution with probability mass functionP(Yr,i+r=n)=n-1r-1pr(1-p)n-r,n=r,r+1,….The lower and upper control limits LCL, UCL should satisfy the following inequalities∑i=UCL∞i-1r-1pr(1-p)i-r⩽a/2,∑i=rLCLi-1r-1pr(1-p)i-r⩽a/2,where α is a prespecified (maximum) level of false alarm. In the resulting CCCrchart plot, the observed values of Yr,i+r should be plotted against i=r, r+1, r+2,… and a signal will be issued at time min{i:Yi+r⩾UCL or Yi+r⩽LCL}.Since the use of large r values will result in a rapid upsurge of the lower control limit as the process fraction nonconforming p approaches zero, it is advisable that small values of r be used when a high quality process is to be monitored.Bourke (1991) proposed the use of the CCC2 (termed as RL2) for monitoring high quality processes. Chan et al. (2003) argued that a CCCrchart with large r will detect a shift in p much faster than a CCCrwith a smaller value of r. Bourke (2006) studied in detail the performance of the CCC2 chart (also, in relation to the np chart) and offered guidelines for choosing the chart parameters.Unfortunately, CCCrcharts have not been used much in practice; this might be attributed to the fact that, when large shifts occur, the CCCrchart becomes very insensitive as r increases.Motivated by the last remark, we introduce in the next section a compound rule that uses simultaneously the principles set in a CCC1 and CCC2 chart. It turns out that the compound rule guarantees a fast detection of moderate and large shifts in the quality of the monitored characteristic; therefore it offers a nice tool that overcomes the difficulty of CCCrcharts to capture large shifts (when large r’s are used) while at same time it is quite simple to be put to use by a practitioner.As already mentioned in Section 2, the decision rule used in a CCC1 chart is of the form “declare the process out of control if Yi⩽k1”. The design of the chart involves the choice of parameter k1 so that a desirable level of performance is achieved. We recall that, since a quality expert would traditionally be interested only in getting warnings for possible upward shifts in the fraction p of nonconforming items, no UCL needs to be used in the decision rule.Likewise, the decision rule for CCC2 chart is of the form “declare the process out of control if Yi−1+Yi⩽k2”, where k2 is the design parameter (appropriately chosen so that a prespecified (maximum) level of false alarm is achieved).The compound rule to be studied in this article makes simultaneous use of both decision rules stated above. Thus, the combined decision rule, to be denoted by CCC12, will be of the form “declare the process out of control if Yi⩽k1 or Yi−1+Yi⩽k2”, where k1,k2 are positive integers (k1<k2) selected so as to secure a desired in and out of control performance.The introduction of this compound rule is justified by the fact that the simultaneous use of both CCC1 and CCC2 charts is expected to offer increased detecting ability for small to moderate shifts as compared to the sole use of CCC1 and a satisfactory performance for large shifts. Moreover they are simple enough to be easily implemented by practitioners a fact that ensures the use of the proposed chart in practical applications.It should be stressed that in the proposed chart we use only a lower control limit and not an upper one. This is because we are not interested in having a signal when the plotted quantity increases beyond an upper control limit, since that would simply indicate process improvement. It is worth mentioning that in the SPC literature, process improvement is of equal importance as deterioration, however this is the case when improvement occurs after a corrective action has taken place. The time this correction is carried out is known in advance and the practitioner wishes to detect this improvement afterwards. The present study does not address such a problem, so it seems plausible to ignore the UCL and trigger an alarm only when the LCL is violated. Similar one-sided control charts have been in use when one wishes to detect increases in the variance of the process, see e.g. Crowder and Hamilton (1992) and Maravelakis and Castagliola (2009).A popular performance indicator for control charts of high quality is the Average Number of Inspected Samples or Average Number of Items Sampled (ANIS). If S represents the number of products tested until the chart produces an out-of-control signal (given an initial state of the process), then the mean of S is called Average Number of Inspected Samples (ANIS). The in-control ANIS (to be denoted by ANIS0) is the mean of S, provided that the process is in-control; it represents the average number of samples until the process is declared out-of-control while in fact is in-control. In a similar fashion, the mean of S provided that the process is out-of-control is called out-of-control ANIS and will be denoted by ANIS1. It is noteworthy that, in our case, the sample consists of a single product (item) and that the number of items representing a point in a chart are only the conforming ones (namely the conforming items lying between two nonconforming ones).Apparently, the performance of the compound rule may be assessed by studying the event S=s which occurs if and only if•at the time the sth item is inspected, either of the conditions Yi−1+Yi⩽k2 or Yi⩽k1 is satisfied, andneither of the above conditions was met up to the inspection of the (s−1)th item.In the next section we offer a method that leads to the exact computation of the run length distribution i.e. the distribution of the waiting time random variable S. To achieve this, we shall be using a finite Markov chain imbedding technique.In this section, we focus on the calculation of the exact distribution of the random variable S. We shall first provide some general results pertaining to the imbedding of waiting time random variables in a finite Markov chain; then we shall use these results to illustrate how the run length distribution of the composite rule introduced in Section 2 can be assessed.Let us denote by f(s)=P(S=s), F(s)=P(S⩽s), the probability mass function and cumulative distribution function of the random variable S.A simple method for capturing the exact distribution of S is offered by using the Markov chain Imbedding technique (see Fu & Koutras (1994); a more convenient reference is the monograph by Fu & Lou (2003) or Balakrishnan & Koutras (2002)). According to this technique a discrete random variable S defined on a sequence of binary trials can be described by a Markov Chain {Vt,t=0,1,2,…} with finite state space Ω={α1,α2,…,αc} so as its cumulative distribution be captured by the formulaF(s)=P(S⩽s)=P(Vs=ac).State αcis the absorbing state of the Markov Chain {Vt,t=0,1,2,…} andπ0′=(P(V0=a1),P(V0=a2),…,P(V0=ac))the (row) vector of initial probabilities of it. Denoting byΛ=[P(Vt=aj|Vt-1=ai)]c×cthe transition probability matrix of the chain, it is immediate that F(s)=P(S⩽s) can be expressed as(4.1)P(S⩽s)=Pr(Vs=ac)=π0′Λsec,whereec′=(0,0,0,…,0,1)1×c∈Rc.The probability mass function of S may then be easily deduced by exploiting the formula P(S=s)=P(S⩽s)−P(S⩽s−1) which, in view of (4.1) yieldsP(S=s)=π0′(Λs-Λs-1)ec=π0′Λs-1(Λ-I)ec.Taking into account that asis an absorbing state, we may write the transition matrix Λ in the form(4.2)Λ=Ph0′1,h=1-P·1where P is a (c−1)×(c−1) matrix, and 0=(0,0,…,0)′, 1=(1,1,…,1)′ are (c−1)×1 column vectors. Then, the probability mass function of S takes on the following more attractive form(4.3)f(s)=P(S=s)=π1′Ps-1h,whereπ1 is a (c−1)×1 column vector that contains all the entries of the initial probability vectorπ0 except the last one. More details on the development of these formulae may be found in Balakrishnan, Bersimis, and Koutras (2009).According to the foregone discussion, in order to capture the exact distribution of S, it suffices to define an appropriate Markov Chain {Vt,t=0,1,2,…} and then use formula (4.3) for calculating the probability mass function of the random variable S. Thus, the problem of capturing the exact distribution of S, calls for the establishment of an appropriate state space and the computation of the associated transition probabilities.A state space that may serve adequately our needs in the case of the waiting time random variable S is the followingΩ={(u1,u2):u1=0,1,2,…,k2+1,u2=k1+1,…,k2+1}∪{∗},where {∗} stand for the absorbing state of the chain. The indices u1 and u2, used to describe the states of the Markov chain, have the following meaning:•If 0⩽u1⩽k2, then there exist exactly u1 nonconforming items (failures) between item t and the last non-conforming item (we assume that we always begin with a nonconforming item). If u1=k2+1, then there exist at least k2+1 conforming items between item t and the last observed non-conforming item.If k1+1⩽u2⩽k2−u1, then there exist exactly u2 conforming items between t and the previous, before the last, non-conforming item observed in the sequence 1, 2, …, t (looking backwards from t). If u2=k2+1 then there exist at least k2+1 conforming items between t and the previous, before the last, non-conforming item observed in the sequence 1,2,…,t (looking backwards from t).For illustration purposes, let us consider the sequence of length 20 displayed in the second row of Table 1. In the row entitled “Diagnosis”, label “C” stands for a conforming product while label “N” for a nonconforming one. Rows 3 and 4 display the values of the indices u1 and u2 when the parameters k1, k2 take on the values k1=2, k2=5. We recall that, we deal with a control chart using 100% inspection. Our Markov chain enters its absorbing state at time t=20 (i.e. when the 20th product is inspected) since this is the first instance where one of the conditions of our composite rule is met (namely Yi⩽k1=2).Having defined our state space Ω, the next step to take is the description of the transition matrix P. Denoting by p the probability of observing a conforming item and q the probability of observing a non-conforming item, provided that the process is in control, the non-vanishing transition probabilities of matrix P are arising as follows:•from state (u1,u2) we can move with probability p to–state (u1+1,u2+1) if u1⩽k2 and u2⩽k2,state (u1+1,k2+1) if u1⩽k2 and u2=k2+1,state (k2+1,k2+1) if u1=k2+1 and u2=k2+1.from state (u1,u2) we can move with probability q to–state (0,u1) if u1>k1 and u2>k2,absorbing state if u1⩽k1 or u2⩽k2.It is not difficult to check that, P is a (k2+2)(k2−k1+1)×(k2+2)(k2−k1+1) matrix and may be written in blocked form as follows:(4.4)MatricesP0,…,Pk2+1,Qk1+1,…,Qk2+1and 0 have dimension (k2−k1+1)×(k2−k1+1), with allP0,…,Pk2+1being equal toPx=0p000000p000000⋱000000p000000p00000pwhile Qx, x=k1+1, k1+2,…,k2+1 are of the formQx=00⋯0000⋯00⋮⋮⋱⋮⋮00⋯00q·δx,k1+1q·δx,k1+2⋯q·δx,k2q·δx,k2+1.We have used the symbol δm,nto denote the well known Kronecker delta function which takes on the value 1 if and only if m=n and 0 elsewhere.Finally, the vector of initial probabilities associated with the imbedding we have described above, is a vector of length (k2+2)×(k2−k1+1) having all its entries 0 except for the k2−k1+1 element which equals 1.As an example let us consider the case k1=2 and k2=6. Then the blocks of the transition probability matrix P are given as follows:Px=0p00000p00000p00000p0000p,forx=0,1,2,…,7,Q3=00000000000000000000q0000,Q4=000000000000000000000q000,Q5=0000000000000000000000q00,Q6=00000000000000000000000q0,Q7=000000000000000000000000q.The vector of initial probabilities is a vector of length 35 with all its elements vanishing except for the 5th entry (is associated to the state {(0,6)} of Ω) which is 1.It must be stressed that some of the states of the transition matrix P are inaccessible and could therefore be eliminated so as the size of P be reduced. However, we chose to retain them, since this way we can have a more compact description of the transition probability matrix in use.The computation of the exact distribution of S can now be easily accomplished by exploiting formula (4.3). A program, in Mathematica and Matlab formats, that calculates the probability mass function of S is available by the authors upon request. In Fig. 1, we present the distribution function for various values of parameters k1, k2 and p.The composite chart introduced in this article is a combination of CCC1 and CCC2 charts. Therefore, it seems plausible to proceed to a direct comparison of the performance of all CCC12, CCC1, CCC2 charts in terms of their ANIS values. To achieve a fair comparison, the typical procedure used in quality control literature is to set the ANIS0’s of all charts “as close as possible” and then compare the average number of samples (items) needed till an out-of-control signal is triggered. We recall that, since the run length distributions we are dealing with are discrete, it is not possible to choose the parameters of our charts so as all ANIS0’s be identical, therefore we go with the “as close as possible” requirement.In Table 2, we provide the ANIS values for the three competing charts CCC1, CCC2 and CCC12. In the first column the type of chart is stated. The values next to CCC12 charts indicate the k1, k2 values selected. Likewise, the values next to CCC1 and CCC2 charts indicate the control limits of each chart.The column labeled as ANIS0 refers to the in-control ANIS value of each chart. This value varies for the six charts under comparison, however the differences are quite small and we can argue that they are practically insignificant (note that in all cases, the differences are in favor of CCC1 and CCC2 charts). The in-control fraction of nonconforming items was set at 0.010. The last six columns (under the ANIS1 label), display the ANIS1 achieved by each control chart for (out of control) nonconforming fractions ranging from 0.03 to 0.11. It is clear that the CCC12 chart, for at least a pair of (k1,k2), has the best performance for all p>0.03 values considered in Table 2.The parameters k1 (i1<k1<j1) and k2 (i2<k2<j2) are algorithmically selected. Specifically, we create a (j1×j2) dimensional table including the values of the in-control ANIS. We then choose the combinations of k1 and k2, leading to in-control ANIS values close to the target. For all these pairs, we calculate the out-of-control ANIS for the shift we aim to and we choose the combination giving the minimum out-of-control ANIS.In Table 3we provide a similar comparison with an in-control p value 0.001. Note that CCC2 exhibits the best performance for small shifts, CCC12 outperforms for moderate shifts and finally CCC1 exhibits the best performance for large shifts.In Table 4an additional comparison is given considering an in-control p value 0.005. In this case, we arrive again at the conclusion that CCC2 has the best performance for small shifts and CCC12 is the fastest control chart for moderate and large shifts.A reasonable question that could be raised here is, why should one use CCC12 and not, for example, CCC13 (which is in fact a combination of CCC1 and CCC3) or any similar composite scheme. For illustration purposes we present in Table 5a comparison of all 4 schemes CCC1, CCC2, CCC12 and CCC13. As can be easily verified the suggested scheme (CCC12) is equally good or faster than CCC13 for all practiced shifts. Similar results have been deduced for other combinations of the parameters as well as for other charts of the same nature. Keeping in mind that CCC12, as compared to other composite charts, seems to be the easiest one to implement and interpret, we suggest its use for the cases described in this paper.In closing this section, let us compare the performance of the proposed chart to other alternatives like the EWMA chart. Since the distribution of the CCC data is highly skewed we should formally employ a transformation that will produce values whose distribution is close to the normal distribution. Two popular EWMA charts that could be used are: the EWMA-Q chart (see e.g. Quesenberry (1995)) or the EWMA chart which makes use of the double square root transformation (Nelson’s approach). According to (p. 171–172, Xie, Goh, & Kuralmani (2002)) the performance of the two charts is almost the same. However, the EWMA chart using the double square root transformation has the advantages that the distribution does not have to be known or estimated and it is simpler to implement and understand. Therefore, it seems to be preferable for the type of data we have at hand. In Table 6, we present the ANIS values for CCC1, CCC2, CCC12 and EWMA charts. As expected, the EWMA chart is significantly faster than the other charts. Similar results arise for rest parameters combinations not reported in the present paper.In order to illustrate the use of the proposed chart, we shall present two examples.Example 1Let us consider a procedure designated for monitoring the content of a specific drug used by patients suffering uterus cancer. Since the active substance needs to be exactly at a prespecified nominal value, the pharmaceutical company should undergo a 100% inspection. Each vial contains 5milliliter and the active substance in it should be exactly 30milligrame. If the active substance weight deviates from the nominal value then the vial is considered as non-conforming.Since the drug is of vital importance for the health of the patient that uses it, the pharmaceutical company should choose to set the in control value of p to a very small value, say 0.001. Should one wish to work with control charts having an in control ANIS value close to 10,000, the design parameters of the CCC12 chart could be set to k1=61, k2=500, while for the CCC1 and CCC2 charts one could use the values k1=106 and k2=641 respectively.Using the data for the active substance weights of the vials produced during a specific time period that the process was shifting out of control, we obtained the three control charts (CCC1,CCC2 and CCC12) displayed in Fig. 2. In Fig. 2, the x-axis represents the number of runs of conforming items, while the y-axis represents the values of Yi−1+Yiand Yi, respectively. The CCC1 chart triggers an out of control signal at sample points 28 and 46, CCC2 chart gives an out of control signal at sample points 10, 29, 30, 31 and 46. For the CCC12 chart the points plotted below the control limit are 10, 28, 29, 30, 31 and 46. It is clear that the CCC12 chart is faster than CCC1 and at the same time it keeps issuing an alarm at the points where the CCC2 chart does.Example 2Xie, Goh, and Lu (1998) presented a real data set from a read-write error test of a specific computer hard disk. A sample is considered as non-conforming if there occurs at least one non-conformity. The data used are the ones given in Table 2 of Xie et al. (1998) with an appropriate modification to make them fit to our framework. Specifically, each point in the CCC data of Xie et al. (1998) consists of the conforming items plus the last non-conforming item. In the methodology presented in the previous sections we do not count the last non-conforming item in each point, but only the conforming items. Therefore, the data used are the ones in Table 2 of Xie et al. (1998) minus one for each of the 28 points.The value of p is not known therefore it needs be estimated. The raw data consist of 208 observations and the total number of non-conformities occurring among them is 28, thereforpˆ=28208=0.1346. In order to plot the control charts we need to choose the parameters so that the competing charts have similar performance. Using the methodology practiced in previous sections we get that the appropriate parameters to achieve this are k1=1 for CCC1, k2=6 for CCC2 and k1=0, k2=2 for CCC12. The control charts are depicted in Fig. 3.The CCC1 chart issues an out of control signal at sample points 3, 4, 5, 6, 8, 10, 11, 13, 15 and 16, CCC2 chart gives an out of control signal at sample points 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15 and 16. For the CCC12 chart the points plotted below the control limit are 4, 5, 6, 8, 9, 11, 13, 15 and 16.

@&#CONCLUSIONS@&#
In this paper we introduced a new control chart for monitoring high quality processes. This chart uses a combination of two well established rules which couch on the cumulative count of conforming items. The run length distribution of the suggested chart is studied by means of a suitable Markov chain approach. It appears that the performance of the new control chart, which is easy to apply and interpret, has a performance better or as good as alternative control charts whose implementation is more difficult, therefore it is expected to offer a useful tool to the practitioners who wish to monitoring high quality processes.