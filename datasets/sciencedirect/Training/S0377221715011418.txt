@&#MAIN-TITLE@&#
Optimal search and ambush for a hider who can escape the search region

@&#HIGHLIGHTS@&#
How to solve a search game when the hider can escape the search region.How to optimize the alternation between search and ambush.When should the hider attempt to flee the search region?How should ambush frequency change over time?What is optimal portion of region to search when time is limited?

@&#KEYPHRASES@&#
Game theory,Two-person games,Search games,Search problems,Predator–prey interactions,

@&#ABSTRACT@&#
Search games for a mobile or immobile hider traditionally have the hider permanently confined to a compact ‘search region’ making eventual capture inevitable. Hence the payoff can be taken as time until capture. However in many real life search problems it is possible for the hider to escape an area in which he was known to be located (e.g. Bin Laden from Tora Bora) or for a prey animal to escape a predator’s hunting territory. We model and solve such continuous time problems with escape where we take the probability of capture to be the searcher’s payoff.We assume the searcher, while cruise searching, can cover the search region at unit rate of area, for a given time horizon T known to the hider. The hider can stay still or choose any time to flee the region. To counter this, the searcher can also adopt an ambush mode which will capture a fleeing hider. The searcher wins the game if he either finds the hider while cruise searching or ambushes him while he is attempting to flee; the hider wins if he flees successfully (while the searcher is cruising) or has not been found by time T. The optimal searcher strategy involves decreasing the ambush probability over time, to a limit of zero. This surprising behaviour is opposite to that found recently by Alpern et al. (2011, 2013) in a predator-prey game with similar dynamics but without the possibility of the hider escaping. Our work also complements that of Zoroa et al. (2015) on searching for multiple prey and Gal and Casas (2014) for a combined model of search and pursuit.

@&#INTRODUCTION@&#
Since their introduction in the classical text of Isaacs (1965), search games have proved a useful method of modelling optimal search for a mobile or immobile antagonistic hider who is confined to a bounded search regionR. Even for mobile hiders, it was shown by Gal (1979); 1980) for multidimensional regions and Alpern and Asic (1985) for finite length networks, that eventual capture is almost surely accomplished and moreover capture time has finite expectation. Hence such games have been traditionally solved by taking capture time (search time) as the payoff of a zero sum game.However in many real life problems, the hider is able to at least attempt to leave the region in which he is initially known to be confined. For example, Osama Bin Laden successfully escaped from the Tora Bora caves, where he was at one time known to be hiding (see Weaver 2005). In the predator-prey context, it is possible for the hider (prey animal) to escape the hunting territory of the predator who is searching for it. In such a context of potential escape, a more reasonable searching aim is to maximize the probability of eventually finding the hider, placing less emphasis on the search time but more on the search outcome. Here we initiate the study such problems where the searcher has a limited time horizon T in which to capture the hider and the eventual outcome is uncertain.Thus we are led to a continuous time game, where the hider can stay still or choose any time m, 0 ≤ m ≤ T, in which to attempt a flight from the search region. To counter this possibility, the searcher has an additional ‘ambush’ mode, in which he can counter an attempt at flight. In the predator-prey context, the ambush mode might involve sitting still and surveying the search region for a move of the prey, or an eagle circling above the region to spot the prey if it goes out of the vegetation cover in an attempt to leave the region. For law enforcement, an ambush mode might involve setting up road blocks to counter an attempted location change of an escaped prisoner (who has escaped prison but not the surrounding search region). In a search game context on a network, ambush strategies might consist of the searcher waiting at a node (e.g. the central node of a star network) to catch a mobile hider. Such search strategies were initially excluded by Gal (1979) in order to obtain certain results, but later incorporated into the theory by Alpern and Asic (1986), who showed that in the figure eight network they had to be present in optimal search strategies. Such strategies were shown to be important in a predator-prey context for dual mode predators (who can alternate between a ‘sit and wait’ mode and a cruising mode) by Alpern, Fokkink, Gal, and Timmer (2013); Alpern, Fokkink, Timmer, and Casas (2011). Thus our game has four possible outcomes. The two outcomes where the hider wins are (i) where the hider never attempts to flee and is not found by time T, and (ii) where he successfully flees because the searcher is cruise-searching at the flight time m. The two outcomes where the searcher wins are when he (iii) finds the hider while cruise-searching, before any hider attempt to flee, and when he (iv) ambushes the hider when the latter attempts to flee, by adopting the ambush mode at time m.To give the reader some additional intuition about our model, we mention an interpretation of the a discrete time version given in Section 5 as a smuggling or search-inspection game: A smuggler (hider) brings his material randomly to one of n identical warehouses on the left side of a river. The police are known to be in the area for T days. On any of these days, or on dayT+1,the smuggler can attempt to cross the river to the safe right side. Similarly, on each day the police can either search one of the warehouses or alternatively patrol the river, but not both. The police apprehend the smuggler if on one of the T days they either find the material in the warehouse they search, or are patrolling and the smuggler attempts to cross the river. If at the end of the T days the smuggler has not attempted a crossing and he has not been found, he can cross without fear on the next day, so he wins. The smuggler also wins if he crosses on a day when the police are searching a warehouse. We need to add the ‘noisy searcher’ assumption that the smuggler, safe in his warehouse, can hear whether or not a speedboat is patrolling the river, so each morning he knows how many warehouses have been searched thus far. The ‘silent’ version, with a canoe instead of a speedboat, is a harder problem, still open. Some progress in this context was made by Arcullus (2013).While the notion that the sought after hider has the possibility of fleeing the search region is new, the notion of an ambush strategy for the searcher has been studied in the literature. Originally introduced for search games in Alpern and Asic (1986), various forms of ambush problems have been explored in Baston and Bostock (1987), Hohzaki and Iida (2001), Baston and Kikuta (2004), and Zoroa, Fernández-Sáez, and Zoroa (2011); Zoroa, Zoroa, and Fernández-Sáez (1999). In the predator-prey context, the ambush mode of certain predators is often called the ‘sit-and-wait’ strategy. The alternation of predators between cruise searching and ambush search has been studied by Alpern et al. (2011); Arcullus (2013), Zoroa, Fernández-Sáez, and Zoroa (2015) and Arcullus (2013). The biological context has received additional attention in a wider context by Broom (2013), Pitchford (2013) and Gal and Casas (2014), where hide-search is combined with pursuit-evasion in a novel way. Djemai, Meyhöfer, and Casas (2000) gives related empirical work on search problems between a host and a parasitoid. Other recent work on search games includes the more abstract work of Oléron Evans and Bishop (2013) and the operational research related approach of Zoroa, Fernández-Sáez, and Zoroa (2012); Zoroa, Zoroa, and Fernández-Sáez (2009). The two monographs on search games are Garnaev (2000) and Alpern and Gal (2003). Related work on patrolling is given in Lin, Atkinson, Chung, and Glazebrook (2013) and Zoroa et al. (2009). Connections with inspection and smuggling games are mentioned in Section 5, on a discrete version of our game.We begin by describing a continuous time dynamic model of search and ambush that is similar to that introduced in Alpern et al. (2013, 2011). A hider (prey) is hidden at a random point of a unit size (area) search regionR.The searcher (predator) can searchRat a unit time rate for time T, so that all ofRcould be searched by time 1 (if T > 1). However the hider can counter exhaustive search by fleeing (leaving the regionR) at a timet=mof his choice. In this model, successful flight (during a period when the searcher is cruising) wins the game for the hider. To counter this possibility, the searcher can adopt an ambush mode which will catch a fleeing hider, winning for the searcher. The game ends, as a win for the searcher, if the searcher either finds the hider before he flees or if he successfully ambushes the hider while he is fleeing. Thus far the dynamics of our model are the same as in Alpern et al. (2011). However in that model a successful (unambushed) flight by the hider simply gives him a new randomized location in the regionR,leading to a repetition of the stage game. In the current model a successful flight takes the hider outside ofRto a safe location, and is thus considered a win for him. In the previous model eventual capture of the hider was ensured, only its time was in doubt, and the searcher’s aim was to minimize the search time. In the current model, eventual capture is not assured, and the searcher’s aim is to maximize the probability of capture. Thus the current model is a win-lose game where capture (by either by finding the prey while cruising or ambushing it while it is fleeing) is a win for the searcher (payoff 1) and successful flight (during a cruising period of the searcher) a win for the hider (payoff 0). More generally, the payoff (to the maximizing searcher) is the probability of a capture, and the value V of the game is the optimal probability of capture, given best play on both sides. If the searcher has an unlimited time horizon in which to capture the prey, he can win with as high a probability as he likes. For example if he ambushes 99% of the time, randomly placed within each unit interval, he will still eventually search the whole regionR.Consequently the hider cannot afford remain still forever. But whenever he flees, he will face an ambushing searcher and be captured, with 99% probability. So we make the reasonable assumption that the searcher has a limited time T in which to make the capture, perhaps this is the length of the daylight period. We analyse this game Γ(T).We formally describe the game Γ(T) where the searcher tries to capture the hider within a fixed time horizon T, either by finding him or ambushing him. As described in Alpern et al. (2013, 2011) the alternation between searching and ambushing can be modelled very simply by a search strategy s(t), 0 ≤ t ≤ T which measures the amount (or equivalently, fraction) ofRthat the searcher has covered by time t, given that he covers area at unit rate while cruising and at zero rate while ambushing. We have the restrictions(t2)−s(t1)≤t2−t1as well as the initial conditions(0)=0.Suppose that in a small time intervalJ=[t,t+Δt]the searcher adopts a search mode one third of the time and an ambush mode two thirds of the time, perhaps randomly in many subintervals. Then the total area ofRsearched during the time interval J will be Δt/3, so we may describe s on this interval bys′(t)=1/3,ands(t+Δt)−s(t)=Δt/3.A smooth function s is considered as the uniform limit of alternations between cruising and ambushing, as described more specifically in the earlier papers. In general, we interpret s′(t) as the probability that the searcher is searching at time t, with the complementary probability1−s′(t)for ambushing. Thus a hider who flees before being discovered at time m when the searcher is adopting strategy s(t) will succeed (and win) with probability s′(m) and be successfully ambushed with probability1−s′(m).A strict alternation policy of the searcher would have only two modes: searching (s′(t)=1) and ambushing (s′(t)=0), with slopes 1 or 0. We abstract the problem by taking limits of such strictly alternating paths, and require s(t) to be continuously differentiable. If we interpret s′(t) as the speed of the searcher, the assumption that at high speed he is less likely to spot a fleeing hider is in accordance with empirical data and other search models (e.g. Alpern & Lidbetter 2015). In our model, the searcher is noisy, and his speed s′(t) (the probability or intensity of searching) is detectable by the hider. (An attempt to remove this assumption from our earlier model is given in Arcullus (2013)).We evaluate the payoff functionP=P(s,m)(the probability that the searcher wins) when the searcher adopts strategys=s(t)and the hider moves at time m as the sum of two terms. The first term s(m) is the probability that the searcher finds him before he has moved, and the second is the probability that he has not been found before he moves (1−s(m)) times the probability1−s′(m)that the searcher is ambushing when the hider moves. Thus for m ≤ T we have(1)P(s(t),m)=s(m)+(1−s(m))(1−s′(m))=1−(1−s(m))s′(m).If the hider never flees, we say thatm=T+,and the payoff isP(s,T+)=s(T),the total amount searched by time T. The searcher’s strategy function s(t) can be considered as a continuous behavioural strategy and since this game has perfect recall such strategies should be sufficient.A heuristic approach to this game is for the searcher to choose s(t) so that he is indifferent to which moving (fleeing) time m the hider chooses. So if the payoff P(s(t), m) does not depend on m, it must satisfy the ordinary differential equation(2)∂P(s,m)∂m=−(1−s(m))s′′(m)+(s′(m))2=0.The general solution to (2), for the boundary conditions(0)=0,is given in terms of a parameter k as(3)sk(t)=1−1−kt,withconstantpayoff(4)P(sk,m)=1−k/2.Now k can be evaluated using the searcher’s unit speed constraint,(5)sk′(t)≡12k1−kt≤1,fort≤T,givingtheinequality(6)0≤k≤k¯,where(7)k¯=k¯(T)=2T2+1−2T.(Herek¯is the value of k so thatsk¯′(T)=1). The searcher wishes to choose k satisfyingk≥k¯to maximize his payoff1−k/2,so he takesk=k¯ands¯(t)=sk¯(t).This gives maximum payoff(8)V(T)=1−k¯/2=T+1−T2+1,which we will show is the value of the game. Note that by (5)s¯′(T)=sk¯′(T)=12k¯1−k¯T=122T2+1−2T1−(2T2+1−2T)T=1.This means that the strategys¯is cruising with probability 1 at the final time T. Thus if the hider has not been found before time T, the payoff is the same if he moves at time T or never moves. Summarizing, we have shown the following.Proposition 1Consider the game Γ(T) where the searcher has time T in which to try to find the hider. By adopting the search strategys¯(t)=1−1−k¯t, 0 ≤ t ≤ T, the searcher guarantees that for any hider fleeing time m, he captures the hider with probability(9)P(s¯,m)≥V(T)≡T+1−T2+1.Fig. 1plots the value V(t) (dashed curve) and the optimal searcher strategiess¯(t)=sk¯(T)(t)for time horizonsT=.5,1,2,3,each drawn on the relevant interval [0, T]. Note that each curve ends at T at unit slopes′(T)=1when it has searched a proper fractions¯(T)=V(T)<1of the search regionR,that is, when it reaches the V(t) curve. Thus the search strategiess¯(t),which we later show to be optimal, never complete an exhaustive search of the regionR,no matter how large the time horizon.We now establish the optimality of the searcher strategys¯(t).The following relies on our assumption that the searcher is noisy, that is, the hider at time t knows the searcher strategy s(t) up to time t, in particular the derivative s′(t). We assume there is no time delay, although in practice there might be a small time delay, so that the hider could survive only with probability close to1−V(T).A subgame perfect strategy for the hider, which relies only on the state variables s and t (and not s′) is given in the next section, and is in some senses more satisfactory.Proposition 2Let s(t) be any searcher strategy for the game Γ(T). Then for some m we have payoffP=P(s,m)≤V(T).The idea of the proof is to compare s to the strategys¯=s¯(t)described in the previous subsection. Observe that any searcher strategy s is one of three types:Type 1s′(0)≥1−V(T).Type 2s′(0)<1−V(T)and for some t,s′(t)>s¯′(t).Type 3s′(0)<1−V(T)and for all t,s′(t)≤s¯′(t).If s is a type 1 strategy, then the hider can ensure P ≤ V(T) by moving at timem=0,since he will be successfully ambushed with probability1−s′(0)≤V(T).Next suppose that s is type 2. Let m be the infimum of the set of t withs′(t)>s¯′(t).Thens′(m)=s¯′(m)ands(m)<s¯(m)and by the definition (1) of P it follows thatP(s,m)<P(s¯,m)=V(T).For s of type 3, we haves(t)<s¯(t)for all t > 0 so thats(T)<s¯(T)=V(T).So if the hider never moves (i.e. m > T) he is captured with probabilityP=s(T)<V(T).□It is now easy to convert the above proof into an effective strategy for the hider, given our assumption that the searcher is noisy and at time t the hider knows s(t) and s′(t). With some time lags of information, strategies that guaranteeP≤V(T)+ɛcan be found. For s of type 1, the hider simply moves at timem=0(or shortly thereafter if there is an information lag). For s of types 2 or 3, the hider moves at the first time m such thats′(m)=s¯′(m)and P(s, m) < V(T) if such an m exists. If not, then the hider never moves and since s covers less ofRat this point thans¯does,P(s,m)<P(s¯,m).If there is a small time lag, a constraint on the acceleration of the predator will be sufficient for the predator to approximate his current speed s′(t) from his speeds′(t−ɛ)a short time earlier. Of course our later work, with stochastic games, shows that the prey (hider) has a strategy that doesn’t require any knowledge of the predator’s speed s′(t) at all, since he only relies on knowledge of the state variable s(t), so that this technicality is avoided by our solution of the stochastic game in Section 4.Call the hider strategy we have described aboveh¯.Then we have shownProposition 3The hider strategyh¯described above ensures that the searcher captures the prey (wins) with probability P ≤ V(T), for any searcher strategy s.If we combine Propositions 1 and3, we obtain the following solution to the game Γ(T).Theorem 4The value of the ambush search game Γ(T) with a unit area search region is given byV(T)=T+1−T2+1and the optimal searcher and hider strategies are given bys¯andh¯as described above.We now consider a stochastic game approach, taking as state variables the amount of time h left for the searcher,h=T−t(if t represents elapsed time) and the unsearched area r remaining to be searched. This approach gives a subgame perfect optimal strategy for the hider. If the total area of the search regionRis normalized to 1, thenr=1−s(t).Given the stage game G(r, h), we need to determine the probabilityp(t)=s′(t)for the predator to cruise search and the probability q(t) Δt that the prey flees in the next time interval(t,t+Δt).LetF(t)=Pr(τ≤t)be the probability distribution of the prey’s fleeing time m, and letf(t)=F′(t)be the probability density. The a priori probability that the prey flees in(t,t+Δt)is equal to f(t) Δt up to order O(Δt2). However, if the game reaches stage r, h then the prey has not fled up to time t. In the stage game, the probability of fleeing in the next time interval is a conditional probability:q(t)Δt=Pr(m∈(t,t+Δt)∣m≥t)=f(t)Δt/(1−F(t))+O(Δt2).In other words, q is the intensity of the probability distribution F. It is the negative logarithmic derivative of1−F.The problem in the stage game is represented by the following matrix, where the searcher chooses the rows with (unknown) optimal probabilities p and1−p,while the hider chooses the columns with unknown optimal probabilities qΔt and1−qΔt.We determine the optimal fleeing intensity q by letting the time interval Δt go to zero.It is clear that there is no pure strategy saddle point as the optimal response to the searcher cruising is for the hider to flee; and the optimal response to a fleeing hider is for the searcher to ambush. We compute the optimal probabilities, and to compute the intensity we need to take limits Δt → 0. The result therefore depends on the terms up to first orderFor the probability of search p only the terms which are independent of Δt matter, and the matrix reduces toThe probability p of cruising that makes the hider indifferent between fleeing or waiting, is such that the sums of the columns in the matrix of constant terms, weighted by p and1−p,are balanced:1−p=V(hr).Solving for p using the formula (8) for V gives(10)p=1−V(hr)=(h/r)2+1−h/r.As the game proceeds, remaining time h decreases to zero while unsearched area r decreases to some positive number rT, the fraction of space that never is searched. Since a non-fleeing hider will be found with probability1−rTwe know thatrT=1−V(T).The probability p of search thus goes to 1 (and of ambush goes to 0) as time approaches the time horizon T. This agrees with our earlier observation, without the stochastic game approach, thatp=s′(T)=1at the conclusion of the game.The optimal fleeing intensity q, requires a computation that involves first order terms. We now need to balance the rows in the matrix up to first order, weighted by q(t) Δt and1−q(t)Δt:Δtr−V(hr)Δtr+V′(hr)hr(Δtr−Δth)−V(hr)qΔt=q−V′(hr)Δtr−V(hr)qΔt.Solving for the fleeing intensity q gives(11)q=1r(1−V(hr)+V′(hr)hr),or(12)q=1r2+h2,usingtheformula(8)forV(h/r).As observed earlier, as the game approaches its conclusion at the time horizon T, h goes to 0 and r goes to a positive number rT, so fleeing intensity goes to 1/rT. Note from (10) that p depends only on the ratio of h and r, but q does not. The probability of search p can be thought of as a speed, so it depends on the ratio of time and space. The intensity of fleeing depends on time. The state variables r and h decrease during the game. As the game continues, the hider’s urge to flee increases. Asymptotically, it is equal to 1/rT, the reciprocal value of the fraction of the space that remains unsearched.We can now determine the probability distribution F(t) of the fleeing time over the course of the game, which depends on the searcher’s strategy. The probability density of fleeing at time t is given byf(t)=(1−F(t))q(t),soq(t)=f(t)/(1−F(t))=F′(t)/(1−F(t))and so(13)∫0tq(t)dt=−ln(1−F(t)),orF(t)=1−exp(−∫0tq(x)dx)Next, we consider the equilibrium path of the game.Theorem 5The unique subgame perfect equilibrium path in the game is characterized as follows, when the area of the search region is normalized to 1. As already established, the searcher by time t covers an area equal tos¯(t)=1−1−k¯t,withk¯as in(7). By time t, the hider has fled with cumulative probability(14)F(t)=tT2+1.That is, the hider flees with uniform density on the time horizon interval [0, T], in such a way that he has fled with probabilityT/T2+1by time T.By (12), the fleeing intensity given byq(t)=1r(t)2+h(t)2=1(1−s¯(t))2+(T−t)2=1(1−k¯t)+(T−t)2=1(1−(2T2+1−2T)t)+(T−t)2=11+T2−tConsequently, F(t) is given by (13) asF(t)=1−exp(−∫0t11+T2−xdx)=tT2+1,asclaimed.□We can also consider hider responses to other searcher strategies. If the searcher only ambushes and does not search, thenr(t)=1and we find thatq(t)=1/1+(T−t)2. Substitution of this intensity gives the distributionF(t)=t+1+T2−1+T2−2Tt+t2T+1+T2.So against constant ambush the subgame perfect probability that the hider flees before time T is equal toF(T)=1+T−1+T2=V(T).as it should be. Of course, if the hider knew in advance that the searcher was only ambushing, he would never move.There are four ways the game Γ(T) can end:1.hider never flees and is never found (hider wins)hider escapes, successfully flees (hider wins)searcher finds hider during cruise search (searcher wins)searcher ambushes hider while fleeing (searcher wins).In this section we calculate the probabilitiespi=pi(T),i=1,…,4,that the game Γ(T) has ending i (in the above list), under the assumption of equilibrium play (along the equilibrium path). Clearly we must have∑i=14pi(T)=1,p1(T)+p2(T)=1−V(T),p3(T)+p4(T)=V(T).It is interesting to see how the likelihood of these outcomes changes with the time horizon T.The hider wins either by a successful flight or by remaining in hiding without being found. The latter probability is(1−s(T))(1−F(T)),but the former probability is more involved. The hider flees at time t with probability f(t)dt and is the caught in ambush with probability1−s′(t),or has already been found in search with probability s(t). Therefore, the probability that the hider escapes in time(t,t+dt)is equal to(1−s(t))s′(t)f(t)dt.The probability that the hider escapes before time t0 is(15)∫0t0(1−s(t))s′(t)f(t)dt=−12∫0t0f(t)d(1−s(t))2Along the equilibrium path f(t) is constant and(1−s(t))2=(1−s¯(t))2=1−k¯t. The integral reduces to(16)12∫0t0k¯T2+1dt.In other words, along the equilibrium path the probability of a successful flight increases linearly with time during the game.By time T, the probability of a successful flight is given by (16) as(17)p2(T)=k¯T2T2+1=(T2+1−T)TT2+1,by(7),and=142(22−2)=0.29289,forT=1.The probability that the hider has not fled and has not been found by timeT=1is given by(18)(1−F(T))(1−V(T))=(1−TT2+1)(T2+1−T),orp1(T)=(T−T2+1)2T2+1,whichequals=(2−1)22=0.12132forT=1.Adding the probabilities of the two ways (17 and 18) that the hider can win gives(2T2+1−2T)T2T2+1+2(T−T2+1)22T2+1=T2+1−T=1−V(T),asexpected.The probability that the hider is ambushed before time T is the probability that he has fled by time T minus the probability (17) that he has escaped by time T, namely(19)F(T)−(2T2+1−2T)T2T2+1=(1+T−1+T2)−(2T2+1−2T)T2T2+1p4(T)=T2+1−1T2+1.Finally, we calculate the probability that the hider is found during cruise search. This must be the probability V(T) that the searcher wins minus the probability (19) that the searcher wins by ambushing, that isV(T)−T2+1−1T2+1=(T−T2+1+1)−T2+1−1T2+1p3(T)=T(T2+1−T)T2+1We can now summarize the above analysis of the equilibrium probabilities of the outcomes of Γ(T) Fig. 3.Theorem 6At equilibrium, the four outcomesi=1,2,3,4of the game Γ(T) occur with the following probabilities.p1(T)=(T2+1−T)2T2+1,p2(T)=p3(T)=(T2+1−T)TT2+1,p4(T)=T2+1−1T2+1.In particular, note that the probability that the game ends with a successful flight of the hider (who wins) is the same as the probability that it ends with the searcher finding the hider while cruising.Fig. 2shows how the likelihood of the game Γ(T) ending in the four possible ways depends on the time horizon T. Perhaps a better way to see the distribution of the probabilities for the four ending types is to use a stacked plot, in which the curves are p3(T),p3(T)+p4(T)=V(T),p3(T)+p4(T)+p2(T),from the bottom up. When the time horizon T is small, the hider is most likely not found; when T is larger the most likely outcome is a successful ambush of a fleeing hider. The region below the thick red curve V(T) is win for the searcher while above it is a win for the hider. As mentioned above, the probability that the hider is found (before he flees by a cruising searcher) is the same as the probability that he escapes (successfully flees).Our continuous game Γ(T) allows continuous time switching between ambush and search modes. Here, we show how to solve an associated discrete game G(n, τ). As described at the end of this section, this game is related to game of smuggling or inspection. We divide the search regionRinto N identical subregions in which the prey can hide. We assume each region can be searched in a single period, which is now our unit of time. SoT=1corresponds toτ=n,the time to search all possible locations. In general τ denotes the number of periods in which the searcher can find or ambush the hider. We retain the payoff 1 for a win for the searcher and 0 for a win for the hider. The payoff matrix for the game G(n, t), n ≤ N, t ≤ τ, with searcher choosing rows and hider choosing columns, is given recursively asReplacing the game name G by its value, denotedw=w(n,t)and noting that there are only mixed solutions, we obtain the recursive formulaewith boundary conditionsw(0,t)=1andw(n,0)=0.Once the values w are calculated, we can immediately calculate the optimal probabilitiesp=p(n,t)of the searcher searching andq=q(n,t)of the hider hiding. The game G(4, 6) and its optimal strategies are shown below in Fig. 4. Each node represents a subgameG(4−s,6−t),starting with G(4, 6) at the lower left (the origin). The horizontal axis is the number t of elapsed periods and the vertical axis s denotes the number of searched locations. The game starts at the origin and at each step goes slanted up (if searching) or horizontally right (if ambushing). The search strategy produces a random path that ends at the right or top dashed lines, depending on whether the searcher first runs out of time or locations to search. The optimal probability p of searching is placed (in percentage) to the left of each slanted line. The optimal probability q of the hider moving is place just to the left of the node. For example in the game G(4, 6) at the origin, the search probability is 33%, the ambush probability is 67% (not shown) and the optimal probability of an immediate move by the hider is 13%. Note that for the game G(1, 1) (at coordinate (5,3)) both p and q are 1/2 (50%), which makes sense as this is the familiar game of matching pennies. The game G(4, 6) is a model of the continuous game withT=6/4=1.5. We superimpose the continuous solution for a region of area 4, and time horizonT=6.The discrete game described above can be related to the literature on smuggling or inspection games, as in Washburn and Wood (1995), Hohzaki and Masuda (2012) and Garnaev (1994; 2000). As noted in the introduction, we can describe the discrete model as an inspection game, as follows. A smuggler (hider) brings his material randomly to one of n identical warehouses on the left side of a river. The police are known to be in the area for T days. On any of these days, or on dayT+1,the smuggler can attempt to cross the river to the safe right side. Similarly, on each day the police can either search one of the warehouses or alternatively patrol the river, but not both. The police apprehend the smuggler if on one of the T days they either find the material in the warehouse they search, or are patrolling and the smuggler attempts to cross the river. If at the end of the T days the smuggler has not attempted a crossing and he has not been found, he can cross without fear on the next day, so he wins. The smuggler also wins if he crosses on a day when the police are searching a warehouse. We need to add the ‘noisy searcher’ assumption that the smuggler, safe in his warehouse, can hear whether or not a speedboat is patrolling the river, so each morning he knows how many warehouses have been searched.Finally, it is possible to relate the discrete game to a continuous time network search game with infinite length. Consider the infinite network pictured in Fig. 5, consisting of four arcs of length 1/2 (to the left of node A) and one infinite length arc to the right of A. The game begins with the searcher at A and the hider choosing any point to the left of A. The searcher moves at unit speed for time t, 0 ≤ t ≤ T. Waiting at A corresponds to the ambush strategy, while searching an finite arc is cruise search. The hider wins if he gets to the infinite line when the searcher is not at A (or on the long line). If time ‘periods’ are of length 1 and the searcher can only stay at A or search a finite arc and return to A, the network game is in fact identical to our discrete game. In fact for any given T the long line can be of length T rather than of infinite length. Such continuous time games have been discussed in Alpern and Asic (1985; 1986).

@&#CONCLUSIONS@&#
This paper initiates the study of search games where the hider has the potential to flee the search region and the hider has a corresponding ability to counter that possibility by waiting in ambush. The strategy of ambush (called ‘sit-and-wait’ if the searcher is a predator) has some similarity to the strategy of inspect in inspection games. In our zero sum game model, the payoff to the maximizing searcher is the probability that he captures the hider. We give a complete solution to this problem, for both the searcher and the hider, for all time horizons T. The full strategy for the intensity with which the hider attempts to flee at time t requires a stochastic game formulation, which is given and solved.Our main result on the optimal search strategy s(t) giving the amount of area searched by time t is in stark contrast to the corresponding optimal search strategy in the models of Alpern et al. (2013, 2011) where a successful flight of the hider gave him merely a new location in the search region rather than (as in our current model) an escape from that region. In the former model, with expected capture time as payoff, it was found that ‘ambush frequency should increase over time’. In our model, we find that ambush frequency should decrease over time and moreover it should go to zero at the time horizon T. This stark difference thus yields a testable hypothesis for the question of whether a predator is trying to capture a prey as quickly as possible or to maximize the probability of eventual capture.By looking at a discrete version of our model, we show the relationship between our game and discrete games of smuggling and inspection which have been studied in the literature. As such, our new game can be seen as a continuous time inspection game.