@&#MAIN-TITLE@&#
Optimality cuts and a branch-and-cut algorithm for the K-rooted mini-max spanning forest problem

@&#HIGHLIGHTS@&#
We introduce optimality cuts for the K-rooted mini-max spanning forest problem.Optimality cuts are used within a new branch-and-cut algorithm.Extensive computational testings with the new method are carried out.With such an algorithm we are able to substantially improve previous results on the problem.

@&#KEYPHRASES@&#
Combinatorial optimization,Branch-and-cut,K-rooted mini–max spanning forest problem,Optimality cuts,

@&#ABSTRACT@&#
Let G = (V, E) be an undirected graph with costs associated with its edges and K pre-specified root vertices. The K−rooted mini-max spanning forest problem asks for a spanning forest of G defined by exactly K mutually disjoint trees. Each tree must contain a different root vertex and the cost of the most expensive tree must be minimum. This paper introduces a Branch-and-cut algorithm for the problem. It involves a multi-start Linear Programming heuristic and the separation of some new optimality cuts. Extensive computational tests indicate that the new algorithm significantly improves on the results available in the literature. Improvements being reflected by lower CPU times, smaller enumeration trees, and optimality certificates for previously unattainable K = 2 instances with as many as 200 vertices. Furthermore, for the first time, instances of the problem with K ∈ {3, 4} are solved to proven optimality.

@&#INTRODUCTION@&#
Let G = (V, E) be a connected undirected graph with a set V of n vertices, a set E of m edges, and associated edge costs {cij≥ 0: {i, j} ∈ E}. A forest is an acyclic subgraph of G. It is spanning if it contains all vertices of G. Additionally, it is called K-rooted if on top of being spanning it is defined by exactly K ≥ 2 mutually disjoint trees, each of them containing a distinct pre-specified root vertex. Denoting by R = {r1, … , rK} ⊂ V the set of root vertices and by {Tk= (Vk, Ek): k = 1, … , K} the set of trees for a K-rooted forest, we assume that Tkis the tree containing rk. The cost of that tree is then given by∑{i,j}∈Ekcijand the K-rooted mini-max Spanning Forest Problem (K-MMSFP) is to find a K-rooted forest of G with a minimum cost for its most expensive tree.K-MMSFP applications are described in Huang and Liu (2004), Yamada, Takahashi, and Kataoka (1997), Zhou, Min, and Gen (2002) and Mekking and Volgenant (2010). The design of reliable networks for telecommunications or electric power distribution (see Yamada et al. (1997), for details) probably being the most straightforward of them. Other noteworthy applications are related to supply chain management. In that case, a K-MMSFP model results when a particular type of location-allocation of consumers to distribution centers is imposed. Corresponding associated objective functions aim at balancing service costs (Zhou et al., 2002) or, alternatively, workload (Huang & Liu, 2004).Yamada, Takahashi, and Kataoka (1996) proved K-MMSFP to be NP-hard when K ≥ 2. Known polynomially solvable cases of the problem include the Minimum Spanning Tree Problem, for which K = 1 applies, the Bottleneck Spanning Tree Problem and the bottleneck version of 2-MMSFP (see Mekking and Volgenant (2010), for the last two problems).Heuristics and Branch-and-bound algorithms for K-MMSFP are investigated in Yamada et al. (1996) and Mekking and Volgenant (2010). The Branch-and-bound algorithm in Yamada et al. (1997), named Edge Based Branch-and-bound algorithm (EBB), uses three types of combinatorial lower bounds and performs branching on the edge variables. The one in Mekking and Volgenant (2010) implements branching on the node variables and is denoted by NBA. Refinements on the combinatorial lower bounds originally introduced in Yamada et al. (1997), allowed NBA to outperform EBB in terms of CPU time and number of Branch-and-bound nodes. More recently, da Cunha, Simonetti, and Lucena (2011) investigated two Integer Programming (IP) formulations for K-MMSFP and implemented a Branch-and-cut algorithm based on one of them.This paper significantly improves on the best results previously attained for K-MMSFP, i.e., those in da Cunha et al. (2011). While the algorithm in that reference originates from an undirected graph formulation of the problem, ours is based on a directed graph one. Indeed, our formulation was originally introduced in da Cunha et al. (2011), but was not further investigated there. Here, however, it is significantly reinforced with the use of some new optimality cuts. These cuts are related to the optimality cuts normally used in Benders Decomposition (Benders, 1962) and allowed our algorithm to outperform its most effective competitor. This assertion particularly applies to CPU time and the size of the instances solved to proven optimality. Additionally, ours is the first algorithm to solve K = {3, 4} instances, which are typically harder to solve than the K = 2 ones.This paper is organized as follows. In Section 2, our K-MMSFP IP formulation and the optimality cuts are described. Following that, our Branch-and-cut algorithm is presented in Section 3. Among others, that section also contains a separation heuristic for the optimality cuts and a multi-start Linear Programming (LP) K-MMSFP heuristic. Computational experiments then follow, in Section 4, with our algorithm being compared with those found in the literature. Finally, Section 5 closes the paper with some conclusions and directions for future research.Two IP formulations for K-MMSFP were introduced in da Cunha et al. (2011). One is based on the previously defined undirected graph G = (V, E). The other relies on a directed graph that originates from G. However, only one Branch-and-cut algorithm, associated with the formulation corresponding to G, was investigated there. Here, we opt for investigating an alternative algorithm, based on the directed graph formulation. Although the LP relaxation bounds attained by both formulations are exactly the same, we empirically noticed that, as n grows, the CPU time taken to compute each of them lean in favor of the directed graph formulation bound. Additionally, that formulation is more suitable for the separation of our optimality cuts.A directed graph D = (V, A) is obtained after redefining every edge e = {i, j} ∈ E in terms of two arcs, (i, j) and (j, i), each of them with a corresponding cost ce. Accordingly, one obtains A = {(i, j) ∪ (j, i): {i, j} ∈ E} and, for simplicity, we will also denote arc costs by {cij: (i, j) ∈ A}. The different contexts in which edge and arc costs are going to be considered should be clear enough to avoid misunderstandings.Feasible K-MMSFP solutions are described over D in terms of K disjoint arborescences spanning all vertices in V. As before, arborescence roots are denoted by {rk: 1 ≤ k ≤ K}. Variables for our directed graph formulation of K-MMSFP are then described as:•yik∈{0,1},whereyik=1(resp.yik=0) applies if vertex i ∈ V is spanned (resp. not spanned) by the arborescence rooted at rk,xijk∈{0,1},wherexijk=1(resp.xijk=0) applies if arc (i, j) ∈ A is contained (resp. not contained) in the arborescence rooted at rk,w∈R,that corresponds to the cost of the most expensive arborescence.To simplify the presentation, some additional notation is required. Accordingly, non root vertices of V are denoted byR¯=V∖R. Furthermore, given an index k ∈ {1, … , K} and subsets V′ ⊆ V and A′ ⊆ A, we defineyk(V′)=∑i∈V′yikandxk(A′)=∑(i,j)∈A′xijk. For any given S ⊆ V, the complement of S in V is denoted byS¯=V∖S. Accordingly,(S,S¯)={(i,j)∈A:i∈S,j∉S}is used to identify those arcs pointing outwards of S. Given a vector(x¯,y¯,w¯)=(x¯1,⋯,x¯K,y¯1,⋯,y¯K,w¯)∈[0,1]2Km×[0,1]Kn×Rand an index k ∈ {1, … , K}, the support graphD¯k=(V¯k,A¯k)is defined for those vertices and arcs corresponding to nonzero entries in(x¯k,y¯k)∈[0,1]2m+n. Accordingly, it thus follows thatV¯k={i∈V:y¯ik>0}andA¯k={(i,j)∈A:x¯ijk>0}apply. Conversely, when the undirected graph G is involved, E(S) = {{i, j} ∈ E, i, j ∈ S} identifies the edges of E with both endpoints in S. Additionally, for a given set S ⊆ V, let MST(S, q) be the least cost for a forest of (S, E(S)) containing exactly q edges. Finally, for a formulation P of K-MMSFP, w(P) corresponds to the LP relaxation lower bound implied by P.The directed graph formulation of da Cunha et al. (2011) is given by(1)w*=min{w:(x,y,w)∈(R2Km,BKn,R)∩PD},where polytope PDis defined as follows:(2a)w≥∑(i,j)∈Acijxijk,k=1,⋯,K(2b)∑k=1Kyik=1,i∈R¯(2c)xk((V∖{i},{i}))=yik,i∈R¯,k=1,⋯,K(2d)xk((W,W¯))≥yik,i∈R¯,W⊆V∖{i},rk∈W,k=1,⋯,K(2e)yrkk=1,k=1,⋯,K(2f)yik≥0,i∈V,k=1,⋯,K(2g)xijk≥0,(i,j)∈A,k=1,⋯,K.Constraints (2a) guarantee that w is larger or equal to the cost of the most expensive arborescence. Constraints (2b) ensure that every non root vertexi∈R¯is assigned to a single arborescence. In particular, when that vertex is assigned to the arborescence rooted at rk, constraints (2c) enforce that there must exist exactly one arborescence arc pointing to it. Strictly speaking, arcs pointing towards root vertices could have been eliminated from digraph D. However, in order to keep the notation simple we did not do that but will now assume a cost of ∞ for each of them. Accordingly, as a consequence of (2b), (2c) and the arc costs involved, precisely (n − K) arcs of D are thus implied by optimal solutions to (1). Finally, cutset inequalities (2d) guarantee that the arcs implied by any point of PDdefine a circuit free subgraph of D.An important property of polytope PDis that it may contain extreme points for which all y variables are integer valued but some of the x variables are fractional (see da Cunha et al. (2011)). However, as indicated in that reference, no branching would be necessary for a fractional solution such as that. When faced with that situation, it suffices to computing optimal arborescences for the subgraphs implied by identically indexed variables y valued at 1.Optimality cuts take as input the value of feasible solutions to K-MMSFP and may eventually cut integral points off PD. At an extreme case, input values equal the optimal solution value for K-MMSFP. When that applies, the resulting reinforced K-MMSFP “relaxation” becomes infeasible and an optimality certificate is thus obtained for the upper bound at hand. Optimality cuts, together with cutset inequalities (2d), are separated within our Branch-and-cut algorithm. We firstly address the K = 2 case. Separation for larger values of K then follow, in the sequel.Let(x^,y^,w^)be the incidence vector for a feasible 2-MMSFP solution of valuew^. In addition, assume thatD^1=(V^1,A^1)andD^2=(V^2,A^2)define the support graphs for that solution. Notice, in this case, thatD^1andD^2respectively correspond to disjoint arborescences rooted at r1 and r2. Then select a setW⊂V^1such thatr1∉W,takeS=W∪(V∖V^1),and assume thatMST(S,|S|−1)≥w^holds. Accordingly, if a feasible 2-MMSFP solution exists with a value less thanw^,not all vertices of S should be spanned by the arborescence rooted at r2. Such a condition is enforced by inequality(3)x1((V∖S,S))≥1which ensures that at least one vertex of S must be part of the arborescence rooted at r1. Notice that an inequality of type (3) is stronger than a corresponding cutset inequality (2d). However, it is not valid for all feasible 2-MMSFP solutions. In particular, it forbids solutions where all vertices of S are spanned by an arborescence rooted at r2.To indicate how inequality (3) may be used within a Branch-and-cut algorithm, let(x¯,y¯,w¯)be a LP relaxation solution to (1). Accordingly, letD¯1=(V¯1,A¯1)andD¯2=(V¯2,A¯2)be its corresponding support graphs. Now assume that out ofD¯1andD¯2,a setW⊂V¯1is selected such thatr1∉Wand a setS=W∪(V∖V¯1)is identified for which the following conditions hold: (a)MST(S,|S|−1)≥w^,and (b)∑(i,j)∈(V∖S,S)x¯ij1<1. It thus follows that the optimality cut implied by S is violated at(x¯,y¯,w¯)and should then be appended to the LP relaxation. If the resulting program turns out to be infeasible,(x^,y^,w^)would thus be certified as optimal for 2-MMSFP.In order to show how the scheme outlined above may be implemented, let us consider instance P20, 46, introduced in Yamada et al. (1997) (see that reference for the corresponding edge costs). Assuming that r1 = 1 and r2 = 20, let(x¯,y¯,w¯),depicted in Fig. 1, be an optimal solution to the problem of optimizing w over PD. Notice from that figure thatV¯1={1,2,⋯,8,11,12,⋯,19}andV¯2={9,10,⋯,20}. Notice as well that the solution respectively ships 0.1282 and 0.8718 units of flow from the roots r1 and r2 to the vertices in W = {11, 12, … , 19}. Assuming that a valid upper boundw^=871is at hand, let us takeS=W∪(V∖V¯1)={11,12,⋯,19}∪{9,10,20}. Since MST(S, |S| − 1) = 902 > 871 holds, a corresponding cut (3), which is violated by 0.8718 at(x¯,y¯,w¯),may then be appended to the LP program.Let us now address the case where K ≥ 3. Assume that S ⊂ V,r1∉Sand R∖{r1} ⊂ S. Additionally, notice that a trivial lower bound on w* is given by MST(V, n − K)/K. Therefore, a valid lower bound on the optimal solution value of the (K-1)-MMSFP instance defined by subgraph (S, E(S)), edge costs {cij: {i, j} ∈ E(S)} and roots R∖{r1}, is thus given by MST(S, |S| − K + 1)/(K − 1). Accordingly, wheneverMST(S,|S|−K+1)/(K−1)≥w^holds, inequality (3) ensures that at least one vertex in S must appear in the arborescence rooted at r1.Our Branch-and-cut algorithm uses the callback routines of Mixed Integer Programming (MIP) solver XPRESS, release 19.00. However, additional solver resources such as pre-processing tests, heuristics and procedures for separating valid inequalities are not used. The algorithm implements a best-first search strategy but, apart from that, default XPRESS settings for managing the Branch-and-cut tree are enforced.An initial lower bound on w* is obtained by solving the LP(4)min{w:(x,y,w)∈P¯D},whereP¯Dis the polytope defined by (2a)–(2c),(2e)–(2g) and{xijk+xjik≤yik,xijk+xjik≤yjk: {i, j} ∈ E, k ∈ {1, … , K}}. Denote by(x¯,y¯,w¯)a solution to (4).Quite clearly, if(x¯,y¯)∈BKn+2Kmholds,(x¯,y¯,w¯)is an optimal solution to K-MMSFP. However, whenx¯∉B2Kmandy¯∈BKnapply,(x¯,y¯)would still lead, as previously discussed, to an optimal solution to the problem. Just recalling, K different trees would have to be computed, one for every subgraph of G induced by the set of vertices assigned to a same root iny¯. These trees would be optimal for the problem and their corresponding K-MMSFP value is easy to obtain.Whenevery¯∉BKnapplies, one attempts to reinforce (4) by appending toP¯Dviolated inequalities (2d) and (3), provided they exist. If successful, the resulting reinforced linear program is solved and this overall procedure is repeated until either: (a) the linear program becomes infeasible, (b) no violated inequality is found or, (c) the solution to the linear program is integral valued. Whenever (b) applies andy¯∉BKnholds, one would then branch on a fractional valued variable y. The procedure outlined above is carried out at every enumeration tree node of our Branch-and-cut algorithm.The exact separation of cutset inequalities (2d) is carried out in O(n4) time complexity. To that effect, a series of O(n) min-cut computations are implemented as follows:1.For k = 1, … , K, do:(a)Take the network defined byD¯kand arc capacities{x¯ijk:(i,j)∈A¯k}.For everyi∈V¯k∖{rk}do:i.Compute the min-cut separating rkfrom i, denote it by(V∖Sik,Sik),and letfik=∑(i,j)∈(V∖Sik,Sik)x¯ijkbe its corresponding capacity.Letj*∈argmax{y¯jk:j∈Sik}. Iffik<y¯j*kholds, the cutset inequality∑(i,j)∈(V∖Sik,Sik)xijk≥yj*kis violated and should be appended to the LP relaxation at hand.Optimality cuts correspond to strengthened cutset inequalities (2d). As such, the two procedures we implemented for separating them benefit from the cutset separation algorithm in subsection 3.1. In particular, every vertex setSikgenerated by that algorithm is taken into account to separate optimality cuts.As before, letw^be a valid K-MMSFP upper bound. Additionally, assume that it is available at the time a minimum cut(V∖Sik,Sik),separating rkfromi∈V¯k∖{rk},is identified. The first of our optimality cut separation approaches is based on setsSikfor whichfik<1holds. These sets are taken into account even if they do not imply a violated cutset inequality (2d). Accordingly, let us assume that a setS=Sik∪(V∖V¯k)is at hand. IfMST(S,|S|−K+1)/(K−1)≥w^holds, the inequality (3) corresponding to S and to an applicable index k (and not only index 1, as in (3)) is appended to the LP relaxation. Such a cut is violated by1−fik.Our second separation approach is based on combining the candidate vertex sets indicated above. These combinations typically give rise to larger sets S for whichMST(S,|S|−K+1)/(K−1)≥w^more frequently holds. To illustrate the idea, consider the 2-MMSFP instance P20,46 with r1 = 1 and r2 = 20. Additionally, assume that a valid upper boundw^=871is available for it. The corresponding support graphD¯1for that instance is depicted in Fig. 2. Let us now assume that the separation of cutset inequalities for r1 has just been carried out and that all minimum cuts separating r1 fromi∈V¯1are readily available. Fig. 2 shows thatV∖V¯1={20}and we assume that the following vertex sets, corresponding to r1 andi∈V¯1,are at our disposal:S131={13,⋯,19}withf131=0.11277,S111={11,⋯,19}withf111=13andS71={7,9,10}withf71=23. Notice thatf131+f71=0.783930<1holds and consider setS=S131∪S71∪V∖V¯1. Given thatMST(S,|S|−1)=904≥w^=871,a violated optimality cut is thus identified and should therefore be appended to the LP relaxation at hand.The separation procedure outlined above may be formalized as follows. Assume that we are running our cutset inequalities separation algorithm. For a given k ∈ {1, … , K}, let the algorithm be at the initialization phase of the k-th min-cut computation round. Denote bySka set containing vertex setsSikfor whichfik<1apply,Skbeing initially empty. As the algorithm proceeds withSjkbeing currently investigated, wheneverSkalready contains a setSikfor whichSjk∩Sik≠∅holds, setSjkshould in principle be discarded. However, ifSik⊂Sjkandfik=fjjapply,Sjkshould replaceSikinSk. Anyway,Skmust only contain disjoint vertex sets. At the end of the current cutset inequalities separation round, every possible combination of the vertex sets inSkshould then be taken as candidates for violated optimality cuts. In more detail, letS⊂Skbe a set containing some of the vertex sets inSkand letI={i∈V¯k:Sik∈S}be its corresponding index set. Then, if∑i∈Ifik<1holds, a setS=(∪i∈ISik)∪(V∖V¯k)is defined and MST(S, |S| − K + 1) is computed for it. ProvidedMST(S,|S|−K+1)/(K−1)≥w^holds, a cut (3) violated by at most1−∑i∈Ifikis thus identified.Letw¯be a valid K-MMSFP LP relaxation bound obtained at the root node of our Branch-and-cut enumeration tree. Additionally, letrcijkbe the reduced cost of variablexijkfor the LP relaxation solution corresponding tow¯. From LP duality theory, ifrcijk+w¯≥w^holds,xijkmay be set to 0 without eliminating any optimal solution to KMMSFP.Under our formulation, every tree implied by a feasible K-MMSFP solution is described in terms of a non-spanning arborescence of D. As such, the reduced cost test above could be made stronger by borrowing ideas proposed for the Steiner Problem in Graphs in Duin (1993) and in Polzin and Daneshmand (2001). This strengthening being attained as follows. For every rk, for k ∈ {1, … , K}, associate LP reduced costs{rcijk:(i,j)∈A}to the arcs of D. Then find shortest paths going from rkto every vertexi∈R¯. Denoting bypikthe cost of one such path, ifpik+rcijk+w¯≥w^holds,xijkmay be safely set to 0.We will now describe a multi-start Linear Programming Heuristic (LPH) that generates feasible solutions to K-MMSFP. Within our Branch-and-cut algorithm, LPH is called right after every K-MMSFP LP relaxation bounding problem is solved. Such an action is taken prior to separating inequalities (3). In order to describe LPH, denote by(x¯,y¯,w¯)the LP relaxation solution at hand. Then, for any k ∈ {1, … , K}, takey¯ikas the probability of assigning vertexi∈R¯to the arborescence rooted at rk. Accordingly,{y¯ik:i∈R¯,k∈{1,⋯,K}}is then used to randomly assign the vertices inR¯to the different roots. Once the node-to-root assignments are sorted out, we run Kruskal’s algorithm for each of the subgraphs of G thus obtained. LPH is called 10 times for every LP relaxation problem that is solved.From the literature prior to 2010, the only K = 2 instances we had access to are those that originate from graph P20, 46 (see Yamada et al. (1997), for details). They are defined over a planar graph with n = 20 and m = 46. From the period spanning 2010 onwards, the K = 2 instances introduced by da Cunha et al. (2011) are available to us. They were generated in accordance with the guidelines suggested in Mekking and Volgenant (2010) and belong to two different families, random cost and two dimensional Euclidean cost. Random cost instances are generated by randomly drawing edge costs from the integral values in the range [0, 1000]. Euclidean instances, on the other hand, have their vertex coordinates randomly chosen from a square of side 1000. Additionally, their edge costs are taken as rounded down Euclidean distances between given pairs of vertices. Irrespective of the families they belong to, instances of da Cunha et al. (2011) were generated for n ∈ {50, 80} and graph densities 25 percent, 50 percent, 75 percent and 100 percent.Some 2-MMSFP instances associated with bipartite graphs were also introduced in Mekking and Volgenant (2010) and in da Cunha et al. (2011). For the latter reference, the instances are generated by firstly restricting n to be even and then defining a partition of the vertex set. Accordingly, vertices indexed1,…,n2are allocated to one subset and their complement in V to the other. Following that, edge set E is initialized with the following edges:{1,n2+1},{n2+1,2},{2,n2+2},…,{n2,n}. Having done that, additional edges of E are randomly generated until the required pre-defined graph density is reached.Instead of directly using the test set of da Cunha et al. (2011), we opted for generating a new one that is larger and more complete. The new set contains instances that conform with those found in that reference. Additionally, it also includes Euclidean instances for the following combinations of K and n: K = 2 and n ∈ {150, 200}, K = 3 and n ∈ {50, 80}, and K = 4 and n = 50. Accordingly, our test set goes further than those in the literature, that are restricted to K = 2 instances.To generate our K = 2 instances, three different graphs are considered for every value of n ∈ {50, 80, 150, 200}, every pre-specified graph density and every different family type (i.e., Euclidean or random cost). Each of these graphs, in turn, gives rise to a number of different instances. Each instance being identified by its corresponding roots, defined as follows: r1 = 1 and r2 = i, for i = 2, … , min {n, 100}. Accordingly, 3(min {n, 100} − 1) K = 2 instances are thus generated for a graph with n vertices.As for our K ∈ {3, 4} instances, they originate from the same n ∈ {50, 80} Euclidean cost graphs we previously used to generate K = 2 instances. For each of these graphs, corresponding roots for K = 3 instances are taken as: r1 = 1, r2 = i, for i = 2, … , 49, and r3 = n. Analogously, for the K = 4 instances, roots are defined as: r1 = 1, r2 = i, for i = 2, … , 48, r3 = n − 1 and r4 = n.Our Branch-and-cut algorithm, denoted BC+, is compared here with BC, the Branch-and-cut algorithm in da Cunha et al. (2011), and NBA, introduced in Mekking and Volgenant (2010). BC+ and BC were implemented in C and computational results for both of them were obtained on the same 2.0Ghz Intel XEON E5405 based machine with 8 gigabytes of RAM memory. On the other hand, NBA was coded in Delphi Pascal and was tested on a machine with a processor comparable to an Intel Pentium III, running at 900 megahertz. Furthermore, apart from P20,46, test sets previously used for BC and NBA are different from each other. Accordingly, for those instances that are common to BC, BC+ and NBA, dual bounds may be compared. However, even for them, CPU times can not be directly compared.Table 1 shows the results obtained for the various instances originating from P20,46. Each instance corresponds to a different set of root vertices, as indicated in the first column of that table. The next six columns give, for each algorithm, number of enumeration tree nodes and CPU times, in seconds. Lower bounds at the root nodes of the enumeration trees then follow, for the next three columns. It should be pointed out that LB1 is the strongest combinatorial lower bound obtained in Mekking and Volgenant (2010). In addtion to LB1, Table 1 also shows LP bounds w(PD), for the undirected graph formulation in da Cunha et al. (2011), andw(PD+),that applies to the formulation investigated here. The latter bound, one should recall, corresponds to w(PD), reinforced with the optimality cuts. Finally, optimal solution values w* are shown in the last column.Results in Table 1 indicate that optimality cuts (3) are decisive to improving w(PD) bounds. Indeed, for all instances tested,w(PD+)improves on w(PD). Furthermore, for 5 out of 10 instances, no branching is required for BC+. On the average,w(PD+)lower bounds are 5 percent stronger than their w(PD) counterparts. As a result, average root node duality gaps dropped from 5.9 percent to 0.5 percent. Consequently, as compared to BC, fewer enumeration tree nodes are required by BC+. On the other hand, w(PD) andw(PD+)are always stronger than LB1. Since BC+ and NBA were tested with different machines and were coded with different languages, it is difficult to conclude which of them is the fastest.Table 2brings the results obtained for our 2-MMSFP Euclidean and random cost instances with n ∈ {50, 80}. For the various different graph densities involved, results are presented for non-bipartite graphs (instance size indicated by n) and bipartite graphs (instance size indicated byn2). The following information is then presented in pairs, respectively for BC and BC+: average and maximum CPU times (in seconds), and average and maximum number of enumeration tree nodes. Finally, closing the table, the average duality gaps attained by w(PD) andw(PD+)are indicated. Results quoted in Table 2 originate from a pool of 147 instances for n = 50 and 237 instances for n = 80.As Table 2 indicates, the duality gap reductions attained by BC+ over BC are, on the average, of at least 55 percent. Additionally, the number of enumeration tree nodes investigated by BC+ is one order of magnitude lower than that for BC. Furthermore, average CPU times quoted for BC+ are at least 2.2 times better than those quoted for BC. Finally, for some particular groups of instances, BC+ was, on the average, 7 times faster than BC.Aimed at identifying which new feature of BC+, i.e., variable fixing tests or the use of optimality cuts, contributes the most for improving computational results, we conducted some additional experiments for the n ∈ {50, 80} Euclidean cost instances. For our additional experiments, an enhanced version of BC was implemented. It separates optimality cuts but does not use variable fixing tests. The performance attained by that algorithm indicates that the single most important improving factor for BC is the use of optimality cuts. Accordingly, as compared to BC, average CPU times for instances with K = 2 and n ∈ {50, 80} dropped by 68 percent for enhanced BC. If variable fixing tests were also enforced, CPU time reductions of 71 percent would be attained. Therefore, the use of variable fixing tests also proves to be important. However, it is not on par with the use of optimality cuts.Now, as much as possible, we will try to compare BC+ results with the NBA results quoted in Mekking and Volgenant (2010). The comparison is attempted over similarly generated Euclidean cost instances, defined over complete graphs. CPU times quoted in Mekking and Volgenant (2010) correspond to averages over 20 n = 50 instances and over 5 n = 80 instances. Their corresponding values are respectively 41.4 and 2313.3 CPU seconds and the ratio defined by the latter over the former would thus be 55.9. On the other hand, a 7.2 ratio is attained by BC+ over corresponding averages for similarly generated instances. Therefore, the average CPU time needed by BC+ to solve Euclidean instances apparently grows at a lower rate. As for the actual CPU times, these are clearly difficult to compare. However, the number of enumeration tree nodes investigated in either case is clearly much smaller for BC+. Corresponding figures quoted in Mekking and Volgenant (2010) are 1.89 × 105 nodes for the n = 50 instances and 4.17 × 106 nodes for n = 80 instances. BC+, on the other hand, never explores more than 151 enumeration tree nodes for any of our corresponding instances.We will now discuss BC+ computational results for dense and sparse Euclidean cost instances for K = 2 and n ∈ {150, 200}. We restrict attention to this type of instance because, from our previous computational experiments, no evidence exists that, for the other types of graphs and cost structures used, harder to solve instances would result for BC+. Table 3 showsthe results obtained. In total, 297 instances are found for each value of n ∈ {150, 200}. For the first test set, BC+ managed to solve all instances within the imposed CPU time limit, i.e., one hour for each of them. However, for the second set some instances remained unsolved. A detailed analysis of the results obtained, follows.Under the CPU time limit imposed, entries in the first column of Table 3 show the number of instances BC+ failed to solve. Subsequent columns bring the following information: average CPU time (unsolved instances excluded), maximum CPU time, average Branch-and-cut root node duality gap, and the average and final tree search duality gaps. Notice that the last two columns only apply to those instances that remain unsolved. For a given graph density, a “tl” entry may eventually appear under the “maximum CPU time” label. It indicates that BC+ failed to solve all corresponding instances. Likewise, under the “average and final tree search duality gaps” labels, entries may eventually display the symbol “-”. It would then indicate that BC+ managed to solve all 297 instances involved. If it happens otherwise, these gaps are then computed with the best upper and lower bounds available at the time implicit enumeration was called off.Three instances are left unsolved in Table 3. However, BC+ average and maximum duality gaps for them are below 0.14 percent. These instances originate from dense graphs. Indeed, sparse graph instances were solved quite easily by BC+. All in all, as compared to previous algorithms, BC+ performance does appear quite impressive.Computational results in Mekking and Volgenant (2010) only apply to K = 2 instances. Therefore, NBA is missing from the comparisons to be carried out in this subsection. Accordingly, we will restrict attention to BC and BC+. These will be compared for test sets with K = 3, n ∈ {50, 80} as well as with K = 4 and n = 50. Under a CPU time limit of one hour, every K = 3 instance with n = 50 vertices was solved to proven optimality by either algorithm. For the other two test sets, however, some instances remained unsolved.Table 4 shows results obtained for the K = 3 and n = 50 test set. They come in pairs, with entries respectively for BC and BC+. The first four columns give average and maximum CPU times. The next four bring average and maximum number of enumeration tree nodes. Finally, the last two columns give average root node duality gaps.Results for the 4-MMSFP n = 50 test set then follow in Table 5. Given that not all of these instances were solved to proven optimality, Table 5 complements the description of Table 4 with a few additional columns. These are required to provide some additional relevant information. Accordingly, the first two columns in Table 5 show the number of instances that remained unsolved at the end of the experiment. Column pairs that follow respectively give average CPU times, average root node duality gaps and average and maximum duality gaps when implicit enumeration was called off (either due to optimality proof or CPU time limit).From our results for the 3-MMSFP n = 50 case, optimality cuts do appear to contribute decisively to reducing root node duality gaps. Accordingly, the average root node duality gap for BC is 5 percent while the corresponding figure for BC+ is 3.6 percent. As a result, the average number of enumeration tree nodes dropped by 37 percent, from BC to BC+. For dense graph instances, duality gap reductions also translate into lower CPU times. Contrary to that, for sparse graph instances, these gains are offset by the additional CPU time required to separate optimality cuts.For the 4-MMSFP n = 50 instances, optimality cuts did not perform as well as they did for the 3-MMSFP n = 50 ones. The reason being that root node upper bounds turned out to be somewhat loose. As a result, fewer and weaker violated optimality cuts ended up being separated. However, as implicit enumeration proceeded, better quality upper bounds were eventually obtained. Accordingly, not only a larger number of optimality cuts were then separated but their quality also improved. Overall, even for the 4-MMSFP n = 50 instances, BC+ significantly benefits from the use of optimality cuts. As compared to BC, BC+ solves a larger number of test instances to proven optimality. Furthermore, that is accomplished under lower CPU times. Finally, for those instances that remained unsolved, the average and maximum duality gaps attained by BC+ are invariably better than their BC counterparts.Computational results for instances with K = 3 and n = 80 vertices are presented next, in Table 6. The first three pairs of columns respectively give the number of instances that could not be solved to optimality, the average root node duality gaps and the average duality gaps when implicit enumeration was called off (only for those instances that remain unsolved). Remaining columns are restricted to instances that were simultaneously solved by BC and BC+. The first of them indicate the number of instances. The following ones give average CPU times (in seconds) and average number of enumeration tree nodes.Table 6 results show that BC+ attains smaller root node duality gaps but BC succeeds in solving a larger number of test instances. In particular, for those instances both algorithms manage to solve, fewer Branch-and-cut nodes are explored by BC+. However, smaller average CPU times are attained by BC, particularly for sparse graph instances.In order to understand why computational results now lean in favor of BC, we carried out some detailed analysis of the performance of both algorithms. As likely explanations for the BC advantage we suggest: (a) the fact that better quality feasible solutions are only attained later on in the enumeration tree, thus resulting in weaker initial optimality cuts and (b) the excessive CPU time demand for separating optimality cuts. In relation with item (b), the cardinality ofSk(see subsection 3.2) turns out to be quite high for instances with n = 80 vertices and K = 3. Accordingly, the number of combinations of elements ofSkto investigate becomes excessive (see the second separation procedure of subsection 3.2). Consequently, CPU time demands for BC+ ended up being far too high.To determine if item (a), above, does indeed apply, we conducted some additional experiments. In particular, we investigated the potential benefits derived from having better upper bounds early on in the Branch-an-cut tree. For these experiments, we took as an initial upper bound for BC+ the best K-MMSFP upper bounds previously attained. Most of these bounds are either certified optimal values or near optimal ones. However, in spite of this big push BC+ got, it still lagged behind BC. In particular, average CPU times were only reduced by about 10 percent, not enough for BC+ to outperform BC. In summary, our additional experiments indicate that, in spite of positively impacting on the performance of BC+, better upper bounds alone are not enough to make BC+ outperform BC for the 3-MMSFP n = 80 instances.Let us now turn to item (b), above. In an attempt to validate it, we investigated a variant of BC+ to be denoted by BC+p. The new algorithm separates optimality cuts only at enumeration tree nodes with a depth of at most p ≥ 1, where p is a given pre-defined parameter. Accordingly, BC+ may be viewed as BC+pwhen p → ∞. Likewise BC+, BC+palso implements the primal heuristic of subsection 3.4 and the variable fixing tests of subsection 3.3. However, differently from our previous experiments for item (a), a good quality K-MMSFP upper bound is not passed as an input parameter for BC+p. Two different values of p were investigated. Namely, p = 1, that restricts the use of optimality cuts to the root node of an enumeration tree, and p = 4. Our motivation for keeping the values of p small stems from our previous computational results. In particular, those indicating that root node duality gaps are reduced with the use of optimality cuts. Additionally, it is also reasonable to assume that the lower the enumeration tree depth, the stronger the overall contribution of its optimality cuts are.BC+pcomputational results for p = 1 and p = 4 indicate that a controlled use of optimality cuts allows that algorithm to solve more instances with K = 3 and n = 80 vertices than BC. In particular, if we restrict attention to those instances BC, BC+1 and BC+4 all solve, BC+1 and BC+4 are faster than BC by respectively 13 percent and 11 percent, on the average. Therefore, the previous dominance of BC over BC+ may be credited to our use of optimality cuts at every enumeration tree node. Such a practice, as we have just indicated, does not pay off for the 3-MMSFP n = 80 set of instances.

@&#CONCLUSIONS@&#
A Branch-and-cut algorithm for the K-rooted mini-max Spanning Forest Problem was investigated in this paper. The algorithm is based on a directed graph formulation which is significantly reinforced with the use of some new optimality cuts. Benefiting from these cuts and also from some variable fixation tests, the new algorithm dominates a recently introduced Branch-and-cut algorithm for the problem. Specifically, it more than doubles the size of the K = 2 instances solved to proven optimality. Furthermore, it also manages to solve the much harder K = {3, 4} instances, something that was previously unattempted in the literature.The main contribution of our investigation is the introduction of the optimality cuts. These cuts are dependent on the quality of the upper bounds at hand and consequently they would certainly benefit from additional effective primal heuristics for the problem. Likewise they would also benefit from the use of more effective separation heuristics. Accordingly, our suggestion for future work is to attempt to address these two issues.