@&#MAIN-TITLE@&#
Lifetime maximization in wireless directional sensor network

@&#HIGHLIGHTS@&#
Lifetime of directional wireless sensor networks is maximized.We set the sensing direction of sensors for target coverage.A column generation algorithm is proposed for maximizing lifetime.The subproblem is addressed with a combination of an ILP and a genetic algorithm.We show that ‘non-dominated groups’ provide better lifetime.

@&#KEYPHRASES@&#
Wireless sensor networks,Directional sensors,Column generation,Heuristics,

@&#ABSTRACT@&#
This paper addresses two versions of a lifetime maximization problem for target coverage with wireless directional sensor networks. The sensors used in these networks have a maximum sensing range and a limited sensing angle. In the first problem version, predefined sensing directions are assumed to be given, whereas sensing directions can be freely devised in the second problem version. In that case, a polynomial-time algorithm is provided for building sensing directions that allow to maximize the network lifetime. A column generation algorithm is proposed for both problem versions, the subproblem being addressed with a hybrid approach based on a genetic algorithm, and an integer linear programming formulation. Numerical results show that addressing the second problem version allows for significant improvements in terms of network lifetime while the computational effort is comparable for both problem versions.

@&#INTRODUCTION@&#
Wireless sensor networks (WSNs) are used in a wide range of applications. In addition to battlefield surveillance, volcano eruption and tsunami prediction, WSN are now being used for health care (Akylidiz et al., 2002; Latré et al., 2011). The continuous betterments in microelectronics and production technologies have made embedded systems affordable and computationally competitive. The raise in smart-phones is probably the most emblematic aspect of this general trend. However, the progresses in energy storage have been less spectacular. Consequently, while technology allows for WSN with a larger number of smart sensors, the question of their lifetime is a growing challenge. More specifically, assuming that each sensor is either active or in sleep mode (where it does not consume energy) and that many sensors are available in the vicinity of the targets, maximizing lifetime is to decide which sensor to turn in active mode, and when, so as to keep all the targets under the sensing range of at least one active sensor.Column generation has recently appeared to be a very successful approach for increasing lifetime in wireless omni directional sensor networks (Alfieri et al., 2007; Rossi et al., 2012a), and for omni directional sensors with adjustable sensing ranges (Cerulli et al., 2012; Rossi et al., 2012). Optimal solutions can be found for reasonably small instances, but column generation also serves as a very good heuristic for larger instances. The use of heuristics for addressing the subproblem is a successful strategy for generating attractive columns fast, however, because of the tailing-off effect (Aloise et al., 2010; Lübbecke and Desrosiers, 2005), the end of the search for an optimal solution often requires a tremendous number of iterations that increases the solution quality by an infinitesimal amount. This allows to derive very good heuristics simply by stopping the column generation algorithm when the reduced cost is less than a given threshold (Gu et al., 2007).Directional sensor networks differ from omni directional sensor networks in the fact that sensors can only sense in a restricted angle. Moreover, they can rotate so as to change their sensing direction, allowing to cover other targets. Consequently, the decisions to be made regarding sensors are not only when to turn each of them on, but also to specify their sensing direction when they are active. Such directional sensors are typically video cameras (Feng et al., 2005; Rahimi et al., 2005), ultrasonic sensors (Djugash et al., 2006) and infrared sensors (Szewczyk et al., 2004).Most authors have addressed the problem of maximizing lifetime by assuming that sensing directions were given (Ai and Abouzeid, 2006; Cai et al., 2007, 2009). The most popular assumption is to consider that sensing directions are equally distributed in the interval [0,2π) with no overlapping as in Ai and Abouzeid (2006) and Cai et al. (2009). The advantage of such a choice is that any target in the range of a sensor can be covered using a unique sensing direction. Even though this way of building directions is arbitrary, the authors of Cai et al. (2009) mention that their algorithms remain valid regardless of this choice. Nevertheless, the way sensing directions are built may also have an impact on the network lifetime. To the best of our knowledge, determining the number of sensing directions and setting their distribution in the interval [0,2π) for each sensor with the purpose of maximizing network lifetime is a new problem that has not been addressed yet. The main novelty is that directions are not defined a priori, but only once the network is deployed. This allows for building contextual directions: the directions of a sensor are built depending on the location of the targets that are within range. The problem of lifetime maximization with predefined directions for sensing is referred to as LM-PDS. The problem of both building the sets of contextual directions for sensing and maximizing network lifetime is referred to as LM-CDS.The contribution of this paper is threefold. First, a polynomial-time algorithm is proposed for building the contextual directions for each sensor, allowing to reach the maximum network lifetime. Second, an exact column generation algorithm hybridized with a genetic algorithm is introduced for addressing both LM-PDS and LM-CDS. Finally, numerical results quantify the gain in lifetime by addressing LM-CDS rather than LM-PDS while a computational time analysis shows that LM-PDS and LM-CDS both require comparable computational efforts. This supports the conclusion that, if directions can be set freely once the network is deployed, then LM-CDS should be preferred over LM-PDS.This paper is organized as follows. Section 2 introduces notations and proposes a polynomial-time algorithm for building contextual sensing directions for each sensor. Section 3 proposes a column generation algorithm for addressing LM-PDS and LM-CDS. Numerical results are given in Section 4 for LM-PDS and LM-CDS, and these results are discussed. Section 5 concludes this paper.In this paper, all angles are expressed in radians and are in the interval [0,2π). Let n and m be the number of sensors and targets, respectively. For all i∈{1,…,n}, sensor i can be used for biunits of time (in small bursts or continuously) before its battery is discharged. In the case of those wireless sensor networks where not all sensors are used for the first time, the battery levels of sensors may differ, hence potentially different values for biare considered. All sensors have the same sensing angle φ and sensing range Rs, which means that any target k whose distance from i is less than or equal to Rsis covered by this sensor provided it is active, and that its sensing direction is such that k can be seen from i. More precisely, let Dibe the set of targets whose distance to sensor i is less than or equal to Rs. Θkis the angle under which target k is seen from i, for all k∈Di. When sensor i is used with sensing direction θ, it covers all the targets in Diwhose angle is the interval [θ,θ+φ) if θ+φ< 2π. If θ+φ⩾2π, then sensor i covers all the targets in Diwhose angle is larger than or equal to θ, as well as the targets whose angle is in the interval [0,θ+φ−2π).More formally, Di,θis the set of all the targets that are covered by sensor i under the sensing direction θ:Di,θ={k∈Di,θ⩽θk<θ+φ}ifθ+φ<2π{k∈Di,θ⩽θkorθk<θ+φ-2π}otherwiseA sensing direction θ of sensor i is said to be normalized if there exists k∈Disuch that θ=θk. Thus, the number of normalized sensing directions is at most ∣Di∣. It can be less if two or more targets are seen under the same angle from i.As an example, Fig. 1shows a sensor denoted by i with sensing angleφ=π2(this angle is not on the figure), and six targets represented as circles with indexes in {1,…,6} that can be covered by i. For the sake of readability, the angle under which each target is seen from i is also displayed on the figure. In Ai and Abouzeid (2006) and Cai et al. (2009), LM-PDS is addressed by considering that i has the four following sensing directions: 0,π2, π and3π2. Sensing directions 0 and π are shown in gray in Fig. 2whereas sensing directionsπ2and3π2are in white. It can be seen that Di,0={1,2},Di,π2={3,4}, Di,π={∅}, andDi,3π2={5,6}, hence sensing direction π is useless. The intersection of these sets is empty as no two sensing directions overlap. Moreover, none of these sensing directions is normalized.In the literature, the notion of groups (sometimes referred to as covers) has long been shown to be the most efficient way to address a wide variety of optimization problems in wireless sensor networks (Slijepcevic and Potkonjak, 2001; Wang et al., 2009). In the case of directional sensors, a valid group is defined as a subset of sensors with a sensing direction for each of them, such that each target is covered by at least one sensor of that group. A group is not valid if the coverage requirement is not satisfied. LM-PDS and LM-CDS are to design valid groups and to compute the amount of time during which they are used so as to maximize the network lifetime, while enforcing that sensor i is used at most biunits of time, for all i in {1,…,n}. Thus, exactly one group is active at a time, the sensors that are not part of the active group are turned off (so that they do not consume energy) whereas all the sensors of the active group are active as they sense in the direction specified by the group for each of them. Consequently, a solution to LM-PDS or LM-CDS is a collection of groups with a duration. A feasible solution is composed of valid groups only, with durations that satisfy battery limitations for all sensors. From now on, when mentioning groups we always refer to valid groups, unless differently specified.This paragraph states some properties that allow for building the most efficient sensing directions for a sensor, which is a prerequisite for addressing LM-CDS.Lemma 1For every feasible solution of LM-PDS, there exists a feasible solution to LM-CDS that uses normalized sensing directions only, with the same lifetime.For all i∈{1,…,n}, we can build a normalized sensing direction from any predefined sensing direction θ as follows. Let k be the target in Di,θthat minimizes θk−θ if θk⩾θ, or that minimizes 2π+θk−θ otherwise. Then, the normalized sensing direction θ′=θkcan be used instead of θ without compromising coverage, as Di,θis included inDi,θ′. Indeed, replacing θ with θ′ is just rotating anti-clockwise from θ and stopping when a target is seen at angle θ′, which does not compromise coverage. Consequently, the normalized sensing direction θ′ can be used for the same duration as sensing direction θ. By repeating this process and replacing all predefined sensing directions with their normalized counterpart, we produce a feasible solution that uses normalized sensing directions only, with the same lifetime.The search for an optimal solution to LM-CDS can be restricted to normalized sensing directions. This has the advantage of restricting the search to a discrete set (rather than the continuous set [0,2π)), which cardinality is at most ∣Di∣ for all i∈{1,…,n}.Let k be a target in Di. The normalized sensing direction θkof sensor i is said to be dominated if there exists k′∈Disuch thatDi,θkis a strict subset ofDi,θk′.Lemma 2For every feasible solution of LM-PDS, there exists a feasible solution to LM-CDS that uses non-dominated sensing directions only, with the same lifetime.A feasible solution to LM-PDS is a collection of groups in which active sensors have a predefined working direction. The following transformation is applied to all the groups. By definition, for each active sensor in a group, there exists a non-dominated direction of that sensor that covers all the targets covered by its current predefined direction in that group. Hence we can replace that direction by any non-dominated direction without compromising coverage. By repeating the process to all active sensors in all groups, we obtain a feasible solution to LM-CDS that uses non-dominated directions only, and that has the same lifetime as the solution to LM-PDS.Lemma 1 implies that the search for an optimal solution to LM-CDS can be restricted to non-dominated sensing directions. It also implies that the lifetime of an optimal solution to LM-CDS is larger than or equal to the optimal lifetime of LM-PDS for the same problem instance. Indeed, if we consider the example of Fig. 2 with a single sensor and targets 1 and 6 only, then the network lifetime is 0 for LM-PDS (problem is unfeasible) whereas it is equal to bi>0 with LM-CDS.Back to the example of Fig. 1, there are three non-dominated sensing directions:π4is shown on Fig. 3, while5π8and16π9are shown on Fig. 4.We now propose a polynomial-time algorithm for determining all non-dominated sensing directions for a sensor. Let σibe the number of non-dominated sensing directions for sensor i. By definition, σi⩽∣Di∣ for all i∈{1,…,n} as non-dominated sensing directions are a subset of normalized ones. Non-dominated sensing directions can be found as follows. First, the targets in Diare assumed to be re-indexed in such a way that θk<θk+1 for all k∈{1,…,∣Di∣−1}, and duplicate directions are removed by considering only one target covered by i corresponding to a given direction. For all k∈ {1,…,∣Di∣−1}, sensing direction θk+1 is non-dominated if|Di,θk|⩽|Di,θk+1|, and θ1 is non-dominated if|Di,θ|Di||⩽|Di,θ1|. Indeed, when going from sensing direction θkto θk+1, target k is no longer covered. So if sensing direction θk+1 does not allow to cover at least one target out ofDi,θk, then sensing direction θk+1 is dominated by θk.Algorithm 1 computes all non-dominated sensing directions for all sensors, and the set of targets covered by these sensing directions. More precisely, it returns:•σithe number of non-dominated sensing directions of sensor i for all i∈{1,…,n},Θi,qthe qth non-dominated sensing direction of sensor i, for all i∈{1,…,n}, and for all q∈{1,…,σi},Δi,qthe set of targets covered by sensor i when its sensing direction is Θi,q, for all i∈{1,…,n}, and for all q∈{1,…,σi}.When addressing LM-PDS, all these parameters are given. We use Algorithm 1 only for LM-CDS, where the sensing directions can be set freely for all sensors. In the example of Fig. 1, Algorithm 1 returns σi=3 and the following non-dominated sensing directions for i:Θi,1=π4(see Fig. 3),Θi,2=5π8, andΘi,3=16π9(see Fig. 4). The targets covered by these sensing directions are respectively Δi,1={2,3}, Δi,2={3,4}, and Δi,3={1,2,5,6}.Since the number of targets in the vicinity of a sensor is at most m, the complexity of Algorithm 1 is set by the sorting of A (i.e., the list of all target angles whose distance to the current sensor is less than Rs), and by the number of sensors to be processed. Hence, it requiresO(nmlog(m))operations in the worst case. In general, the maximum number of targets within the sensing range of a sensor, denoted by m′, is usually very small compared to m, reducing the aforementioned complexity in practice.Algorithm 1Computing the normalized and non-dominated sensing directions of all sensorsAll valid groups are indexed in {1,…,p}. For all j in {1,…,p}, group Sjis modeled as a column vector having∑i=1nσibinary entries, built as follows. For all i∈{1,…,n} we definegi=∑ℓ=1i-1σℓ. For all i∈{1,…,n} and q∈{1,…,σi}, elementSgi+q,jis set to 1 if and only if sensor i is part of that group, and its sensing direction is Θi,q.For Sjto be a well-formed description of a group, the sum over q in {1,…,σi} ofSgi+q,jmust be less than or equal to one, for all i∈{1,…,n}. If it is zero, this means that sensor i is not part of Sj. If it is one, this means that sensor i is part of Sj, and that it is used in a unique and well-determined sensing direction.In addition to the sensing directions, we also apply the notion of dominance to the groups. A valid group Sjis dominated if there exists another valid groupSj′such thatSi,j′⩽Si,jfor all i∈{1,…,gn+σn}, and there exists a sensor i0 and a sensing direction index q0 for whichSgi0+q0,j′<Sgi0+q0,j. In other words, a group is dominated if some sensors can be removed without compromising coverage. It can easily be shown that there exists an optimal solution to LM-CDS that uses non-dominated groups only, so we can restrict the search for groups to non-dominated ones. In addition, since there are m targets to cover, it can be deduced that any non-dominated group has at most m sensors.LM-PDS and LM-CDS only differ by the sensing directions of each sensor and their number, hence they can be addressed with the same algorithm. Since column generation has successfully been used for solving close versions of wireless sensor networks problems (Alfieri et al., 2007; Gu et al., 2007), we propose a column generation algorithm for LM-PDS and LM-CDS. This algorithm is enhanced by the addition of a genetic algorithm for addressing the subproblem.The master problem is concerned with the calculation of the time during which each group is used for maximizing lifetime, while ensuring that the energy limitation of each sensor is satisfied. Each column in the master problem corresponds to a group. Since the number of groups is generally too large for being enumerated, a restricted master problem is considered (i.e., a single column is used at the beginning), and a subproblem is introduced for generating attractive columns, so as to allow the restricted master problem to increase the network lifetime further.The subproblem is first addressed with a genetic algorithm that has the advantage of being fast and of returning more than one attractive group at each iteration. A group (or a column) is said to be attractive if its reduced cost in the restricted master problem is strictly positive. When the genetic algorithm fails to find any attractive group, an integer linear programming formulation of the subproblem is solved for either generating an attractive group, or proving that none exists, which also proves that the current restricted master problem solution is optimal for the master problem.The master problem has p decision variables denoted by tjfor all j∈{1,…,p}, where p is the number of groups. tjis the amount of time during which group j is active. The master problem’s constraints enforce that sensor i is not used more than biunits of time.Maximize∑j=1ptj∑j=1p∑q=1σiSgi+q,jtj⩽bi∀i∈{1,…,n}tj⩾0∀j∈{1,…,p}The restricted master problem is identical to the master problem, but it does not contain all the columns (i.e., all the groups). Hence, p is just the number of columns in the restricted master problem at the current iteration of the column generation algorithm. Since determining if the problem is feasible (i.e., deciding if there exists a valid group) is aNP-complete problem (Cai et al., 2009), we initially put a single non-valid group (p=1) defined by Si,1=0 for all i∈{1,…,gn+σn} with the constraint t1=0 (otherwise the problem is unbounded). Thus, the first time the subproblem is solved, it is for finding a valid group, or for proving that none exists, which is equivalent to showing that the master problem is infeasible. Such a situation may occur if a target cannot be covered by any sensor, or if a unique sensor can cover two targets, but with two different sensing directions.The subproblem consists in generating the most attractive group Sp+1 for the restricted master problem. It maximizes the reduced cost of the corresponding group, which is1-∑i=1n∑q=1σiSgi+q,p+1yi, where the dual variable associated with constraint i in the master problem is denoted by yi. For Sp+1 to be a valid group, each sensor should have at most one sensing direction (none if the sensor is not in Sp+1), and each target should be covered by at least one sensor (for all k in {1,…,m}, Ckis the set of all indexes h=gi+q such that sensor i covers target k with sensing direction Θi,q). Finally, we add the valid inequality enforcing that any non-dominated group should count at most m sensors. Hence the subproblem can be stated as the following integer linear program.Maximize1-∑i=1n∑q=1σiSgi+q,p+1yi∑q=1σiSgi+q,p+1⩽1∀i∈{1,…,n}∑h∈CkSh,p+1⩾1∀k∈{1,…,m}∑i=1n∑q=1σiSgi+q,p+1⩽mSgi+q,p+1∈{0,1}∀i∈{1,…,n},∀q∈{1,…,σi}Every time the subproblem generates a group with a strictly positive reduced cost, p is incremented by one, the corresponding column is added to the restricted master problem, and it is resolved by taking advantage of the optimal basic solution of the previous iteration, which is still feasible with the introduction of a new column.One could consider strengthening the formulation by preventing supersets of previously enumerated groups to appear again, by enforcing additional valid inequalities as in Cerulli et al. (2012). However, this is not helpful here. Indeed, as the column generation algorithm progresses, the number of strictly positive dual variables increases (note that yi⩾0 for all i∈{1,…,n}), so most of the supersets of previously enumerated groups have a strictly negative reduced cost (others just have a zero reduced cost), hence explicitly attempting to cut them off is useless because they are not attractive.Since the subproblem is a hard combinatorial optimization problem, it is desirable to address it using a heuristic method. We have devised a genetic algorithm for solving the subproblem. In comparison to the ILP approach, a genetic algorithm is not only faster, but also returns more than just one attractive group (column) at the end of the search. As mentioned already, the subproblem is first addressed with the genetic algorithm (GA). If the GA fails to find any attractive group, two more attempts are made with the GA to find attractive groups by restarting it afresh. Only when all three runs of the GA fail to find any attractive group, we resort to the ILP approach for solving the subproblem. If the ILP approach finds an attractive group then this means that the GA got trapped in a local optimum. If the ILP approach also fails to find any attractive group then this means that no attractive group exists, which in turn means that current restricted master problem solution is optimal for the master problem. Therefore, the ILP approach is used only to escape from local optima or to prove the optimality of the current master problem solution. Most often, the GA finds attractive groups and the ILP approach is used only sparingly. As a result, whole process gets speed-up without compromising the optimality of the solution obtained.Each chromosome represents a group, i.e., a potential solution to the subproblem. We have encoded a chromosome by an integer vector of length n. A value of q∈{1,…,σi} at the ith position of a chromosome indicates that sensor i is in the group represented by that chromosome with Θi,qas its sensing direction, whereas a 0 at the ith position indicates that sensor i is not in the group. Here, groups are encoded in a way that is entirely different from the way they are encoded in the master problem. Ease of use and efficiency considerations are behind this choice. In comparison to the encoding scheme used in master problem, our genetic operators (crossover and mutation) can be applied more easily with the encoding scheme used here. Moreover, it leads to a shorter chromosome length of n, whereas the encoding scheme used in master problem leads to a chromosome length of∑i=1nσi. Chromosome length has a significant impact on execution time of a genetic algorithm. To compensate for difference in encodings, whenever a group is passed to the master problem, it is transformed as per the encoding scheme used for the master problem.Those two encodings are illustrated with the following example for LM-CDS. There are n=5 sensors, each of them has a number of non-dominated directions:σ=34232. Suppose that group S1 is such that sensors 2 and 4 are active and used in their third and first directions respectively. This group is represented as the following vector in the master problem:The corresponding chromosome is03010.Fitness of a group is determined using a primary and a secondary fitness functions. The objective function of the subproblem and the number of sensors in the group are respectively used as the primary and secondary fitness functions. A group is considered to be more fit than the other, if either its primary fitness function value is larger than the other or the primary fitness function values are equal, but it has smaller number of sensors than the other. The reason behind the use of two fitness functions is that many groups can have the same value for the primary fitness function.Two parents for crossover are selected using probabilistic binary tournament selection method. A parent is selected in this method by picking two chromosomes uniformly at random from the current population and comparing their fitness. The chromosome with better fitness is selected to be a parent with probability πbt, otherwise the chromosome with worse fitness is selected. The second parent is selected in a similar manner.A child chromosome is generated via uniform crossover operator from the two selected parents. In uniform crossover operator, each position of child chromosome is copied from the corresponding position of one of the two parents. For each position, one of the two parents is selected uniformly at random and the value at the corresponding position in the selected parent is copied to the child. Algorithm 2 provides the pseudo-code of the crossover operator where u01 is a uniform variate in [0,1].Algorithm 2Pseudo-code of crossover operatorThe child chromosome generated through crossover has to undergo mutation. The mutation operator considers each position of child chromosome one-by-one, and checks whether it is zero or not. If a position, say i, is non-zero, then mutation operator resets this position to zero with probability πm. If it is zero, then, with probability πmmutation operator generates a random number between zero and σiand resets this position to the generated random number. It has to be noted that replacing a non-zero value at position i with a zero corresponds to deleting the sensor i from the group whereas replacing a zero at position i with some random value between one and σicorresponds to inserting the sensor i into the group with some randomly chosen direction as its sensing direction. Algorithm 3 provides the pseudo-code of the mutation operator where random(0,…,σi) is a function that randomly returns an integer in [0,σi].Algorithm 3Pseudo-code of mutation operatorSince our genetic operators (crossover and mutation) do not ensure the validity of the generated child, a repair operator, which is described next, is used to transform the child into a valid group.Repair operator The repair operator first transforms the child into a valid group and then into a non-dominated group.In order to transform the child into a valid group, each uncovered target is considered one-by-one in some random order and an attempt is made to add a new sensor to the child so that the target under consideration is covered by at least one of the directions of the newly added sensor and primary fitness function value is reduced by the least amount. If such a sensor is found then it is added to the child with a randomly chosen sensing direction from several directions that can cover the target in question and the coverage information of all affected targets are updated. If such a sensor does not exist, then to cover the target in question, we have to change the sensing direction of one of the sensors already present in the child. The targets needing such adjustments are placed in a list and processed separately after all uncovered targets are considered once.Targets belonging to the list of uncovered targets are processed one-by-one in an iterative manner. During each iteration a target, say k, is selected randomly from the list and a sensor i that can cover k is also selected randomly from the set of all sensors that can cover k. Obviously, sensor i already belongs to the child, but has a sensing direction that cannot cover target k. The sensing direction of i is altered now so that it can cover target k. If several directions of i can cover k then one such direction is selected randomly and the coverage information of all targets affected are updated. Target k as well as all other uncovered targets which are now covered by the new sensing direction of i are deleted from the list of uncovered targets. However, some new targets may now become uncovered because of change in sensing direction of i. These newly uncovered targets are added to the list of uncovered targets and processed in an analogous manner except for one difference. Since these targets could potentially be covered by sensors not present in the child, therefore, whenever such a target is selected, a check is done to find whether there exists a sensor i′ that is not already present in the child and that can cover this target (ties are broken arbitrarily). If it is so, then i′ is added to the child with a sensing direction that can cover the target in question (ties are broken arbitrarily) and the coverage information of all the affected targets are updated. Otherwise, the target is processed as described previously. The whole process is repeated until the list of uncovered targets becomes empty.Once a child becomes valid, it is transformed into a non-dominated group in an iterative manner by deleting those sensors from the child all of whose covered targets are also covered by other sensors belonging to the child. During each iteration, we compute the set Ψrof those sensors belonging to the child, all of whose targets are redundantly covered. Then from Ψr, a sensor i′ is selected randomly and removed from the child. The coverage information of all the affected targets are updated. This process is repeated till Ψrbecomes empty. Algorithm 4 presents the pseudo-code of repair operator.Algorithm 4Pseudo-code of repair operatorOur genetic algorithm uses the steady-state population replacement model (Davis, 1991) instead of the commonly used generational model. Unlike generational replacement, where during each generation whole parent population is replaced with same number of newly produced children, in the steady-state population replacement method a single child is produced in each generation and it replaces a less fit member of the population. In comparison to the generational method, the steady-state population replacement method generally finds better solutions faster because of always retaining the best solutions in the population and the immediate availability of the child for further selection and reproduction. In addition, in steady-state population replacement method, we can easily prevent the occurrence of multiple copies of the same individuals in the population. In the generational approach, multiple copies of the highly fit individuals may exist in the population. Within few generations, these highly fit individuals can take over the whole population thereby making the crossover completely ineffective. Therefore, mutation becomes the sole way to improve solution quality and as a result, solution quality, if at all improves, improves very slowly. This situation is called premature convergence. In the steady-state approach, the child can be compared with existing population members, and, if it is found to be identical to any existing population member then it is discarded. In this way multiple copies of same individuals are avoided in the population and the problem of premature convergence is averted.Our genetic algorithm follows the policy of discarding the newly generated child in case it is found to be identical to any existing population member, otherwise newly generated child always replaces the worst member of the population irrespective of its own fitness.A two stage procedure is used to generate each member of the initial population. The first stage starts by making a decision regarding choosing some sensors using a greedy policy in this stage or choosing all sensors in a completely random fashion while generating a chromosome. This decision is governed by parameter πα∈[0,1]. With probability πα, the probability of greedy choice πβis set to a non-zero value, otherwise it is set to zero. Once this decision is made, an iterative process starts. Initially all targets belong to a list of uncovered targets. During each iteration an uncovered target is chosen randomly from this list and a check is made to determine whether this target can be covered by a sensor not yet included in the chromosome. If there are more than one such sensors, then from these sensors, with probability πβ, a sensor is added to the chromosome whose inclusion leads to the smallest reduction in the value of the primary fitness function, otherwise a sensor is chosen randomly and added to the chromosome. If more than one direction of the newly added sensor can cover the target in question then one such direction is chosen randomly. If no sensor exists that can cover the target in question then this means that the sensing direction of a sensor already present in the chromosome needs to be changed to cover this target. In this case, a sensor which is already present in the chromosome and can cover the target in question is selected randomly and its sensing direction is randomly set to one of the directions that can cover it. After the target in question is covered, the coverage information of all affected targets are updated. The targets in question along with all previously uncovered targets which are now covered are deleted from the list of uncovered targets and any target which becomes uncovered now is added to the list of uncovered targets and another iteration begins. This process is repeated until the list of uncovered targets becomes empty, i.e., all targets are covered. The second stage transforms the chromosome into a non-dominated group in the same manner as in the repair operator. Algorithm 5 provides the pseudo-code for generating a member of initial population. When the problem is not feasible, i.e., no valid group exists, our initial solution generation algorithm may go into an infinite loop. To prevent that we have utilized a global variable NUM_ATM which keeps track of the number of times the work directions of sensors already present in the solution got changed. If the value of NUM_ATM exceeds the value of a parameter MAX_ATM, we immediately stop the initial population generation process and terminate the genetic algorithm.Algorithm 5Pseudo-code for generating an initial solutionEach newly generated chromosome is compared with the population members generated so far, and, if it is found to be identical to one of them then it is discarded, otherwise it is included in the initial population.This procedure is repeated until the desired number of distinct population members are generated.If the genetic algorithm finds an attractive group then MAX_NUM_GROUPS best attractive groups or all attractive groups in case number of attractive groups are less than MAX_NUM_GROUPS are passed to the master problem in each iteration of the column generation algorithm. If the genetic algorithm fails to find even one attractive group then two more attempts are made by starting the genetic algorithm afresh before resorting to the ILP based approach. Our genetic algorithm terminates when the fitness of the best solution does not improve over MAX_NUM_IT consecutive iterations.The pseudo-code of our genetic algorithm is given in Algorithm 6 where unique(C) is a function that checks whether generated child C is unique with respect to current population members or not. If C is unique it returns true otherwise it returns false. Evaluate(C) is another function that evaluates the fitness of C in terms of primary and secondary fitness functions.Algorithm 6Pseudo-code of genetic algorithmIn order to compare LM-PDS and LM-CDS in terms of solution quality and computational time, the column generation algorithm introduced in the previous section is used to address both problems on the same set of instances.We have considered four different number of sensors in the network: n∈{50,100,200,400}. The corresponding number of targets is m∈{30,60,120,240}: thus we maintain the same ratio between n and m, which allows to measure the effect of the problem size. Indeed the relative variations of n and m are less relevant in this work: if the number of targets increases for a fixed n, the network lifetime can only decrease (the problem may also become unfeasible, especially for small sensing angles). If the number of targets gets sparse for a fixed n, then many sensors become useless as they do not cover any target, which leads to a smaller (and hence easier) problem instance with an even lowernmratio. The current ratio is 60%, which is reasonably large, given that in practice, the number of sensors is always larger than the number of targets (Wang et al., 2009). Sensors and targets coordinates are generated randomly in a 500×500 area, and the sensing range is Rs=150 as in Wang et al. (2009). In addition, we have considered three different sensing anglesφ∈2π3,π2,π3. They are given in decreasing order because the smaller the directional angle, the more difficult the problem is. A grand total of sixty instances have been addressed by generating five instances for all (n,φ) pair.The computer used to produce all the computational results is powered by an Intel Xeon Processor at 2.8GHz with 8GB RAM, running Microsoft Windows 7. All linear programs and integer linear programs are addressed using the GNU Linear Programming Kit (GLPK), and all algorithms are implemented in C.The genetic algorithm uses a population of min (n,50) individuals. Two different values of πbtare used in probabilistic binary tournament selection method to select the two parents. The first parent is selected with πbt=0.9, whereas the second parent is selected with probability πbt=0.8. Mutation probability πmis set to 0.05. While generating an initial population member, the probability πα, with which the partial greedy policy is used in sensor selection, is set to 0.34. If partial greedy policy is used in generating an initial population member then sensors are selected via the greedy policy with probability πβ=0.4. MAX_ATM is set to 2m, i.e., we terminate the initial population generation process if a solution cannot be generated even after changing a total of 2m work directions. The maximum number of best attractive groups MAX_NUM_GROUPS that the genetic algorithm can pass to the master problem is set to 10. As mentioned already in the previous section, the genetic algorithm terminates when the fitness of the best solution does not improve over MAX_NUM_IT consecutive iterations. However, the value of MAX_NUM_IT varies over the set iter={50,400,800,1200,1600} from one run of the genetic algorithm to the other. If the genetic algorithm returned less than MAX_NUM_GROUPS attractive covers in the previous run then MAX_NUM_IT is set to next higher value, if possible, in iter, otherwise MAX_NUM_IT is set to next lower value, if possible, in iter. For instances with 50 or less sensors, MAX_NUM_IT is set to 50 in the very first run of the genetic algorithm. For all instances with more than 50 sensors, MAX_NUM_IT is set to 400 in the very first run of the genetic algorithm, and if its value falls below 400, it is reset to 400. There is also a provision for premature termination of the genetic algorithm in case it fails to find a solution different from current population members in 10 consecutive attempts. All these parameter values have been chosen empirically after large number of trials.As a preliminary result, Table 1shows the benefit of combining the genetic algorithm and the ILP formulation for addressing the subproblem on six instances. The first two columns report the number of sensors n and the sensing angle φ common to all sensors in radians. Column “ILP alone” reports the CPU time (in seconds) of the column generation algorithm where the subproblem is addressed with the ILP formulation alone. Column “ILP+GA” reports the CPU time of the column generation algorithm where the subproblem is addressed with the combination of GA and ILP introduced in Section 3. The last column reports the speed-up factor, i.e., it indicates how many times ILP+GA is faster in comparison to ILP alone. Lifetimes are not reported in Table 1 because they are identical for both approaches. These results show the benefit of using GA for producing attractive and diverse groups quickly and efficiently. CPU time savings are of the same magnitude as for other problem variations of lifetime maximization in WSN (Rossi et al., 2012a,). In addition, the benefit of using GA grows with the problem size because the ILP formulation of the subproblem becomes more and more difficult when the network size increases.As a consequence, we compare LM-PDS and LM-CDS in terms of number of directions, then in terms of computational effort and lifetime with the column generation algorithm described in Section 3 where GA and ILP are combined for addressing the subproblem.First, the total number of directions for both LM-PDS and LM-CDS, as well as the average number of directions actually used in the best solutions found are compared. The results are given in Table 2. The first two columns give the number of sensors n and the sensing angle φ, and each row reports results for five instances having the same n and φ. Column 3 is the number of directions for LM-PDS. Since the first row corresponds to 50 sensors with three directions (becauseφ=2π3), there are exactly 50×3=150 directions for the five corresponding instances. Columns 4 and 8 display the average number of directions used in the best solution found (all solutions may not be optimal, more detail on this matter is given in Section 4.3) for LM-PDS and LM-CDS respectively. Columns 5 and 9 display the average rate (in percent) of directions that are used a non-zero amount of time in the best solution, for LM-PDS and LM-CDS respectively. Columns 6 and 10 show the average number of sensors per group in the best solution found for LM-PDS and LM-CDS respectively.Column 7 is the average number of non-dominated directions computed for LM-CDS. Unlike in LM-PDS, this number depends on the layout of targets and sensors, as non-dominated directions depend on the relative positions of the targets that can be covered by a sensor. Column 11 displays the average increase (in percent) of the number of directions, when comparing LM-PDS to LM-CDS. Column 12 shows the average increase of the number of directions used in the best solution, and column 13 displays the average increase of the number of sensors per direction used in the best solution.Table 2 shows that the number of directions in LM-CDS tends to be much larger than with LM-PDS, especially when φ is large. The same trend can be observed, but in a lesser extent, with the number of directions used in the best solutions. This might suggest that LM-CDS is more difficult to solve than LM-PDS, as the number of directions to select for building a group is significantly larger. However, this is not the case as can be seen from the next section. For explaining this counter-intuitive result, we can observe that since the number of sensors required for building a valid group is lesser in LM-CDS than in LM-PDS, the subproblem (which is finding an attractive valid group) is easier with LM-CDS than with LM-PDS. The last column of Table 2 confirms that the average number of sensors per direction used in the best solution is lesser with LM-CDS.Both LM-PDS and LM-CDS are now compared in terms of number of optimal solutions found, lifetime and computational effort. Table 3reports the results for the sixty instances. Columns 3 and 7 report the number of instances (out of five) solved to optimality for LM-PDS and LM-CDS respectively. Indeed, the maximum CPU time allotted for solving each instance is set to one hour, so if the optimal solution is not found within one hour, then the algorithm returns the best lifetime found so far. In that case, the proposed exact algorithm returns a heuristic solution. Columns 4 and 8 report the average lifetime over the five instances for LM-PDS and LM-CDS respectively, regardless of optimality of the solutions. Columns 5 and 9 report the average CPU time required for computing the obtained optimal solutions. If none of the five instances could be solved to optimality, then dnf (did not finish) is displayed. Columns 6 and 10 whose heading is “avg. CPUboth” report the average CPU time over instances solved to optimality for both LM-PDS and LM-CDS. Finally, the last two columns show the lifetime increase in average when using non-dominated directions, as well as the CPU time increase when comparing LM-PDS to LM-CDS. The CPU time comparison is performed only on instances solved to optimality for both LM-PDS and LM-CDS.As expected, it can be observed that the problem is more difficult for large instances and small sensing angles. Table 3 also shows that lifetime is 10–20% higher with LM-CDS compared to LM-PDS. The largest gains seem to be obtained for smaller instances. This might be due to the fact that larger instances are characterized by a higher density of sensors and targets in the 500×500 area. Thus, targets are covered by a larger number of sensors, even if sensing directions are not carefully chosen. Consequently, the benefit of using non-dominated sensing directions might be less visible in this case. The results obtained with n=100 and n=200 support this interpretation as the benefit of LM-CDS over LM-PDS is much more visible for smaller sensing angles. The instances with n=400 sensors are much more difficult to solve (only one instance out of 30 is solved to optimality) so we can hypothesize that after one hour, the algorithm is still quite far away from the optimal lifetime because of the tailing-off effect of column generation. Hence, at such an early stage of the search, the benefit of using non-dominated sensing directions may not be very visible.Whereas the number of optimal solutions found for LM-PDS and LM-CDS is nearly the same, the algorithm generally returns an optimal solution to LM-CDS much faster than for LM-PDS. Naturally, this comparison is performed on easy instances only, as the optimal solution is required for both LM-PDS and LM-CDS. Nevertheless, the results for difficult instances in terms of solution quality suggest that LM-CDS is solved more efficiently than LM-PDS as the differences in terms of lifetime remain significant despite network size and density. CPU time savings are less significant for small sensing angles on those easy instances. It can also be observed that when an instance is solved to optimality, it is processed much faster with smaller values of φ. This is typically the case of easy instances: an isolated target covered by a small number of sensors is very likely to be responsible for the network lifetime, especially when φ is small.The instances for which n=100 are at the frontier of the cases that can be solved to optimality, and the number of solutions solved to optimality with LM-CDS is less than with LM-PDS. This is particularly visible forφ=π3. In that case, we also reach the maximum average CPU time for LM-PDS, which suggests that finding an optimal solution to LM-PDS becomes time consuming because of the tailing-off effect. Even if the number of optimal solutions found for LM-CDS is lesser, solution quality is still significantly better with LM-CDS. We hypothesize that with LM-PDS, the situation in which lifetime is defined by a set of targets covered by a limited number of directions is more likely to happen than with LM-CDS, where the number of directions is much larger as shown in Table 2. Hence, the search for an optimal solution to LM-PDS may be faster whereas the tailing off effect may be responsible for slower convergence with LM-CDS. When n=50, this is even more visible as solving LM-CDS is sometimes longer than solving LM-PDS. However, as n increases, the growth of coverage density probably tends to lesser the occurrence of a situation where a restricted set of targets is barely covered. As the conditions favoring premature convergence of LM-PDS tend to disappear when n increases, the number of instances solved to optimality becomes larger with LM-CDS. Naturally, as instance size makes these problems more difficult to solve in one hour, the advantage of LM-CDS in terms of number of optimal solution found is no longer visible for n=400.

@&#CONCLUSIONS@&#
