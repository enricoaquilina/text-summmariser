@&#MAIN-TITLE@&#
Total completion time with makespan constraint in no-wait flowshops with setup times

@&#HIGHLIGHTS@&#
The multi objective problem with setup times is addressed.Different algorithms including the most recent ones are proposed.One of the algorithms performs better than the others, statistically verified.Algorithms, including the best one in the literature, have the same CPU time.Best algorithm reduces the error of the best one in the literature by at least 90%.

@&#KEYPHRASES@&#
Scheduling,No-wait flowshop,Setup times,Total completion time,Makespan,

@&#ABSTRACT@&#
The m-machine no-wait flowshop scheduling problem with the objective of minimizing total completion time subject to the constraint that the makespan value is not greater than a certain value is addressed in this paper. Setup times are considered non-zero values, and thus, setup times are treated as separate from processing times. Several recent algorithms, an insertion algorithm, two genetic algorithms, three simulated annealing algorithms, two cloud theory-based simulated annealing algorithms, and a differential evolution algorithm are adapted and proposed for the problem. An extensive computational analysis has been conducted for the evaluation of the proposed algorithms. The computational analysis indicates that one of the nine proposed algorithms, one of the simulated annealing algorithms (ISA-2), performs much better than the others under the same computational time. Moreover, the analysis indicates that the algorithm ISA-2 performs significantly better than the earlier existing best algorithm. Specifically, the best performing algorithm, ISA-2, proposed in this paper reduces the error of the existing best algorithm in the literature by at least 90% under the same computational time. All the results have been statistically tested.

@&#INTRODUCTION@&#
There is a set of n jobs ready for processing on a set of m machines in an m-machine flowshop such that all the jobs have to go through machine 1, machine 2, …, and machine m in this order. The intermittent processing of jobs is acceptable in an m-machine flowshop. Although such an acceptance is applicable for many manufacturing environments, there are abundant other manufacturing environments where discontinuous processing is not possible. Such an m-machine flowshop is known as an m-machine no-wait flowshop. A no-wait flowshop problem occurs when the operations of a job have to be processed continuously from the first machine to the last machine without disruptions either on or between machines. Therefore, if need arises, the starting of the operation of a job on machine r is delayed so that this operation’s completion coincides with the start of the operation of the job on machine r+1. This problem can be denoted by Fm/nwt/Obj where Fm denotes that it is an m-machine, nwt denotes that it is a no-wait environment, and Obj denotes the objective function to be optimized.The no-wait flowshop problem is applicable in many industries including metal, plastic, and chemical. It is widely applicable in semiconductor manufacturing, e.g., Chien et al. (2011) and Huang, Yang, and Huang (2009), and in printed circuit board manufacturing, e.g., Nagano, da Silva, and Lorena (2012). Additional applications can be found in advanced manufacturing environments, such as just-in-time and flexible manufacturing systems. More applications are presented by Hall and Sriskandarajah (1996).Two performance measures are considered in this paper; total completion time (TCT) and makespan (Cmax). Both performance measures are commonly used in the scheduling literature. There are some scheduling environments where each completed job is needed as soon as it is processed. For such scheduling environments, managers are interested in minimizing mean or TCT of all jobs. It should be noted that both mean completion time and total completion time are equivalent performance measures, and in this paper, the TCT is used. The objective of minimizing TCT is predominantly significant in scheduling environments where reducing inventory or holding cost is of primary concern. The significance of minimizing total cost of inventory or holding cost has been discussed by many researchers. Minimizing Cmaxis another important objective in scheduling environments where a simultaneously received batch of jobs is required to be completed as soon as possible. For example, a multi-item order submitted by a single customer needs to be delivered in the shortest possible time. Therefore, both of these performance measures have been widely used in the literature for different scheduling environments. The majority of researchers considered only one of these performance measures while others considered both performance measures with different combinations. In other words, some researchers tried to minimize a weighted sum of the two performance measures while some others tried to minimize one of the two performance measures while the other performance measure is not greater than a certain value.Assuming that setup times are included in processing times (or equivalently setup times are assumed to be zero), some researchers considered the problem of Fm/nwt/TCT, e.g., Pan, Tasgetiren, and Liang (2008) and Framinan, Nagano, and Moccellin (2010). Pan et al. (2008) presented a particle swarm optimization algorithm while Framinan et al. (2010) provided a new constructive heuristic for the problem and showed that their heuristic performs better than the earlier existing heuristics. For the problem of Fm/nwt/Cmax, and making the same assumption of zero setup times, Framinan and Nagano (2008) proposed a heuristic based on an analogy between the m-machine no-wait flowshop problem and the well-known Traveling Salesman Problem, Zhu, Li, and Wang (2009) provided a local search algorithm, Laha and Chakraborty (2009) presented a constructive heuristic based on the principle of job insertion, Qian, Wang, Hu, Huang, and Wang (2009) proposed a hybrid differential evolution algorithm, Tseng and Lin (2010) presented a hybrid genetic algorithm, Samarghandi and ElMekkawy (2012a) provided a hybrid algorithm of tabu search and particle swarm optimization algorithm, and Davendra, Zelinka, Bialic-Davendra, Senkerik, and Jasek (2013) proposed a discrete self-organizing migrating algorithm.All the aforementioned papers assumed that setup times are zero. This assumption is undoubtedly valid for certain applications. However, the assumption is not valid for some other applications, Atighehchian and Sepehri (2013), Pessan, Neron, and Haouari (2013), and Yin, Wu, Wu, and Chen (2013). Thus, by making this assumption for those applications adversely affects the solution quality. Allahverdi and Soroush (2008) presented various applications and the significance of considering setup times as separate from processing times. Allahverdi, Gupta, and Aldowaisan (1999), Allahverdi, Ng, Cheng, and Kovalyov (2008) provided a review of scheduling literature on setup times including the literature on the no-wait flowshop scheduling problems.Shyu, Lin, and Yin (2004) considered the problem of F2/nwt, sjk/TCT where setup times were considered as separate from processing times. They presented an ant colony optimization (ACO) algorithm. Brown, McGarvey, and Venture (2004) addressed the problem of Fm/nwt, sjk/TCT. They presented an algorithm called TRIPS. Ruiz and Allahverdi (2007) addressed the same problem that Brown et al. (2004) considered. Ruiz and Allahverdi (2007) proposed an efficient dominance rule and presented seven heuristics including two stochastic local search methods. They have indicated that their heuristics outperform ACO of Shyu et al. (2004) and TRIPS of Brown et al. (2004). Nagano et al. (2012) considered the same problem addressed by Brown et al. (2004) and Ruiz and Allahverdi (2007), and proposed a new metaheuristic, a hybrid of genetic algorithm and cluster search, and showed that the new metaheuristic outperforms the best performing heuristic of Ruiz and Allahverdi (2007). Rabiee, Zandieh, and Jafarian (2012) considered the problem of F2/nwt, sijk/TCT. They proposed an adapted imperialist competitive algorithm and compared its performance with genetic and simulated annealing algorithms. Huang et al. (2009) considered the two-stage multiprocessor or flexible no-wait flowshop scheduling problem with unit setup time. In a flexible no-wait flowshop, there exists more than one machine in at least one stage. They presented an integer programming model and proposed an ant colony optimization heuristic.Brown et al. (2004) also considered the problem of Fm/nwt, sjk/Cmaxand presented a heuristic called TRIPS. Samarghandi and ElMekkawy (2012b) proposed genetic and particle swarm optimization algorithms for the same problem addressed by Brown et al. (2004). Ying, Lee, Lu, and Lin (2012) considered the problem of Fm/nwt/Cmaxwith sequence-dependent family setup times. They presented genetic algorithm-based, simulated algorithm-based and stochastic local search algorithm-based heuristics. Jolai, Rabiee, and Asefi (2012) addressed the problem of Fm/nwt, sjk/Cmaxfor flexible environments where at each stage more than a single machine exists. They proposed a population based simulated annealing algorithm, an adapted imperialist competitive algorithm, and a hybridization of both algorithms.The literature cited so far addressed only a single criterion. Assuming setup times are zero, Allahverdi and Aldowaisan (2002) addressed the problem of Fm/nwt/αCmax+(1−α)TCT by reducing the problem into a single criterion. Again by assuming zero setup times, Ruiz and Allahverdi (2009) considered the problem of Fm/nwt/αCmax+(1−α)Lmax. Several heuristics were proposed by both papers. Another related problem was addressed by Arabameri and Salmasi (2013) who presented several heuristics based on tabu search and particle swarm optimization algorithm for the problem of Fm/nwt, sijk/αE+(1−α)T.Another related problem was addressed by Naderi, Aminnayeri, Piri, and Ha’iri Yazdi (2012). Assuming setup times are zero, they addressed the problem of Fm/nwt/Cmax, TT. First, they formulated the problem mathematically. Then, they solved the multi-objective mathematical model by using a Fuzzy programming method which is a multiple criteria decision making approach. Furthermore, they proposed a novel multi-objective iterated local search algorithm by utilizing different local search engines. The computational results indicate that their proposed algorithm outperforms the existing algorithms.By assuming that setup times are zero, Aydilek and Allahverdi (2012) and Allahverdi and Aydilek (2013) addressed the m-machine no-wait scheduling problem with both performance measures of Cmaxand TCT by using the constraint optimization approach rather than by combining the two performance measures into a single performance measure. Specifically, the objective Aydilek and Allahverdi (2012) considered was to minimize Cmaxsubject to the constraint that TCT is not greater than a certain value while the objective Allahverdi and Aydilek (2013) considered was to minimize TCT subject to the constraint that Cmaxis not greater than a certain value. Both Aydilek and Allahverdi (2012) and Allahverdi and Aydilek (2013) presented different heuristics for the problem and both have shown that one of their proposed heuristics significantly outperform the rest of the heuristics. Similar problems have been addressed for different objectives for other scheduling environments. For example, Framinan and Leisten (2006) considered a regular flowshop (no no-wait) with the objective of minimizing Cmaxsubject to the constraint that the maximum tardiness being less than or equal to a given value.In this paper, we address the same problem that Allahverdi and Aydilek (2013) addressed, i.e., minimizing TCT subject to the constraint that Cmaxis less than or equal to a given value in an m-machine no-wait flowshop. In this paper, we propose new heuristics for the problem and show that most of the newly proposed heuristics are significantly better than the best heuristic of Allahverdi and Aydilek (2013). Moreover, Allahverdi and Aydilek (2013) assumed that setup times are zero. In this paper, we relax this assumption by treating setup times as non-zero values. Therefore, the problem addressed by Allahverdi and Aydilek (2013) is a special case of the problem addressed in this paper. By considering setup times as non-zero values, some idle times on the machines can be used for setup operations, and thus, job completion times may significantly be reduced depending on the size of the idle time and the time of the setup operation.The two-machine no-wait flowshop scheduling problem with the objective of TCT is NP-Complete in the strong sense, Hall and Sriskandarajah (1996). Therefore, the problem addressed in this paper is NP-Complete in the strong sense as m-machine is addressed rather than the two-machine, moreover, setup times are treated as separate, and furthermore, there is a constraint on Cmax. Therefore, the solution of the problem can be approximated by developing algorithms.There is a set of n jobs to be scheduled on a set of m machines in a no-wait environment with separate setup times. The problem to be addressed is TCT subject to the constraint that Cmaxis less than or equal to a given value. The constraint on Cmaxis normally given by the scheduler. In other words, the objective is to minimize TCT such that all the available jobs have to be finished within a certain time which is the time constraint on Cmax. The problem can be defined as:MinimizeTCTSubject toCmax⩽Cwhere C is an upper bound on Cmax. It should be noted that a very large value of C reduces the problem to minimize TCT. On the other hand, a very small value of C leads to a problem which does not have a solution. If the C value is not given, then, the following algorithm (Algorithm-Cmax) can be used to find a feasible and yet a relatively tight C value. Allahverdi and Aydilek (2013) considered the same problem addressed in this paper by assuming setup times are zero. They provided an algorithm to obtain a C value in case the C value is not provided by the scheduler. In this paper, we provide, in the following, a similar algorithm (Algorithm-Cmax) for the case where setup times are considered as separate from processing times. Moreover, rather than starting the algorithm with a random sequence, we obtain an initial sequence by applying the Yoshida and Hitomi’s algorithm (Yoshida & Hitomi, 1979) after reducing the problem to a two-machine problem. It should be noted that even though the Yoshida and Hitomi’s algorithm is for the case of regular two-machine flowshop, the solution of the Yoshida and Hitomi’s algorithm can be considered as an initial sequence for the Algorithm-Cmaxfor our no-wait m-machine flowshop problem. In other words, rather than selecting a random sequence as Allahverdi and Aydilek (2013) used, we use an approximate sequence as the initial sequence. The steps of Algorithm-Cmaxare given below where ti,jand si,jdenote processing time and setup time of job i on machine j, respectively. Let Cmax(σ) and TCT(σ) represent makespan and total completion time of a given sequence σ. It should be noted that in the first step of the following algorithm, the m-machine problem is first reduced to a two-machine case.Algorithm-CmaxStep 1: Generate a random integer g between 1 and m-1 and define the processing times on machines 1 and 2 aspi1=∑1≤j≤gti,jandpi2=∑g+1≤j≤mti,jand setup times assi1=∑1≤j≤gsi,jandsi2=∑g+1≤j≤msi,j. Apply the Yoshida and Hitomi’s algorithm to obtain the sequence λStep 2: Set p=1, h=1Step 3: Select a random job in sequence λ and insert it to a random position and call the new sequence πp. Let Cp=Cmax(πp)Step 4: Interchange the two jobs in positions h and h+1 of the sequence πp, and if Cmaxof the sequence after the exchange is less than Cp, then update the sequence πpto be the sequence after the exchange and set Cp=Cmax(πp).Step 5: Set h=h+1, if h=n, go to Step 6, otherwise go to Step 4Step 6: Set p=p+1, if p=n, go to Step 7, otherwise go to Step 3Step 7: Set C=min(C1, …, Cn),Step 8: Let π be the sequence where C is obtained.As stated earlier, the constraint on Cmaxis given by the scheduler in practice for a specific problem. Since the proposed methodology is not presented for a specific problem but rather for a general problem, a constraint on Cmaxneeds to be generated. This constraint is also needed for comparing the performances of the algorithms to be presented in the next section. The constraint should depend on the number of jobs, n, the number of machines, m, as well as the setup times, si,j, and processing times, ti,j, of the jobs. The above algorithm provides a relatively tight value of C. A relatively large value of C is also considered in addition to a relatively tight value of C. This is accomplished by replacing Step 7 of the algorithm with “Set C=max(C1, …, Cn)”.In this section, we propose several algorithms to find a solution for the problem. The algorithms include an insertion algorithm, and recent versions of simulated annealing algorithm, genetic algorithms, a differential evolution algorithm, and cloud theory-based simulated annealing algorithms.As pointed out earlier, Allahverdi and Aydilek (2013) considered the same problem addressed in this paper except that they assumed setup times are zero. They proposed an insertion algorithm for the problem and showed that their proposed insertion algorithm performed better than several other considered algorithms including genetic algorithm and simulated annealing algorithm. We apply their algorithm to our problem by considering setup times as separate from processing times, and call this algorithm as IA. It should be noted that when setup times are zero, our problem reduces to their problem. In the computational experiments we also include zero setup times for a fair comparison. Their algorithm IA can be summarized as:•First obtain a sequence from Algorithm-Cmax.Insert a job in each position (1 to n) to obtain n sequences (π1, π2, …, πn).Select the best sequence with respect to TCT (subject to Cmax⩽C) to obtain σk.Repeat this for all the n jobs to obtain (σ1, σ2, …, σn).Choose the sequence among the best sequences with the minimum TCT to obtain σk.Take the last θkand repeat the above procedure L times (number of loops).Among (θ1, θ2, …, θL), obtain θ.Apply the pair-wise exchange procedure to the sequence θ to obtain the solution.It should be noted that Allahverdi and Aydilek (2013) used several values for parameter L of their algorithm including 1, 5, 10, 15, 20. They showed that the algorithm performs best for L=20 as expected since the parameter L denotes the number of loops of the insertion algorithm. Therefore, we also have taken a value of 20 for the L parameter, and hence, the computational time of this algorithm when L=20 is the stopping criteria for all the algorithms that will be presented. In other words, one of the parameters of the algorithms, to be presented, is selected such that the computational times of all the algorithms are the same as that of IA.Genetic algorithm (GA), Chen, Chang, Cheng, and Zhang (2012) and Sioud, Gravel, and Gagné (2012), is known to perform well for different scheduling problems, and hence, many researchers have used GA. GA imitates evolution process of nature by implementing the fundamental principles of genetics. GA is applicable to any problem whose solution space can be represented by a population of structures. This has led to the use of GA to solve scheduling problems, where the sequences of jobs can be represented as structures in a population.In GA, first, an initial population is selected. Next, the process of evolution is replicated by generating new generations utilizing genetic operations on the current population structures. The sequences in the current population with higher fitness values are given higher chance for crossover which increases the chance of obtaining an offspring with high fitness values. This process is repeated until the maximum population size is reached. Moreover, new populations are generated until the number of new generations is reached.Allahverdi and Aydilek (2013) used a GA for the same problem that is addressed in this paper except that they assumed setup times are zero. We adapted the GA of Allahverdi and Aydilek (2013) to our problem. Moreover, Allahverdi and Aydilek (2013) used the partially mapped crossover (PMX) operator for crossover. In this paper, we have tested three more crossover operators. Specifically, in addition to PMX, we have utilized linear order crossover (LOX), two point crossover (TPC), and similar job order crossover (SJOX). Furthermore, we have utilized two different mutation operators, i.e., exchange and insertion operators. We have found that LOX crossover operator and insertion mutation operator performed better for this problem. We call this adapted GA as GA-AA.Once the population size has been determined, 90% of the initial population has been generated by using the Algorithm-Cmax. The rest of the initial population is randomly generated such that the makespan constraint is satisfied for all the sequences in the initial population. Some random but feasible solutions are included in the initial population in order not to trap in local solutions. However, the percentage of the randomly generated solutions is kept small. Because, a high percentage increases the computational time significantly as the majority of randomly generated sequences does not satisfy the makespan constraint. The generation of offspring is continued such that the makespan constraint is satisfied.In addition to the crossover and mutation operators and the initial population, the performance of a genetic algorithm is affected by population size, generation size, crossover and mutation probabilities. In GA-AA, the values for population size, generation size, crossover and mutation probabilities are determined by fine-tuning the ones used by Allahverdi and Aydilek (2013) as will be discussed in Section 4.1.Pang (2013) recently proposed an improved genetic algorithm for the no-wait flowshop scheduling problem to minimize maximum lateness with class setup times. Pang (2013) indicated that his improved GA performed well. Since Pang (2013) considered a similar environment of no-wait flowshop and setup times as the one addressed in this paper, we adapted his GA to our problem which we denote it by GA-P. The description of GA-P is omitted for the sake of brevity. It should be noted that the newly generated offspring need to be checked for the constraint that the makespan value is not greater than C value for the problem addressed in this paper. We have used the same initial population as used in GA-AA. The rest of the parameter values, except the number of generations, used by Pang (2013) are utilized in GA-P. The number of generation is determined such that the computational times are the same.Differential evolution (DE) is one of the latest evolutionary optimization algorithms. Das and Suganthan (2011) provided a recent and a detailed survey of DE algorithm to different optimization problems including scheduling in no-wait flowshops. Tasgetiren, Pan, Suganthan, and Buyukdagli (2013) presented a DE algorithm which performs very well for makespan and mean completion time performance measures. We adapted their DE algorithm to our problem and fine-tuned the DE algorithm parameters to our problem. More specifically, the crossover probability is 0.4, and the mutation scale factor is 0.5. As with other algorithms, for a fair comparison, the population size is determined such that the computational times are the same.In simulated annealing (SA) algorithm different sequences are explored by exchanging the positions of randomly selected jobs in order to improve the current solution. The exploration can also be conducted by inserting a randomly selected job into a randomly selected position. Aydilek and Allahverdi (2012) used the insertion neighborhood structure for a scheduling problem with a different objective function where setup times are assumed to be zero. We have observed that the performance of SA improves when the insertion neighborhood structure is used for the problem addressed in this paper. Therefore, we utilize this structure in our proposed SA and call this as Improved Simulated Annealing Algorithm 1 (ISA-1). The steps of ISA-1 are as follows:1.Set the values Ti, Tf, cf, R and the initial sequence si.Set the temperature T=Tiand the sequence s=si.Set j=1Generate two random integers h and l between 1 and n. Insert the job in position h to position l of the sequence s, and call this new sequence st.Evaluate L=TCT(s), and Lt=TCT(st) where TCT denotes the total completion time.(Makespan constraint) If Cmax(st) ⩽ C, go to Step 7. Else, go to Step 8.If Lt<L then update s with st, i.e. set s=st. Else, update s with stwith probability exp(-d/T), where d = (Lt-L)/L.Set j=j+1. If j=R+1, go to Step 9, else go to Step 4.Set T=T∗cfIf T<Tf, go to Step 11, else go to Step 3.s is the solution for the heuristic.We have also observed that one of the exploration methods of exchange and insertion might perform better than the other depending on the current solution. Therefore, we combine the two exploration methods, i.e., we utilize both methods and select the one with the better solution. We call this algorithm as Improved Simulated Annealing 2 (ISA-2). The steps of ISA-2 are the same as those of ISA-1 except the steps 4 and 5. The steps 4 and 5 of ISA-2 are given below.4.Generate two random integers h and l between 1 and n. Exchange the jobs in positions h and l of the sequence s, and call this new sequence s1. Insert the job in position h to position l of the sequence s, and call this new sequence s2.Evaluate L=TCT(s), L1=TCT(s1) and L2=TCT(s2) where TCT denotes the total completion time. Define Lt=min (L1, L2) and set st=s2 if L2⩽L1 and set st=s1 otherwise.We have noticed that selecting one of the methods with a certain probability has not improved the results.The parameters of initial temperature Ti, final temperature Tf, cooling factor cf, and number of repetitions R affect the performance of ISA-1 and ISA-2. We have fine-tuned the values of these parameters as following. We have tested 0.3, 0.2, and 0.1 for Ti, 0.002, 0.001 0.0005, and 0.0001 for Tf, and 0.99, 0.98, and 0.97 for cf. The number of repetitions R is selected such that all the considered heuristics have the same computational time. We have tested all combinations of the above parameter values using forty replications. It is obvious that higher values for Tiand cf and lower value for Tfgive better performance. However, this increases the computational time significantly. Therefore, according to our tested results, the parameters are set at Ti=0.10, Tf=0.0001, cf=0.98.Recently, Dhouib, Teghem, and Loukil (2013) proposed a new version of simulated annealing algorithm for permutation flowshop scheduling problems. They showed that their algorithm is very effective since their algorithm obtained the optimal solution for 90% of the considered cases. Dhouib et al. (2013) considered the regular flowshops while we consider no-wait flowshops. Moreover, their objective was to minimize the number of tardy jobs while our objective is to minimize total completion time subject to the makespan constraint. We adapted their algorithm to our problem, and denoted it by SA-D.In the SA-D algorithm in our paper, we have used the same parameter values as Dhouib et al. (2013) except the number of repetitions. This is determined such that the computational times of all the algorithms are the same.Torabzadeh and Zandieh (2010) proposed a different version of simulated annealing algorithm, called cloud theory-based simulated annealing (CSA) algorithm, for the two-stage assembly flowshop scheduling problem with a weighted average of makespan and mean completion time. They have indicated that their CSA algorithm performs better than the previous best existing heuristics. Recently, Allahverdi and Aydilek (2014) introduced an improved version of CSA for the two-stage assembly flowshop scheduling problem to minimize total tardiness. We adapt the improved version of Allahverdi and Aydilek (2014)’s CSA to our problem, called ICSA-1.The algorithm has three input parameters, initial temperature Ti, final temperature Tf, and the annealing index λ. Tiand Tfvalues are taken from Torabzadeh and Zandieh (2010) which are Ti=0.10 and Tf=0.0001. The annealing parameter is selected in order to have the same computational time.The steps of the improved cloud theory-based simulated annealing algorithm are as follows.1.Set the values for Ti, Tf, λ, and the initial sequence si.Set the temperature T=Ti,the sequence s=siand r=0.Set He=T, En=T, and u0=1−T.Set Fn=max{(En+He−1/3rand(0,1)), Epsilon} where Epsilon is an extremely small positive number; less than 10−8.Set TP=Fn(−2 ln(u0))1/2Pick two random integers h and l between 1 and n. Swap the jobs in position h and l of the sequence s, and call this new sequence as st.Evaluate L=TCT(s) and Lt=TCT(st) where TCT(s) is the total completion time of the sequence s.(Makespan constraint) If Cmax(st)⩽C, go to Step 9. Else, go to Step 10.If Lt<L then update s with st, i.e. set s=st. Else, update s with stwith probability.exp(−d/TP), where d=(Lt−L)/L.Set r=r+1.Set T=Ti*λr.If T<Tf, go to step 13, else go to step 3.s is the sequence for the heuristic.An insertion neighborhood structure is used in the step 6 of ICSA-1. It was observed that even though the insertion neighborhood structure performed better than the exchange neighborhood structure on average, this was not true all the times. Thus, we combined the two neighborhood structures such that the better of the two is selected. We call this as ICSA-2. The steps of ICSA-2 are the same as those of ICSA-1 except steps 6 and 7 which are6.Pick two random integers h and l between 1 and n. Swap the jobs in position h and l of the sequence s, and call this new sequence s1. Insert the job in position h to position l of the sequence s, and call this new sequence s2.Evaluate L=TCT(s), L1=TCT(s1) and L2=TCT(s2) where TCT(s) denotes the total completion time of the sequence s. Define Lt=min (L1, L2) and set st=s2 if L2⩽L1 and set st=s1 otherwise.The proposed algorithms are evaluated in this section. The computer used was a PC with Intel Core 2 Duo CPU T8300 processor of 2.40GHz running under Windows Vista Business Service Pack 2 operating system with 4GB RAM.As recommended by Hall and Posner (2001), processing time of job i on machine j (ti,j) is randomly generated from a uniform distribution U(1,100). Setup time of job i on machine j (si,j) is randomly generated from the uniform distribution U(0, k*ti,j). The variable k can be considered as the maximum ratio of setup times to processing times. For example, when k=0.6, the setup time is at most 60% of the processing time.We have considered 0, 0.2, 0.6, and 1.2 values for the k variable. It should be noted that when k=0, the setup times are zero for all jobs and on all machines which reduces to the no setup time environment. The reason for considering this case is to be able to compare the proposed algorithms with the heuristics that exist for the case of no setup time.The number of jobs n and the number of machines m were varied at different values. The considered values for n were 20, 30, 40, 50, and 60 while those for m were 3, 6, and 9.For each selected combination of n, m, and k, forty replicates were generated. The performances of algorithms were evaluated by average error. The average error is defined as 100x(Algorithm solution – Best solution)/Best solution. Furthermore, the percentage of the number of best solutions is considered.The experiments were conducted once but the presentation of the results have been separated into two stages in order to express the findings more clearly. In the first stage, the algorithms IA, GA-AA, GA-P, DE, and SA-D are compared with each other while, in the second stage, the algorithms IA, ISA-1, ISA-2, ICSA-1, and ICSA-2 are compared with each other. It will be shown that the best performing algorithm is IA which is far better than the others, i.e., SA-D, GA-AA, DE, and GA-P in the first stage. In the second stage, it will be shown that all the other four algorithms, i.e., ISA-1, ISA-2, ICSA-1, ICSA-2 are much better than the algorithm IA. This indicates that the well performing four algorithms in the second stage surely are better than the other four algorithms in the first stage, i.e., SA-D, GA-AA, DE, and GA-P as well.The results of the computational experiments for the first stage are discussed in the next subsection 4.1 followed by those of the second stage in subsection 4.2.The parameters of GA-AA were calibrated by Allahverdi and Aydilek (2013). Specifically, they used n for the number of population and generation sizes, 0.99 for the crossover probability, and 0.05 for the mutation probability. In this paper, we further fine-tuned the parameters such that in addition to their values, we have investigated a value smaller than and a value larger than the one that they used for each parameter. More specifically, we investigated 0.5n, n, and 1.5n for the number of population and generation sizes, 0.98, 0.99, and 1.0 for the crossover probability, and 0.04, 0.05, and 0.06 for the mutation probability. For each combination of the parameter values, forty replicates were conducted. The best performing combination of the parameter values was n, 1.5n, 0.98, and 0.04 for the population size, generation size, crossover probability, and mutation probability respectively.The computational results of IA, GA-AA, DE, GA-P, and SA-D are summarized in Fig. 1. The overall average errors of IA, GA-AA, GA-P, DE and SA-D are 0.02, 12.51, 9.44, 7.36 and 21.72, respectively. The overall average error refers to the average of the error values for all the considered variables n, m, k, and the number of replicates. In other words, each value of the overall average error is the average of 2400 combinations of n (5 values), m (3 values), k (4 values), and 40 replicates. By using the ANOVA statistical analysis, it has been confirmed that the performances of the algorithms are statistically different at 2.5% level of significance. Given that the performances of the algorithms are not the same, next, the Tukey honestly significant difference (HSD) test was used to find the best performing algorithm at 2.5% level of significance. The test results confirmed that, at this significance level, statistically the best performing algorithm is IA while the worst performing algorithm is SA-D. The results for a representative case of HSD are given in Fig. 2which clearly shows that the best performing algorithm is IA. It should be noted that the same conclusion is true for other combinations of n, m, and k. Furthermore, the test results indicated that, statistically, the algorithm GA-P performs better than GA-AA, and DE, in general, performs better than GA-P. Hence, algorithm IA outperforms the algorithms GA-AA, GA-P, DE, and SA-D. Moreover, the computational time of IA was less than or equal to those of the others. Therefore, the remaining algorithms will be only compared with IA in the following subsection.In this subsection, the performance of IA is compared with ISA-1, ISA-2, ICSA-1, and ICSA-2. The computational results for average error and the percentage of best solutions are presented in Tables 1 and 2for all m, n, and k values. Each point is the average of forty replicates in the tables. The algorithms IA, ISA-1, ISA-2, ICSA-1, and ICSA-2 were compared under the same computational time, which is given in Table 3. It should be noted that the computational time for the largest size problem was about half a minute as can be seen from the table. Hence, the computational time is not an issue, and thus, the algorithms are compared with respect to the two performance measures described earlier.The results are summarized in Figs. 3–11. Fig. 3 depicts the average error of the algorithms with respect to the number of jobs. It is clear from the figure that all the four algorithms ISA-1, ISA-2, ICSA-1, and ICSA-2 perform much better than IA, the best existing algorithm in the literature. Fig. 4 shows the same result by excluding the error of IA for a better comparison of the remaining four. Fig. 4 clearly shows that ISA-2 and ICSA-2 perform better than ISA-1 and ICSA-1. When ISA-2 and ICSA-2 are compared, on average, ISA-2 performs better than ICSA-2. Moreover, the performances of ISA-2 and ICSA-2, in general, does not seem to be sensitive to the number of jobs while those of ISA-1 and ICSA-1 deteriorate as n increases.Figs. 5 and 6 show the performances of the algorithms with respect to m and k, respectively. As seen from the figures, the performances of the algorithms do not seem to be sensitive either to m or k. It is clear from the figures that the analysis from the previous paragraph is still valid. Moreover, Fig. 6 indicates that the proposed algorithms ISA-1, ISA-2, ICSA-1, and ICSA-2 perform much better than IA for all values of k including k=0. It was shown by Allahverdi and Aydilek (2013) that IA was the best algorithm for the case of no setup times, i.e., k=0. Therefore, the proposed algorithms ISA-1, ISA-2, ICSA-1, and ICSA-2 in this paper can also be used for the case zero setup times. On average, the best performing algorithm, proposed in this paper, ISA-2 reduces the error of the best existing algorithm in the literature, IA, by 93%. Moreover, for k>0, the improvement is at least 90%, on average.In addition to the above analysis, we compared the algorithms statistically by using a Tukey honestly significant difference (HSD) test at 2.5% level of significance. The results for two representative cases of HSD are given in Figs. 7 and 8. The results in general confirm the earlier conclusions.Figs. 9–11 indicate the results for the percentage of best solutions versus n, m, k, respectively. These results are consistent with the average error analysis.The overall average errors of algorithms IA, ICSA-1, ISA-1, ICSA-2, and ISA-2, are 5.03, 1.73, 1.44, 0.62, 0.38, respectively.It should be noted that the errors of the algorithms that have been discussed so far are relative errors since the performance of an algorithm is compared with that of the best performing algorithm. We have also conducted some experiments to compare the performance of the best two algorithms, i.e., ICSA-2 and ISA-2, with the optimal solution. The exhaustive search is used in finding the optimal solution. The errors of the best two algorithms compared with the optimal solution, for small sized problems, are reported in Table 4for n=6, 7, 8, 9, 10, m=3, 6, 9, and k=0, 0.2, 0.6, 1.2. As can be seen from the table, the overall maximum absolute errors of ISA-2 and ICSA-2 are 0.19% and 0.36%, respectively while the overall average absolute errors of ISA-2 and ICSA-2 are 0.04% and 0.09%, respectively. Moreover, when all combinations of n, m, k, and the number of replicates are considered, the percentages of the best solutions for ISA-2 and ICSA-2 are 89.0 and 81.7, respectively. It should be noted that the number of best solution in these percentages refers to the number of optimal solution. However, when only the numbers of best solutions, including both optimal and non-optimal, are considered, the percentages are 94.3 and 85.5 for ISA-2 and ICSA-2, respectively. This indicates that, when both algorithms do not provide the optimal solution, the number of best solution of ISA-2 is higher than that of ICSA-2 which is consistent with the overall averages. As expected, the algorithm ISA-2 performs better than ICSA-2 for small size problems as well. Therefore, the algorithm ISA-2 is recommended to solve the problem addressed in this paper.All of the above conclusions were for the case of a relatively tight value of C in Algorithm-Cmax. The computational experiments have also been conducted for a relatively large value of C, i.e., by replacing Step 7 of Algorithm-Cmaxwith “Set C=max(C1, …, Cn)”. The performances of the best performing algorithms, i.e., ISA-2 and ICSA-2 were either the same or slightly better for a relatively large value of C, and hence, the computational results for large value of C are not reported.

@&#CONCLUSIONS@&#
The m-machine no-wait flowshop scheduling problem has been addressed in this paper where setup times were considered as separate from processing times. The objective was to minimize total completion time such that makespan is not greater than a certain value. Several algorithms have been proposed. The proposed algorithms were IA, ISA-1, ISA-2, ICSA-1, ICSA-2, GA-AA, GA-P, DE, and SA-D. The computational analysis has been conducted at two stages. At the first stage, the algorithms IA, GA-AA, GA-P, DE, and SA-D were compared with each other, and it was shown that IA performs better than the other four. At the second stage, the algorithms IA, ISA-1, ISA-2, ICSA-1, and ICSA-2 are compared with each other. The computational results indicated that the ISA-2 and ICSA-2 performed better than the rest of the algorithms, and, in general, ISA-2 performed better than ICSA-2. Moreover, algorithm ISA-2 proposed in this paper reduces the error of IA, the best existing algorithm in the literature, by about 90% under the same computational times. All the results were statistically verified.Even though the paper has addressed the problem with setup times, the case when setup times are zero has also been investigated, i.e., when k=0. The analysis has indicated that for k=0, the proposed best algorithm ISA-2 reduces the error of the best existing algorithm for the problem without setup times by about 93%. Therefore, the proposed best algorithm ISA-2 is considered as the best algorithm not only for the case of non-zero setup times but also for the case of zero setup times.A direction for research may be to investigate some tight lower bounds for the problem addressed in this paper. Such lower bounds may be utilized in a branch-and-bound algorithm, Rudek (2013), to find the optimal solution for larger size problems that have been solved in this paper.In this paper, the main objective was to minimize total completion time with a constraint on makespan value. An extension of this problem could be to minimize makespan with a constraint on total completion time. It should be noted that this latter problem has been addressed in the literature but for the case when setup times are assumed to be zero. Hence, it can be considered for the case of non-zero setup times.