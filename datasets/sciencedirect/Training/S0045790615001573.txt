@&#MAIN-TITLE@&#
Color image representation using invariant exponent moments

@&#HIGHLIGHTS@&#
A new image descriptor, namely Exponent moments (EMs), is introduced.The geometric invariant property of EMs is derived and analyzed.A EMs magnitudes based color image retrieval scheme is presented.

@&#KEYPHRASES@&#
Content-based image retrieval,Exponent moments,Geometric invariance,RGB color space,

@&#ABSTRACT@&#
In order to retrieve an image from a large image database, the descriptor should be invariant to geometric transformations (e.g., rotation, scaling, and translation). It must also have enough discriminating power and immunity to noise for retrieval from a large image database. The Exponent moments (EMs) descriptor has many desirable properties such as expression efficiency, robustness to noise, geometric invariance, fast computation, and multi-level representation. In this paper, we analyze the rotation, scaling, and translation (RST) invariant property of EMs, and propose a content-based image retrieval approach using invariant EMs. Experimental results show that the EMs can be used as an effective descriptor of global image content, and the proposed retrieval approach yields higher retrieval accuracy than some current state-of-the-art retrieval methods.

@&#INTRODUCTION@&#
WITH advances in information technology, there is an explosive growth of image databases (DBs), which demands effective and efficient tools that allow users to search through such a large collection. Traditionally, the most straightforward way to implement image database management systems is by means of using the conventional database-management systems such as relational databases or object-oriented databases. The system of these kinds is usually called keyword-based, in which the images are annotated with keywords. As the databases grow larger, to retrieve a particular image with these methods becomes tedious and inadequate. To solve these problems, content-based image retrieval (CBIR) has emerged as a promising alternative, and has drawn substantial research attention in the last decade [1]. In a typical CBIR, low-level features related to visual content are first extracted from a query image, the similarity between the set of features of the query image and that of each target image in a DB is then computed, and target images are next retrieved which are most similar to the query image. Extraction of good visual features which compactly represent a query image is one of the important tasks in CBIR [2,3]. Recently, some low-level visual features (including color, texture, shape, and other information) have been proposed, and have been widely applied in many CBIR systems [4].Color is one of the most common and determinant low-level visual features, which is stable against direction variations, size of image and background complexity. As conventional color features used in CBIR, there are color histogram, color correlogram, color structure descriptor (CSD), and scalable color descriptor (SCD) [3]. The latter two are MPEG-7 color descriptors [5]. Li [6] presented a novel algorithm based on running subblocks with different similarity weights for object-based image retrieval. By splitting the entire image into certain subblocks, the color region information and similarity matrix analysis are used to retrieve images under the query of special object. Aptoula and Lefèvre [7] presented three morphological color descriptors, one making use of granulometries independently computed for each subquantized color and two employing the principle of multiresolution histograms for describing color, using respectively morphological levelings and watersheds. Chen et al. [8] proposed an adaptive color feature extraction scheme by considering the color distribution of an image. Based on the binary quaternion-moment-preserving (BQMP) thresholding technique, the proposed extraction methods, fixed cardinality (FC) and variable cardinality (VC), are able to extract color features by preserving the color distribution of an image up to the third moment and to substantially reduce the distortion incurred in the extraction process. Lu and Chang [9] used the color distributions, the mean value and the standard deviation, to represent the global characteristics of the image, and the image bitmap is used to represent the local characteristics of the image for increasing the accuracy of the retrieval system. Liu and Yang [10] proposed a novel image feature representation method, namely, the color difference histogram (CDH), which is used to describe image features for image retrieval. For the proposed histogram, orientation and perceptual color information are combined in the unified framework, and both of their spatial layouts are considered. Talib et al. [11] proposed a new semantic feature extracted from dominant colors (weight for each DC). The newly proposed technique helps reduce the effect of image background on image matching decision where an object’s colors receive much more focus. Texture features are intended to capture the granularity and repetitive patterns of surfaces within in an image, and their role in domain-specific image retrieval, such as in aerial imagery and medical imaging, is particularly vital due to their close relation to the underlying semantics in these cases. Texture features, such as gray-level co-occurrence matrix (GLCM), Markov random field (MRF) model, simultaneous auto-regressive (SAR) model, Wold decomposition model, and edge histogram descriptor (EHD), have long been studied in image processing, computer vision, and computer graphics. He et al. [12] presented a novel method, which uses non-separable wavelet filter banks, to extract the features of texture images for texture image retrieval. Compared to traditional tensor product wavelets (such as DB wavelets), the new method can capture more direction and edge information of texture images. Tsai et al. [13] respectively employed log-polar mapping (LPM) combined with fast Fourier transformation (FFT), Gabor filter, and Zernike moment to extract three kinds of rotation-invariant texture features for image retrieval. Rakvongthai and Oraintara [14] investigated the use of complex wavelets for texture retrieval in a noisy environment where the query image is noisy. Based on a statistical framework, the feature vector is formed by modeling an image in the complex wavelet domain and estimating parameters from the image. Lasmar and Berthoumieu [15] introduced two new multivariate models using, respectively, generalized Gaussian and Weibull densities. These models can capture both the subband marginal distributions and the correlation between wavelet coefficients. Tzagkarakis et al. [16] described the design of a rotation-invariant texture retrieval system that exploits the non-Gaussian heavytailed behavior of the distributions of the subband coefficients, representing the texture information via a steerable pyramid. Aptoula [17] presented the results of applying global morphological texture descriptors to the problem of content-based remote sensing image retrieval. Specifically, they explored the potential of recently developed multiscale texture descriptors, namely, the circular covariance histogram and the rotation-invariant point triplets. Murala et al. [18] presented a novel CBIR scheme using local tetra patterns (LTrPs). The LTrP encodes the relationship between the referenced pixel and its neighbors, based on the directions that are calculated using the first-order derivatives in vertical and horizontal directions. Ehmann et al. [19] developed structural texture similarity metrics, which account for human visual perception and the stochastic nature of textures. The metrics allow substantial point-by-point deviations between textures that according to human judgment are essentially identical. They are based on a steerable filter decomposition and rely on a concise set of subband statistics, computed globally or in sliding windows. Shape is known to play an important role in human recognition and perception. Object shape features provide a powerful clue to object identity. Humans can recognize objects solely from their shapes. The significance of shape as a visual feature can be seen from the fact that every major CBIR system incorporates some shape features in one form or another [20]. By using a mathematical form of analysis, Li et al. [21] compared the amount of visual information captured by Zernike moments (ZM) phase and the amount captured by ZM magnitude, and then proposed combining both the magnitude and phase coefficients to form a new shape descriptor for CBIR. Xu et al. [22] presented an innovative partial shape matching (PSM) technique using dynamic programming (DP) for the retrieval of spine X-ray images. Jian and Lam [23] proposed an efficient method based on singular values and potential-field representation for face-image retrieval, in which the rotation-shift-scale-invariant properties of the singular values are exploited to devise a compact, global feature for face-image representation. Wei et al. [24] proposed a novel content-based trademark retrieval system with a feasible set of feature descriptors, which is capable of depicting global shapes and interior/local features of the trademarks.Most of the early studies on CBIR have used only a single feature among various color, texture, and shape features. However, it is hard to attain satisfactory retrieval results by using a single feature because, in general, an image contains various visual characteristics. Recently, active researches in image retrieval using a combination of color, texture, and shape features have been performed. Tian et al. [25] proposed a new feature descriptor based on the edge orientation difference histogram (EODH), and integrated the descriptor and Color-SIFT to reduce the semantic gap in image retrieval system. Yap and Paramesran [26] proposed a content-based image retrieval using Legendre chromaticity distribution moments (LCDM), which can provide a compact, fixed-length and computation effective representation of the color contents of an image. Chun et al. [27] proposed a content-based image retrieval method based on an efficient combination of multiresolution color and texture features. As its color features, color autocorrelograms of the hue and saturation component images in HSV color space are used. As its texture features, BDIP and BVLC moments of the value component image are adopted. The color and texture features are extracted in multiresolution wavelet domain and combined. Based on conventional complex-type moments (CTMs) and quaternion, Chen et al. [28] introduced the quaternion-type moments (QTMs) for representing color images. Wang et al. [29] proposed a new and effective color image retrieval scheme which uses the combination of dynamic dominant color, Steerable Filter texture feature, and pseudo Zernike moments shape descriptor. In [30], two-dimensional or one-dimensional histograms of the CIELab chromaticity coordinates are chosen as color features, and variances extracted by discrete wavelet frames analysis are chosen as texture features. Jeena et al. [31] proposed local oppugnant color texture pattern (LOCTP), which is able to discriminate the information derived from spatial inter-chromatic texture patterns of different spectral channels within a region. It determines the relationship in terms of the intensity and directional information between the referenced pixels and their oppugnant neighbors. Singha et al. [32] proposed an image retrieval technique based on the combination of Haar wavelet transformation using lifting scheme and the color histogram (CH) called lifting wavelet-based color histogram. Here, the color feature is described by the CH, and the Haar wavelet transformation is used to extract the texture features and the local characteristics of an image.According to the relation between the exponential function and triangular function, Meng and Ping [33] introduced a new moment named Exponent moments (EMs) in 2011. EMs is a new kind of orthogonal moment defined on the circular domain. EMs are free of numerical instability so that high order moments can be computed accurately. Besides, EMs magnitudes are invariant to geometric transformation. As a result, we believe EMs are more suitable for CBIR systems. In this paper, we propose a new content-based image retrieval approach using invariant EMs. The novelty of the proposed algorithm includes: (1) A new image descriptor, namely Exponent moments (EMs), which has many desirable properties such as expression efficiency, robustness to noise, fast computation, and multi-level representation, is introduced, (2) The geometric invariant property of EMs is derived and analyzed, and (3) A EMs magnitudes based color image retrieval scheme is presented.The rest of this paper is organized as follows. Section 2 recalls the decomposition and reconstruction about Exponent moments (EMs). Section 3 analyzes the rotation, scaling, and translation (RST) invariant property of EMs. Section 6 discusses the content based color image retrieval using invariant EMs. Simulation results in Section 5 will show the performance of our CBIR scheme. Finally, Section 6 concludes this presentation.In 2011, Meng and Ping [33] extended radial harmonic Fourier moments and introduced a new moment named Exponent moments (EMs). Compared with other orthogonal moment, EMs has many desirable properties such as better image reconstruction, lower noise sensitivity, geometric invariance, lower computational complexity. Besides, the EMs is free of numerical instability issues so that high order moments can be obtained accurately.A function set Pn,m(r,θ) defined in a polar coordinate system (r,θ) contains the radial function An(r) and Fourier factor in angle direction exp(jmθ)(1)Pn,m(r,θ)=An(r)exp(jmθ)whereAn(r)=2/rexp(j2nπr), n,m=−∞,⋯, 0,⋯, +∞,0⩽r⩽1,0⩽θ⩽2π. According to the characteristic of radial function and Fourier factor in angle direction, the set of Pn,m(r,θ) is orthogonal and sound over the interior of the unit circle∫02π∫01Pn,m(r,θ)Pk,l∗(r,θ)rdrdθ=4πδn,kδm,lwhere 4π is the normalization factor, δn,kand δm,lare the Kronecker symbols, andPk,l∗(r,θ)is the conjugate of Pk,l(r,θ).The image f(r,θ) can be decomposed with the set of Pn,m(r,θ) as(2)f(r,θ)=∑n=-∞+∞∑m=-∞+∞En,mAn(r)exp(jmθ)where En,mis the EMs of order n with repetition m, whose definition is(3)En,m=14π∫02π∫01f(r,θ)An∗(r)exp(-jmθ)rdrdθhere,An∗(r)is the conjugate of An(r).Following the principle of orthogonal function, the image function f(r,θ) can be reconstructed approximately by limited orders of EMs (n⩽nmax,m⩽mmax). The more orders used, the more accurate the image description(4)f′(r,θ)=∑n=-∞+∞∑m=-∞+∞En,mAn(r)exp(jmθ)≈∑n=-nmaxnmax∑m=-mmaxmmaxEn,mAn(r)exp(jmθ)where f′(r,θ) is the reconstructed image. The basis functions An(r)exp(jmθ) of the EMs are orthogonal over the interior of the unit circle, and each order of the EMs makes an independent contribution to the reconstruction of the image.Fig. 1(a) and (c) gives some examples of image reconstruction using ZMs and EMs for standard image “Barbara” (moment orders K=5, 10, 15, 20, 25, 30, 35, 40, 45, 50). As can be seen from Fig. 1(a) and (c), the reconstructed images using EMs show more visual resemblance to the original image in the early orders. The edges of the reconstructed images are also better defined with less jaggedness. Fig. 1(b) and (d) are the absolute difference between origin image and reconstructed images using ZMs and EMs for standard image “Barbara”.Here, we will derive and analyze the rotation, scaling, and translation (RST) invariant property of EMs [34].Translation invariance can be achieved by putting the origin of coordinates at the image centroid. The common centroid (xc,yc) of gray image can be defined as follows(5)xc=m1,0(f)/m0,0(f)yc=m0,1(f)/m0,0(f)where m0,0(f), m1,0(f), and m0,1(f) are respectively the zero-order and first-order geometric moment for gray image.Let the origin of the coordinate system be located at (xc,yc), the central EMs, which are invariant to image translation, can be obtained as follows(6)E¯n,m=14π∫02π∫01f(r¯,θ¯)An∗(r¯)exp(-jmθ¯)r¯dr¯dθ¯where(r¯,θ¯)is the image pixel coordinate representation in polar form by locating the origin at (xc,yc).Let fr(r,θ)=f(r,θ+α) denote the rotation change of an image f(r,θ) by the angle α, then EMs of f(r,θ+α) and f(r,θ) have the following relationsEn,m(fr)=14π∫02π∫01fr(r,θ)An∗(r)exp(-jmθ)rdrdθ=14π∫02π∫01f(r,θ+α)An∗(r)exp(-jmθ)rdrdθ=14π∫02π∫01f(r,θ)An∗(r)exp(-jm(θ-α))rdrdθ=14π∫02π∫01f(r,θ)An∗(r)exp(-jmθ)rdrdθ×exp(jmα)=En,m(f)exp(jmα)where En,m(fr) and En,m(f) are the EMs of fr(r,θ) and f(r,θ), respectively.According to above equation, we know that a rotation of the image by an angle α induces a phase shift ejmαof the En,m(f). Taking the norm on both sides of above equation, we have(7)|En,m(fr)|=|En,m(f)exp(jmα)|=|En,m(f)||exp(jmα)|=|En,m(f)|So, the rotation invariance can be achieved by taking the norm of the images’ EMs. In other words, the EMs magnitudes |En,m(f)| are invariant with respect to rotation transform.The EMs magnitudes are invariant to scaling if the computation area can be made to cover the same content. In practice, this condition is met because the EMs is defined on the unit disk. Given an image defined on a discrete domain f(k,l), where k=0,⋯,M−1 and l=0,⋯,N−1, we can map the image to a unit-disk domain of (xk,yl)∈[−1, 1]×[−1, 1] with(8)xk=k-M/2M/2,yl=l-N/2N/2Fig. 2shows the magnitudes distribution of EMs En,m(n=−2, −1,⋯, 2; m=−2, −1,⋯, 2) for gray image Barbara under various common image processing operations and geometric transforms. It can be seen that the EMs magnitudes of image have good robustness against common image processing operations and geometric transforms. Hence, EMs magnitudes are more suitable for describing image content and robust image retrieval.For content-based color image retrieval (CBIR), image features in color image database are extracted and stored in an index file that is linked to the original color images. The descriptor of the query color image is represented in vector form and the similarity is calculated between the descriptor vectors of database color images and of the query color image. This section presents a content-based color image retrieval scheme based on invariant EMs magnitudes. Fig. 3describes our image retrieval system framework.According to Sections 2 and 3, we can extract rapidly the invariant EMs features, i.e. EM magnitudes. However, we do not need too much EM magnitudes in color image retrieval, since color image features can normally be captured by just a few low-frequency EM magnitudes. The choice of the max order value nmax will depend on the size of the given color image and also on the resolution needed. Besides, we must consider fully the symmetrical characteristic of EM magnitudes distribution (|En,m|=|E−n,−m|) when the EM magnitudes are selected. Fig. 4shows the standard image Barbara and its EM magnitudes distribution (moment order K=2). Table 1lists the selected invariant EMs features for different max orders. From the reconstruction error curve presented in Section II, we can see that EMs, with the max order up to twenty, could have a sufficiently good color image representation power.In this paper, we use the magnitudes-based distance to measure the similarity between two color images. The magnitudes-based distance d′(i) (for all i) between two EMs magnitudes m1 and m2 is the absolute difference between them. The normalized magnitudes-based distance d isd(i)=d′(i)max(m1,m2)The overall magnitudes-based distance D between the magnitudes of two EMs vectors is then defined as(9)D=1N∑i=1Nd2(i)where d(i) is the normalized distance between the ith magnitudes of the two EMs vectors, and N is the total number of moments used.When retrieving color images, we firstly calculate the similarity between the query color image and each target color image in the image DB, and then sort the retrieval results according to the similarity value.In this paper, we propose a new content-based image retrieval scheme using invariant Exponent moments (EMs), which achieve higher retrieval efficiency. The proposed CBIR scheme can be summarized as follows: (1) For each color component (Red, Green, Blue), the invariant EM magnitudes are computed and selected; (2) The invariant EM magnitudes for three color components are combined into the invariant EMs Vector; (3) The similarity between color images is computed by using the invariant EMs Vectors.To evaluate the performance of the proposed scheme, we conduct an extensive set of CBIR experiments by comparing the proposed scheme to several state-of-the-art image retrieval approaches [2,6,26].The color image retrieval systems have been implemented in MATLAB R2011a programming environment on a Pentium 4 (2GHz) PC. To check the retrieval efficiency of proposed method, we perform experiments over 3000 images from 150 categories of the COREL photo gallery, in which each category contains 100 images. Every database image is of size 256×384 or 384×256, which cover a variety of topics, such as “Flowers”, “Buses”, “Beach”, “Elephants”, “Sunset”, “Buildings”, and “Horses”.We also perform experiments over 3000 images from 256 object categories of the Caltech image database. The Caltech image database comprises 30,607 images, in which each category has a minimum of 80 images. Caltech images are harvested from other popular online image database, and they represent a diverse set of lighting conditions, poses, backgrounds, image sizes, and camera systematics. The categories were hand-picked by the authors to represent a wide variety of natural and artificial objects in various setting. The organization is simple and the images are ready to use, without the need for cropping or other processing. Corel and Caltech images have been widely used by the image processing and CBIR research communities. Fig. 5shows our image retrieval system interface.In our image retrieval, the invariant EM magnitudes are used to capture the color content. To evaluate the overall performance of the proposed image feature in retrieval, a number of experiments were performed on our image retrieval.In order to choose the “good” maximum EMs order value for extracting image feature, we randomly selected 500 images as query images from the above image database, and tested the image retrieval accuracies for different maximum EMs order values. Fig. 6shows the mean of retrieval precisions of 500 times query results for different maximum EMs order values, which reflects the image retrieval efficiency. From Fig. 6, we can obtain the optimal maximum EMs order value nmax=5.We report experimental results that show the feasibility and utility of the proposed algorithm and compare its performance with three state-of-the-art image retrieval approaches [2,6,26]. To simulate the practical situation of online users, the sequence of query images used in all the experiments is generated at random.Figs. 7–9show the image retrieval results using the scheme [2], scheme [6], scheme [26], and the proposed method. The image at the top of left-hand corner is the query image; other 20 images are the retrieval results.In order to further confirm the validity of the proposed algorithm, we randomly selected 500 images as query images from the above image database (The tested 10 semantic class includes bus, horse, flower, dinosaur, building, elephant, people, beach, scenery, and dish). Each kind is extracted 50 images, and each time returns the first 20 most similar images as retrieval results. To each kind of image, the average normal precision and the average normal recall of 10 times query results are calculated. These values are taken as the retrieval performance standard of the algorithm, as shown in Fig. 10.According to Figs. 7–10, we see that the image retrieval accuracy by the proposed method is competitive with the other tested methods. The effectiveness of the proposed image retrieval results from using the invariant EMs descriptor, which has many desirable properties such as expression efficiency, robustness to noise, geometric invariance, and fast computation.In order to improve further the retrieval performance, we can also add relevance feedback to this scheme. The image retrieval with relevance feedback has four main components: query, retrieval, labeling, and learning. When a query is submitted, its low-level visual features (invariant EM magnitudes) are extracted. Then, all images in the database are sorted based on a similarity metric. If the user is satisfied with the result, the retrieval process is ended. If the user is not satisfied, he can label some images as positive feedbacks and/or some images as negative feedbacks. Using this feedback process, the system is trained based on machine learning using the embedded relevance feedback algorithm. Then, all the images are re-sorted based on the recalculated similarity metric. If the user is still not content with the result, he repeats the process.

@&#CONCLUSIONS@&#
