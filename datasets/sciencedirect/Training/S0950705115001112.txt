@&#MAIN-TITLE@&#
Construction of semantic bootstrapping models for relation extraction

@&#HIGHLIGHTS@&#
A general formalization of existing bootstrapping frameworks is concluded.A formalization of new semantic bootstrapping model is defined.A unique SSDP to guide learning iterations of bootstrapping.A novel bottom-up kernel method for comparing patterns.The application of the new model to KBP-ESF task.

@&#KEYPHRASES@&#
Relation extraction,Bootstrapping,Trigger word,Kernel,Pattern learning,

@&#ABSTRACT@&#
Traditionally, pattern-based relation extraction methods are usually based on iterative bootstrapping model which generally implies semantic drift or low recall problem. In this paper, we present a novel semantic bootstrapping framework that uses semantic information of patterns and flexible match method to address such problem. We introduce formalization for this class of bootstrapping models, which allows semantic constraint to guide learning iterations and use flexible bottom-up kernel to compare patterns. To obtain the insights of reliability and applicability of our framework, we applied it to the English Slot Filling (ESF) task of Knowledge Based Population (KBP) at Text Analysis Conference (TAC). Experimental results show that our framework obtains performance superior to the state of the art.

@&#INTRODUCTION@&#
Relation extraction (RE) is an important but unsolved problem in information extraction (IE). It focuses on extracting structured relations from unstructured sources such as documents or webs, which can potentially benefit a wide range of natural language processing (NLP) tasks such as question answering, ontology learning, and summarization [1].To solve the RE problem, a number of machine learning approaches have been recently applied. One common paradigm is the usage of bootstrapping [2] to learn relation patterns. The popularity of this framework lies in its ability to learn sufficient patterns and instances simply by iterations starting from a small number of seeds. Its central assumption is the pattern-relation duality principle [3] that good seed samples lead to good patterns, while good patterns help to extract good instances. Here, good patterns are usually referred to patterns that have high coverage (high recall) and low error rate (high precision), and good instances are instances that are realized by good patterns. Systems such as DIPRE [3], Snowball [4], and ExDisco [5] took a small set of domain-specific examples as seeds and an unannotated corpus as input. The seed examples can be either target relation instances or sample linguistic patterns in which the linguistic arguments correspond to the target relation arguments. New instances or new patterns will be found in the documents where the seed is located. The new instances or patterns will be used as new seed for the next iteration. However, Komachi’ analysis in [6] showed that semantic drift is an inherent property of iterative bootstrapping algorithms and, therefore, poses a fundamental problem. Hence, these systems without semantic constraint are greatly troubled by the problem of semantic drift.Relation patterns are defined as the structured features of the context of the entity and its attribute value (e.g. Bill Gates and Microsoft of the relation org:founded_by of organization entity) in a target relation mentioning [7]. Consequently, how well the system performs largely depends on how well patterns are represented. However, most existing patterns are with inflexible representation or without semantic constraint. Patterns in [3,4,7–9] using shallow syntactic features have poor performances in the extraction of the relations that are ambiguous or lexically distant in their expression. Dependency patterns [10–15] have been shown to perform better, since they are more informative for relation extraction. The shortest dependency pattern (SDP) and the subject–verb–object (SVO) pattern, among other dependency patterns, are two commonly used patterns [10,1,12,13]. However, due to less semantic constraint, they gain the generality at the cost of lacking specific information and thus may produce semantic drift in bootstrapping iterations.Similarity method, a measure which determines whether a pattern or instance derived from a new sentence is relation oriented or not, is another important key method for bootstrapping model. Unfortunately, the existing similarity methods are rigid or unsuitable for extracting relations expressed in complex structure patterns, since they cannot weigh the relative importance of different features of patterns only by using exact match method [3,7,8] or cosine-like method [12,4]. Kernel methods [16,10,11,17,15] have been proven to be effective in measuring the similarity of two complex relation patterns. Most existing kernels [11,16,18,19] compared two patterns by following their structures from the root node to its child nodes through the syntax trees. However, these methods still have limitations in measuring different kinds of patterns, which degrade the performance of new relation extraction. For example, “Bolin’s son, Yorke B. Mizelle, is a good boy” and “Bolin is survived by her son, Yorke” are two example sentences of relation per:children of person entity. The derived shortest dependency patterns [10] (shown in Fig. 3) that involve the respective root nodes of the two sentences son and survived may not be identified as similar by the kernel in [11,16]. It means that these kernels have poor performance in comparing weak relations that are not expressed by the main semantics of the sentences as the two sentences mentioned above.To address the aforementioned problem, this paper proposes a general framework for semantic bootstrapping with a novel bottom-up kernel method. The framework represents relations with a semantic dependency pattern where trigger words are used as the semantic anchor. The usage of trigger words allows semantic constraint to guide the learning iterations. Furthermore, a novel flexible similarity method is proposed to compare similarities of patterns. We introduce a formalization for this class of models and illustrate how this model classes can be constructed. Our guiding hypothesis is that relation-mentioning will share similar structures in their dependency trees. We thus model relations by quantifying the degree to which relations are attested in similar dependency patterns. The expressive power of our framework stems from four parameters which guide model construction. The first parameter extracts trigger words of target relations. The second parameter determines what type of features contribute towards the representation of relation pattern. The third parameter allows us to weigh the relative importance of new derived patterns. Finally, the fourth parameter determines which patterns can be added as the seed patterns of next iteration.We evaluate our framework on the English Slot Filling (ESF) [20] task of Knowledge Based Population (KBP) at Text Analysis Conference 2013 (TAC2013). The performances of methods can be evaluated by micro-average or macro-average. In this paper, to compare all evaluated methods in the same metric, we computed the micro-average precision, recall, and F1 value by using the metric defined in [21]. Because we have large enough samples in the experiment, we simply divided the corpus into the training set and the testing set to evaluate the performance. If the samples are limited, one can consider to use a cross-validation method [22]. The final experimental results show that our new model consistently outperforms former bootstrapping models yielding results superior to the state-of-the-art methods.Our contributions are threefold: a novel framework for bootstrapping model of RE that incorporates semantic constraint information, uses a novel bottom-up kernel method to compare patterns, and generalizes existing bootstrapping models of RE; an application of this framework to the English slot filling task; and an empirical comparison of our semantic bootstrapping models against state-of-the-art bootstrapping models.The rest of this paper is organized as follows: In Section 2, we give a brief overview of existing bootstrapping models of relation extraction. In Section 3, we present our modeling framework. Section 4 details experiments of parameters of semantic bootstrapping model and English slot filling. Discussion of our future work concludes the article in Section 5.Bootstrapping model has been proven to be useful framework for variety of information extraction tasks in natural language processing (NLP), such as named entity recognition [23–25], relation extraction [3,4,8] and question and answering [7]. This section will give a brief overview of existing bootstrapping models for RE.The bootstrapping framework of RE was originally introduced in DIPRE system [3], which describes a duality principle that drives the bootstrapping process. However, it cannot avoid producing noisy and wrong patterns because it does not have a good mechanism to evaluating patterns and seeds. The Snowball system [4] developed the bootstrapping framework of DIPRE system with a three-tuple pattern representation and a new strategy for evaluating patterns and relation instances. It forms a standard bootstrapping framework of relation extraction which is still been used in many derived bootstrapping frameworks [8,14,26,17,5]. The framework can be formalized as following:Definition 1A bootstrapping model is a tuple〈R,I,P,rep,s,e〉. R is the set of target relation. I and P are the set of seed instance and seed pattern of the target relation, which can achieve dual learning and can be expanded in iterations. rep is the pattern representation method. s is the similarity method, which maps relation mentioning sentences to seed instances. e is the evaluation method of newfound instances or patterns, and determines which one can be added as new seed of next iteration.To illustrate the framework, we construct a framework of bootstrapping for the target relation per:title, using training corpus as the following sentences: “Tomas was elected as the defense chief.”, using〈John,prosecutor〉as a seed instance and its corresponding seed sentence is “John was elected as the prosecutor”. Fig. 1shows the Stanford dependency analysis of the seed sentence. The dependency tree of the sentence is represented as a graph. The sentence head is the main verb elected which is modified by its passive nominal subject John, its passive auxiliary was and the as prepositional modifier prosecutor. The as prepositional modifier is modified by the determiner the. Next we will describe the existing corresponding methods of bootstrapping models in detail.One of challenges in bootstrapping framework is how to learn selective patterns which have high coverage to represent relations. How well the system performs largely depends on how well the patterns are represented. An ideal relation pattern should be abstract over surface word orders and can mirror semantic relations as clearly as possible.Traditional bootstrapping models, such as the Snowball system [3], Question and Answer system [7], and Espresso system [8] made use of named entity (NE) tags, surface strings, and their linear orders as components in the pattern representation:(1)rep(s)={p|p=left,tag1,middle,tag2,right},wheretag1andtag2are the relation related NE tags. left, middle, right are the left, middle, and right part around NE tags in a relation mentioning sentence s, respectively.Based on this representation, the pattern of the seed sentence and corpus sentence mentioned above can both be represented as “〈PER〉 was elected as 〈TITLE〉”. However, this kind of linguistic expressions are very limited in relations that are ambiguous or lexically distant in their expression.Alternative approaches have also been suggested in [10–14,26,27,15] for generating patterns from dependency analysis trees. Compared with shallow feature patterns, dependency patterns can extract relations located in long complex sentences more precisely [1,28]. The most used dependency-based pattern is the shortest dependency path (SDP) [10,1,29], which assumes that the contribution of the sentence dependency graph to establishing a relationship is almost exclusively concentrated on the shortest dependency path between an entity and its attribute value [10]. The SDP was firstly used in [10] and was developed in [1,30,31] to the most popular forms. The SDP is defined as follows:For each entity–value pair in a relation-mentioning sentence, the shortest dependency path from entity e to its attribute value v is defined as:(2)rep(s)=SDP(e,v)={tag(e),rel1,v1⋯reli,vi⋯,reln,tag(v)},whereviis the node i in dependency tree,reliis the dependency relation of two nodes. For a lexical chunk c, tag is a tag label function that istag(c)∈{PER,ORG,LOC,DATE⋯}. The tag of chunk is relation dependent, for example, tags of entity–value pairs of per:children are PER and PER, respectively; tags of per:employee_of are PER and ORG, respectively.Based on the SDP, the pattern of the seed sentence and the corpus sentence mentioned above can both be represented as “〈PER〉 nsubjpasselectedprep_as 〈TITLE〉. Obviously, the SDP offers a condensed representation of the information need to assess relations [10]. However, because there is less semantic constraint, the SDP patterns gain the generality at the cost of lacking specific information and thus may produce semantic drift in bootstrapping iterations.After generating a number of patterns from the initial seed pairs, the system scans available documents to search sentences of text that match the patterns. Similarity defining method determines whether a pattern or instance derived from a new sentence is relation oriented or not. Consequently, it is another important key of bootstrapping models.Vector pattern based systems such as Snowball system propose cosine-like similarity method to its corresponding patterns of two sentencessiandsj:(3)sim(si,sj)=〈psi,psj〉,iftagsmatch,0,otherwise.Here, the〈psi,psj〉is the dot product ofpsiandpsj. Based on this similarity method, we can compute the similarity between the seed pattern and the new pattern derived from corpus sentence to be 1. Hence we can extract new entity–value pair 〈Tomas, defense chief〉. However, the cosine-like similarity method, which does not weigh the relative importance of different features, is therefore weak for extracting relations expressed in complex structure patterns.Other complex structured patterns, which have a less fixed structure and occur less frequently, are unlikely to be measured using the previous proposed similarity methods. Most existing methods [3,8,17,1,29] utilize the simplest exact match method, which is defined as(4)Match(si,sj)=1,ifrep(si)=rep(sj),0,otherwise.Most structure pattern based systems such as the SDP based system use this kind of similarity method. Similarly, the similarity of the seed pattern and the pattern derived from the corpus sentence can be determined to be 1 after normalization. We can also extract entity–value pair 〈Tomas, defense chief〉. On one hand, this rigid match method can maintain the semantic information of patterns. On the other hand, it may lose many sentences with same relation mentioning but with different forms of expression.Kernel methods [10,11,16,15] have been proven to be effective to measure complex structured patterns’ similarity in supervised relation extraction systems. Zelenko et al. [16] firstly proposed a kernel method to measure similarities of structured patterns from the root node to its child nodes through shallow parse tree. This kernel method was used with a slightly more general version in evaluating similarities of dependency-based patterns in [11] as following:(5)K(P1,P2)=0,ifm(r1,r2)=0,s(r1,r2)+Kc(r1[c],r2[c]),otherwise,wherem(r1,r2)∈{0,1}is a matching function between the two root nodes of two dependency trees,s(r1,r2)∈{0,∞}is a similarity function,Kcis a kernel function over children.tiis the ith node and the set of its all children is labeled asti[c]. Let a and b be sequences of indices, namely a is a sequencea1⩽a2⩽⋯⩽an, and likewise for b.d(a)=an-a1+1andl(a)is the length of a. Then(6)Kc(ti[c],tj[c])=∑a,b,l(a)=l(b)λd(a)λd(b)K(ti[a],tj[b]).Based on this similarity method, we can also extract entity–value pair 〈Tomas, defense chief〉.Komachi’analysis in [6] of has shown that semantic drift is an inherent property of iterative bootstrapping algorithms and, therefore, poses a fundamental problem. Hence, any bootstrapping approach to semantic relation extraction requires a method to control the expansion phase and avoid semantic drifting. This can be achieved via an automatic assessment of the quality of the new term pairs as well as the quality of the generated patterns.Riloff and Jones [23] proposed mutual bootstrapping (MB), where both the terms, and the contexts used to extract the terms, are extracted in alternating bootstrap iterations. The MB is designed in [32] to balance reliability and productiveness of the seed. It is described as(7)score(fi)=seen(fi)new(fi)log2(seen(fi)),where seen(f) is the number of terms (by type) extracted with context feature f that are already in the semantic class, and new(f) is the total number of terms (by type) extracted with context feature f. The highest scoring context feature is added to the semantic class.A different evaluation method was introduced in [8]. It assumed that good patterns are highly associated with reliable instances. It used point-wise mutual information [32] for measuring associations between patterns and instances. conf(p), the confidence of a pattern p, is computed as its average strength of association across each input instance i in I, weighted by the reliability of each instance i as:(8)conf(p)=∑i∈Ipmi(i,p)maxpmi∗conf(i)|I|,where conf(i) is the reliability of instance i (will be defined below) andmaxpmiis the maximum point-wise mutual information between all patterns and all instances. conf(p) ranges from [0,1]. The reliability of the manually supplied seed instances is conf(i)=1. The point-wise mutual information between instancei={e,v}and pattern p is estimated using the following equation:(9)pmi(i,p)=log|e,p,v||e,∗,v||∗,p,∗|.Similarly to our pattern reliability measure, conf(i), the reliability of an instance i, is:(10)conf(i)=∑p∈Ppmi(i,p)maxpmi∗conf(p)|P|.The evaluation method e evaluates the new instance and decides whether it can be added as a seed of the target relation. Therefore, we can enrich the seed instance set to 〈John, prosecutor〉, 〈Tomas, defense chief〉. Since the pattern of new instance is the same as the seed pattern, the set of seed pattern is not updated.Our framework of semantic bootstrapping model can now be formally specified by extending definition of existing bootstrapping model from Section 2:Definition 2A semantic bootstrapping model is a tuple〈R,I,P,T,tm,rep,s,e〉. R is the set of target relations, I and P are the set of seed instances and patterns respectively, which can achieve dual learning. The parameter rep is pattern representation method; s is the similarity method that measures the similarity between seed patterns with patterns derived from new sentences; e is the evaluation method of newfound instances and patterns. Our additional set and parameter are the set of trigger words T, and the trigger words mining method tm.Note that trigger words are used as the semantic constraint for each relation pattern. Definition 2 proposes a new trigger word set and its corresponding mining method for the bootstrapping model. Compared with the similarity methods mentioned in Section 2.2, we utilize a novel robust similarity method for the new semantic dependency pattern of our model. If the similarity between seed patterns and the pattern derived from a new sentence is higher than a threshold, new instances can be extracted as candidate seed instances.We can now construct a semantic model that illustrates our framework. According to Definition 2, in order to construct a tuple of bootstrapping framework for the target relations, we must provide a trigger word mining function, a pattern representation function, a similarity function, and an evaluation function. The model is resulted from a trigger word mining function which considers activation between candidate trigger words and entity–value pairs, a pattern representation function which take trigger words as the semantic anchor of the SDP, a kernel-based kernel function which evaluates weighted bottom-up similarities, and a dual pattern and instance evaluation function. we will define these functions in the next section.Key part in the semantic bootstrapping model construction process is the notation of semantic shortest dependency pattern (SSDP) and the bottom-up kernel (BUK) method for patterns comparison. The SSDP is the shortest dependency paths with trigger words as the semantic nodes and the BUK is a new similarity method which measures two patterns by summed similarities from bottom nodes to up nodes of patterns.Trigger word plays an important role in bootstrapping models. On the one hand, it acts as the conceptual anchor point in activating a target relation. On the other hand, the bootstrapping model can suppress the semantic drift with trigger words as the semantic constraint in iterations. Hence, the trigger word extraction of a target relation is one of the key problems in bootstrapping models. We essentially state the definition of trigger word mentioned in [33] asDefinition 3Trigger words are words with semantic information, which activate patterns of specific relations and act as the patterns’ conceptual anchor points.If rep is the shortest dependency path (SDP) from an entity to its attribute value, the pattern of the seed sentence in Section 2.1 can be represented as shown in Fig. 1. Obviously, the word elected acts as the semantic conceptual anchor point of the pattern and activates the relation per:title. Therefore, performance of the trigger word based dependency patterns mainly depends on how well the trigger words are identified.Classifier-based model of relation extraction proposed in [34] firstly gathered trigger word list from WordNet [35] by checking whether a word has the semantic class “person|⋯|relative”. This trigger words mining method is dictionary dependent and generally has poor domain portability in practice.Another trigger word mining method proposed in [36] defined trigger words as all the words on the dependency path except stop words:(11)tm(r)={w∈π|w∉Wstop},where π is the dependency path of sentences of corpus,Wstopis the set of stop words.We proposed an activation force based trigger word mining method in [37]. The method assumes that the trigger word and entity–value pair of a relation can activate each other in a large collection of corpus. We defined trigger force (TF) of a trigger wordwiby weighted summing the activation force that an entity e exerts onwiand the activation force [38,39] thatwiexerts on the attribute–value v of the entity as following:(12)Trigger_Force(wi)=μaf(e,wi)+(1-μ)af(wi,v),where μ is a smoothing parameter falls in the interval [0,1]. This parameter is used to adjust the relative importance ofaf(e,wi)andaf(wi,v), which is illustrated as following:(13)af(e,wi)=(fe,wi/fe)(fe,wi/fwi)/de,wi2,(14)af(wi,v)=(fwi,v/fwi)(fwi.v/fv)/dwi,v2,wherefe,fwi, andfvare the occurrence frequencies of e,wi, and v, respectively.fe,wiis the co-occurrence frequency of e followed bywiwithin L words.fwi,vis the co-occurrence frequency ofwifollowed by v within L words.de,wiis the average distance between e andwiin their co-occurrence, anddwi,vis the average distance betweenwiand v in their co-occurrence.Therefore, by setting a thresholdtf0, the trigger words of a target relation can be extracted as(15)tm(r)={w|Trigger_Force(w)⩾tf0}.The SDP representation method offers a condensed representation of relations. However, because there is less semantic constraint, the SDP is likely to cause semantic drift in bootstrapping iterations. To maintain the semantic information of the SDP, we constrain each SDP, which contains words, with a trigger word as the semantic node. Then, we can define the semantic shortest dependency pattern (SSDP) as follow:For each entity–value pair in a relation-mentioning sentence, the semantic shortest dependency pattern from entity e to its attribute value v is defined as:(16)SSDP(e,v)=SDP(e,wi)+SDP(wi,v),ifWs≠∅,wherewi∈Ws∩Wtris one of the trigger words in the intersection of the set of words between entity and its attribute–valueWsand trigger word setWtr. The trigger words are extracted by methods described in Section 3.2.1.Note that, there are also many sentences with the structure where no words exist between the entity and its attribute value as shown in Fig. 2. Even the SDPs derived from the sentences do not include any word, they may have high coverage, which should be extracted as patterns to represent relations to enhance the final extraction recall. Therefore, we update (16) as follows:(17)SSDP(e,v)=SDP(e,wi)+SDP(wi,v),ifWs≠∅,SDP(e,v),otherwise.If SSDPs contain no words (the pattern shown in Fig. 3), the exact matching method is effective. Otherwise, the similarity measurements become complicated. Fig. 3 shows two SSDPs derived from weak relation sentences of relation per:children introduced in Section 1. The root nodes of the two SSDPs are survived and son respectively. For most of match methods, the two nodes cannot be determined as match to each other. Consequently, the similarity of the two patterns is 0 when being determined by the kernel method represented in (5). This means that these kernels have poor performance for extracting weak relations that are not expressed by the main semantics of sentences.To address this problem, we define a novel kernel, named bottom-up kernel (BUK) to compare pairs of SSDPs. We hypothesize that the nearer the dependency to entity–attribute–value the more important the dependency is. The BUK compares patterns from the entity–attribute–value node up to the root node by following structures of their SSDPs. We now formalize the notions of relation examples.Definition 4A dependency dep is a set of attributes{rel,l}, with rel representing the relation of the dependency and l representing the governor lexical word of the dependency relation.We use dep.l and dep.rel to denote the value of attributes with the name l and rel in the dependency dep respectively, e.g., dep.l=son and dep.rel=nsubj.Definition 5A relation example is defined inductively as•Let dep be a dependency,P=([],dep)is a relation example. Here, [] denotes an empty dependency sequence.Let dep be a dependency,[D1,D2⋯]be the parents dependency sequence of the entity–attribute–value node of the relation example. Then, the pairP=([D1,D2⋯],dep)is a relation example.Based on this definition, we state thatdep.lis the children of the attribute word of[D1,D2⋯]. We use the P.d to denote the last element of the example pair, and use the shorthand P.l to refer to P.d.l. We then define a BUK on the dependencies in terms of dependencies’ attributes.We now define kernels on relation examples that represent similarity of two SSDPs. we first define a matching functionm(·,·)∈{0,1}and a similarity functions(·,·)on dependencies. The matching function determines whether the two SSDPs are matchable or not. We define that two SSDPs are matchable if their attribute of the dependencies are all in the trigger word set. The similarity function on dependencies is computed in terms of the dependencies’ attributes.For example,(18)m(P1.d,P2.d)=1,ifP1.l,P2.l∈Wtr,0,otherwise,and(19)s(P1.d,P2.d)=γ1+γ2,ifP1.rel=P2.relandP1.l=P2.l,γ1,ifP1.l=P2.l,0,otherwise,whereγ1andγ2are weights to attribute l and rel,Wtris the trigger word set of each relation. Trigger words constrain the pattern’s semantic information. If the two patterns contain the same trigger word of a target relation, the two patterns are more likely to be similar in expressing the same relation. Therefore, a bigger weight should be given to the attribute l.Specifically, for two relation examplesP1andP2, we define the similarity function in terms of similarity functionK(P1,P2)of the end dependencies and the similarity functionKpof the parent dependencies as:(20)K(P1,P2)=0,ifm(P1.d,P2.d)=0,s(P1.d,P2.d)+Kp(Dp1,Dp2),otherwise,whereKpis the similarity function that calculates the similarity between the parent dependencies set ofDp1andDp2, and can be defined as follows:(21)Kp(Dp1,Dp2)=∑dep1∈Dp1∑dep2∈Dp2λd(1)λd(2)k(dep1,dep2).d(1) and d(2) are the distances from the current element to their last dependency respectively. The constant0<λ<1is a decay factor that penalizes matching dependencies that are spread out off the dependency distances. The farther the dependency to the entity–attribute–value, the smaller the weight of its similarity is. It can be proved that K is a kernel function [16]. Take the two patterns in Fig. 3 as example. Firstly, the match function t compares the governor word of the last dependency of two patterns, because the two governor words are the same and belongs to the set of trigger words, som(P1.d,P2.d)=1. Secondly, similarity functions(P1.d,P2.d)compares the relation of the last dependencies. Since the relation and the governor word of the last dependency of two patterns are equal to each other, we haves(P1.d,P2.d)=γ1+γ2. As there is no similar parent dependency, the similarity of the two SSDPs isK(P1,P2)=γ1+γ2.We improve the MB algorithm for the evaluation of the reliability of patterns and entity–value pairs in [32] as following:(22)Conf(pn)=∑k|I′|[ik=ik′]|I′|log(|I′|)×100%,where[ik=ik′]is the Iverson notation that equals 1 when the seed of last iteration matches the extracted seed instanceik′. Intuitively, the sum in the numerator is the number of correct pairs of the extracted seed set. Similar to the pattern reliability measure, we define the reliability of a seed pair as(23)Conf(in)=∑k|P′|[pk=pk′]|P′|log(|P′|)×100%.Among the patterns and seed pairs evaluated during each iteration, we use the measures defined in (22) and (23) to identify the reliable patterns and seed pairs for the next iteration to extract additional patterns and seed pairs.To obtain insights of the reliability and the applicability of the new semantic bootstrapping model, we apply it to the KBP-ESF task of TAC.The training and testing data are formed by query relevant documents from the ESF corpus, which contains long complex sentences. The ESF corpus includes 2.3 Millions news docs and 1.5 Millions web and other types docs from 2009 to 2012, and contains1̃Million newswire docs from a subset of Gigaword (5th edition) [40],1̃Million web docs, and1̃00 Thousands docs from discussion fora in 2013. For each relation, we used all correct ESF entity–value pairs from 2009 to 2012 assessments results data [41] as the seed pairs to match sentences in relevant docs, forming the seed sentences. Query entities of ESF2013 were used as test entities and assessments results data [41] of ESF2013 were used as the standard answer. We learned relation patterns in all the docs of 2013 corpus, and formed the testing data with 5000 docs by choosing the top 50 relevant docs of each entity. The numbers of entities and attribute slots of the training and the test data are listed in Table 1. The distribution of the slots in evaluating the queries of ESF2013 is shown in Fig. 4.All relevant docs are analyzed by Stanford CoreNLP [43]. It provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, and mark up the structure of sentences in terms of phrases and word dependencies, and indicate which noun phrases refer to the same entities. In this paper, we use the dependencies in the “collapsedDependency” format [44].However, for many slots in the ESF task, such as per:title, per:charges, per:origin, per:religion and per:cause_of_death whose values are title, charge, origin, religion, and cause, they cannot be labeled as named entities by the tool of Stanford CoreNLP. For these slots, we trained a entity labeling model to recognize these five types.Definition 6An entity labeling model is a model based on the conditional random fields (CRF) [45]. By using context words and the part_of_speech (POS) of context as features, the model utilizes the CRF principle to train an optimal entity labeling model.Based on the assessment results data released by the official site of TAC-KBP, we choose relevant docs of entities in 2009–2012 with correct labels of these five slots as training data. We used the CRF++ [46] to train five entity labeling models and applied them to relevant documents of entities in 2013 to recognize these five types. For simplicity, we only used context with the width of 2 as features. The test accuracy is approximately 90% for all the five types. All relevant types are labeled as TITLE, CHARGE, ORIGIN, RELIGION or CAUSE.Moreover, considering the time complexity of co-reference analysis, we did not do co-reference analysis on the relevant docs.During learning iterations, the bootstrapping model stops learning patterns until no more patterns are added into the set of seed patterns. Furthermore, the construction of bootstrapping models involves a number of parameters to be adjusted: the parameter λ of the TF in (12), the parameterγ1,γ2, and λ in the BUK, the threshold of the confidence of patterns, and the entity–value pairs. In this paper, we explored the parameter space of our semantic bootstrapping models on the ESF data set. The best performing model was then used in all our subsequent experiments. We expect a semantic model optimized on the ESF2013 task to perform well. We next explain how parameters were instantiated in our semantic models with an emphasis on the influence of the pattern representation function selection and similarity functions.Similar to the preprocess procedure introduced in [47], we investigate the impact of different in (12) on the precision of top 10 extracted trigger words by changing it from 0 to 1, with a step of 0.1 (shown in Fig. 5). From Fig. 5, we can observe that the precisions of all three relations increase before μ reaches 0.5, and decrease afterμ=0.5. The results suggest that whenμ=0.5, the trigger word mining method can get a good performance. Therefore, we conduct the experiment of trigger word extraction in the condition ofμ=0.5, with the top 10 trigger words of four PER relations shown in Fig. 6.Here, because of different training data set scale, we set different thresholds in (15) for different relations respectively. In addition, to ensure the recalls, if a word mentions any relation of entity, we judge the word as a candidate trigger word correspondingly without handling ambiguities.The ratio ofγ1γ2in (19) denotes the relative importance of attribute word and relation of a dependency. Since we use trigger words to constrain SSDPs’ semantic information, a bigger weight should be assigned to the attribute w.Based on this point of view, we carried out experiments to investigate the ratio ofγ1γ2on the performance by changing it from 1 to 5, with step size equal to 1. Fig. 7shows the impact of the ratioγ1γ2on F1 value of five relations of person entity [48]. The results suggest that all the five relations achieve the best performance when the ratio was set as 2, which indicates that the weights of the words are two times of the weights of the dependency relations. Therefore, the following experiments were conducted withγ1γ2.Much like the kernels in [11,16], we set the parameter λ of (21) as 0.5. In addition, all similarity thresholds are set to be 0.9 in finding the final attribute–values.By using the new semantic bootstrapping model with the BUK as the similarity method (SBS-BUK), we learned SSDPs from the training data and applied these SSDPs on 5000 relevant docs of 2013 entities to extract their attributes defined in ESF task of KBP. There are 494 relation patterns of person entity and 246 relation patterns of organization entity in all. Table 2shows some learned example SSDPs of some slots in ESF. Fig. 8illustrates performances of 10 slots in ESF.From Fig. 8, we can observe that, our method has a good performance with the average recall of 34.0%, the average precision up to 62.2% and F1 value equals 42.7%. Especially, the recalls of per:age, per:cause_of_death, and per:city_of_death are all above 75%, which are significantly higher than the stateoftheart methods investigated in this paper. It can be easy to understand that the reason for the high recall is because of the flexibility of the BUK which adopts a relatively looser and effective similarity method. Meanwhile, the constraint of trigger word of the semantic bootstrapping model makes all patterns and instances added during each iteration be relation oriented, which can largely improve the precision.For more insights on the semantic bootstrapping model, we compared it with other three methods. In order to facilitate comparison, we conduct the patterns and seed pairs of all measured with the same evaluation method described in Section 3.2.4. The overall precision, recall, and F1 value are micro averages [21], which merge the counts of true positive, false positives across all relations, and compute the overall performance by definition as a single relation.First, we implemented the existing bootstrapping model, with the shortest dependency path [29] as the representation method and the exact match method as the similarity method, which is denoted as BS-SDP. Based on the same match method, we implemented the semantic bootstrapping model with the semantic shortest dependency pattern as the pattern representation method and we denote it as SBS. From Table 3, we can observe that the SBS is superior to BS-SDP, in terms of precision and F1. This suggests that the semantic bootstrapping model with trigger words as semantic constraint can improve the performance significantly. In addition, compared with BS-SDP, the SBS reaches a good performance at a cost of slight drop of recall due to the strict semantic constraint of trigger words.Second, we implemented the semantic bootstrapping model with kernel method as the similarity method. In this implementation, we chose dependency kernel method [11] and the bottom-up kernel method as the similarity methods, denoted as SBS-DK and SBS-BUK respectively. From Table 3, we can see that recalls of SBS-DK and SBS-BUK are higher than the recall of SBS. That indicates kernel method with flexible strategy can significantly improve the measurement of recall from that of exact match method. More specifically, with the comparison of SBS-DK and SBS-BUK, we can conclude that the SBS-BUK is superior to the SBS-DK, which shows that the BUK is more suitable than Dependency kernel for comparing SSDPs.Furthermore, we conducted analysis of paired two-sample mean (two-tailed test) of recall and precision between our SBS-BUK and other three methods. We assumed that our SBS-BUK method results has no difference with the other three methods, and chose 0.10 as the threshold of statistical significance. As shown in Tables 4 and 5, all the p values are below 0.10, then the null hypothesis is rejected in favor of the alternative hypothesis. We can conclude that our proposed methods has statistically significant difference compared with the other three methods.

@&#CONCLUSIONS@&#
This paper presented a general framework for the construction of semantic bootstrapping models. The framework incorporate trigger words as the semantic constrain to guide the bootstrapping iterations. It extends previous work on traditional bootstrapping model of relation extraction by providing a principled way for defining trigger words, pattern representation method, similarity method and evaluation method. Furthermore, we defined a new bottom up kernel method to determine whether a pattern or instance derived from a new sentence is relation oriented or not.We evaluated our framework on the ESF task of TAC-KBP and compared it against the state-of-the-art models. We adapted an optimal model on testing data by exploring a relatively small subset of the parameter space. Based on the optimal model, experiments revealed that the semantic bootstrapping model is superior to the traditional bootstrapping model without semantic constraint. Experiments also showed that the BUK similarity method has better performance than existing dependency tree kernel method in all three measurements.Aside from the interesting research on pattern representation, trigger words mining, and similarity method of the semantic bootstrapping models, we intend to optimize the pattern evaluation method to improve the heuristic evaluation method used in this paper. For the trigger word mining method, we did not perform the threshold optimization in this study, leaving a space for further improvement. Finally, our experiments were conducted without using co-references information of the dependency tree. All the three measurements introduced in this paper are expected to be improved when the co-references information is used.