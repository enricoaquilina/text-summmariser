@&#MAIN-TITLE@&#
The self regulation problem as an inexact steepest descent method for multicriteria optimization

@&#HIGHLIGHTS@&#
A review of an inexact steepest descent method for multicriteria optimization.Full convergence of the sequence generated to a Pareto critical point under quasi-convexity.Full convergence of the sequence generated to a weak Pareto optimal point under pseudo-convexity.A model of self regulation in Psychology using a variational rationality approach.

@&#KEYPHRASES@&#
Multiple objective programming,Steepest descent,Self regulation,Quasi-convexity,

@&#ABSTRACT@&#
In this paper we study an inexact steepest descent method for multicriteria optimization whose step-size comes with Armijo’s rule. We show that this method is well-defined. Moreover, by assuming the quasi-convexity of the multicriteria function, we prove full convergence of any generated sequence to a Pareto critical point. As an application, we offer a model for the Psychology’s self regulation problem, using a recent variational rationality approach.

@&#INTRODUCTION@&#
The method described by (Burachik, Graña Drummond, Iusem, & Svaiter, 1995) for a continuously differentiable optimization problem generates a sequence with the property that any accumulation point of it is a critical point for the objective function. It is the steepest descent method with Armijo’s rule, which was later generalized by (Fliege & Svaiter, 2000) for multicriteria optimization, in the case where the objective function is a vectorial function. The result of full convergence is assured when the objective function is convex, provided that the problem’s solution set is non-empty, see (Burachik et al., 1995), or in a more general way, when the objective function is quasi-convex; see (Bello Cruz & Lucambio Pérez, 2010; Kiwiel & Murty, 1996). Graña Drummond and Svaiter (2005) generalized this result for convex vectorial optimization and (Bento, Ferreira, & Oliveira, 2012) generalized it for quasi-convex multicriteria optimization, see also (Bello Cruz, Lucambio Pérez, & Melo, 2011). See (Miglierina, Molho, & Recchioni, 2008) for a computational approach of a gradient like method in the context multiobjective. For extensions of other scalar optimization methods to the vectorial setting, see (Bonnel, Iusem, & Svaiter, 2005; Ceng, Mordukhovich, & Yao, 2010; Fliege, Graña Drummond, & Svaiter, 2009; Villacorta & Oliveira, 2011) and references therein.As far as we know, (Bento et al., 2012) were the first ones who presented a result of full convergence of the exact steepest descent method, with Armijo’s rule, for quasi-convex multicriteria optimization – a work that includes contributions in both Euclidean and Riemannian contexts. In the present paper, we study the method proposed by (Fliege & Svaiter, 2000), which is the inexact version of the method presented in (Bento et al., 2012). Relative errors on the search directions are admitted in this method, that is, an approximation of the exact search direction is computed at each iteration. Specifically, we present the global convergence of any sequence generated by this method to a Pareto critical point (resp. weak Pareto optimal point) of the multiobjective optimization problem in the quasiconvex case (resp. pseudo-convex case).This paper is organized as follows: In Section 2, we present the self regulation problem under the context of Psychology; In Section 3, the multicriteria problem and the first order optimality condition for it are presented, along with some basic definitions; In Section 4, the inexact steepest descent method used to find a solution for multicriteria problems is stated and the well-definition of the sequence generated by it is established; In Section 5, a result for partial convergence of the method is presented without any additional assumption on the objective function. Moreover, assuming that the objective function is quasi-convex and that the Riemannian manifold has non-negative sectional curvature, we present a result for full convergence; Finally, Section 6 offers a “distal-proximal” model of self regulation in Psychology, using a recent variational rationality approach; see (Soubeyran, 2009 – Variational rationality, a theory of individual stability and change: worthwhile and ambidextry behaviors), (Soubeyran, 2010 – Variational rationality and the unsatisfied man: routines and the course pursuit between aspirations, capabilities and beliefs), (Soubeyran, 2012a – Worthwhile to change course pursuits and behavioral traps) and (Soubeyran, 2012b – Variational rationality: a course pursuit between desired ends and feasible means), which models behaviors as an approaching or avoidance process, a course pursuit between “desired enough” ends and “feasible enough” means.In this section, devoted to applications, we will focus our attention to the so-called “multiple goals self regulation problem”, in the field of behavioral sciences. Our paper extends the steepest descent method of (Fliege & Svaiter, 2000) to the quasi-convex case in multicriteria optimization. We will show a strong link between our research and the “variational rationality” approach of Soubeyran’s “theories of change” (Soubeyran, 2009, 2010, 2012a, 2012b). Change problems consider “why, how, and when” it is worthwhile to move from a bad or not so favorable situationx∈Xto a better oney∈Xthat could be known or unknown. There is a number of different formulations that depend on the context, but in general the limit case of full rationality is an optimizing one, and the case of bounded rationality is a better one.The variational rationality approach examines two kinds of “change problems”: (i) adaptive choice problems, such as the problem of “selecting the context to choose from”, that is, the formation of sets to be taken in consideration; (ii) transformation problems, such as creation and destruction, invention and innovation, or problems involving evolution of institutions, dynamic interactions, and changes of different nature, as health, behavioral, organizational and cultural. It has its applications in Economics, Decision Theory, Management, Psychology, Artificial Intelligence, Philosophy, Sociology, and Applied Mathematics (e.g., Variational Analysis, Optimization and Variational Inequalities). In this variational context, our present paper shows how useful it is to set together distal and proximal goals in order to reach a distal goal. This variational approach emphasizes, each step of the process, two main variational principles: a “satisfactory, but not too much sacrificial” principle and a “worthwhile to change” principle. Since the space of situations is the Euclidian spaceX=Rn, changesu=y-xfrom a given situation x to a hopefully better situation y can be characterized by their directionsv∈Xand their deptht>0. In the context whereu=tv, these two variational principles deals with:(i)the choice, for each step, of a “satisfactory – but not too much sacrificing” direction (that is, a directional “satisfactory – but not too much sacrificing” principle);the choice, for each step, of a “worthwhile change” principle.The notions of self regulation and goal are discussed now. Self regulation considers the systematic activities or efforts that are made to direct thoughts, feelings, and actions towards the accomplishment of someone’s goals (Zimmerman, 2000). A goal is a conscious or unconscious mental representation of some future objective (to approach or to avoid), and it can be distal or proximal, abstract or concrete, vague or precise, long term or short term, extrinsic or intrinsic, high or low in commitment, more or less desirable, and more or less feasible. Related to its feasibility aspects we list importance, priority, urgency, direction, intensity, difficulty, and measurability.Self regulation has two aspects, a positive and a negative one. The positive side of it considers purposive processes where agents are engaged in goal-directed actions. It examines goal setting, goal striving and goal pursuit processes.(a)Goal setting is the mental process of moving from the consideration of distal goals to the formation of more proximal goals. Distal goals are desired future ends (visions, futures plans, etc.), either promotion aspirations (such as ideals, fantasies, dreams, wishes, hopes or challenges) or prevention aspirations (as duties and obligations). They represent desirable but quite unrealistic and vague ends (higher order goals). Proximal goals can be wants, intentions, task goals, i.e. much more feasible but less desirable intermediate ends (sub goals).Goal striving (goal implementation) examines the transition phase between setting a distal goal and reaching it.Goal pursuit (goal revision) focuses on the final phase, after reaching the given goal or failing to reach it. It examines the role of feedbacks (self evaluations of successes and failures, including the revision of causal attributions and self efficacy beliefs; see (Tolli & Schmidt, 2008)) in order to revise goals.Our paper considers only the positive aspect of self regulation. It focuses on proximal goal setting activities, examines some aspects of goal revision activities, and refuses to consider goal striving activities.The famous basketball player Michael Jordan wrote the following about goal setting in his book (Jordan & Miller, 1994), “I approach everything step by step …. I had always set short-term goals. As I look back, each one of the steps or successes led to the next one. When I got cut from the varsity team as a sophomore in high school, I learned something. I knew I never wanted to feel that bad again …. So I set a goal of becoming a starter on the varsity. That’s what I focused on all summer. When I worked on my game, that’s what I thought about. When it happened, I set another goal, a reasonable, manageable goal that I could realistically achieve if I worked hard enough …. I guess I approached it with the end in mind. I knew exactly where I wanted to go, and I focused on getting there. As I reached those goals, they built on one another. I gained a little confidence every time I came through …”.Bandura (1997) argued that people possess multiple systems of goals, hierarchically arranged from proximal goals to extreme distal goals. Goal proximity defines “how far goals are conceptualized into the future”. A goal hierarchy interconnects at least three levels of goals: peak goals (higher order goals, such as visions, dreams, fantasies, aspirations, ideals, wishes, hopes), distal goals (challenges, wants, intentions), and task goals. A subset of task goals can be subordinate to distal goals which can be subordinate to peak goals. Hence, the proximal goal distinction is relative to the interconnected network of goals. Other goal is providing the temporal context. The main point to be emphasized here is that distal goals and proximal goals are used for different and complementary functions connected to cognition, affection, motivation and conation related to goal difficulty, goal commitment and psychological distance.(i)distal goals define desired ends (enduring aspirations) that attract individuals;proximal goals regulate immediate cognitive and functions, which provide the ways to find and follow a path of step by step changes moving from the initial situation to approach the desired end or avoid an undesirable end. In this context it is important to distinguish task goals and strategies. Task goals define what is to be accomplished, and strategies define how it should to be accomplished (Wood & Bandura, 1989).In this section, we present the multicriteria problem, the first order optimality condition for it and some basic definitions.LetR+m={x∈Rm:xj⩾0,j∈I},R++m={x∈Rm:xj>0,j∈I}andI≔{1,…,m}. Forx,y∈R+m,y⪰x(orx⪯y) means thaty-x∈R+mandy≻x(orx≺y) means thaty-x∈R++m.Given a continuously differentiable vector functionF:Rn→Rm, we consider the problem of finding a Pareto optimal point of F, i.e., a pointx∗∈Rnsuch that there exists no otherx∈RnwithF(x)⪯F(x∗)andF(x)≠F(x∗). We denote this unconstrained problem as(1)minx∈RnF(x).Let F be given byF(x)≔f1(x),…,fm(x). We denote the jacobian of F byJF(x)≔∇f1(x),…,∇fm(x),x∈Rn,and the image of the jacobian of F at a pointx∈RnbyIm(JF(x))≔JF(x)v=(〈∇f1(x),v〉,…,〈∇fm(x),v〉):v∈Rn.Using the above equality, the first-order optimality condition for Problem 1 see, for instance, (Fliege & Svaiter, 2000) is stated as(2)x∈Rn,Im(JF(x))∩(-R++m)=∅.Note that form=1, we retrieve the well-known stationarity condition for constrained scalar-valued optimization.In general, (2) is necessary, but not sufficient condition for optimality. A point ofRnsatisfying (2) is called Pareto critical point.In this section, we state the inexact steepest descent methods for solving multicriteria problems by admitting relative errors in the search directions, that is, an approximation of the exact search direction is computed at each iteration, as considered in (Graña Drummond & Svaiter, 2005; Fliege & Svaiter, 2000; Fukuda & Graña Drummond, 2013).Letx∈Rnbe a point which is not Pareto critical point. Then there exists a directionv∈RnsatisfyingJF(x)v∈-R++m,that is,JF(x)v≺0. In this case, v is called a descent direction for F at x.For eachx∈Rn, we consider the following unconstrained optimization problem inRn(3)minv∈Rnmaxj∈I〈∇fj(x),v〉+(1/2)‖v‖2,I≔{1,…,m}.Lemma 4.1The following statements hold:(i)The unconstrained optimization problem in(3)has only one solution. Moreover, the vector v is the solution of the problem in(3)if and only if there existsαi⩾0,i∈I(x,v), such thatv=-∑i∈I(x,v)αi∇fi(x),∑i∈I(x,v)αi=1,whereI(x,v)≔{i∈I:〈∇fi(x),v〉=maxj∈I〈∇fj(x),v〉}.If x is Pareto critical point of F and v denotes the solution of the problem in(3), thenv=0and the optimal value associated to v is equal to zero.Ifx∈Rnis not a Pareto critical point of F and v is the solution of the problem in(3), thenv≠0andmaxj∈I〈∇fj(x),v〉+(1/2)‖v‖2<0.In particular, v is a descent direction for F at x.The proof of item i can be found in (Bento et al., 2012). For the proof of the remaining items, see, for example, (Fliege & Svaiter, 2000). □From the item i of Lemma 4.1 we note that the solution of the minimization problem (3) is of the form:v=-JF(x)tw,w=(α1,…,αm)∈R+m,‖w‖1=1(sumnorminRm),withαj=0forj∈I⧹I(x,v). In other words, ifS≔{ej∈Rm:j∈I}(set of the elements of the canonical base of Euclidean spaceRm), then w is an element of the convex hull ofS(x,v), where(4)S(x,v)≔u¯∈S:〈u¯,JF(x)v〉=maxu∈S〈u,JF(x)v〉.Note that the minimization problem (3) may be rewritten as follows:minv∈Rnmaxu∈S〈u,JF(x)v〉+(1/2)‖v‖2=minv∈Rnmaxu∈S〈JF(x)tu,v〉+(1/2)‖v‖2.In view of the previous lemma and (3), we define the steepest descent direction function for F as follows.Definition 4.1The steepest descent direction function for F is defined asRn∋x↦v(x)≔argminv∈Rnmaxj∈I∇fj(x),v+(1/2)‖v‖2∈Rn.This definition was proposed in (Fliege & Svaiter, 2000). Note that, from the item i of Lemma 4.1 it follows that the steepest descent direction for vector functions becomes the steepest descent direction whenm=1.The optimal value associated tov(x)will be denoted byα(x). Note that the functionRn∋x↦maxj∈I∇fj(x),v+(1/2)‖v‖2∈R,is strongly convex with modulus1/2and0∈∂maxj∈I〈∇fj(x),·〉+1/2‖·‖2(v(x)).So, for allv∈Rn,(5)maxj∈I∇fj(x),v+(1/2)‖v‖2-α(x)⩾1/2‖v-v(x)‖2.Lemma 4.2The steepest descent direction function for F is continuous. In particular, the functionRn∋x↦α(x)∈Ris also continuous.See (Bento et al., 2012) for the proof of the first part. The second part is a immediate consequence of the first. □Letσ∈[0,1). A vectorv∈Rnis say be aσ-approximate steepest descent direction at x for F ifmaxj∈I〈∇fj(x),v〉+1/2‖v‖2⩽(1-σ)α(x).Note that the exact steepest descent direction at x is aσ-approximate steepest descent direction for F withσ=0. As a immediate consequence of Lemma 4.1 together with last definition, it is possible to prove the following:Lemma 4.3Givenx∈Rn,(a)v=0is aσ-approximate steepest descent direction at x if, only if, x is a Pareto critical point;if x is not a Pareto critical point and v is aσ-approximate steepest descent direction at x, then v is a descent direction for F.Next lemma establishes the degree of proximity between an approximate direction v and the exact directionv(x), in terms of the optimal valueα(x).Lemma 4.4Letσ∈[0,1). Ifv∈Rnis aσ-approximate steepest descent direction at x, then‖v-v(x)‖2⩽2σ|α(x)|.The proof follows from (5) combined with Definition 4.2. See (Graña Drummond & Svaiter, 2005). □A particular class ofσ- approximate steepest descent directions for F at x is given by the directionsv∈Rnwhich are scalarization compatible, i.e., such that there existsw̃∈convSwith(6)v=-JF(x)tw̃.Note thatw̃determines a scalar functiong(x)≔〈w̃,F(x)〉whose steepest descent direction coincides with v, which justifies the name previously attributed to the direction v; see (Graña Drummond & Svaiter, 2005) for a good discussion.Next proposition establishes a sufficient condition for v, given as in (6), to be aσ-approximate steepest descent direction for F at x.Proposition 4.1Letσ∈[0,1)and v as in(6). Ifmaxj∈I〈∇fj(x),v〉⩽-(1-σ/2)‖v‖2,or equivalently,(7)maxu∈S〈JF(x)tu,v〉⩽-(1-σ/2)‖v‖2,then v is aσ-approximate steepest descent direction for F at x.See (Graña Drummond & Svaiter, 2005). □From Remark 4.1 we note that, for eachx∈Rn, the steepest descent direction for F atx,v(x), is scalarization compatible. Next lemma tell us thatv(x)satisfies the sufficient condition of the last proposition withσ=0and that such condition is natural.Lemma 4.5The following statements hold:(i)α(x)=-(1/2)‖v(x)‖2;maxu∈S〈JF(x)tu,v(x)〉=-‖v(x)‖2.In order to prove item i note that(8)α(x)=maxu∈S〈JF(x)tu,v(x)〉+(1/2)‖v(x)‖2.Moreover, from Remark 4.1, we have(9)v(x)=-JF(x)tw,w∈convS(v(x)),S(v(x))≔S(x,v(x)),where convS(v(x))denotes the convex hull ofS(v(x)). So, combining (8) and (9) with the definition ofS(v(x)), we getα(x)=〈JF(x)tu¯,-JF(x)tw〉+(1/2)‖JF(x)tw‖2,u¯∈S(v(x)).Hence,α(x)=〈JF(x)tw,-JF(x)tw〉+(1/2)‖JF(x)tw‖2,from where it follows item i. Item ii is an immediate consequence of item i combined with (8).□The inexact steepest descent method with the Armijo’s rule for solving the unconstrained optimization problem (1) is as follows:Method 4.1Inexact steepest descent method with Armijo’s ruleInitialization. Takeβ∈(0,1)andx0∈Rn. Setk=0.Stop criterion. Ifxkis a Pareto critical point STOP. Otherwise.Iterative Step. Compute aσ-approximate steepest descent directionvkfor F atxkand the steplengthtk∈]0,1]as follows:(10)tk≔max2-j:j∈N,Fxk+2-jvk⪯F(xk)+β2-jJF(xk)vk.Set(11)xk+1≔xk+tkvk,and GOTO Stop criterion.The previous method was proposed by (Fliege & Svaiter, 2000) and becomes the classical steepest descent method whenm=1. Other variants of Method 4.1 can be found in (Fukuda & Graña Drummond, 2013; Graña Drummond & Svaiter, 2005).Next proposition ensures that the sequence generated by the Method 4.1 is well-defined.Proposition 4.2The sequence{xk}generated by the steepest descent method with Armijo’s rule is well-defined.The proof follows from item ii of Lemma 4.3 combined with the fact that F is continuously differentiable. See (Fliege & Svaiter, 2000) for more details. □In this section, we present a partial convergence result without any additional assumption on F besides its continuous differentiability. In the sequel, assuming quasi-convexity of F and following the ideas of (Bento et al., 2012; Graña Drummond & Svaiter, 2005), we extend the full convergence result presented in (Graña Drummond & Svaiter, 2005) for quasi-convex multicriteria optimization. It can be observed that, if Method 4.1 terminates after a finite number of iterations, then it terminates at a Pareto critical point. From now on, we will assume that{xk},{vk}and{tk}are infinite sequences generated by Method 4.1.The following theorem tell us that if F is continuously differentiable, then the sequence of the functional values of the sequence{xk},{F(xk)}, is monotonously decreasing and each accumulation point of{xk}, if any, is a Pareto critical point. The proof of next theorem can be found in (Graña Drummond & Svaiter, 2005).Theorem 5.1The following statements hold:(i){F(xk)}is decreasing.If{xk}has accumulation point, then{tk2‖vk‖2}is a summable sequence andlimk→+∞tk‖vk‖2=0.Each accumulation point of the sequence{xk}, if any, is a Pareto critical point.If the sequence{xk}begins in a bounded level set, for example, ifLF(F(p0))≔{x∈Rn:F(x)⪯F(p0)},is a bounded set, then, since F is a continuous function,LF(F(p0))is a compact set. So, item i of Theorem 5.1 implies that{xk}⊂LF(F(p0))and consequently{xk}is bounded. In particular,{xk}has at least one accumulation point.In this section, under the assumption of quasi-convexity on F, full convergence of the steepest descent method is obtained.Definition 5.1LetH:Rn→Rmbe a vectorial function.(i)H is called convex iff for everyx,y∈Rn, the following holds:H((1-t)x+ty)⪯(1-t)H(x)+tH(y),t∈[0,1];H is called quasi-convex iff for everyx,y∈Rn, the following holds:H((1-t)x+ty)⪯max{H(x),H(y)},t∈[0,1],where the maximum is considered coordinate by coordinate;H is called pseudo-convex iff H is differentiable and, for eachx,y∈Rn, the following holds:JH(x)(y-x)⊀0⇒H(y)⊀H(x).For the first two definitions above, see Definition6.2and Corollary6.6of (Luc, 1989, pp. 29 & 31), respectively. For the third definition see Definition9.2.3of (Goh & Yang, 2002, p. 274). Note that H is convex (resp. quasi-convex) iff, H is componentwise convex (resp. quasi-convex). On the other hand, if H is componentwise pseudo-convex, then H is pseudo-convex, although the reciprocal be naturally false; see Theorem9.2.3of (Goh & Yang, 2002, p. 274) and Remark 5.3. It is immediate from the above definitions that if H is convex then it is quasi-convex (the reciprocal is clearly false). If H is differentiable, convexity of H implies that for everyx,y∈Rn,(12)JH(x)(y-x)⪯H(y)-H(x),from which we may conclude that H is pseudo-convex. It is easy to obtain an example showing that the reciprocal is false.Next proposition provides a characterization for differentiable quasi-convex functions.Proposition 5.1LetH:Rn→Rmbe a differentiable function. Then, H is a quasi-convex function if, only if, for everyx,y∈Rn, it holdsH(y)≺H(x)⇒JH(x)(y-x)⪯0.Let us assume that, for every pair of pointsx,y∈Rn, it holds(13)H(y)≺H(x)⇒JH(x)(x-y)⪯0.Takex̃,ỹ∈Rnand assume that it is true thatH(ỹ)≺H((1-t)x̃+tỹ),t∈[0,1).Using (13) withy=ỹandx=(1-t)x̃+tỹ, we obtain(1-t)JH((1-t)x̃+tỹ)(x̃-ỹ)⪯0,which impliesddthj((1-t)x̃+tỹ)=〈∇hj((1-t)x̃+tỹ),ỹ-x̃〉⩽0,j∈I,whereh1,…,hmrepresent the coordinate functions of H. But this implies thathj((1-t)x̃+tỹ)⩽hj(x̃),j∈I,and, hence, thatH((1-t)x̃+tỹ)⪯H(p̃)=max{H(x̃),H(ỹ)},which proves the first part of the proposition. The proof of the second part follows immediately from the definition of quasi-convexity combined with differentiability of H; see (Bento et al., 2012) for more details. □From the previous proposition follows that pseudo-convex functions are quasi-convex. The reciprocal is naturally false. Next proposition provides a sufficient condition for a differentiable quasi-convex function to be pseudo-convex.Definition 5.2A pointx∗∈Rnis a weak Pareto optimal point of F iff there is nox∈RnwithF(x)≺F(x∗).LetH:Rn→Rmbe a differentiable quasi-convex function. If each Pareto critical point of H is a weak Pareto optimal point, then H is a pseudo-convex function.Takey∈Rn. Since that, by hypothesis, each Pareto critical point is an weak Pareto optimal, if y is Pareto critical there is nothing to be done. Let us suppose that y is not a Pareto critical point. Then, there existsv∈Rnsuch that(14)JH(y)v≺0.Let us assume, by contradiction, that H is not pseudo-convex. In this case, there existsx̃∈Rnsuch thatH(x̃)≺H(y), with(15)JH(y)(x̃-y)⊀0.From (14) and (15), it follows that(16)JH(y)(x̃-y)-βJH(y)v⪯0,β>0.Now, sinceH(x̃)≺H(y), from the continuity of H there existsδ>0such thatH(z)≺H(y)for allz∈B(x̃,δ)(ball with center inx̃and rayδ). In particular,H(x̃-(δ/2)(v/‖v‖))≺H(y)and, because H is quasi-convex, we obtainJH(y)x̃-(δ/2)(v/‖v‖)-y⪯0.But this tell us that withβ=δ/(2‖v‖), we haveJH(y)(x̃-y)-βJH(y)v⪯0,which contradicts (16), and the resulted is proved. □Consider the following vectorial functionH:R→R2given byH(t)=(t,-t3/3). Note that H is not componentwise pseudo-convex becauseh2(t)≔-t3/3is not pseudo-convex. However, since H is quasi-convex and each Pareto critical point of H is a weak Pareto optimal point for H, it follows from last proposition that H is pseudo-convex.We know that criticality is a necessary condition, even though not sufficient, for optimality. In (Bento et al., 2012) the authors proved that, under convexity of the vectorial function F, criticality is equivalent to the weak optimality. Next we prove that the equivalence still happens if F is just pseudo-convex.Proposition 5.3LetH:Rn→Rmbe a pseudo-convex function. Then,x∈Rnis a Pareto critical point of H, i.e.,Im(∇H(x))∩(-R++m)=∅,iff x is a weak Pareto optimal point of H.Let us suppose that x is a Pareto critical point of H. Assume by contradiction that x be not a weak Pareto optimal point of H, i.e., that there existsx̃∈Rnsuch that(17)H(x̃)≺H(x).As H is pseudo-convex, then (17) implies thatJH(x)(x̃-x)≺0.But this contradicts the fact that x is a Pareto critical point of H, and the first part is therefore concluded. The second part is a simple consequence of the fact that F is differentiable with the definitions of Pareto critical point and weak Pareto optimal point. For more details, see (Bento et al., 2012). □A sequence{zk}⊂Mis quasi-Fejér convergent to a non-empty set U iff, for allz∈U, there exists a sequence{∊k}⊂R+such that∑k=0+∞∊k<+∞,‖zk+1-z‖2⩽‖zk-z‖2+∊k,k=0,1,….In next lemma we recall the theorem known as quasi-Fejér convergence.Lemma 5.1LetU⊂Rnbe a non-empty set and{zk}⊂Rna quasi-Fejér convergent sequence. Then,{zk}is bounded. Moreover, if an accumulation pointz¯of{zk}belongs to U, then the whole sequence{zk}converges toz¯as k goes to+∞.See (Burachik et al., 1995). □Consider the following set(18)U≔{x∈Rn:F(x)⪯F(xk),k=0,1,…}.In general, the above set is an empty set. To guarantee that U is non-empty, an additional assumption on the sequence{xk}is needed. In next remark we give such condition.Remark 5.4If the sequence{xk}has an accumulation point, then U is a non-empty set. Indeed, letx¯be an accumulation point of the sequence{xk}. Then, there exists a subsequence{xkj}of{xk}which converges tox¯. Since F is continuous{F(xk)}hasF(x¯)as an accumulation point. Hence, using{F(xk)}as a decreasing sequence (see item i of Theorem 5.1), the usual arguments easily show that the whole sequence{F(xk)}converges toF(x¯)and the following relation holdsF(x¯)⪯F(xk),k=0,1,…,which implies thatx¯∈U, i.e.,U≠∅.Eachvkof the sequence{vk}is a scalarization compatible, i.e., exists a sequence{wk}⊂convSsuch thatIn next lemma we present the main result of this section. It is fundamental to the proof of the global convergence result of the sequence{xk}.Lemma 5.2Suppose that F is quasi-convex and U, defined in(18), is a non-empty set. Then, for allx̃∈U, the following inequality is true:‖xk+1-x̃‖2⩽‖xk-x̃‖2+tk2‖vk‖2,k=0,1….Consider the hingexkx̃‾,xkxk+1‾,αk, wherexkx̃‾(resp.xkxk+1‾) is the segment joiningxktox̃(resp.xktoxk+1) andαk=∠(x̃-xk,vk),k∈N. By the law of cosines, we have(19)‖xk+1-x̃‖2=‖xk-x̃‖2+tk2‖vk‖2-2tk‖xk-x̃‖‖vk‖cosαk,k=0,1,….Sincecos(π-αk)=-cosαkand〈-vk,x̃-xk〉=‖vk‖‖xk-x̃‖cos(π-αk), equality (19) becomes(20)‖xk+1-x̃‖2=‖xk-x̃‖2+tk2‖vk‖2+2tk〈-vk,x̃-xk〉,k=0,1,….On the other hand, from Assumption 1, there existswk∈convSsuch thatvk=-JF(xk)twk,k=0,1,….Hence, the equality (20) yields(21)‖xk+1-x̃‖2=‖xk-x̃‖2+tk2‖vk‖2+2tk〈wk,JF(xk)(x̃-xk)〉,k=0,1,….Since F is quasi-convex andx̃∈U, from Proposition 5.1 withH=F,x=xkandy=x̃, we haveJF(xk)(x̃-xk)⪯0,k=0,1,….So, becausewk∈convS, we get(22)〈wk,JF(xk)(x̃-xk)〉⩽0,k=0,1,….Therefore, by combining (21) with (22), the lemma proceeds.If F is quasi-convex and U, defined in(18), is a non-empty set, then the sequence{xk}is quasi-Fejér convergent to U.The resulted follows from item ii of Theorem 5.1 and Lemma 5.2 combined with Definition 5.3. □Suppose that F is quasi-convex, and U, as defined in(18), is a non-empty set. Then, the sequence{xk}converges to a Pareto critical point of F.From Proposition 5.4,{xk}is quasi-Fejér convergent to U. Thus, Lemma 5.1 guarantees that{xk}is bounded and, therefore, has an accumulation pointx¯∈Rn. Then, from Remark 5.4, we conclude thatx¯∈Uand that the whole sequence{xk}converges tox¯as k goes to+∞(see Lemma 5.1). The conclusion of the proof is a consequence of item iii of Theorem 5.1. □If F is pseudo-convex and U, as defined in(18), is a non-empty set, then the sequence{xk}converges to a weak Pareto optimal point of F.Since F is pseudo-convex, and in particular quasi-convex, the corollary is a consequence of the previous theorem and Proposition 5.3. □This section offers a “distal-proximal” model of self regulation in Psychology, using a recent variational rationality approach (Soubeyran, 2009, 2010, 2012a, 2012b) which models behaviors as an approaching or avoidance process, a course pursuit between “desired enough” ends and “feasible enough” means.Variational rationality (Soubeyran, 2009, 2010, 2012a, 2012b) is a theory about an endless unsatisfied man, who, refuses to satisfy some of his unsatisfied needs, and at the same time aspires to accomplish some others. We can summarize some of the main points of this variational approach of the self regulation problem, based on cognition (knowledge), motivation (desires) and affection (feelings and emotions) as follows:(i)the agent, focusing his attention on the unsatisfied needs he has chosen to satisfy, considers desired ends. He forms aspirations (distal goals). Setting aspirations goals is a way to know what he really wants among all his wishes, without considering if they are realistic or not;then, the agent starts to consider feasible means (defined as the means he must find, create, build, gather and use);given the difficulties for gathering such feasible means the agent chooses to partially satisfy his aspirations.Next, the agent self regulates all his goal-oriented activities:goal setting: setting proximal goals is a way for him to assess the difficulties in order to better know what his real possibilities are. This allows him to make a balance between “desired enough” ends and “feasible enough” means;goal striving: it represents the path (way of doing, strategy) the agent chooses to follow and the obstacles he must overcome to attain his successive proximal goals and partially satisfies them;goal pursuit: it is the revision of the goals, using the feedback that comes from successes and failures.This variational approach is progressive (adaptive). The step by step joint formation of distal (global) and proximal (local) goals and related actions is a process that includes a lot of interactions, tatonnements and adjustments that are driven by inexact perceptions, evaluations and judgments.Among several variational principles, three of them are worth mentioning in the present paper:–the “satisficing with not too much sacrificing” principe and the “worthwhile to change” principle (Soubeyran, 2009, 2010);the “tension reduction–tension production” principle (Soubeyran, 2012a, 2012b).In our context of inexact multicriteria proximal algorithms, we are modeling the main motivational concepts of the variational Soubeyran’s approach (Soubeyran, 2009, 2010). They include:(a)The map of unsatisfied needs (the needs system). An agent has two ways to perceive, judge and estimate a situation, either in terms of unsatisfaction or in terms of satisfaction. Usually an agent deals with a lot of unsatisfied needs which depend of his present situationx∈X. LetI=1,2,…,mbe the list of different potential needs. The perceived unsatisfied needs functions are0⩽ni(x)<+∞, which represent the strength of each perceived needi∈Ifor each situationx∈X. LetN:X→Rm, given byN(x)=(n1(x),n2(x),…ni(x),…,nm(x)),be the map of unsatisfied needs in this situation. These needs can be rather vague and abstract. Hull (1935) and Murray (1938) give an extensive list of different needs.The map of aspiration gaps. As soon as the agent chooses not to renounce to satisfaction of the need system, all these unsatisfied needs become, in this present situation, aspiration gapsai(x),i∈I, although in general, the perceived aspiration gapsai(x)⩾0,i∈Iare lower than perceived unsatisfied needs:0⩽ai(x)⩽ni(x),i∈Ibecause agents usually aspire to fulfill no more than their unsatisfied needs.The map of aspiration levels (desirable ends, or the distal goal system). Let us denote byg‾i(x),i∈I, the aspiration levels forx∈X. They still represent vague, abstract, and non-committed higher-order goals (visions, ideals, aspirations, fantasies, dreams, wishes, hopes, wants, and desires). These aspirations levels represent desirable (but perhaps unrealistic) ends. Lewin (1951) defines aspiration levels as desirable ends, with some being unrealistic in a near future, and others not.The map of satisfaction levels (the experienced utility system). Most of the time unsatisfied needs are partially satisfied. LetG:X→Rm,G(x)=(g1(x),g2(x),..,gi(x),..,gm(x)), be the map of present satisfaction levels (or outcomes) in the present situation x, wheregi(x)⩽g‾i(x),i∈I, i.e., the levels at which all needs are partially satisfied.The map of discrepancies (the drive system). The differences between aspiration levels and satisfaction levels define more precisely aspiration gapsai(x)=g‾i(x)-gi(x)⩾0,i∈Iwhich are non-negative. We will assume in this paper that aspirations gaps are equals to unsatisfied needs, i.e., they represent the discrepanciesfi(x)=ni(x)=ai(x)=g‾i(x)-gi(x)⩾0,i∈I,x∈X,We consider here satisfaction levelsgi(x),i∈I, instead of discrepancies. Moreover, for simplification, we consider all aspiration levels as constant, i.e.,g‾i(x)=g‾i<+∞,i∈I,x∈X. Then,fi(x)=g‾i-gi(x)⩾0,andgx(v)=-fx(v),i∈I,x∈X.The main problem is to know how the agent sets all these levels, step by step (progressively).A “goal system” (Kruglanski et al., 2002) comprises: (i) a cognitive network of mental representations of goals and means which are structurally interconnected by several somewhat strong cognitive links, (ii) in the short run, a subset of limited available resources (physiological, material, mental, social means), because means are scarce and difficult to obtain, (iii) an allocation process where goals compete for the use of these limited available resources, and (iv) a motivational process of goal setting, goal commitment, goal striving and goal pursuit (using affective feedback engendered in response to success and failure outcomes, goal revision including persistence of pursuit, means substitution and the management of goal-conflict). In our specific case the goal system is the satisfaction mapX∋x↦G(x)∈Rm.Available means are identified to the situationx∈X. These means can represent actions, resources and capabilities “to be able to do” them see (Soubeyran, 2009, 2010). The fact that outcomes compete for restricted means can be modelized as follows: we decompose the given x into the sumx=x1+x2+⋯+xi+⋯+xkwherexi∈Xis the bundle of means allocated to goal i andgi=gi(xi)is the level of satisfaction of this objective.Starting from the situationx∈X, letv∈Xbe a direction of change,t>0be the intensity of change,u=y-x=tv be the change andGx(v)=JG(x)vbe the vector of marginal satisfaction levels of change. The related different needs may have different degree of importance and urgency and, in each step, the agent must weight each of them to define priorities. This task (solving trade off) is not easy and must be done progressively. Definegx:Rn→R, given bygx(v)≔mini∈I〈∇gi(x),v〉=mini∈I(JG(x)v)i,i∈I,i∈I,the marginal satisfaction function. It represents the minimum of the different marginal satisfaction levels(JG(x)v)i,i∈I. The consideration of this marginal satisfaction function avoids to choose weights for each marginal satisfaction level and to have to adapt them each step.Let situations likex∈Xrepresent means which generate the vector of satisfaction levelsG(x). The agent, in situationx∈X, considers (explores) new situationsy=x+tv,t>0,v∈X. This global exploration process is costly. Let us define the local consideration costs (search costs, exploration costs)cx(v)=(1/2)v2⩾0. The choice of a quadratic function models the case where local exploration is not too costly: consideration costscx(v)⩾0are large “in the large” and small “in the small”. Notice that, while the agent considers feasible directions of change over the whole state space, he takes care of consideration costs (a local aspect).In general (Soubeyran, 2009, 2010) the proximal payoff balances desired ends and feasible means. In this paper the proximal payofflx(v)=gx(v)-cx(v)balances the marginal satisfaction levels and the costs to consider them (local exploration costs). Sincelx(v)⩾0⇔gx(v)⩾cx(v),we will say that it is “worthwhile to explore in direction v, starting from x”, because the marginal satisfaction levelgx(v)in this direction is higher than the costscx(v)to be able to consider them. For eachx∈Xconsider the local search proximal problem: find a direction of changev(x)∈Xsuch thatlx(v(x))=suplx(v),v∈X. Letl‾x=suplx(v),v∈Xbe the optimal proximal payoff function at x andv(x)=argmaxlx(v),v∈X∈Xbe the unique optimal direction of change, starting from x. Then,l‾x=lx(v(x)). From Lemma 4.1 and Lemma 4.2, it follows:(1)Ifx∈Xis Pareto critical, thenv(x)=0∈Xandl‾x=0.Ifx∈Xis not Pareto critical, thenl‾x>0andgx(v)⩾gx(v(x))>cx(v(x)),i∈I.The mappingsX∋x↦v(x)∈XandX∋x↦l‾x∈Rare continuous.Starting from x and using variational rationality concepts, the optimal direction of changev(x)defines the unique direction of aspiration and the optimal proximal payoffl‾x=lx(v(x))defines the proximal aspiration level (net of consideration costs). From Lemmas 4.1 and 4.2, we get:(1)Ifx∈Xis Pareto critical, then the direction of aspiration and the proximal aspiration level are zero.Ifx∈Xis not Pareto critical, then, their is a strictly positive direction of aspiration and the proximal aspiration level is strictly positive.Direction of aspirations and proximal aspiration levels are continuous.Ifx∈Xis not Pareto critical,(i)set a local (net) satisficing level of changel̃x=σl‾x,0<σ⩽1which is positive and strictly lower than the local aspiration level of changel‾x>0. As a “variational rationality” concept (Soubeyran, 2009, 2010), this local satisficing level of changel̃xis situational dependent (it changes withx∈X). Notice that (Simon, 1955), the father of the satisficing concept, defines an invariant satisficing level without any reference to an aspiration level of changel‾x.Then, the agent will try to find a directionv§∈Xsuch thatlx(v§)⩾l̃x. This means that the satisficing direction of changev§“improves enough” with respect to the aspiration direction of changev(x), including exploration costs. In variational terms such a direction not only satisfices (Simon, 1955) but even more, it balances satisficing (“improving enough”) marginal satisfactions to changenx(v)with some sacrifices to changecx(v), because the net satisfaction levellx(v§)is higher than the (net) satisficing level. This is a local version of the variational “sacrificing with not too much sacrificing” principle (Soubeyran, 2009, 2010). This is equivalent to say that the satisficing direction of changev§∈Xis an inexact solution of the local search proximal problem. In this context proximal goals are local aspiration levels of change and satisficing levels of change.In terms of variational rationality, the (Fliege & Svaiter, 2000) steepest descent method appears to be an “aspiration driven local search proximal algorithm”. In situationx∈X, the distal goal is the aspiration level of changel‾xand the proximal goal is the satisficing levell̃x.It is true that inertia matters, since it is costly to be able to change from some situationx∈Xto a new improving situationy∈X. As variational concepts, there are two kinds of “costs to be able to change” (Soubeyran, 2009, 2010): (i) consideration costs (perception, exploration, search and evaluation costs, etc.), (ii) capability costs to changeC(x,y), i.e., the costs to be able to change (to be able to stop to use old means, to be able to use again old means, and to be able to imagine, find, build, gather, and learn how to use new means). Means can be capabilities (competences, skills), ingredients and resources. In the present paper consideration costs arecx(v)=(1/2)v2and capability costs to change areC(x,y)=KtJG(x)(y-x)=tJG(x)(y-x), witht>0. This formulation, specific to the present paper, means that costs to change from x to y increase with the difficulty to change, modelized here as the vector of gradientsΛ(x,y)=tJG(x)(y-x), including the step length of changet>0. Then, the second variational principle tells us that it is “worthwhile to change”, from x to y, ifA(x,y)=G(y)-G(x)(advantages to change) are higher than some proportion,β>0, of costs to change, i.e.G(y)-G(x)⩾βC(x,y)whereβ>0is a rate of tolerance which calibrates how the change (transition)x↷yis acceptable. More generally (Soubeyran, 2009, 2010) it is “worthwhile to change” from x to y if motivations to changeM(x,y)=UA(x,y)are higher than some proportion,β>0, of resistances to changeR(x,y)=ΛC(x,y)whereU(·)andΛ(·)are the experienced utility and desutility of advantages and costs to change.The variational concept of “worthwhile changes” is related to the famous (Lindblom, 1959) “muddling through” economizing principle where agents make small steps (incremental changes, choosing the step size in our context) and successive limited comparisons (balancing pro and cons).Remark 6.2Our paper considers quasi-convex (or quasi-concave) payoffs. In terms of variational rationality, this case is very interesting, because it allows large flat portions that can be very costly to explore (quadratic exploration costs are “large in the large”). Hence, in this case, convergence is a very nice result.The goal of this paper was to provide conditions of convergence for a path of change towards a Pareto optimal in a multicriteria optimization setting. The variational concept of a behavioral trap (Soubeyran, 2009, 2010) appears in this context at the local level of the consideration (say exploration) process. More precisely, we will say thatx∗∈Xis a local exploration trap ifl‾x∗=0⇔lx∗(v)=gx∗(v)-cx∗(v)⩽0,v∈X.This means that it is not worthwhile to explore it locally, because, whatever the direction of changev∈X, marginal advantages to changenx∗(v)are lower than local exploration costs to changecx∗(v). Lemma 4.1 shows that ifx∗∈Xis Pareto critical, thenx∗∈Xis a local exploration trap.We proved the full convergence of each sequence generated by the inexact steepest descent method to a Pareto critical point associated to quasi-convex multicriteria optimization problems. We also showed a striking result, namely, the strong connection of such an inexact proximal algorithm with the self regulation problem in Psychology. Further researches can be made in this direction.

@&#CONCLUSIONS@&#
