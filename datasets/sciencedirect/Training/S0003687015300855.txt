@&#MAIN-TITLE@&#
A literature review on the levels of automation during the years. What are the different taxonomies that have been proposed?

@&#HIGHLIGHTS@&#
We present a literature review of the evolution of the levels of autonomy.We gather and compare the literature on taxonomies on levels of automation.We present the differences between the proposed taxonomies.We survey the term adaptive automation, a new trend in the literature on autonomy.

@&#KEYPHRASES@&#
Levels of autonomy,Autonomy/automation,Taxonomies,Adaptive automation,

@&#ABSTRACT@&#
In this paper we present a literature review of the evolution of the levels of autonomy from the end of the 1950s up until now. The motivation of this study was primarily to gather and to compare the literature that exists, on taxonomies on levels of automation. Technical developments within both computer hardware and software have made it possible to introduce autonomy into virtually all aspects of human-machine systems. The current study, is focusing on how different authors treat the problem of different levels of automation. The outcome of this study is to present the differences between the proposed levels of automation and the various taxonomies, giving the potential users a number of choices in order to decide which taxonomy satisfies their needs better. In addition, this paper surveys deals with the term adaptive automation, which seems to be a new trend in the literature on autonomy.

@&#INTRODUCTION@&#
Looking through history, people have confronted the introduction of automation with scepticism especially in the beginning. The first major demonstration of concern for the potentially negative social impacts of labour-saving machinery was the Luddite movement in the early 1800s (Brain, 1998). During that time English workmen attempted to prevent the use of knitting machinery in their industry by destroying it. Later on, in the 1950s Diebold coined the term “automation” (Diebold, 1952). To his disappointment he discovered soon after that the term had already been used by an executive of the Ford Motor Company. Diebold, however, still stated that “automation is a new word denoting both automatic operation and the process of making things automatic” (Diebold, 1952).Since then, automation has made a lasting entry into the world of manual labour, and as a result many functions and operations previously performed by humans have been taken over by machines. This change has come with the benefit of replacing lots of manual labour, and has resulted in an increase of productivity in terms of energy and materials saving, improvement of quality, accuracy and precision. What has been really achieved with automation, however, is the shift of the role of the operator from manual to supervisory control (Sheridan and Verplank, 1978). As a result, instead of performing tasks like activating manual switches and following operation procedures, they perform the intellectual or cognitive tasks of diagnosis, planning and problem solving (Liu and Hwang, 2000). Automation systems can be designed and employed in a way to secure a best-fit for the capabilities, advantages and disadvantages of both human and machine.All this human-machine interaction and cooperation can be expressed by various Levels of Automation (LOA). Each of these levels specify a different degree to which a task is automated. This implies that automation is not all or none, but can vary across a continuum of intermediate levels, between fully manual performance and fully autonomous conditions at the two extremes. Several different LOA have been proposed by different researchers, resulting in numerous taxonomies describing the interaction between humans and machines.The scope of this paper is to gather the proposed approaches on taxonomies of LOA in an attempt to bring this vast literature together. In addition, the authors try to summarize, categorize and compare the different approaches.When we started to dig into the literature concerning the LOA, the authors came across with the two words “autonomy” and “automation”. In Section 2, we tried to find (if any) similarities/differences between them and clarify the way they should be used. Furthermore, subsection 3.1 deals with the different LOA proposed by different researchers and subsection 3.2 presents a comparison and summary of them. In Section 4, we present the terms of adaptive, adjustable and adaptable automation. Finally, in Section 5 the conclusions are drawn. The tables describing analytically the taxonomies proposed by different authors are presented in the Appendix of the document, in an attempt to keep the core of the paper shorter and simpler for the reader to follow. We make some short descriptions of the proposed taxonomies in Section 3.1 and in addition the full taxonomy is presented in the Appendix.In this section, the interpretation of the words autonomy and automation is discussed. Our scope is to investigate if there exists any difference between them. In fact knowing how these two terms are used is a necessary precondition for analysing the literature on this subject.Historically the word autonomy appears first while the word autonomy is launched later on (http://www.oxforddictiona). Many authors do understand the difference between these two words and several amongst them tend to use them interchangeably. On the other hand, there are some studies in which the two words are used as distinct terms ((Clough, 2002a), (Clough, 2002b)). We have made an extensive search into what exists in the literature and how different authors treat both words. Let us introduce first the etymologies of the two words as they exist in the dictionaries and in addition an extended study on how authors tend to use them is going to be presented.The word “autonomy” has been launched in the early 17th century, originating from the greek word “autonomia/autonomous” which means “auto = self” and “nomos = law”, independent and self-governing ((http://dictionary.cambrid), (http://dictionary.referen)). The word by itself is a concept found in different kinds of sciences, like engineering, philosophy, biology and medicine. As far as the engineering etymology is concerned, the word autonomy is used in order to describe the ability of an engineering system to make its own decisions about its actions while performing different tasks, without the need for the involvement of an exogenous system or operator (Albus et al., 1998). Since each engineering system has a certain degree of autonomy associated with it, autonomy means independence from an outside supervisor, which may be another engineering system or a human. As a result, autonomous systems can make a choice free from outside influence since they have some perceivable notion of “free will”, and autonomy is the ability of the system to change its initially programmed way of action, to the degree that it has been decided a priori by the designer of the system.The word “automation” was introduced in the mid of the 19th century and is inspired by the earlier word automatic ((http://dictionary.cambrid), (http://dictionary.referen)). Automation includes the execution by a machine agent of a function that was previously carried out by a human ((Parasuraman, 2000), (Parasuraman and Riley, 1997)). This can concern different control systems for operating equipment in numerous applications such as chemical and power plants, aircraft and air traffic control, automobiles, ships, unmanned vehicles and robots, heating and air conditioning in buildings, business systems, medical devices, home appliances, military systems and stand-alone computers are used in order to name only a few examples. However, the concept of automation has changed through time. It can e.g. mean a simple reallocation of a function from human to machine which is complete and permanent. In that case, the function will tend to be seen simply as machine operation not as automation (Parasuraman and Riley, 1997). To summarize, the word automation refers to a system that will do exactly what it is programmed by the programmer to do without having any choice or possibility to act in any different way dependent on the situation at hand. Its actions are predefined from the beginning and it has no ability to change them into the future.It seems that at least as far as the etymologies are concerned the two words have two different meanings ((http://dictionary.cambrid), (http://dictionary.referen)). The question that arises is: “Do these terminologies follow the scientific literature as well?” The answer to that question is not easy. It seems that in engineering terms the authors tend to use them interchangeably.In Table 1we have summarized scientific papers dealing with autonomy and/or automation. This summary indicates that most of the authors tend to use the word automation over the word autonomy even when referring to a system that is “free to make choices”. One conjecture is that many authors are more familiar with the word automation and hence tend to use that in favor of the word autonomy. This is done even when referring to what other authors call the Levels of Autonomy ((Johnson et al., 2009), (Parasuraman, 2005)), thereby denoting what seems to be the more or less identical term Levels of Automation ((Parasuraman, 2000), (Endsley and Kaber, 1999), (Fereidunian et al., 2007a), (Hancock, 2013), (Hancock et al., 2013), (Miller and Parasuraman, 2007), (Onnasch et al., 2014), (Parasuraman et al., 2000)). We have no indication that there is a difference one word has been used over the other.All the previous observations lead to the conclusion that there is no constant way of using both words and that there is quite a lot of flexibility on how they can be used. As far as this paper is concerned we decided to treat the two words as distinct, being constant to the meanings described in dictionaries - thereby using the term “autonomous system” when we refer to a system that “has the freedom to make choices”. Although we try to be consistent with the usage of the words autonomy and automation, quite often we need to reproduce them both, in the way the authors use them since we think it is inappropriate to change their terminology. So, when presenting a taxonomy, or reproducing some points from another study we do that without criticising or distinguishing the terms, we just present them the way the authors do staying consistent to their nomenclature.This section is the core of the study. Its scope is to present the different approaches on LOA as proposed in the literature so far. In the beginning of the section we present analytically the approaches that are included in the paper, and in the sequel we try to summarize them in a common table (see Fig. 1) trying to make some sort of categorization. The scope of this table is to give the readers the opportunity, to find any possible differences and similarities between them. The sumarization done is trying to give an answer to the following key questions:1.Why do different authors use a differing number of LOA?What are the differences and similarities between the different LOA of different authors?Can different taxonomies be combined in a proper way so that new taxonomies can evolve?Do there exist more or less used LOA? What does this mean in practice? Which are these levels?Which is (if it exists) the “best taxonomy” of LOA proposed? How can a reader decide which is the best taxonomy for his/her needs?This subsection includes most of the previous presented approaches on LOA that we had access to in the well known article databases. No novel approach has been excluded from the study at least deliberately, but we decided not to include similar approaches by the same authors unless there was some kind of differentiation of his/her previously proposed work.This study begins with an approach that seems to be one of the most widely cited and used taxonomies amongst the ones that have been presented so far. This is the approach proposed by Sheridan and Verplank (1978) and Sheridan (1992). Their analytic approach is one of the oldest taxonomies that can be found in the literature and has been the basis for many others presented later on. Sheridan and Verplank identified six functions that either a human operator or a computer could maintain during teleoperation control. They included commands like gets, selects, starts, requests, approves and tells. They offer a detailed explanation on how the human operator and the computer are supposed to cooperate with each other and how they can change roles under different LOA. In that sense, they actually introduce 10 LOA, proposing a variety of choices regarding the cooperation of operator and machine varying from fully manual to fully computer automated, giving an analytical description of who can be in control in every stage. The levels they propose are presented and analysed in Table 5 in the Appendix.A decade later, in 1987, Endsley (1987) presented a more compact taxonomy consisting of a model of 4 LOA for an advanced cockpit developed in the context of the use of expert systems to supplement human decision making for automated systems control (the human operator is the pilot in this approach). She identified 4 functions during which the human operator or the machine had the possibility to be in charge. These functions included suggest, concur, veto and act. She offered her 4 different LOA, which are described in detail in Table 6 in the Appendix. It seems that her taxonomy has different boundaries than the one by Sheridan and Verplank (1978) and Sheridan (1992). The main differences between the approaches are 1) the fact that she skips the fully manual level and 2) she gives less in-between options as far as the intermediate levels of automation are concerned. In that sense her approach eliminates or amplifies the power of the system over the human. There exists a variation that extends from the possibility of the human acting upon system recommendation to being completely excluded from the loop by having the system deciding and acting on an autonomous way. Central to this study is the fact that any possible considerations of pilot workloads, situation awareness, performance, and acceptance are key to the successful design and implementation of expert systems which will truly enhance the pilot in the performance of his tasks.Endsley's approach is followed by Ntuen and Park (1988) and Ntuen and Park (1996), who progressed her approach by just adding a first level of fully manual teleoperation. Their final approach consistes of 5 levels, 4 of which are identical with Endsley's.In the following year 1989, Riley (1989) published a novel proposal different in layout from the approaches that have been presented up to that time. This means that the authors approached the taxonomy problem in a completely different way. They did not only care about the level of autonomy that they were going to use, but they also introduced the idea of the system's intelligence. In that sense the taxonomy is presented as a 2-D matrix the rows of which corresponded to the LOA while the columns to the Levels of Intelligence. Each combination of a level of intelligence and a level of autonomy is referred to as an “automation state”, and each state corresponds to a unique, predefined form. The taxonomy is presented in Tables 7 and 8, and Fig. 2 in the Appendix. In this approach each succeeding level of intelligence subsumes all the previous ones. The number of levels he uses (12 levels) is the largest amongst all presented authors. However he remained loyal to the boundaries of fully autonomous and fully manual levels. Between these levels, the first six ones were created based on the sophistication of the machine's information processing functions and authority to manipulate the human operator's displays. In addition, the next six ones, starting from the level named servant, give the machine the ability and opportunity to take actions. In this case, the distinction between the different levels is made based on the permission and override protocol between the operator and machine. In this approach the user has more things to take into consideration, when deciding which is the proper combination for each different operation that he is going to carry.Yet a different taxonomy for sorting human mediated control of remote manipulator systems is proposed several years later by Miligram et al. (1995) in the content of tele-robot control. Their research is based on a 3-D approach which includes the degree of machine autonomy, the level of structure of remote environment, and the extent of knowledge or modellability of the remote world. As far as the LOA are concerned, they propose a taxonomy of five levels considering the different roles a human operator could play in telerobot control, including decision maker and direct controller (trading off decision making and other elements of the control system is a key aspect that must be considered as far as the human operator role is concerned (Burtnyk and Greenspan, 1991)). The taxonomy proposed is presented in the Appendix in Table 9.Later on, Endsley and Kiris (1995) focused on the out of the loop performance problem, which excludes the human from the ability to take over manual control in the event of a of failure. Their objective was to identify LOA that sufficiently maintained human operators in the control loop during normal system functioning to permit manual task performance during automation failures. They suggested that implementing automation while maintaining a high level of control for the human operator provides definite benefits in minimizing the out of the loop performance problem, as compared with full automation. This usage of a lower LOA, which maintained the human operator in the loop is beneficial to situation awareness and participants are better able to perform tasks manually when needed. The levels of automation as presented by the authors are equal to the ones described in (Endsley, 1987) with the addition of the fully manual level.The same year as Endsley and Kiris (1995) and Draper (1995) presented a taxonomy by introducing a different layout from the ones already presented. This approach combines human operators with machine control in a teleoperator capable of carrying out functions that can be either semi-autonomous or fully autonomous. In his research, he identified nine degrees of automation functions. Amongst these functions five are carried out by the human operators and the other four are allocated to the machine. He categorizes his functions to levels of control, machine roles, human tasks and critical information. The levels of control continuum as presented by him are described analytically in Table 10 in the Appendix.Building on Draper's research (Draper, 1995) and by evolving their own previous approach (Endsley, 1987), Endsley and Kaber (1999) presented a new taxonomy of 10 levels to be used in the context of teleoperation. Their work provided wider applicability to a range of cognitive and psychomotoric tasks requiring real time control in different domains like air traffic control, aircraft piloting, advanced manufacturing and teleoperation. All these domains share common characteristics. This taxonomy provided advantages over the previous proposed ones in the sense that it identified numerous LOA combinations which were not included in other taxonomies proposed by different researchers. Their approach described with detail “who” (human or system) is supposed to do “what” (task) at each level as compared to the previous hierarchies of degrees of autonomy. In all levels there is a distinction on who has the greater authority, the human or the machine, and this was described and analysed thoroughly. The levels of autonomy proposed are presented in Table 11 in the Appendix.Later on, Parasuraman et al. (2000), building on their previous approaches ((Sheridan and Verplank, 1978), (Sheridan, 1992)), started to emphasize the different aspects of human machine interaction that could be noticed. In that sense, they proposed that automation could be applied across four different classes of input functions named as they are presented in Table 2. The above described model did not explicitly provide LOAs, like the ones presented until that time, but rather stipulated that each of the four factors can be automated at a different level. Within each of these types, automation can be applied across a continuum of levels from low to high, i.e., from fully manual to fully automatic. They also proposed that any particular level of automation should be evaluated by examining its associated human performance consequences. These constitute primary evaluative criteria for levels of automation. However, human performance is not the only important factor. Secondary evaluative criteria include automation reliability and the costs of decision/action consequences. These should also be applied to evaluate the feasibility and appropriateness of particular levels of automation.In 2001, the year after the approach of Parasuraman et al., Lorenz et al. (2001) presents a more compact taxonomy than the previous ones, consisting of only three LOA. This one is a quite simple approach taking into account only three principles that they considered important. Thus, the levels introduced are: 1) The Base Line, 2)The Automation Support and 3)The Automation Support Failure Level. These levels do not follow directly the fully manual fully autonomous principles during the Automation Support Level. The operator can choose between the alternatives when presented with suggested actions by the automation system: 1) to agree before the veto time has elapsed, 2) to disagree by pressing a button and 3) to give no response which would be considered as a silent agreement. In case of an acceptance the suggested actions were implemented automatically and the operator was notified about all actions and their outcome until full recovery was achieved but could not intervene. A rejection from the side of the operator would be equivalent to a switch to manual fault management. This is what differentiates this approach to the previous ones: it takes into account the fault management level. The levels of this taxonomy analytically are presented in Table 12 in the Appendix.Clough, (2002a) presented a taxonomy with a specific application on Unmanned Aerial Vehicles. In his approach autonomy was split into four different levels which depend on the amount of human interaction and the point at which it occurs. These different levels of automation are presented in Table 13.Clough's approach has been followed by Proud et al. (2003) who presented a taxonomy of automation with eight different levels. This approach was also different than the one dimensional approaches that have been presented until now. It corresponded to complete human and computer responsibility respectively, (similar to Sheridan's scale and degrees of automation). They tailored each level of autonomy scale to fit the tasks encompassed by a function type or column: observe, orient, decide, or act. In order to explain the taxonomy, one needs to remember that each of the columns has a different meaning. Observe column refers to gathering, monitoring, and filtering data. Column orient refers to deriving a list of options through analysis, trend prediction, interpretation and integration. In addition, the levels in the decide column refer to decision-making based on ranking available options, and the levels in the act column refer to execution or authority to act on the chosen option. What these columns manage to ensure, is that individual levels in each scale are relatively consistent in magnitude of change between levels across the function types. Generally, the levels of autonomy can be broken down into three different sections: (a) the ones where the human is primary and the computer is secondary (Level 1–2), (b) the ones where the computer operates with the human interaction (Levels 3–5) and (c) the ones where the human has decreasing access to information and decreasing override capability (Levels 6–8). It is very important to understand the differences between the levels in order to interpreter them correctly. The Table 14 in the Appendix presents the taxonomy analytically.The last and most recent approach presented in this paper is the one by Fereidunian et al. (2007b), Fereidunian et al. (2007a), who presented a methodology which is an extension of the well established LOA proposed by Sheridan (1992), switch due to the implementation requirements. In the current approach, the automation scheme proposed deals with 11 LOA instead of the original 10-levels one. The level 1 of the original Sheridan's taxonomy is shifted down to form a new level 0, and a new level named 1∗ is introduced (The computer acquires the date from the process and registers them without analysis). The taxonomy as proposed by Feredunian et al., is presented with details in Appendix in Table 15.The different taxonomies presented in the previous subsection share many similarities and differences as well, when viewed in detail. The goal of this subsection is to summarize them and try to reach some conclusions regarding the previous approaches. The most important thing, and the first one to be considered, is the number of LOA that each approach includes in its taxonomy. However, there are more things that need to be taken into consideration when comparing different LOA approaches. Practically, the comparison that is carried, is based on giving satisfactory answers to the following questions:1.How many different LOA exist in each taxonomy?Which levels of one taxonomy are similar to the levels of another?Are there some levels amongst the different taxonomies that can be combined?Do there exist more popular and less popular levels?The answers to these questions will be given by a special table created by the authors presented in Fig. 1. The left column of the table includes all the possible LOA that have been proposed by all studies included in this paper. At each level (table row) a code name has been given, the one that makes it easier for the reader to understand which level it is. Each table row shares the same properties when it comes to levels of autonomy, i.e. every row corresponds to a specific level of automation that has been presented. Each one of the columns corresponds to a given author/group from the ones presented in the previous section. The intersection of rows and columns gives the current level of autonomy that has been attributed by each author and if the name attributed by the author is different by the code name we used in the left column, the exact name as proposed by the authors is given under the level number (in bracket). From this table, it seems that in most of the taxonomies presented there is a pattern when it comes to the boundary levels of fully manual and fully autonomous states. In most studies this is the case with the exceptions of (Clough, 2002a), (Billings, 1991), (Draper, 1995), (Endsley, 1987) and (Lorenz et al., 2001) which do not follow the fully manual vs. fully autonomous principle.Between the various intermediate levels that exist, it seems that some are more popular than others when it comes to their frequency of use. For example levels like Fully manual (a), Computer offers decisions (f), Human veto restrict time (m) and Fully autonomous (s) are considered as the most popular ones. Other levels are sporadically used by the different authors. The level execute and inform the human (n), and supervisory control (r) are a little bit more popular, amongst the ones not already mentioned. The remaining ones are used rarely in different mixtures and frequencies by authors.But what does it really mean that one level is more used than another? It seems that the correct answer to this question does not exist. The fact that there are some levels that are used by most authors shows that these levels can be used on a wide range of applications. Does this make one level more popular/essential than another? That is a good question to answer. This is in a way expected, since between fully manual and fully autonomous levels there exists a finite number of levels that can be invented and therefore it is common that authors “invent” identical levels. What users need to remember, is that what can really vary is the application on which the different taxonomies are going to be applied on. Every application is special, and it has its own needs, so therefore no statistics are important, the user only needs to decide what fits his/her needs better. However, an interesting categorization could be based on what applications every taxonomy has been used so far. Table 3presents the categorization of different taxonomies according to applications that they have been applied to. This can be a helpful tool, for readers that want to apply a taxonomy on a specific operation. However, it is important that the readers should not consider that this categorization should restrict any other possible usage of any taxonomy on another technological field. On the contrary - this is should be welcome.What is important to remember is that amongst the different levels presented by the authors there exist no “correct” or “wrong” levels, “better or worse” ones, they are just different. It would be wrong to claim that some levels are better than others, or that one taxonomy is the best one. To be accurate, there is no available tool in measuring how “good” or “bad” a taxonomy is, which gives the opportunity to every potential user to use the one that fits his needs better. Even taxonomies that are supposed to be used for the same types of applications can vary a lot. For example taxonomies by Sheridan and Verplank (1978), Sheridan (1992), Parasuraman et al. (2000) and Endsley (1987) are supposed to be used for the same application: avionics. However, there exists quite a significant difference between the number of the levels that their taxonomies include. In that sense every potential user should decide which approach fits his needs better, with the freedom to design his own taxonomy by mixing the levels that have already been proposed or even add some new ones. In that sense the authors believe that there does not exists such a thing as “best taxonomy” presented at least as far as all possible applications are concerned. The number and the variety of levels is in most cases different. However, it needs to be admitted that taxonomies that are more analytical than others (have more levels) have probably more chances to be used in different types of applications.In this subsection we present our approach on a taxonomy of Levels of Automation. Our approach is used to show how a new taxonomy can be created, and what the authors would take into account if they would design a taxonomy fitting their needs better. This taxonomy, is not meant to be one more taxonomy added to the ones already proposed. It is just a simple way of showing the reader what we would prioritize and take into account when designing a taxonomy by ourselves. By no means do we claim that this taxonomy is superior than the others. It consists of the levels that we think are crucial in most applications, and also levels which according to us seem to have a wide range of usability.In addition, we tried to combine levels that seem to have no significant differences between them, at least from our point of view. What was interesting when trying to produce our approach were the things that we needed to focus on. What we decided to do is to create a taxonomy that could be widely used, meaning that we did not want to restrict ourselves with a limited number of LOA. We followed the principle of fully manual and fully autonomous boundaries. The challenge was what levels to include in between them. In that sense we tried to keep it short but we also tried to find similarities amongst previously presented taxonomies that would help us mix and combine some of them. Therefore, we concluded in an 8-level approach included some “popular” and some “unpopular” levels. For example we include the level Decision proposal stage (Level 2) which is a combination of levels already proposed by other users. Also, we introduced the failure mode at the fully autonomous level, which means that the computer can be fully in charge unless an unexpected condition arises. In that case, if the error is not included in the specifications the computer should seek human support. The levels and explanations of our proposed taxonomy are presented analytically in Table 4. This is an example that shows how a taxonomy of levels on automation can be created. This example, shows that it is up to any user to decide how they can create their own taxonomy of levels of automation and prioritize their needs and requirements.So far the effects on system performance of various forms of automation have been discussed. The forms were defined by different levels of autonomy or by different stages of information processing to which machine aid can be applied (Parasuraman, 2005). The taxonomies presented in the previous section assume that once a LOA is identified by the designer, it remains fixed or consistent until the end of the operation. This approach can be referred to as static automation (Parasuraman et al., 1992).On the other hand, there is the possibility that the level and/or type of automation might not be fixed but has the ability to change in real time during system operation. This possibility i.e. that the levels of autonomy change during a system's operations, is referred to as adaptive automation ((Moray et al., 2000), (Parasuraman et al., 1993), (Scerbo, 1996)). Adaptive automation is akin to dynamic function allocation, in which the division of labour between human and machine agents is not fixed but dynamic, flexible, and context dependent ((Inagaki, 1993), (Parasuraman et al., 1992), (Scerbo, 1996), (Hancock et al., 1985), (Kaber and Endsley, 2004), (Rouse, 1988), (Scerbo, 2001)). Adaptive automation can be important, since the peripheral situation can affect the performance of the systems especially since they are not based on the philosophy “autonomate as much as possible” (Fereidunian et al., 2007b). Consequently, the automation solution should be smart enough to adapt the LOA to changes in peripheral situations. Many researchers have investigated human performance in relation to adaptive automation using simulations of flight, air traffic control, driving tasks, and process control ((Inagaki, 1993), (Moray et al., 2000), (Parasuraman et al., 1993), (Scerbo, 1996)). Lets say for example that, if the performance in a higher level of automation is getting worse, for any kind of reasons this means that actions need to be taken. In that case it is good if there exists a possibility of re-evaluating the LOA that the system is operating at, and ideally changing it. In that case, the automation may change level to a lower one and/or turn over more or even all control to the human until the problem is solved. On the other hand, the opposite example can exist. If high human workload is detected and/or the human operator is not responding appropriately, automation may go to a higher level so as to become less dependent on the human. Adaptive automation may reduce the human performance costs (unbalanced mental workload, reduced situation awareness, complacency, skill degradation, etc.) that can sometimes be associated with high-level decision automation. The thorny human factors issue of allocation of function has typically been based on stereotypical characteristics of human and computer capabilities, an approach that has been met with marginal success.Although the adaptive automation concept is not new ((Hancock et al., 1985), (Rouse, 1988), (Parasuraman, 1987), (Rouse and SheridanJohannsen, 1976)) many researchers have carried out empirical studies regarding it ((Moray et al., 2000), (Hancock and Scallen, 1996), (Hilburn et al., 1997), (Kaber et al., 2001), (Parasuraman and Hancock, 1999), (Parasuraman and Mouloua, 1996), (Scallen et al., 1995)). A variety of frameworks for adaptive human-automation systems have been suggested along these lines. In the previous section we presented analytically the use and the necessity of the intermediate LOA as a way of improving human automation performance ((Endsley and Kiris, 1995), (Wickens et al., 1998)). In contrast, several authors ((Miller and Parasuraman, 2007), (Opperman, 1994)) propose that the LOA should be adjustable during system operation, which is also consistent with the adaptive automation concept ((Inagaki, 1993), (Parasuraman et al., 1992), (Scerbo, 1996), (Rouse, 1988)).Different research has demonstrated that adaptive automation has its merits, but in most of these works the automation solution decides on its own how to adapt its own behavior ((Hancock et al., 1985), (Rouse, 1988), (Scerbo, 2001), (Banks and Lizza, 1991), (Dornheim, 1999), (Hancock and Scallen, 2001), (Kaber and Riley, 1999), (Miller and Hannen, 1999), (Opperman, 1999), (Parasuraman et al., 1999)). A different proposal can be implemented, by proposing that the human should remain in charge, deciding how much automation to use. This approach has been characterized as adaptable automation ((Scerbo, 2001), (Opperman, 1994)). Adaptable automation can lead to benefits similar to those of adaptive automation while avoiding many of its pitfalls.

@&#CONCLUSIONS@&#
