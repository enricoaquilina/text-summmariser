@&#MAIN-TITLE@&#
Geo-referenced flight path estimation based on spatio-temporal information extracted from aircraft take-off noise

@&#HIGHLIGHTS@&#
Method for geo-referenced flight path estimation during take-off.Spatial information extraction using a microphone array with three non-coplanar axes.Detailed analysis of the spatial aliasing effect on aircraft take-off noise signals.Brings a correlation between aircraft position and acoustical indicators.Aid for airport noise monitoring and acoustic source localization.

@&#KEYPHRASES@&#
Aircraft,Localization,Flight path estimation,Take-off,Noise,Acoustic,

@&#ABSTRACT@&#
The closer proximity between airports and residential areas has created a growing attention regarding noise pollution. The noise abatement procedures established by the aeronautical authorities and the models for computing noise contours around airports are proof of that. There are also models for identifying aircraft taking off which have focused on the correlation between the aircraft position and the noise signal. However, this correlation has been made so far without spatial information. The present study proposes a method to estimate the geo-referenced flight path followed by an aircraft taking off, using the spatio-temporal information extracted from the noise signal and improved with a smoothing algorithm. A microphone array with twelve sensors is used in order to evaluate different sensor spacings and the spatial aliasing effect when working with take-off noise signals. The flight path estimation method assumes that the aircraft is following a ground track collinear to the runway and was compared against radar information and Automatic Dependent Surveillance-Broadcast (ADS-B) data. The average method accuracy was between 3 and 6 meters. The estimated flight path has a ground length of about two kilometers, including locations at least one kilometer apart from the measurement point.

@&#INTRODUCTION@&#
Aircraft noise has become a major issue at airports, which arises from growing air traffic, the airport expansion necessity and the closer proximity of residential areas (ICAO [12]). Many studies related with aircraft noise impact have been conducted to highlight the extent of the problem such as Clark, Head and Stansfeld [4], Givoni and Rietveld [10], Montazami, Wilson and Nicol [22].Knowledge of aircraft type operating is a major requirement to estimate the acoustical impact of an airport on the community. It is a mandatory entry for both, models computing noise contours around airports such as ECAC [7], FAA [8], ICAO [11] and aircraft noise certification procedures. The flight path is also required as there are several elements that depend on the aircraft position with relation to the observer, such as lateral attenuation, that is determined by the airplane bank angle, the elevation angle and the lateral distance to the receiver (Plotkin, Hobbs and Bradley [28], SAE [31,32]). The current methods for computing noise contours around airports do not use the take-off noise signal, instead they use a default acoustic profile by aircraft type and expected operational conditions. Moreover, the vast majority of airport noise monitoring systems use the signal only to compute some statistical indicators such as the equivalent continuous noise level (DGAC [5], Jones and Pagdin [16], MASSPORT [21], TNO [38]).Recently, a new computational model to identify aircraft class based on take-off noise signal segmentation in time was introduced by Sánchez-Pérez, Sánchez-Fernández, Suárez-Guerra and Carbajal-Hernández [36]. The model, that clearly improves the classification process over previous works such as Rojo, Sánchez, Felipe and Suárez [30], Sánchez-Fernández, Sánchez-Pérez, Carbajal-Hernández and Rojo-Ruiz [35], starts from the basis that aircraft noise is a non-stationary process that varies in frequency during a take-off and proposes a segmentation in time to attempt correlating the aircraft position with the noise signal. With the aim of obtaining this correlation accurately, the present study proposes a method to estimate the geo-referenced flight path followed by an aircraft taking off, by means of spatio-temporal information extracted from the noise signal measured with a microphone array and the fact that the aircraft ground track is collinear to the runway in the earliest stage of take-off.This work is presented in six sections. Section 2 provides a detailed description of the measurement system, including the microphone array design. Section 3 introduces the spatio-temporal information extraction and improvement algorithm, also giving a profound evaluation of different sensor spacing. Section 4 presents the flight path estimation process and a detailed review of the spatial aliasing effect when working with take-off noise signals. Section 5 gives the method evaluation and the results discussion, followed by the conclusions drawn in Section 6.Sound source localization by means of noise signal measurements requires using a microphone array, which allows signal direction-of-arrival (DOA) estimation. The key parameters of a microphone array are the microphone number, the array geometry and the sampling rate (Genescà, Romeu, Arcos and Martín [9], Kuo, Veltin and McLaughlin [19]).The array geometry design involves selecting the adequate sensor spacing, which is directly related to angular resolution. As the distance between sensors increases, it is possible to detect lower angular changes and therefore a better angular resolution is achieved. However, the increase in distance leads to a decrease in the maximum frequency analyzable, which may result in information loss about the signal of interest. The latter restriction exists due to a common problem known as spatial aliasing.Another significant element is the sampling rate. If sound speed c remains the same, as well as the distance d between a microphone pair, but the sampling rate Fs is increased, more samples can be taken during the time interval that the sound wave takes to propagate from one microphone to another. Therefore a better angular resolution is achieved since more samples can be used to spatially map the position of the source. In this work, a sampling rate of 51 200 Hz was used, the highest allowed by the equipment used.Table 1depicts the abovementioned using sound speedc=343m/s. The maximum detectable samples m, refer to the highest number of samples that can be taken at a sampling rate Fs, during the time interval the sound wave takes to travel the distance d between a sensor pair. This quantity can be obtained asm=(d/c)Fs. The angular resolution is180/mand the maximum analyzable frequency isf=c/2d, which is also a restriction due to the spatial aliasing.In array processing, if the signals coming from sources at different locations are not spatially sampled by the sensors array densely enough, i.e. the inter-element array spacing is too large, these will produce the same output and their positions cannot be uniquely determined based on the array signals received (Benesty, Chen and Huang [1], Liu and Weiss [20]).For signals having the same angular frequency w and the corresponding wavelength λ, but different DOAθ1andθ2satisfying the condition(θ1,θ2)∈[−π/2π/2], aliasing implies that the array response vectors for each signald(θi,w)are equal. Therefore,d(θ1,w)=d(θ2,w), which leads to expression (1).(1)e−jwτm(θ1)=e−jwτm(θ2)whereτmis the propagation delay for the signal from sensor 0 to sensor m, which is a function ofθi. For a uniformly spaced linear array with an inter-element spacing d,τm=mτ1=m(dsinθi)/candwτm=m(2πdsinθi)/λ, where c is the sound speed. Consequently, the expression (1) changes to expression (2).(2)e−jm(2πdsinθ1)/λ=e−jm(2πdsinθ2)/λIn order to avoid spatial aliasing, the condition|2π(sinθi)d/λ|θi=θ1,θ2<πhas to be satisfied. Then,|d/λ(sinθi)|<1/2. Since|sinθi|⩽1, this requires that the array distance d should be less thanλ/2. According to the Nyquist sampling theorem, two samples are required for every period of the highest signal frequency Fourier component. In this case, two spatial samples are needed for every wavelength, making the element spacingd⩽λ/2=c/2f, this result may be interpreted as a spatial sampling theorem (Benesty et al. [1], Chandran [3], Liu and Weiss [20]). It has been shown that a spacing that exceeds one-half wavelength produces ambiguity errors in DOA estimation algorithms. A detailed analysis of the spatial aliasing effect on take-off noise measures conducted in this study is presented in Section 4.1.Based on sensor spacing limitations and their relationship to the angular resolution and maximum analyzable frequency, we state that twelve microphones arranged in a three-dimensional array is more than the minimum required to estimate the geo-referenced flight path of an aircraft taking off.In order to verify the abovementioned, the following methodology was defined:–Create a microphone array prototype, including the measurement system for sampling the signals in real time.Create a method to extract spatial information from the real time take-off noise measurements.Create a method to generate a geo-referenced flight path using the extracted spatial information.Evaluate microphone spacing with respect to the estimation accuracy.Evaluate the spatial aliasing effect on real time take-off noise measurement using different microphone spacing.Several researches have shown that aircraft take-off noise relevant frequencies are below 3000 Hz, which are also used to identify between aircraft classes that include propeller-driven and jet aircrafts (Rojo et al. [30], Sánchez-Fernández et al. [35], Sánchez-Pérez et al. [36]). Bearing this in mind, a microphone array with three axes collinear with the x, y and z axes from the Cartesian coordinate system, was defined. Accordingly, four microphones were arranged for each axis, comprising distances from 5 to 40 cm and allowing analyzing frequencies up to 3430 Hz. Fig. 1(a) shows the arrangement for the x and z axes and Fig. 1(b) the arrangement for y axis.Since the distance between microphones determines the angular resolution and the maximum frequency analyzable (given the restrictions imposed by the spatial aliasing), the set of distances selected allows evaluating them regarding the accuracy of the flight path estimation, which is done in Section 3.4. It also permits the assessment of the spatial aliasing effect when working with aircraft take-off noise signals and microphone arrays with sensor spacing from 5 to 40 cm, which is presented in Section 4.1.The equipment used was selected taking into account the aircraft noise frequency range, the accuracy to be achieved and the array distance limitations. All these were defined having as guideline several standards such as SAE [31,33,34]. The core equipment includes:•Twelve pre-polarized piezoelectric microphones provided with an optimized frequency response from 20 Hz to 10 kHz. These sensors are widely used in multi-channel sound measurements including acoustic arrays, due to their excellent phase-matching and sensitivity characteristics. According to the recommended practice published by SAE [33], the microphone used for airport noise monitoring should meet the requirements of Class 1 accuracy specified in the standard IEC 61672-1 (IEC [13]), in order to record precisely the equivalent continuous noise level. Four microphones comply with the Class 1 requirement, three more than the minimum required, so as to have redundant accurate information about the sound pressure, which is useful for future research of the acoustic impact. The remaining eight microphones comply with Class 2 requirements.Two digital signal acquisition cards NI 9234 and one NI 9233. These cards have four channels and allow a maximum sampling rate of 51.2 kHz using external master timebase. Also, they include the capability to read from and write to transducer electronic data sheet (TEDS) Class 1 smart sensors (NI [24]).A module to synchronize up to four data acquisition cards, which has four 32-bit general-purpose counter/timers built in NI [25].A personal computer.Fig. 2shows the microphone array built and fully configured during a measurement day. The four Class 1 microphones were placed on the x axis with the diaphragm up to comply with the recommendations about microphone orientation and obstructions in the sound field specified in SAE [34].The measurement point location is shown in Fig. 3as well as the microphone array axes geographic orientation. The x axis is oriented with a true heading of 110° while the y axis has a true heading of 200°. The array was placed at a height of 5 meters to decrease the ground reflection effects as recommended in SAE [34].The measurements were obtained during two different days where the weather conditions were variable. The temperature ranged from 18 to 27 °C and the dew point ranged from −6 to−1°C. The latter parameters were obtained from meteorological aerodrome reports (METAR) and can be used to compute relative humidity. These values are determinant to calculate the speed of sound, as well as to estimate the atmospheric attenuation (Bies and Hansen [2], ISO [14,15]). No significant weather such as rain was observed.Overall, 88 recorded take-offs were achieved, performed by different aircraft types such as Boeing 737-300/700/800, Airbus A319 and A320, Embraer ERJ-145 and E-190, MD-80, ATR-42 and Tupolev TU-204. The take-off time, aircraft type, airline, flight number, registration tag and engine type were provided by the aeronautical authorities. This information was cross-checked with that observed during the measurements.Digital filters, on both the analog input and output of digital signal acquisition cards, always produce a delay because a minimum number of samples are needed before the digital filter can work effectively (NI [26]). For this reason, a time shift to the acquired signals was performed. Due to the synchronization of two kinds of acquisition card being needed, the signals acquired from these cards had a different delay. Accordingly to manufacturer specifications, the delay in seconds was computed as follows:–NI9233:12.8/fs+3μs,NI9234:38.4/fs+3.2μs.The first step to obtain spatio-temporal information is to compute the time-difference-of-arrival (TDOA) between a microphone pair. The generalized cross-correlation (GCC) algorithm proposed by Knapp and Carter [17] is the most widely used approach to TDOA estimation. The GCC methods are computationally efficient. They induce very short decision delays and hence have a good tracking capability: an estimate is produced almost instantaneously (Benesty et al. [1]). The TDOAτˆGCCis obtained as the lag time that maximizes the GCC function between the microphone output filtered signals, computed with expressions (3)–(7).(3)τˆGCC=argmaxτry1y2GCC(p)(4)ry1y2GCC(p)=F−1[Ψy1y2(f)]=∫−∞∞Ψy1y2(f)ej2πfpdf=∫−∞∞υ(f)φy1y2(f)ej2πfpdf(5)φy1y2(f)=E[Y1(f)Y2⁎(f)](6)Yn(f)=∑kyn(k)e−j2πfk,n=1,2(7)Ψy1y2(f)=υ(f)φy1y2(f)wherery1y2GCC(p)is the GCC function,φy1y2(f)is the cross-power spectrum,Ψy1y2(f)is the generalized cross-spectrum andυ(f)is the frequency-domain weighting function. In this work, the phase transform general correlation method (PHAT) is applied, which statesυ(f)as expression (8).(8)υ(f)=1/|φy1y2(f)|Since the GCC function is defined for two microphones, all sensor pairs provide spatial information. Therefore, in order to prevent spatial aliasing, each signal pair was filtered allowing frequencies between 20 Hz andf=c/2d, where d is the related sensor spacing.The signal measured during a take-off is characterized by the progressive increase in energy as the aircraft approaches the measuring point and the opposite as it moves away. This can be inferred from Fig. 4(a). Because the noise measured at the receiver point is a combination between several sources, including the aircraft noise, the spatio-temporal information extraction was performed from a point near the maximum energy zone, where the aircraft signal is less likely to be masked and therefore, the generalized cross-correlation is more stable. This point was defined asTmid.In this work, the estimation ofTmidis performed based on the correlation between the signals(t)and a Gauss function defined asw(t)=e−12(αtT/2)2, where T is the signal length. The time instant corresponding to the correlation maximum is defined asTmid. The valueα=2.5was selected experimentally as the one that best fit the aircraft signal absolute|s(t)|as it is shown in Fig. 4(b) through the comparison between|s(t)|and the Gauss functions withα=[22.53].OnceTmidis calculated and with the aim of tracking the aircraft position, half-second 50% overlapping segments in both directions fromTmid(t<Tmidandt⩾Tmid) are extracted, computing the TDOA and DOA for each segment. This results in a time-dependent functiong:t→θ, which returns the DOA in the range of[0°,180°]and is defined by expressions (9)–(11).(9)g(t)=cos−1(cτˆGCC/d)(10)y1(k)=s1(k)|⌊(t−0.25)Fs⌋⩽k<⌊(t+0.25)Fs⌋(11)y2(k)=s2(k)|⌊(t−0.25)Fs⌋⩽k<⌊(t+0.25)Fs⌋whereτˆGCCis computed with expression (3), using the half-second segmentsy1(k)andy2(k), extracted from the sensors signalss1ands2.Fig. 5shows the functiong(t)(light solid line) for an A320 take-off using microphone pairs in the z axis, comprising distances from 5 to 40 cm. As distance decreases, many abrupt fluctuations appear due to the degradation of the angular resolution. For example, with the spacing of 40 cm, a total of 59 samples can be obtained that should be used to characterize an angular opening of 180°, leading to an angular resolution of 3°. In consequence, aircraft position changes of 3° with respect to the measurement point could be detected.On the other hand, with the spacing of 5 cm, the maximum of the functionry1y2GCC(p)computed with expressions (4)–(8), should be located in the range[−7,7], because the highest number of samples that can be taken at a sampling rate of 51 200 Hz, during the time interval the sound wave takes to travel a distance of 5 cm is seven. Therefore, the aircraft position will be described in increments of27.5°=180/7and any change in the generalized cross-correlationry1y2GCC(p), induced by some other source, such as wind, birds, dog barks or even other aircrafts, would lead to an abrupt change in the functiong(t).Something similar happens with the microphone pairs in the x and y axes of the same or other measurements. Appendix A shows more results that illustrate the above.The entire spatio-temporal information extraction algorithm is presented in Fig. 6. The step one is the estimation ofTmidbased on correlation between|s(t)|and a Gauss function, the step two is the signal segmentation fromTmid, using half-second 50% overlapping segments as explained above and the step three is the smoothing algorithm presented in Section 3.3.1.Abrupt fluctuations in the functiong(t)will produce an erratic flight path, since the estimation will be mainly based on the spatio-temporal information provided by each axis through the functiong(t). Therefore these mistakes must be removed, which can be accomplished using a smoothing algorithm. The main idea of the smoothing algorithm presented in this work is to pass the functiong:t→θ, through a sequential filtering process.The first filter removes the local maximums and minimums representing unstable changes, which avoids unreal transitions in the flight path. The second is an averaging filter or moving average that uses five elements to compute the mean. The filter itself is a feature created to soften, therefore was tested individually. However, the resulting functiong(t)tended to keep the erroneous fluctuations, since these were averaged instead of being removed. Also, the effect of the two previous filters was compared against the use of a moving median-average filter, which determines the median of 5 elements, removing the two most distant and averaging the remaining values. Nevertheless, the latter filter still preserves some erroneous fluctuations, because in some cases the fluctuations were very close and were not effectively removed by the filter.The application of the first two filters involves the removal of a considerable number of points from the original functiong(t), which tends to become in a set of linear transitions. This is more noticeable with the small sensor spacings due to the existence of more erroneous fluctuations. In order to prevent this effect, the third filter was defined as a piecewise cubic Hermite interpolation that preserves the non-linear behavior of the original functiong(t). Finally, the smoothed functiong(t)is obtained as shown in Fig. 5 by the dotted line.With this algorithm, a function of DOA with respect to time is obtained, preserving the main shape of the functiong(t)and eliminating erroneous fluctuations. Even for small sensor spacing such as 5 cm that implies a low angular resolution, a curve similar to those achieved with larger distances can be obtained. More results of the smoothing algorithm are shown in Appendix A, Figs. A.1, A.2.The sound field radiated by a source may be divided into three regions: the hydrodynamic near field, the geometric near field, and the far field. The far field is characterized by the satisfaction of the three criteria defined in expressions (12)–(14) (Bies and Hansen [2]).(12)r≫πD2/(2λ)(13)r≫D(14)r≫λ/(2π)where r is the distance from the source to the measurement point, λ is the wavelength and D is the characteristic source dimension. However, it should be pointed out that while satisfaction of inequality given by Eqs. (12)–(14) is sufficient to ensure that one is in the far field, it may not always be a necessary condition (Bies and Hansen [2]).Because the aircraft noise is a combination of several sound generating mechanisms, which dominate sound radiation in different directions depending on the flight phase and engine-airframe combination (NASA [23]), this paper presents a far field analysis with respect to various of those generating mechanisms.For example, in the case of the main landing gear of an Airbus A320, the maximum dimension of its structure is about 3 m. Given that the relevant frequencies for aircraft class identification have been established below 3000 Hz (Sánchez-Pérez et al. [36]), the frequency can be set asf=3000Hzand the wavelength asλ=0.114m. Evaluating the expressions (12)–(14) based on the previous values results inr≫πD2/(2λ)=[π(3)2]/[(2)(0.114)]=124m,r≫3mandr≫λ/(2π)=(0.114)/(2π)=0.0182m. Moreover, in the case of an Airbus A380 engine, the nacelle dimensions (width and height) are around 4 m. In this case, the expressions (12)–(14) result inr≫πD2/(2λ)=[π(4)2]/[(2)(0.114)]=220m,r≫4mandr≫λ/(2π)=(0.114)/(2π)=0.0182m. Also, recent studies have shown experimentally by means of measurements with microphone arrays that the boundary between the near field and far field with respect to the engine exit nozzle of diameterd=5.08cmfor a commercial airplane isr=50d=2.54m(Koch, Bridges and Brown [18], Kuo et al. [19]).Therefore, since the minimum distance between the measuring point and the runway is 150 m, the aircraft, as a combination of the previous sources, complies most of the time with the expressions (12)–(14). In addition, experimental tests in the same measurement location were conducted with a uniformly spaced microphone array, with sensor spacing between 20 and 40 cm. For all cases tested, the TDOA between equally spaced microphones pairs was the same, which confirms a plane wavefront behavior. Consequently, in this work it is considered that the aircraft is in the far field.Given that the array is in the far field with respect to the aircraft, all microphone pairs in the same axis should provide the same spatio-temporal information. However, each sensor spacing produces a different functiong(t)since distance determines the angular resolution as well as the maximum analyzable frequency and hence the functiong(t)shape.Furthermore, an increase in the angular resolution (AR) or the maximum analyzable frequency (MAF) supposes an increase in the estimation accuracy ofg(t), but these quantities are inversely related. Therefore, in this paper a merit index Q is defined in order to assess which distance allows an appropriate AR–MAF relationship. Then, the index Q for the spacing k is computed with expressions (15)–(17).(15)Q=1/(K−1)∑Gka(16)Gka={Sk,1a,Sk,2a,…,Sk,Ka}−{Sk,ka}(17)Si,ja=D[(gia(t),gja(t)),M]where K is the number of possible spacings for the a axis andGkais the set of similaritiesSi,jabetween the functiong(t)for the spacing i in the a axis (gia(t)) and the functiong(t)for the spacing j in the same axis (gja(t)), using the measure M.Table 2presents an example of the Q merit index computed for each axis using an A320 take-off measurement. To compute the similarity three different measures were used:–Pearson correlation coefficient (PCC): a common statistical strength measurement of the linear relationship between two random variables.Spectral angle (SPA): widely used to detect similarity of shape between two vectors (Sweet [37]).Spectral Similarity Score NS3: introduced by Nidamanuri and Zbell [27], which combines the relative merits of spectral angle and amplitude differences between two spectra.In the x axis it can be observed that the merit Q for the spacing of 40 cm is the best using any measure (QNS3=0.1210,QSPA=0.1126andQPCC=0.9387). The same applies to the y axis. However, for the z axis the best merit is achieved by the spacing of 35 cm using the NS3 and SPA measures and the spacing of 10 cm using the PCC measure. In spite of this, the spacing of 40 cm had the second best merit using NS3 and SPA measure. Something similar happens with the spacing of 35 cm; this obtained a high merit in all cases when it was not first. Merits calculated using other take-off noise measurements are shown in Tables B.1 and B.2 from Appendix B.From this analysis it can be inferred that the spacing of 40 cm provides the best AR–MAF relationship, which means that working with frequencies below 428 Hz produces similar results than analyzing frequencies up to 3420 Hz, but allows for better angular resolution and therefore better accuracy in the estimation ofg(t). Besides, the spacings of 35 cm (or 32 cm in the case of y axis) and 25 cm (or 22 cm in the case of y axis) are not disposable and could improve the estimation if they are used in conjunction with the spacing of 40 cm.The aircraft position vectorv→shown in Fig. 7could be calculated if the magnitude and any two angles formed with Cartesian axes are known. As the magnitude has no way of being found from the take-off noise signal, it is impossible to determine the aircraft position using the above premise. However, a vector in the same direction thanv→but with magnitude equal to one, can be calculated as it forms the same angles with Cartesian axes. This vector defined asvˆ=v→/|v→|, represents the DOA of the aircraft signal.Since the x, y and z axes of the microphone array match with the Cartesian axes, the angles α, β and φ at time t are defined asα=gx(t),β=gy(t)andφ=gz(t), which means that α, β and φ are the estimated angles between the signal wavefront and the x, y and z axes, respectively, using the algorithm defined in Section 3.3. Therefore, the vectorvˆ=(a,b,c)could be estimated with expressions (18)–(20).(18)cosα=(vˆ⋅iˆ)/|vˆ|=[abc][100]=a(19)cosβ=(vˆ⋅jˆ)/|vˆ|=[abc][010]=b(20)cosφ=(vˆ⋅kˆ)/|vˆ|=[abc][001]=cMoreover, given that the norm of the vectorvˆis equal to one, any vector's component could be calculated based on the other two, by means of expression (21). Therefore, the take-off flight path estimation could be also done using only two axes.(21)|vˆ|=1=a2+b2+c2The vast majority of the airport departure procedures include a starting straight leg of length greater than one nautical mile. Hence, this work considers that the aircraft ground track has the same direction as the runway during the entire measurement. Therefore, the runway was characterized from two geographic points located on it, as described in expression (22).(22)(x,y,0)=s→+k1(e→−s→)wheres→=(sx,sy,0)represents the starting point on the runway whilee→=(ex,ey,0)symbolizes the end point. The vector(e→−s→)must have the same direction of the take-offs.In order to estimate the aircraft position at time t, the intersection between the lines from expressions (22) and (23) is calculated, findingk1andk2by means of Eq. (24).(23)(x,y,0)=m→+k2(a,b,0)(24)[sxsy0]+k1{[exey0]−[sxsy0]}=[mxmy0]+k2[ab0]where the director vector of the line defined in expression (23) is the vectorvˆprojection in the xy plane whilem→=(mx,my,0)represents the measurement point location in the xy plane.Subsequently, the distance r between the measuring point and the intersection point is determined, while the aircraft altitude h is found by trigonometry with expression (25), adding the measuring point height.(25)h=tan(90−φ)r+5In this work, the two possible alternatives to estimate the flight path were tested. The first was to compute the vectorvˆby means of the spatio-temporal information provided by only two axes and the second was to use the information from all three axes. However, after several experimental comparisons, it was found that using all three axes provides flight path estimates more consistent and closer to its real counterparts.Fig. 8shows the geo-referenced flight path estimated for an A320 take-off as well as the measurement point, the airport runway and the surrounding residential areas. Fig. 9does the same but with an E190 take-off. For more flight path estimations refer to Appendix C (Figs. C.1 and C.2). The flight paths display the aircraft position in space for the 24 seconds the signal lasted and are divided into three areas; the white area represents estimation with a high degree of certainty while the black ones stand for estimation with a medium degree of certainty. Each area is also marked in time so that the white area comprisestb⩽t⩽tewhile the black ones covert<tbandt>te. The latter (with medium certainty) are located at the measurement ends, because the effect of undesirable noises is most noticeable when the aircraft signal energy is low. In the case of Fig. 8,tb=3.6sandte=15.8s. These values were found as the first time instant from both sides ofTmidthat do not comply with the following rules:1.The ground track described by the aircraft positions projected in the xy plane,p→xy(t)andp→xy(t−1), at time instant t andt−1, has the same direction of the take-off movements at the airport:cos−1([p→xy(t)−p→xy(t−1)]⋅(e→−s→)/‖p→xy(t)−p→xy(t−1)‖‖s→−e→‖)=0The take-off aircraft speed falls in the range[120kt,250kt]as stated in SAE [34]:120kt⩽‖p→(t)−p→(t−1)‖/(t−(t−1))⩽250ktThe aircraft height or z component of the aircraft positionp→z(t)is always increasing:ht=p→z(t)⩾ht−1=p→z(t−1)Then, the flight path could be represented as a functionp→:t→R3wherep→(t<tb)andp→(t>te)are estimated by means of linear regression as defined in expression (26).(26)p→:t→R3={ϕ→=[ρ0ρ1ρ2]+[γ0γ1γ2]t=ρ→+γ→t|argminρ,γ∑i=15(p→(tb+i)−φ→)2,t<tbm→+k2(a,b,0)+(0,0,h)|a=cosgx(t),b=cosgy(t),tb⩽t⩽teϕ→=[ρ0ρ1ρ2]+[γ0γ1γ2]t=ρ→+γ→t|argminρ,γ∑i=15(p→(te−i)−φ→)2,t>tewherep→(t)represents the aircraft position at time t and thegx(t),gy(t)andgz(t)functions are determined by averaging the curves computed for 25, 35 and 40 cm spacings in the case of the x and z axes, and 22, 32 and 40 cm spacings in the case of y axis.Since the white area was estimated with a high degree of certainty while the black ones with a medium degree of certainty, this paper suggests using the flight path in the time intervaltb⩽t⩽teto extract the spatio-temporal patterns while the flight path in the intervalst<tbandt>teonly to estimate the acoustic impact.Physical world signals are naturally broadband and the spatial sampling theorem requires careful thought in this context. The implication is that in order to prevent spatial aliasing, one should spatially sample at half of the wavelength corresponding to the smallest wavelength (or highest temporal frequency) of interest (Dmochowski, Benesty and Affès [6]). Hence, the spatial aliasing leads to the inverse relationshipf=c/2dbetween the sensor spacing d and the maximum analyzable frequency f. As the sensor spacing grows, more high frequency components should be neglected. This spectrum reduction has a significant effect on wideband signals such as the aircraft take-off noise, since it has relevant frequencies up to 3000 Hz.For example, Dmochowski et al. [6] concluded that unless a wideband signal possesses a strong harmonic component, spatial aliasing is not experienced with broadband signals. This conclusion was obtained using simulated signals consisting of I tones uniformly spaced from 1000 Hz to 2000 Hz with amplitudeAi=1and a uniform linear array with an intersensor distanced=c/1000, which means that all tones comprising the signal lead to spatial aliasing. Since the aliases occurred at different azimuths for different frequencies, the integrated broadband beampattern tended to average out the incorrect DOAs.On the other hand, the take-off noise signals have several harmonic components with amplitude significantly greater than the rest as shown in Sánchez-Fernández et al. [35], Sánchez-Pérez et al. [36]. In consequence an evaluation of the real effect of the spatial aliasing is required. In this work, the maximum sensor spacing used is 40 cm, which limits using the aircraft noise spectrum down to 428 Hz. Then, in order to evaluate the spatial aliasing effect on aircraft take-off noise signals, the geo-referenced flight path was estimated with and without fulfilling the spatial sampling theorem. Fig. 10depicts the spatial relationship between the flight path estimated in Fig. 8 and its counterpart without avoiding spatial aliasing.Both flight paths were compared computing the distance between locations corresponding to the same time instant. Table 3summarizes the results using seven different take-off measurements, showing the minimum and maximum distance between flight paths as well as the average for both, the high certainty area and the medium certainty area. For example, in the case of the high certainty area, measurement six yielded a minimum of 0.3 m and a maximum of 16.3 m while the average was 4.1 m. The remaining measurements yielded similar results.In general, flight paths with and without fulfilling the spatial sampling theorem differ in an average distance from 3 to 8 m, achieving minimums below 1 m for the area of high degree of certainty. This suggest that the spatial Nyquist criterion has little impact when working with aircraft take-off noise signals and sensor spacings up to 40 cm, which is not different from that demonstrated by Dmochowski et al. [6] using wideband signals generated from a computer simulation modeling anechoic propagation and a maximum sensor spacing of 35 cm. This also confirms that low-frequency components are more important when spatially analyzing aircraft take-off noise.Another factor contributing to spatial aliasing having little effect on aircraft take-off noise signals is that the distance the wavefront has to travel is variable since the aircraft position relative to the observer varies. When the aircraft position is parallel to the axis formed by a microphones pair, the wavefront has to travel a distance equal to the sensor spacingdt; any non-parallel aircraft position would require the wavefront to travel a lower distancedt+n<dt. This means that frequencies in the rangec/2dt<f⩽c/2dt+nwill not lead to spatial aliasing. Fig. 11depicts the abovementioned.Despite the limited impact of spatial aliasing observed during the conducted tests, caution must be taken when working with higher than 40 cm sensor spacing because the actual effect has not been evaluated and will also involve substantial elimination of the original signal.

@&#CONCLUSIONS@&#
This paper proposes a method for estimating the geo-referenced flight path followed by the airplane during take-off, based on spatio-temporal information extracted from the noise signal. The proposed method allows knowing the aircraft position at a maximum distance from the measurement point of about one kilometer and generates a flight path covering a ground track around two kilometers. The spatio-temporal information is extracted using a microphone array with twelve sensors arranged in three non-coplanar axes and improved with a smoothing algorithm. Different sensor spacings were evaluated obtaining the best results with distances between 22 and 40 cm. Also, it was shown that spatial aliasing has little impact when working with aircraft take-off noise signals and sensor spacing below 40 cm. The average method accuracy was between 3 and 6 meters, when comparing the estimated flight path against radar information and ADS-B data.The ability to correlate the spatial position and a signal segment by means of the flight path estimated, allows as future work, the extraction of spatio-temporal patterns for aircraft class identification. Besides, it will be possible to compute some elements related to the flight path such as lateral and atmospheric attenuation, the Doppler Effect, among others, which could improve the acoustic impact estimation and the classification model accuracy by means of pattern corrections.The proposed method will allow a noise monitoring system to be self-contained, gathering not only acoustical indicators but also spatial information, which cannot always be obtained in real time by means of ADS-B broadcasting, since not all aircraft currently have this technology. However, this redundant information provided by radar and ADS-B could be used to validate and correct the estimated flight path. Furthermore, when the noise signal is the unique data source such as in sniper shots localization, the techniques applied in this work are the only means to extract spatial information.