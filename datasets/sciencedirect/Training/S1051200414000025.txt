@&#MAIN-TITLE@&#
An empirical study on improving dissimilarity-based classifications using one-shot similarity measure

@&#HIGHLIGHTS@&#
We study enhancing the classification accuracy of dissimilarity-based classifications (DBC).The study is done empirically when measuring the dissimilarity with one-shot similarity (OSS).Two DBC approaches using the Euclidean distance and the OSS distance measures are compared.The latter, albeit not always, enhances the classification accuracy for certain kinds of data.

@&#KEYPHRASES@&#
Statistical pattern recognition,Dissimilarity-based classification (DBC),Semi-supervised learning (SSL),One-shot similarity (OSS) measure,

@&#ABSTRACT@&#
This paper reports an experimental result obtained by additionally using unlabeled data together with labeled ones to improve the classification accuracy of dissimilarity-based methods, namely, dissimilarity-based classifications (DBC) [25]. In DBC, classifiers among classes are not based on the feature measurements of individual objects, but on a suitable dissimilarity measure among the objects instead. In order to measure the dissimilarity distance between pairwise objects, an approach using the one-shot similarity (OSS) [30] measuring technique instead of the Euclidean distance is investigated in this paper. In DBC using OSS, the unlabeled set can be used to extend the set of prototypes as well as to compute the OSS distance. The experimental results, obtained with artificial and real-life benchmark datasets, demonstrate that designing the classifiers in the OSS dissimilarity matrices instead of expanding the set of prototypes can further improve the classification accuracy in comparison with the traditional Euclidean approach. Moreover, the results demonstrate that the proposed setting does not work with non-Euclidean data.

@&#INTRODUCTION@&#
The aim of this paper is to report an empirical result obtained by additionally using unlabeled data together with labeled ones to improve the classification accuracy of dissimilarity-based methods, namely, dissimilarity-based classifications (DBC) [25]. In DBC, defining classifiers among the classes is not based on the feature measurements of individual objects, but rather on a suitable dissimilarity measure among the individual objects. The advantage of this strategy is that it offers a different way to include expert knowledge on the objects in classifying them [10]. A few of the issues we encounter when designing DBCs are as follows: selecting (creating) the prototype subset from a given data set [18,21,26]; reducing the dimensionality of the dissimilarity space [16,28]; solving non-Euclidean problems in the dissimilarity space (pseudo-Euclidean embedding) [10]; increasing the robustness of the dissimilarity space (or combining dissimilarity representations) [17]; optimizing classification (or clustering) based on dissimilarity increments (i.e., differentiation of dissimilarity distances) [2,13].In order to explore the other issues, various strategies have been proposed in the literature. Among them, investigations have focused specifically on generalizing the dissimilarity representation by using various methods, such as feature lines and feature planes [23,24] and hidden Markov models [3]. In [23], the authors enrich (generalize) the dissimilarity representation by using the nearest feature rules. The generalization provided by the feature lines and/or planes covers all the possible intra-class pairs and triplets of prototypes to find the intrinsic geometric information available at the pairwise dissimilarities. The enrichment of the dissimilarity representation is beneficial for a specific structure of data, such as correlated (cigar-like or elongated) datasets having, possibly, a moderately nonlinear structure. In this strategy, however, objects are represented by a vector of dissimilarities with prototype feature lines (or planes) that are computed between objects of the same class. Consequently, the strategy has two drawbacks: the high amount of generated feature lines that increase computational cost [24] and the use of the labels of objects that leads to a supervised learning system.On the other hand, when designing a DBC with a measuring system, we sometimes suffer from the difficulty of collecting sufficient (labeled) training data for each class. Labeled instances, for example, are often difficult, expensive, or time-consuming to obtain, as they require the services of an experienced expert. Meanwhile, unlabeled data, defined as the samples that do not belong to the classes being learned, may be relatively easy to collect, but the use of this type of data is limited. To address this problem, in a learning framework of semi-supervised learning (SSL) [1,4,6,29,32,33], a large amount of unlabeled data, together with labeled data, can be utilized to build better classifiers. Because SSL requires less human effort and results in higher accuracy, it is of great interest both in theory and in practice [14,19,20].In DBC, the SSL strategy can also be considered to improve the classification performance. One of the easiest ways with which unlabeled data contribute to learn DBC classifiers is to simply append them to the representation set. Assume that the cardinalities of a training set, T, and the prototype subset (representation set), P, are denoted by|T|and|P|, respectively. When employing an additional unlabeled data U (where the sample size of the set U is|U|), the cardinality and the dimensionality of the dissimilarity row vectors that result are|T|and|P|+|U|, respectively. Here, a prototype selection method can be utilized to reduce the dimensionality of the dissimilarity space. Consequently, in the traditional feature-based classification (FBC), employing SSL strategy leads to increasing the cardinality of the training data, while, in DBC, utilizing the above strategy results in increasing the dimensionality of the training data. However, as in FBC, it is not also guaranteed that increasing the dimensionality leads to a situation in which the classification accuracy is improved.In order to improve the classification performance of DBC in an SSL fashion, in this paper we use the well-known one-shot similarity (OSS) [30,31] measuring scheme based on the background information of available extra (unlabeled) data. To achieve this improvement, we first compute the confidence levels of the training data with the OSS distance. We then construct the dissimilarity matrices, where the dissimilarity is measured with the averaged OSS confidence levels. In OSS, when given two vectors,xiandxj, and an additionally available (unlabeled) data set, A, a measure of the (dis)similarity betweenxiandxjis computed as follows. First, a discriminative model is learned withxias a single positive example and A as a set of negative examples. This model is then used to classify the other vectorxj, and to obtain a confidence score. Next, a second such score is obtained by repeating the same process with the roles ofxiandxjswitched. Finally, the (dis)similarity of the two vectors can be obtained by averaging the above two scores.The major task of this study is to deal with how the dissimilarity distance can be effectively measured. However, when a limited number of objects are available or the representational capability is insufficient to cover the possible variations of data, it is difficult to achieve the desired classification performance in the dissimilarity representation. To overcome this limitation and thereby improve the classification performance of DBC, in this paper we study a way of exploiting additionally available unlabeled data when measuring the dissimilarity distance with the OSS distance. As in SSL for FBC, we use the easily collected unlabeled data as the background data set, A, with which we can enrich the representational capability of the dissimilarity measures. That is, our goal is to effectively measure the dissimilarity distance with the additional unlabeled data as well as the labeled ones. In DBC, the SSL process is realized in representation stage, while, in FBC, it is implemented in generalization stage.The main contribution of this paper is to demonstrate that the classification accuracy of DBC can be improved by using the OSS measuring technique based on unlabeled data. More specifically, experiments have been performed to demonstrate that the OSS distance measure performs better than the Euclidean distance measure. Here, the additional unlabeled set is used as well, but now differently than for building the set of prototypes: it is used in the distance measure and not in building the dissimilarity space. The remainder of the paper is organized as follows. In Section 2, after providing a brief introduction to DBC and OSS, we present an explanation for the use of OSS in DBC and an SSL-type DBC algorithm. Following this, in Section 3, we present an experimental setup for the traditional DBC and proposed DBC algorithms. In Section 4, we present the experimental results of artificial and real-life datasets. Finally, in Section 5, we present our concluding remarks as well as some feature works that deserve further study.

@&#CONCLUSIONS@&#
In our efforts to improve the classification performance of DBC, we empirically evaluated an approach using the OSS measuring technique based on the background information of available unlabeled data. After dividing each data set into the subsets L, E, and U, we constructed dissimilarity matrices through the Euclidean distance or the OSS distance using all three subsets or only one part. The proposed approach, namedDOSS, was tested on two artificially generated Euclidean and non-Euclidean datasets (i.e. Difficult Data and Balls3D) and thirteen UCI/SSL-type datasets. The results obtained were compared with those of three traditional approaches, namedDL−l2,DLU−l2, andDLE−l2. Here,DL−l2represents a traditional DBC, in which the dissimilarity distance was measured in the Euclidean distance using L only, whileDLU−l2denotes a DBC extending the set of prototypes using U as well as L, and measuring the dissimilarity distance in the Euclidean distance.DLE−l2is similar toDLU−l2but uses E instead of U.Our experimental results, obtained from the numerical and statistical (t-test) comparisons, demonstrate that the classification accuracy of the NN classifiers designed inDOSSapproach is better than that of the other approaches when the cardinality of the prototype subset (P) has been appropriately chosen. This means that, in DBC for certain datasets, the OSS distance measure performs better than the Euclidean distance measure as well as the approaches that extend the set of prototypes. However, the results obtained from the experiment on Balls3D data demonstrate that the proposed approach does not work with non-Euclidean data. Meanwhile, the size of U (amount of unlabeled data) does not play a significant role. In order to render the evaluation more complete, two ways using theDOSSmatrix were subsequently investigated. However, the experimental results obtained show that there is no absolute winner in terms of classification accuracies. Moreover, based on a study on the embedded pseudo-Euclidean space for theDOSSmatrix, a remarkable relation between classification accuracies and non-Euclidean properties could not be found.Although we have shown that DBC can be improved using the OSS measure, many tasks remain unexplored. One of them is to further improve the classification accuracy by selecting an optimal, or nearly optimal, cardinality of P (and U) and utilizing various distance learning techniques in theDOSSapproach. Also, it is not yet clear which types of significant datasets and classifiers are more suitable for the DBC using OSS. Next, even the class-label of U is not used in the training phase, U as well as both L and E are selected from the same data. As a result, the three subsets share the same distribution characteristics. Thus, a question arises: is the classification accuracy of theDOSSapproach superior or inferior to that of the approach when U is collected from a completely different data set? In addition, why does SVM designed inDOSSnot work for certain applications? The investigation of the underlying reason for these remains unchallenged. Finally, the proposedDOSSapproach lacks details to support its technical soundness, while comparisons are done based on fairly simplistic models. In conclusion, the problems of theoretically investigating the OSS measuring technique invoked for DBC and developing a more scientific model for comparison remain to be challenged.