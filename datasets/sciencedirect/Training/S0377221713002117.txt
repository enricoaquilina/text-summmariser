@&#MAIN-TITLE@&#
An enumeration procedure for the assembly line balancing problem based on branching by non-decreasing idle time

@&#HIGHLIGHTS@&#
A new branch and bound is proposed for the simple assembly line balancing problem.A novel flow based logical test and a strengthened dominance rule are put forward.The results from the proposed algorithm outperform those provided by the previous procedures found in the literature.

@&#KEYPHRASES@&#
Branch and bound,Manufacturing,Assembly line balancing,

@&#ABSTRACT@&#
In this article, we present a new exact algorithm for solving the simple assembly line balancing problem given a determined cycle time (SALBP-1). The algorithm is a station-oriented bidirectional branch-and-bound procedure based on a new enumeration strategy that explores the feasible solutions tree in a non-decreasing idle time order. The procedure uses several well-known lower bounds, dominance rules and a new logical test based on the assimilation of the feasibility problem for a given cycle time and number of stations (SALBP-F) to a maximum-flow problem.The algorithm has been tested with a series of computational experiments on a well-known set of problem instances. The tests show that the proposed algorithm outperforms the best existing exact algorithm for solving SALBP-1, verifying optimality for 264 of the 269 benchmark instances.

@&#INTRODUCTION@&#
An assembly line is a production system most commonly used in the flow-line production of goods on an industrial scale. It consists of m workstations connected by a conveyor belt or similar mechanical device. As unfinished products travel from station to station, certain operations are performed to obtain the final product. The indivisible operations necessary to finish a product are known as tasks j=1,…,n and require a fixed operation time tjto be completed.The conveyor belt speed determines the output rate and the time in which each task must be completed before moving on to the next station. The available time is the same for every station and is referred to as cycle time c. The total operation time of the tasks assigned to each station can never exceed the cycle time.Additionally, some tasks may not be able to start until another task has been completed. These precedence constraints must be fulfilled (i.e., if any task i assigned to station k precedes a task j assigned to station h, then h⩾k must hold).The simple assembly line balancing problem type 1 (SALBP-1) consists of assigning each task to a station and fulfilling the precedence constraints without exceeding the given cycle time c. The goal of this optimisation problem is to maximise the line efficiency by minimising the number of stations used m. This process is equivalent to minimising the total idle time for all stations.Note that SALBP-1 is a reversible problem. As such, the precedence constraints may be reversed to obtain a different instance, and any solution found for the new instance can be converted to a solution for the original instance. Tasks can also be assigned to workstations in reverse order, and the initial or final workstations can even be constructed simultaneously.Before describing the proposed algorithm in further detail, we present a quick review of the existing literature concerning SALBP-1.Over the last 60years [8], numerous procedures have been proposed for solving this problem. A detailed review is available in [15]. These procedures may be classified into three groups:•Constructive (or greedy) algorithms, based on assigning tasks to stations using a priority rule. These procedures rarely yield an optimal solution for large instances, but they can offer sufficient solutions for practical purposes in a short computation time [19].Enumerative algorithms, which have been proven to yield the best results for SALBP-1. Enumerative algorithms may be classified as truncated, graph-based and tree-search-based procedures. The truncated algorithms are heuristic procedures [5,9], while graph-based algorithms are usually dynamic programming approaches [2,7,11]. Among tree-search-based procedures, branch-and-bound procedures perform particularly well [10,12,16].Metaheuristic procedures, which have the advantage of being easily applicable to general problems, although their results are not usually as good as those obtained by exact procedures. This group includes Tabu Search procedures [17], ant colony optimisation [1] and genetic algorithms [6].Our proposed algorithm belongs to the second group: enumerative algorithms. It is a station-oriented, bidirectional branch-and bound procedure with a new ramification strategy, which enumerates feasible task assignments to stations – identified as the nodes of the branch-and-bound tree – in a non-decreasing idle time order. This branching method allows the use of a strengthened variation of Johnson’s dominance rule [12]. The algorithm also includes Jackson’s dominance rule [11] and the Schrage–Baker labelling dominance rule [18]. The bounding strategy is based on a well-known set of seven lower bounds [14] and a new logical test based on the well-known maximum flow problem. Additionally, several preprocessing rules are applied to the problem to increase the efficiency of the algorithm.The remainder of this manuscript is organised as follows. Section 2 details the preprocessing of the problem. Section 2.1 focuses on the lower bounds, reduction techniques and logical tests used in the algorithm, while Section 2.2 describes a greedy heuristic and reviews the well-known Hoffmann heuristic, both of which are used to obtain upper bounds. Section 2.3 summarises the preprocessing step by combining the components described in Section 2. In Section 3, we describe the branch-and-bound procedure in further detail: the enumeration procedure is described in Section 3.1, the bounding strategies during the search tree are introduced in Section 3.2, the dominance rules are described in Section 3.3, and the steps performed by the branch-and-bound algorithm are schematised in Section 3.4. Section 4 presents the results obtained in the computational experience with the established benchmark set of problem instances. Finally, Section 5 gives a brief summary and some conclusions. Table 1shows the notation that will be used throughout the paper.Our procedure uses a well-known set of seven lower bounds, which will be referred to using Scholl’s notation [14]. These lower bounds will be used to prove whether a known solution is optimal and to preprocess the problem. Their use in the bounding strategy inside the branch-and-bound procedure will be further described in Section 3.2.1.Four of these bounds are an assimilation of the SALBP-1 problem to a BPP-1. The first and most intuitive bound (LB1) neglects the precedence and integrality constraints; it can be defined as the rounded-up sum of all of the operation times divided by the cycle time. The second bound (LB2) divides tasks into groups by their operation times: the first group (J1) includes all tasks j that verify tj>c/2. The number of tasks in this group is a bound itself because none of these tasks may share a station with another task included in J1. The bound may be strengthened by adding half the number of tasks included in J2, a second group composed by tasks with an operation time of exactly half the cycle time.A third bound (LB3) can be defined similarly to LB2 by dividing tasks into groups considering operation times in thirds of cycle time. Based on the same concept of counting tasks with specific operation times, another bound can be defined [3]: LB6 divides tasks into three groups considering halves and thirds of the cycle time, sorts them by duration and successively tries to assign them to virtual stations. Adding a minimum number of stations for the tasks that have not been assigned further restricts this bound.A fourth bound (LB4) can be defined by relaxing the problem to a one-machine scheduling problem [12]. By applying this bound to both the original and reversed problem, we obtain the heads and tails of every task. The earliest Ejand latest Ljstations to which each task may be assigned can be calculated given an upper bound m and the aj(heads) and nj(tails), respectively:(1)Ej=⌊aj⌋+1(2)Lj=m-⌈nj⌉+1To further restrict the following bound, the latest stations may be calculated as the latest to which the task can be assigned to improve the current solution by considering a more restrictive upper bound (m=m−1):(3)Lj=m-1-⌈nj⌉+1=m-⌈nj⌉If any task j verifies Ej>Ljfor a number of stations m′, then a feasible solution with m′ stations cannot exist. The minimum m′ for which all tasks verify Ej⩽Ljis a fifth bound (LB5). Our algorithm also uses the classical formulation of LB5: for each task, the sum of hj, zjand processing time pjis obtained. The largest of these values constitutes a fifth lower bound (LB5).Finally, a seventh lower bound (LB7) is found by assimilating the SALBP-1 problem to a SALBP-2 (which consists of minimising the cycle time for a given number of stations). For an m′ number of stations (the most restrictive lower bound), a minimum number of tasks bound to share a station can be found. This number is used to calculate an upper bound for the cycle time c(m′). The first m′ to verify c(m′)⩾c is a lower bound to the original problem.The first reduction rule increases the task operation time, if possible. Known as the Extended Duration Augmentation Rule, this rule constitutes an extension of the Johnson dominance rule [12]. Considering no precedence constraints and known Ejand Ljfor all tasks, the set of tasks that can share a station with a task j is composed by those tasks i for which Ei⩽Ljand Ej⩽Li. If no combination between j and the tasks in this set fills the station completely, tjcan be increased by the difference between the cycle time and the maximum possible load. The problem can be solved as a 0–1 knapsack problem, considering the task operation times as both weights and values and a maximum load equal to the cycle time, as observed in Martello and Toth [13].The well-known maximum load rule [11] is also applied: any node that includes a station loaded with a subset of tasks of those assigned in a previously explored partial solution can be fathomed. This rule does not imply an explicit comparison between partial solutions because the maximality of station loads can be checked while the solution is constructed [12].Another reduction rule consists of prefixing tasks for each station [14]. Let Ejand Ljbe the earliest and latest stations to which the task j may be assigned to find a solution with m−1 stations. If a task j verifies Ej=Lj=k, it can be automatically assigned to station k. Task prefixing alters the heads and tails of these tasks. If task j is prefixed to station k, then(4)aj=k-1(5)nj=m-kA further reduction rule is applied to add precedence constraints [5]. Considering any two tasks j and i that are not related by precedence, such a constraint may be added between them if Lj⩽Ei. If this condition is fulfilled, these two tasks cannot share a station and neglecting this precedence constraint cannot lead to a better solution.A new logical test is proposed to prove whether a feasible solution can exist with m−1 stations. This test is based on the assimilation of the SALBP-F (given c cycle time and m−1 stations) as a maximum flow problem or, alternatively, as a transportation problem.Given a SALBP-1 instance and an upper bound with m stations, considering Ejand Ljknown for all tasks j (which indicate the earliest and latest station, respectively, to which the task j may be assigned to obtain a solution with m−1 stations), the problem can be assimilated to a maximum flow problem.The graph related to the maximum flow problem is defined by the following elements:•A starting node α, an ending node ω, n nodes related to the tasks and m−1 nodes related to the stations.An edge defined from α to each node 1 to n related to the tasks, with capacity equal to operation time of the task.An edge defined from each node related to the m−1 stations and ω, each capacity equalling the cycle time.An edge defined from each node related to a task j and each node related to a station k that verifies Ej⩽k⩽Lj. The capacity of this edge is the operation time of task j.A solution with m−1 stations can be proven not to exist if the maximum flow problem related to this graph has a solution with flow smaller than ∑j=1,…,ntj. In such a case, it is not possible to assign part of the operation time corresponding to at least one task to m−1 stations. Let us note that if nodes α and ω, as well as their corresponding incoming and outgoing edges were removed, and all edges were set to a fixed cost, the resulting graph would correspond to a transportation feasibility problem.This situation can be observed as an extension of LB1 in the following aspects: (1) LB1 is solved from station 1 to each station with the tasks that must be assigned to that station or an earlier station and (2) the earliest station per task is verified to be less than or equal to the station to which is assigned the operation time of the task, thus avoiding unfeasible assignments.The problem can be solved with a maximum flow algorithm, but a more efficient method can be applied, as observed in Algorithm 1. The method uses a special ordering of tasks by non-decreasing latest station Lj. To break ties between two tasks, those with a lower earliest station Ejare prioritised. If the tie persists, the tie is broken lexicographically.If this test does not find a feasible solution, the task ordering guarantees that a previously assigned task cannot assign its operation time to stations later than Lj. Thus, flow cannot be redirected by edges connected to later stations. Additionally, the task ordering guarantees that each task assigns its flow to the first available station, which also prevents redirection to earlier stations. Both statements guarantee that no augmenting path exists.This procedure may be applied using the inverted precedence graph to obtain a new dominance rule. To do so, the task ordering is modified by ordering the tasks by non-increasing Ej. To break ties between two tasks, those with a greater latest station Ljare prioritised. If the tie persists, it is broken lexicographically.Algorithm 1. Maximum Flow Testfori=1→mdoIdleTimei←cend forfori=1→ndotask←orderitime←dtaskfor (station=Etask→Ltask) and (time>0) doToAssign←MIN{IdleTimestation; time}IdleTimestation←IdleTimestation−ToAssigntime←time−ToAssignend foriftime>0 thenreturn(Dominated)end ifend forreturn(NotDominated)A first upper bound for the problem is obtained by a constructive procedure, based on prioritising the largest tasks. For each station, the largest task that fulfils the precedence constraints and with operation time not greater than the idle time, is sequenced until the station is full. The procedure then opens a new station, which is filled in the same manner, continuing until all tasks have been assigned. This procedure ensures a feasible solution in a very short computation time, providing a value for m that is used extensively in the preprocessing steps. Another solution may be found by applying the same constructive procedure on the reversed problem. This upper bound is only kept if it is more restrictive than that offered by the direct method.A second upper bound is obtained using the heuristic developed by Hoffmann [9], which is a truncated enumerative method. Starting with the first station, the algorithm enumerates all feasible task assignments to said station k. Only the partial assignment with the lowest idle time is kept. This procedure is repeated for station k+1, considering the remaining tasks, until all tasks are assigned.The Hoffmann heuristic can be seen as a greedy method, where each decision selects the best station with a heuristic rule based on minimising idle time. It is used in the present algorithm to obtain a second and improved upper bound. Feasible assignments are enumerated using an adaptation of the procedure developed by Fleszar and Hindi [5]. This heuristic can be applied in a forward or backward direction (or both directions simultaneously). In the implementation, the procedure is applied in both directions, keeping the best solution obtained.Before starting the branch-and-bound algorithm, several preprocessing procedures can be applied to reduce the problem, verify optimality and increase the algorithm efficiency.The preprocess first calculates a first upper bound with the previously described constructive heuristic. Next, the seven lower bounds are calculated in addition to heads and tails for each task and the earliest and latest station to which they may be assigned. If the solution offered by the greedy heuristic has not been proven optimal, extended duration augmentation and precedence constraints addition rules are applied, as described in Section 2.1.2. Any modification in the precedence restrictions and operation times changes the lower bounds, and any change in LB4 in turn changes the earliest and latest stations to which each task may be assigned. Additionally, any such change could further restrict the number of tasks that may share a station, thus increasing some of the durations and adding precedence constraints. Therefore, the reduction rules and the lower bounds calculations are performed iteratively until no further changes appear.After the reductions, a second upper bound is calculated using the Hoffmann heuristic, which uses the reduction rules from Section 2.1.2. If the solution found is an improvement over the first upper bound, the earliest and latest stations to which each task may be assigned are modified. This change alters the reduction rules, possibly modifying some of the lower bounds and allowing the Hoffmann heuristic to offer a better solution.Note that the aforementioned preprocessing steps are also executed whenever a new solution is found, including during the branch-and-bound procedure.The enumeration strategy in the proposed algorithm is one of its most distinctive characteristics: the procedure applies a station-oriented, depth-first search in which the descending nodes are built for each node and the node with a maximum load is chosen for branching. If no improved solution is found in the developed branch, the algorithm backtracks and chooses the undeveloped node with a larger local load.The following example illustrates this strategy; see Section 3.4 for a complete description of the procedure. Fig. 1presents a precedence graph with c=10 (LB1=integer by excess (43/10)=5). The enumeration tree created by this branching technique (considering only the forward direction) is shown in Fig. 2.The first node is created by assigning task 1 to the first station, as no other task can be assigned (B1={1}). The descending nodes are built ({3,4,6}, {2,3}, {2,4}, {3,4} and {3,6}), and B2={3,4,6} (with load D2=10) is selected for branching. The descending nodes are built, and the node with the maximum load is chosen for branching (B3={2,5}). The next node is B4={7,8}, which also constitutes a maximum load. Lastly, node 5 is constructed: B5={9}.In this example, the optimal solution has been found (UB=LB). However, if we had assumed that optimality had not been proven, the enumeration strategy would continue. The procedure would backtrack to node 4, but no other sequence for station 5 exists. Backtracking to node 3, no improved sequence can be found for station 4 (the current sequence and its subsets are the only feasible assignments and assigning a subset of a previous solution can never lead to an improved solution, as defined by the maximum load rule [10]). Tracing back to node 2, the procedure explores node 6: B3={2,7}, with a load of 9. After proving that no improved solution can be obtained in this branch (see the description of bounds in Section 3.2), the procedure backtracks to node 1 and explores the next node with the largest load (node 7): B2={2,3}, with load 9. When backtracking again to node 1, the procedure chooses node 8, with load 8 (B2={2,4}) for branching.Enumeration continues until all descending nodes for node 1 have been fathomed. Tracing back to node 0, as task 1 is the only assignable task for station 1, the procedure is terminated and the solution is proven optimal.In an exact procedure, both the forward and backward procedure will offer the optimal solution for the problem. However, as shown by Scholl and Klein [16], the search tree can be considerably smaller in one direction.Thus, it is necessary to establish a criterion to determine which direction is preferable before generating the following node. Several such criteria can be considered, such as developing the station with a lower cardinality of potentially assignable tasks or a criterion based on the sum of operation times of the potentially assignable tasks. Our algorithm uses the bidirectional rule defined by Scholl and Klein [16] due to its superior performance.Let kfbe the earliest unloaded station, kbthe latest unloaded station, Bkfthe set of tasks that are potentially assignable to station kf(this set is composed by tasks j which verify Ej⩽kf⩽Lj) and Bkban analogous set of tasks that are potentially assignable to station kb.An average task time (Tk) for potentially assignable tasks can be defined for any station k as follows:(6)Tk=∑j∈BktjLj-Ej+1|Bk|According to this branching rule, a forward step is taken if Tkf>Tkbor if Tkf=Tkband |Bkf|⩽|Bkb|. Otherwise, a backward step is taken.To reduce the computational effort, thereby increasing the efficiency of the procedure, the tasks can be ordered such that the first tasks checked are the most likely to be assigned to the current station, [2].The tasks that are potentially assignable to the current station are ordered according to the following criteria:•If the node is developed with a forward step, the tasks have a non-decreasing earliest station (Ej) order. If there is a tie, the tasks with a greater latest station (Lj) are prioritised. If two tasks tie in both conditions, the largest task (greatest tj) appears first. If the tie persists, it is broken lexicographically.If the node is developed with a backward step, the tasks have a non-increasing latest station (Lj) order. If there is a tie, the tasks with a lower earliest station (Ej) are prioritised. If two tasks tie in both conditions, the largest task (greatest tj) appears first. If the tie persists, it is broken lexicographically.As previously stated, the main difference between the proposed algorithm and the exact procedures developed to date is the enumeration strategy: this strategy creates descending nodes for each node and explores them in order of non-increasing loads. To this end, the enumeration process develops and explores all the nodes with load equal to the cycle time, then all the nodes with load c−1, and so forth.This enumeration technique can be ineffective because it requires that all possible assignments are enumerated for every feasible load, which implies some repeated calculations. Furthermore, not every possible load is feasible: if no combination of potentially assignable tasks to the current station can fill a certain load, then attempting to create and explore nodes with that load is pointless.To avoid such inefficiency and unnecessary calculations, the procedure creates a list of potentially feasible loads for every station constructed and performs the enumerative process only for potentially feasible loads, from largest to smallest. Such a list can be obtained by solving the related 0–1 knapsack problem, as observed in Martello and Toth [13], with the potentially assignable tasks for the current station.In this algorithm, several bounding techniques are applied to detect as rapidly as possible if the current node cannot lead to an improved solution, and stop its development. Additionally, some of the bounds and constraints are strengthened and updated throughout the algorithm.The easiest way to detect if the current node cannot lead to an improved solution is to check the local lower bounds. Except for LB4, the same set of lower bounds used to preprocess the problem data will be used to obtain the local lower bounds.The local lower bound for a given node is a lower bound on the number of stations required by the currently unassigned tasks. It may be calculated using any of the lower bounds described in Section 2.1. Only the most restrictive local lower bound (the greatest in value) is considered. If for any developed node, the sum of said local lower bound and the number of stations enumerated is greater or equal to the current upper bound m, the node is fathomed.Additionally, LB1 can be strengthened throughout the enumeration using a new strategy described in Section 3.2.3.The earliest and latest stations to which a task can be assigned for a solution with m−1 stations to exist are calculated before starting the branch-and-bound procedure and are used throughout the algorithm to prefix tasks and decide whether a node should be fathomed. However, the value of the earliest and latest stations may be updated while exploring a partial solution.Let mfand mbbe the number of stations enumerated in both directions (forward and backward) for a given node, BPjthe set of unassigned precedents of task j and BFjthe analogous set of followers. The earliest and latest stations can be calculated for each task and node as follows:(7)Ej=maxEj;mf·c+tj+∑i∈BPjtic(8)Lj=minLj;mb·c+tj+∑i∈BFjticThis update is based on the local bound calculated with LB1, and the newly found values may be more restrictive than the earliest and latest stations resulting from solving the one-machine scheduling problem (LB4).LB1 may be improved during the branch-and-bound procedure by solving the 0–1 knapsack problem related to the unloaded stations. For each non-constructed station, a combination of potentially assignable tasks with a smaller idle time may be found. If this idle time is greater than zero for at least one station, the sum of all such idle times can be added to the local LB1 numerator.Let kfbe the earliest unloaded station and kbthe latest. LB1 may be strengthened by solving the 0–1 knapsack problem, as observed in Martello and Toth [13], for each unconstructed station from kfto kb. For each station, the difference between the cycle time and the maximum possible load obtained is added to the local LB1 numerator. After this update, if LB1 is greater or equal to the current upper bound, the procedure backtracks to a previous node.The main advantage of dynamic programming approaches versus branch-and-bound algorithms is that the former ensures that already explored partial solutions are never developed. To avoid both the development of any node that is equivalent to an already explored node and exploring nodes that cannot lead to an improved solution, several dominance rules are applied.The modified Extended Duration Augmentation Rule (EDAR) may be applied while the node is enumerated. For every node and every task j, the combination of tasks offering the maximum load is found. If said maximum load is less than the cycle time, the difference may be added to the duration of j. However, solving the related knapsack problem for every node entails repeated calculations, which should be avoided. To that end, for each node and task, the combination of non-sequenced tasks offering the maximum load is stored.For every node and task that has not been assigned (j), the algorithm verifies whether said combination of tasks has changed (that is, if any of the tasks belonging to that set have been assigned). If so, the combination is recalculated and the duration of j is increased accordingly. If the set has not changed, the duration of j is kept from the previous node.Note that EDAR must precede any bound calculations because working with improved durations may restrict lower bounds and dominance rules.Additionally, with the new operation times, the partial solution might be proven unfeasible by the maximum flow test described in Section 2.1.3. Thus, it is convenient to redo the test for the unconstructed stations, fathoming the current node if the partial solution is proven unfeasible.The Jackson dominance rule [11] is based on the following definition. A task i may dominate a task j if all of the following conditions are fulfilled: (1) no precedence relation exists between them; (2) the successors of j are a subset of the successors of i; and (3) the operation time of j is not greater than the duration of i. If both the successors and the operation times of two tasks are the same, the lower-numbered task is said to dominate the other.Given a sequenced station k with a set of assigned tasks Bk, this partial solution is dominated if the following conditions are fulfilled: (1) at least one task j belonging to Bkcan be dismissed from the solution and substituted by an available task i; (2) this task i dominates j according to the previous definition and fulfils all the precedence constraints, and (3) the total operation time for station k does not exceed the cycle time.If every successor to task j is a successor of i, the solution cannot be improved by performing j before i, which means that j is potentially replaceable by i. The last condition (tj⩽ti) ensures that the idle time is not increased by the replacement.To apply this dominance rule, the dominances between tasks are stored before starting the branch-and-bound procedure. Whenever a partial solution is found, before generating the descending nodes, the following conditions are checked: (1) the idle time is positive; (2) any task j assigned to the current station is dominated by an unassigned task i; (3) said task i is assignable (does not violate precedence constraints and has a duration that does not exceed the idle time); and (4) the sum of the idle time and the duration of j is greater than or equal to the duration of i.If these four conditions are verified, the node is fathomed.This dominance rule [18] consists of identifying partial solutions containing the same subset of tasks as a previously sequenced solution. If the tasks assigned in one node are identical to those assigned in a previous node and the former does not require fewer stations than the latter, the first solution is identical to or better than the second.To check whether a partial solution is identical to a previously enumerated solution, a method of storing partial solutions is needed. A partial solution will be defined by the tasks assigned and the number of stations needed to assign them. To that end, a binary tree of depth n (number of tasks) is created. For every partial solution enumerated so far, a branch of the tree will be developed while checking for dominance.Each time the enumeration procedure finds a node and before branching using the node, the procedure checks whether the partial solution has been already explored by comparing it to those stored in the binary tree. If the partial solution is dominated by a previously enumerated solution, the descending nodes are not created.This method may present memory issues for the largest problems due to the need to store every partial solution found. This challenge can be overcome by limiting the size of the stored tree. The implementation reserves 1gigabytes of memory to store partial solutions. When the memory is not completely filled, both the search for dominating partial solutions and the storage of new partial solutions are performed. Once the memory limit is reached, the algorithm only searches for dominating partial solutions. If no dominating solution is found, the procedure considers the partial solution not to be dominated but does not store it in memory.The branching procedure consists of enumerating all feasible sequences for every station, applying techniques to increase the procedure efficiency. Before beginning the enumeration, a zero partial solution is created, in which all of the variables are initialised. The recursive function that creates the node k proceeds as follows:1.The forward or backward construction step is determined (Section 3.1.1).The current best solution is checked for optimality: if the best lower bound equals the best solution found so far, stop.The tasks that have not yet been assigned are noted, and their durations added. If this sum is not greater than the cycle time, a new solution has been found and steps 3.a to 3.c are applied; otherwise, continue.a.Tasks not yet assigned are assigned to the last station, and the sequence is stored. If the solution is proven optimal, stop.Apply preprocessing steps with new upper bound value. If the solution is proven optimal, stop.Due to preprocessing changes, some of the partial solutions in construction might be incongruous. The last created node in which all assignments are consistent with the newly calculated information is found and flagged. The recursive function is forced to return until the flagged node, and continues developing from that node.The earliest and latest stations are updated (Section 3.2.2). If any task j verifies Ej>Lj, fathom the node (the function returns).Flow test is conducted, task durations are increased (Section 3.3.1), and lower bounds are calculated (Section 3.2.1). If the local lower bound is equal to or worse than the best known solution, the node is fathomed.Task prefixing (Section 2.1.2) is performed. If the idle time of the current station is less than zero, the node is fathomed. If the idle time equals zero or no other task fits the current station, the optimal load for this node has been found, and the branch-and-bound function is called for station k+1 with the current partial solution.LB1 is strengthened, as described in Section 3.2.3. If LB1 is greater than or equal to the current upper bound m, the node is fathomed.The feasible loads for the current station are calculated, as described in Section 3.1.3.All tasks that are potentially assignable to the current station are arranged in the order described in Section 3.1.2. Let us note that this ordering is not dependent on the feasible loads obtained in step 8.From every x from cycle time c to 0; use the Hoffmann heuristic (Section 2.2) to generate all feasible assignments with no idle time if the cycle time was equal to x.a.For every sequence with no idle time, apply the maximum load (Section 2.1.2), Jackson (Section 3.3.2) and Schrage–Baker rules (Section 3.3.3). If it verifies all rules, the branch-and-bound function is called for station k+1 with the current partial solution.If zero load is reached, the current node is fathomed and it returns to a previous call to the function.To assess the quality of the proposed bounds and the solution procedure, the algorithm was programmed in C++ and compiled using the GNU GCC compiler, version 4.2.1. A Macintosh MacBook Pro with a 2.33gigahertz Intel Core 2 Duo processor and 2gigabytes of RAM running Apple’s Mac OS X operating system, version 10.6.8, was used for the experiments. Neither the implementation nor the compiler uses threads or other forms of parallel code; thus, the computer can be considered comparable to a single processor clocked at 2.33gigahertz.The implementation was tested using an instance set derived from SALBP-1, which is available at www.assembly-line-balancing.de. This instance set is composed of 269 instances that include between 8 and 297 tasks.The implementation, and some of its variations are compared with three algorithms from the literature: SALOME [16], the state-of-the-art branch-and-bound procedure for this problem, the BDP algorithm [2], the state-of-the-art heuristic for this problem, and the Beam-ACO metaheuristic [4]. The results reported from SALOME are not those reported in [16] but those found on the webpage where the instance set is available. A 3gigahertz Intel Pentium IV with 1.5gigabytes of RAM running Windows XP was used in their experiment, with a limited running time of 3600seconds. The results of the BDP and Beam-ACO procedures are those found in their respective articles. The computer used in the experiment for the BDP was the same used in this manuscript, while the BEAM-ACO was run on an AMD64X2 4400 processor with 4gigabytes of memory. As BDP depends on two control parameters, different values are reported for this method.We consider all of the used computers to have similar characteristics, as all of them are modern commodity computers; in addition, the differences between compilers (SALOME was coded in Pascal) and operating systems are considered negligible. Table 2shows the combined results for all instances. The number of best known and optimal solutions are reported in addition to the average and maximum running time measured in real time (not CPU time). The results reported for BEAM ACO correspond to the best solution found after ten independent runs of 360 CPU seconds each.The results show that our algorithm outperforms the previous exact method SALOME, considered the state-of-the-art exact algorithm in the literature, in terms of number of optimal solutions verified as well as in the quality of non-verified solutions, as stated by the number of best known solutions found by both algorithms. Additionally, the algorithm finds and it is able to verify more optimal solutions than SALOME even when the algorithm is limited to shorter running times (600seconds in comparison to 3600seconds).When compared with the best performing heuristic procedures, our exact algorithm outperforms Beam-ACO in terms of number of best solutions found, but it is slightly worse than BDP (the proposed algorithm reports a worse solution for 1 of the 269 instances). Consequently, we can state that the exact algorithm can obtain comparable results to those of the heuristic procedures and, as it is an exact algorithm, it provides optimality verification for most of the solutions found.To assess the impact of the different components of the algorithm in the quality of the solutions obtained, four versions of the proposed exact algorithm were tested, based on the use of two key components of our proposal: (1) elimination of flow test and task duration rules in step 5 of the recursive function from Section 3.4 and (2) the usage of an ordered search for feasible loads, executed in step 10 of the recursive function. The eliminations on step 5 require no further change on the general structure of the remaining components, but the elimination of the ordered search for feasible loads requires the removal of step 8 and the substitution of step 10 for another method to structure the search.The modified step 10 uses a depth-first, laser search where every time a partial solution for the station is constructed, the maximum load, Jackson and Schrage–Baker rules are applied. If the partial solution verifies all the rules, the branch-and-bound recurrence function is called for station k+1 with the current partial solution. All partial solutions will be explored in the order they are constructed.The four combinations, based on the usage of each element, were executed with a time limit of 3600seconds per instance to assess the quality of each component and its interaction. Table 3reports the results of each of the variants.The results show that the each component has some importance on the results provided by the algorithm, being the most important feature the proposed order to search partial solutions. It is worth mentioning that the basic version without the use of both rules performs worse than the original SALOME code, highlighting the importance of the local lower bound method used by SALOME, or the proposed ordered search, in comparison to the basic depth first search method.Finally, Table 4shows the individual results for the harder instances from the set. The instances whose running times exceed 600seconds for any of the exact algorithms are reported. The final lower and upper bound and the running time for the instance (or the time limit if it is reached) are reported. The results show that even if the new procedure obtains more optimal solutions than SALOME, it behaves worse for some instances (the most notorious is Scholl, with a cycle time of 1483, for which SALOME finds the optimal solution easily, while the proposed algorithm does not find an optimal solution within the 3600seconds time limit).Please note that the new algorithm uses stronger and more time intensive preprocessing rules, which have a positive effect on the average but may behave poorly for some instances.This article proposes a new and efficient bidirectional branch-and-bound procedure for solving SALBP-1. Its most distinctive characteristics are a new enumeration strategy and new logical tests. The enumeration strategy is a depth-first search in which the node with the largest load among the descending nodes is chosen for ramification. The new logical tests include a task augmentation rule based on the knapsack problem and the assimilation of the related SALBP-F to a maximum flow problem. These new features, along with the problem preprocessing, the bidirectional criteria and strong bounding techniques, result in smaller search trees and, consequently, in shorter computation times.Computational results show that the proposed algorithm outperforms the best existing exact procedure for SALBP-1 [16]. Our new proposal offers the optimal solution for 264 out of 269 instances studied. Furthermore, the procedure obtains the best-known solution for 267 of these instances.Our results suggest that exploring the nodes in non-decreasing idle time can obtain better solutions, even in shorter running times.

@&#CONCLUSIONS@&#
