@&#MAIN-TITLE@&#
An efficient memory control method for video and image processing in digital TV

@&#HIGHLIGHTS@&#
The proposed scheme distributes contiguous lines of data to multiple banks of SDRAM.It reduces the waiting cycles while reading blocks of data in rectangular shapes.It can be implemented by exchanging several MSBs and LSBs of row addresses.It does not increase of hardware complexity of memory controllers.It does not require re-design of image signal processors in digital TVs.

@&#KEYPHRASES@&#
Memory controller,Image signal processing,Address generation,SDRAM,

@&#ABSTRACT@&#
High definition (HD) and ultra-high definition (UHD) digital TV require high-resolution images and lots of data transfers between processors and memory devices often become the bottleneck of the system. Video and image signal processing usually require blocks of square or rectangular shaped pixel data for signal processing. It requires frequent precharging and activating new rows, and results in extra latencies for reading and writing pixel data in memory devices. This paper proposes an efficient memory controller for video and image processing to reduce the latencies for reading and writing blocks of pixel data. The controller stores a frame of pixel data by distributing contiguous lines of pixel data to multiple banks in sequence. Its efficiency is enhanced more with an interface protocol such as AMBA AXI in which outstanding transactions are allowed. Memory controllers according to the proposed scheme are designed and the performance and the efficiency are compared with the previous works.

@&#INTRODUCTION@&#
A digital image consists of two-dimensional array of pixel data and a video consists of multiple digital image frames. The number of pixels in an image frame depends on the resolution of image. The resolution of digital TVs has increased from standard definition (SD, 720×480) to ultra-high definition (UHD, 3840×2160 and 7680×4320) according to the demands of high quality videos. Video and image processing operations usually require blocks of two-dimensional pixel data in a frame [1]. The size of the block varies from 2×2 pixels to 128×128 pixels depending on the image processing operations [1,2]. The shape of the block is a square or a rectangle.The size of pixel data in one frame of 4k UHD image is about 33MB for 32bit RGBA format. In general, the pixel data are stored in the memory according to the same shape as the frame of an image in order to reduce the amount of calculation to obtain addresses for reading and writing. As a result, it requires the larger memory space for the pixel data of a frame than 33MB because some memory spaces are unused unless the numbers of vertical or horizontal pixels are coincident with the powers of 2. In addition, several frames of pixel data are required for lots of image and video processing, and the memory space for frame data is large in most cases. The memory devices for frame data are usually SDRAM installed on the same PCB as off-chip devices. There are waiting cycles when the next data are stored in a different row in DRAM devices. The pixel data of a frame and therefore a block are usually stored in several contiguous rows of a bank in two-dimensional shape. New rows are opened and closed several times while reading a block of pixel data, and the waiting cycles are accumulated. In order to solve the problem, required data can be read to a buffer memory in advance so that they can be fed to processing units immediately. As the size of a block becomes larger, the size of the buffer memory need to be larger. In addition, prefetching pixel data using a buffer memory is not applicable when the addresses of the data for the next processing are not known in advance.In order to eliminate changing rows when reading or writing a block data, the two-dimensional array of the block can be converted to a one-dimensional array so that the block data can be stored contiguously in a row. However, the waiting cycles still arise when the size of blocks are variable, for example, in compressing and decompressing movies because the data of larger blocks other than basic blocks may not be contiguously stored. The block array conversion method sometimes degrades the performance of memory access. For example, when neighboring pixel data are required for motion compensation of a macroblock in H.264 decoder, the neighboring blocks of the block need to be read although all pixels of the neighboring blocks are not necessary. The converted one-dimensional array needs to be converted to a 2-dimensional array again for a display unit. Moreover, complex calculation for addresses and the corresponding datapath circuits are required. The array conversion method seems to work for a specific processing of blocks with a fixed size. However, the waiting cycles are unavoidable in most of real applications.The problem of the waiting cycles due to reading and writing a block of pixel data in a frame memory can be solved using multiple banks of DRAMs. Each row of a block is stored in a different bank so that the bank is also changed when the row is changed. Changing a bank does not generate waiting cycles if the bank is already open.Efforts to increase the performance of memory access in image signal processing system using the multiple banks have been reported several times [7–12]. One of them is reducing waiting cycles by analyzing motion image decoding processes and estimating the next addresses. Another effort is employing cache memories to reduce the number of access to a DRAM. The two methods can be applied to specific systems and dedicated memory controllers are required. Another approach reduces waiting cycles by sending PRECHAGRE and ACTIVE commands early to memory controllers of systems supporting outstanding address communications when addresses are provided in advance. It does not reduce waiting cycles for the data in different rows of the same bank although it can reduce waiting cycles due to PRECHARGE and ACTIVE operations between memory access requests to the data in different banks.In this paper, I propose a memory controller architecture for image processing systems which requires two-dimensional block data of square or rectangular shapes. The proposed memory controller changes the bank when changing row is required so that block data are written or read without waiting cycles in system with an on-chip network supporting outstanding address transactions. A simple conversion of the address of the data is enough for the proposed operation of changing bank without modifying the interface logic of masters and it does not increase the complexity of hardware. The proposed memory controller can increase the performance of the video codec and the image processing system in digital TVs with high resolution and it also works for general data other than block data of rectangular shape without the degradation of performance.SDRAM is widely used as a main memory of IT devices since its manufacturing cost is the lowest. The 1 transistor 1 capacitor (1T1C) structure which enables the economical manufacturing has the disadvantage that the stored information can be lost due to leakage current. The problem is solved by REFRESH operation which refreshes the stored periodically. DRAM also adopts address multiplexing which split a destination address into two pieces and supplies them one by one in order to reduce the manufacturing costs by reducing the number of pins of a package. As a result, the performance is degraded and the architecture of the controller becomes complicated. The performance of SDRAM has been increased by introducing the interface of double data rate (DDR). DDRx(x=1, 2, 3, 4) SDRAMs transfer data at both clock edges and the operating frequencies are greatly increased [3–6].Memory architecture of DRAMs consists of several banks which can be controlled separately as shown in Fig. 1. The memory controllers generate bank information from the address of the data, and the bank information is delivered to a DRAM so that a bank is selected for a read or a write operation. The bank system enables more efficient control of DRAMs when reading and writing data. The proposed algorithm utilizes the bank system in conjunction with the advanced interface protocol.The maximum data bandwidth of SDRAMs, BWmax is represented as Eq. (1).(1)BWmax=dfWDQ[bps]where f is the operating frequency, WDQis the number data pins, and d is 2 for DDRx SDRAMs and is 1 otherwise. However, the maximum bandwidth can be achieved instantaneously, and the average bandwidth is usually much smaller than that of Eq. (1). It is caused by waiting cycles in which memory cells are not reachable for reading or writing due to REFRESH, ACTIVE, and PRECHARGE. They are investigated further below.REFRESH operation prevents the DRAM from losing data due to the leakage currents. It requires the number of cycles proportional to that of rows in a bank since it is reading every cell row by row. The period of REFRESH is usually tens of milliseconds though it depends on operation voltage, temperature, and process variations. Every cell in a row should be read at least once in the period, and the memory cells are not accessible during the REFRESH operation.PRECHARGE operation precharges bit lines of a bank before a word line is activated. It closes a row of a bank when the row is no longer necessary for reading or writing. It also prepares to open a new row, and must precede the ACTIVE operation. It usually requires 2–3cycles in single data rate (SDR) SDRAMs depending on the operation frequencies due to the large capacitance of the bit lines.ACTIVE operation activates a word line of a bank corresponding to a destination address. It opens a row to read or write data. It follows the PRECHARGE operation. Once a row is open, it is accessible without another ACTIVE command until the PRECHARGE command is issued. It usually requires 2–3cycles in single data rate (SDR) SDRAMs depending on the operation frequencies due to the large RC delays of the word lines.Most of the SDRAM contains more than 4 banks, which can be controlled independently. For example, bank 1 can be activated or bank 2 can be precharged while bank 0 is active. Using the properties, ACTIVE or PRECHARGE command for another bank can be issued if the next request is available before the current request is finished while waiting for data in reading operation for a bank. Otherwise, NOP commands are issued. It will increase the effective bandwidth by issuing PRCHARGE or ACTIVE command for another bank in advance.Pixel data of a movie or a still image are stored and displayed by frame which is a two-dimensional array of pixel data. For example, a frame resolution of high definition (FHD) for digital TVs has 1920 pixels horizontally and 1080 pixels vertically, that is, 1920×1080 pixels. A frame resolution of 4k ultra high definition (UHD) is 3840×2160pixels. Image processors or codecs store image data in the memory space of multiples of 2nin order for the simple calculation of addresses when they store the frame data. For example, for FHD images, 2048×2048 bytes are allocated for each color component and the pixel data in a row of a frame can be stored in one row or two rows of an SDRAM bank depending on the capacity of the SDRAM. The lower bits of addresses are used for horizontal (or column) position of pixels and the upper bits are used for vertical (or row) positions of pixels. For an example of 1Gb (128M×8b) DRAM, a bank consists of 2048bytes in a row and 16,384 rows. A 25 bit address is required to specify a byte or a pixel assuming that a pixel means a color component of a real pixel. The lower 11 bits of the address are used for the horizontal (or column) position of a pixel and the upper 14 bits are used for the vertical (or row) position. That is, the 25 bit address represents the position of a pixel in a frame, and a calculator for the address generation is not necessary. If the position of a pixel is (x,y), x is the same as the address[10:0] (or the lower 11 bits of the address) and y is the same as the address[24:11] (or the upper 14 bits of the address). In this scheme, about 50% of the memory space is not used. If the pixel data of each row are stored contiguously to increase the utilization of the memory space, the lower 11 bits of the address are not coincident with the x coordinate of the pixel any more, and additional multipliers and adders are necessary for the address calculation, which results in increase of gate counts and the propagation delay in datapath.When pixel data of images are stored in 2-dimensional array format, three cases can occur as shown in Fig. 2. Assuming 1Gb (128M×8b) DRAM, each bank receives 14 bit row addresses and 11 bit column addresses, and a row in a bank can store 2048 pixels as described above. Fig. 2(a) shows the first case in which frame data of a 4k image are stored. The pixels of one horizontal line cannot be stored in one row of a bank and are stored in two rows since the number of pixels in a row of a 4k image is 3840. Although the frame data are not stored in rectangular shape physically, the addresses can be generated with 24 bit offset values which consist of 12 bits for column positions and 12 bits for row positions as if the data are stored in rectangular shape. Fig. 2(b) shows the second case in which frame data of an FHD image are stored. The pixel data of a horizontal line can be stored in a row of a bank, and the offset addresses consist of 11 bits for column positions and 11 bits for row positions. Fig. 2(c) shows the final case in which a frame data of an SD image is stored. The pixel data of two horizontal lines can be stored in a row of a bank. The two pixel lines are not stored continuously, but the second pixel line starts from the 1025th byte in the row. The offset addresses consist of 9 bits for column positions and 10 bits for row positions as if the data are stored in rectangular shape although the data are spread in the bank. Consequently, an address generator can generate offset addresses according to the number of pixels in rows and columns regardless of the resolutions of images.Most image processing algorithms such as filtering and (de)compressing movies or still images require pixel data blocks of square or rectangular shapes [1]. The sizes of blocks are various from 2×2 to 128×128 [2]. They are stored in 2-dimensional array as mentioned above. For example, 16 pixels of a 4×4 block are stored in 4 rows and 4 columns of a DRAM bank. Four rows are opened and closed for a 4×4 block data in the cases of Fig. 2(a) and (b), and the same operations are required for the next block whether it is contiguous or not. For the case of Fig. 2(c), two rows are opened and closed for a 4×4 block. Closing the current row and opening the next row require waiting cycles for the PRECHARGE and the ACTIVE operation. As a result, a block of data cannot be obtained without interruption. For example, reading a 4×4 block of pixel data (16 bytes) requires additional 18cycles for an SDRAM with the CAS latency of 3 compared with reading 16 bytes of data in a row.Image signal processors usually demand blocks of pixel data in rectangular shapes as mentioned above, and the block data are stored in several contiguous rows of a bank in a DRAM. As a result, several rows need to be opened sequentially to get the data, which generates waiting cycles to change the rows. One frame of an image is stored in a bank contiguously in conventional systems. Assuming 4×4 block data, 4–6 waiting cycles are required for precharging and activating a row, and 16–24 waiting cycles are included in the writing or reading time for the block data even if the PRECHARGE and ACTIVE commands can be sent in advance for systems supporting the outstanding address communications.In order to remove the waiting cycles, I utilize the multiple banks which can be operated independently. The image is distributed throughout the multiple banks so that the neighboring lines of pixel data are stored in the neighboring banks in the proposed scheme. Assuming 4 banks as shown in Fig. 3, the first horizontal line data are stored in the first row of the first bank, and the second line data are stored in the row of the second bank, and so on. The fifth line data are stored in the fifth row of the first bank. The data designated for the first row of the second bank are stored in the second row of the first bank, and so on. In the proposed scheme, opening a new row is replaced by changing a bank. Access to an activated row in a bank does not require any waiting cycles, and the state of a bank can be different since the multiple banks of DRAMs are independently controlled. For example, the first row of the first bank is activated while precharging the second bank and the third row of the third bank is activated simultaneously. Therefore, the block data can be written or read without waiting cycles if the row of the bank for the next data has been activated in advance. The one-to-one mapping between a memory space and an address is still satisfied even though the memory space is relocated for the given address. That is, the address ranges for the proposed scheme are the same as those of the conventional scheme and there is no waste of the memory space.The address calculation for the proposed data storage scheme makes the hardware or the software for image signal processors more complex. There have been similar approaches of storing pixel data of a contiguous row in the next bank so that PRECHARGE and ACTIVE commands can be issued in advance [8–12]. They generate commands or addresses to distribute pixel data in multiple banks, which requires re-design of an image processing system or a memory controller and increases hardware complexity. It is more efficient for memory controllers to calculate the addresses so that image signal processors behave in the conventional manners. That is, image signal processors request data reading or writing as usual, and the memory controllers distribute the block data according to the proposed scheme. It can be achieved easily utilizing the address multiplexing feature in which row and column addresses are received sequentially. The row address includes the information of a bank and a row. Assuming 4 banks, the left two bits and the remaining bits of the row address represent the bank ID and the row ID, respectively. For the first five rows in bank 0 of the 1Gb DRAM mentioned above, the leftmost two bits of the row addresses are “00” and the rightmost two bits are ‘00’, ‘01’, ‘10’, ‘11’, and ‘00’ as shown in Fig. 4. If we exchange the leftmost and the rightmost two bits, the row addresses are changed as shown in Table 1. The first four original row addresses point 4 rows in bank 0 and the first four modified row addresses point the first rows of the 4 banks. That is, the contiguous four rows are distributed to each bank according to the proposed scheme [13]. If a DRAM has 8 or 16 banks, the leftmost and the rightmost 3 or 4 bits can be exchanged. Therefore, the proposed scheme can be implemented by adding a combinational logic that exchanges the leftmost and the rightmost 2–4 bits to the conventional memory controllers. The complexity of the combinational logic is similar to a shifter. If we add a multiplexor, the memory controller can behave according to both the proposed scheme and the conventional manners. It can be switched dynamically using a configuration register. If a DRAM has 16 banks and only 4 banks are required, 12 banks can be in the power-down mode by exchanging only 2 bits of the addresses and the active 4 banks are operated in the proposed scheme. The proposed scheme can be implemented easily without increasing the complexity of the memory controller.One condition is preferred for the better results when the proposed scheme is applied. The address for the next memory access needs to be known in advance in order to activate the row of the next bank during the idle cycles of the present operation. Network interface protocols such as AMBA AXI supporting the outstanding address communications satisfy the condition, and otherwise, the memory controllers need to have both the master and the slave interfaces. The next memory access request can be delivered before the current operation has not been completed if the outstanding address communications are supported, and the addresses for the following operations are known in advance so that the commands for the activation of the new rows can be issued during the idle cycles of the current operation. The proposed scheme can be applied easily since recent SoCs usually employ the network interface protocols supporting the outstanding address communications such as the AXI.The next memory access request is not delivered before the current operation has not been completed if network interface protocols with stop-and-wait communications such as AMBA AHB are employed. Therefore, the proposed scheme may not reduce the waiting cycles much. The memory controllers with the master and the slave interfaces can be a possible solution. The slave interface is used for the writing operation and receiving the read requests in the form of write transactions, and the read data are delivered through the master interface. The processor should have a slave interface to receive the read data. The writing operation can be completed using a slave interface although a buffer for a few transactions is required. The data communications using the dual interfaces require the major modification of memory controllers and the image signal processors. Another solution is activating the same row of the next bank as the current one in advance. If the next request corresponds to a part of a block data, the waiting cycles to activate a new row can be removed. Even if the prediction is wrong, there is no penalty in operation cycles although unnecessary energy consumption for activating a row is inevitable. However, the waiting cycles between the memory access requests cannot be removed, and the advanced network interface protocols are preferred to the AHB. Nonetheless, the proposed scheme can still results in better performance with the AHB interface than the conventional scheme because once a block of data is accessed, the neighboring block of data can be accessed without waiting cycles. That is, when a block of data is accessed, the rows of the banks are opened and the data of the neighboring block are in the same rows.The performance of the proposed data storing scheme for digital TVs is compared with that of the conventional scheme in various applications. The motion compensation units of H.264 decoders usually read 9×9 block pixel data, and the deblocking filter of the decoders write 16×16 block pixel data. One pixel consists of 8 bits since the data for luma and chroma are stored separately [14]. FIR filters are employed in a lot of systems including image signal processors in digital TVs and the sizes of blocks are various. Assuming 3×3 filtering, an FIR filter reads and writes 5×5 block pixel data which consist of 24 or 32 bits. The operation cycles of reading and writing 9×9, 16×16, and 5×5 block pixel data, respectively, are compared for the conventional and the proposed schemes in Table 2. The data width of the memory devices is assumed to be 16 bits. The ‘AHB’ represents a conventional memory controller with the AHB interface, and the ‘AXI’ represents a memory controller with the AXI interface which supports multiple outstanding address transactions [11]. The proposed scheme reduces the write and read cycle by 40–78% and 45–78%, respectively while the ‘AXI’ scheme reduces the write and read cycle by 11–23% and 25–44%, respectively for SDR and DDR2 SDRAMs.A memory controller is designed using Verilog-HDL according to the proposed storing scheme. The memory controller is applied to an H.264 decoder to verify the operation and performance. The sequences of major memory access to a frame memory for H.264 decoding includes reading 9×9 pixel data by a motion compensation (MC) unit, writing 16 pixel data by a deblocking filter (DF), and reading 16 pixel data for a display by a data_out unit. When the above sequences are repeated 16 times, the decoding process for a macroblock is completed. Fig. 5shows the comparison results of memory access time during the H.264 decoding of a sub-block. The system bus frequency is 100MHz, and the data width of memory devices is 32 bits. A SDR SDRAM and a DDR2 SDRAM are employed with the operating frequencies of 100MHz and 200MHz, respectively. The proposed scheme reduces memory access time by 51% and 32% for DDR2 and SDR SDRAM, respectively compared with the ‘AHB’, and by 41% and 14% compared with the ‘AXI’. The memory control scheme of Chien’s work [12] will show the amount of improvement similar to this work since the data distribution is similar. However, Chien’s work requires complex address generators and the memory controller should be re-designed to include the embedded address generator (EAG) and to modify the FSM to support ‘Burst Terminate Burst (BTB)’ and ‘Anticipative Row Activation (ARA)’ techniques. The EAG and FSM need to be re-designed again depending on the architecture of video codec. The memory controllers in the previous works mentioned above [7–11] usually require that address generators or command generators including FSMs are re-designed to support the proposed schemes. It is not a simple work due to the timing issues for memory controllers. However, the proposed scheme does not require the modification of the FSM and only a multiplexor is added at the output stage of the address. The proposed memory controller can be used in any systems without performance degradation, and it can be switched between bank interleaving mode and normal mode by configuring a mode register dynamically. The normal mode represents the data storing scheme in the conventional manner and the bank interleaving mode represents the proposed scheme. The proposed scheme does not depend on the architecture of video codec.The experiment assumes the worst case that all the 4×4 sub-blocks refer different location, and the memory access time will be shorter in real decoding. In addition, the memory access time will be reduced further if decoding schemes to reduce the memory access such as caching the reference data are employed. The synthesis results using a 0.18μm CMOS standard cell library shows that the complexity of hardware increases by 0.1% when the proposed memory access scheme is applied. Therefore, the hardware complexity does not increase practically. An H.264 decoder with the memory controller is implemented using an FPGA and the operation is verified as shown in Fig. 6.

@&#CONCLUSIONS@&#
