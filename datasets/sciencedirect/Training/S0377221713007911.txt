@&#MAIN-TITLE@&#
Recent advances in robust optimization: An overview

@&#HIGHLIGHTS@&#
Overview of papers on robust optimization published since 2007.Give an informative and comprehensive view of the robust optimization domain.Vitality of this research area with theoretical and practical studies.

@&#KEYPHRASES@&#
Robust optimization,Distributional robustness,Risk theory,Decision rules,

@&#ABSTRACT@&#
This paper provides an overview of developments in robust optimization since 2007. It seeks to give a representative picture of the research topics most explored in recent years, highlight common themes in the investigations of independent research teams and highlight the contributions of rising as well as established researchers both to the theory of robust optimization and its practice. With respect to the theory of robust optimization, this paper reviews recent results on the cases without and with recourse, i.e., the static and dynamic settings, as well as the connection with stochastic optimization and risk theory, the concept of distributionally robust optimization, and findings in robust nonlinear optimization. With respect to the practice of robust optimization, we consider a broad spectrum of applications, in particular inventory and logistics, finance, revenue management, but also queueing networks, machine learning, energy systems and the public good. Key developments in the period from 2007 to present include: (i) an extensive body of work on robust decision-making under uncertainty with uncertain distributions, i.e., “robustifying” stochastic optimization, (ii) a greater connection with decision sciences by linking uncertainty sets to risk theory, (iii) further results on nonlinear optimization and sequential decision-making and (iv) besides more work on established families of examples such as robust inventory and revenue management, the addition to the robust optimization literature of new application areas, especially energy systems and the public good.

@&#INTRODUCTION@&#
This review focuses on papers indexed on Web of Science as having been published since 2007 (included), belonging to the area of Operations Research and Management Science, and having ‘robust’ and ‘optimization’ in their title. There were 130 such papers when this paper was revised in May 2013. We also identified 45 PhD dissertations from 2007 on with ‘robust’ in their title and belonging to the areas of operations research or management. Among those we chose to focus on the works with a primary focus on management science rather than system design or optimal control, which are broad fields that would deserve a review paper of their own, and papers that could be of interest to a large segment of the robust optimization research community. We also felt it was important to include PhD dissertations to identify these recent graduates as the new generation trained in robust optimization, whether they have remained in academia or joined industry. We have also added not-yet-published preprints identified through the online archive optimization-online.org to capture ongoing research efforts; however, we have not attempted to provide a comprehensive picture of works-in-progress, which may evolve substantially, including in their content, as they make their way through the peer-reviewing process. We have augmented this list by selecting, among the 883 works indexed by Web of Science that had either robustness (for 95 of them) or robust (for 788) in their title and belonged to the Operations Research and Management Science topic area, the ones best completing the coverage of the previously identified papers. While many additional works would have deserved inclusion, we feel that the works selected give an informative and comprehensive view of the state of robust optimization to date in the context of operations research and management science.The term “robust optimization” has come to encompass several approaches to protecting the decision-maker against parameter ambiguity and stochastic uncertainty. At a high level, the manager must determine what it means for him to have a robust solution: is it a solution whose feasibility must be guaranteed for any realization of the uncertain parameters? or whose objective value must be guaranteed? or whose distance to optimality must be guaranteed? The main paradigm relies on worst-case analysis: a solution is evaluated using the realization of the uncertainty that is most unfavorable.The way to compute the worst case is also open to debate: should it use a finite number of scenarios, such as historical data, or continuous, convex uncertainty sets, such as polyhedra or ellipsoids? The answers to these questions will determine the formulation and the type of the robust counterpart. Issues of over-conservatism are paramount in robust optimization, where the uncertain parameter set over which the worst case is computed should be chosen to achieve a trade-off between system performance and protection against uncertainty, i.e., neither too small nor too large.In this framework, the manager must take a decision in the presence of uncertainty and no recourse action will be possible once uncertainty has been realized. It is then necessary to distinguish between two types of uncertainty: uncertainty on the feasibility of the solution and uncertainty on its objective value. Indeed, the decision maker generally has different attitudes with respect to infeasibility and sub-optimality, which justifies analyzing these two settings separately.When uncertainty affects the feasibility of a solution, robust optimization seeks to obtain a solution that will be feasible for any realization taken by the unknown coefficients; however, complete protection from adverse realizations often comes at the expense of a severe deterioration in the objective. This extreme approach can be justified in some engineering applications of robustness, such as robust control theory, but is less advisable in operations research, where adverse events such as low customer demand do not produce the high-profile repercussions that engineering failures – such as a doomed satellite launch or a destroyed unmanned robot – can have. To make the robust methodology appealing to business practitioners, robust optimization thus focuses on obtaining a solution that will be feasible for any realization taken by the unknown coefficients within a smaller, “realistic” set, called the uncertainty set, which is centered around the nominal values of the uncertain parameters. The goal becomes to optimize the objective, over the set of solutions that are feasible for all coefficient values in the uncertainty set. The specific choice of the set plays an important role in ensuring computational tractability of the robust problem and limiting deterioration of the objective at optimality, and must be thought through carefully by the decision maker.A large branch of robust optimization focuses on worst-case optimization where the worst case of the constraints is computed over a convex uncertainty set of the parameters, which bounds the maximum allowable deviation of the parameters from their nominal values. The goal is to derive tractable reformulations that provide insights into the optimal solution as well as probabilistic guarantees of constraint violation. The reader is referred to Ben-Tal and Nemirovski (2008) and Bertsimas, Brown, and Caramanis (2011) for comprehensive surveys of robust optimization and to Ben-Tal, El Ghaoui, and Nemirovski (2009) for a book treatment of the topic. Further, Averbakh and Zhao (2008) provide a unified treatment for a rather general class of mathematical programming problems under data uncertainty, where the uncertainty set is represented by a system of convex inequalities. Fischetti and Monaci (2009) present a heuristic way to model uncertainty, leading to a modelling framework called Light Robustness, which couples robust optimization with a simplified stochastic programming approach, and exhibits high flexibility and simplicity of use.Ben-Tal and Den Hertog (2011) show that the robust counterpart of a convex quadratic constraint with ellipsoidal implementation error is equivalent to a system of conic quadratic constraints. Sniedovich (2012) emphasizes the difference between local robustness, of which robust optimization is an example, and global robustness, which is what decision-makers facing the severe uncertainty described as “black swans” in the popular media would like to protect themselves against. Nemirovski (2012) provides safe tractable approximations of chance constraints when data uncertainty is incorporated through constraints that must be satisfied with high probability.When uncertainty affects the optimality of a solution, robust optimization seeks to obtain a solution that performs well for any realization taken by the unknown coefficients. While a common approach is to optimize the worst-case objective, some studies have investigated other robustness measures. Uncertainty on the objective can also be approached using the tools described earlier by creating a new inequality that brings the objective into the feasible set.Single objective. Robust linear optimization with cost uncertainty is investigated both in Thiele (2010), who analyzes over-conservatism, and Gancarova and Todd (2012), who study the loss in objective value when an inaccurate objective is optimized instead of the true one.Multiple objectives. While much of the work on robust optimization has focused on problems with a single robustness measure, it can be more appropriate in some settings to consider multiple robustness measures instead. Robust multiobjective optimization is investigated in particular in Gaspar-Cunha and Covas (2008), who discuss robustness assessment for multi-objective optimization through the use of evolutionary algorithms. Further, Hu and Mehrotra (2012a) use a multiexpert multicriteria robust weighted sum approach and identify a robust Pareto decision that minimizes the worst-case weighted sum of objectives over a given weight region. The model is then extended to include ambiguity or randomness in the weight region as well as the objective functions.Other robustness measures.Roy (2010) proposes a new robustness criterion that holds great appeal for the manager due to its simplicity of use and practical relevance. This framework, called bw-robustness, allows the decision-maker to identify a solution that guarantees an objective value, in a maximization problem, of at least w in all scenarios, and maximizes the probability of reaching a target value of b (b>w). Gabrel, Murat, and Lei (2013) extend this criterion from a finite set of scenarios to the case of an uncertainty set modeled using intervals. Kalai, Lamboray, and Vanderpooten (2012) suggest another criterion called lexicographic α-robustness, also defined over a finite set of scenarios for the uncertain parameters, which mitigates the primary role of the worst-case scenario in defining the solution. In addition, Morrison (2010) develops a framework of robustness in combinatorial optimization, based on persistence (of decisions) using the Dempster–Shafer theory as an evidence of robustness and applies it to portfolio tracking and sensor placement.Since duality has been shown to play a key role in the tractability of robust optimization (see for instance Bertsimas & Sim (2004) and Gorissen, Ben-Tal, Blanc, & Den Hertog (2012)), it is natural to ask how duality and robust optimization are connected. Beck and Ben-Tal (2009) show that primal worst is equal to dual best. The relationship between robustness and duality is also explored in Gabrel and Murat (2010) when the right-hand sides of the constraints are uncertain and the uncertainty sets are represented using intervals, with a focus on the connections between linear programs with uncertain right hand sides and linear programs with uncertain objective coefficients using duality theory. This avenue of research is further explored in Gabrel, Murat, and Remli (2010) and Remli (2011). Doan, Kruk, and Wolkowicz (2012) approach robustness from an algorithmic standpoint in the context of semidefinite programming (SDP) to address ill-conditioning and instability issues.Most early work on robust optimization focused on static decision-making: the manager decided at once of the values taken by all decision variables and, if the problem allowed for multiple decision stages as uncertainty was realized, the stages were incorporated by re-solving the multi-stage problem as time went by and implementing only the decisions related to the current stage. As the field of static robust optimization matured, incorporating – in a tractable manner – the information revealed over time directly into the modeling framework became a major area of research.Because of the difficulty in incorporating multiple stages in robust optimization, many theoretical works have focused on two stages. Assavapokee, Realff, and Ammons (2008) and Assavapokee, Realff, Ammons, and Hong (2008) develop tractable algorithms in the case of robust two-stage problems where the worst-case regret is minimized, in the case of interval-based uncertainty and scenario-based uncertainty, respectively. Given linear programs, Thiele, Terry, and Epelman (2009) present a cutting-plane method based on Kelley’s algorithm for solving convex adjustable robust optimization problems, while Terry (2009) provides in addition preliminary results on the conditioning of a robust linear program and of an equivalent second-order cone program. Finally, Minoux (2011) provides complexity results for the two-stage robust linear problem with right-hand-side uncertainty.Chen, Sim, and Sun (2007) suggest a tractable approximation for a class of multistage chance-constrained linear programming problems, which converts the original formulation into a second-order cone programming problem. Chen and Zhang (2009) propose an extension of the Affinely Adjustable Robust Counterpart framework described in Ben-Tal, El Ghaoui, et al. (2009) and argue that its potential is well beyond what has been discussed in the literature so far. Bertsimas, Iancu, and Parrilo (2010) establish the optimality of policies affine in the uncertainty for one-dimensional robust optimization problems with convex state costs and linear control costs. This is further explored in Iancu (2010), which introduces a hierarchy of polynomial policies that are parameterized in the observed uncertainties, and that can be efficiently computed using semidefinite optimization methods and implements this framework in problems drawn from inventory and revenue management.Kuhn, Wiesemann, and Georghiou (2011) consider decision rule policies in the context of stochastic programming, not only to the primal but also to a dual version of the problem, and analyzes the loss of optimality due to this approximation using techniques drawn from robust optimization. The authors show that both resulting approximate problems are equivalent to tractable linear or semidefinite programs of moderate sizes. The method also extends to cases involving random recourse, multiple decision stages and ambiguous probability distributions.O’Donoghue, Wang, and Boyd (2011) describe a min–max approximate dynamic programming policy for a discrete-time dynamical system perturbed by noise. Shapiro (2011) shows how dynamic programming equations can be naturally written for adjustable multi-stage robust optimization, with an application to inventory management. Vayanos, Kuhn, and Rustem (2012) consider convex multi-stage robust optimization problems and approximate the adaptive decisions by finite linear combinations of prescribed basis functions. The authors demonstrate how to optimize over these decision rules at low computational cost through constraint randomization and obtain a priori probabilistic guarantees on the feasibility properties of the optimal decision rule.Finally, Van Parys, Kuhn, Goulart, and Morari (2013) investigate the control of constrained stochastic linear systems under only limited information regarding the disturbance process, i.e. when only the first two moments of the disturbance distribution are known, for two types of distributionally robust constraints: (i) constraints required to hold with a given probability for all disturbance distributions sharing the known moments and (ii) Conditional Value-at-Risk (CVaR) constraints that bound the expected constraint violation for all disturbance distributions consistent with the given moment information.An early stream in robust optimization modeled stochastic variables as uncertain parameters belonging to a known uncertainty set, to which robust optimization techniques were then applied. An advantage of this method was to yield approaches to decision-making under uncertainty that were of a level of complexity similar to that of their deterministic counterparts, and did not suffer from the curse of dimensionality that afflicts stochastic and dynamic programming. Researchers are now making renewed efforts to connect the robust optimization and stochastic optimization paradigms, for instance quantifying the performance of the robust optimization solution in the stochastic world. The topic of robust optimization in the context of uncertain probability distributions, i.e., in the stochastic framework itself, is also being revisited.Chen et al. (2007), mentioned earlier, provide a robust optimization perspective to stochastic programming. Manuja (2008) proposes a formulation for robust linear programming problems that allows the decision-maker to control both the probability and the expected value of constraint violation. Bertsimas and Goyal (2010) investigate the performance of static robust solutions in two-stage stochastic and adaptive optimization problems. The authors show that static robust solutions are good-quality solutions to the adaptive problem under a broad set of assumptions. They provide bounds on the ratio of the cost of the optimal static robust solution to the optimal expected cost in the stochastic problem, called the stochasticity gap, and on the ratio of the cost of the optimal static robust solution to the optimal cost in the two-stage adaptable problem, called the adaptability gap. Bertsimas, Goyal, and Sun (2011) analyze the role of geometric properties of uncertainty sets, such as symmetry, in the power of finite adaptability in multistage stochastic and adaptive optimization.Duzgun (2012) bridges descriptions of uncertainty based on stochastic and robust optimization by considering multiple ranges for each uncertain parameter and setting the maximum number of parameters that can fall within each range. The corresponding optimization problem can be reformulated in a tractable manner using the total unimodularity of the feasible set and allows for a finer description of uncertainty while preserving tractability. She also studies the formulations that arise in robust binary optimization with uncertain objective coefficients using the Bernstein approximation to chance constraints described in Ben-Tal, El Ghaoui, et al. (2009), and shows that the robust optimization problems are deterministic problems for modified values of the coefficients.Bandi and Bertsimas (2012) propose a new approach to analyze stochastic systems based on robust optimization. The key idea is to replace the Kolmogorov axioms and the concept of random variables as primitives of probability theory, with uncertainty sets that are derived from some of the asymptotic implications of probability theory like the central limit theorem. The authors show that the performance analysis questions become highly structured optimization problems for which there exist efficient algorithms that are capable of solving problems in high dimensions. They also demonstrate that the proposed approach achieves computationally tractable methods for (a) analyzing queueing networks, (b) designing multi-item, multi-bidder auctions with budget constraints, and (c) pricing multi-dimensional options.Distributionally robust optimization can be divided into two broad subgroups: (i) robust optimization using moment information and (ii) robust optimization directly on the probability distributions.Using moment information.Popescu (2007) analyzes robust solutions to a certain class of stochastic optimization problems, using mean-covariance information about the distributions underlying the uncertain parameters. The author connects the problem for a broad class of objective functions to a univariate mean–variance robust objective and, subsequently, to a (deterministic) parametric quadratic programming problem. Kang (2008) studies robust linear optimization with a focus on probabilities of constraint violation, using bounds based on moment information. The reader is also referred to Doan (2010) for a moment-based uncertainty model for stochastic optimization problems, which addresses the ambiguity of probability distributions of random parameters with given moments through a minimax decision rule, and a comparison with data-driven approaches.Bertsimas, Doan, Natarajan, and Teo (2010) propose a semidefinite optimization model to address minimax two-stage stochastic linear problems with risk aversion, when the distribution of the second-stage random variables belongs to a set of multivariate distributions with known first and second moments. The minimax solutions provide a natural distribution to stress-test stochastic optimization problems under distributional ambiguity. Becker (2011) studies the distributionally robust optimization problem with known mean, covariance and support and develops a decomposition method for this family of problems which recursively derives sub-policies along projected dimensions of uncertainty while providing a sequence of bounds on the value of the derived policy. Zymler, Kuhn, and Rustem (in press) develop tractable approximations based on semidefinite programming for distributionally robust individual and joint chance constraints, assuming that only the first- and second-order moments as well as the support of the uncertain parameters are given.With uncertainty directly on the distributions.Delage (2009) implements distributionally robust optimization in the context of data-driven problems and uses observed data to define a “well structured” set of distributions that is guaranteed with high probability to contain the distribution from which the samples were drawn. Delage and Ye (2010) investigate distributional robustness when the uncertainty affects the problem both in terms of the distribution and of its moments. The authors show that the resulting problems can be solved efficiently and prove that the solutions exhibit, with high probability, best worst-case performance over a set of distributions.Ben-Tal, Bertsimas, and Brown (2010) consider the optimization of a worst-case expected-value criterion, where the worst case is computed over all probability distributions within a set. The work introduces a notion of robustness that allows for different guarantees for different subsets of probability measures. The concept of distributional robustness is also explored in Goh and Sim (2010), with an emphasis on linear and piecewise-linear decision rules to reformulate the original problem in a flexible manner using expected-value terms, in particular the expected value of the positive part of the recourse variables, for which the authors compute distributionally robust bounds.Cromvik and Patriksson (2010a) show that, under certain assumptions, global optima and stationary solutions of stochastic mathematical programs with equilibrium constraints are robust with respect to changes in the underlying probability distribution. Xu, Caramanis, and Mannor (2012) also investigate probabilistic interpretations of robust optimization by showing the connection between robust optimization and distributionally robust stochastic programming, and uses this result to construct robust optimization formulations for sampled problems. Dupacova and Kopa (2012) consider stochastic programs whose set of feasible solutions depends on probability distributions that are not fully known, and use a contamination technique to study the robustness of results to perturbations on the probabilities. They suggest a robust efficiency test with respect to the second order stochastic dominance criterion. Wong (2012) estimates certain nonlinear risk measures under moment bound constraints, and considers an SDP formulation for simultaneous confidence bands. Ben-Tal, Den Hertog, De Waegenaere, Melenberg, and Rennen (2013) focus on robust linear optimization problems with uncertainty regions defined by phi-divergences, which arise for instance in settings involving moments of random variables and expected utility, and consider applications to asset pricing and the multi-item newsvendor problem.Finally, Wiesemann, Kuhn, and Sim (2013) propose a unifying framework for modeling and solving distributionally robust optimization problems based on standardized ambiguity sets that encompass many ambiguity sets from the recent literature as special cases. The authors determine sharp conditions under which distributionally robust optimization problems based on their approach are computationally tractable, and tractable conservative approximations otherwise.Zhu and Fukushima (2009) and Zymler (2010) also study distributional robustness in the context of specific applications, such as portfolio management.Chen et al. (2007) present an approach for constructing uncertainty sets for robust optimization using new deviation measures that capture the asymmetry of the distributions. These deviation measures lead to improved approximations of chance constraints. Bertsimas and Brown (2009) describe how to connect uncertainty sets in robust linear optimization to coherent risk measures, an example of which is CVaR. In particular, the authors show the link between polyhedral uncertainty sets of a special structure and a subclass of coherent risk measures called distortion risk measures. Natarajan, Pachamanova, and Sim (2009) take the opposite perspective and discuss how uncertainty sets in robust optimization map to risk measures in finance. They also propose a specific approach to generating coherent risk measures in this context.Dentcheva and Ruszczynski (2010) propose the concept of robust stochastic dominance and show its application to risk-averse optimization. They consider stochastic optimization problems where risk-aversion is expressed by a robust stochastic dominance constraint and develop necessary and sufficient conditions of optimality for such optimization problems in the convex case. In the nonconvex case, they derive necessary conditions of optimality under additional smoothness assumptions of some mappings involved in the problem.Finally, Hu and Mehrotra (2012b) consider a framework to decision-making with ambiguous and inconsistent utility assessments. Iancu and Trichakis (in press) show that robust optimization problems have many optimal solutions, they introduce a new concept of Pareto robustly optimal and, they propose an efficient method to get Pareto robustly optimal solutions.Robust nonlinear optimization remains much less widely studied to date than its linear counterpart, especially when the problem is nonlinear in the uncertainty itself or in the presence of non-convexities. Zhang (2007) provides formulations to nonlinear programming problems that are valid in the neighborhood of the nominal parameters and robust to the first order. Teo (2007) presents a method for robust nonconvex optimization with arbitrary objective functions, which iteratively moves along descent directions and terminates at a robust local minimum. Boni, Ben-Tal, and Nemirovski (2008) analyze problems with uncertain conic quadratic constraints, formulating an approximate robust counterpart. Hsiung, Kim, and Boyd (2008) present tractable approximations to robust geometric programming, by using piecewise-linear convex approximations of each nonlinear constraint. Geometric programming is also investigated in Shen, Ma, and Chen (2008), where the robustness is injected at the level of the algorithm and seeks to avoid obtaining infeasible solutions because of the approximations used in the traditional approach. In Ben-Tal, Den Hertog, and Vial (2012), there is an extensive and structured treatment of robust nonlinear optimization, using Fenchel Duality.Mutapcic and Boyd (2009) focus on robust convex optimization with pessimizing oracles and describe a general solution method for solving such a problem that alternates between optimization and worst-case analysis. Takeda, Taguchi, and Tanaka (2010) study robustness for uncertain convex quadratic programming problems with ellipsoidal uncertainties and proposes a relaxation technique based on random sampling for robust deviation optimization problems. Bertsimas, Nohadani, and Teo (2010b) present a robust optimization approach for unconstrained non-convex problems and problems based on simulations. Such problems arise for instance in the partial differential equations literature and in engineering applications such as nanophotonic design. An appealing feature of the approach is that it does not assume any specific structure for the problem. The case of robust nonlinear optimization with constraints is investigated in Bertsimas, Nohadani, and Teo (2010a) with an application to radiation therapy for cancer treatment. Bertsimas and Nohadani (2010) further explore robust nonconvex optimization in contexts where solutions are not known explicitly, e.g., have to be found using simulation. They present a robust simulated annealing algorithm that improves performance and robustness of the solution.A special case of nonlinear problems that are linear in the decision variables but convex in the uncertainty when the worst-case objective is to be maximized is investigated in Kawas and Thiele (2011a). In that setting, exact and tractable robust counterparts can be derived. A special class of non-convex robust optimization is examined in Kawas and Thiele (2011b). Further, interval uncertainty-based robust optimization for convex and non-convex quadratic programs are considered in Li, Gabriel, Shim, and Azarm (2011), while Lasserre (2011) considers minimax and robust models of polynomial optimization.In summary, research efforts on the theory of robust optimization have focused on creating and analyzing distributionally robust approaches as well as developing connections between uncertainty sets and risk theory.We describe below examples to which robust optimization has been applied. While an appealing feature of robust optimization is that it leads to models that can be solved using off-the-shelf software, it is worth pointing the existence of algebraic modeling tools that facilitate the formulation and subsequent analysis of robust optimization problems on the computer such as ROME (Goh & Sim, 2011), AIMMS (Paragon Decision Technologies, 2011) and Yalmip (Löfberg, 2012).Combinatorial optimization problems. The capacitated vehicle routing problem with demand uncertainty is studied in Sungur (2007) and Sungur, Ordonez, and Dessouky (2008), and the robust traveling salesman problem with interval data in Montemanni, Barta, Mastrolilli, and Gambardella (2007). The robustness of combinatorial auctions with respect to different bidding behavior is studied in Schneider, Shabalin, and Bichler (2010). Zhang (2011) investigates two-stage minimax regret robust uncapacitated lot-sizing problems with demand uncertainty, in particular showing that it is polynomially solvable under the interval uncertain demand set. Remli and Rekik (2012) consider the problem of combinatorial auctions in transportation services when shipment volumes are uncertain and propose a two-stage robust formulation solved using a constraint generation algorithm.Scheduling.Goren and Sabuncuoglu (2008) analyze robustness and stability measures for scheduling in a single-machine environment subject to machine breakdowns and embed them in a tabu-search-based scheduling algorithm. Hazir, Haouari, and Erel (2010) consider robust scheduling and robustness measures for the discrete time/cost trade-off problem. Mittal (2011) investigates efficient algorithms that give optimal or near-optimal solutions for problems with non-linear objective functions, with a focus on robust scheduling and service operations. Examples considered include parallel machine scheduling problems with the makespan objective, appointment scheduling and assortment optimization problems with logit choice models.An important question in logistics is not only how to operate a system most efficiently but also how to design it in the presence of uncertainty. Of particular interest is the issue of where to open facilities. Uncertainty can be either on (node) demands and unit (link) costs of the network (in the majority of the research efforts), or – more rarely – on network connectivity (link capacities or failures).Uncertain demand and/or unit costs. The robust capacity expansion problem of network flows under demand and travel time uncertainty is investigated in Ordonez and Zhao (2007), who provide tractable reformulations under a broad set of assumptions. Atamtürk and Zhang (2007) study the network flow and design problem under demand uncertainty from a complexity standpoint, with applications to lot-sizing and location–transportation problems. They provide complexity results for the two-stage network flow and design problem. Mudchanatongsuk, Ordonez, and Liu (2008) analyze the network design problem under transportation cost and demand uncertainty. They present a tractable approximation when each commodity only has a single origin and destination, and an efficient column generation for networks with path constraints.Torres Soto (2009) also takes a comprehensive view of the facility location problem by determining not only the optimal location but also the optimal time for establishing capacitated facilities when demand and cost parameters are time varying. The models are solved using Benders’ decomposition or heuristics such as local search and simulated annealing. Minoux (2010) proves that the robust network design problem with uncertain demand is NP-hard. Further, the problem of locating a competitive facility in the plane in the presence of uncertain demand is studied in Blanquero, Carrizosa, and Hendrix (2011) with a deviation robustness criterion.Baron, Milner, and Naseraldin (2011) apply robust optimization to the problem of locating facilities in a network facing uncertain demand over multiple periods. They consider a multi-period fixed-charge network location problem for which they show that different models of uncertainty lead to very different solution network topologies, with the model with box uncertainty set opening fewer, larger facilities. Bardossy (2011) presents a dual-based local search approach for deterministic, stochastic, and robust variants of the connected facility location problem. Gabrel, Lacroix, Murat, and Remli (2011) investigate a robust version of the location transportation problem with an uncertain demand using a 2-stage formulation. The resulting robust formulation is a convex (nonlinear) program, and the authors apply a cutting plane algorithm to solve the problem exactly.Robust hub location problems are investigated in Alumur, Nickel, and Saldanha-da-Gama (2012), where the uncertainty is on the set-up costs for the hubs and the demands to be transported between the nodes. Gulpinar, Pachamanova, and Canakoglu (2013) consider a stochastic facility location problem in which multiple capacitated facilities serve customers with a single product, with uncertain customer demand and a constraint on the stock-out probability. Robust optimization strategies for facility location appear to have better worst-case performance than non-robust strategies.Link capacities/failures.Nagurney and Qiang (2009) suggest a relative total cost index for the evaluation of transportation network robustness in the presence of degradable links and alternative travel behavior. Complexity results for the robust network design problem under uncertain link capacities are also provided in Minoux (2009). The problem of designing an uncapacitated network in the presence of link failures and a competing mode is investigated in Laporte, Mesa, and Perea (2010) in a railway application using a game theoretic perspective. In addition, the robust network flow problem is also analyzed in Boyko (2010), which proposes a stochastic formulation of minimum cost flow problem aimed at finding network design and flow assignments subject to uncertain factors, such as network component disruptions/failures when the risk measure is CVaR.An extension to the facility location problem is supply chain design under demand uncertainty, which involves site locations, choices of production, packing and distribution lines, and the capacity increment or decrement policies. Such problems are studied in Poojari, Lucas, and Mitra (2008) and Pan and Nagi (2010).The topic of robust multi-stage inventory management has been investigated in detail in Bienstock and Ozbay (2008), whose model computes robust basestock levels, and Ben-Tal, Boaz, and Shimrit (2009), who extend the Affinely Adjustable Robust Counterpart framework to control inventories under demand uncertainty. See and Sim (2010) study a multi-period inventory control problem under ambiguous demand for which only mean, support and some measures of deviations are known, using a factor-based model. The parameters of the replenishment policies are obtained using a second-order conic programming problem.Song (2010) considers stochastic inventory control in robust supply chain systems. The work proposes an integrated approach that combines in a single step data fitting and inventory optimization – using histograms directly as the inputs for the optimization model – for the single-item multi-period periodic-review stochastic lot-sizing problem. Operation and planning issues for dynamic supply chain and transportation networks in uncertain environments are considered in Chung (2010), with examples drawn from emergency logistics planning, network design and congestion pricing problems. Finally, Cakmak (2012) investigates two risk-modeling approaches in the context of inventory management, risk-averse models and robust formulations and analyzes the resulting policies.A number of robust optimization papers focusing on inventory management or logistics are specific to the application considered: (i) warehouse management, (ii) train operations, or (iii) the semi-conductor industry.(i)Ang, Lim, and Sim (2012) propose a robust storage assignment approach in unit-load warehouses facing variable supply and uncertain demand in a multi-period setting. The authors assume a factor-based demand model and minimize the worst-case expected total travel in the warehouse with distributional ambiguity of demand. A related problem is considered in Werners and Wuelfing (2010), who optimize internal transports at a parcel sorting center.Fischetti, Salvagnin, and Zanette (2009) investigate methods to improve robustness of railway timetables based on a combination of linear programming (LP) and ad hoc stochastic programming/robust optimization techniques, while Cacchiani, Caprara, and Fischetti (2012) focus on Lagrangean heuristics. Galli (2011) describes the models and algorithms that arise from implementing recoverable robust optimization to train platforming and rolling stock planning, where the concept of recoverable robustness has been defined in Liebchen, Lübbecke, Möhring, and Stiller (2009) as the ability to recover a given solution by limited means in all scenarios. A survey of nominal and robust timetabling problems is provided in Cacchiani and Toth (2012). The concept of recoverable solution is also examined in depth by Erera, Morales, and Savelsbergh (2009) for the problem of repositioning empty cargo containers.Ng, Sun, and Fowler (2010) consider the semiconductor lot allocation problem using robust optimization. Lot sizes are regarded as uncertain planning data when making the allocation decisions due to potential yield loss. The robust mixed-integer programming problem is solved by applying branch-and-price and Benders decomposition.Robust optimization works in finance either model parameters such as the mean and covariance of stock returns as being subject to parameter ambiguity, or the stock returns themselves as being uncertain parameters in known uncertainty sets. Fabozzi, Kolm, Pachamanova, and Focardi (2007) describe extensively applications of robust optimization in finance from a practitioner’s perspective. The reader is further referred to Fabozzi, Huang, and Zhou (2010) for a survey on robust portfolio selection, which incorporates not only the traditional mean–variance objective, but also other risk-return measures.Gulpinar and Rustem (2007) combine a multi-period portfolio design with multiple return and risk scenarios, incorporated in a scenario tree, with ambiguity on the mean-covariance parameters. The authors consider several uncertainty models, with either risk scenarios at each node, or risk scenarios at each time period, or risk scenarios for each rival return scenario (defined by the sub-scenario trees rooted at nodes of the first time period). Robust multi-period portfolio problems are also investigated in Pinar (2007), with a focus on minimizing downside risk, measured from a target level, and maximizing terminal wealth, as well as Bertsimas and Pachamanova (2008), which analyze the viability of different robust optimization approaches to multiperiod portfolio selection.Robust optimization approaches focusing on the first two moments of the return distributions are investigated by Schoettle and Werner (2009), who study the impact of two popular uncertainty sets on the traditional efficient frontier. DeMiguel and Nogales (2009) build upon the observation that mean–variance portfolios constructed using the sample first two moments of asset returns perform poorly out of sample due to estimation error and suggest a class of portfolios, constructed using robust estimators and the solution of a single nonlinear programming problem, that have better stability properties than the traditional minimum-variance portfolios. Natarajan, Sim, and Uichanco (2010) consider the case where only the mean, covariance and support information of asset returns are known and the investor’s utility is piecewise linear concave. The authors derive exact and approximate optimal trading strategies for a robust expected utility model, where the investor maximizes his worst-case expected utility over a set of ambiguous distributions, using a tractable conic programming approach. They provide connections with robust or ambiguous convex risk measures, in which the investor minimizes his worst-case risk under distributional ambiguity. Mean–variance models when the mean and the covariance matrix are only known to belong to a pre-specified uncertainty set are also studied in Ye, Parpas, and Rustem (2012), who write the resulting problem as a conic programming problem.Nguyen and Lo (2012) build robust portfolio optimization models based on investors’ rankings of the assets instead of estimates of their parameters such as expected returns. They solve a robust ranking problem using a constraint generation scheme. Li, Natarajan, and Doan (2013) present a distributionally robust approach to portfolio optimization based on overlapping marginals and robust to dependency structures in the random losses. The authors then compute robust bounds on performance metrics of the joint portfolio.Value at Risk.Huang, Fabozzi, and Fukushima (2007) extend the worst-case Value-at-Risk (VaR) approach to incorporate uncertain exit times in robust portfolio selection, while Natarajan, Pachamanova, and Sim (2008) approximate the problem of minimizing the VaR of a portfolio based on robust optimization techniques by optimizing a modified, coherent VaR measure, called Asymmetry-Robust VaR, which incorporates asymmetries in the distributions of returns. Goh, Lim, Sim, and Zhang (2012) introduce the concept of Partitioned VaR to capture asymmetry in asset return distributions by considering positive and negative returns separately. Their approach generates better risk-return tradeoffs than the traditional Markowitz framework in simulations.Conditional Value at Risk.Natarajan et al. (2009) present a model for worst-case CVaR based on partial moment information when the underlying distributions of the random variables are not precisely known. Zhu and Fukushima (2009) study CVaR minimization when only partial information on the underlying probability distribution is available and consider the cases of mixture distribution uncertainty, box uncertainty, and ellipsoidal uncertainty. Huang, Zhu, Fabozzi, and Fukushima (2010) consider a related problem of portfolio selection under distributional uncertainty in a relative robust CVaR approach, where relative CVaR is related to the worst-case risk of the portfolio relative to a benchmark, computed when the exact knowledge of the distribution is available.Other risk measures.Chen (2008) focuses on downside risk measures expressed through lower partial moments (LPM). A key result is that it characterizes a class of return distributions in which the Sharpe ratio is essentially the only risk adjusted performance measure, in the sense that the LPM related Risk Adjusted Performance Measures – such as the Sortino ratio and the Omega Statistic – are all equivalent to the ordinary Sharpe ratio, which is easy to compute and optimize. Chen, He, and Zhang (2011) investigate this topic further by considering robust portfolio problems where expected utility is maximized under ambiguous distributions of the investment return.Absolute deviation (from the mean) is also sometimes considered as a risk measure in robust portfolio management, for instance in Moon and Yao (2011), which leads to a linear programming problem. The authors test the robust strategies on real market data and discuss performance of the robust optimization model based on financial elasticity, standard deviation, and market condition such as growth, steady state, and decline in trend.Fertis, Baes, and Lüthi (2012) propose the concept of robust risk measure, defined as the worst possible of predefined risks when each among a set of given probability measures is likely to occur. In particular, they introduce a robust version of CVaR and of entropy-based risk measures, and shows how to compute and optimize the Robust CVaR using convex duality methods.Derivatives.Zymler, Rustem, and Kuhn (2011) propose a robust optimization model for portfolios that may include European-style options, leading to tractable, convex second-order cone programming problems, and derive guarantees on the worst-case portfolio return, both weak (when the return falls within the specified uncertainty set) and strong (when it falls outside). The presence of derivatives in the portfolio creates nonlinearities, in the uncertainty, of the portfolio return, and makes problems involving VaR difficult to solve. Zymler, Kuhn, and Rustem (2013) address this issue by developing two tractable approximations to the problem of computing the VaR of a portfolio with derivatives when the first two moments of the underlying asset prices are known.Uncertain continuously compounded rates of return.Kawas and Thiele (2011a) consider the case where the worst-case value of a portfolio must be maximized in a static framework, when the objective is linear in the decision variables (asset allocation) and nonlinear but convex in the uncertain parameters, in line with the Log-Normal model of stock prices. The work shows that tractable and insightful robust optimization models can still be derived for this specific class of nonlinear robust problems. This is extended in Kawas and Thiele (2011b) to the case of nonlinear nonconvex portfolio management problems, which arise when short sales are allowed, i.e., decision variables can be negative. Further extensions are provided in Kawas (2010).Additional topics.Bienstock (2007) develops a framework for robust portfolio management that is based on empirical histograms and uses a cutting-plane approach that proves to be effective for large, real-life data sets. Leibfritz and Maruhn (2009) consider the question of designing a hedging portfolio, which produces a payoff greater than or equal to that of another portfolio (financial instrument) in all states of the economy, in the presence of model or implementation errors. The resulting optimization problem is solved by a sequence of linear and nonlinear semidefinite programming (SDP–NSDP) problems. The NSDP problem is related to an eigenvalue minimization problem. The authors show convergence of the iterates of the sequential approach. Florez-Lopez (2010) provides a comparative analysis of methods to achieve robustness in credit scoring in the presence of missing data.Gregory, Darby-Dowman, and Mitra (2011) evaluate the cost of robustness in portfolio optimization by considering the maximum return portfolio optimization problem. The authors derive the robust model under polyhedral uncertainty sets from a min-regret perspective and examine the properties of robust models with respect to portfolio composition. Fonseca, Zymler, Wiesemann, and Rustem (2011) consider the robust optimization of currency portfolios, where the uncertainty is on the foreign exchange rates. A key issue that does not affect stock-only portfolios is that exchange rates must satisfy the non-arbitrage property, to avoid “free” money-making opportunities generated by repeated conversion through a set of currencies. Robust decision times rather than asset allocations (e.g., when to sell an underperforming stock) are analyzed in Dziecichowicz (2011). Selecting assets to maximize similarity compared to an index when the similarity coefficients are uncertain is studied in Chen and Kwon (2012).Delage and Ye (2010) and Ben-Tal et al. (2010) also make theoretical contributions to the robust optimization literature that are illustrated on financial management examples.Revenue management problems can be divided into two broad categories: (i) quantity-driven revenue management, in which the decision variables are the quantities of goods on offer (airline seats, hotel rooms, etc.) or allocation decisions (assignments of aircrafts and crews to flight routes), and (ii) price-driven revenue management, where the decision variables are the prices of those goods. The first type of problems often leads to linear programming formulations while the second type usually generates nonlinear problems.Online algorithms.Ball and Queyranne (2009) analyze online algorithms for (quantity-based) revenue management problems such as the two-fare problem, where the decision-maker must reserve seats for customers who arrive late in the selling process but are willing to pay a higher fare than early arrivals (e.g., business travelers vs tourists). The analysis builds upon the concept of competitive ratio, i.e., the ratio of the policy’s performance to the offline optimal. The competitive analysis of online algorithms is also at the core of Lan (2009) for the multi-fare booking problem, incorporating complex features such as dynamic policies and overbooking.Airline revenue management.Gao, Johnson, and Smith (2009) discuss airline fleet planning and robust crew scheduling and argue that an integrated approach addressing both simultaneously reduces costs and improves operational robustness. A multi-objective approach to robust airline scheduling is presented in Burke et al. (2010). Tam, Ehrgott, Ryan, and Zakeri (2011) compare stochastic programming and bi-objective optimization approaches to robust airline crew scheduling. Davendralingam (2011) studies a robust mean variance optimization approach for concurrent airline network and aircraft design, building upon the insight that both decisions are tightly linked to passenger driven demand.Customer choice. As mentioned earlier, a core application of the work in Mittal (2011), which investigates efficient algorithms for problems with nonlinear objective functions arising in robust optimization, is assortment optimization with logit choice models. Rusmevichientong and Topaloglu (2012) also consider robust assortment planning problems under the multinomial logit choice model with uncertain parameters, both in static and dynamic settings. A key novelty of the problem is the structure of the uncertainty, which affects the decision-maker’s problem in a nonlinear manner. The robust approach yields, for a family of uncertainty sets, over 10% performance in the worst-case performance compared to other methods.Project selection and management.Yamashita, Armentano, and Laguna (2007) study robust optimization models for project scheduling with resource availability cost when the activity durations are uncertain and uncertainty is modeled via a set of scenarios. Robust project selection has been investigated in Liesio, Mild, and Salo (2008) under incomplete cost information and project interdependencies. Driouchi, Leseure, and Bennett (2009) provide a robustness framework for monitoring real options under uncertainty, which play a key role in the value of various projects. Duzgun and Thiele (2010) consider a project selection problem with uncertain cash flows, when each uncertain parameter can belong to one of several ranges (such as high cash flow range and low cash flow range) and the number of parameters that can fall within each range is bounded by the decision maker. The work also provides a robust ranking mechanism for the projects, based on multiple ranking lists that the manager goes through, switching from one to the other as specific uncertainty budgets are exhausted.Lim and Shanthikumar (2007) investigate single-product robust dynamic pricing that protects the manager’s revenue against errors in the underlying model at the optimization stage, using notions of relative entropy and stochastic differential games. Integrated inventory and pricing decisions are analyzed in Zhang (2010) in a multi-stage robust framework using the Extended Affinely Adjustable Robust Counterpart methodology. Adida and Perakis (2010) present a computational study comparing robust and stochastic approaches for dynamic pricing and inventory control. Perakis and Roels (2010) describe an approach to obtain robust controls in network revenue management. Dziecichowicz (2011) approaches pricing problems from another angle by determining robust times for goods to be put on sale.Chung, Yao, Friesz, and Liu (2012) consider dynamic congestion pricing in the presence of demand uncertainty when flows correspond to dynamic user equilibrium on the network of interest and suggest a robust optimization approach based on a bi-level cellular particle swarm optimization.The robust, risk-sensitive, and data-driven control problem of Markov decision processes (MDP) is investigated in Le Tallec (2007), which develops a new connection between robust control of uncertain MDPs and risk-sensitive control of dynamical systems. In particular, he shows a duality between the penalized worst-case control of uncertain MDPs with rectangular uncertainty and the minimization of a Markovian dynamically consistent convex risk measure of the sample cost. This new notion of risk is shown to have desirable properties for multi-period decision making.Bertsimas and Doan (2010) consider robust and data-driven approaches to a fluid model of call centers that incorporates random arrival rates with abandonment to determine staff levels and dynamic routing policies. Kirkizlar, Andradottir, and Ayhan (2010) investigate the robustness of policies known to be optimal or near-optimal for Markovian systems when used to assign servers to tasks in non-Markovian systems.Bertsimas, Gamarnik, and Rikun (2011) apply the robust optimization framework to performance analysis in queueing networks. The authors model the underlying primitives of those stochastic networks as deterministic rather than stochastic and assume that they satisfy the implications of the probability laws used in the stochastic model, which take the form of simple linear constraints in the deterministic world. They then derive performance bounds and show that these bounds imply similar bounds in the corresponding stochastic queueing models. The interface of queueing systems and robust optimization is further explored in Rikun (2011). The reader is referred to Bandi and Bertsimas (2012) for related work from a broader perspective.Wiesemann, Kuhn, and Rustem (2013) consider robust Markov Decision Processes (MDPs) that offer probabilistic guarantees in view of the unknown distributional model parameters, assuming that an observation history of the MDP is available. The authors derive a confidence region that contains the unknown parameters with a prespecified probability and determine a policy that attains the highest worst-case performance over this confidence region by using the solution of tractable conic programs of moderate size.Stochastic games with applications to homeland security and flow control in a single-server queueing system are studied in Kardes (2007), which proves the existence of equilibrium points under some assumptions and provides an explicit mathematical programming formulation for an equilibrium calculation. Hörner and Lovo (2009) define and investigate belief-free equilibria in two-player games with incomplete information. Pita et al. (2009) analyze real-world Stackelberg games under human uncertainties, while Ordonez and Stier-Moses (2010) extend the Wardrop traffic assignment problem by adding flow-independent random deviations to the cost functions that model congestion in each arc. Kardes, Ordonez, and Hall (2011) apply concepts from discounted robust stochastic games to queueing control.Xu (2009) and Fertis (2009) investigate applications of robust decision-making to machine learning and statistical estimation, respectively. Both analyze the connection between robustness and successful learning by proving that certain estimators are special cases of robust optimization problems. Xu (2009) proposes novel robust learning algorithms and Fertis (2009) develops robust maximum likelihood estimators for a class of problems. Robust estimation and regression are also the focus of Nguyen (2009), which presents computationally efficient methods for robust mean-covariance estimation and robust linear regression using special mathematical programming models and semi-definite programming, and implements these methods in portfolio management. In addition, Xu, Caramanis, and Mannor (2009) analyze regularized support vector machines (SVMs) and show an equivalence with a new robust optimization formulation, with implications both for algorithms and analysis. Xu, Caramanis, and Mannor (2010) consider l1 norm regularized least squares (“Lasso”) and show that the solution to Lasso, in addition to its sparsity, has robustness properties, in the sense that it is the solution to a robust optimization problem. Robust optimization in the context of machine learning is described in detail in Caramanis, Mannor, and Xu (2011). Finally, Xu, Caramanis, and Sanghavi (2012) study robust principal component analysis in the presence of contaminated data.As another application, robust classification using support vector machines (SVM) – a type of learning algorithms – is the focus of Trafalis and Gilbert (2007). The authors provide second order cone programming and linear programming formulations for the training of a SVM when a bounded perturbation is added to the value of an input. Ben-Tal, Bhadra, Bhattacharyya, and Nath (2011) study the problem of constructing robust classifiers when the training is subject to uncertainty. The problem is formulated as a chance-constrained program that is relaxed using Bernstein’s approximation, which is richer than the traditional Chebyshev bound, to yield a second-order cone problem whose solution is guaranteed to satisfy the original problem.A topic that has received growing attention is the design and analysis of robust optimization models to the area of energy systems. In particular, (Zhang & Guan, 2009) investigate the two-stage unit commitment problem with uncertain demand and propose a tractable solution method. Ribas, Hamacher, and Street (2010) develop a strategic planning model for an integrated oil supply chain considering three sources of uncertainty: crude oil production, demand for refined products and market prices. To deal with these uncertainties, three formulations are proposed: (1) a two-stage stochastic model with a finite number of realizations, (2) a robust minmax regret model and (3) a maxmin model. These models are applied to Brazil’s oil chain under a 10-year time horizon. The results indicate significant financial differences between the three formulations, depending on the agent’s risk profile.A robust power grid optimization problem is presented in Jiang, Zhang, Li, and Guan (2010) using an integer programming model. Bertsimas, Litvinov, Sun, Zhao, and Zheng (2011) propose a two-stage adaptive robust optimization model for the security constrained unit commitment problem in the presence of nodal net injection uncertainty. The solution methodology is based on a combination of Benders’ decomposition and outer approximations, and is tested on a large-scale power system operated by the ISO New England. In addition, a Benders decomposition for the two-stage security constrained robust unit commitment problem is described in Jiang, Zhang, Li, and Guan (2011). Finally, an application of robust optimization to renewable energy, specifically wind energy, is considered in Jiang, Wang, and Guan (2012), with the objective of providing a robust unit commitment schedule for the thermal generators in the day-ahead market that minimizes the total cost under wind output uncertainty.An important application of robust optimization is the “public good” area, i.e., examples with an immediate benefit for the health, safety or well-being of the general public, such as the optimization of medical treatment and humanitarian supply chains. Bortfeld, Chan, Trofimov, and Tsitsiklis (2008) present an application to radiation therapy, where uncertainties due to breathing motion need to be taken into account to determine treatment plans for cancer patients.The problem of bringing robustness to patient flow management in the context of optimized patient transports in hospitals is addressed in Hanne, Melo, and Nickel (2009). A robust optimization approach to evacuation planning under uncertainty is presented in Yao, Mandala, and Chung (2009). Cromvik and Patriksson (2010b) apply results on the robustness of stochastic mathematical programs with equilibrium constraints to intensity-modulated radiation therapy, in addition to traffic network design. Further, Chen et al. (2011) proposes a robust optimization approach for managing hospital beds for emergency and elective inpatients.In the context of humanitarian supply chains, Ben-Tal, Do Chung, Mandala, and Yao (2011) document the performance of a dynamic (affinely adjustable) robust optimization approach to solve emergency response and evacuation traffic flow problems with time dependent demand uncertainty. Southwell (2012) formulates a robust and flexible model of decision analysis under risk and uncertainty under various metrics.Finally, Goryashko and Nemirovski (2011) optimize daily operation of pumping stations under demand uncertainty, based on the concept of Affinely Adjustable Robust Optimization.

@&#CONCLUSIONS@&#
In this paper we have reviewed recent developments in the literature on robust optimization in operations research and management science. The large number of papers published on robustness and robust optimization since 2007 is a testimony to the vitality of this research area both from a theoretical perspective and in terms of practical applications. Key recent developments include: (i) an extensive body of work on robust decision-making under uncertainty with uncertain distributions, i.e., “robustifying” stochastic optimization, (ii) a greater connection with decision sciences by linking uncertainty sets to risk theory, (iii) further results on nonlinear optimization and sequential decision-making and (iv) besides more work on established families of examples such as robust inventory and revenue management, the addition to the robust optimization literature of new application areas, especially energy systems and the public good. We expect that issues such as distributionally robust optimization, tractability of policies in large-scale dynamic problems under high uncertainty, and application-specific frameworks in particular in the “hot topics” areas of health care and energy systems, will continue to receive much attention in the years to come.