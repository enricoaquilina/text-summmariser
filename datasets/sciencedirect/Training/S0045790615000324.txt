@&#MAIN-TITLE@&#
Brain tumors detection and segmentation in MR images: Gabor wavelet vs. statistical features

@&#HIGHLIGHTS@&#
A fully automatic system for detection of slices that contain tumor in MR images is presented.A fully automatic system for tumor segmentation using single-spectral MR images is presented.A study for evaluating the efficacy of statistical features over Gabor wavelet features is included.

@&#KEYPHRASES@&#
Lesion detection/segmentation,Gabor wavelet features,Statistical features,MR imaging,T1-weighted,Fluid-attenuated inversion recovery,

@&#ABSTRACT@&#
Automated recognition of brain tumors in magnetic resonance images (MRI) is a difficult procedure owing to the variability and complexity of the location, size, shape, and texture of these lesions. Because of intensity similarities between brain lesions and normal tissues, some approaches make use of multi-spectral anatomical MRI scans. However, the time and cost restrictions for collecting multi-spectral MRI scans and some other difficulties necessitate developing an approach that can detect tumor tissues using a single-spectral anatomical MRI images. In this paper, we present a fully automatic system, which is able to detect slices that include tumor and, to delineate the tumor area. The experimental results on single contrast mechanism demonstrate the efficacy of our proposed technique in successfully segmenting brain tumor tissues with high accuracy and low computational complexity. Moreover, we include a study evaluating the efficacy of statistical features over Gabor wavelet features using several classifiers. This contribution fills the gap in the literature, as is the first to compare these sets of features for tumor segmentation applications.

@&#INTRODUCTION@&#
Medical imaging has a significant role in diagnosis and prognosis of brain tumors, which has helped to manage and diminish the effects of the disease. Magnetic resonance imaging is one of the most popular medical imaging techniques [1]. This is because MRI is non-invasive (using no ionizating radiation), and capable of showing various tissues at high resolution with good contrast. Another advantage of MRI is to produces multiple images of the same tissue region with different contrast visualization capabilities by means of applying different image acquisition protocols and parameters [2]. These multiple images provide useful additional anatomical information about the same tissue region. Complementary information from different contrast mechanisms helps researchers study brain pathology more precisely.In dealing with MR images, one of the most challenging problems is to partition some specific cells and tissues from the rest of the image. This defines the process of segmentation [3]. More specifically, image segmentation involves manually or automatically partitioning the image into a set of relatively homogeneous regions with similar properties, each of which can be tagged with a single label [1]. Segmentation helps physicians find lesions more accurately; therefore, it is an important and crucial process in computerized medical imaging. In manual segmentation, the tumor areas are manually located on all contiguous slices in which the tumor is considered to exist, but this is an expensive, time consuming and tedious task. In addition, it is subject to manual variation and subjective judgments, which increases the possibility that different observers will reach different conclusions about the presence or absence of tumors, or even that the same observer will reach different conclusions on different occasions [4]. Clearly, an automated brain tumor segmentation technique is needed.Although there are several general segmentation methods such as thresholding [5], region growing [6], and clustering [7], they are not easily applicable to the domain of brain tumor identification. This is because intensity similarities between brain tumors and some normal tissues can engender confusion within the algorithm. For example, in T1-weighted (T1-w) MR images, a tumor has intensities similar to those of gray matter (GM) or cerebrospinal fluid (CSF) [1]. In order to overcome this problem, many researchers use multi-spectral MR images for tumor identification [8–10]. However, this approach has four main difficulties [4]. First, acquiring such data is not always feasible due to patients’ condition, severity, and urgency. Second, collection of multi-spectral MR images is expensive. Third, much of the information collected is redundant that increases the data processing time and the likelihood of segmentation errors. And finally, multi-spectral MRI data suffer from inconsistency and misalignment, which requires image registration and bias correction prior to applying the segmentation algorithm [5]. Note that any inaccuracy in registration or bias correction stages will directly affect the precision of tumor segmentation.Owing to the above limitations, we propose in this paper an automated algorithm for tumor detection and segmentation based on 2D single-spectral anatomical MR images. The algorithm includes tumor detection, tumor segmentation, and efficacy evaluation of feature sets. We propose a tumor detection technique based on comparison of mutual information of histograms of the two brain hemispheres. After detection of an image (slice), which includes tumor tissue, it is fed into the segmentation stage in order to delineate the tumorous area. We obtain the candidate tumor regions using a sliding window, which sweeps the whole brain tissue. A proposed post-processing method is applied to remove the false positives/negatives.It is obvious that characterization of tumor that can differentiate various type of tissue is very important and depends to a great extent on the choice of the extracted features to describe the region of interest or its quasi-homogenous regions [11]. A vast variety in location, size, shape, and texture of tumor tissue makes feature extraction a perplexing task. Moreover, in MR brain images various tissues such as white matter, gray matter, and cerebrospinal fluid have complicated structures that increase the difficulty of efficient feature extraction. Despite studies focused on extraction of features useful for tumor segmentation [12–14], the relevant literature has not provided a comparison of which feature extraction technique is more efficient for this kind of applications. In this paper, we apply the two most popular sets of well-established and competent texture-based feature extraction techniques. First is the Gabor wavelet feature extraction method that captures frequency, locality, and orientation, providing multi-resolution texture information about the spatial domain as well as the frequency domain. The second set, statistical features extraction method, is based on applying texture-based feature extraction methods, such as gray level co-occurrence matrix (GLCM), gray level run length matrix (GLRLM), histogram of oriented gradient (HOG), and linear binary pattern (LBP). These feature extraction methods reflect the relationship between the intensity of two image pixels or groups of pixels. Furthermore, they estimate image properties related to first- and second-order statistics. Besides tumor detection and segmentation, we also offer a study on the effectiveness and complexity of these two feature extraction methods in this application. To reduce the danger that the attained conclusion is only due to some idiosyncrasies of the employed machine-learning technique, we performed our experiments using several classifiers such as support vector machine (SVM), k-nearest neighbor principle (KNN), sparse representation classifier (SRC) [15], nearest subspace classifier (NSC), and k-means clustering. Two different MR images – T1-weighted and fluid-attenuated inversion recovery (FLAIR) – are separately processed in this study.Most of the methods discussed and reported in the field of brain tumor segmentation suffer from dependence on multi-spectral MRI data [16,17], multi-scale classification [18,19], and local or global registration [18]. Other limitations are computational complexity and lack of full automation [20,21]. In this paper, we address the above-mentioned shortcomings. For example, our proposed algorithm is independent of atlas registration, control groups, and prior anatomical knowledge. Note that, any inaccuracy in the registration or bias correction stages will directly affect the precision of the tumor segmentation. Further, prior anatomical knowledge dependence conditions algorithms to be trained to incorporate such information, which can lead to error.Our other contribution is computational efficiency combined with much improved accuracy. Furthermore, it is based on single-spectral MRI. Because collecting of multi-spectral MR images is time- and cost-consuming, acquisition of just one spectral MRI data is much more practical. Our method is also fully automatic with no need for any human intervention or initialization. Additionally, in this work we employ five effective texture-based statistical feature extraction methods for tumor segmentation by using the fact that brain tumors often have special structures compared to healthy brain tissues owing to the effect of angiogenesis. The other contribution is comparison of efficacy of these features with the widely used Gabor wavelet features.The rest of the paper is organized as follows. Section 2 summarizes the feature-extraction methods employed. Our experimental methodology (including data preparation) is described in Section 3. The experimental results and discussion are presented in Section 4, while the conclusion appears in Section 5.In this paper, we compare two sets of features. The first set includes Gabor wavelet features, which are extracted using Gabor wavelet transform. The second set consists of statistical features, which are extracted using different texture-based feature extraction techniques: GLCM, GLRLM, HOG, and LBP methods. In this section we briefly discuss these texture-based feature extraction methods.Gabor-wavelets capture the local structure of the image corresponding to spatial frequency (scales), spatial localization, and orientation selectivity [12]. Therefore, they are extensively applied to several research domains including texture analysis and image segmentation. In the spatial domain, a two-dimensional Gabor filter is a Gaussian kernel function modulated by a complex sinusoidal plane wave, defined as:(1)G(x,y)=f2πγηexp-x′2+γ2y′22σ2exp(j2πfx′+ϕ)wherex′andy′are defined as:(2)x′=xcosθ+ysinθy′=-xsinθ+ycosθwherefis the frequency of the sinusoid,θis the orientation of the normal to the parallel stripes of a Gabor function,ϕis the phase offset,σis the standard deviation of the Gaussian envelope andγis the spatial aspect ratio which specifies the ellipticity of the support of the Gabor function. Typically, researchers use Gabor wavelets filters in five different scales and eight orientations. In this work, we follow the same convention as shown in Fig. 1.Mean, median, average contrast, energy and entropy, skewness and kurtosis are useful first-order statistical features. Mean is the average value of the intensity of the image. Variance indicates the intensity variations around the mean. Skewness quantifies the asymmetry of the histogram around the mean. Kurtosis is the flatness of the histogram. Entropy reveals the randomness of intensity values. Formulae for these features are listed as follows [22]:(3)Mean:μ=∑i=0G-1iP(i)(4)Average contrast:σ2=∑i=0G-1(i-μ)2P(i)(5)Skewness:μ3=σ-3∑i=0G-1(i-μ)3P(i)(6)Kurtosis:μ4=σ-4∑i=0G-1(i-μ)4P(i)-3(7)Energy:E=∑i=0G-1[P(i)]2(8)Entropy:H=-∑i=0G-1P(i)log2[P(i)]whereGis the maximum gray level of the image andP(i)is the probability density of the intensity levels which is obtained from:(9)P(i)=h(i)/Nwhereh(i)is the total number of pixels with intensity level(i)andNis the total number of pixels in the image.Spatial gray level co-occurrence estimates image properties that are related to second-order statistics, reflecting the relationship among pixels or groups of pixels (usually two). The GLCM is a 2D histogram that describes the occurrence of pairs of pixels that are separated by a certain distance,d. LetI(x,y)be an image with sizeN×M, and withGgray levels, and(x1,y1)and(x2,y2)be two pixels with gray level intensitiesiandj, respectively. When takingΔx=x2-x1in the x direction andΔy=y2-y1in the y direction, the connecting straight line has a directionθwhich is equal toarctan(Δy/Δx). The normalized co-occurrence matrixCθ,dis defined as:(10)Cθ,d(i,j)=(Num{((x1,y1),(x2,y2))∈(N×M)×(N×M)|A})/KHere A is a given condition, such as(Δx=dsinθ),(Δy=dcosθ),(I(x1,y1)=i),and(I(x2,y2)=j). Further on,Numrepresents the number of elements in the co-occurrence matrix andKis the total number of pairs of pixels [23]. Normally,d=1,2andθ=0°,45°,90°,135°are used for calculation. Eight different texture features are defined using co-occurrence matrix as follows [14]:(11)Entropy:-∑i=0G-1∑j=0G-1Cijlog2Cij(12)Correlation:∑i=0G-1∑j=0G-1ijCij-μxμyσxσy(13)Homogeneity:∑i=0G-1∑j=0G-1Cij1+|i-j|(14)Absolute value:∑i=0G-1∑j=0G-1|i-j|Cij(15)Inertia(contrast):∑i=0G-1∑j=0G-1(i-j)2Cij(16)Inverse difference:∑i=0G-1∑j=0G-1Cij1+(i-j)2(17)Maximum probability:Ci,jmaxi,j(18)Angular second moment(energy):∑i=0G-1∑j=0G-1(Cij)2whereCijis the(i,j)th element of the co-occurrence matrix.GLRLM is a spatial domain second-order statistical method that assigns a quantitative parameter to a spatial domain gray level value. In GLRLM, a texture primitive called gray level run length is considered to be the maximum collinear attached set of pixels with the same gray level. The gray level runs are characterized by the length and direction of the run for a particular gray value [24]. To calculate GLRLM, the number of gray level runs of various lengths must be ascertained. In the gray level run length matrix ofR(θ)=[r′(i,l|θ)], the elementr′(i,l|θ)provides an estimate of the number of times an image contains a run with a length ofl, for a gray level i, in the direction of angleθ. The gray level run length matricesR(θ)are calculated for 0°, 45°, 90° and 135°. The following five GLRLM features are calculated using these matrices:(1)SRE: Short Run Emphasis:(2)LRE: Long Run Emphasis:(3)GLD: Gray Level Distribution:(4)RLD: Run length Distribution:(5)RP: Run Percentage:HOG features are descriptors frequently used for object detection purposes in image processing and computer vision. The rationale behind these descriptors is that local object appearance and shape can be described by a distribution of intensity gradients or edge directions. The technique sums-up incidences of gradient orientation in localized portions of an image [25]. HOG is computed on a dense grid of uniformly spaced cells, and uses overlapping local contrast normalization for higher accuracy. In HOG, an image is divided into small, connected regions called cells, and for each cell a histogram of gradient directions or edge orientations is compiled for the pixels inside the cell. The combination of these histograms then constitutes the descriptor. For improved accuracy, the local histograms can be contrast-normalized by calculating a measure of the intensity across a larger region, called a block, and then using this value to normalize all cells within the block. This normalization offers lower sensitivity to changes in illumination or shadowing. Eighty HOG features are derived in this work.The LBP operator [26] sweeps a window over the image and gives labels to central pixel of the window by thresholding its neighborhood with the central value and specifying binary numbers for its neighbors. Then the LBP calculates the sum of the binary numbers multiplied by powers of two increasing clockwise or counterclockwise. The histogram of these 256 different labels is used as a texture descriptor. Considered neighborhood can be in different sizes. Any radius and any number of pixels in the neighborhood can be used. In the following, the notation(P,R)will be used for pixel neighborhoods, which meansPsampling points on a circle of radius ofR. The value of the LBP code of a pixel(xc,yc)is given by:(25)LBPP,R=∑p=0P-1S(gp-gc)2pS(x)=1ifx⩾00otherwisewheregis the pixel intensity value. We have chosenP=8andR=1 in our experiment.The proposed automated algorithm includes detection of slices containing tumor, MRI intensity normalization, windowing, feature extraction, dimensionality reduction, classification, post-processing and feature efficacy evaluation. Our proposed method for tumor slice detection is based on histogram asymmetry between the two brain hemispheres. We first divide the brain into two hemispheres by finding the longest diameter as the brain midline. In order to detect histogram asymmetry, histograms of each hemisphere are obtained. Then, using mutual information of their histograms, the slice likely to contain a portion of the tumor is determined. After recognition of a slice, which includes tumor tissue, the slice is fed into the segmentation stage, which localizes the tumor area. We obtain the candidate tumor regions using a sliding window, which sweeps through the whole brain tissue in the detected slice. A tumor classification approach described below is then applied to every instance of the window. If the window is classified to have tumor, the central pixel of the window will be labeled as tumor. On the other hand, if it is classified as healthy, the central pixel will be labeled as healthy. A proposed post-processing method is applied to remove the false positives/negatives.Additionally, we report a study in which we compare the efficiency of Gabor wavelet features with a set of statistical features; i.e., the two main groups of competent and successful texture-based features in tumor segmentation. Several classification methods such as SVM, KNN, SRC, NSC, and the k-means clustering are applied for efficacy evaluation of the two feature sets. Final results are then compared using three performance criteria described below. The overall process is depicted in Fig. 2.The Gabor wavelet features and statistical features possess different capabilities for accurate MRI lesion segmentation. We will quantify this capability using a multistage algorithm and three commonly used performance criteria: sensitivity, specificity, and accuracy. Having the following definition;TruePositives(TP)=correctly classified positive examples,TrueNegatives(TN)=correctly classified negative examples,FalseNegatives(FN)=incorrectly classified positive examples,FalsePositives(FP)=incorrectly classified negative examples,let us denote the numbers of true positives, true negatives, false negatives, and false positives bynTP,nTN,nFN, andnFP, respectively. The aforementioned performance criteria are then defined as follows:(27)Sensitivity=nTP(nTP+nFN)100%(28)Specificity=nTN(nTN+nFP)100%(29)Accuracy=(nTP+nTN)(nTP+nTN+nFP+nFN)100%The main idea in tumor slice detection is based on histogram asymmetry between the two brain hemispheres. Dividing the brain into two hemispheres is achieved by finding the longest diameter as the brain midline. In order to find histogram asymmetry, histograms of each hemisphere is calculated. Then, using mutual information [27], slices likely to contain the tumor are determined.The algorithm includes six steps. The first step separates the brain from the background. The second uses the center-mass algorithm to find the brain’s center. The third finds the brain’s borderline; cf. Fig. 3(b). The fourth determines the lengths of all possible brain diameters. The fifth step designates the longest diameter as the brain midline; cf. the midline shown in Fig. 3(c) and (d). The sixth step finds the tumor slice based on mutual information between histograms of the two brain hemispheres. Using the brain midline, the intensity histogram for each hemisphere is calculated. In both synthesized and real databases we use, the number of slices is the same for all subjects. In this case, we can assume that the corresponding slices represent the same region of the brain, which have almost similar structures. This gives us the opportunity to create the standard histograms for healthy brain hemispheres for all slices using the training data; cf. Fig. 4(a). These standard histograms are compared with the histograms of the testing data in order to find the hemispheres containing tumor. Fig. 4(b) and (c) show sample histogram of healthy and tumor hemispheres. This method has the advantage of finding the exact tumor hemisphere, which facilitates the segmentation process to search only in the hemisphere of interest. If the number of slices is not consistent, another approach is to calculate the mutual information between histograms of the two hemispheres of a single brain image. In this case, the segmentation algorithm needs to search the whole brain (not only one brain hemisphere).The size of the tumors detectable by this method depends on the threshold for the amount of mutual information. Higher values make it easier to detect small tumors, but only at the cost of a certain percentage of false positives (healthy slices are determined to contain tumor tissue). On the other hand, a lower threshold prevents false positives, but the algorithm will not be able to detect small tumors. This is a trade-off problem as a degree of freedom for the designer depending on the application. In our experimental case, we chose the threshold based on observations of the training data, tolerating the system’s failure to detect very small and hardly visible tumors.Due to the intra-scan and inter-scan image intensity variations, after detection of slices that include tumor, we normalize the MR image intensity. Image intensity normalization is necessary in quantitative texture analysis. There are six MRI intensity normalization methods: contrast stretch normalization, intensity scaling, histogram stretching, histogram normalization, Gaussian kernel normalization, and histogram equalization. Based on the result of [28], the histogram normalization method presents the best performance compared to the other normalization methods. Here the histogram normalization method is applied prior to quantitative texture analysis, which is about stretching and shifting the original image histogram in order to include all the gray scale levels in the image. It is defined as:(30)f(x,y)=GWM-BWMhmax-hmin(h(x,y)-hmin)+BWMwhereh(x,y)is the original histogram of the initial image,f(x,y)is the new histogram, andhminandhmaxare the smallest and largest gray scale level, respectively.GWMandBWMare the new minimum and new maximum intensity levels.In order to create the training set, we automatically crop random windows from each selected hemisphere containing tumor. Having the brain midline and borderline helps us to restrict the windows to just cover the brain tissue and not the background. For the test step, a same-sized sliding window sweeps over all the brain, excluding the area outside the borderline. Two sets of features, Gabor wavelet features and statistical features, are extracted using the aforementioned feature extraction methods.The Gabor wavelet features and statistical features are extracted using Gabor wavelet transform, first-order statistical descriptors, GLCM, GLRLM, HOG, and LBP methods, as described in Section 2.Gabor-wavelet features are extracted by applying Gabor-wavelet kernels with five different scales and eight orientations on three different window sizes as33×33,45×45, and65×65windows. The length of the Gabor feature vector is 43,560, 81,000, and 169,000, with regard to33×33,45×45and65×65window sizes, respectively. Fig. 5illustrates the real parts of the results of applying Gabor wavelet filters to a sample window in the brain MR image.First-order statistical features include mean, median, average contrast, intensity energy and entropy, skewness and kurtosis. In our experiment, GLCM features are extracted by applying the angleθ=0°, 45°, 90° and 135°. In each orientation, GLCM matrix and eight derived features are calculated. GLRLM features are calculated for 0°, 45°, 90° and 135°. Extracted features are SRE, LRE, GLD, RLD, and RP in four directions. HOG features measure the occurrences of gradient orientations in the regional areas of the image. Using two scales and 8 orientations, eighty HOG feature values are extracted. Finally, the length of LBP features is 256. The total of seven first-order statistical features, 20 GLRLM features, 112 GLCM features, 80 HOG features, and 256 LBP features makes a 475-dimentional statistical feature vector (see Fig. 6).For feature dimensionality reduction, we rely on principal component analysis (PCA). PCA is a mathematical tool that uses an orthogonal transformation to project a set of possibly correlated variables into a group of linearly uncorrelated ones that are called principal components [29]. The principal components attempt to maintain most of the variability of the data. We apply PCA to each set of extracted features, obtaining principal (feature) vectors from which we then select those with the highest eigenvalues. We assume N nonzero eigenvectors as the output of the PCA. We select M eigenvectors corresponding to the highest eigenvalues. The optimal number of selected features (M) is obtained by calculating the reconstruction ratio,γ.γis defined as the ratio of the sum of the M selected eigenvalues to the sum of all eigenvalues, as:(31)γ=∑i=1Mλi∑i=1Nλiwhere theλisare the eigenvalues sorted in decreasingly magnitude. Here we choseγto be 0.99. In all our cases, a maximum of 20 features satisfy this constraint.For classification, four supervised robust classification techniques are applied and the results are compared. These techniques are SVM, KNN, NSC, SRC and one unsupervised clustering method, k-means.The number of healthy windows is generally much higher than the number of tumor windows, which makes the training set imbalanced. To avoid the usual difficulties known to be caused by imbalanced training sets, we preferred to use the same number of healthy windows as that of tumor windows. Training samples are randomly selected. A 10-folded cross-validation is used to validate the robustness of our model. Cross-validation helps also to prevent overfitting.After training the classifier, the recognition rate of the classifier on independent data (unseen during learning) is used as the indicator of our algorithm’s performance in tumor segmentation, and also each feature set’s suitability for tumor segmentation.Brain tumor image data used in this work were obtained from the NCI-MICCAI 2013 Challenge on Multimodal Brain Tumor Segmentation (http://martinos.org/qtim/miccai2013/index.html) organized by K. Farahani, M. Reyes, B. Menze, E. Gerstner, J. Kirby and J. Kalpathy-Cramer. The challenge database contains fully anonymized images from the following institutions: ETH Zurich, University of Bern, University of Debrecen, and University of Utah and also publicly available images from the Cancer Imaging Archive (TCIA). All in all, twenty-five real and simulated T1-w and flair MR images of the brain with high-grade glioma are utilized in this study. A few examples of this data set (simulated T1-w brain images) are depicted in Fig. 7.As indicated, each window was treated as a separate training example, described by a feature vector. We label the training examples as positive or negative. An example is labeled as positive if tumor pixels cover more than half of the window. To be able to evaluate the statistical significance of our results, all experiments are conducted using the 10-folded cross-validation technique, which makes it possible to use t-test.Before proceeding to the work, we need to answer two questions regarding the conditions used in the experiments. What is the impact of noise reduction on texture-based feature extraction? What is the optimum size of the window?Regarding the first question, noise in the original image is reduced by Gaussian filters. Keeping all other conditions the same, statistical feature vectors are extracted with noise reduction, and then without noise reduction. The experiments summarized in Fig. 8show that noise reduction actually impaired classification accuracy when we apply texture-based features. Therefore, we decided to avoid noise reduction.Regarding the second question, different window sizes are tried. The statistical feature vectors obtained from three different window sizes (33×33,45×45, and65×65) are classified by several classification methods. As shown in Fig. 9, the window size45×45yields the highest accuracy. Based on this experience, we decide to use the45×45window size in the rest of the study.After a slice is recognized to contain tumor, we apply the segmentation process to localize the tumor area. We attain the candidate tumor regions using a sliding window that sweeps the whole brain tissue. Gabor wavelet and statistical feature sets are extracted from each instance of the window. After applying PCA for dimensionality reduction on each feature set, they are classified applying different approaches. If the window is classified to have tumor, the central pixel of the window will be labeled as tumor. On the other hand, if it is classified as healthy, the central pixel will be labeled as healthy. Fig. 10(b) shows the result of this labeling on three sample brain slices using statistical features and SVM with RBF kernel. As it can be seen, there are some parts of the tumor that are mistakenly labeled as healthy or some parts of the healthy tissue labeled as tumor by mistake. In order to remove these false positives/negatives, a consistency verification algorithm [30] is applied.That is, we use a majority filter to alter pixel labels that are inconsistent with their neighbor labels in a certain neighborhood. For instance, if the center pixel of a window is labeled as tumorous while the majority of the surrounding pixels are labeled as healthy, the center pixel’s label is simply switched to healthy. On the other hand, if a pixel inside the tumor area is mistakenly labeled as healthy, since the majority of the surrounding labels are tumor, it will switch to tumor. Here, consistency verification is applied in a 3×3 neighborhood window. The results of applying consistency verification algorithm are depicted in part (c) of Fig. 10. The accuracy of the proposed system is calculated by comparing the segmentation results to the golden standards, which are provided in the database (NCI-MICCAI 2013).Fig. 11shows the results of SVM with linear and RBF kernels for Gabor wavelet and statistical features extracted from T1-w images of simulated data. The horizontal axis represents the number of features used for classification purposes, and the vertical axis shows the classification accuracy. We can see that, with only 10 first features of the PCA output, the accuracy of the classifiers becomes stable. Using 10 features, the classification accuracies of SVM with linear kernel and RBF kernel are 94.8±0.3% and 96.1±0.2% for statistical features, and 91.7±0.4%, and 95.3±0.6% for Gabor wavelet features, respectively.The classification result of the KNN classifier is shown in Fig. 12. With only 10 first features of the PCA output the accuracy of the classifiers becomes stable. Using 10 features, the classification accuracies of KNN with k=1 and k=7 are 89.6±0.4% and 92.5±0.7% for statistical features, and 87.5±0.7%, and 90.7±0.8% for Gabor features, respectively.Fig. 13shows the results of NSC with Gaussian and general under-sampling for Gabor wavelet and statistical features. The NSC is a technique known to be very sensitive to noise and the result is polluted with distortions. Using 15 features, classification accuracies of NSC-Gaussian and NSC-general are 63.5±1.3%, 63.8±0.8% for statistical features, and 61.8±1.6% and 64.5±1.1% for Gabor features, correspondingly. In our experiments, the general case outperforms the Gaussian.Additionally, the accuracy of the sparse representation classifier becomes stable after applying only the first 12 features of the PCA output and offers78.1±0.4recognition rates for statistical features and71.1±0.2for Gabor feature, as it is depicted in Fig. 14.Next, unsupervised k-means clustering divides the feature vectors into two groups of normal and tumors. Labels achieved from k-means clustering for the test group are then compared with the real labels, and the accuracy is calculated. The classification accuracies of k-means using Euclidean and city-block distances are 83.2±0.1% and 85.4±0.1% for statistical features, and 69.6±0.3% and 71.3±0.2% for Gabor wavelet features, respectively.While many techniques for feature extraction have been published, we are not aware of any convincing comparative study in the domain of tumor segmentation. We have evaluated the proficiency and ability of two widely used feature sets – Gabor wavelets and statistical features – in this application. Table 1summarizes the classification accuracies achieved by different classifiers on T1-w images from simulated data described by the two different feature sets: Gabor wavelets, and statistical features. Table 2shows the classification accuracies of the same classifiers on FLAIR sequences of simulated dataset explained by two feature sets as Gabor wavelets and statistical features. Similarly, Tables 3 and 4show the result of classifiers on a real dataset, for T1-w and FLAIR modalities, respectively. It is clearly seen that in most cases statistical features provide higher accuracy than Gabor wavelets features.Of course, the picture provided by classification accuracy can be somewhat one-sided. For better insight, therefore, Tables 5–9present values of three performance criteria – sensitivity, specificity and accuracy – for T1-w images of a simulated dataset. It can be seen that statistical features lead to significantly better results for all three criteria in the case of SVM with linear and RBF kernels, KNN (k=1), SRC, NSC with Gaussian under-sampling, and k-means clustering. In NSC with general under-sampling case, Gabor wavelets features lead to better results for all three criteria. For KNN (k=7), the majority of better performances are still with statistical features. Similar experiments on FLAIR modality of simulated data, as well as, T1-w and FLAIR images of real data are applied and similar results are achieved.Although Gabor wavelets are employed widely in computer vision and medical image processing owing to their effective directional selectivity, they occupy a large amount of memory, and their high redundancy makes the computation slow. To get a better idea about these costs, we measured the run-times needed for the individual steps. The results summarized in Table 10were measured on an Intel Xeon CPU X5472 machine at 3GHz and with 64GB of RAM. We should remember that this concerns T1-w images of 25 subjects, for which each subject has 181 slices. Even in our laboratory conditions, although the feature extraction times for both Gabor wavelet and statistical features are almost the same, the dimensionality reduction using PCA is almost nine times faster for statistical features. Therefore, statistical features in comparison with Gabor wavelet features have the potential to be highly valuable in tumor segmentation methods.

@&#CONCLUSIONS@&#
In this paper, an integrated automated framework that is able to detect MR images containing tumor and then segment the tumor is implemented on T1-w and FLAIR sequences (separately). The notable accuracy of the algorithm in tumor segmentation in concert with its low computational complexity demonstrates the efficiency of our proposed method. Another main advantage is its independence from atlas registration, prior anatomical knowledge, or bias corrections that restrict the general application of many state-of-the-art methods. Another benefit of the proposed method is in the use of single-spectral MRI. While using multi-spectral MR images address the intensity similarities between tumor and healthy tissues, in many practical clinical situations only one type of anatomical MR image is collected due to time, cost, and patient situation limitations. In addition, use of multi-spectral data implies the need to ensure that each of the spectra must be properly registered. Additionally, despite some other methods’ need for initial assumptions, such as a given number of tissue classes or a multi-scale classification, our algorithm does not require any such input. This makes the proposed algorithm much more robust and general than other methods. As an additional study, we also compared the capability and efficacy of two different feature sets – Gabor wavelets and statistical features – in automated segmentation of brain tumor lesions in MRI images. Our comparison results indicate that statistical features usually offer higher accuracy than Gabor wavelet features. Moreover, statistical features have much smaller dimensionality than Gabor wavelet-based feature. Gabor wavelets features occupy a large amount of memory; they are highly redundant and lead to high computational costs. These observations seem to prove that statistical features are sufficiently adequate to discriminate tumor tissues from other tissue types in T1-w and FLAIR images.