@&#MAIN-TITLE@&#
Steady-state skill levels of workers in learning and forgetting environments: A dynamical system analysis

@&#HIGHLIGHTS@&#
We study worker skill-levels’ long-term characteristics under learning and forgetting.Our convergence results are applicable to general learning and forgetting functions.Using the dynamical system analysis approach has given our paper theoretical rigor.We provide numerous examples to support the practicality of our theoretical results.

@&#KEYPHRASES@&#
Manufacturing,Learning and forgetting,Batch production,Dynamical system,Skill level,Convergence results,

@&#ABSTRACT@&#
This article presents a study on the long-term (i.e., steady-state, convergence) characteristics of workers’ skill levels under learning and forgetting in processing units in a manufacturing environment, in which products are produced in batches. Assuming that all workers already have the basic knowledge to execute the jobs, workers learn (accumulate their skill) while producing units within a batch, forget during interruptions in production, and relearn when production resumes. The convergence properties in the paper are examined under assumptions of an infinite time horizon, a constant demand rate, and a fixed lot size. Our work extends the steady-state results of Teyarachakul, Chand, and Ward (2008) to the learning and forgetting functions that belong to a large class of functions possessing some differentiability conditions. We also discuss circumstances of manufacturing environments where our results would provide useful managerial information and other potential applications.

@&#INTRODUCTION@&#
This article investigates the problem of finding the long-term (i.e., steady-state) characteristics of batch production time in an environment where workers have to produce a fixed number of units of an item in batches at different points in time. Assuming that the workers already have the basic knowledge of operations to do the job, workers learn further while producing units within a batch, forget during interruptions in production, and relearn when production resumes; hence, learning and forgetting in processing time occurs intermittently in a batch manufacturing environment. We propose a model that will identify mathematical properties on general learning and forgetting functions that will be instrumental in studying the steady-state skill level of workers in such a batch manufacturing environment.Under batch manufacturing, the equipment is shared by several products, and the products are produced in batches (lots). Therefore, workers have to go through the process of a learn-forget-relearn cycle repeatedly. During the periods of production and non-production of an item, respectively, workers’ skills (in producing that item) improve and decline, as measured by the instantaneous amount of time it takes them to complete a unit. Batch production time is defined as the amount of time to complete a production of q units within a batch. In order to analyze the steady-state characteristics, an infinite-horizon assumption is assumed. We also assume a constant demand rate d and a fixed lot size q.In a learn-forget-relearn cycle manufacturing environment, scheduling tasks are complicated. Even for those tasks being performed by the same worker, depending on the worker’s skill level at the start of production, the batch production times for different production cycles could be inconsistent. Consequently, our steady-state results can help managers assess the long-term impacts on scheduling, costs, and time when producing the same item at the regular interval q/d. For instance, our steady-state batch production time can be used in computing the corresponding batch production-cost (such as labor cost); it is an important element of the average cost per cycle, in addition to inventory holding and setup costs. A manager can, in turn, use this information in determining the order quantity that is most cost effective (Teyarachakul et al., 2008). As to setting up standard times, Baloff (1966) suggested to use per-unit time when workers’ learning reach plateau. However, under the presence of learning and forgetting in batch manufacturing environments, the converged workers’ skill levels and the corresponding production times are particularly useful information in determining the appropriate standard times.Accurate understanding of the long-term influence of learning and forgetting in production will aid in estimating productivity, determining economic lot size, setting time standards, estimating wage incentives, and predicting labor requirements (Nembhard & Osothsilp, 2001). For example, the steady-state production rate for producing a particular product is obtained as the ratio of lot size to the steady-state batch production time. This is valuable information for a manager seeking better long-term productivity; if the steady-state production rate is lower than required, for example, the manager may need to use appropriate interventions (such as wage increase, investment in new production technology or equipments, or further training) to boost the learning rate and hence steady-state productivity.In this article we study the existence of steady-state skill level of workers in a batch production environment through the existence of fixed points. In the literature there are articles that consider similar problems. They either involve an experimental setting in which convergence to a unique value was observed (Sule, 1978; Globerson & Levin, 1987), or study a case of convergence to a unique value under specific functional forms of learning and forgetting (Axsater & Elmaphraby, 1981; Elmaghraby, 1990), or report a case of “alternating convergence” and investigate the average cost per period (Teyarachakul et al., 2008). The two cluster points case considered here, which is analogous to alternating convergence in the study of Teyarachakul et al. (2008), refers to a situation where the batch production time alternates between two distinct positive values in the steady-state.Our analysis indicates that, under certain learning and forgetting environments, the batch production time may either converge to a fixed value (call it the desirable level) or alternate between two distinct points. In the latter case, the batch production times of workers tend to move away from the desirable level during the transition from one cycle to the next. Thus, in such a scenario, when skill level of workers is not at this desirable level, their productivity level will oscillate between these two distinct points, one below and one above the desired level. As in the previous case, this information can be put into use to help the managers make appropriate scheduling decisions. Furthermore, a manager who has this information, rather than being concerned of the workers’ unreliable productivity, will predict such an outcome and is likely to make necessary interventions. This could be in the form of training workers to the desired level at the beginning of each production cycle so that their skill level will not change (since it’s a fixed value). Furthermore, our convergence results are likely to provide deeper understanding long-term perspective of learning and forgetting effects on a number of manufacturing problems such as group scheduling (Yang & Chand, 2008), and flexibility acquisition policy (Kher, Malhotra, Philipoom, & Fry, 1999).Although the work of Teyarachakul et al. (2008) is interesting in their discovery of a new type of convergence (referred to as alternating convergence there), their results are restricted to Globerson and Levin’s (1987) exponential forgetting function and Wright’s (1936) learning curve. There are large number of other well-performing predictors of learning and forgetting. A list of them can be found in Appendix A of Teyarachakul, Chand, and Ward (2011).In this article we consider general classes of learning and forgetting functions; develop a mathematical model to analyze characteristics of learning and forgetting functions that lead to the convergence or clustering in batch production time. Our results extend the application and scope of the results in Teyarachakul et al. (2008) Furthermore, our analyses are quite deterministic; namely, given any pair of learning and forgetting functions (see Appendix A of Teyarachakul et al. (2011), or Examples 1–3,4–7 in our Appendix A), in order to determine whether the convergence (to a single point) or two cluster point behavior is the case, all we need is to check if these functions satisfy the conditions (1), (2), and (3) in Section 2. Then Propertys 4.1 and 4.2 will help in final identification of the type. Hence, the applicability of our results go beyond that of previous work of the same nature.Besides providing a mathematical model describing and analyzing the behavior of workers’ skill levels, our results can also be utilized in predicting such patterns and develop appropriate actions/interventions. Namely, in a batch-production environment, where a manager has quite a good understanding of learning and forgetting trends of workers, by checking the parameters (1)–(3), he/she will know if workers’ skill level will converge or exhibit two-cluster point behavior. In the second case, the manager will likely to take some countermeasures to change the behavior to the convergence case, or will make use of the outcome to the benefit of the company in some way.In Lapre, Mukherjee, and Van Wassenhove (2000), the authors studied, in part of their analysis, a learning curve that links different types of learning in quality improvement and reduction of waste rate. As a part of this study, they collected empirical data on the production volume spanning seven years beginning at 1984. The data shows alternating levels of production rates from one year to the next. Although they have a good idea on the learning curve, there is no information on the forgetting trend. Without any idea on the forgetting, one cannot firmly claim that the resulting production pattern is due to a similar skill level pattern. But, it is likely that they are linked. An inquisitive manager who wants to determine the cause(s) leading to such production patterns will seek some additional information. Our model and analysis provide an effective tool to identify some possible factors contributing to this end.Any physical system that evolves in time, including the batch production environment under the investigation in this article, is an example of a dynamical system. Hence, it is natural to utilize the tools of dynamical systems in such a study. Fixed points of dynamical systems play a very important role in analyzing the long-term behavior of the states of a system; they are either attractive points of the system (to which all sequences in a certain neighborhood converge) or are repulsive points (from which all points, except the fixed point itself, move away). With these observations, this article will conduct investigations from the dynamical systems point of view; consequently, we provide a more rigorous approach to the steady-state results studied earlier (such as the ones in Teyarachakul et al. (2008)). In the meantime, we will also be able to study a wide variety of forgetting and learning functions simultaneously.The organization of this paper is as follows. First, in Section 2 we formulate the model, as well as define functions and related variables. The model properties and convergence characteristics are presented in Sections 3 and 4, respectively. In Section 5, we illustrate a scenario where case of two cluster points is observed, and how our model could be modified and be applied to other circumstances. Finally, we offer some final remarks and suggest future research opportunities. The appendix contains some selected examples for each of the convergence types studied.In a batch production environment, the length of a production cycle is defined as the difference in the start times of two consecutive batches. Without loss of generality, we assume the production rate is greater than the demand rate; consequently, a production run is followed by an interruption between two successive batches to deplete the stored inventory. Workers learn during the production and forget during the break (a learn-forget cycle) within each production cycle. We will define skill level x as the skill/learning gained from producing x−1 units by an inexperienced worker, with no interruption in production. Throughout this article x=x(t), where t is time, will denote the skill level of workers at time t. Hence, workers’ skill level at the beginning of the production cycle (at the state with no learning) is 1, i.e. x(0)=1. When there is no interruption, x is a strictly increasing function of time; however, in the batch production environment, which we consider here, this is not the case.Adopting the notation and terminology in Teyarachakul et al. (2008), a learning function L(x) is defined as the “instantaneous” per-unit production time at the instant when the skill level is x. Due to learning, the worker with higher skill level spends less time to complete one unit; hence L(x) is a strictly decreasing function. Throughout this article, L(x) will be assumed a twice differentiable function. Given the list of learning functions studied in the literature (see for example Appendix A in Teyarachakul et al. (2011)), this is not an unrealistic requirement. Furthermore, we will assume thatdL(x)dx<0,d2L(x)dx2>0and limx→∞L(x)=c, where c is a non-negative constant. These conditions are consistent with the fact that a worker gains more experience by producing additional units; the per-unit production time declines in a decreasing manner; and there is a limit on the reducible per-unit production time due to worker learning. Note that the properties of a learning function imply continuity of L(x) with a continuous and (twice differentiable) strictly-decreasing inverse.In batch production, the amount of learning is defined as the decrease in the unit production-time, more specifically, the amount of learning at the skill level x within a batch of q units is lq(x)=L(x)−L(x+xq), where xqis the skill level gained from producing q units. The batch production time pq(x) for q units starting with a skill level x is given bypq(x)=∫xx+xqL(s)ds. In turn, the interruption duration Iq(x) following the production interval that x belongs to is defined asIq(x)=qd-pq(x). In such an environment, skill level of workers (in producing a certain item) changes from one batch to the next. In order to study this change we introduce the skill transfer function Gq, where Gq(x) is defined to be the skill level at the start of the next batch when the skill level at the beginning of the current batch is x. Clearly, Gq: [1,∞)→[1,∞), and in general, we have Gq(x) <x+xq, because of the forgetting that takes place during interruption in batch production process.Forgetting in a batch production environment results in an increase in the unit production-time after an interruption; this is modeled by a forgetting function Fq(x)=F(L(x+xq), Iq(x)). Specifically, F(L,Iq) denotes the per-unit production time after an interruption of Iq(x) time units given a per-unit production time of L(x+xq) at the start of the interruption. Without forgetting, L(x+xq) would be the next-unit production time after the break Iq(x). The next unit production time after the break is Fq(x), and we have Fq(x)>L(x+xq) because workers loose some of their skills during the break between two consecutive batches. This loss of skill naturally results in some amount of forgetting, which we define as the increase in the unit production-time, due to an interruption. Hence, the amount of forgetting in a production cycle with interruption duration Iq(x) (with a batch of q units) is given asfq(x)=f(x,Iq(x))=Fq(x)-L(x+xq),which is always non-negative by the fact that Fq(x)>L(x+xq), and is also well defined once the functions L and Fqare chosen.Since Gq(x) is the skill level at the start of the next batch following the interruption duration Iq(x), the amount of forgetting is also defined as fq(x)=L(Gq(x))−L(x+xq) (see Fig. 1). Moreover, we have L(Gq(x))=L(x+xq)+fq(x)=L(x)−lq(x)+fq(x), from which it follows thatGq(x)=L-1(L(x)-lq(x)+fq(x)),since L(x) is invertible. Therefore, L(Gq(x))=Fq(x).We will assume that, as a function of L and Iq, the function Fqis differentiable with respect to L and Iqwith continuous derivatives, respectively. In addition we will assume that the following properties hold:1.∂fq(x)∂Iq>0equivalently,∂(F(L,Iq)-L)∂Iq>0.0<∂F(L,Iq)∂L<1for all L>0limIq→∞F(L,Iq)=L(1).These properties can be interpreted as saying that the amount forgotten is increasing in the interruption duration Iq(1); the per-unit time after an interruption F(L,Iq) is increasing in the per-unit time L at the start of the interruption (2); and the amount of forgetting is bounded by the cumulative amount learnt so far (3). These conditions are either intuitive (for example, you cannot lose experience or skills more than what you have had) and/or are strongly supported by evidence in psychology and in other related literature (see Bailey (1989), Shtub, Levin, & Globerson (1993), Nembhard and Osothsilp (2001); Teyarachakul et al. (2008); etc.).It should be emphasized here, that, once a learning function L and a forgetting function Fqare chosen (or determined empirically), the functions lq(x) and fq(x) are well-defined, and, in turn, the function Gq(x) is well-defined on the basis of them. Moreover, Gq(x) relates the influence of both learning and forgetting within a batch to the worker’s skill level at the start of the next batch. Also, it follows from the properties of the functions L and Fqassumed above, Gqis differentiable with a continuous derivative.Fact 2.1lq(x) is strictly decreasing in x, and fq(x) is strictly increasing in x.The proof of Fact 2.1. is given in Appendix B. In the rest of the article, we will be working in a batch production setting with a fixed batch of q units and a constant demand rate d with a learning function L and a forgetting function Fq(x) possessing the properties 1–3 above. Since q is fixed, for simplicity, we will drop the subscript q in all the functions. In this setting, if xnis the skill level of workers at the beginning of the nth batch and xn,qis the skill level gained from producing q units given xn, then xn+xn,qwill be the skill level at the end of producing q units; hence, L(xn) and L(xn+xn,q) are the unit production time at the start and at the end of the nth batch, respectively. Thus, we havel(xn)=L(xn)-L(xn+xn,q),f(xn)=L(xn+1)-L(xn+xn,q),andF(xn)=F(L(xn+xn,q),I(xn))=L(xn+1),and therefore,L(xn+1)=L(xn)-l(xn)+f(xn).Also, from the definition, G(xn)=xn+1. Consequently, given a skill level x at the beginning of batch 1, G1(x)=G(x) is the skill level at the beginning of batch 2, and the iterate Gk(x)=G(Gk−1(x)) is the skill level at the beginning of batch k+1, k⩾0. Intuitively, after the break and losing part of his/her skill level due to forgetting, a worker cannot start the production with the perfect skill level of infinity; so, we will assume that supx∈[1,∞)G(x)<∞, and therefore supx∈[1,∞)G2(x)<∞ too.Our major interest is in the long-term behavior of the batch production time function, i.e. inlimk→∞p(xk)=limk→∞p(Gk-1(x)).Naturally, this necessitates an in depth study of sequences of the form{Gk(x)}k=1∞. First, we note here that by the way G(x) is constructed, it must be a continuous function of x and so is each Gk(x).The behavior of the sequence {Gk(x)} might follow numerous patterns. If the convergence of the sequence does not take place in a monotonic fashion, it turns out that the function G2(x) provides further insight into the nature of the sequence {Gk(x)}. For this purpose, in this section we will analyze some essential features of the functions G(x) and G2(x). All the results in this section and the following one are based on the assumptions made in the previous section for the learning and forgetting functions used in constructing the skill transfer function G(x). Since we use the fixed-point properties to provide sufficient conditions for the convergence to hold, it is not so surprising that many properties of G(x) and G2(x) that we focus on are related to their fixed points. In the dynamical systems literature, as it also happens in other disciplines, notation and terminologies for some key objects may differ from one source to another. In order to avoid any potential confusion, we will adopt the terminology and notation used in Elaydi (2000) and Davidson and Donsig (2002).Property 3.1G(x) has a unique fixed point x∗.First, observe that if x∗ is a fixed point of G(x), then G(x∗)=x∗, and since L(G(x))=L(x)−l(x)+f(x), it follows that L(x∗)=L(G(x∗))=L(x∗)−l(x∗)+f(x∗); and hence, l(x∗)=f(x∗). Conversely, if x∗ is a point with l(x∗)=f(x∗) it follows that L(G(x∗))=L(x∗). Since L(x) is strictly decreasing, it is invertible, so G(x∗)=x∗ must hold. Hence x∗ is a fixed point of G(x). Therefore, we need to show that a point x∗ with l(x∗)=f(x∗) exists.The amount forgotten cannot exceed the amount of learning at the initial state, i.e., l(1)⩾f(1)⩾0. Since ℓimx→∞l(x)=ℓimx→∞[L(x)−L(x+xq)]=0, and since by Fact 2.1l(x) and f(x) are strictly decreasing and strictly increasing functions, respectively, there exists 1<x0<∞ such that l(x0)<f(x0). Therefore, the function h(x)=(l−f)(x) is a continuous strictly decreasing function with h(1)⩾0 and h(x0)<0. By Intermediate Value Theorem, there exists x∗∈[1,x0] such that h(x∗)=0, and equivalently, l(x∗)=f(x∗). Thus, x∗ is a fixed point of G(x). Since h is strictly decreasing, x∗ is unique.□The next property illustrates that if a skill level at the beginning of the current batch is less (greater) than the fixed point x∗, then a skill level at the start of the next batch will increase (decrease).Property 3.2Let x∗be a fixed point of G(x).(a)if x<x∗, then G(x)>x andif x>x∗, then G(x)<x.It follows from the proof of Property 3.1 that the function h(x)=(l−f)(x) is positive if x∈[1,x∗) and negative if x∈(x∗,∞). Thus, for x<x∗, l(x)>f(x). (See Fig. 2.) Hence, L(G(x))=L(x)−l(x)+f(x)<L(x). Since L(x) is strictly decreasing, G(x)>x must hold.This proves (a). The proof of (b) is similar.□The patterns of convergence in the worker’s experience level is greatly influenced by the sign of∂G(x)∂xand∂G2(x)∂x. Notice that since G2(x∗)=G(G(x∗))=G(x∗)=x∗, x∗ is also a fixed point of G2(x). However, G2(x) may possess other fixed points as well. The fixed points of G2(x), that are not fixed points of G(x), are the periodic points of G(x) with period 2. (We say that a is a periodic point of a function v(z) if there is a positive integer m such that vm(a)=a. The smallest such m is called as the period of a.)Property 3.3Let x∗be a fixed point of G(x).(a)Let∂G(x)∂x⩾0for all x. If x<x∗, then G(x)⩽x∗; if x>x∗, then G(x)⩾x∗.Let∂G(x)∂x<0for all x. If x<x∗, then G(x)>x∗; if x>x∗, then G(x)<x∗.Let∂G(x)∂x<0for all x and x′ be a fixed point of G2(x). If x<x′, then G2(x)<x′; if x>x′, then G2(x)>x′.Proofs of Properties 3.3, 3.4, 3.5 and 4.3 are provided in Appendix B. The interpretation of Property 3.3(a) is that if the skill level at the start of the next batch, G(x), increases with worker skill level x at the beginning of the current batch, then all elements in the sequence {Gk(x)} are either less than or equal to x∗ or greater than or equal to x∗. Otherwise (the case of∂G(x)∂x<0), the elements in the sequence {Gk(x)} alternate between being less than or equal to x∗ and greater than or equal to x∗ (Property 3.3(b)), and all elements of the odd subsequence or the even subsequence are either less than or equal to x′ or greater than or equal to x′ (Property 3.3(c)). Intuitively, Property 3.3 provides some information regarding the possible convergence patterns of the sequence {Gk(x)}, which we will discuss later.Property 3.4Let x∗be a fixed point of G(x) and suppose x′ is a fixed point of G2(x). Then,(a)G(x′) is also a fixed point of G2(x),x′≠x∗if and only if G(x′)≠x′,x′≠x∗if and only if G(x′)≠x∗.The number of fixed points of G2(x) is odd.In what follows, we limit our consideration to the properties of G2(x) with three or fewer fixed points. (Graphically, G2(x) crosses the line y=x at each of its fixed points.) Our analytical scope is justified by the fact that no function G(x) exists in the literature such that G2(x) has more than three fixed points or is tangent to the line y=x at some fixed points. Furthermore, our computational study of 108 cases of examples using Globerson and Levin’s S-Shaped and exponential forgetting functions (1987), along with Wright’s (1936) learning function, has yielded the same outcome. Therefore, the case of one or three fixed points, with G2(x) crossing the line y=x at each, seems natural and sufficiently serves our purpose in this convergence study. (See also the discussion in Section 4.) Properties 3.6 and 3.7 below provide additional information on the behavior of the function G2(x).Property 3.6Suppose G2(x) has only one fixed point, say x∗. If x<x∗, then G2(x)>x; if x>x∗, then G2(x)<x.G2(x) is a continuous function such that G2(x)⩾1 and ℓimx→∞G2(x)<∞. Thus, the graph of G2(x) must intersect the line y=x at some point, say x∗∈[1,∞). It also follows from the assumption of the single fixed point of G2(x) that G2(x)>x if x<x∗ and G2(x)<x if x>x∗.□Suppose G2(x) has three fixed points, say x−, x∗, x+with x−<x∗<x+, and crosses the line y=x at each fixed point. Then(a)G2(x)>x if x∈[1,x−) or x∈(x∗,x+),G2(x)<x if x∈(x−,x∗) and x∈(x+,∞).Similar to the proof of Property 3.6, G2(x) has the properties of continuity, G2(x)⩾1 and ℓimx→∞G2(x)<∞. It also follows from the assumption of three fixed points x−, x∗, x+ and the assumption that G2(x) intersects the line y=x at each fixed point and that, G2(x)>x if x∈[1,x−) or x∈ (x∗,x+); G2(x)<x if x∈(x−,x∗) and x∈(x+,∞) (see Fig. 3).□In this section we will discuss the possible types of convergence and the convergence behavior of workers’ skill levels. The behavior of the convergence of the sequence {Gk(x)} is greatly influenced by the sign of∂G(x)∂x. For instance, if∂G(x)∂x⩾0for all x, then the sequence {Gk(x)} converges to x∗ in a manner similar to the result obtained by Teyarachakul et al. (2008). Namely, if0⩽∂G(x∗)∂x, then x∗ is an attractive fixed point (Davidson & Donsig, 2002); that is, when x is close enough to x∗, the sequence {Gk(x)} converges to x∗. For the opposite case, when∂G(x)∂x<0for all x, two distinct cases are possible: either there is convergence to x∗ (i.e., x∗ is an attractive fixed point), or there is no convergence to x∗ (i.e., x∗ is a repelling fixed point, i.e. for all x≠x∗, in an interval U around x∗, the sequence {Gk(x)} leaves the interval U).Observe that, by the Mean Value Theorem,xn+2-xn+1=G(xn+1)-G(xn)=∂G(t)∂x(xn+1-xn)for some t∈(xn,xn+1). Since∂G(x)∂x<0for all x, if xn>xn+1, then xn+2>xn+1 (and if xn<xn+1, then xn+2<xn+1). Hence, the sequence {Gk(x)} alternates and may not converge to x∗. In order to gain more insight, one may look at the behavior of G2(x), which will explain the behaviors of the odd and even subsequences of {Gk(x)}. We will consider two circumstances: when G2(x) has a single fixed point and three fixed points. Recall that by Property 3.5, G2(x) cannot have an even number of fixed points.We will exhibit different behaviors of the sequence {Gk(x)} in separate cases. We call a pointx̃a cluster point of a sequence {Gk(x)} if a subsequence of {Gk(x)} converges tox̃.Case 1: The sequence {Gk(x)} converges tox∗. In this type of convergence, in the distant future (i.e., when k is large enough), every batch starts the production with a worker’s skill level at x∗.Case 2: The sequence{Gk(x)} has two distinct cluster points,x−andx+. In this case, the sequence {Gk(x)} is obviously not convergent (to the fixed point x∗), and in the distant future every other batch starts with the skill level x−, while the next batch begins with the skill level x+. That is, the skill level at the beginning of consecutive production cycles alternates between x− and x+. Note that both x− and x+ are fixed points of G2(x), but not of G(x). Under this type of behavior, the sequence {Gk(x)} is decomposed into two subsequences; the odd subsequence {G2k−1(x), k=1, 2, 3, …} and the even subsequence {G2k(x), k=1, 2, 3, …}. While one subsequence converges to x−, the other converges to x+, k→∞. Hence x− and x+ are distinct cluster points of {Gk(x)}.Next, we will provide sufficient conditions for each different behavior type of the sequence {Gk(x)}. We will also use the notation∂v(z)∂zz=α=∂v(α)∂zfor convenience.Property 4.1(Case 1: Convergence to the fixed point)Let x∗be the fixed point of G(x). If∂G(x∗)∂x>0or-1<∂G(x∗)∂x<0, then the sequence {Gk(x)} converges to x∗for any x∈(x∗−δ, x∗+δ) for some δ>0.Assume first that∂G(x∗)∂x>0. Since by Property 3.2, we have G(x)>x on [1,x∗) and G(x)<x on (x∗,∞),∂G(x∗)∂x⩽1must hold. If0<∂G(x∗)∂x<1, then x∗ is an attractive fixed point. Hence, there exists a δ>0 such that if x∈(x∗−δ, x∗+δ), then {Gk(x)} converges to x∗ (Davidson & Donsig, 2002).If∂G(x∗)∂x=1and the graph of G(x) is tangent to the line y=x at x∗, then the condition supx∈[1,∞)G(x)<∞ implies that G(x) must have another fixed point different from x∗. But this contradicts Property 3.1; hence, G(x) must cross the line y=x. Since∂G(x)∂xis continuous, given any ε such that0<ε<∂G(x∗)∂x, there exists δ>0 such that x∈(x∗−δ, x∗+δ) implies that∂G(x)∂x-∂G(x∗)∂x<ε. For such a point x, by Properties 3.2 and 3.3(a), we have x<G(x)<x∗ if x<x∗ and x>G(x)>x∗ if x>x∗. In either case, the sequence {Gk(x)} is a monotonic sequence and bounded by x∗; hence, it must converge to x∗.If-1<∂G(x∗)∂x<0, then0<∂G(x∗)∂x<1, and hence, x∗ is an attractive fixed point. Therefore, as in the case of0<∂G(x∗)∂x<1, there exists δ>0 such that for any x∈(x∗−δ, x∗+δ) the sequence {Gk(x)} converges to x∗.□The next statement provides conditions for {Gk(x)} to have two cluster points.Property 4.2Case 2: Two cluster-pointsLet x∗be the fixed point of G(x).If∂G(x∗)∂x<-1and∂G(x)∂x<0for all x, then there exists x−and x+such that x−and x+are distinct cluster points of the sequence {Gk(x)}.Since∂G(x∗)∂x<-1,x∗is a repelling fixed point (Davidson & Donsig, 2002). Thus, there is δ>0 such that if x∈(x∗−δ,x∗+δ) and x≠x∗ then {Gk(x)} does not converge to x∗. (Fig. 4illustrates the case when∂G(x∗)∂x<-1.)Since 1⩽Gk(x)<∞ for any x∈[1,∞), by the Bolzano-Weierstrass Theorem (Apostol, 1974), the sequence {Gk(x)} must have at least one cluster point. By Property 3.3(b), terms of this sequence take values both greater than and less than x∗, alternatingly. That is, the odd and even terms of the sequence will lie on different sides of x∗. In order to study the behavior of the sequence of odd terms and the sequence of even terms, we will resort to the function G∘G(x)=G2(x).First we observe that∂G2(x∗)∂x=∂G2(x)∂G(x)·∂G(x)∂xx=x∗=∂G2(x∗)∂G(x)·∂G(x∗)∂x=∂G(x∗)∂x2>1.Since G(x∗)=x∗ and∂G(x∗)∂x<-1, the point x∗ is a repelling fixed point for G2(x).Next, we will show that if∂G(x∗)∂x<-1, it is not possible for G2(x) to have a single fixed point. If x∗ were the only fixed point of G2(x), then by Property 3.6, for x<x∗, we would have G2(x)>x, and for x>x∗, we would have G2(x)<x. By Property 3.3(c), this would lead to two monotonic sequences bounded by x∗. That is, if x<x∗, we would havex<G2(x)<G4(x)<⋯<x∗andG(x)>G3(x)>G5(x)>⋯>x∗or if x>x∗, we would havex>G2(x)>G4(x)>⋯>x∗andG(x)<G3(x)<G5(x)<⋯<x∗where each of the subsequences are separated by x∗. By boundedness and monotonicity, both subsequences must be convergent with limits; say x1 and x2, and since x∗ is repelling,x∗≠x1 and x∗≠x2. But then x1 and x2must be fixed points of G2(x), which contradicts the condition that G2(x) has x∗ as the only fixed point. So, we assume that G2(x) has three fixed points. Now, by Propertys 3.7 and 3.3(c), we obtain that the subsequences {G2k−1(x)} and {G2k(x)} are bounded, monotonic and separated by x∗, which is repelling. Hence, {G2k−1(x)} and {G2k(x)} are convergent subsequences to x− and x+ which are fixed points of G2(x) and x−<x∗<x+.□It follows from the proof above that, in the case of two cluster points, if k is large enough, the locations of the terms Gk(x) in the sequence {Gk(x)} alternate between x− and x+ as shown in Fig. 5. Examples of both cases are provided in Appendix A.As illustrated in our analysis, both cases are observed in additional types of learning and forgetting functions (such as Bevis, Finnear, & Towill (1970) and Globerson & Levin’s S-Shaped Forgetting Function (1987)). See Appendix A.Remarks 11.In Property 4.2 we did not consider the possibility of∂G(x∗)∂x=-1. The reason being is that in that case there are numerous possibilities, many of which are not realistic. That is why, here we would like to consider a few possibilities in that situation, where we will assume∂G(x)∂xtaking constant values on intervals (x, x∗) and (G(x), x∗). Indeed, if∂G(x∗)∂x=-1and∂G(x)∂x<0for all x, then the sequence {Gk(x)} either converges to x∗ or has two cluster points. This claim is based on the following observation: using the Mean Value Theorem,G2(x)-x∗=∂G(r)∂x·∂G(t)∂x(x-x∗),where x∈(x∗−δ,x∗+δ), t∈(x,x∗) and r∈(G(x),x∗).α=∂G(r)∂x·∂G(t)∂xthen α is always positive. Consequently, if α<1, then x∗ is an attractive fixed point. Using an argument similar to the proof of Property 4.2, it can be shown that if α>1, then x∗ is a repelling fixed point, and therefore the sequence {Gk(x)} has two cluster points. When α=1, there are infinitely many distinct pairs of fixed points of G2(x); it is not the case under our consideration.The same proof also applies, with obvious modifications, to the cases that G2(x) has more than three fixed points.If one assumes the conditions∂G(x)∂x>0,-1<∂G(x)∂x<0, or∂G(x)∂x<-1for all x, then proofs of Properties 4.1, 4.2 are still valid (this time for all x rather than for if x∈ (x∗−δ,x∗+δ) for some δ). These are similar conclusions to those in the article by Teyarachakul et al. (2008).Both Properties 4.1 and 4.2 state the conditions on∂G(x∗)∂xand their impact on the behavior of the sequence {Gk(x)}. Next we will present the conditions implying-1<∂G(x∗)∂x<0or∂G(x∗)∂x<-1.Let x∗be the fixed point of G(x). Then,(a)∂G(x∗)∂x<1if and only if∂f(x∗)∂x>∂l(x∗)∂x-2∂L(x∗)∂x,∂G(x∗)∂x>1if and only if∂f(x∗)∂x<∂l(x∗)∂x-2∂L(x∗)∂x.So far, we have explored the behavior of the sequence {Gk(x)}, in which the existence of the fixed point x∗ plays an important role. The natural question following this analysis would be how one could find the limit x∗ in the convergence case. We propose using the well known Newton’s Method (Davidson & Donsig, 2002) to obtain the limit as a beginning procedure to study the convergence behavior of the sequence {Gk(x)}.Recall that at the fixed point x∗ we have l(x∗)=f(x∗). Let g(x)=(l−f)(x). Then, x∗ is the fixed point of G(x) if and only if g(x∗)=0. Now, we will describe two methods: the bisection method and Newton’s method in Properties 4.4 and 4.5, respectively, to obtain this fixed point.Property 4.4Bisection method to obtain x∗The (attractive) fixed point x∗of G(x) can be obtained as follows:1.Find a point x0 such that g(x0)<0 (which exists by the properties of the functions l(x) and f(x)).Letx1=12(1+x0). If g(x1)>0, letx2=12(x0+x1); if g (x1)<0, letx2=12(1+x1).Repeat this process to form a sequence {xm}; by construction, this sequence converges to the fixed point x∗.The (attractive) fixed point x∗of G(x) can be obtained as follows:1.Begin with any x0 such that g′(x0)≠0.Form a sequence {xm} byxm+1=xm-g(xm)g′(xm)for m=0, 1, 2, …The point to which {xm} converges is the fixed point x∗ of G(x).1.Bisection method of finding x∗ does not require any differentiability properties.Formally, Newton’s method requires the function g (x) (hence l(x) and f(x)) be twice differentiable. We assumed earlier that L(x) is twice differentiable and F(x) is differentiable (not necessarily twice differentiable); however, many of the functions L(x) and F(x) considered in the literature (hence l(x) and f(x)) are twice differentiable, hence Property 4.5 is applicable.Newton’s method is more powerful than just providing a way of obtaining the fixed points. It also provides reliable criteria for the speed of convergence to the fixed point. Namely, it implies that the sequence {xm} converges to the fixed point quadratically (see Davidson & Donsig, 2002, pp. 344–346 for details).In this section, we will discuss some real-world situations where: (a) one is likely to observe long-term batch production time alternate between two values as predicted by the results in Section 4, (b) one can utilize the information provided by our analysis (that batch production time may converge or may alternate between two values) in making managerial decisions, and (c) one can extend our results, with minor modifications to our model, to an environment with learning and forgetting in setups, where each setup begins at regular intervals.Any batch production setting where learning and forgetting functions exhibit slow decrease and increase, respectively, such as the functions in Appendix A, Examples 5 and 7, has the potential to exhibit long-term batch production time that alternates between two values. For example, the knowledge that a new production technique can alter the learning-forgetting interaction on a production line can be quite beneficial to a manager, who can make decisions that would yield positive results (increase in productivity, reducing costs, etc.), simply because the scheduling and coordination of tasks are simpler to execute. Consider an environment, where facilities (such as a production line) are shared, which produces two different products, each of which are in relatively steady demand; however, a competing manufacturer for Product 2 emerges. Each round of production starts with producing Product 1, then follows by processing Product 2, and then goes back to processing Product 1 and so on. Suppose batch production times of both products converge to their respective unique values (their fixed points). To better compete with the emerging competitor, the management decides to implement a new production method. This method is more efficient than the old method and has a different fixed point; however, they are sufficiently similar that the workers who are quite used to the old method now experience new learning and forgetting rates which increase and decrease slowly. Such an environment would quite possibly lead to the two-cluster case for Product 2, after a few iterations. A manager who is not aware that such a phenomenon (alternating skill levels) could occur may observe the changing production times and incorrectly conclude that the new method has failed since the production times have not stabilized. However, a manager informed about the existence of these cluster points would instead make the necessary interventions, such as effective scheduling or, training the workers up to the desired level (i.e., very close to the value of the new fixed point), for attaining a predictable productivity level.We briefly discussed in Section 1 that the information about the existence of the two cluster point case can be useful for workforce scheduling. As another example, consider a team of workers experiencing a situation of the two cluster point case, and, as a result, the batch production alternates between 1days (i.e., x+), and 5days (i.e., x−). Suppose that the workers are also skillful in producing a highly-profitable product with seasonal demand; this product is different from the one with steady demand that workers produce regularly. This highly-profitable product happens to have a peak demand during week N, which is a “slow” week (i.e. 5days) of production for the steady-demand product. Given this situation, a manager handles his work force scheduling by hiring temporary workers to increase the production rate of the steady-demand product (e.g. finishing in 3days rather than 5). Therefore, the skilled workers would be available sooner to work on the more profitable product for a longer time. Although this intervention seems intuitively obvious (and it’s the most likely one); our analysis provides a solid mathematical basis that justifies such intervention.The steady-state results obtained in Section 4 have the potential to be applicable, with minor modifications, to other business environments. Consider the case, where learning and forgetting occurs in the process of setting up an operation (defined as learning and forgetting in setups), which is performed at regular intervals (such as every day at 8:00am, or on Monday of every week, or on the first day of every month) far enough in the distant future, and learning and forgetting is assumed to satisfy characteristics listed in Section 2. In practice, if the task of setting up machines or an operation is labor-intensive, procedural, and performed through a series of different activities and decisions, such a process is influenced by workers’ learning and forgetting. Under these circumstances, a worker’s learning occurs during the setting up process and forgetting occurs during the time gap between two successive setups, where the time gap is measured as the difference between two setup start times, i.e. I. In this new setting we let L(x) be the setup cost for a given skill level x, and let F(L,I) be the next setup cost given the previous setup cost of L, and the time between the two consecutive setups of I periods. In our original model the interruption duration is the difference between the end of the current-batch production and the start of the next batch, which may vary from one batch to another.However, in this new setting, the assumption of setting up an operation at regular intervals implies that the time between two consecutive setups (interruption duration) is fixed. Another point of departure in this new setting from our original model is the number of repetitions during the learning phase. Each batch requires only one setup; thus, the number of repetitions in this case is only one. In the original model each batch production consists of q units and therefore q repetitions. We claim that in this new case, we have∂G(x∗)∂x>0and thus the sequence {Gk(x)} of setup costs converges to x∗ for any x∈(x∗−δ, x∗+δ) for some δ>0. Next, we will next justify our claim.Since l(x) is independent of the interruption duration and since q=1, it follows, as in Fact 2.1 in Section 2, that l(x) is strictly decreasing in x. Since∂I∂x=0, it follows that∂(F(L,I)-L)∂I·∂I∂x=0. Then, again, following the same steps of the proof of Fact 2.1, we have f(x) strictly increasing in x. Therefore, as in Properties 3.1, 3.2, and 3.3(a), in this new setting, we conclude that.(i)G(x) has a unique fixed point x∗;if x<x∗, then G(x)>x, and if x>x∗,then G(x)>x; andassuming∂G(x)∂x⩾0for all x, if x<x∗, then G(x)⩽x∗ and if x>x∗, then G(x)⩾x∗.Notice that, in this new setting, if x<y, then L(x)>L(y) and L(x+1)>L(y+1). For the forgetting function F(L,I), we have∂F(L,I)∂L>0; it follows that F(L(x+1), I)>F(L(y+1), I) and G(x)<G(y). Therefore, we have∂G(x)∂x>0for all x. From this fact we have∂G(x∗)∂x>0; hence, Property 4.1 applies to this new circumstance as well: if x∈(x∗−δ, x∗+δ) for some δ>0, then the sequence {Gk(x)} converges to x∗.This article considers convergence characteristics of workers’ skill levels under the presence of learning and forgetting in processing units. We study the steady-state behaviors under learning and forgetting for a more general class of functions; hence it generalizes Teyarachakul et al. (2008) work while extending the applicability of such results as described in Section 5. In doing so, we use the fixed-point approach, a well-known dynamical systems technique to study long-term behavior of systems evolving in time. We use the more commonly used term “the two cluster points”, instead of their term “an alternating convergence”, in order to describe the same long-term characteristics of the sequence {Gk(x)}.Although the case of two cluster points in the batch production-time is rather new, it is an interesting one. One possible interpretation is that in the long run, when workers start a batch with very low skill levels (such as x−), because of the long production time needed, they end up with a short break before the next batch begins. Thus, they have minimal loss of their skill level. When the next batch starts, they still remember most of their learning gained from the previous batch and begin the new batch with a high skill level (such as x+). However, a high skill level results in a fast production, leading to a long break, and hence, more forgetting during the break. This makes workers start the following batch with low skill levels (such as x−). This pair of cycling skill levels (x−,x+) is repeated over and over in the long run as described in the example in Section 5.Note that whether the sequence {Gk(x)} converges to x∗ depends on the location of the skill level x at the start of the sequence which must be within (x∗−δ, x∗+δ) for some constant δ>0, in addition to the condition of∂G(x∗)∂x>0or-1<∂G(x∗)∂x<0. In order to ensure that the convergence of the sequence takes place, one possible approach is to assign the workers to produce x units with no interruption in production, where x∗−δ<x<x∗+δ. This will bring x within the range that guarantees the existence of convergence. Teyarachakul et al. (2008) specify the sufficient conditions for the convergence independent of the value of x at the start of the sequence; and we also improve upon those results.Besides the case of convergence of {Gk(x)} to the fixed point x∗, our model also leads to the possibility of the existence of two cluster points for {Gk(x)}. At this juncture, a natural research question arises: in a setting alike the one discussed in Section 5, could a manager collect to statistically test the existence of two cluster points for {Gk(x)}? Another research interest for a manager would be to know the speed of convergence in a more general setting where Newton’s method is not applicable (such as bisection method); that is, how long it takes any convergence to occur.We studied the behavior of worker’s skill levels in a fixed batch environment. If an operations manager observes two cluster point case, he/she might think of intervening by changing the batch size. It will be beneficial if such an intervention or series of such interventions will lead to an optimal batch size for a given pair of learning and forgetting functions. We assumed throughout the paper that learning happens naturally/for free. However, if learning also (or, instead) occurs through some costly investment/training, a manager would be interested in knowing the optimal investment level to balance the training costs and productivity gains. Finally, one further research possibility would be to investigate the effects of learning and forgetting in a two-cluster points situation on the optimal lot size.Example 1Learning Function: Wright’s Learning Curve (1936)L(x)=L(1)x−m, where m is learning slope.Forgetting Function: Globerson and Levin’s Exponential Forgetting Function (1987).F(L,I)=L+(1−e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: L(1)=1.00, q=40, m=0.42, b=0.15, d=2.963Fixed points of G(x): x∗=6.730; fixed points of G2(x): x∗=6.730Example 2Learning Function: Wright’s Learning Curve (1936)L(x)=L(1)x−m, where m is learning slope.Forgetting Function: Globerson and Levin’s Exponential Forgetting Function (1987).F(L,I)=L+(1−e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: L(1)=5.00, q=20, m=0.42, b=0.50, d=0.467Fixed points of G(x): x∗=1.667; fixed points of G2(x): x−=1.018, x∗=1.667, x+=5.617Example 3Learning Function: Wright’s Learning Curve (1936)L(x)=L(1)x−m, where m is learning slope.Forgetting Function: Globerson and Levin’s Exponential Forgetting Function (1987).F(L,I)=L+(1−e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: L(1)=5.00, q=20, m=0.42, b=0.50, d=0.467Fixed points of G(x): x∗=5.644; fixed points of G2(x): x∗=5.644Example 4Learning Function: Wright’s Learning Curve (1936)L(x)=L(1)x−m, where m is learning slope.Forgetting Function: Globerson and Levin’s S-Shaped Forgetting Function (1987).F(L,I)=L+(1−(bI+1)e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: L(1)=5.00, q=20, m=0.42, b=0.15, d=0.444Fixed points of G(x): x∗=3.950; fixed points of G2(x): x∗=3.950Example 5Learning Function: Wright’s Learning Curve (1936)L(x)=L(1)x−m, where m is learning slope.Forgetting Function: Globerson and Levin’s S-Shaped Forgetting Function (1987).F(L,I)=L+(1−(bI+1)e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: L(1)=10.00, q=4, m=0.32, b=0.15, d=0.229Fixed points of G(x): x∗=2.430; fixed points of G2(x): x−=1.152, x∗=2.430, x+=7.136Example 6Learning Function: Bevis’s Exponential Learning Curve (1970)L(x)=Ae−xB, where A and B are the learning parameters.Forgetting Function: Globerson and Levin’s S-Shaped Forgetting Function (1987).F(L,I)=L+(1−(bI+1)e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: A=20, q=20, B=0.50, b=0.15, d=0.667Fixed points of G(x): x∗=1.895; fixed points of G2(x): x∗=1.895Example 7Learning Function: Bevis’s Exponential Learning Curve (1970)L(x)=Ae−xB, where A and B are the learning parameters.Forgetting Function: Globerson and Levin’s S-Shaped Forgetting Function (1987).F(L,I)=L+(1−(bI+1)e−bI)(L(1)−L), where b is the forgetting parameter.Parameters: A=10, q=10, B=0.20, b=0.15, d=0.263Fixed points of G(x): x∗=3.021; Fixed points of G2(x): x−=1.412, x∗=3.021, x+=7.099Proofs of Fact 2.1, Properties 3.3, 3.4 and 3.5, and Property 4.3Proof of Fact 2.1SincedL(x)dx<0,d2L(x)dx2>0and lq(x)=L(x)−L(x+xq), the function lq(x) is strictly decreasing in x.Recall that fq(x)=F(L(x+xq), Iq(x))−L(x+xq), andIq(x)=qd-pq(x). Then∂fq(x)∂x=∂(F(L,Iq)-L)∂L·∂L∂x+∂(F(L,Iq)-L)∂Iq·∂Iq∂xSince∂Iq∂x>0and∂(F(L,Iq)-L)∂Iq>0, we have∂(F(L,Iq)-L)∂Iq·∂Iq∂x>0. Also, since∂L∂x<0and∂(F(L,Iq)-L)∂L=∂F(L,Iq)∂L-1<0,∂(F(L,Iq)-L)∂L·∂L∂x>0. Thus, it follows that∂fq(x)∂x>0, implying that fq(x) is strictly increasing in x.□Properties 3.3(a) and (b) follow from the sign of∂G(x)∂xand the fact that G(x∗)=x∗. Property 3.3(c) is obtained by using the chain rule,∂G(x)∂x<0for all x implies that∂G2(x)∂x>0for all x, and G(x′)=x′. □For (a), given a fixed point x′of G2(x), then G2(x′)=x′, G(G2(x′))=G(x′)=G2(G(x′)); and hence, G(x′) is also a fixed point of G2(x). For (b) and (c), all we need to show is that x′≠x∗ implies G(x′)≠x′ and G(x′)≠x∗. If x′≠x∗, then G(x′)≠x′ since by Property 3.1 a fixed point x∗ of G(x) is unique. Furthermore, x′≠x∗ also implies that G(x′)≠G(x∗)=x∗.□Since x∗ is a fixed point of G(x), it must also be a fixed point of G2(x). Thus, G2(x) must have at least one fixed point. Consider the fixed point x′of G2(x), where x′≠x∗. By Property 3.4, G(x′) is also a fixed point of G2(x) with G2(x′)=x′, G(x′)≠x∗ and G(x′)≠x′.Thus, all fixed points of G2(x), other than x∗, must come in pairs x′, G(x′). Hence the number of fixed points of G2(x), including x∗, must be an odd integer.□Since L(G(x))=L(x)−l(x)+f(x), by the chain rule,∂L(G(x))∂(x)=∂L(x)∂(x)-∂l(x)∂(x)+∂f(x)∂G(x)and∂L(G(x))∂(x)=∂LG(x)∂G(x)·∂(G(x))∂(x). Thus∂G(x)∂(x)=∂L(x)∂x-∂l(x)∂x+∂f(x)∂x∂L(G(x))∂G(x).So, if x=x∗, ∗,∂G(x∗)∂x=1+∂f(x∗)∂x-∂l(x∗)∂x∂L(x∗)∂x.Thus,∂G(x∗)∂x<1if and only if-2<∂f(x∗)∂x-∂l(x∗)∂x∂L(x∗)∂x<0. It follows that∂G(x∗)∂x<1if and only if∂f(x∗)∂x>∂l(x∗)∂x-2∂L(x∗)∂x; hence (a) is proved. Proof of (b) is similar.□

@&#CONCLUSIONS@&#
