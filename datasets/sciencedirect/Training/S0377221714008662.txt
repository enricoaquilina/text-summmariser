@&#MAIN-TITLE@&#
Refined ranking relations for selection of solutions in multi objective metaheuristics

@&#HIGHLIGHTS@&#
Ranking methods for solutions of multi objective optimization problems are proposed.Both methods are refinements of the Pareto dominance relation.The methods help metaheuristics to select good solutions.Desirable properties for applications are shown theoretically.We report experimental results for PACO and GA for multi objective flow shop problem.

@&#KEYPHRASES@&#
Multi objective optimization,Ranking relations,Ant colony optimization,Genetic algorithms,Flow shop scheduling problem,

@&#ABSTRACT@&#
Two methods for ranking of solutions of multi objective optimization problems are proposed in this paper. The methods can be used, e.g. by metaheuristics to select good solutions from a set of non dominated solutions. They are suitable for population based metaheuristics to limit the size of the population. It is shown theoretically that the ranking methods possess some interesting properties for such applications. In particular, it is shown that both methods form a total preorder and are both refinements of the Pareto dominance relation. An experimental investigation for a multi objective flow shop problem shows that the use of the new ranking methods in a Population-based Ant Colony Optimization algorithm and in a genetic algorithm leads to good results when compared to other methods.

@&#INTRODUCTION@&#
Optimization problems with several objectives are common in industrial, engineering, or scientific contexts. Abstractly formulated, a multi objective optimization problem asks for solutions from a solution space X (also called search space) that are optimal with respect to d > 1 objectives. Typically, the objectives are conflicting and it is only possible to optimize a (small) subset of the objectives simultaneously. This is reflected in the concept of the Pareto dominance relation. A solution dominates another if it is better in at least one objective and not worse in all other objectives. Based on this relation a solution is called Pareto optimal if it is not dominated by any other solution from X. The goal in multi objective optimization is to find the set of Pareto optimal solutions, called Pareto set, or at least a subset of it. Unfortunately, many discrete multi objective optimization problems are NP-hard, i.e. it is not possible to solve them in polynomial time (if P ≠ NP). For continuous multi objective optimization problems the optimization function is often a black box or algebraically too complicated, i.e. it is impossible to solve them analytically. In these cases, usually the goal is to find a set of non dominated solutions that are close to the Pareto optimal solutions. Another common selective feature is the diversity of the chosen set of solutions.To explore the solution space the use of algorithms maintaining a population of solutions seems beneficial. Therefore, multi objective variants of various population-based metaheuristics have been developed in recent years. Among the earliest multi objective variants of genetic algorithms is, e.g. the Vector Evaluation Genetic Algorithm (VEGA) from Schaffer (1984) (see overviews in Coello Coello, 2009; Coello Coello et al., 2005; Fonseca and Fleming, 1995). Also the ant colony optimization metaheuristic (ACO) was extended to solve multi objective optimization problems, e.g. by Iredi et al. (2001) and Doerner et al. (2001) (for an overview see Angus and Woodward, 2009 or Leguizamón and Coello Coello, 2011, Chapter 3). For problems on continuous solution spaces extended particle swarm approaches (PSO) have been proposed, e.g. by Coello Coello and Salazar Lechuga (2002) and Hu and Eberhart (2002) (for an overview see Reyes-Sierra and Coello Coello, 2006).The Pareto dominance relation is often used in population-based metaheuristics to rank the elements of a set of solutions. But for a set of non dominated solutions this relation is insufficient to guide heuristics into favourable regions of the search space. This is particularly relevant, when the number of objectives is large since the number of non dominated solutions increases along with the number of objectives. This effect has been called a “curse of dimensionality” by Kukkonen and Lampinen (2007). Therefore, several methods to compare and rank elements of sets of (non dominated) solutions have been discussed in the literature. Some of these ranking methods are used for post-Pareto optimality, i.e. to select solutions from the final set of non dominated solutions computed by some metaheuristic.Aside from ranking the found solutions, there are other methods to prune a set of (non dominated) solutions. One possibility is to apply clustering methods to the set of solutions in order to select a representative solution from each cluster. One potential aim of using clustering methods is to obtain a large diversity in the set of selected solutions (Kukkonen and Deb, 2006).In this paper we are interested in using ranking methods for metaheuristics by applying them in each iteration to select only a few solutions from the set of already found (non dominated) solutions. Hence, the ranking methods are used to prune a potentially large set of solutions to a small subset of good solutions. This small set forms the population which is then used in the next iteration to create new and hopefully better solutions. Maintaining a small population has advantages with respect to the memory and time requirements of an algorithm. This is particularly important in restrictive computational environments, e.g. when solutions need to be delivered in real time or the algorithm runs on specific hardware, e.g. as part of an embedded system. Another important reason for the use of small populations is objective functions that are expensive to evaluate. Clearly, the choice of which solutions are to be kept in the population is particularly important for small population sizes.The simplest kind of ranking schemes is aggregation methods. They use, for instance, an aggregation function calculating a weighted sum of the objectives (Jakob et al., 1992) or the distance to a target vector of objective values (Wienke et al., 1992). Furthermore, there are also objective based ranking methods. One such method is to use given priorities for a lexicographic sorting of the objectives or performing a separate optimization of the single objectives in an order that is compliant with the priorities (Cvetkovic and Parmee, 2002). Weights, target vectors, and priorities should be given by the user. But for many applications this might be difficult or impossible for the user because, for instance, no reasonable weights are known.In contrast to the above ranking methods that need different kinds of user input, several methods have been developed based on the notion of dominance. To rank a solution a within a set of solutions X one could use the number of solutions in X that are dominated by a (dominance rank) or the number of solutions in X dominating a (dominance count) (see also Fonseca and Fleming, 1993; Zitzler and Thiele, 1999). An alternative is to use the number of times the current set of non dominated solutions has to be removed from the remaining set of solutions until the solution itself becomes non dominated. This measure has been called dominance depth by Srinivas and Deb (1994). Additionally to the comparison of single objective vectors also sets of non dominated solutions can be compared. This is commonly done in the indicator function framework, which assigns a real value to a set or sets of non dominated solutions. One example is the binary hypervolume indicator that is defined as the hypervolume of the objective space (i.e. the space of vectors of potential values of the different objectives) dominated by one set of solutions but not by another (we refer the interested reader to Zitzler et al., 2003).Some ranking methods consider how much two solutions differ with respect to the different objectives. Garza-Fabre et al. (2009) have proposed three such methods. An example is the Global Detriment method which computes for each solution the sum of the differences to other solutions over all those objectives where the solution is worse than the corresponding other solution. A potential disadvantage of these methods is that they typically need some normalization between the different objectives. Therefore, these methods are not considered further in this paper. However, we use one representative of these methods as a comparison method. This method uses the same measure as the Global Detriment method, but only for pairwise comparison, and random weights for the normalization (for details see Section 3.2).By regarding only the information whether two objective values differ and thereby disregarding the magnitude of the difference of the objective values the decision process can be greatly simplified. The number of objectives for which one solution is better or worse than the other can be helpful for a decision between alternative solutions. A similar reasoning simplifies everyday decisions when comparing different choices by the number of advantages and disadvantages. This basic idea was formally captured by the relation favour that prefers a solution over another if it wins, i.e. is better, in more objectives than the other (Drechsler et al., 2001). Several extensions or similar relations have been proposed in the literature. They modify the decision if an objective is counted as won or lost (Laumanns et al., 2002; Sülflow et al., 2007) or how many won objectives are required for preference (Farina and Amato, 2004; Zou et al., 2008). Approaches based on the number of won objectives can also be used to rate a solution with respect to a set of solutions e.g. (Bentley and Wakefield, 1998; Maneeratana et al., 2006; Mostaghim and Schmeck, 2008). A detailed description of these methods is given in Section 3.In this paper we propose two new ranking relations which are based on the relation favour (Section 4). We prove that both relations are refinements of the Pareto dominance relation and are total preorders. The ranking relations can be used in multi objective population based meta-heuristics for selecting the solutions that are included into the population and thus guide the search for better solutions. We compare the different ranking schemes when used in a Population-based Ant Colony Optimization algorithm (P-ACO) and in a genetic algorithm (GA). As test problem a multi objective flow shop scheduling problem is used. The results show that the new ranking schemes are advantageous to select the solutions for the population of the P-ACO and the GA.The paper starts with the introduction of basic definitions in Section 2. A detailed review of related ranking relations from the literature and a few corresponding theoretical results are presented in Section 3. The new ranking relations are introduced in Section 4. The metaheuristics P-ACO and GA which are used for the experiments are described in Section 5. The test problem and the experiments are described in Section 6. The experimental results are presented in Section 7. A short conclusion is given in Section 8. Note, that this paper is an extension of Moritz et al. (2013).Consider a multi objective optimization problem with a set of solutions X and a vector of objective functionsf→(a)=(f1(a),…,fd(a)),where a ∈ X andfi:X↦R. The solutions in X can, for example, be vectors of real values in case of continuous optimization problems or vectors of elements from a finite set in case of combinatorial optimization problems. The aim is to find solutions from X that minimize the objectives, i.e.(1)mina∈Xf→(a)=mina∈X(f1(a),…,fd(a)).Note, that by using − fi(a) maximization is also possible.In order to find a minimum in a two or higher dimensional space the Pareto dominance relation (≺) is used. Let a, b ∈ X, then(2)a≺b⇔∀i∈[1:d]:fi(a)≤fi(b)∧f→(a)≠f→(b).Solution a dominates b if a≺b. Note that, if a≺b then there is at least one i ∈ [1: d] with fi(a) < fi(b). Two solutions a, b ∈ X are called incomparable if a⊀b∧b⊀a or indifferent in case off→(a)=f→(b). A solution a ∈ X is called Pareto optimal if ∄b ∈ X: b≺a. A solution a ∈ X is called non dominated solution with respect to a subset X′⊆X if ∄b ∈ X′: b≺a. The set of all Pareto optimal solutions from X is called the Pareto set and the corresponding set of objective vectors inRdis called the Pareto front of X.The different properties of relations are summarized in Table 1. Let R and S be two relations on a set X. Then S is a refinement of R if∀a,b∈X:(a,b)∈R∧(b,a)∉R⇒(a,b)∈S∧(b,a)∉S.In terms of the domination relation a refinement is useful as it preserves the original order and elements that are incomparable with the domination relation could be comparable with respect to the refinement.Given an irreflexive and asymmetric relation R over a set W, two vectorsu→,v→∈Wdare compared by:•BR(u→,v→)=|{i:(u→i,v→i)∈R,i∈[1:d]}|ER(u→,v→)=|{i:(u→i,v→i)∉R,(v→i,u→i)∉R,i∈[1:d]}|WR(u→,v→)=|{i:(v→i,u→i)∈R,i∈[1:d]}|Note that due to the asymmetry and irreflexivity each element i ∈ [1: d] is included in exactly one of the three sets used to computeBR(u→,v→),ER(u→,v→),andWR(u→,v→). Thus, the sum of the sizes of the three sets is d, i.e.BR(u→,v→)+ER(u→,v→)+WR(u→,v→)=d. This notion is used to compare elements of the solution space of multi objective optimization problems with respect to their values in the objective spaceRdusing the < relation. In the following we writeBR(a,b)instead ofBR(f→(a),f→(b))whenever we compare two solutions a, b ∈ X. We handleER(a,b)andWR(a,b)analogously. In that caseB<(a,b),E<(a,b),andW<(a,b),respectively, counts the number of objectives where a solution a is better (respectively equal, worse) than a solution b (Drechsler et al., 2001; Farina and Amato, 2004; Sülflow et al., 2007; Zou et al., 2008).For a solution u ∈ X, a set X′⊆X of solutions and an irreflexive and asymmetric relation R⊆X × X a similar notion is introduced:•BR(u,X′)=|{x:(u,x)∈R,x∈X′}|ER(u,X′)=|{x:(u,x)∉R,(x,u)∉R,x∈X′}|WR(u,X′)=|{x:(x,u)∈R,x∈X′}|Note, thatBR(u,v)andBR(u,{v})have a different meaning. For X′′, X′⊆X defineBR(X′′,X′)=∑u∈X′′BR(u,X′). AnalogouslyER(X′′,X′)andWR(X′′,X′)are defined.In this section we review different approaches that have been proposed in the literature to compare non dominated solutions based on certain relations between their objective values.The relation favour(Drechsler et al., 2001) compares two solutions with respect to the number of objectives in which one solution is better than the other solution. This is captured by the following formal definition.(3)a≺fb⇔B<(a,b)>B<(b,a)Obviously,≺fis an irreflexive and asymmetric relation.But relation favour is not transitive (Drechsler et al., 2001). Since ties in the number of objectives where one solution is better than the other and vice versa are possible relation favour is not total. Moreover, for d ≤ 2, i.e. for two or one objective, the favour relation and the Pareto dominance relation are equivalent (Drechsler et al., 2001). Relation favour is a refinement of the Pareto dominance relation. Since this has not been noticed in the literature so far (to the best of our knowledge) we provide proof in the following.Theorem 3.1The favour relation is a refinement of the Pareto dominance relation on X, i.e. for a, b ∈ X:a≺b∧b⊀a⇒a≺fb∧b⊀fa.It suffices to show that a≺b impliesa≺fbas the second part of premise and conclusion are a direct consequence of the asymmetry of ≺ and≺f. By definition of the Pareto dominance relation it holds that ∄i ∈ [1: d]: fi(b) < fi(a), i.e.B<(b,a)=0,and ∃i ∈ [1: d]: fi(a) < fi(b), i.e.B<(a,b)>0. This impliesa≺fb.□In addition, we show some properties on the combination of the Pareto dominance relation and the favour relation used in the next section.Proposition 3.1Let a, b, c ∈ X with a≺b. Then:(i)b≺fc⇒a≺fc,c⊀fb⇒c⊀fa,c≺fa⇒c≺fba⊀fc⇒b⊀fc.Because a≺b, with a, b ∈ X, for any c ∈ X it holds that(1)B<(b,c)≤B<(a,c),because ∀k ∈ {i: fi(b) < fi(c)}: fk(a) ≤ fk(b), andB<(c,b)≥B<(c,a),because ∀k ∈ {i: fi(c) < fi(a)}: fk(a) ≤ fk(b).These inequalities together with the corresponding premise of the implication give the result.(i)Due tob≺fcwe haveB<(b,c)>B<(c,b)yielding:B<(a,c)≥B<(b,c)>B<(c,b)≥B<(c,a). By definition (Eq. (3)) this is equivalent toa≺fc.Fromc⊀fbwe knowB<(c,b)≤B<(b,c)and thereforeB<(c,a)≤B<(c,b)≤B<(b,c)≤B<(a,c),i.e.c⊀fa.Similarlyc≺fagivesB<(c,b)≥B<(c,a)>B<(a,c)≥B<(b,c),i.e.c≺fb.Finallya⊀fcgivesB<(b,c)≤B<(a,c)≤B<(c,a)≤B<(c,b),i.e.b⊀fc.□The favour relation on a set X can be represented by a directed graph G = (V, E) with node set V = X and an edge set defined by the favour relation, i.e. (b, a) ∈ E iffa≺fb. G is called the favour graph of X and vectorf→of objective functions. The following lemma shows that every directed graph can be the favour graph of V and somef→.Lemma 3.1For every directed graph G = (V, E) that is loop-free (i.e.∀a∈V:(a,a)∉E) and has at most one edge between two nodes there exists a vector of objective functionsf→on the set X = V such that the favour graph of V andf→is isomorphic to G.Let G = (V, E) be given with V = {v1, …, vn} and E = {e1, …, em}. For the construction letf→={f1,…,f3m}be 3m-dimensional vector of objective functions. For each v ∈ V let v(h), with h ∈ [1: m], be the three dimensional subvector off→(v)which defines the positions 3h − 2, 3h − 1, and 3h inf→(v). Define the objective functions such that for each edge eh= (vi, vj) ∈ E it holds thatvj(h)=(1,1,2),vi(h)=(2,2,1),and for all other vectorsvl(h)=(1,3,1),i ≠ l ≠ j. By the construction, it follows that if there exist an edge eh= (vi, vj) ∈ E thenvj(h)≺fvi(h)andvj(k)⊀fvi(k)∧vi(k)⊀fvj(k)for k ∈ [1: m], k ≠ h. If two nodes vi, vj∈ V are not connected by an edge in G thenvj(h)⊀fvi(h)∧vi(h)⊀fvj(h)for all h ∈ [1: m]. Altogether it follows for vectors vi, vj∈ V that the favour relationvi≺fvjholds iff (vj, vi) ∈ E. Hence, the favour graph of V andf→is isomorphic to G.□It should be mentioned that several variations of the favour relation have been proposed. For example the ε-preference rates an objective fi, i ∈ [1: d], of a solution as won only if its value is larger by a constant value εithan the corresponding value of the competitor solution (Sülflow et al., 2007). This is analogous to a corresponding variation of the dominance relation that was called ε-dominance by Laumanns et al. (2002). Other modifications consider an additive or multiplicative tolerance for the number of won objectives, e.g. by demandingL+B<(a,b)>W<(a,b)ork·B<(a,b)>W<(a,b)where L and k are constants. For values L > 0 and k > 1 a stricter form of dominance can be enforced, and for values L < 0 and k < 1 weaker forms are enforced. With small modifications this has been implemented in the notion of L-dominance by Zou et al. (2008) and (1 − k)-dominance by Farina and Amato (2004), respectively. A solution a is said to (1 − k)-dominate solution b (denoted by a≺1 − kb) iffE<(a,b)<dandB<(a,b)≥(d−E<(a,b))/(k+1),with k ∈ [0: 1]. The latter inequality can be transformed tok·B<(a,b)≥W<(a,b). L-dominance for solutions a and b is defined byB<(a,b)−W<(a,b)=L>0,i.e.B<(a,b)−L=W<(a,b). Zou et al. (2008) demanded in addition that a is better than b with respect to some norm, e.g. the sum of the objective values.Instead of comparing two solutions directly it is also interesting to compare them by checking which one performs better with respect to a reference set of solutions. This has been done for instance in the domination rank, domination count, and domination depth based ranking methods. Two other such methods are the winning score by Maneeratana et al. (2006) and the average ranking by Bentley and Wakefield (1998). For a set of solutions X the winning score of a solution a ∈ A⊆X is defined asS(a)=∑b∈A(B<(a,b)−W<(a,b)). The average rank is given byrank(a)=∑i=1dri(a)where ri(a) is the rank of a with respect to objective i. Corne and Knowles (2007) have shown that winning score and average rank are equivalent, i.e. they induce the same order on the elements of A.We use the winning score for a comparison with our new methods in the experimental analysis. The corresponding relation is abbreviated as Win. In addition, we propose a comparison method—called method W—that uses a similar measure as the Global Detriment method of Garza-Fabre et al. (2009) (see also Section 1), however only pairwise and it uses weights for normalization. Method W uses the weighted sum of the objectives for the ranking, i.e.a≺Wbiff∑i=1dwifi(a)≤∑i=1dwifi(b).Note, that the winning score and the relation used in method W are both refinements of the Pareto dominance relation. For the former this is because a≺b implies that the average rank of a is smaller than the average rank of b. For the latter this is because, a≺b implies that the weighted sum of a is smaller than the weighted sum of b. Furthermore, both relations are total preorders, since ≤ is used as comparison operator in both relations which implies reflexivity, transitivity, and totality. By using < instead of ≤ reflexivity can be removed.A good overview and experimental comparison over different ranking methods can be found in Garza-Fabre et al. (2009) and Garza-Fabre et al. (2010).In this section we introduce the following new comparison operations: relation WL and relation Points. Both relations are based on the relation favour. They are used to compare (non dominated) solutions.For a solution a ∈ X the comparisons are based on the number of solutions in A⊂X compared to which a wins, is incomparable, or loses according to the favour relation, i.e.B≺f(a,A),E≺f(a,A),orW≺f(a,A)respectively. The following theorem relates Pareto dominance to these numbers.Theorem 4.1Let A⊆X and a, b ∈ X. It holds thata≺b⇒B≺f(a,A)≥B≺f(b,A)∧W≺f(a,A)≤W≺f(b,A). If a, b ∈ A both inequalities are strict.Assume a≺b. By Proposition 3.1 for every x it holds that (i) ifb≺fxthena≺fxand (ii) ifx≺fathenx≺fb. Hence, the first sentence of the theorem holds. Furthermore, by Theorem 3.1 we havea≺fb. Thus, it follows thatB≺f(a,A)≥B≺f(b,A)+1andW≺f(a,A)−1≤W≺f(b,A)when a, b ∈ A.□Note that relation favour may distinguish between non dominated solutions only for multi objective optimization problems with more than two objectives. This is because for two objectives the comparison between two non dominated solutions is always tied. Consequently, the relations introduced in the following have no refining effect in case of two or less objectives as they rely on relation favour.Let A⊆X, a, b ∈ X, and≺WLAbe a relation on X defined as follows.(4)a≺WLAb⇔B≺f(a,A)>B≺f(b,A)∨(B≺f(a,A)=B≺f(b,A)∧W≺f(a,A)≤W≺f(b,A))Relation≺WLAis called WL relation. If the context is clear we may omit A in the notation. Some favourable properties of relation WL are given in the following.Theorem 4.2For A⊆X the WL relation≺WLAis a total preorder on X.We show that the WL relation≺WLAis (i) transitive and (ii) total (which implies it is reflexive).(i)Let a, b, c ∈ X witha≺WLAbandb≺WLActhena≺WLAcfollows from the transitivity of >, =, and ≤ .Assumea⊀WLAb,with a, b ∈ X. Consider the two possible cases: (a)B≺f(a,A)<B≺f(b,A)and (b)B≺f(a,A)=B≺f(b,A)∧W≺f(a,A)>W≺f(b,A). In each case the definition of the WL relation impliesb≺WLAa.□The theorem ensures the possibility of sorting a set of solutions according to the WL relation with sorting algorithms that are based on pairwise comparisons, e.g. mergesort. Note, that the WL relation is not a partial order since antisymmetry does not hold, i.e.a≺WLbandb≺WLadoes not imply a = b.UsingW≺f(a,A)<W≺f(b,A)instead ofW≺f(a,A)≤W≺f(b,A)in Eq. (4) would result in an irreflexive relation. But this would have the negative side effect that the relation is not total anymore and therefore two different solutions with the same objective values are not comparable.Example 4.1Let X = {a, b, c} with f(a) = (1, 2, 3), f(b) = (3, 1, 2), and f(c) = (2, 3, 1), i.e.a≺fc,c≺fb,andb≺fa. ThenB≺f(a,X)=B≺f(b,X)=B≺f(c,X)=1andW≺f(a,X)=W≺f(b,X)=W≺f(a,X)=1. Hence,a≺WLb≺WLc≺WLa. Since, a, b, c are pairwise different relation≺WLis not antisymmetric.The following proposition is needed to show that the WL relation is a refinement of the Pareto dominance relation.Proposition 4.1Let A⊆X and a, b ∈ A. Thena≺b⇒b⊀WLAa.Due to Theorem 4.1a≺b impliesB≺f(a,A)>B≺f(b,A). Thus, by definition (see Eq. (4))b⊀WLAaholds.□A consequence of the previous proposition is the following theorem.Theorem 4.3The WL relation≺WLAis a refinement of the Pareto dominance relation on A⊆X, i.e. for a, b ∈ A:a≺b∧b¬≺a⇒a≺WLAb∧b⊀WLAa.By Proposition 4.1a≺b impliesb⊀WLAa. Because the≺WLArelation is total (Theorem 4.2)a≺WLAbholds.□Note, that the statement of the theorem without the second part of the premise is also correct. In contrast to the Pareto dominance relation it does not hold in general thata≺WLbimpliesa≺fbor vice versa. The definition of the WL relation implies that the order created on A by the WL relation is equal to the lexicographical order induced by the pairs(B≺f(a,A),−W≺f(a,A)).We extend relation WL in the following such that for sets A, B, C, D⊆X(5)A≺WLC,DB⇔B≺f(A,C)>B≺f(B,D)∨(B≺f(A,C)=B≺f(B,D)∧W≺f(A,C)≤W≺f(B,D))If C = D we simply writeA≺WLCB.Assume that A is a set of solutions and that B is the subset of size k from A that is best ranked with respect to the WL relation. Then a desirable property would be that B ranks best (when compared analogously to other subsets of size k) with respect to its complement in A, i.e. A − B. Formally, we say property (*) holds, iff for all subsets B, C⊆A with |B| = |C|:B≺WLAC⇒B≺WLA−B,A−CC.To see why property (*) is desirable consider an example from sports. Let B be a subset of the set A of all teams in a league and let S(B, A) be the sum of the total score of all teams in B for all games against the teams in A. Let games be a relation that compares sets of teams with respect to the sum of total scores, i.e.B≺gamesACiff S(B, A) > S(C, A). If (*) holds for relation games the teams in B cannot profit from (illegal) agreements about the outcome of the internal games in B, i.e. the games between teams of B. To see this, assume that for a set of teams C⊂A with |C| = |B| it holds thatB≺gamesAC. Property (*) impliesB≺gamesA−B,A−CC. Thus S(B, A − B) > S(C, A − C). Therefore, teamB≺gamesACbecause team B was better than C in the games against the respective other teams of A but not because of the outcome of the internal games with B respectively C.The following example shows that property (*) does not hold in general for the WL relation. Consider a directed graph G = (V, E) with V = {v1, …, v11}. Let A = {v1, …, v5}, B = {v6, …, v10}, and C = {v11}. For every node v ∈ A edge (v11, v) ∈ E. All other edges in E are only between nodes of B such that every node in B has two ingoing edges from other nodes in B (for details see Fig. 1). As shown in Lemma 3.1 there exists an objective functionf→such that G is the favour graph of X = V. ThenB≺f(b,X)=2for each node b ∈ B,B≺f(a,X)=1for each node a ∈ A, andB≺f(v11,X)=0. Thus, set B contains the five highest ranked nodes with respect to the WL relation. Set A contains nodes which are lower ranked than every node in B but higher ranked than v11 and node v11 is lower ranked than any node in A∪B. Therefore,B≺WLXC. ButA≺WLX−A,X−BBsinceB≺f(b,X−B)=0for each b ∈ B andB≺f(a,X−A)=1for each a ∈ A.The relation that is introduced in the next section satisfies property (*).A potential problem of relation WL is that it ignores ties. Therefore it is proposed here to use a generalization of the scoring scheme which is also used in many sport leagues and tournaments where a team gets 2 (or 3) points for each won game and 1 point for each tied game. Inspired by this scheme we introduce the point score of a solution a ∈ X with respect to a set of solutions A⊆X.(6)S(a,A)=w·B≺f(a,A)+1·E≺f(a,A)where w ≥ 1 is a constant specifying how many points are attributed to a won comparison. For sets A, B⊆X define(7)S(B,A)=∑a∈BS(a,A)Based on this performance measure the Points relation is defined. For a, b ∈ X and A⊂X define(8)a≺PtAb⇔S(a,A)≥S(b,A)The Points relation can be extended naturally (in the sense thatb≺PtAc⇔{b}≺PtA{c}) to the set of subsets of X such that for sets A, B, C⊆X(9)B≺PtAC⇔S(B,A)≥S(C,A)If it is clear from the context which set is the reference set A, we omit the reference set in the notation.Theorem 4.4For A⊆X the Points relation≺PtAis a total preorder on X.Transitivity and totality are a consequence from ≥ being transitive and total. Reflexivity is a consequence of totality.□The theorem ensures that it is possible to use the Points relation for sorting a set of solutions with a generic sorting algorithm, e.g. mergesort. Note, that the Points relation is not a partial order since antisymmetry does not hold, i.e.a≺Ptbandb≺Ptadoes not imply a = b.Example 4.2Consider Example 4.1. Since there are no ties it follows thata≺Ptb≺Ptc≺Pta. Since, a, b, c are pairwise different≺Ptis not antisymmetric.Let A⊆X and a, b ∈ A thena≺b⇒b⊀PtAa.Assume a≺b. By Theorem 4.1 we haveB≺f(a,A)>B≺f(b,A). Any x ∈ A which contributes toE≺f(b,A)contributes one point to S(b, A) and it holds thatb⊀fx∧x⊀fb. Sincex⊀fbwe have by Proposition 3.1 thatx⊀fa. Hence,x≺fadoes not hold. Thus, x contributes at least one point to S(a, A) (one point in case ofa⊀fxand w points in case ofa≺fx). Altogether, it follows that S(a, A) > S(b, A) and the theorem holds.□The Points relation≺PtAis a refinement of ≺ on A, i.e. for a, b ∈ A:a≺b∧b⊀a⇒a≺PtAb∧b⊀PtAa.The premise a≺b implies by Proposition 4.2b⊀PtAa. Since the Points relation is total (Theorem 4.4)a≺PtAbfollows.□Note, that the statement of the theorem without the second part of the premise is also correct. Note also that, for w > 1 the Points relation might prefer dominated solutions over non dominated ones. As an example consider a set X = {a, b, c}∪D, with |D| ≥ 2, a≺c and ∀d ∈ D: a≺d∧c≺d (and all other pairs are incomparable). Hence, S(b, X) = |X| = |D| + 3, S(a, X) = 2 + w(|D| + 1), S(c, X) = 2 + w(|D|). Thus, c is ranked better than b if w > 1.In sports w = 2 is often used for games where ties occur only rarely or never. However, in cases where ties are very likely to occur often a higher w-value is used. An example is the soccer league where w = 3 should encourage the teams to avoid ties and play for a win. In volleyball there is nowadays a distinction between clearly won games that yield 3 points and close games which give 2 points. An analogous extension of relation Points is left as future work.For the Points relation with w = 2 an interesting property holds as shown in the following. For A⊆X it holds thatS(A,A)=|A|2+(w−2)·B≺f(A,A). Thus, w = 2 is the only value for w where the score S(A, A) of a set A depends in general only on the size of the set and not on parameter w. In the following we explain why this property is advantageous when the Points relation is used for the selection of a subset of k ≥ 1 good solutions from a set of non dominated solutions. For this we extend the Points relation such that for sets A, B, C, D⊆X we defineA≺PtC,DBiff S(A, C) ≤ S(B, D). Assume that A is a set of non dominated solutions and B, C⊂A with |B| = |C| = k and S(B, A) ≥ S(C, A). Then, it holds that S(B, A − B) = S(B, A) − S(B, B) = S(B, A) − k2 ≥ S(C, A) − k2 = S(C, A) − S(C, C) = S(C, A − C). This proves that for w = 2 and sets A, B, C⊂X with |B| = |C| property (*) holds:B≺PtAC⟶B≺PtA−B,A−CC.For values of w ≠ 2 property (*) does not necessarily hold. In that case the reason for a high score S(B, A) might be that the comparison of elements of B with each other leads to a high (small) number of wins with respect to≺ffor w > 2 (respectively 1 ≤ w < 2). Then a subset C⊆A with |C| = k and S(C, A) < S(B, A) might exist that has a better score than B with respect to its corresponding complement, i.e. S(C, A − C) > S(B, A − B).In the following we give two examples which show that property (*) does not hold in general for the Points relation when w ≠ 2. Consider a directed graph G′ = (V, E) with V = {v1, …, v12}. Let A = {v1, …, v5}, B = {v6, …, v10}, and C = {v11, v12}. For every node v ∈ A edge (v12, v) ∈ E. For every node v ∈ B edges (v11, v), (v12, v) ∈ E. All other edges in E are only between nodes of B such that every node in B has two ingoing edges from other nodes in B (same as for the nodes of B in graph G as shown in Fig. 1). As we have shown in Lemma 3.1 there exists an objective functionf→such that G′ is the favour graph of X = V. First consider the case w = 1.5 < 2. Then each node a ∈ A has score S(a, X) = 12.5, each node b ∈ B has score S(b, X) = 12, node v11 has score S(v11, X) = 7, and node v12 has score S(v12, X) = 2. Hence, S(A, X) > S(B, X). But S(A, X − A) = 37.5 is smaller than the score S(B, X − B) = 40. Now consider the case w = 4 > 2 and a graph G′′ that is similar to G′ with the difference that each edge (v11, v) for v ∈ B is removed and edge (v11, v′) is added for each node v′ ∈ A. Then each node a ∈ A has score S(a, X) = 18, each node b ∈ B has score S(b, X) = 19, node v11 has score S(v11, X) = 7, and node v12 has score S(v12, X) = 2. Hence, S(B, X) > S(A, X), but S(B, X − B) = 50 is smaller than the score S(A, X − A) = 65.A summary of the properties of the ranking relations that have been studied in this paper is given in Table 2. Note, that by requiring < instead of ≤ in the definition of the WL relation (last in equation of Eq. (4)) one would obtain the corresponding strict weak ordering relation, i.e. a relation which is irreflexive, asymmetric, transitive, and where incomparability is transitive. Analogously, this holds for the Points relation when requiring > instead of ≥ in Eq. (8).In this section we describe the two metaheuristic algorithms that are used to test the new ranking relations. As test problem we use a multi objective scheduling problem with the aim to find a permutation of n given jobs that is optimal for given set of cost functions (details are described in Section 6).In contrast to the traditional ACO algorithms (for an overview see Dorigo and Stützle, 2004) the population-based ACO (P-ACO) as proposed by Guntsch and Middendorf (2002) uses a population P of p solutions that is transferred from one iteration to the next (see Algorithm 1). The population is then employed to compute the pheromone information that is used by the ants to compute a set L of l new solutions. The pheromone information for the scheduling problem is stored in a pheromone matrix [τij], i, j ∈ [1: n] where τijis the pheromone value for placing job j at place i in the schedule. Each pheromone value τijis defined by τij= τinit + Δ · k using Δ = (τmax − τinit)/p, where τinit and τmax are parameters of the algorithm giving the minimum and maximum pheromone values and k is the number of permutations in the current population that have job j at position i. As in traditional ACO algorithms an ant constructs a solution iteratively such that the probability pijto select job j for position i in the permutation ispij=τij/∑k∈SτikwhereSis the set of jobs that are still selectable, i.e. the set of jobs that have not already been placed on positions 1 to i − 1 in the permutation. This way of using the pheromone information is particularly suitable for scheduling problems (see also Merkle and Middendorf, 2014).In the original P-ACO algorithm in every iteration the best solution from the set of new solutions L is added to P and the oldest solution is removed from P. Alternative strategies for the removal of solutions from P have also been proposed in Guntsch and Middendorf (2002), e.g. to remove the worst solution. In this paper we use a different population update method that is based on the ranking relations: the solutions in P∪L are sorted with one of the ranking methods and the best p solution form the new population P for the next iteration. A stable sorting algorithm enforces that solutions of the population are not replaced by solutions that are not better.We use a standard GA to investigate the influence of the different ranking methods when the algorithm is applied to the multi objective scheduling problem (for an introduction to genetic algorithms see, e.g. Mitchell, 1996). The GA uses a population P of p solutions that are transferred from one iteration to the next. In every iteration a set L of l new solutions is computed. The new solutions are obtained by two types of operations from solutions in P: (i) crossover of two solutions (called parents) from P and (ii) mutation of a solution in P. As crossover operation a two point crossover is used, where the interval between two random points of a permutation is taken from one parent and the other positions are filled by the remaining jobs in the order of occurrence in the other parent. As mutation operator a switch operation is used to exchange the order of two neighboured jobs in a permutation.To create the l new solutions from the parent population each possible pair of solutions is taken to create one new solution by crossover. Moreover, each solution from P is taken to create one new solution by mutation. Hence, altogether l = p · (p − 1) + p = p2 new solutions are created per iteration. The p old solutions from P together with the p2 new solutions are ranked with one of the ranking methods. Then the best p solutions are selected to form the new population P for the next iteration. A stable sorting algorithm is applied to ensure that solutions in the population are not removed from the population in favour of an equally ranked solution, that was generated in the respective iteration.The different P-ACO and GA algorithms are denoted by X–P-ACO, respectively X–GA, where X ∈ {Pt, WL, W, Win} is the respective ranking method that is used in the algorithm. When the type of algorithm is clear from the context X is used as abbreviation of X–P-ACO or X–GA.The P-ACO with the new ranking methods was also compared to two multi objective P-ACO algorithms from the literature: (i) the crowding P-ACO (Cr–P-ACO) introduced in Angus (2007) and (ii) a P-ACO which is called standard P-ACO (Std–P-ACO) here and is motivated by Guntsch and Middendorf (2003). In the crowding P-ACO the amount of updated pheromone is inversely proportional to the dominance depth of the corresponding solution (Deb et al., 2000). The population update is done by a crowding scheme. In each iteration for each newly generated solution a random subset of the population is chosen. If the new solution dominates the solution of this subset, that has the highest similarity with the new solution, the new solution replaces that solution. Otherwise the new solution is discarded. Similarity is measured in the solution space as the number of common adjacent jobs. Note, that this is different from the crowding measure that was used in Deb et al. (2000), where similarity was analysed with respect to the objective space. The standard P-ACO computes the non dominated front from the solution in P∪L in every iteration. The new population for the next iteration is determined by selecting a randomly chosen solution s from the non dominated front and then choosing the p − 1 solutions closest to s in the objective space. Note that the Cr– and Std–P-ACO make no use of the new ranking methods, but are based solely on the Pareto dominance relation.

@&#CONCLUSIONS@&#
Two new methods for ranking the solutions of multi objective optimization problems have been proposed. The new methods are called WL relation and Points relation, respectively and are based on the favour relation that was studied in Drechsler et al. (2001). The ranking methods can be used by iterative metaheuristics to select good solutions that are to be used in the next iteration from a set of solutions that have been found in the current iteration. It was shown theoretically that the new ranking methods have desirable properties that are useful for such an application. In particular, the ranking methods were related to the notion of Pareto dominance. It was shown, e.g. that both ranking methods form a total preorder and both are refinements of the Pareto dominance relation.In an experimental study the ranking methods were used in a P-ACO algorithm and in a GA to select the solutions that are allowed to enter the population. The P-ACO algorithms with the new ranking methods were compared with four other P-ACO algorithms, e.g. P-ACOs using other ranking methods and the Crowding P-ACO from Angus (2007). The GA algorithms with the new ranking methods were compared to two GAs that use other ranking methods. In particular, we studied a situation where the population size is kept small and the algorithms are applied to a four objective flowshop problem. We used no additional heuristic information. The results show that both metaheuristics profit from the new ranking methods and perform well on the flowshop problem.For future work it is interesting to study the combination of several ranking methods within one algorithm. Our results indicate that a combination of one or both of Pt and WL ranking together with the Win ranking might perform very well. This could be good also for metaheuristics with a large population where the aspect of diversity is important.Other values for the w parameter of the WL ranking could also be of further interest. How the different ranking methods perform in other evolutionary multi objective algorithms and on other problems can be investigated.