@&#MAIN-TITLE@&#
Medium range optimization of copper extraction planning under uncertainty in future copper prices

@&#HIGHLIGHTS@&#
A stochastic model for strategic planning in copper mines is presented.The uncertainty in copper price is represented via a multistage scenario tree.Risk management strategies are presented (VaR, CVaR, MEAN-RISK, SDC).Deterministic, risk neutral and risk averse approaches are compared.Risk averse ones give better solutions than the others: bad scenarios have greater profit and lower probability to appear.

@&#KEYPHRASES@&#
Mining,Planning models,Copper price uncertainty,Multistage stochastic mixed 0–1 optimization,Risk aversion,

@&#ABSTRACT@&#
Deterministic mine planning models along a time horizon have proved to be very effective in supporting decisions on sequencing the extraction of material in copper mines. Some of these models have been developed for, and used successfully by CODELCO, the Chilean state copper company. In this paper, we wish to consider the uncertainty in a very volatile parameter of the problem, namely, the copper price along a given time horizon. We represent the uncertainty by a multistage scenario tree. The resulting stochastic model is then converted into a mixed 0–1 Deterministic Equivalent Model using a compact representation. We first introduce the stochastic model that maximizes the expected profit along the time horizon over all scenarios (i.e., as in a risk neutral environment). We then present several approaches for risk management in a risk averse environment. Specifically, we consider the maximization of the Value-at-Risk and several variants of the Conditional Value-at-Risk (one of them is new), the maximization of the expected profit minus the weighted probability of having an undesirable scenario in the solution provided by the model, and the maximization of the expected profit subject to stochastic dominance constraints recourse-integer for a set of profiles given by the pairs of target profits and bounds on either the probability of failure or the expected profit shortfall. We present an extensive computational experience on the actual problem, by comparing the risk neutral approach, the tested risk averse strategies and the performance of the traditional deterministic approach that uses the expected value of the uncertain parameters. The results clearly show the advantage of using the risk neutral strategy over the traditional deterministic approach, as well as the advantage of using any risk averse strategy over the risk neutral one.

@&#INTRODUCTION@&#
The open pit mining production scheduling is a typical mining problem which has been treated by heuristic approaches to solve a huge deterministic MIP problem, see e.g., Boland, Dumitrescu, Froyland, and Gleixser (2009) and references therein. We consider here a planning problem for a large underground mine, El Teniente in Chile. The management mine has also used a large scale deterministic MIP, with heuristics, to support long range planning, see Caro, Epstein, Santibañez, and Weintraub (2007) and Epstein et al. (2012). The planning involves decisions regarding which blocks to extract each year, which machinery to use, how to transport the material for grinding and processing into commercial copper, etc. The use of the deterministic model has been very successful, yielding an improvement in Net Present Value over a 25year horizon of about 5%, over 100 million US $. In this paper, we introduce explicitly the issue of uncertainty, which is of concern to the firm. There are two major sources of uncertainty in the firm’s planning. One is derived from the market. Copper prices are highly volatile, especially lately, and hard to predict. This uncertainty is represented in the paper by a multistage scenario tree, and is treated by a scenario analysis scheme. The other main source of uncertainty is the grade (% of copper) in different parts of the mine. Prospecting can improve knowledge about the grade. In addition, as the extraction of the mine progresses, more information on grades becomes available, so we do not deal with that uncertainty in this paper. Only uncertainty in prices is considered.In this work we consider a time horizon of 5years (so, it is a medium range planning), which is appropriate for making commercial decisions related to copper sales. The uncertainty is reflected through price scenarios, which define a possible price for each period (typically, a year) throughout the horizon. The decisions to be made concern the quantity of copper to extract in each period and the blocks from which it will be extracted. To solve the problem, we need to satisfy the nonanticipativity principle (J-B Wets, 1974; Rockafellar & Wets, 1991). The satisfaction of the related constraints is implicit in the Deterministic Equivalent Model (DEM) presented below in compact form, which is equivalent to the stochastic model.The deterministic problem is already very large, as all 30 by 30 by 30 meter blocks in the mine are defined explicitly. The detailed mixed 0–1 DEM is therefore also very large, even considering only a 5year horizon. Since on the one hand, in stochastic modeling the basic problem needs to be solved repeatedly and, on the other hand, decision making at this level does not require a high level of detail, we first reduce the size of the problem through an aggregation procedure, with a low loss in optimality. The uncertainty in the copper prices will be represented by a set of scenarios in the aggregated model. We will present a tight mixed 0–1 DEM, such that a state-of-the-art commercial solver can solve the instances for a moderate number of scenarios.We first introduce the stochastic model by maximizing the expected profit along the time horizon over all scenarios (i.e., as in a risk neutral environment), subject to the satisfaction of all the problem constraints in all defined scenarios. We are able to solve very large tight DEMs (up to 800,000+ constraints, 274,000 0–1 variables and 1900+ continuous variables) using a state-of-the-art MIP solver for cases with 77-scenarios in a reasonable amount of elapsed time; see Section 5. The expected profit is maximized but the DEM does not consider the risk of scenarios with bad consequences. Thus, in addition, we present several approaches for risk management in a risk averse environment, namely, (1) the maximization of the well known Value-at-Risk (VaR), (2) the maximization of several variants of the Conditional Value-at-Risk (CVaR), (3) the maximization of the mean-risk, i.e., the expected profit minus the weighted probability of a “bad” scenario occurring for the given solution provided by the model, (4) the maximization of the expected profit subject to first-order stochastic dominance constraints recourse-integer (sdc) for a set of profiles given by the pairs of target profits and bounds on the probability of failure, and (5) the maximization of the expected profit subject to second-order sdc whose set of profiles are given by the pairs of target profits and bounds on the expected shortfall. An extensive computational experience on a realistic problem is presented by comparing the risk neutral approach, the above risk averse strategies and the performance of the traditional deterministic approach by considering the expected value of the uncertain parameters.There is a vast literature on production planning under uncertainty, where it is represented by a set of scenarios. See hierarchical approaches in Gfrerer and Zapfel (1995) and Lasserre and Merce (1990). For recent state-of-the-art surveys, see Alonso-Ayuso, Escudero, and Ortuño (2007), M- Choi and Chiu (2012), and Graves (2008). Most of the approaches only consider two-stage environments, but we are interested in multistage production planning problems as the subject of our work, where the uncertainty presentations and decision variables are structured in scenario trees as the works in Ahmed, King, and Parija (2003), Alonso-Ayuso et al. (2007), Baricelli, Lucas, and Mitra (1996), Brandimarte (2006), Cristobal, Escudero, and Monge (2009), Eppen, Martin, and Schrage (1989), Escudero, Galindo, Gómez, García, and Sabau (1999), Graves (2008), Huang (2005), Leung, Tsang, Ng, and Wu (2007), Lucas, Mirhassani, Mitra, and Poojari (2001), Lulli and Sen (2002), Romeijn (2002), Santoso, Ahmed, Goetschalckx, and Shapiro (2005), Tomasgard and Høeg (2005), among others. Most of these works consider only the uncertainty in the demand along the time horizon but, while this is an important parameter, there are some other parameters that have also uncertainties, as the frequent volatile prices of the products in our case. Additionally, most of the previously cited works only consider the risk neutral strategy (i.e., the optimization of the objective function expected value (i.e., cost) over the scenarios, without considering the variability of the objective function values for specific scenarios and, then, without minimizing (or reducing, at least) the impact of the bad scenarios. Risk averse strategies have been recently considered in the literature, by using a mean-risk approach. One of the first approaches in the so named excess probability strategy introduced in Schultz and Tiedemann (2003), where the aim is to minimize a combination of 1. expected cost and 2. weighted probability of scenarios whose cost is over a given threshold. Another interesting work that uses a risk averse strategy is presented in Eppen et al. (1989), where the aim is to minimize the expected cost surplus over the scenarios.The other risk averse strategies that are used in our mining problem such as Value-and-Risk (Charpentier & Oulidi, 2008; Gaivoronski & Pflug, 1999; Gaivoronski & Plug, 2005), different variants of the Conditional Value-at-Risk (CVaR) (Ahmed, 2006; Beraldi, Consigli, de Simone, Iaquinta, & Violi, 2011; Colvin & Maravelias, 2011; Ehrenmann & Smeers, 2011; Ogryczak & Sliwirski, 2011; Rockafellar & Uryasev, 2000; Schultz & Tiedemann, 2006; Shapiro, Dencheva, & Ruszczynski, 2009), Stochastic Dominance Constraints (SDC) strategies, see Dentcheva and Ruszczynski (2003), Dentcheva and Martinez (2012), Gollmer, Neise, and Schultz (2008), and Gollmer, Gotzes, and Schultz (2011) and the references therein, among others, are more frequently used in the electric sector. See in Conejo, Carrion, and Morales (2010) a set of applications of decision making under uncertainty in the electricity market with risk aversion by using some of the above cited strategies for a two-stage setting. See also Aranburu, Escudero, Garín, and Pérez (2012, chap. 8), Drapkin, Gollmer, Gotzes, Neise, and Schultz (2009), Drapkin et al. (2011), Fabian, Mitra, and Roman (2013), Fabian et al. (2008), Fabian et al. (2011), and Lizyayev (2012) for applications of the two-stage SDC strategies, specifically, in energy and finance, among others, particularly for second-order SDC by using Lagrangean and cutting plane approaches. See Artzner, Delbaen, Eber, and Health (1999), Ruszczynski and Shapiro (2006) for the axioms for coherent measures in two-stage settings and Artzner, Delbaen, Eber, Health, and Ku (2007) for its extension to the multistage setting.The main contributions of the paper are as follows:1.We Present a tight MIP model for solving difficult medium-range deterministic copper extraction planning problem. We also extend the deterministic model for allowing to consider copper price uncertainty in the model by scenario analysis, given its high volatility. As a result, we can partially reduce profit impact of the solution in non-desirable scenarios by maximizing the expected profit over the scenarios (i.e., the so named risk neutral strategy is used) subject to the satisfaction of the constraint system for all scenarios in the multistage scenario tree used for representing the uncertainty. The resulting DEM has huge dimensions.We introduce a variant of CVAR strategy in which a combination of the VaR and the weighted Conditional expectation above VaR is maximized in contrast to the traditional CVaR strategy. The results are very good at the cost of requiring a higher computational effort.We present a non-trivial extension to the multistage environment of well known two-stage risk averse strategies (some of them very recently introduced in the literature, and one of the CVaR strategies is new) and performing for the first time, to our knowledge, a computational comparison of the advantage of risk reduction by each strategy at the cost of reducing (sometimes only slightly) the expected profit obtained by the risk neutral approach. It is not the first time that risk averse measures have be been used for risk management of multistage stochastic mixed 0–1 problems, see Colvin and Maravelias (2011), Conejo et al. (2010), Gaivoronski, Sechi, and Zuddas (2012), and Pflug and Römisch (2007), for instance, a good up-to-date survey on risk averse strategies in multistage problems has been presented in Pflug and Römisch (2007), computational studies of VaR variations and CVAR multistage strategies have been presented in Beraldi et al. (2013), Colvin and Maravelias (2011), and Philpott and de Matos (2012) for capital budgeting, pipeline planning and dynamic scheduling in general, respectively, and a study for water resource management in a multistage environment has been presented in Gaivoronski et al. (2012) by iteratively reoptimizing (1) the balance between the water level target delivery and the level risk to meet, measured the latter one by the semi-deviation of the scenario levels versus the estimated one, and (2) studying the worst case scenario by barycentering the level of user demand, among others. As far as we know, however, no multistage extension of the other risk averse measure but minmax, VaR, CVaR and semi-deviation bounding has yet been performed. No computational comparison of multistage risk measures has been performed either.Computationally we recognize that a plain use of even state-of-the-art MIP solvers cannot solve large-scale multistage stochastic MIP problems where risk reduction is to be performed by cross scenario risk averse strategies. Instead of using MIP solvers, it is strongly suggested to use some decomposition algorithm, as outlined in Section 6.The remainder of the paper is organized as follows. In Section 2 we describe the mining problem, including the aggregation process; also, a tight mixed 0–1 optimization model is presented for the deterministic version of the problem, in which all parameters are assumed to be known in advance. In Section 3, the copper price uncertainties are presented, the scenario analysis methodology that is used to deal with the uncertainty is also presented and the model for the risk neutral environment is given. Section 4 presents the risk averse strategies of our choice, namely, VaR, several variants of CVaR, mean-risk and the sdc strategies. Section 5 reports on the computational experiment using a state-of-the-art MIP solver, with three illustrative large-scale 27-, 45- and 75-scenarios cases. It also reports the computational comparison between the risk neutral strategy and the traditional deterministic strategy where the uncertain parameters have been replaced by the expected ones. Section 6 concludes, outlining our future work that, basically, will consist of using decomposition algorithms for the splitting variable representation of the problem. In this way, the solution of larger instances can be obtained with reasonable computational effort, something that cannot be done using a MIP solver, even when using the compact representation of the model.We consider an underground mine that has to be mined along a time horizon. Mining is carried out in several sectors of the mine. In each sector, there are a number of vertical columns, composed of blocks of 30 meters by 30 meters by 30 meters. Each column has a height of hundreds of meters. Thus, a column may consist of up to 50 vertical blocks. The columns are adjacent to each other, and are extracted in sequence.The extraction method used is called block caving: At each drawpoint of a column, a void is created so that the rock breaks and falls due to gravity (see Fig. 1). The danger of block caving is that it removes much of the supporting rock from underneath the surface rock, often leading to subsidence, the gradual settling or sinking of the surface. Thus, the following specific rules must be respected in the mining process:•The columns enter production in a specified sequence, given by their spacial location.For mechanical structural reasons, the height of columns cannot be arbitrary. When considering neighboring columns, their height cannot be too different. In this form, if a column r reaches a height H, the columns neighboring r need to be extracted with height close to H. This condition is called neighborhood smoothness.At each drawpoint there is a maximum extraction rate to prevent the roof from collapsing and a minimum number of blocks to be extracted from each column to ensure a proper structure of the remaining mine.Additionally, there is a cost associated with increasing or decreasing production in a sector from one period to the next one.Fig. 2depicts a typical flow process. In the block caving process, the broken rock is removed from the bottom of the columns and hauled using specialized machinery to a dumping point. There, through gravity rock is driven through a draining process and then the ore reaches a crusher where a rock reduction process is carried out. Finally, the crushed rock reaches a lower level, where it is sent via train to downstream processes. There are two processing streams in the plants, called B and C.Decisions need to be made on when to cave in each column, when to move to the next column, and how far up in the column to extract. The rate of copper content tends to drop as we go up the column, so, depending on copper prices, it may be preferable at some point to drop the present column and move to the next one. At any rate, once a column is dropped from production, it cannot be re-entered due to mechanical and stability issues. Another important decision consists of selecting which of the available sectors should be worked on. Then, downstream operations need to be integrated, including transportation, rock reductions, operations at mills and concentration plants until commercial copper is produced. The mine process can be represented in a network form, where the nodes represent specific activities and the arcs represent transportation, as shown in Fig. 3.An aggregation procedure was presented in Weintraub, Pereira, and Schultz (2007) to reduce the size of the deterministic version of the problem. The aggregation was based on a cluster analysis (Zipkin, 1980), where the blocks of the original problem were aggregated based on spatial neighborhoods and similarities on the grade contents in copper and molibdenum, i.e., tons produced and extraction speed. The aggregation process involves defining components which are of significance to obtain an aggregate value. In this form, weights are assigned to each component according to their significance for the final value. In the mining problem, the most important component was speed of extraction. The clustering method was a modification of the approach proposed in Hartigan (1975). This aggregation process insures feasibility when the solution is again disaggregated. Fig. 4shows an example with 50 blocks disposed in 10 columns. The figure depicts an example of how the blocks have been aggregated into 20 clusters. Note that a cluster can include blocks from different columns; for instance, cluster 12 consists of 4 blocks that form an L. It is worth pointing out that, due to the extraction method, precedence relations do exist. For example, clusters 20 and 16 need to be extracted before cluster 15, since extraction is performed by gravity. In special cases, clusters are linked so that they have to be extracted simultaneously. In the aggregated form, the smoothness of extracted columns is not preserved directly. When disaggregating, the cluster solution smoothness is imposed again. We use the aggregated model in the stochastic version of the problem presented in this paper.We now present a tight deterministic MIP model for the aggregated version of the problem, where some blocks have been aggregated into clusters. The notation to be used through the paper is as follows:•T, set of periods in the time horizon.S, set of sectors.Ks, set of clusters in sector s, fors∈S.Tk, set of periods when cluster k can be reached in the extraction process, fork∈Ks,s∈S.Ps, set of subsets of clusters in sector s, such that each elementPiinPsis a set of clusters that must be extracted simultaneously, fors∈S. Note 1:Tk=Tk′, fork,k′∈Pi,Pi∈Ps,s∈S. Note 2:Psdefines a partition ofKs, fors∈S.Predk, set of predecessor clusters of cluster k, such that all clusters in Predkmust be extracted by the time cluster k is extracted, fork∈Ks,s∈S. Note 1:Predk⊂Ks, fork∈Ks,s∈S. Note 2:Tkshould be defined taking into account the precedence relationships defined by set Predk.•percentkcuandpercentkmo, percentage of copper and molybdenum in cluster k, respectively, fork∈Ks,s∈S.areak, maximum area (in m2) that can be mined in cluster k, fork∈Ks,s∈S.TONk, number of tons of rock that can be processed in cluster k at any period (i.e., a year), fork∈Ks,s∈S.TONsini, number of tons of rock that have been processed in sector s at the pre-initial period (i.e., period 0), fors∈S.TON¯, maximum number of tons of rock that can be processed per period.TONst, minimum number of tons of rock that can be processed, if any, in sector s at period t, fors∈S,t∈T.TON¯st+andTON¯st-, maximum increase and decrease of tons of rock processed in sector s from period t-1 to period t, respectively, fors∈S,t∈T.area¯sandareas, maximum and minimum area that can be processed (in m2) in sector s, respectively, fors∈S.TON¯tB, maximum number of tons of rock that can be processed at stream B at period t, fort∈T.discountt, discount factor in period t for prices and costs, fort∈T.pricetcuandpricetmo, copper price and molybdenum price per ton at period t, respectively, fort∈T.coststm, cost per ton unit of mining in sector s at period t, fors∈S,t∈T.coststa, cost per ton unit of area in sector s at period t, fors∈S,t∈T.costst+andcostst-, cost per ton unit of production increase and decrease from period t−1 to period t, respectively, fors∈S,t∈T.costtBandcosttC, cost per ton unit of processing at streams B and C at period t, respectively, fort∈T.•zkttakes the value 1 if cluster k is extracted in period t and 0 otherwise, fort∈Tk,k∈Ks,s∈S.xstakes the value 1 if sector s is extracted and 0 otherwise, fors∈S.•tonst, number of tons of rock extracted in sector s at period t, fors∈S,t∈T.tonst+andtonst-, increase and decrease in the number of tons extracted in sector s at period t, fors∈S,t∈T.tontBandtontC, number of tons sent to process in period t in processing streams B and C, respectively, fort∈T.(1)max∑t∈Tdiscountt∑s∈S∑k∈KsTONkpricetcupercentkcu+pricetmopercentkmozkt-∑s∈Scoststmtonst+coststa∑k∈Ksareakzkt+costst+tonst++costst-tonst--costtBtontB-costtCtontC.Function (1) maximizes the net present value of the total profit along the time horizon. The profit for each period includes the income from selling the extracted copper and molibdenum, reduced by the mining and sector costs, the cost of production increase and decrease from one period to the next one, and processing costs.(2)∑t∈Tkzkt⩽xs,∀k∈Ks,s∈S(3)∑t′∈Tk:t′⩽tzkt′⩽∑t′∈Tj:t′⩽tzjt′∀j∈Predk,t∈Tk,k∈Ks,s∈S(4)zkt=zk′t∀t∈Tk,k,k′∈Pi,Pi∈Ps,s∈S(5)tonst=∑k∈Ks:t∈TkTONkzkt∀s∈S,t∈T(6)tontB+tontC=∑s∈Stonst∀t∈T(7)tonst+-tonst-=tonst-TONsini,ift=1tonst-tons,t-1,ift>1∀s∈S,t∈T(8)area̲sxs⩽∑k∈Ksareak∑t∈Tkzkt⩽area¯sxs∀s∈S(9)∑s∈Stonst⩽TON¯∀t∈T(10)TON̲stxs⩽tonst∀s∈S,t∈T(11)0⩽tontB⩽TON¯tB∀t∈T(12)0⩽tonst+⩽TON¯st+xs∀s∈S,t∈T(13)0⩽tonst-⩽TON¯st-xs∀s∈S,t∈T-{1}(14)0⩽tontC∀t∈T(15)zkt∈{0,1}∀t∈Tk,k∈Ks,s∈S(16)xs∈{0,1}∀s∈S.Constraints (2) guarantee that no cluster is processed in an unselected sector and, additionally, they ensure that each cluster is processed at most once. There are different alternatives for modeling precedence relationships. However, constraints (3), that guarantee that if a cluster is processed at a given period then all predecessor clusters are also processed by that period, have given very good results in other contexts since it results in a stronger model (see Agustín, Alonso-Ayuso, Escudero, & Pizarro, 2012; Bertsimas & Stock, 1998, among others). Our results confirm those other results. Notice that this type of constraints does not force a cluster to be processed if any of its predecessors is processed. Additionally, if a predecessor cluster has not been processed, then the given cluster cannot be processed yet. Constraints (4) force the clusters in setPito be extracted simultaneously in each sector. Constraints (5) evaluate the number of tons processed in each sector at each period. Constraints (6) are the flow conservation constraints for the processing stream. Constraint (7) calculates the increase and decrease in the number of tons processed in each period, respectively. Constraints (8) impose upper and lower bounds for the total area processed in each sector. Constraints (9) and (10) impose bounds on the number of tons processed in each period. Constraints (11) impose an upper bound due to the capacity of processing stream B. Stream C is not a bottleneck. The volumes (tons) processed are well below the capacity of stream C, so its capacity is never an active constraint. Constraints (12) and (13) bound the maximum increase and decrease of tons in each sector in each period.As stated above we consider the underground mine El Teniente (Chile) as our pilot case. It is exploited by CODELCO, one of the leading copper extracting companies in the world. The time horizon is 5years (from 2006 to 2010). The overall number of sectors is 18, but given our horizon, only 3 of them are considered as active,S={ES,FW,NN}. The extraction can only be carried out either on the two smaller sectors (FW and NN) or on the larger one (ES). Then, the following constraints must be added to the model:xES+xFW⩽1xES+xNN⩽1Those sectors have|KES|=2100,|KFW|=664and|KNN|=2640clusters. The column numbers go from 70 to 2500, each with a basal area between 250m2 and 400m2 and a height between 549m and 959m. Thus, a column may consist of between 18 and 32 vertical blocks.CODELCO sells about 10% of the copper production that is traded in the world. That means it is not a marginal price taker. However, it cannot sell in the market any amount of copper. If the amount put into the market is too large, it will drive down prices. So, CODELCO plans the yearly production considering also in some form its effect on prices, though not in a rigorous way. In this form, it assigns limits of production to each mine, and sectors. Constraints (9) and (10) limit from above and below the total production in each period, which considers the limits of production vis a vis markets. Once these limits on production are imposed, the problem that we are addressing consists mainly of deciding how to deal with the uncertainty resulting from the high volatility in world copper prices (see Section 3). At any rate, whether TON is bounded or not does not affect the tightness approach used in the model design, nor the methodology for risk management proposed in what follow.The deterministic model assumes that prices are known in advance of the planning decision. However, as we can see in Fig. 5, copper prices can vary along the planning horizon. Notice the volatility of the uncertain parameters which are therefore very difficult to predict.For representing the uncertainty in copper prices, we use a scenario tree approach in which uncertainty is modeled in terms of a set of scenarios. See e.g., Alonso-Ayuso, Escudero, and Ortuño (2003) for symmetric scenario trees, among many others, and Escudero, Garín, Merino, and Pérez (2012) for nonsymmetric ones. For this purpose we need the following definitions. A stage of a time horizon is a set of one or more periods (in our case, years) in which the random parameters are realized; a scenario is the realization of uncertain parameters during the stages of the time horizon; and each node at a given stage represent the group of scenarios with the same uncertain parameter realizations up to that stage. (That is, a node defines a group of partial scenarios.)To illustrate the multistage scenario tree concept, let Fig. 6depict a symmetric scenario tree in which each node represents a stage, where a decision can be taken. Once a decision has been taken, various possible situations may occur. In our example there are two situations in stage t=2. This information is generally presented in the form of a tree in which each path from the root to a leaf represents a scenario and corresponds to the realization of the entire set of uncertain parameters. For example, path {1,3,6,12} represents one scenario, and it is customary to call it scenario 12. In what follows, we do not distinguish between a scenario (or a group) and the corresponding node on the tree (with the same number). Each node in the tree must be associated with a group of scenarios in such a manner that any two scenarios belong to the same group (i.e., having the same partial scenario) in a given stage if they include the same occurrences of uncertain parameters up to that stage. In this case, the well known non-anticipativity principle applies. It was stated in J-B Wets (1974) and restated in Rockafellar and Wets (1991); see also Birge and Louveaux (2011), among others. This principle ensures that the solution at each t does not depend on information that is yet unavailable and requires that the decisions pertaining to scenarios in the same node (i.e., partial scenarios with the same value in the parameters) be the same. For example, for stage 3, scenarios 12 and 13 belong to the same node associated with path {1,3,6}, i.e., with node g=6. Notice the difference between a scenario (a path from the root node to a leaf node) and a partial scenario (a path from the root to an intermediate node).The notation for the scenario tree to be used in the paper is as follows:T,set of stages in the time horizon 1,2,…,T.set of all stages except the last one.set of scenarios.set of nodes.set of nodes in stage t(Gt⊆G), fort∈T.set of scenarios in node g (Ωg⊆Ω), forg∈G.immediate ancestor node of node g, forg∈G. Notice that Ωg={ω} forg∈GT, where ω is the related scenario ω from Ω in node g.set of ancestor nodes to node g, including itself.Let us consider the following deterministic problem(17)maxax+cys.t.Ax+By=bx∈{0,1}n,y⩾0,where m, n and ncare the number of constraints, and 0–1 and continuous variables, respectively, a and c are n- and nc-dimensional objective function coefficient vectors, respectively; b is the m-dimensional right-hand-side (rhs) of the constraint system; A and B are m×n and m×ncconstraint matrices, respectively; and x and y are the n-vector of 0–1 variables and the nc-vector of continuous variables along the setTof periods, respectively. If the parameters of vector c (i.e., copper prices) in this problem are random parameters with a set of discrete occurrences, say, cωover the set Ω of scenarios ω∈Ω, we will model our problem for maximizing the expected profit over the scenarios as follows:(18)max∑ω∈Ωwω(axω+cωyω)s.t.Axω+Byω=b∀ω∈Ω(x,y)∈Nxω∈{0,1}n,yω⩾0∀ω∈Ω,where wωis a positive weight/probability assigned to scenario ω (with∑ω∈Ωwω=1); xωand yωrepresent the x and y variables for scenario ω, respectively.N, the non-anticipativity set, is defined by(19)N=v|vtω=vtω′,∀ω,ω′∈Ωg,g∈Gt,t∈T-,where v=(x,y) andvtωis such thatvω=vtω,∀t∈T. Upon incorporating the set (19) in model (18), we can obtain the related multistage Deterministic Equivalent Model (DEM). The non-anticipativity set can be represented implicitly, through the variable definition (compact formulation) or explicitly, including new constraints in the model (splitting variable representation), see (Escudero et al., 2012), among others. For the purpose of the paper, we will only consider the compact representation since it is to be solved by a commercial MIP solver, and the splitting variable representation is more focused on decomposition methods, Section 6.Variables in model (1)–(16) have nonzero coefficients only in the constraints related to two consecutive stages (in our case, yearly periods) and the objective function is to maximize the expected value (i.e., mean) of the expected profit (risk neutral) of all scenarios. The model can be represented as follows:(20)QE=max∑g∈Gwg(agxg+cgyg)s.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈Gxg∈{0,1}nt,yg⩾0∀g∈G,wherewg=∑ω∈Ωgwωgives the weight assigned with node g, ntis the number of x and y variables at stage t, and agand cgare the counterparts of parameters a and cωrelated to node g, forg∈G, such that the values of the parameters for each scenario in the node are identical. Additionally, xgand ygrepresent the x and y variables for node g, respectively, and A′ and B′ are the constraint matrices in node g for the x and y variables related to the immediate ancestor of node g. Notice that in our case, the values of the vectors agare the same for the nodes {g} that belong to the same stage t, i.e., the groups inGt.It is beyond the scope of this work to present a methodology for multistage scenario tree generation and reduction; see e.g., Beraldi and Bruni (submitted for publication), Dupacova, Consigli, and Wallace (2000), Heitsch and Römisch (2009), Hoyland, Kaut, and Wallace (2003) for different alternative ways for performing it. A rigorous development of scenario trees for future copper prices is extremely complex. To our knowledge it is still an open research problem. However, as an illustrative instance, Fig. 7depicts an ad hoc generated multistage 27-scenario tree for the copper prices during the years 2006 to 2010. The procedure basically consists of considering a base price for copper in 2006 ($2567 per ton). From each node in the tree, three sons are created: the first one has a price 35% greater than his father, the second one has the same price that the father and the third one has a price 35% lower than the father. We assume that the modeler gives more likelihood to the increase of the copper prices, and, then, the weights for each of the three sons are36,26,16, respectively. All scenarios clearly have the same price, 2576 US$/ton for stage 1 (i.e., year 2006), then prices go up or down. For stage 5 (i.e., year 2010) the range is from 705 to 6316 US$/ ton, see the statistical historical information in COCHILCO (1996–2011). Results of the computational experience for cases with 27-, 45- and 75-scenario trees are reported in Section 5.The only goal of the model that we considered in the previous section was to maximize only the expected value of the objective function and, thus a so called risk neutral strategy was considered. The main criticism that can be made about this very popular mean strategy is that it ignores the variance in objective function value over the scenarios and, in particular, the “left” tail of the undesirable scenarios. There are, however, some other approaches that, additionally, deal with risk management in a risk-averse approach by considering, e.g., scenario immunization, see Dembo (1991), and its treatment in Escudero (1995), semi-deviations (Ogryczak & Ruszczynski, 1999), value-and-risk and conditional value-at-risk (Rockafellar & Uryasev, 2000; Schultz & Tiedemann, 2006), excess probabilities (Schultz & Tiedemann, 2003), and first- and second-order stochastic dominance constraint recourse-integer strategies (Gollmer et al., 2008; Gollmer et al., 2011) and references therein, among others. In this section we present a modification of model (20) that allows us to consider the risk aversion environment.Let us consider R(X,Ω) a risk measure such that their larger values correspond to the larger values of risk. We consider the following risk averse measures, which take into account the bad tail of the profit distribution over the scenarios:•R(X,Ω)=−VaRβ(X,Ω): Well known theoretical research suggests that the measures based on quantiles are good functions for risk management. Among them, the Value-at-Risk (VaR) has turned into a reference to many applications in the financial, transportation and productions planning sectors, among others. That approach is very attractive since it is easy to interpret. By definition, the VaRβ(X,Ω) of a solution X to the problem is the highest value, say α, such that the sum of weights of the scenarios in Ω with a profit lower than α is no greater than β (where β∈(0,1) is provided by the modeler).R(X,Ω)=−CVaRβ(X,Ω). The advantage of the VaR strategy over the traditional maxmin strategy is obvious, since it specifies a bound β on the probability of the occurrence of a scenario whose profit is below α. However, it does not consider how bad the scenarios with a profit below VaR can be. The β-Conditional Value-at-Risk (β-CVaR), defined as conditional expectation of profit below α, takes into account the profit of these undesirable scenarios. See Rockafellar and Uryasev (2000) and Schultz and Tiedemann (2006).R(X,Ω)=DPϕ(X,Ω). As an alternative to the VaR and CVaR strategies, this risk measure so called Deficit Probability (see Schultz & Tiedemann, 2003) is defined as the sum of the weights of the scenarios in Ω with an associated profit below a given threshold, say ϕ, that is provided by the modeler.Stochastic dominance constraint recourse-integer strategies (sdc): The previous risk measures can be integrated in a mean-risk model, in which the maximization of profit is combined with the minimization of risk. As an alternative to the previous strategies, let us consider the recent approaches based on the classic concept of first- and second-order sdc, see Gollmer et al. (2008) and Gollmer et al. (2011), respectively. This concept aims at identifying acceptable feasible solutions so that the strategy optimizes over them. “A random variable X is said to be stochastically greater in first order, respectively second order, than a random variable Y, i.e., X⪰1Y, respectively X⪰2Y, iff Eh(X)⩾Eh(Y) for all nondecreasing, respectively nondecreasing convex, functions h for which both expectations exist” see Gollmer et al. (2008), respectively Gollmer et al. (2011).The concepts and notation to be used in our approach are as follows:–First order stochastic dominance. The modeler gives a set of profilesP={(ϕp,βp),p=1,…,P}, where ϕpis the threshold profit to be satisfied by any scenario ω in Ω and βpis the bound of the probability of failure, such that the sum of the weights of the scenarios in ω with profit below ϕpmust be upper bounded by βp, p=1,…,P.Second order stochastic dominance. The modeler gives a set of profilesP={(ϕp,ep),p=1,…,P}, where ϕpis as above and epis the upper bound of the expected profit shortfall. The concept of the expected shortfall of the profit on reaching a given threshold may have its roots in the Integrated Chance Constraints concept introduced in Klein (1986), see also Eppen et al. (1989) and Klein and van der Vlerk (2006).Some of these risk measures, and many other approaches in the literature, try to reduce the probability of occurrence of undesirable scenarios or the maximization of the solution value for the worst scenario with a given probability of failure, but they do not pay attention to the best scenarios (except the last strategy depending on the number of profiles). On the contrary, decision makers usually look for a trade-off between the risk minimization and the profit maximization. For this reason, the risk measures are usually combined with the optimization of the expected value of the objective function (see above), leading to strategies that combine Expected Value and Deficit Probability (Schultz & Tiedemann, 2003) and Expected Value and CVaR (Schultz & Tiedemann, 2006), among others. All of the above cited risk averse strategies are presented for the two-stage setting and, to our knowledge, they have not been used in the multistage setting, and this extension is non-trivial. What follows show how these approaches are modeled in a multistage stochastic mixed 0–1 program by including some new 0–1 variables and/or constraints.The model that maximizes a combination of the expected profit and the Value at Risk can be represented as follows:(21)maxγ∑g∈Gwg(agxg+cgyg)+ραs.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈G∑g′∈Ngag′xg′+cg′yg′+Mωνω⩾α∀g∈GT,whereΩg={ω}∑ω∈Ωwωνω⩽βxg∈{0,1}nt,yg⩾0∀g∈Gνω∈{0,1}∀ω∈Ωα∈R,where α is a rational variable, νωis a 0–1 variable with value 1 if the profit for scenario ω is smaller than α and 0 otherwise, Mωis a big enough parameter (although for computational purposes, it should be as small as possible, but still allowing any feasible solution to the original problem), and γ and ρ are weighting factors, such that γ∈{0,1} and ρ>0. Remember thatNgis the set of ancestor nodes in the path back from leaf node g to root node 1. Note: The β probability of failing to satisfy a given constraint may have its roots in the concept of Chance Constraints introduced in Charnes and Cooper (1959).As stated at the beginning of Section 4, the advantage of the VaR strategy over the traditional maxmin strategy is obvious since it takes into account a bound on the probability of the occurrence of scenarios whose profit is below VaR. However, it does not consider how bad the scenarios with a profit above VaR can be. By contrast, the so-called VaR & overCVaR strategy maximizes a combination of the VaR and of the weighted Conditional expectation above VaR, and the model is as follows:(22)maxα+ρ∑g∈GTwg∑g′∈Ngag′xg′+cg′yg′-α+s.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈G∑g′∈Ngag′xg′+cg′yg′+Mωνω⩾α∀g∈GT,whereΩg={ω}∑ω∈Ωwωνω⩽βxg∈{0,1}nt,yg⩾0∀g∈Gνω∈{0,1}∀ω∈Ω.where z+=max{0,z}.The so-called Qe & CVaR strategy maximizes a combination of the expected profit and the Conditional Value-at-Risk and can be expressed as follows:(23)maxγ∑g∈Gwg(agxg+cgyg)+ρα-11-β∑g∈GTwgα-∑g′∈Ngag′xg′+cg′yg′+s.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈Gxg∈{0,1}nt,yg⩾0∀g∈Gα∈RNote: For γ=0 and ρ=1 one obtains the CVaR strategy introduced in Rockafellar and Uryasev (2000).A more amenable representation of model (23) is as follows, see Schultz and Tiedemann (2006):(24)maxγ∑g∈Gwg(agxg+cgyg)+ρα-11-β∑ω∈Ωwωvωs.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈Gα-∑g′∈Ngag′xg′+cg′yg′g⩽vω∀g∈GT,whereΩg={ω}xg∈{0,1}nt,yg⩾0∀g∈Gvω⩾0∀ω∈Ωα∈R,where vωis a non-negative variable equal to the difference (if it is positive) between α and the profit for scenario ω. Therefore, in the objective function, the weighted sum of this variables is minimized.Consider model (25), which maximizes the expected profit minus the weighted probability of occurrence of any scenario whose profit is below a given threshold, see Schultz and Tiedemann (2003). As in the VaR strategy, a new 0–1 variable per scenario, say νω, is needed but now its value is 1 if the profit for scenario ω is smaller than the give threshold ϕ, and 0 otherwise.(25)max∑g∈Gwg(agxg+cgyg)-ρ∑ω∈Ωwωνωs.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈G∑g′∈Ng(ag′xg′+cg′yg′g)+Mωνω⩾ϕ∀g∈GT,whereΩg={ω}xg∈{0,1}nt,yg⩾0∀g∈Gνω∈{0,1}∀ω∈Ω.For a given set of profilesP={(ϕp,βp),p=1,…,P}, the first-order stochastic dominance constraint strategy (called sdc-1) can be modeled as follows:(26)max∑g∈Gwg(agxg+cgyg)s.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈G∑g′∈Ngag′xg′+cg′yg′g+Mωνωp⩾ϕp∀g∈GT,whereΩg={ω},p∈P∑ω∈Ωwωνωp⩽βp∀p∈Pxg∈{0,1}nt,yg⩾0∀g∈Gνωp∈{0,1}∀ω∈Ω,p∈P,where νωpis a 0–1 variable with value 1 if the objective function value for scenario ω is smaller than threshold ϕpand 0 otherwise.For a given set of profilesP={(ϕp,ep),p=1,…,P}, the second-order stochastic dominance constraint strategy (called sdc-2) can be modeled as follows:(27)max∑g∈Gwg(agxg+cgyg)s.t.A′xσ(g)+Axg+B′yσ(g)+Byg=b∀g∈Gϕp-∑g′∈Ng(ag′xg′+cg′yg′g)⩽vωp∀g∈GT,whereΩg={ω},p∈P∑ω∈Ωwωvωp⩽ep∀p∈Pxg∈{0,1}nt,yg⩾0∀g∈Gvωp⩾0∀ω∈Ω,p∈P,where vωpis a non-negative variable equal to the difference (if it is positive) between threshold ϕpand the profit for scenario ω, the so called profit shortfall. Notice that this strategy does not require additional 0–1 variables.Solution considerations: We must point out that the models (21), (22), (26) and (27) have a computational disadvantage when compared with the models (24) and (25), since they have constraints linking 0–1 variables from different scenarios. Notice that the disadvantage is stronger for the models (26) and (27) with|P|>1than for the models (21) and (22). At any rate, a decomposition approach must be used for solving very large instances. A Lagrange relaxation can be proposed for dualizing those linking constraints as done in the strategy presented in Gollmer et al. (2011) for the second-order sdc. Moreover, see in Section 6 the outline of our future research work on this subject.Obviously, the risk averse strategies may have better results than the risk neutral one for decision makers with aversion to risk, mainly to the so called black swan scenarios. The ranking of the goodness of the strategies is only based on the modeler’s preferences but, undoubtedly, the CVaR strategies are better that the VaR one. For sophisticated users, the stochastic dominance based strategies are the ones that most protect the user from unwanted scenarios implementations in terms of the profit obtained. So, the planning problem that is the subject of our work is basically a market related problem rather than a logistic problem. However, we can observe in the results of Section 5 how much each risk averse strategy reduces the risk at the cost of reducing the expected profit (that sometimes is not very high in our testbeds).The previous models have been tested by using a realistic instance. We present two different studies. First, we compare the solution obtained by the deterministic expected value based model with the solution obtained by the stochastic one using the risk neutral strategy. In a second step, we analyze the impact of considering risk adverse measures in the model. We use three illustrative cases related to 27-, 45- and 75-scenario trees, respectively. Note that we use a discrete distribution for β-VaR and presenting the uncertainty, while VaR and CVaR were initially proposed for continuous distributions. Therefore, the weight of each scenario for small trees can be so big that only a small number of scenarios can represent risky situations and, then, the VaR and CVaR values could not be representative. Notice that changes in only one scenario can cause big changes in the value of these risk measures. For this reason, among others, a higher number of scenarios is more interesting than a smaller one.We can observe in Section 5.1 that the expected profit obtained by using the risk neutral strategy is very similar to the Expected result of the Expected Value (EEV) obtained by the deterministic model. However, given the volatility of the copper prices, the β-VaR, β-CVaR and conditional expected negative profit are much better by using the stochastic model than by using the deterministic one. Additionally, the risk reduction provided by the other strategies cannot be provided by the deterministic model.Section 5.2 computationally analyzes the deterioration of the expected profit due to the risk reduction obtained by the risk averse strategies that have been studied in Section 4.The computational experience has been carried out using the following HW/SW platform: 2 quad-core Xeon E5450 3.0gigahertz 64-bit processors with 6megabyte of cache each and 64gigabyte (8×8gigabyte) of 667megahertz fully buffered RAM memory, GAMS 23.6 (GAMS, 2011) as a modeler system and CPLEX v12.2 (IBM ILOG, 2010) as the optimizer. It uses realistic data from a real-life copper extraction instance.Table 1shows the dimensions of the deterministic model based on the expected value of the uncertain parameters and the risk neutral DEM (20). The headings are as follows: m, number of constraints; n01, number of 0–1 variables; nc, number of continuous variables; nel, number of nonzero elements in the constraint matrix; and den, matrix density (in %). The dimensions are quite large for the DEM instances.Let us start with the stochastic model (20) applied to the 27-scenario tree case depicted in Fig. 7 for the uncertainty in copper prices. This model has been solved using two different values for the termination criteria, namely, quasi-optimality gap bounds GAP=0.01% and 0.5%. Table 2shows the main statistics of the solution obtained in both cases. Notice that a slightly better solution has been obtained for the 0.01% maximum gap, but 20hours of computation were required, with a gap of 0.02% after 2000seconds of elapsed time. Given the solution’s quality and the required elapsed time, we consider it reasonable to set the maximum gap to 0.5%. Notice that this gap only refers to the profit (here, the objective function to be maximized), called the solution value in the table.Let EV (Expected Value) denote the traditional deterministic model where the uncertain parameters have been replaced by their expected values, EEV is the Expected profit of the Expected Value, obtained by applying the EV solution to the scenarios, and WS (Wait-and-See) is the average of the profits obtained by the independent models related to each scenario, which is an upper bound of the expected profit of the original stochastic model. Notice that the WS solution usually does not satisfy the relaxed non-anticipativity constraints. The methodology for obtaining the EEV is very well established for the two-stage setting, see Birge and Louveaux (2011), but it is not for the multistage one, see Escudero, Garín, and Pérez (2007). Alternatively, we propose the following methodology for obtaining the EEV in a rolling horizon type of calculation (see Agustín et al., 2012 for more details): (1) The solution for the first stage is obtained from the EV solution, (2) Once the solution up to stage t is fixed,|Gt|independent scenario subtrees remain, (3) The EV solution is independently obtained for the scenario subtrees, whose root nodes are the nodes inGt, so that the solution for each root node is fixed to its EV solution, (4) The procedure continues until stage T−1, where the mixed 0–1 two-stage problems for each related node are solved. So, at the end of the process there is a solution for each scenario and EEV is obtained by weighting the solution values for the scenarios as calculated by the procedure. Table 3shows the main results related to the WS and EEV solutions. We can observe that the EEV solution value (in our case, the expected profit) is only 0.6% smaller than that provided by the risk neutral model (20). However, it has worse VaR, CVaR and conditional expected negative profit than most of the alternative approaches presented above, even than the risk neutral maximization of the expected profit over the scenarios along the time horizon. Additionally, the expected profit deterioration by using risk averse strategies may not be so high (depending on the risk targets) but the risk reduction can be very strong.In this section the results for the 27-scenario tree instance are reported by solving the different risk averse models presented in Section 4. A computational comparison with the risk neutral model (20) is presented in order to analyze the impact of these measures on the solution. Tables 4,5present the results of the VaR and CVaR models (21) and (24), respectively, for γ=1 and ρ⩾0. The headings are as follows: ZLP, solution value of the LP relaxation; ZMIP, solution value of the incumbent solution; GAP, related optimality gap (remember that the bound for the optimality GAP has been set to 0.5%); β, upper bound on the probability of default, given by the user for the scenario to occur; VaR is the 0.10-VaR; CVaR is the 0.10-CVaR; %QE, normalized weighted expected profit over all scenarios, where 100 is the expected profit for the risk neutral model (20); P(<0), sum of the weights of the scenarios with a negative profit; E(<0), conditional expectation of the scenarios with a negative profit; t, elapsed time (in secs.) for obtaining the incumbent solution.We can observe in Tables 4,5 that the weight parameter ρ>1 provides good VaR and CVaR values in both models. However, it does no provide good expected profit, since there is a 12% reduction (approx.) with respect to the risk neutral model (20) for ρ=5 and β=0.05, and an even larger reduction for very large ρ values. Notice that the VaR based model (21) requires much more elapsed time that the CVaR model (24) (on average, 1hour and 3-4minutes, respectively).Table 6presents the results of the VaR+Over-CVaR model (22). The headings are the same as in Tables 4,5. We can observe that, in general, this strategy provides good results, but it requires much more elapsed time than the strategy VaR in some cases and the strategy CVaR in all cases.Table 7presents the results of the Qe& DP model (25). The additional headings are as follows: ϕ, threshold profit; and P(<ϕ), sum of the weights of the scenarios with profit below the threshold. The results in the table clearly show a risk reduction when compared with the risk neutral model (20) for big ρ values. The larger the threshold, the worse the solution value is in terms of the CVaR and the probability of having a scenario with negative profit. Therefore, the best combination for this situation seems to be a small threshold (say, ϕ=30) and a large parameter ρ (say, 400); however, notice that in the end the combination is chosen by the user to satisfy his own requirements. This combination provides solutions very similar to the ones provided by the CVaR model (24), see Table 5. However, the former requires more than 5000seconds and the latter only requires 200seconds (approx.) of elapsed time.Finally, Tables 8,9present the results of the Stochastic Dominance Constraint models (26) and (27), respectively. We have not reported results for big setsPof profiles due to the excessively elapsed time required by the MIP solver. However, we have experimented with|P|=2and|P|=1profiles for the sdc-1 and sdc-2 strategies, respectively. We can observe that, in general, the results are very good but, in some cases, the elapsed time is very high. Although more computational experience would be needed, it seems that these strategies are worth considering in the future by using more profiles, provided that a quick exact decomposition algorithm is used instead of a MIP solver, see Section 6.For a better comparison of different solutions proposed by the risk averse approaches, Fig. 8depicts the 0.10-CVaR value (in abscissas) and the Expected Value (in ordinates) presented in Tables 4,5 for the 27-scenario tree case. We can observe how the strategies perform a trade-off between maximizing the profit (expected value) and minimize the risk (-CVaR). Fig. 8(a)–(c) represent the results for β equal to 0.10 and 0.05, and the different values of ρ in Tables 4,5, respectively. Fig. 8(d) represents the results for ϕ equal to 30 and 90 and the different values of ρ in Table 7. Fig. 8(e) represents the results for the different profiles in Table 8, where ϕ1 varies from −10 to 30, β1=0.05, ϕ2=40 and β2=0.10. Finally, Fig. 8(f) represents the results for the different profiles in Table 9, where ϕ varies from 0 to 60 and e1 is equal to 1 and 2. We can observe that the strategies Qe & CVaR and sdc-2 provide the best results in our testbed. These figures for cases (a) to (d) represent the Pareto frontier of the bi-objective problem that consists of maximizing the net profit and minimizing the risk. The asterisk represents the value for the risk-neutral approach. It can be observed that a great reduction in risk can be obtained with some reduction in net profit by adequately weighting the parameters of the risk averse measures.Given the large elapsed time reported in Tables 4,5 for the 27-scenario tree case, we only experimented for the 45- and 75-scenario tree cases with the following strategies:•risk neutral model (20),Qe & VaR model (21) with γ=ρ=1 and β=0.10,Qe & CVaR model (24) with γ=1, ρ∈{0.5,0.75} and β=0.10,Qe & DP model (25), with ρ=400 and ϕ=30,sdc-2 model (27) with ϕ1=30 and e1=2,whose main results are shown in Tables 10,11, respectively. Similarly to the smaller instances with 27 scenarios, we can observe that the tested risk averse strategies provide better solutions than the risk neutral approach, in the sense that, with a moderate reduction in the expected profit (from 2.03% to 7.65%), the different risk measures give an interesting risk reduction as measured by the non-negative 0.10-VaR and 0.10-CVaR values. In any case, observe in Table 1 the very large dimensions of the risk neutral model (20).It is worth pointing out that the risk averse strategies that have been experimented with in this work offer much better results in the VaR, CVaR and conditional expected negative profit than the risk neutral strategy, without, on the other hand, reducing too much the expected profit.

@&#CONCLUSIONS@&#
In this work we have presented the stochastic version of the copper extraction planning problem along a time horizon (i.e., years) under uncertainty in the (volatile) copper prices. The problem is a very large-scale Deterministic Equivalent Model (DEM) with 0–1 and continuous variables, even for a reduced version of the original one, since it must represent the uncertainty in the volatile copper prices by a multistage scenario tree. We have presented the DEM to the stochastic problem in a compact representation. The first conclusion that can be drawn from this work is that even the risk neutral approach, see model (20), provides a better solution than the traditional (and myopic) deterministic solution by considering the expected value of the uncertain parameters. The expected profit EEV obtained by using the deterministic model does not differ too much from the expected profit obtained by using the risk neutral strategy, but the VaR, CVaR and conditional expected negative profit are much worse and, then, the advantage of the stochastic model over the deterministic one is clear. Additionally, by using the appropriate parameters provided by the modeler for the risk averse measures, a high risk reduction can be achieved without too high expected profit deterioration.A second result from the 27-, 45- and 75-scenario tree cases that we have experimented with is that the risk adverse Expected value & CVaR strategy, see model (24), and the second-order stochastic dominance constraints (sdc) strategy, see model (27), seem to provide better results in the solution’s quality (since they reduce the risk of bad scenarios without reducing too much the expected profit) and they require less elapsed time than any other ones. In any case, these results have to be validated by an extensive computational experiment with larger cases. Notice that we did not fully experiment with bigger profiles in the sdc strategies, nor with the Conditional expectation above CVaR strategy (22) and the others, due to the excessive computer requirements (i.e., memory and elapsed time) of the MIP engine for solving the very large scale instances of the real-life copper extraction problem under uncertainty in copper prices.The third definitive conclusion that can be drawn from the analysis of the three scenario tree illustrative cases is that solving the DEM by using a state-of-the-art optimization engine may require, even in compact representation, so much computing effort for large-scale instances that a decomposition algorithm is required. This scheme would allow the use of scenario bundles based on a so-called break stage, see (Escudero et al., 2012). We need to develop a decomposition approach for solving large scale real-life instances, where smaller MIP submodels can be solved in parallel. For that purpose we can represent the DEM by a mixture of the splitting variable and the compact representations. The first representation will allow (based on the break stage) to decompose the model by scenario bundles. A Branch-and-Fix Coordination (BFC) (Alonso-Ayuso et al., 2003) type of scheme can be used for handling the splitting variable representation to obtain the solution value of the original stochastic MIP problem, where the compact representation of the independent submodels related to the scenario bundles for the stages after the break stage will be optimized by using a MIP solver; see (Escudero et al., 2012). As an alternative to the BFC approach, the splitting variable representation will allow to use a Lagrangean Decomposition approach to obtain strong lower bounds on the solution value of the original stochastic problem, by dualizing the nonanticipativity constraints related to all stages up to the break stage; several schemes for updating the Lagrangean multipliers will be computationally analyzed and feasible solutions from the Lagrangean dual solution can be obtained. At any rate, the strategies Value-at-Risk (21), Conditional expectation above VaR (22) and stochastic dominance constraints (26) and (27) require cross scenario constraints. Although those constraints are very few, their dualization via Lagrangean Relaxation is an additional challenge for the decomposition approaches.As a last, but no least piece of future research, we are planning to consider in the decomposition algorithms a combination of exogenous uncertainty (the one that has been tackled in the paper) and the endogenous one where the values of some of the decision variables can modify the weights of the scenarios of the subtree whose root node is the one (in the given stage) where the decision is made. In the mining problem it could be the case when multiple sectors are replaced with clusters. This interesting feature is not considered in the model presented in the paper (since it is a market model rather a logistic model). In any case, it would be a more difficult model with a greater number of constraints and variables but we hope that it can be handled by the decomposition methods to be developed.