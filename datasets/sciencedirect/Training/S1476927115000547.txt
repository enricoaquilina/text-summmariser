@&#MAIN-TITLE@&#
On the impact of discreteness and abstractions on modelling noise in gene regulatory networks

@&#HIGHLIGHTS@&#
In living cells gene expression is thoroughly regulated.Computational models help in understanding the mechanisms underlying gene regulation.Hybrid approaches balance model accuracy and computational efficiency.We identify the key sources of stochastic noise in a simple gene expression pathway.We propose a wise method for building hybrid models without ignoring key parameters.

@&#KEYPHRASES@&#
Gene regulatory networks,Discrete modelling,Hybrid system,Quasi-steady state approximation,Stochastic noise,

@&#ABSTRACT@&#
In this paper, we explore the impact of different forms of model abstraction and the role of discreteness on the dynamical behaviour of a simple model of gene regulation where a transcriptional repressor negatively regulates its own expression. We first investigate the relation between a minimal set of parameters and the system dynamics in a purely discrete stochastic framework, with the twofold purpose of providing an intuitive explanation of the different behavioural patterns exhibited and of identifying the main sources of noise. Then, we explore the effect of combining hybrid approaches and quasi-steady state approximations on model behaviour (and simulation time), to understand to what extent dynamics and quantitative features such as noise intensity can be preserved.

@&#INTRODUCTION@&#
Regulating gene expression is a complex work of orchestration, where the instruments play with improvised variations without a fixed music sheet. Under this regard, the regulation process, in which DNA drives the synthesis of cell products such as RNA, and proteins, can be thought of as a stochastic process. The amount of RNA and proteins in living cells must be thoroughly tuned, both to manage effectively housekeeping functions and to respond promptly to upcoming needs (e.g. to adapt to environmental changes). To this end, gene expression is equipped with several control mechanisms and strategies that grant both reliability and flexibility in terms of throughput. Nevertheless, when observed at the single cell level, the amount of molecules involved in gene expression and its regulation fluctuates randomly (Raj and van Oudenaarden, 2009). This stochastic effect at the molecular level turns out to play important roles in conditioning cell-scale phenomena, e.g. cellular fate decision making, incomplete penetrance or enhanced fitness through phenotypes variability (Raj and van Oudenaarden, 2009).Pioneering works (Novic and Weiner, 1957; Ross et al., 1994) showed that gene expression in populations of genotypically identical cells (i.e. with the same genetic constitution) is highly variable even when epigenetic conditions (i.e. the ones that result from external rather than genetic influence) are kept constant. In Elowitz et al. (2002), the authors identified such a population variability and decomposed the extrinsic and intrinsic contributions therein. Also, in Murphy et al. (2010), it is shown that this variability it is controllable.Recent developments in experimental techniques (see Raj and van Oudenaarden (2009) for a review) have made it possible to detect and count individual molecules and, therefore, to measure the amount of mRNA and proteins in single cells. These measurements have clearly shown that the number of mRNA and proteins can vary significantly from cell to cell. This variability is caused by the fundamentally stochastic nature of the biochemical events involved in gene expression (Raj and van Oudenaarden, 2009) and is studied, e.g., in Mantzaris (2007), Stamatakis and Zygourakis (2010), Stamatakis and Zygourakis (2011), where population-level mathematical frameworks are introduced and applied.As a consequence, the phenotypical variability (i.e. the variability resulting from the interaction of the genotype with the environment) exhibited by populations of identical organisms can be directly caused by stochasticity at the single cell level. Thus, it is becoming clear that noise and stochasticity underlie critical events in cell's life such as differentiation and decision making (Balázsi et al., 2011). Moreover, some authors suggest that random phenotypic switching can represent an efficient mechanism for adapting to fluctuating environments (see, e.g., Balázsi et al., 2011; Raj et al., 2010). These findings have raised new interest in analysing the role of noise in gene expression.The regulation process includes multiple steps leading from gene transcription to the translation of the resulting mRNA to obtain the encoded protein. Each step represents a possible control point, where several biochemical mechanisms play a role (see Alberts et al. (2002) for a comprehensive review and Lillacci and Khammash (2010) for an application to model selection). Characterising the contributions of each single control point in the regulation process of gene expression is a complex task. Identifying which strategies come into play in generating or dampening noisy behaviours is even more challenging. The extensively studied regulation paradigm represented by the feedback control strategy can be used to explain the mechanisms controlling gene transcription and translation. In such mechanisms, the global intensity of the feedback depends on parameters related to every single control point. Computational methods can significantly help investigating the synergistic mechanisms underlying the regulation of gene expression.There are several modelling strategies that can lead to different kinds of computational models, depending on both the particular purposes and on the features of the available data. Models of biological systems proposed in the literature can vary in terms of the abstraction level used to represent molecular amounts (in this regard a model can be either discrete or continuous) and in terms of the underlying paradigm used for describing the temporal evolution of the system, which can be either deterministic or stochastic.Ordinary Differential Equations (ODEs) have been extensively used over the years to describe the behaviour of biological processes. They provide modellers with powerful and well assessed analysis and simulation techniques. Nevertheless, ODE models implicitly assume continuous and deterministic change of concentrations, abstracting away noise and randomness due to stochastic fluctuations. This, for example, makes it difficult to capture qualitatively different outcomes arising from identical initial conditions (e.g., Raj and van Oudenaarden, 2008; Hume, 2000; Ross et al., 1994).One way to represent noise is to couple a Gaussian noise term to the model equations, obtaining a set of Stochastic Differential Equations (SDEs). This approach succeeded in gaining insights on the stochasticity of gene expression underlying circadian clocks (Chabot et al., 2007) and genetic switches (Becksei et al., 2001). However, continuous methods still fail to properly describe various phenomena arising from stochastic fluctuations in systems involving small copy numbers of molecules (Resat et al., 2009), as in the case of bimodal mRNA distributions generated by long transcriptional bursts, during which mRNA level approaches a new steady state (Raj and van Oudenaarden, 2009).The copy numbers of molecules and individual entities in the cell space are discrete and the reactions in which they are involved are stochastic events. Consequently, approaches based on a discrete and stochastic formulation, such as the ones built upon Continuous-Time Markov Chains (CTMCs) (McQuarrie, 1967; Bartholomay, 1958), have been successfully introduced to overcome the modelling limitations of continuous methods. Stochastic systems are formally represented through a chemical master equation and have also been studied, rather directly, in the form of autocatalytic reactions systems, with approaches such as the one described in Dauxois et al. (2009).However, since the analytic solution of the underlying equation is often infeasible for real size systems, these models are usually studied resorting to simulation approaches, mostly based on (variants of) Gillespie's stochastic simulation algorithm (Gillespie, 1977). Unfortunately, in some cases, even numerical simulation can be computationally very expensive. A compromise between accuracy and efficiency can be obtained by combining discrete and continuous evolution in so-called hybrid approaches (Pahle, 2009; Bortolussi and Policriti, 2009, 2013). In this context, we recall also (Salis and Kaznessis, 2005; Salis et al., 2006), where hybrid approaches for stochastic simulation of gene networks have been developed.In this work, we consider a simple model of gene regulation in a transcription/translation genetic network, where a transcriptional repressor negatively regulates its own expression. This model has been widely studied (e.g. Marquez Lago and Stelling, 2010; Stekel and Jenkins, 2008), because it is a minimal system that explicitly describes the processes of transcription and translation and because it is a basic component of many complex biological systems. Despite its apparent simplicity, understanding its behaviour is not easy, because this is governed in a non-trivial way by several quantitative parameters. Actually, different parameter combinations lead to a range of qualitatively different dynamics. In particular, in Marquez Lago and Stelling (2010), the intensity of noise in this system is analysed in terms of various parameters, with special emphasis on the strength of the negative feedback. That paper demonstrates how the application of engineering principles to the role of feedbacks in a biological context could be misleading. The authors show, indeed, that noise generally increases with feedback strength, in contrast to the common knowledge. They also relate the possible different dynamical regimes with the different regions of the parameter space. The overall behaviour emerges from the complex interaction between feedback strength and other parameters of the system, governing the dynamics of the protein and of the mRNA.Starting from the analysis proposed in Marquez Lago and Stelling (2010), we investigate the model with two goals in mind: (i) identifying the parameters that play a key role in the regulation process, by systematically studying the impact of parameters variations on the global dynamics of the system. In this way, we establish a link between the parameter space and the observed temporal patterns, i.e. the diverse behavioural phenotypes; (ii) quantifying the impact of each reaction of the modelled system on the overall dynamics and on noise patterns. This allows us to identify those reactions that, having a minor influence on the global noise pattern, can be safely approximated in a deterministic fashion.At a higher level and on a longer term, we aim at setting up a systematic strategy for correctly building hybrid models of biochemical systems. In such models, only the most relevant sources of noise will be represented via a fully detailed stochastic description.The handy dimension of our model of gene regulation allows us to play with different models and techniques. On the one hand, we study a stochastic model of the negative feedback loop to construct an exact picture of its possible behavioural patterns and of the effects of noise. This precision comes with a high computational cost, especially for certain parameter sets. On the other hand, we systematically apply various forms of model abstraction, in order to mitigate the inefficiency of exact stochastic simulation methods. In particular, we abstract the discrete stochastic dynamics into continuous deterministic dynamics for some of the model components, thus obtaining a stochastic hybrid model. Afterwards, we simplify the model structure reducing the number of model components and reactions, by applying quasi-steady state approximations (QSSAs).These abstractions are not blindly applied, but are rather considered only in the regions of the parameter space for which the hypotheses underlying these techniques are (reasonably) satisfied.We believe that the methodology we adopt is a reliable approach for modelling in systems biology, where too often in silico techniques based on abstractions or approximations are used off-the-shelf, without any concern on their applicability and faithfulness.The model we consider, described among others in Marquez Lago and Stelling (2010), Stekel and Jenkins (2008), is a genetic network composed by the reactions reported in Table 1and schematically represented in Fig. 1(a).The model is a minimal system that describes the self-regulated transcription/translation of a gene into a protein. The gene (G) is transcribed into an mRNA molecule (M), which in turn is translated into a protein P. P regulates its own expression by means of a negative feedback loop: P can bind to G, making it switch from its free active state to an inactive state (Gb). Finally, both M and P can be degraded. All reactions are assumed to follow mass action kinetics, i.e. the speed of the reaction is proportional to the product of the amounts of each reactant and a kinetic constant. In the following, the amounts of P, M, G, and Gb are denoted by XP, XM, XG, and XGb, respectively.Similarly to Marquez Lago and Stelling (2010), we ignore copy-number variations (CNVs) and assume to have a single copy of the gene. The reason for this assumption is that CNVs may rise from different structural rearrangements (e.g. deletions, duplications, inversions) and can involve different genomic regions (e.g. enhancer, promoter, coding), hence having potentially different and sometimes unpredictable effects on the expression of the surrounding/overlapping genes. These effects may be difficult to model and may introduce a level of variability that goes beyond the aim of this work.In Marquez Lago and Stelling (2010), a very detailed phenomenological description of the different behaviours of the model has been carried out, changing parameters in order to explore a large portion of the parameters’ space. The authors claim that this simple feedback network has a counter-intuitive behaviour: while, in engineering, negative feedbacks are assumed to be a mechanism to decrease noise, the authors show that in this network, instead, noise increases with feedback strength.Following on from those results, in this section we provide a simpler picture of the possible behavioural patterns of the model; we found out, in fact, that the seemingly counter-intuitive behaviour can be explained by analysing a combination of a minimal set of parameters.First of all, with a preliminary high level analysis of the stochastic dynamics of M, P, gene repression, and of the interactions between dynamical regimes involved in the model (partly reported in the Supplementary Material, Appendix A), we identified the following two key parameters:(1)P binding/unbinding ratio α=bindP/unbindP;P/M degradation ratio β=degP/degM.The first parameter α was used in Marquez Lago and Stelling (2010) as an indicator of the strength of the feedback regulation: the higher the value of α, the stronger the repression and the smaller the number of mRNA molecules on average. While in Marquez Lago and Stelling (2010) the authors fix the binding rate and vary the unbinding rate (thus increasing feedback strength by increasing the binding strength), in our work we fix the unbinding rate and vary the binding rate (thus increasing feedback strength by increasing the binding affinity), hence using a different mechanism to represent repression intensity. This choice has an impact on the dynamics of the network, in particular on the behaviour of the bursty protein regime and on the feasibility of the QSSA (see also Section 3.3 and Appendix A in the Supplementary Material).The second parameter β is the ratio between the half-life of M and the half-life of P. From a dynamical point of view, it describes the speed at which production and degradation of the protein reach equilibrium, relative to the mRNA. Essentially, it captures how the protein level reacts to fluctuations at the mRNA level: the higher the value of β, the faster P's response. This means that XMand XPwill be highly correlated for high β, and so noise at the level of XMlevel will propagate more effectively to XP.The values of the stochastic rate constants we use are based on those from Marquez Lago and Stelling (2010) and their units are s−1. After a prescreening in which we used several values according to Marquez Lago and Stelling (2010) for stochastic simulations, we identified the values that proved to be representative in reproducing the complete gamut of all the interesting observable phenotypes. Therefore, in this work we choose to vary α in the set {0.0166, 16.6, 16600}, and β in the set {0.01, 1, 100}. In the following, we refer to these three values for α and β as low (L), medium (M), and high (H), and we refer to the combinations of parameters with the names listed in Table 2.The parameter α is varied by fixing the value for unbindPto 1 and modifying bindP, defined as α·unbindP. Similarly, we fixed the value for degMto 0.001 and vary degP=β·degMwhile varying β. Moreover, we define P production rate as the product of P degradation rate and the steady state value for P per M molecules, i.e. prodP=degP·Psteadywith Psteadyequal to 3500. We have chosen this value because it allows us to obtain biologically meaningful numbers of proteins for all the parameter combinations. However, reasonably changing this parameter does not disrupt the observed behaviours. This enables us to explore parameter combinations with a low degradation rate, ensuring that translation rate does not become too large considering a maximum rate constant of 108–1010M−1s−1 (Zhou and Zhong, 1982) (see Appendix B in the Supplementary Material for further details). We finally fix prodMto 35 considering an average RNA polymerase transcription rate of 24–79 nucleotides/s and 1100 base pairs as the average size of an mRNA molecule (Vogel and Jensen, 1994), i.e. an mRNA molecule is produced (on average) in 14–46s.We proceed now by building a fully stochastic model from our set of reactions, in order to undertake a thorough stochastic analysis of its dynamics. The simulation tool we use is COPASI (Hoops et al., 2006), a framework that provides us with all the algorithms needed to run stochastic, hybrid, and deterministic simulations.In order to outline the possible dynamics, we partition our parameter space into different regions, by creating nine different versions of our model, one for each parameter combination. For each model we then set the initial amounts of M and P to the corresponding steady state values and run 1000 stochastic simulations with limit time 10,000s.11We empirically identified 10,000s as a limit time that is long enough to allow us to observe the specific steady state dynamics of P and M in all the parameters combinations we considered. Moreover, we are taking the population average at the chosen time 10,000, and not the time average along a single trajectory, as commonly done. However, in our context, these two approaches are equivalent as all the models we consider are ergodic. This is obvious for the Continuous-Time Markov Chain (CTMC) models, but it can be shown also for the hybrid models, by applying a result in (Costa and Dufour, 2008), characterising ergodicity in terms of a Discrete-Time Markov Chain (DTMC) obtained by sampling trajectories of the Piecewise Deterministic Markov Process (PDMP) at random times.As listed in Table 2, for combinations having low α, the initial XPand XMare 86, 000 and 25, respectively. For combinations having medium α, the initial XPand XMare 2700 and 1, respectively. Finally, for combinations having high α, the initial XPand XMare 86 and 0, respectively.Fig. 2shows, for each of the nine versions of the model, one representative simulated trajectory of XPtogether with its coefficient of variation (CV) and the correlation between XPand XMat time t=10, 000. A comprehensive summary of population statistics of XPand XMis reported in Table 3(top panel), and further details are in the Supplementary Material.With L-L combination we have that, since repression is weak, the average XMvalue is relatively high and, consequently, XPsteady state is also high. Moreover, since P degradation is slower than M degradation, XPdynamics are slower than XM's, i.e. XPfluctuates with a lower frequency than XMdoes; moreover, at steady state XPbehaves like a simple birth-death process with very low noise. We can say that XPis very close to its deterministic average behaviour. It is not surprising that this is also the combination with the lowest XP−XMcorrelation and coefficient of variation for XP. In case of M-L combination P dynamics are still slower than M's but repression is stronger than before, causing XMand XPsteady state values to be much lower. In particular, XMstarts to take very low values with fluctuations between 0 and 4 (see Fig. S1 for instances of XMsimulated trajectories). This combination of discreteness and possible absence of M is immediately reflected in P dynamics. Indeed, such dynamics are still very close to a simple birth-death process but, as indicated also by the increment of the coefficients of variation for XMand XP, with higher noise. Combination H-L generates a strong gene repression that causes XMto fluctuate between 0 and 1. Moreover, since P degradation is very low, the effect of repression is even amplified by the almost constant presence of P, hence XMis 0 most of the time. As a consequence, XPtends to slowly degrade but displays some small “steps” corresponding to those rare and short intervals in which XMtakes value 1.By increasing β to a medium value, we have that XMand XPstart to show a correlation higher than 0.5. In this parameter regions, each change in XMis followed by a change in XP, that is quantitatively equivalent (when scaled on XM). With L-M combination XMfluctuates at steady state around a value of 25, but in this case the coefficient of variation is higher, meaning that its dynamics are noisier. Since the number of P molecules varies in accordance with the number of M ones, we have that the noise in XMis reflected and amplified at the level of XP, generating a behaviour that is noisier than in L-L. With M-M combination we can observe that XPstarts to present an irregular fluctuating-like behaviour till reaching, with combination H-M, a behaviour that exhibits bursts. This is evidently caused by the high degree of discreteness in XM(i.e. XMtakes very small values). In particular, bursts are emerging because P degradation is fast enough to increase the frequency of the intervals in which XMis equal to 1 and to allow XPto rapidly reach a low amount when XMis back to 0. Note that the system alternates periods in which P is degraded to periods in which M is produced in few copies, and so XPincreases.When β is high, P fluctuates with a higher frequency than M, hence it reaches stochastic equilibrium faster than M. This causes, for all three values of α, the correlation between XPand XMto be very high (greater than 0.98). With combination L-HXPfluctuates around the mean value with high level of noise. This increase in noise in all combinations having low α can be visually observed also in the XPdistributions in Fig. S2. With the intermediate combination M-H, the time course of P copy number starts to exhibit a multi-modal behaviour. This can be explained by observing that XMfluctuates between 0 and 3 and considering that, for a high value of β, XPis able to reach its steady state between successive changes in XMlevel. Hence, P dynamics look like M's with discrete levels properly rescaled. From Fig. S2 it is easy to see that we have three main discrete levels of XPsituated around 0, 3500, 7000 and 10, 500. By further increasing the repression with H-H combination, we end up with a bimodal behaviour. This is clearly the consequence of the fact that, for high values of α, XMfluctuates only between 0 and 1, a behaviour that is shown by XP, which mainly alternates between two discrete levels. From Fig. S2 we can observe that these two levels are 0 and 3500.Our exploration of the parameter space is clearly model-specific and cannot be directly generalised to other models of gene regulatory networks; however, from a methodological point of view, our results clearly illustrate that this kind of thorough exploration is essential when studying genetic networks, in order to understand the role of feedback loops in generating different patterns of time courses of both mRNA and translated proteins. In particular, we showed that certain parameter combinations are responsible for bursty temporal patterns. While there is strong experimental evidence supporting transcriptional bursts both in prokaryotes (Golding et al., 2005) and (especially) in eukaryotes (Raj et al., 2006), the underlying biological mechanism still remains unclear. Even though many complex mechanisms, involving the biochemical machinery of DNA transcription, seem to contribute to pulsatile transcription (as suggested in Golding et al. (2005)), our study supports the fact that gene regulation mechanisms themselves (and the relative speed of the different reactions involved) play an important role in determining this pattern of transcription.Our case study also shows the importance of modelling without abstracting away any part of the feedback loop in order to reproduce the full spectrum of possible behaviours. Indeed, in a study similar to ours, Peccoud and Ycart (1995) specified a Markovian model of gene regulation considering four parameters: λ and γ, the rates of gene switching from active to inactive state and vice versa, and μ and σ, the rates of mRNA transcription and degradation, respectively; while their model can describe both fluctuating and bursty temporal patterns, it does not account for bimodality in mRNA distribution. This suggests that abstracting away details even in a simple biological model can result in a loss of expressiveness. We will address this issue in Section 3.Another result of our analysis which is worth considering in more detail is the trend of XP– XMcorrelation. Evaluating this parameter in individual living cells is not an easy task, due to technical problems in detecting single molecules of mRNA and proteins in the same cell, at the same time (Raj and van Oudenaarden, 2009). Nevertheless this correlation analysis can give us useful insights into the process of gene expression, as it allows us to study the propagation of fluctuations in mRNA levels to the amount of produced proteins. Among the few experimental results currently available, it is worthwhile recalling those obtained by Raj et al. (2006), which show that mRNA and protein levels are strongly correlated when protein lifetime is short, but that this correlation decreases when protein lifetime is long. These results are consistent with the predictions of our model, where the highest values for XP– XMcorrelation are obtained when β is high.In the previous section, we considered the explicit stochastic model of the simple negative feedback loop. Modelling each part of the loop following Gillespie's computational approach, we obtain an exact stochastic model (under the assumption that molecules are well stirred), whose analysis gives us a precise picture of the patterns of dynamical behaviour and of the effects of noise. However, even for this simple genetic network, the computational analysis can be difficult to carry out because exact simulation algorithms can be very inefficient under certain parameter configurations. This happens, for instance, for low α and high β, where P's dynamics are much faster than M's, and the number of P molecules ranges close to 100, 000; in this situation, the number of firing P production and degradation events is so large that explicit simulations are severely slowed down. When exact simulation is not feasible, one can either use approximate simulation algorithms, such as τ-leaping (Gillespie and Petzold, 2006), or adopt some form of model abstraction (see, e.g., Rathinam et al., 2003; Gibson and Bruck, 2000; Ramaswamy and Sbalzarini, 2010).Here we discuss methods in the latter category, focusing both on techniques that abstract the dynamics, from discrete stochastic to continuous deterministic, and on techniques, like quasi-steady state approximation (Rao and Arkin, 2003), that simplify the model structure reducing the number of reactions and components. In particular, we consider three abstraction approaches: (i) an approximation of the stochastic discrete dynamics with continuous deterministic ones, applied to all model components, thus obtaining a model defined by a set of ordinary differential equations (ODEs), (ii) a replacement of the stochastic discrete dynamics with continuous deterministic ones, localised to some of the components of the model, thus obtaining a stochastic hybrid model, and (iii) an approximation obtained by the removal of specific model reactions performed by the computation of quasi-steady state values.Establishing the quality of an abstraction a priori is a difficult issue, as there are no simply derivable analytic formulae to invoke. We will however discuss and use heuristic arguments, to justify the use of abstractions in certain regions of the parameter space, justifying them by a though a posteriori statistical evaluation.The most common approach for dynamics abstraction is to replace the stochastic model with a fully deterministic one based on ODEs. It is known that this type of approximation is exact in the thermodynamic limit (Gillespie, 2000) and it usually works well, provided that the number of molecules in the system is sufficiently large, while it fails if noise plays a relevant role in the system dynamics. Evaluating the system of ODEs associated with our model, we can easily verify that the molecule numbers for the different species converge to stable steady states for all parameter configurations considered. This behaviour is different from the one observed by performing stochastic simulations, in which not all the parameter configurations yield patterns that converge to a steady state (see Fig. 2). A configuration of parameters where the deterministic approximation of the whole system turns out to be appropriate (with respect to the behaviour of P) corresponds to low α and β (low repression and slow P). In this case, in fact, the amount of M ranges around 25 and P's slow dynamics have the effect of averaging the noise at the level of M, so that noise at the level of P is extremely low. This also holds for G's dynamics. In general, for small β the approximation is reasonable, although less accurate as feedback strength increases, corresponding to a decrease in the number of M molecules (see Fig. 2).From the discussion above, it follows that the inherent discreteness of M and G evolution, especially in the high repression regime, plays a central role in determining the qualitative pattern of dynamical evolution. Then, noise at the level of M propagates more or less rapidly to P's dynamics. The intrinsic noise of P's dynamics, instead, should be less relevant in this respect if the steady state of XPis sufficiently high. Therefore, a reasonable abstraction of this model would see P as a continuous quantity evolving according to an ODE, while maintaining discrete dynamics of M and gene repression.Mathematically, this gives rise to a stochastic hybrid model, belonging to the class of Piecewise Deterministic Markov Processes (PDMPs) (Davis, 1993). These processes are described by a set of continuous variables and a set of discrete variables. Continuous variables are subject to continuous evolution, while discrete changes happen spontaneously at times determined by exponential distributions, as in CTMCs. In particular, as rates of discrete jumps can depend on the value of continuous variables, the discrete process is non-homogeneous in time. PDMPs can be analysed by simulation or even by numerical solution of their master equation, which is a partial differential equation, although the latter approach is computationally rather demanding (Trivedi and Kulkarni, 1993). Hybrid simulation algorithms for biochemical systems based on PDMPs (Pahle, 2009; Crudu et al., 2009) usually implement some heuristic rule for partitioning species into discrete and continuous ones, in general according to their copy numbers in order to minimise errors caused by the continuous approximation. The partitioning rule can be either static or dynamic. Static partitioning is performed before simulation, after a screening of the current parameter set. Dynamic partitioning, instead, is performed during simulation: molecules that at a certain time fall below a specific threshold are treated discretely and stochastically.We applied dynamic partitioning to our system,22We do not consider further static partitioning, as it turned out to be not very accurate for high feedback values (data not shown). In this case, in fact, P trajectories often approach zero, and treating P as always continuous can introduce significant errors. In particular, in such an extreme, feedback strength is increased, as now P exerts a repression also when its value lies between 0 and 1.setting the continuous-to-discrete switching threshold to 10 (hence, when the number of molecules falls below 10 we switch to a fully stochastic system) and the discrete-to-continuous switching threshold to 20. The use of separate thresholds helps to avoid too many switches due to noise effects. These two thresholds have been heuristically selected to avoid unnecessary switching between discrete and stochastic models.We expect this hybrid scheme to work well in most cases, with a possible loss of precision for high feedback repression (which reduces the overall number of P molecules).In Table 3 and Fig. 3we compare the behaviour of the hybrid model with dynamic partitioning to the behaviour of the fully stochastic model. We can see that the hybrid simulation works very well, and essentially all behaviours of the fully stochastic model are qualitatively captured. In Fig. 3 we report the most interesting combinations. At the quantitative level, the hybrid model seems to be also able to capture quite accurately the first two moments of the distribution as well as the correlation between XMand XP(Table 3), with some loss of precision for M and large values of α. This supports our initial conjecture that the inherent discrete and stochastic dynamics of G and M are what mainly determine noise modes of protein expression. Intrinsic fluctuations of the protein due to stochastic production and degradation are less relevant in this respect, hence can be safely abstracted away.In terms of simulation time, the hybrid model outperforms the stochastic simulation in those parameter regions in which P's dynamics are the bottleneck for stochastic simulation (Table S6), as expected (Crudu et al., 2009). In fact, since we are approximating only P's dynamics as continuous, our hybrid abstraction will improve stochastic simulation only when the number of P production and degradation events dominates the simulation cost. In all other cases, the overhead introduced by hybrid simulation33In hybrid simulation, the ODE integration engine needs to be coupled with an event detection mechanism (Burden and Faires, 2005) that requires to find the roots of non-linear equations to identify the firing time of stochastic events (Pahle, 2009). This is because the stochastic part of the process in the hybrid system is time inhomogeneous, with rates that depend on the continuous variables. Approximate hybrid strategies can avoid this overhead (Pahle, 2009; Hoops et al., 2006), at the price of reducing the integration step of ODE solvers in order to avoid significant loss in accuracy.can overcome the gain in computational efficiency. In our system, for instance, the hybrid approach is faster for high β. Indeed, for low α and high β, we obtain a 277-fold speed-up, while the performance is less appealing for larger feedback strength, as the P number is reduced, hence so is the translation frequency and P degradation reactions in the stochastic model. However, notice that the execution time of the hybrid model is essentially constant for all parameter sets, allowing us to study the behaviour of the system for parameter combinations in which stochastic simulation is computationally unfeasible (e.g. for large values of β).We stress that the choice of which hybrid or ODE solver to use is crucial. For large values of β, e.g. P's deterministic dynamics are stiff; in this case, a stiff solver (Burden and Faires, 2005) should be used. If a non-stiff integrator is employed (such as methods belonging to the explicit Runge-Kutta family Burden and Faires, 2005), then no speed-up may be observed at all (data not shown) compared to exact stochastic simulation.A different abstraction technique consists in reducing the number of model variables and reactions, using the Quasi-Steady State Approximation (QSSA) (Rao and Arkin, 2003; Cao et al., 2005; Mastny et al., 2007). The idea behind QSSA is that, if a set of reactions acting on one (or more) molecular species is very fast, then their dynamics will quickly reach an equilibrium. Therefore, one can remove these reactions from the model, assuming that the entities involved only in these reactions are at their steady state. In practice, model variables are partitioned into fast and slow, and the steady state of fast variables conditional on the slow ones being constant is computed. For a stochastic model, one obtains a steady state distribution for fast variables (assuming ergodicity). Then, a reduced system is constructed, containing only the slow species, averaging out the fast variables from the rate functions depending on them according to the previously computed steady state distribution. Since analytical expressions are rarely obtained in this way, such averaged rates can be approximated either by stochastic simulation (Mastny and S Liu, 2005, 2007), or using the deterministic steady state distribution of fast variables, i.e. the one obtained from the ODE model.In our model the binding and unbinding of the gene repressor turns out to be a natural candidate for QSSA due to the dynamics of the reaction. Indeed, QSSA of gene dynamics is assumed in the majority of models of genetic networks. For the simple binding/unbinding mechanism considered in our model, applying QSSA we obtain a nice closed form for the production rate of mRNA. In fact, keeping XMand XPfixed, we get that Gsteady=1 with probability 1/(1+α·XP).44Conditional on XMand XP, the remaining Markov chain has two states, one for G=1 and one for G=0. The rate of going from G=1 to G=0 is then α·unbindP·XP, while the rate of going in the other direction is unbindP. The steady state probability π for G=1 can be obtained by solving the balance equation α·unbindP·XP·π=unbindP(1−π).Then, the two species describing the gene state (G and Gb) and the binding and unbinding reactions can be removed from the model, and the transcription rate, with the gene variable G averaged out, becomes prodM/(1+α·XP). In this case, this expression coincides with the one that can be obtained from the ODE model. The resulting model contains only four reactions and two species, and is schematically illustrated in Fig. 1(b). In Fig. 3 and Table 3, we show the results of stochastic simulation of this reduced model, assuming QSSA on binding and unbinding (also in this case Fig. 3 reports the most interesting combinations).A typical “rule of thumb” to apply QSSA (Crudu et al., 2009; Cao et al., 2005; Mastny and S Liu, 2007) consists in comparing the time scales of the reactions that are to be removed by QSSA with the time scales of the remaining reactions. If the former are much smaller that the latter, i.e. the corresponding rates are faster, then QSSA is usually safe. Practically, we have to check if the binding and unbinding rates are a few orders of magnitude larger than the remaining rates. This is not always the case in our system: for large β, the unbinding rate is comparable to P's speed (more precisely, it is only one order of magnitude larger). Therefore, QSSA is predicted to be valid only for medium to low β. However, simulating the model we observed that the dynamics are qualitatively similar to those of the explicit model for all parameters and, in most cases, they are in good agreement also from a quantitative point of view. This can be explained by observing that gene repression influences directly only M and that the dynamics of binding/unbinding reactions are much faster than those of production/degradation of M and, thus, the dynamics of gene repression reach equilibrium (in the stochastic sense) much sooner than M's.If the unbinding rate is reduced then the QSSA assumption on equilibrium of gene repression will cease to be valid. In this case, it is known that the QSSA can introduce large errors in the stochastic dynamics (Cao et al., 2005), and this is indeed the case in our model, as observed also in (Marquez Lago and Stelling, 2010). This is confirmed in Fig. 4, where we compare the behaviour of the full and the QSSA models for different parameter combinations. In particular, we fixed β as medium and varied only α but, differently from Section 2.1, we fixed the binding rate to bindP=0.0166 and varied the unbinding rate accordingly to unbindP=bindP/α. Note how the model with QSSA severely underestimates noise and exhibits more and much lower peaks w.r.t. the full stochastic model for large α (i.e. very low unbinding rate).The application of QSSA is by no means restricted only to gene dynamics: it can be applied to any variables and sets of reactions that are sufficiently fast (with respect to the species they interact with). For instance, in our model we may apply it to P itself, when β is large.For example, consider a variation of the model in which we apply QSSA to both G and P, for high β and varying α (with unbinding rate fixed, as in Section 2.1). In this case, the model has only one molecular species left, namely M, and two reactions, transcription and M degradation. In particular, we approximate the stochastic QSSA by computing reduced rates from the deterministic system, giving a rate of transcription of the form prodM/(1+α·prodP/degP·XM), where XPis replaced by its deterministic steady state value prodP/degP·XM.55If we apply the recipe of stochastic QSSA (Rao and Arkin, 2003; Mastny and S Liu, 2007), to get the correct QSSA mRNA production rate we need to compute the steady state distribution of the gene and the protein simultaneously, and then compute the marginal probability that Gsteady=1. In this case, we obtain that this probability equals∑k=0∞(1/(1+αk)(1)/(k!)e−λλk, with λ=Psteady·XM. However, we are not aware of a closed form solution of the previous summation, hence we preferred to stick to the simpler deterministic approximation.This version of the model is illustrated in Fig. 1(c), and simulation results are shown in Fig. 5. As we can see, from a qualitative point of view, the dynamics are preserved for low and medium α. From a quantitative point of view, as well, if we compare the XMdistributions for the full stochastic model and those for this minimal model, we obtain that the two models are very similar for low and medium α (Table S5). We stress that QSSA on P can be applied only for large values of β, i.e. when the correlation between P and M is close to 1.It is clear that the hybrid abstraction and the QSSA can be combined together (Crudu et al., 2009). In Fig. 3 and Table 3, we show the results of hybrid simulation of the reduced model where QSSA is used to abstract binding and unbinding. Also in this case the dynamics are essentially similar to those of the explicit model. This can be explained following and combining the considerations we already made for the two abstractions separately.Looking at the histograms of the distribution of the amounts of P and M at time t=10, 000 s (see Figs. S2, S3, S4, S5 for the distributions of P) for all the models considered, we can observe that the distributions look visually quite similar. This is confirmed by statistically testing the difference between the empirical distributions of the abstract models and the empirical distribution of the stochastic model.In particular, we computed the histogram distance (Cao and Petzold, 2006) and we performed both a Mann-Withney test (Mann and Whitney, 1947) and a Kolmogorov-Smirnov test (Sheskin, 2004) (Tables S1, S2, S3). The histogram distance is used in Monte Carlo simulation to calculate the distance between histogram functions that approximate probability density functions of different group of samples. The Mann-Whitney test is a non-parametric test used to check for a significant statistical dominance between two samples. Its two-sided version can be used to check for a significant difference between two populations. It is also used as a test for detecting a difference between locations (means or medians), assuming that the two samples come from distributions with the same shape. The (two-samples) Kolmogorov-Smirnov test, instead, is a classical test for goodness of fit between two samples, testing the null hypothesis that the two samples come from the same distribution (for the two-sided case). These three tests can detect different aspects of differences between distributions, hence we present the results of all of them in the Supplementary Material.All these tests reported no significant difference between the empirical distributions for most parameter combinations. However, some statistically significant differences are detected, mainly for large values of α and in relation to the hybrid approach. Moreover, the tests give different results for some combinations of parameters (with Kolmogorov–Smirnov and Mann–Whitney detecting more significant differences). There could be several reasons for these differences, related to the number of samples considered, or to the particular shape of the density functions.

@&#CONCLUSIONS@&#
