@&#MAIN-TITLE@&#
Steerable pyramid transform and local binary pattern based robust face recognition for e-health secured login

@&#HIGHLIGHTS@&#
Face recognition system using steerable pyramid transform and local binary pattern is proposed.Zero-norm minimization and local learning based algorithms are used for feature selection.99.28% accuracy was obtained in FERET database with fb set.

@&#KEYPHRASES@&#
Steerable pyramid transform,Local binary pattern,e-Health,Face recognition,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
In an e-Health framework, patients may not be able to speak or write username and password to authenticate him; however, his face is still available and can easily be deployed as a login modality. This aspect of face recognition is less researched in the literature, though a general face recognition research is somewhat matured. Face recognition is considered as one of the noninvasive biometrics, which is widely used in many security systems.Over the last 10 years, research about recognizing a face takes a popular area over other biometric systems. That because it's a balance between security, as it can be done efficiently without user cooperation or knowledge and social acceptances as it does not require electro-magnetic illumination generating and does not restrict user movement, so it is nowadays relatively inexpensive. Due to these reasons, face recognition is one of the popular choices in many security and law enforcement applications [1].Hundreds of research works in this area are still published to achieve a higher recognition rate for that incompletely solved problem because of the dynamic structure of faces and different conditions that human faces’ images can be varied on such as illumination, facial expression, makeup, eyeglasses, poses, etc. The current research involves developing a robust face recognition system against age, ethnicity, and occlusion.Recognizing any pattern must consist of two primary steps. First is the feature extraction and the second is the pattern classification. In case of the feature extraction, there are many methods starting from the simplest one that uses pixel intensities as features. The second method is transforming subspaces of pixel intensities into a low dimensional space in the form of either principal component analysis (PCA), linear discrimination analysis (LDA) or independent component analysis (ICA). The third method uses texture information in the form of a local binary pattern (LBP), histogram of gradients (HoG), or Weber local descriptor (WLD). Nevertheless, another method utilizes multi-resolution transform techniques, such as wavelets, which extract features efficiently by analyzing images into distinct scales of resolution, which gives different sub bands from the same face. After decomposition, the components, which are less sensitive to distortion due to illumination and expressions, are taken [2].There are two types of face features: holistic and local. The holistic features (also named as appearance or global features) are the overall face features that are extracted from each face as a single vector. In addition, it cannot deal with the variation of pose effectively such as local features because of its high sensitivity to rotation and translation. The famous holistic approaches are LDA and PCA. The local feature in contrast can be extracted out of many parts (such as noise, mouth, eyes and so on) from the face with its local statistics (such as appearances and geometric) and location as multiple vectors for each face. In another word, it measures the geometric relationship and properties such as distances, angles, areas between the important facial points. There are features that are a combination of holistic and local features. In such case, the face image is divided into blocks, and some feature extraction techniques are applied to these blocks [3].Automatic face recognition is not a new area of research; however, the challenge is still there. The recognition performance significantly decreases with certain factors, such as, rotation, illumination, resolution, noise, etc. Especially, in an e-Health framework, patients face may not align directly to the camera; illumination may vary in different rooms; and noise can be added through transmission. To date, a good performance is achieved by using local features such as LBP or WLD, because these features are robust against some types of geometric modifications. Multi-resolution techniques such as wavelets and their variants are sometimes used to divide the face image into subbands of various scales and orientations for an improved performance. In particular, Gabor filters are fused with the LBP to produce a better descriptor than the LBP alone in the literature. Of them, Local Gabor Binary Pattern (LGBP) histogram, Histogram of Gabor Phase Patterns (HGPP), and Learned Local Gabor Patterns (LLGP) produced good results in several databases [4–6]. The main problem of using Gabor filters is its high computational cost, because each kernel needs to be convolved by the face image [7]. Similarly, the features based on wavelet decomposition are not good if the faces are captured in an uncontrolled environment.Other variants of wavelets, such as contourlet and curvelet were also investigated in literature. Contourlet with PCA was used to extract face features in [8], and curvelet coefficients from different resolution face images were used in a classifier fusion approach of face recognition in [9]. These methods are also computationally expensive because, some of these transforms require quantized image in addition to the original image. Some recent face recognition systems can be found in [10,11], while some applications of multimedia on this topic can be found in [12,13].In this paper, steerable pyramid transform (SPT) and LBP based face recognition system is proposed. SPT can decompose a face image into several orientations and in different resolutions. The first scale representations have the same resolution of the original image. SPT was used in several applications of image processing, for example, image denoising [14], forgery detection [15], and texture classification [7]. It has also been investigated in the face recognition system [16]; however, it was not fully explored there. The contributions of this work are (i) the development of an SPT-LBP based face recognition system, (ii) a thorough investigation of different subbands of the SPT towards the recognition of face, and (iii) a selection of subbands that achieve optimum results.The organization of rest of the paper is as follows. Section 2 explains the proposed SPT-LBP based face recognition system for an e-Health care framework, Section 3 describes the experiments and results, and Section 4 gives the conclusion of the paper.A framework of an e-Healthcare system, where face is used as a secured login for the patients is shown in Fig. 1. A mobile device in the form of a smart phone takes the face picture of the patient, and along with medical data, the face data is transferred to the cloud using the Internet. A cloud manager initiates the process of authentication by asking a resource allocation manager to distribute several tasks, including feature extraction and classification/recognition of the face. If the face is already enrolled in the system, the manager allows the medical data to be further processed, otherwise, it may ask the user for enrollment. A collaborative service manager manages the tasks of different virtual machines (VMs). The VMs are linked to a number of servers, which are responsible for distinctive executions such as feature extraction, classification, etc. The processed medical data will be made available to registered medical doctors.Fig. 2illustrates the process-flow of the proposed face recognition system. The input image is divided into several subbands using the SPT. The subbands are block-divided and LBP histograms are calculated from each block of the subbands. The histograms from the blocks and from the subbands are fused to construct a final feature set.Linear transforms represent the base for many techniques in the area of image processing, image analysis and image coding. An important subclass of linear transforms is subband transforms such as SPT. SPT is a powerful image decomposition technique, which divides an image in many scales and orientations. It is a particular variant of the well-known recursive and multi-scale wavelet transform. The basis functions of SPT are derivative operators in many directions, which involves variable sizes [17].SPT decomposes an image recursively into subbands of different scales and orientations. The orientation bandwidth of these subbands equal to 2π/o, where o represents the number of orientations. Recursive convolutions followed by decimation operations are used to perform SPT. The resultant subbands of SPT are translation and rotation invariant [18,19]. Fig. 3illustrates a block diagram for a first derivative in two scales SPT (both analysis and synthesis). Initially, the image is decomposed into low and high frequency components by applying filters L0 and H0, respectively. The low frequency component is again decomposed into low frequency component and two oriented band-pass components by applying low-pass filter L1, and oriented bandpass filters B0 and B1, respectively. The low frequency part is also down-sampled by a factor of two. In Fig. 3, the shaded part can be inserted into the unfilled small circle to produce a recursive steerable pyramid. The frequency domain output of this system is given by (1).(1)I^(ω→)={|H0(ω→)|2+|L0(ω→)|2(|L1(ω→)|2+∑K=0N|BK(ω→)|2)}I(ω→)+a.t.where a.t. indicates ‘aliasing terms’. To avoid ‘aliasing terms’, filter L1 should have zero magnitude response for frequencies greater than one-fourth of the sampling frequency.The orientation of the filters used in SPT construction is fulfilled by satisfying the following two conditions of steerability:1.A filter is rotated and copied to produce another filter. Therefore, all the filters are copy-rotated of their counterparts.A linear combination of the basis filters can produce a filter of any orientation [18,19].Increasing the derivative degree (more number of orientations) and the number of pyramid levels, yields finer scale and orientation tuning, which means more robust representation of an image. On the other hand that increases the computation time. In this study, a trade-off is supposed by using the third derivative (4 different orientations) in three levels pyramid. Fig. 4illustrates the details of steerable pyramid filter bank structure used in this study. Fig. 5illustrates an example of the output decomposed image of such a system.In Fig. 5, there are 12 different subbands located in three scales and four orientations in addition to the lowest frequency and highest frequency residual subbands (the highest frequency residual subband is not shown). All the basis functions that used to produce these subbands (except for the initial high pass subband and the final low pass subband) are related to each other by some sort of translation, dilation or rotation [18].In this stage, each suuband is convolved with the well-known texture descriptor LBP, yielding different LBP normalized histograms. Each histogram belongs to a specific subband. Different combinations of histograms are fused to produce feature vectors with different lengths. First, the subband images are decomposed into several blocks from where LBP histograms are calculated. Then the histograms from the subbands are fused to produce the features to be fed into a classifier. The procedure is illustrated in Fig. 6.LBP is one of the simplest yet effective local texture descriptor. In a basic LBP calculation, the neighboring pixels’ gray-scale intensities are threshold by the gray-scale intensity of the center pixel in a 3×3 neighborhood (Fig. 7). If the intensity of a neighboring pixel is higher than or equal to the intensity of the center pixel, a ‘1’ is assigned; otherwise, a ‘0’ is assigned for that neighboring pixel. These binary numbers of the neighborhoods are concatenated to produce an 8-bit binary number, which is then converted into a decimal number. This decimal value is assigned to the center pixel [22].There are several limitations of the basic LBP; one of them is the failure to capture information in a broad context, because of 3×3 neighborhood. To overcome this limitation, circular neighborhood in different scales was proposed [22]. If the neighborhood points on the circle do not exactly match with the pixel intensities, a bilinear interpolation was used, allowing the provision of having any number of neighborhood points at any radius. If the radius of the circle is R, and there are P number of neighbors in that circle, the LBP of a center pixel (xc, yc) is calculated by using Eq. (2).(2)LBPP,R(xc,yc)=∑p=0P−1f(ip−ic)2Pwhere icand ipare gray-level values of the center pixel and P neighborhood pixels, and function f(x) is defined by Eq. (3).(3)f(x)={1,ifx≥00,ifx<0A histogram of the LBP is used as features [22].Next step of the proposed system is the feature selection. The number of features using LBP in all subbands is quite large, more than 3500. In one hand, this high number of features makes the system slow; on the other hand, not all the features are equally important. Therefore, we applied some feature selection techniques to reduce the number of features without compromising with the accuracy. In the proposed system, two stages of features’ selection are applied. In the first stage, a zero-norm minimization technique reduces the number of features according to statistical significance, and in the second stage, the number is further reduced by using a local learning based algorithm (LLB) that removes redundancy [15]. The weight threshold of the LLB is fixed to 10−10. The number of selected features is this threshold dependent. For example, for the threshold 10−10, the number of selected features is 50.In the experiments, a classifier based on minimum chi-square (CS) distance was used. In the literature, CS distance measure is proved to be efficient in features like LBP histograms [22]. CS distance is calculated by using Eq. 4.(4)CS(x,y)=∑j(xj−yj)2xj+yjwhere, xjand yjare the jth bin of input face histogram x and the template face histogram y.

@&#CONCLUSIONS@&#
