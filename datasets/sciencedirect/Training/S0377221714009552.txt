@&#MAIN-TITLE@&#
Efficient optimization of many objectives by approximation-guided evolution

@&#HIGHLIGHTS@&#
Our framework for multi-objective optimization uses a formal notion of approximation.Its runtime increases only linearly with the number of objectives.Our framework achieves a good approximation of the Pareto front across many problems.This is rarely the case for established algorithms such as NSGA-II, IBEA and SPEA2.Our approach now allows the optimization of problems with many objectives.

@&#KEYPHRASES@&#
Multi-objective optimization,Approximation,Comparative study,

@&#ABSTRACT@&#
Multi-objective optimization problems arise frequently in applications, but can often only be solved approximately by heuristic approaches. Evolutionary algorithms have been widely used to tackle multi-objective problems. These algorithms use different measures to ensure diversity in the objective space but are not guided by a formal notion of approximation. We present a framework for evolutionary multi-objective optimization that allows to work with a formal notion of approximation. This approximation-guided evolutionary algorithm (AGE) has a worst-case runtime linear in the number of objectives and works with an archive that is an approximation of the non-dominated objective vectors seen during the run of the algorithm. Our experimental results show that AGE finds competitive or better solutions not only regarding the achieved approximation, but also regarding the total hypervolume. For all considered test problems, even for many (i.e., more than ten) dimensions, AGE discovers a good approximation of the Pareto front. This is not the case for established algorithms such as NSGA-II, SPEA2, and SMS-EMOA. In this paper we compare AGE with two additional algorithms that use very fast hypervolume-approximations to guide their search. This significantly speeds up the runtime of the hypervolume-based algorithms, which now allows a comparison of the underlying selection schemes.

@&#INTRODUCTION@&#
Real-world optimization problems are usually very complex and hard to solve due to different circumstances such as constraints, complex function evaluations that can only be done by simulations, or multiple objectives. Most real-world optimization problems are characterized by multiple objectives. As these objectives are often in conflict with each other, the goal of solving a multi-objective optimization (MOO) problem is to find a (not too large) set of compromise solutions. The so-called Pareto front of a MOO problem consists of the function values representing the different trade-offs with respect to the given objective functions. The set of compromise solutions that is the outcome of a MOO run is an approximation of this Pareto front, and the idea of this posteriori approach is that afterwards the decision maker selects an efficient solution from this set. Multi-objective optimization is regarded to be more (or at least as) difficult as single-objective optimization due to the task of computing several solutions. From a computational complexity point of view even simple single-objective problems on weighted graphs like shortest paths or minimum spanning trees become NP-hard when they encounter at least two weight functions (Ehrgott, 2005). In addition, the size of the Pareto front is often exponential for discrete problems and even infinite for continuous ones.Due to the hardness of almost all interesting multi-objective problems, different heuristic approaches have been used to tackle them. Among these methods, evolutionary algorithms are frequently used. They work at each time step with a set of solutions called population. The population of an evolutionary algorithm for a MOO is used to store desired trade-off solutions for the given problem.As the size of the Pareto front is often very large, evolutionary algorithms and all other algorithms for MOO have to restrict themselves to a smaller set of solutions. This set of solutions should be a good approximation of the Pareto front. The main question is now how to define approximation. The literature (see e.g. Deb, 2001) on evolutionary multi-objective optimization (EMO) just states that the set of compromise solutions (i) should be close to the true Pareto front, (ii) should cover the complete Pareto front, and (iii) should be uniformly distributed. There are different evolutionary algorithms for multi-objective optimization such as NSGA-II (Deb, Pratap, Agrawal, and Meyarivan, 2002), SPEA2 (Zitzler, Laumanns, and Thiele, 2002), or IBEA (Zitzler and Künzli, 2004), which try to achieve these goals by preferring diverse sets of non-dominated solutions.However, the above notion of approximation is not a formal definition. Having no formal definition of approximation makes it hard to evaluate and compare algorithms for MOO problems. Therefore, we think that it is necessary to use a formal definition of approximation in this context and evaluate algorithms with respect to this definition.Different formal notions of approximation have been used to evaluate the quality of algorithms for multi-objective problems from a theoretical point of view. The most common ones are the multiplicative and additive approximations (see Cheng, Janiak, and Kovalyov, 1998; Daskalakis, Diakonikolas, and Yannakakis, 2010; Diakonikolas and Yannakakis, 2009; Papadimitriou and Yannakakis, 2000; 2001; Vassilvitskii and Yannakakis, 2005). Laumanns, Thiele, Deb, and Zitzler (2002) have incorporated this notion of approximation in an evolutionary algorithm for MOO. However, this algorithm is mainly of theoretical interest as the desired approximation is determined by a parameter of the algorithm and is not improved over time. Another approach related to a formal notion of approximation is the popular hypervolume indicator (Zitzler and Thiele, 1999) that measures the volume of the dominated portion of the objective space. Hypervolume-based algorithms such as MO-CMA-ES (Igel, Hansen, and Roth, 2007) or SMS-EMOA (Beume, Naujoks, and Emmerich, 2007) are well-established for solving MOO problems. They do not use a formal notion of approximation but it has recently been shown that the worst-case approximation obtained by optimal hypervolume distributions is asymptotically equivalent to the best worst-case approximation achievable by all sets of the same size (Bringmann and Friedrich, 2010b; 2010c). The major drawback of the hypervolume approach is that it cannot be computed in time polynomial in the number of objectives unless P = NP (Bringmann and Friedrich, 2010a). It is even NP-hard to determine which individual gives approximately the least contribution to the total hypervolume (Bringmann and Friedrich, 2012).We introduce an efficient framework of an evolutionary algorithm for MOO that works with a formal notion of approximation and improves the approximation quality during its iterative process. The algorithm can be applied to a wide range of notions of approximation that are formally defined. As the algorithm does not have complete knowledge about the true Pareto front, it uses the best knowledge obtained so far during the optimization process.The intuition for our algorithm is as follows. During the optimization process, the current best set of compromise solutions (usually called “population”) gets closer and closer to the Pareto front. Similarly, the set of all non-dominated points seen so far in the objective space (we call this “archive”) is getting closer to the Pareto front. Additionally, the archive is getting larger and larger and becoming an increasingly good approximation of the true Pareto front. Assuming that the archive approximates the Pareto front, we then measure the quality of the population by its approximation with respect to the archive. In our algorithm•any set of feasible solutions constitutes an (potentially bad) approximation of the true Pareto front, andwe optimize the approximation with respect to all solutions seen so far.We introduce a basic approximation guided evolutionary algorithm which already performs very well for problems with many objectives. One drawback of the basic approach is that the archive size might grow tremendously during the run of the algorithm. In order to deal with this, we propose to work with an approximative archive which keeps at each time step only an ɛ-approximation of all solutions seen so far. We do this by incorporating the ɛ-dominance approach of Laumanns et al. (2002) into the algorithm. Furthermore, we introduce a powerful parent selection scheme which especially increases the performance of our algorithm for problems with just a few objectives by given the algorithm a stronger focus on the extreme points on the Pareto front.We show on a set of well established benchmark problems that our approach is highly successful in obtaining high quality approximations according to the formal definition. Comparing our results to state of the art multi-objective algorithms such as NSGA-II, SPEA2, IBEA, and SMS-EMOA, we show that our algorithm typically gives better results, especially for high dimensional problems.In our experimental study, we measure the quality of the results obtained not only in terms of the approximation quality but also with respect to the achieved hypervolume. Our experiments show that the examined hypervolume-based algorithms can sometimes achieve a larger hypervolume than our algorithm AGE, but AGE is the only one considered that finds a competitive hypervolume for all functions. Hence our algorithm not only performs better regarding our formal definition of approximation on problems with many objectives, but it is also competitive (or better, depending on the function) regarding the hypervolume.This article is based on its previous conference publications. The based AGE algorithm has been introduced in Bringmann, Friedrich, Neumann, and Wagner (2011). The archive approximation has been presented in Wagner and Neumann (2013) and different parent selection schemes for AGE have been examined and discussed in Wagner and Friedrich (2013).The outline of this paper is as follows. We introduce some basic definitions in Section 2. The main idea of approximation guided evolution and the basic AGE algorithm are presented in Section 3. In Section 6 we show how to speed up the approach by using an approximative archive and discuss different parent selection schemes in Section 5. We present our experimental results in Section 8 and finish with a summary and some concluding remarks.Multi-objective optimization deals with the optimization of several (often conflicting) objective functions. The different objective functions usually constitute a minimization or maximization problem on their own. Optimizing with respect to all given objective functions, there is usually no single optimal objective function vector, but a set of vectors representing the different trade-offs that are imposed by the objective functions.Without loss of generality, we consider minimization problems with d objective functions, where d ≥ 2 holds. Each objective functionfi:S↦R,1 ≤ i ≤ d, maps from the considered search space S into the real values. In order to simplify the presentation we only work with the dominance relation on the objective space and mention that this relation transfers to the corresponding elements of S.For two points x = (x1, …, xd) and y = (y1, …, yd), withx,y∈Rdwe define the following dominance relation:x⪯y:⇔xi≤yiforall1≤i≤d,x≺y:⇔x⪯yandx≠y.The typical notions of approximation used in theoretical computer science are multiplicative and additive approximation. We use the following definitionDefinition 1For finite setsS,T⊂Rd,the additive approximation of T with respect to S is defined asα(S,T):=maxs∈Smint∈Tmax1≤i≤d(si−ti).In this paper, we only consider additive approximations. However, our approach can be easily adapted to multiplicative approximations. In this case, the term si− tiin Definition 1 has to be replaced by si/ti.Our aim is to minimize the additive approximation value of the population P we output with respect to the archive A of all points seen so far, i.e., we want to minimize α(A, P). The problem is that α(A, P) is not sensitive to local changes of P. As its definition is based on maximum and minimum values, α(A, P) only measures the approximation of points that are worst approximated. Consequently, it does not take into account approximation values for points that are not “worst approximated”. We will illustrate this with a very simple example. Let us consider a two-dimensional space with an archive A = {(1, 2), (2, 1), (3, 0)} and a population P = {(2, 1)}. Then, α(A, P) = 1 due to archive points (1, 2) and (3, 0). Even if points such as (3, 0) or (2.5, 0.5) are added to the population, the approximation value will remain α(A, P) = 1 because of the worst approximated archive point (1, 2), even though the approximation of (3, 0) is significantly improved.To get a sensitive indicator, which can be used to guide the search, we consider instead the set {α({a}, P)∣a ∈ A} of all approximations of the points in A. We sort this set decreasingly and call the resulting sequenceSα(A,P):=(α1,…,α|A|).The first entry α1 is again α(A, P). Our new goal it then to minimize Sα(A, P)lexicographically, meaning that we take the lexicographically smallest sequence when we face several sequences.11(a1, …, a|A|) < lex(b1, …, b|A|) ⇔ (a1 < b1) or ((a1 = b1) and (a2, …, a|A|) < lex(b2, …, b|A|)).Note that this is a refinement of the order induced by α(A, P): If we have α(A, P1) < α(A, P2) then we also have Sα(A, P1) < lexSα(A, P2). Moreover, this indicator is locally sensitive. Subroutine 1states the pseudo-code for computing Sα(A, P) for a given archive A and a population P.We are now ready to describe the basic AGE algorithm. It works with the vector Sα(A, P) and tries to minimize it with respect to the lexicographical order. Depending on the optimization process the archive A changes and stores at each point in time for each non-dominated objective vector one single solution.The basic AGE algorithm shown in Algorithm 3works with a parent population of μ individuals and produces in each generation λ offspring.A newly produced offspring p is added to the archive A if it is not dominated by any other solution found so far. If it is added to the archive, all solutions that are dominated by p are removed from A (see Subroutine 2). In order to obtain the next parent population, the set consisting of the union of the parent and offspring is considered. From this set, the individual p for which Sα(A, P∖{p}) is lexicographically smallest is removed iteratively until a population of size μ is obtained. Note that in contrast to many other evolutionary algorithms (like Laumanns et al., 2002 or all hypervolume-based algorithms), the basic AGE algorithm needs no meta-parameters besides the population sizes μ and λ.We now analyze the runtime of the basic AGE algorithm in dependence of μ, λ, the archive size A, and the number of function evaluations N of the algorithm. One generation consists of producing and processing λ offspring. The main part of the runtime is needed for theO(λ(μ+λ))computations of Sα(A, P∖{p}), each costingO(d|A|(μ+λ)+|A|log|A|). Hence, we get a runtime ofO(λ(μ+λ)|A|(d(μ+λ)+log|A|))for generating an offspring population of λ individuals. This means for N function evaluations, that is, N generated points overall, we get a total runtime of(1)O(N(μ+λ)|A|(d(μ+λ)+log|A|))As we can see, this basic algorithm becomes very slow due to the (μ + λ)2 factor when, e.g., μ + λ = 200 is chosen. However, this algorithm works well (in the sense of runtime) for very small population and offspring sizes.The following three sections describe three successive improvements for this basic framework of approximation guided evolution.It can be observed that the selection phase is the most costly step in one iteration of the basic AGE given in Algorithm 3 as it has to evaluate the points of the parent and offspring population against the archive. We can obtain a significant speed-up for each generation of the algorithm by cleverly updating the approximation value of the points in the archive that are affected by the removal of a point from the set consisting of the parents and offspring.Let us first assume that the approximations α({a}, {p}) are distinct for all a ∈ A and p ∈ P. For all a ∈ A we denote the point p ∈ P that approximates it best by p1(a) and the second best by p2(a). The respective approximations we denote by αi(a) ≔ α({a}, {pi(a)}) for i ∈ {1, 2}. Now, let p ≠ q ∈ P and consider Sp≔ Sα(A, P∖{p}) and Sq≔ Sα(A, P∖{q}). Significant for the comparison of the two are only the positions a ∈ A where Spor Sqdiffer from S ≔ Sα(A, P). This is the case for all positions in B ≔ {a ∈ A∣p1(a) ∈ {p, q}}. Now, if we delete p from the population P, then the worst approximation of one of the a ∈ B is the maximum of max {α2(a)∣p1(a) = p} and max {α1(a)∣p1(a) = q}. Now observe that ifβ(p):=maxa∈A{α2(a)∣p1(a)=p}is smaller than the respective β(q), then also the larger term above is smaller, as max {α1(a)∣p1(a) = q} < max {α2(a)∣p1(a) = q}. Hence, we end up with the fact that we only have to compare β(p) and throw out the point p with minimal β(p). This is shown in Subroutine 4, which replaces lines 12–15 of Algorithm 3.22AGE with this selection scheme was called “Fast AGE” in Bringmann et al. (2011).Recall that we assumed that all approximations α({a}, {p}) with a ∈ A, p ∈ P are distinct. If this does not hold, we can simply change the indicator Sα(A, P) slightly and insert symmetry breaking terms a · ɛ, where ɛ > 0 is an infinitesimal small number. This means that we treat equal approximations as not being equal and hence in some arbitrary order.We now give an upper bound for the runtime of AGE with Subroutine 4. For one generation, i.e., for producing and processing λ offspring with one run of Subroutine 4, AGE needs a runtime ofO(d(μ+λ)|A|)for computing the values p1(a), p2(a), α1(a), α2(a) and β(p) initially. Then we repeat λ times: We delete the point p* ∈ P with β(p) minimal inO(μ+λ),after which we have to recompute the values p1(a), p2(a), α1(a), α2(a), but only for a ∈ A with p1(a) = p*. Observe that we can store a list of these a’s during the initial computation and keep these lists up to date with no increase of the asymptotic runtime. Also note that we would expect to findO(|A|/|P|)points with p1(a) = p*, while in the worst case there may be up toO(|A|)such points. Summing up, we can estimate the expected runtime for one generation byO(d(μ+λ)|A|+λ((μ+λ)+d|P|·|A|/|P|)),which simplifies toO(d(μ+λ)|A|)as |A| ≥ μ + λ. In the worst case we replaceO(|A|/|P|)byO(|A|)and get a runtime for one generation ofO(dλ(μ+λ)|A|). For N fitness evaluations we, therefore, get a runtime ofO(d(1+μ/λ)|A|N)heuristically, andO(d(μ+λ)|A|N)in the worst case. Note that |A| ≤ N. For anyλ=O(μ),e.g. λ = 1 or λ = μ, this can be simplified toO(dμ|A|N)in both cases, while for λ = Ω(μ), e.g. λ = μ, we get a reduced estimate of the expected runtime ofO(d|A|N).Quite interestingly, and despite the basic AGE’s good performance on problems with many objectives (as shown in Bringmann et al., 2011), it is clearly outperformed by other algorithms in several cases, when the problem has just two or three objectives. The key discovery is that the random parent selection of the basic AGE is free of any bias. For problems with many objectives, this is not a problem, and can even be seen as its biggest advantage. For problems with just a few objectives, however, it is well known that one can do better than random selection, such as selection based on crowding distance, hypervolume contribution, etc. Such strategies then select potential candidates based on their relative position in the current population. For the basic AGE, the lack of this bias means that solutions can be picked for parents that are not necessarily candidates with high potential. Consequently, it is not surprising to see that the basic AGE is outperformed by algorithms that do well with their parent selection strategy, if their strategy is effective in the respective d-dimensional objective space.We improve the basic AGE’s performance, subject to the following conditions:1.The introduced computation time required to select parents should be polynomial in the number of objectives d.The selection mechanism should significantly improve the performance on problems with few objectives, while not influencing the performance on problems with many objectives.The selection scheme should favor individuals that have the potential to improve the approximation quality.Note that most hypervolume-based algorithms, such as SMS-EMOA and MO-CMA-ES, violate condition (1), as some of the computations that are associated with the selection process take time exponential in d. However, we have to note that it is possible to deal with this drawback by approximating the hypervolume, as shown and demonstrated in Bringmann, Friedrich, Igel, and Voß (2013). Nevertheless, as the maximization of the hypervolume can interfere with our goal of improving the approximative quality, we do not consider such approaches.Also note that the exclusive use of domination based-criteria is problematic. Assuming a general d-dimensional unbounded space (with d ≥ 2), then a point in this space dominates 1/2dof the volume. Obviously then, a pure dominance check in high-dimensional spaces is extremely likely to fail. Or, when interpreted the other way around, this means that a check of the dominance relation between two solutions is extremely unlikely to bring up any additional information about the relative quality between these two solutions.It is relatively easy to design algorithms that easily discover points at the fringe of the Pareto front. With these fringe points (or points that are very close to the fringe), the decision maker can get an idea about the achievable ranges for each objective. However, the problem of finding points “between” those fringe points proves to be much more difficult. Selection mechanisms for the (fitness-based) parent selection and the offspring selection tend to have different biases that result in different preferences for fringe points or central points, depending on the “shape” of the intermediate populations and on the shape of the true Pareto front. With an increasing number of dimensions, this problem becomes even more apparent, as solutions should evenly cover the front, while not concentrating only on extreme points.We choose the best-performing selection scheme from Wagner and Friedrich (2013), which works as follows in each generation. In the first step, the population is “pre-processed” (see Algorithm 5): the population is split into fronts of non-dominating solutions,33Iteratively, all non-dominated solutions are identified and then removed (as one front), which results in potentially several fronts of dominating solutions—see NSGA and NSGA-II (Deb et al., 2002).and then solutions in the front i have a probability of 1/i of staying in the population. Thus, we increase the selection pressure, and solutions that are dominated multiple times are less likely to be selected as a potential parent. Additionally, we determine the crowding distances for the points in the reduced population. In the second step of the selection scheme, a binary tournament is performed where solutions of higher crowding distance are preferred. The crowding distance helps to pick diverse parents when the number of objectives is low.Note that the size of the pre-processed population is not deterministic. It is only guaranteed to contain the entire first front (see Line 5 of Algorithm 5).The basic AGE algorithms stores all objective vectors into the archive that are currently not dominated by any other objective vector produced so far. It is common for multi-objective optimization problems that the number of such trade-offs can be very large, i.e. exponential with respect to the given input size in the case of discrete optimization or even infinite for continuous optimization problems. As, in the worst case, the archive size |A| can grow linearly in the number of fitness function evaluations, the runtime given in Eq. (1) becomes quadratic in the number of generated points N. We therefore want to work with an archive of reduced size which can lead to a significant speed up of the algorithm.In this section, we show how we adapt the ɛ-dominance approach Laumanns et al. (2002) in order to approximate the different points seen so far during the run of the algorithm. This archive is significantly reduced and therefore leads to a faster algorithm.In order to approximate the archive, we are facing a problem that is similar to the original problem of multi-objective optimization, namely a set of solutions is sought that nicely represents the true set of compromise solutions.We reuse AGE’s own main idea of maintaining a small set that approximates the true Pareto front. By approximating the archive as well in a controlled manner, we can guarantee a maximum size of the archive, which directly translates into a bound with respect to the runtime of AGE when considering a fixed number of iterations.Our archive approximation is based on the idea of ɛ-dominance introduced in Laumanns et al. (2002). Instead of using an archive Atthat stores at any point in time t the whole set of non-dominated objective vectors, we are using an archiveAɛgrid(t)that stores an additive ɛ-approximation of the non-dominated objective vectors produced until time step t.In order to maintain such an approximation during the run of the algorithm, a grid on the objective space is used to pick a small set of representatives (based on ɛ-dominance, see Fig. 1). We reuse the update-mechanism from Laumanns et al. (2002), and thus can maintain the ɛ-Pareto setAɛgrid(t)of the set A(t) of all solutions seen so far. Due to Laumanns et al. (2002), the size is bounded by|Aɛgrid(t)|≤∏j=1d−1⌊Kɛgrid⌋whereK=maxi=1d(maxs∈Sfi(s))is the maximum function value attainable among all objective functions.We parameterize our algorithm by the desired approximation quality ɛgrid≥ 0 of the archive with respect to the seen objective vectors. AGE is shown in Algorithm 6, and it uses the helper functions given in Subroutines 7and 8. The latter is used to perform a relaxed dominance check on the offspring p in Line 13. A strict dominance check here would require an offspring to be not dominated by any point in the entire archive. However, as the archive approximates all the solutions seen so far (via the flooring), it might very unlikely, or even impossible, to find solutions that pass the strict dominance test.The algorithm works at each time step t with an approximationAɛgrid(t)of the set of non-dominated points Atseen until time step t. Note, that setting ɛgrid= 0 implies the basic AGE approach that stores every non-dominated objective vector. We now investigate the effect of working with different archives sizes (determined by the choice of ɛgrid) in AGE. Our goal is to understand the effect of the choice of this parameter on the actual archive size used during the run of the algorithm as well as on the approximation quality obtained by AGE.Next, we outline the results of our experimental investigation of the influence of approximative archives on the runtime and the solution qualities. Note, that the computational complexity of AGE is linear in the number of objectives. The algorithm was implemented in the jMetal framework (Durillo, Nebro, and Alba, 2010) and is publicly available.44http://cs.adelaide.edu.au/~optlog/research/age.php.The parameter setup of AGE is as follows. We use polynomial mutation and the simulated binary crossover (Agrawal and Deb, 1994) in order to create new offspring. Both variation operators are widely used in MOO algorithms (Deb et al., 2002; Gong, Jiao, Du, and Bo, 2008; Zitzler et al., 2002) and they are transformations of bit-string operators to bounded real-valued domains. The distribution parameters associated with the operators are ηm= 20.0 and ηc= 20.0. The crossover operator is biased towards the creation of offspring that are close to the parents, and is applied with pc= 0.9. The mutation operator has a special explorative effect for MOO problems, and is applied with pm= 1/(number of variables).55Note that other setups can be used, including different recombination and exploration operators. However, this is beyond the scope of this article as we focus on the comparison of the algorithms.Population size is set to μ = 100 and λ = 100, and each run uses 100,000 fitness evaluations. We assess the quality of the final population using the additive approximation measure (Bringmann et al., 2011). First, we draw one million points of the mathematically described true Pareto front uniformly at random. Then we compute the additive approximation that the final population achieved for this sample of the true Pareto front.Exemplary, we show in Fig. 2the results averaged over 100 independent runs for DTLZ 2 with d = 3. Note that the archive grows very quickly in the case of ɛgrid= 0, where every non-dominated point is stored. Without sacrificing solution quality, a speed-up by a factor of 7.8 is achieved with ɛgrid= 0.01. Additional speed-ups can be achieved, but it is then up to the decision maker to balance the computation speed and the solution quality. More results can be found in Wagner and Neumann (2013). For example, for DTLZ 4 with 20 objectives: “a speed-up by a factor of over 250 can be achieved, while achieving even better quality solutions as well.”The choice of ɛgridcan have a significant impact on the final approximation, which is why we consider several values in the final experiments. In particular, with “coarser” archives, the number of points that represent a particular region decreases. Since the fast approximation-guided selection will at first consider only the single best approximating solution per cuboid, fewer points will actually represent that region. If the cuboids end up very large with the choice of a larger value of ɛgrid, then the remaining solutions of the population (that are not the best approximating ones) are not necessarily distributed in way that results in a good approximation.The AGE algorithm consists of different components that make the approach successful. It heavily relies on the used archive which guides the search as it contains information collected during the run of the algorithm with respect to the true Pareto front. In this section, we would like to discuss them further in detail such that practitioners become aware of the different contributions.The framework of AGE has two components that speed up the computation. The first one is the faster approximation calculation described in Section 4 which gives a runtime speed-up compared to the basic approach without any impairment in terms of quality, i.e., the same set of solutions is computed. This improvement in terms of running time should always be incorporated as it does not come with any disadvantage compared to the basic framework (as described in Section 3).A further significant speed-up is obtained by working with an approximative archive as outlined in Section 6. Here, the parameter ɛgriddetermines the size of the archive during the run of the algorithm. This component imposes a trade-off in running time and approximation behavior as an increasing value of ɛgridleads to a speed-up of the approach at the expense of a worsening in the approximation. Setting the parameter ɛgridis crucial for the success of the algorithm and a good choice is dependent on the given multi-objective problem. Our experimental studies on ɛgridhave shown that the value can be chosen to gain very significant speed-ups with almost no impairment in terms of quality. Setting ɛgridtoo large in relation to the range of the objective values would imply that the archive only consists of a few points which implies that there is almost no guidance for the selection process of the algorithm.While the faster approximation calculation and the approximative archive mainly aim for a speed up of the algorithm, the improved parent selection introduced in Section 5 aims for a better spread of the population in the objective space. As the runtime of AGE is mainly determined by the size of its archive different methods can be exploited without having a huge impact on the running time. Different parent selection methods have been examined in Wagner and Friedrich (2013) and the best performing one is integrated into the final AGE algorithm.In this section, we compare AGE to well-known evolutionary multi-objective algorithms on commonly used benchmark functions. We first study low-dimensional problems and later pay special attention to problems with many dimensions. We judge the algorithms by the approximation quality and the hypervolume that they achieve. AGE is investigated for different values of ɛ in order to study the effect of working with an approximative archive on the quality of the results.In our first study, we investigate the performance of AGE on problems with few objectives. We use the jMetal framework (Durillo et al., 2010) to compare AGE with the established algorithms IBEA (Zitzler and Künzli, 2004), NSGA-II (Deb et al., 2002), SMS-EMOA (Emmerich, Beume, and Naujoks, 2005), and SPEA2 (Zitzler et al., 2002) on the benchmark families WFG (Huband, Barone, While, and Hingston, 2005) and LZ (Li and Zhang, 2009), and DTLZ (Deb, Thiele, Laumanns, and Zitzler, 2005). For each of the problems, the objective values are within “roughly” the same ranges. When facing a problem with significantly differing ranges, we recommend (as we do for other algorithms) to rescale the objectives for the algorithms into comparable ranges, as mechanisms like hypervolume or density computations will not necessarily produce “evenly spread” outcomes as intended by the respective algorithms’ authors.It is important to note that we limit the calculations of the algorithms to a maximum of 50,000/100,000/150,000 fitness evaluations for WFG/DTLZ/LZ and to a maximum computation time of 4 hours per run, as the runtime of some algorithms increases exponentially with respect to the size of the objective space. The further parameter setup of the algorithms is as follows. Parents are selected through a binary tournament. We will present our results for population sizes μ = 100 and λ = 100 and average the results over 100 independent runs. The AGE test setup has been outlined in Section 6.2.We assess the algorithms by examining their final populations. To measure the quality of the final population, we consider the additive approximation and the hypervolume (Zitzler and Thiele, 1999). The latter is very popular in the performance assessment of evolutionary multi-objective algorithms and measures the volume of the dominated portion of the objective space relative to a reference point r. For the quality assessment on the WFG and LZ functions, we compute the achieved additive approximations and the hypervolumes with respect to the Pareto fronts given in the jMetal package. For the DTLZ functions, we compute the additive approximations as described in Section 6.2. For the hypervolume computations for DTLZ 1 we choose r = 0.5d, and r = 1dfor all other benchmark problems. We approximate the achieved hypervolume with an FPRAS (Bringmann and Friedrich, 2010a), which has a relative error of not more than 2 percent with probability at 1/1000. The volumes shown for DTLZ 1 are normalized by the factor 2d. As it is very hard to determine the minimum approximation ratio achievable or the maximum hypervolume achievable for all populations of a fixed size μ, we only plot the theoretical maximum hypervolume for μ → ∞ as a reference.

@&#CONCLUSIONS@&#
Evolutionary algorithms are frequently used to solve multi-objective optimization problems. Often, it is very hard to formally define the optimization goal that current state-of-the-art approaches work with. We have presented an evolutionary multi-objective algorithm that works with a formal notion of approximation. The framework of our algorithm allows to work with various formal notions of approximations. The basic framework of AGE works with an archive which stores every non-dominated objective vector and uses this archive to judge the quality of newly produced solutions. In order to increase performance of this basic variant, we introduced an approximative archive and a parent selection scheme which increases performance for low dimensional problems.The experimental results show that AGE efficiently solves problems with few and with many conflicting objectives.66The source code is available under http://cs.adelaide.edu.au/~optlog/research/age.php.Its computation time increases only linearly with the number of objectives. Given a fixed time budget, AGE outperforms current state-of-the-art approaches (including those using fast hypervolume-approximations) in terms of the desired additive approximation on standard benchmark functions for more than four objectives. On functions with two and three objectives, it lies level with the best approaches. Additionally, it also performs competitive or better regarding the covered hypervolume, depending on the function. This holds in particular for problems with many objectives, which most other algorithms have difficulties dealing with. The choice of the approximative archive (determined by the choice of ɛ) mainly determines the computational cost of the algorithm but has no major effect on the quality of the outcome for the investigated choices of ɛ. Thus we can observe runtime reductions by a factor of up to 250 without sacrificing the final solution quality.In summary, AGE is an efficient approach to solve multi-objective problems with few and many objectives. It enables practitioners now to add objectives with only minor consequences, and to explore problems for even higher dimensions.