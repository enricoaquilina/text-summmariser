@&#MAIN-TITLE@&#
A group evidential reasoning approach based on expert reliability

@&#HIGHLIGHTS@&#
A group evidential reasoning approach based on expert reliability is developed.Reliability of an expert in a group is measured.Incomplete assessments are handled to form interval-valued expert reliabilities.Weights and reliabilities of attributes and experts are included in the method.The proposed method is used to analyze an industry evaluation problem.

@&#KEYPHRASES@&#
Decision analysis,Multiple attribute group decision analysis,Expert reliability,Evidential reasoning rule,Evidential reasoning approach,

@&#ABSTRACT@&#
The reliability of an expert is an important concept in multiple attribute group decision analysis (MAGDA). However, reliability is rarely considered in MAGDA, or it may be simply assumed that all experts are fully reliable and thus their reliabilities do not need to be considered explicitly. In fact, any experts can only be bounded rational and their various degrees of reliabilities may significantly influence MAGDA results. In this paper, we propose a new method based on the evidential reasoning rule to explicitly measure the reliability of each expert in a group and use expert weights and reliabilities to combine expert assessments. Two sets of assessments, i.e., original assessments and updated assessments provided after group analysis and discussion are taken into account to measure expert reliabilities. When the assessments of some experts are incomplete while global ignorance is incurred, pairs of optimization problems are constructed to decide interval-valued expert reliabilities. The resulting expert reliabilities are applied to combine the expert assessments of alternatives on each attribute and then to generate the aggregated assessments of alternatives. An industry evaluation problem in Wuhu, a city in Anhui Province of China is analyzed by using the proposed method as a real case study to demonstrate its detailed implementation process, validity, and applicability.

@&#INTRODUCTION@&#
Reliability is an important concept in various domains, such as engineering (Sriramdas, Chaturvedi, & Gargama, 2014), industry (Gonzalez-Gonzalez et al., 2014), transportation (Prabhu Gaonkar, Xie, & Fu, 2013), computer networks (Lin & Yeng, 2013), wireless networks (Chen & Lyu, 2005), software (Yacoub, Cukic, & Ammar, 2004), power (Kwag & Kim, 2014), and satellite (Guo, Monas, & Gill, 2014). In these domains, system reliability is assessed in order to improve system performance or safety. However, a very important factor that influences system reliability, i.e., human behavior, is not taken into account (Purba, Lu, Zhang, & Pedrycz, 2014). Human behavior can significantly influence system performance and safety. Without proper management human factor may result in system accidents (Wang, Luo, Tu, & Liu, 2011).To decrease human errors and prevent system degradation, human reliability analysis (HRA) has become an important topic in the study of reliability. It focuses on human-machine interaction and integrates human factors into system safety analysis (Vanderhaegen, 2001). Many HRA methods have been developed and applied in different systems, including railway system (Vanderhaegen, 2001), drinking water system (Wu, Hrudey et al., 2009), medical device (Lin et al., 2014), cargo tank cleaning (Akyuz & Celik, 2015), and nuclear power plants (Jung, Yoon, & Kim, 2001). Data collection is key to HRA and limits its practicability (Groth & Mosleh, 2012; Konstandinidou, Nivolianitou, Kiranoudis, & Markatos, 2006). Overall, HRA is conducted to reduce or even prevent the negative influence of human errors on system performance and safety.Expert reliability in multiple attribute group decision analysis (MAGDA) is different from human reliability in HRA. Expert reliability is usually used to assess the proficiency of specialists in MAGDA. Specifically, they can be profiled by changes in the assessments of experts on the condition that the experts have discussions to clarify the decision problem under consideration and avoid misunderstanding. It is clear that expert reliability in MAGDA is not intended for reducing or preventing system safety problems caused by human-system interaction. As such, introducing expert reliability in MAGDA is a new problem rather than a problem in HRA.In literature, many researchers have analyzed MAGDA problems. Some have focused on generating consensus-based solutions by partitioning a MAGDA process into a consensus process and an exploitation process (e.g., Choudhury, Shankar, & Tiwari, 2006; Dong, Chen, & Herrera, 2015; Dong, Xu, Li, & Feng, 2010; Fu, Huhns, & Yang, 2014; Fu & Yang, 2010, 2011,2012; Herrera-Viedma, Alonso, Chiclana, & Herrera, 2007; Li, Liechty, Xu, & Lev, 2014; Mata, Martínez, & Herrera-Viedma, 2009). The consensus process aims to reach group consensus required, while the exploitation process intends to generate a consensus-based solution. Others have developed different aggregation operators and methods to analyze group decision problems (e.g., Fan & Liu, 2010; Gao, Li, & Liu, 2015; Liu, 2014; Merigó, Casanovas, & Yang, 2014; Wang & Li, 2015) or MAGDA problems (e.g., Feng & Lai, 2014; Jin, Pei, Chen, & Zhou, 2014; Liu & Yu, 2014). However, none has considered expert reliability. This has significant impact on the rationality and validity of decisions made. In MAGDA, experts (or decision makers) are not necessarily reliable. Simon (1955, 1956) believed that experts have bounded rationality due to their limited computational ability and selective memory and perception, and not integrating environmental factors in decision making. As such, expert reliability should be effectively measured and used to analyze MAGDA problems.In this paper, we propose a new method based on the evidential reasoning (ER) approach (Yang, 2001; Yang, Wang, Xu, & Chin, 2006) to analyze MAGDA problems. We employ the new ER rule established by Yang and Xu (2013) to combine the assessments of experts in a group on each attribute for each alternative. The aggregated group assessments depend not only on expert weights but also on expert reliabilities. In order to determine the final rating, the reliabilities of experts on each attribute for each alternative are measured by the utilities of assessment grades (a concept demonstrated in Section 2) and two sets of experts’ assessments, including original assessments and updated assessments provided after group analysis and discussion (GAD), in which the decision problem under consideration is clarified and misunderstanding is avoided as far as possible. Note that the stubbornness of an expert in a group contributes nothing to his reliability due to the fact that the reliability measure is developed from the viewpoints of other experts weighted by their initial reliabilities, as demonstrated in Section 3.1.After the aggregated group assessments on each attribute for each alternative are generated, they are further combined by the ER rule with attribute weights and reliabilities to produce the aggregated assessments of alternatives, on the basis of which a solution in consideration of expert reliabilities can be made. When there are one or more incomplete expert assessments (see Section 2) on any attribute for an alternative, pairs of optimization problems are constructed to generate the interval-valued aggregated assessment of the alternative.The rest of this paper is organized as follows. Section 2 presents the ER distributed modeling framework for MAGDA problems. Section 3 focuses on discussing the proposed method in detail. An industry evaluation problem is analyzed in Section 4 to demonstrate the detailed implementation process of the proposed method, and its validity and applicability. Section 5 discusses the influence of the interval-valued combined weight of expert assessments on the solution generated by the proposed method using the problem in Section 4. Finally, this paper is concluded in Section 6.For the convenience of introducing the proposed method, in the following we present basic notations used to model MAGDA problems in the ER context.Suppose that a MAGDA problem includes T experts tj(j = 1,…,T) and a facilitator. The relative weights of the T experts on attribute eifor alternative alare denoted by λ(ei) = (λ1(ei), λ2(ei),…,λT(ei)) such that(1)0≤λj(ei)≤1and∑j=1Tλj(ei)=1.All experts deal with a common multiple attribute decision analysis problem which has M alternatives al(l = 1,…,M) and L attributes ei(i = 1,…,L). The relative weights of the L attributes are signified by w = (w1, w2,…,wL) such that(2)0≤wi≤1and∑i=1Lwi=1.In addition to wi, attribute eiis also associated with its reliability symbolized by ri. The reliability of an attribute is the inherent property of the attribute and is defined as the degree to which the assessment of an alternative on the attribute is consistent with the correct assessment of the alternative. In other words, the reliability of an attribute is interpreted as the degree to which the assessment of an alternative on the attribute is correct for the alternative. In general, there is a positive correlation between riand wi; that is, a larger riindicates a larger wiand vice versa. However, riis not normalized and different from the above wiin Eq. (2) because wicharacterizes the relative importance of attribute eiin comparison with other attributes while riis regarded to be unrelated to the reliabilities of other attributes in the ER rule.Assume thatΩ={H1,H2,…,HN}symbolizes a set of grades which is increasingly ordered from worst to best. That is, the utilities of grades u(Hn) (n = 1,…,N) satisfy the constraint 0 = u(H1) < u(H2) <⋅⋅⋅< u(HN) = 1 in the ER context. The M alternatives are assessed at the L attributes using Hn(n = 1,…,N). Let expert tjassess alternative alon attribute eito grade Hnwith a belief degree ofβn,ij(al), then the assessment can be profiled byBj(ei(al))={(Hn,βn,ij(al)),n=1,…,N;(Ω,βΩ,ij(al))}, whereβn,ij(al)≥0,∑n=1Nβn,ij(al)≤1, andβΩ,ij(al)=1−∑n=1Nβn,ij(al)represents the degree of global ignorance (Fu & Wang, 2015; Xu, 2012; Yang & Xu, 2013). IfβΩ,ij(al)=0, the assessment is complete; otherwise, it is incomplete.In this section, we describe how to determine expert reliabilities and how to generate solutions to MAGDA problems with attribute weights and expert reliabilities, which demonstrate the proposed method by an integrated procedure.When the assessments of experts Bj(ei(al)) (j = 1,…,T) are combined using the ER algorithm (Wang, Yang, & Xu, 2006; Yang, 2001), the reliability of Bj(ei(al)) denoted by Rj(ei) is assumed to be equal to the weight of Bj(ei(al)), i.e., λj(ei). Under this assumption, it can be inferred from Eq. (A.2) in Appendix A of the supplementary material that the hybrid weight of Bj(ei(al)) is equal to λj(ei). However, this cannot be always assumed. In situations where one or more experts may have their own special interests and thus give biased assessments, Rj(ei) (j = 1,…,T) cannot be simply determined using λj(ei) (j = 1,…,T). On the other hand, Rj(ei) (j = 1,…,T) objectively measures the ability of expert tjto provide reasonable or unbiased assessments, as demonstrated in Section 1. As such, Rj(ei) (j = 1,…,T) should be determined by an objective method. To conduct it, GAD is organized by a facilitator, in which the following assumption should be satisfied.Assumption 1In GAD organized by a facilitator, it is required that(1)experts freely communicate with each other to clarify a decision problem under consideration, avoid misunderstanding, and minimize bias;the facilitator does not provide suggestions on the assessments of the experts; andeach expert does not put pressure on other experts to follow his or her views.After GAD under Assumption 1, experts independently determine whether and how to renew their assessments. The implication of independence is defined as follows:Definition 1The independence among experts in a group means that an assessment once given by an expert will not be changed no matter whether assessments from other experts are known or not.By using the assessments before and after GAD under Assumption 1, the reliability of an expert tjis qualitatively defined as follows:Definition 2The reliability of an expert in a group is defined as a combination of the similarity between the assessment of the expert before GAD and the assessment of any other expert after GAD.The reason why the reliability of an expert in a group is evaluated by using the assessments of other experts after GAD instead of those before GAD is that the assessments after GAD are more credible than those before GAD for other experts in the group. Under Assumption 1, GAD can help each expert in a group have a more thorough understanding of the decision problem under consideration to rectify misunderstanding and bias without any pressure from the facilitator and other experts. To quantify the reliability of an expert qualitatively described in Definition 2, two complementary measures, i.e., a dissimilarity measure and a similarity measure between assessments Bj(ei(al)) and Bk(ei(al)) in the ER context are constructed as follows:Definition 3Suppose that the distributed dissimilarity between assessments Bj(ei(al)) and Bk(ei(al)) is defined as(3)GDjk(ei(al))={(Hn,=|βn,ij(al)−βn,ik(al)|),n=1,…,N}Then, a dissimilarity measure between the two assessments is constructed using GDjk(ei(al)) as(4)Djk(ei(al))=∑n=1N−1∑m=n+1Nβn,ijk(al)·βm,ijk(al)·(u(Hm)−u(Hn)),which deduces a similarity measure between the two assessments denoted by(5)Sjk(ei(al))=1−Djk(ei(al)).The dissimilarity and similarity measures in Definition 3 and their properties are demonstrated in Section A.2 of Appendix A of the supplementary material. For the convenience of measuring the reliability of expert tjafter GAD under Assumption 1, the assessments before and after the GAD are expressed byB(0)j(ei(al))andB(1)j(ei(al))(i=1,…,L,l=1,…,M). Then, it can be inferred from Definition 2 that the similarity measure in Definition 3 can be used to quantify the reliability of expert tjwithin a group, which is defined as follows:Definition 4Suppose that T experts tj(j = 1,…,T) give their assessments before and after GAD under Assumption 1 for a MAGDM problem using Hn(n = 1,…,N), i.e.,B(0)j(ei(al))andB(1)j(ei(al))(i=1,…,L,l=1,…,M), and a facilitator assigns u(Hn) (n = 1,…,N). Assume thatS(0)(1)jk(ei(al))stands for the similarity betweenB(0)j(ei(al))andB(1)k(ei(al)), andS(0)(0)kl(ei(al))for the similarity betweenB(0)k(ei(al))andB(0)l(ei(al)).Then, the reliability of expert tjafter GAD is measured by(6)Rj(ei(al))=∑k=1,k≠jTS(0)(1)jk(ei(al))·R(0)k(ei(al))T−1with(7)R(0)k(ei(al))=∑l=1,l≠kTS(0)(0)kl(ei(al))T−1Here,R(0)k(ei(al))represents the initial reliability of expert tkbefore GAD, which is closely connected to Rj(ei(al)) in Eq. (6). This means that Rj(ei(al)) resulting from Eq. (6) with other experts possessing higher initial reliabilities is larger and vice versa given thatS(0)(1)jk(ei(al))is fixed for any expert tk. The reliability in Definition 4 and its property are demonstrated in Section A.3 of Appendix A of the supplementary material.Definition 4 indicates that to what degree an expert is reliable is determined from the viewpoints of other experts after GAD given expert assessments before GAD. This means that any expert cannot benefit from his own stubbornness. The movement of the assessment of each expert contributes to the reliabilities of other experts instead of his own reliability, as presented in Eq. (6). The reliability of expert tjis always measured by the weighted average ofS(0)(1)jk(ei(al))(k ≠ j) withR(0)k(ei(al))as weight no matter whether expert tjchanges his assessment after GAD or not. In other words, the reliability of expert tjrelies on whether other experts get close to or deviate from expert tjafter GAD. As a result, the reliability measure given in Eq. (6) is not designed to encourage or reward stubbornness.WhenβΩ,i(0)j(al)>0inB(0)j(ei(al))for some j,βn,i(0)j(al)becomes a variable symbolized byβn,i(0)j*(al), which is limited to [βn,i(0)j(al),βn,i(0)j(al)+βΩ,i(0)j(al)] and satisfies that∑n=1Nβn,i(0)j*(al)=1. It is same in the case ofβΩ,i(1)j(al)>0inB(1)j(ei(al))for some j. In this situation, Rj(ei(al)) becomes an interval denoted by [Rj−(ei(al)),Rj+(ei(al))], which is determined by solving the following pair of optimization problems.(8)MIN/MAXRj(ei(al))(j=1,…,T)(9)s.t.βn,i(0)j(al)≤βn,i(0)j*(al)≤βn,i(0)j(al)+βΩ,i(0)j(al),j=1,…,T,(10)βn,i(1)j(al)≤βn,i(1)j*(al)≤βn,i(1)j(al)+βΩ,i(1)j(al),j=1,…,T,(11)∑n=1Nβn,i(0)j*(al)=1,(12)∑n=1Nβn,i(1)j*(al)=1.In the above pair of optimization problems, bothβn,i(0)j*(al)andβn,i(1)j*(al)symbolize variables to differentiate them from originalβn,i(0)j(al)andβn,i(1)j(al).This section introduces how to generate solutions to MAGDA problems described in Section 2 using precise or interval-valued expert reliabilities and the ER rule (Yang & Xu, 2013).As can be seen in Section A.1 of Appendix A in the supplementary material, whenB(1)j(ei(al))is combined using the ER rule in Theorem A.2 with λ(ei) and Rj(ei(al)), the combined residual support ofB(1)j(ei(al)), i.e., mp(Ω), E(T)(ei(al)) is measured by1−w˜E(T)(ei(al))=1−RE(T)(ei(al))1+w¯E(T)(ei(al))−RE(T)(ei(al)). Here,w˜E(T)(ei(al)),w¯E(T)(ei(al)), and RE(T)(ei(al)) represent the combined hybrid weight, the combined weight, and the combined reliability ofB(1)j(ei(al)), respectively. RE(T)(ei(al)) will be then applied to combine the aggregated group assessments on each attribute. If the facilitator is able to give a precisew¯E(T)(ei(al)), RE(T)(ei(al)) can be obtained as(13)RE(T)(ei(al))=1−mp(Ω),E(T)(ei(al))·(1+w¯E(T)(ei(al)))1−mp(Ω),E(T)(ei(al)).Otherwise, RE(T)(ei(al)) is limited to the interval [RE(T)−(ei(al)),RE(T)+(ei(al))] = [1−2·mp(Ω),E(T)(ei(al))1−mp(Ω),E(T)(ei(al)),1−mp(Ω),E(T)(ei(al))·(1+maxj∈{1,…,T}{λj(ei)})1−mp(Ω),E(T)(ei(al))] because the maximal value ofw¯E(T)(ei(al))is 1 andw¯E(T)(ei(al))should be greater than or at least equal to the maximal λj(ei) (Yang & Xu, 2013).The generation of the aggregated assessment of alternative alincludes two steps:(1)B(1)j(ei(al))is combined using the ER rule with λ(ei) and Rj(ei(al)) to generate the aggregated group assessment of alternative alon attribute eidenoted by B(ei(al)) = {(Hn, βn,i(al)), n = 1,…,N; (Ω, βΩ,i(al))}.To combine B(ei(al)) using the ER rule, the weight and reliability of B(ei(al)) need to be determined. Note that wiand rigiven in Section 2 characterize the fundamental weight and reliability of attribute eiwith regard to alternative al, which represent the upper bounds of the weight and reliability of B(ei(al)) in ideal situations. As such, the overall weight and reliability of B(ei(al)) are respectively profiled byw^i=w¯E(T)(ei(al))×wiandr^i=RE(T)(ei(al))×ri. Only in an ideal situation wherew¯E(T)(ei(al))= 1 andRE(T)(ei(al))=1will we havew^i=wiandr^i=ri. Until now, B(ei(al)) can be combined using the ER rule withw^iandr^ito generate the aggregated assessment of alternative alsymbolized byB(al)={(Hn,βn(al)),n=1,…,N;(Ω,βΩ(al))}. When there are some incomplete assessments before or after GAD or both, or a precisew¯E(T)(ei(al))cannot be provided, or both appear, the interval-valued aggregated assessment of alternative aldenoted byB¯(al)={(Hn,[βn−(al),βn+(al)]),n=1,…,N;(Ω,[βΩ−(al),βΩ+(al)]}will be obtained.As a whole, to generate the aggregated assessment of alternative al, we discuss the following four situations:(1)completeB(0)j(ei(al))andB(1)j(ei(al))for all j = 1,…,T with a precisew¯E(T)(ei(al)),completeB(0)j(ei(al))andB(1)j(ei(al))for all j = 1,…,T without a precisew¯E(T)(ei(al)),incompleteB(0)j(ei(al))and/orB(1)j(ei(al))for some j ∈ {1,…,T} with a precisew¯E(T)(ei(al)), andincompleteB(0)j(ei(al))and/orB(1)j(ei(al))for some j ∈ {1,…,T} without a precisew¯E(T)(ei(al)).In the first situation, B(al) can be obtained fromB(1)j(ei(al))using the ER rule twice, as analyzed in the above two steps. In the second situation,B¯(al)can be derived from solving the following pairs of optimization problems with variablesw¯E(T)*(ei(al))developed also by using the ER rule twice.(14)MIN/MAXβn(al)(15)s.t.maxj∈{1,…,T}{λj(ei)}≤w¯E(T)*(ei(al))≤1.(16)MIN/MAXβΩ(al)(17)s.t.maxj∈{1,…,T}{λj(ei)}≤w¯E(T)*(ei(al))≤1As for the third situation, the constraints in Eqs. (15) and (17) are replaced byRj−(ei(al))≤ Rj*(ei(al)) ≤Rj+(ei(al))(j = 1,…,T) with variables Rj*(ei(al)) in the above optimization problems for generatingB¯(al). Finally, the constraintRj−(ei(al))≤ Rj*(ei(al)) ≤Rj+(ei(al))is incorporated into the above optimization problems to determineB¯(al)in the fourth situation.With the aid of B(al) and u(Hn) such that 0 = u(H1) < u(H2) <⋅⋅⋅< u(HN) = 1, the minimum and maximum expected utilities of alternative alare calculated by(18)umin(al)=∑n=2Nβn(al)u(Hn)+(β1(al)+βΩ(al))u(H1),and(19)umax(al)=∑n=1N−1βn(al)u(Hn)+(βN(al)+βΩ(al))u(HN).From the resulting umin(al) and umax(al), the minimal satisfaction of alternative al(Chin & Fu, 2014; Fu & Chin, 2014) can be obtained as(20)V(al)=umin(al)−maxm≠l{umax(am)}(l=1,…,M),and used to facilitate the comparison of alternatives, which is limited to [-1, 1] because 0 ≤ umin(al) ≤ 1 and 0 ≤ umax(al) ≤ 1 (l = 1,…,M). Such minimal satisfaction measures the gain from selecting the alternative alunder the worst case scenario when there is unknown in the performances of any alternatives. An alternative with larger minimal satisfaction is more preferred to other alternatives. Thus, V(al) (l = 1,…,M) can be used to generate a ranking order of alternatives, which is considered as a solution to the MAGDA problem.In another situation whereB¯(al)is produced, umin(al) and umax(al) are determined by solving the following two optimization problems with variablesβn*(al)andβΩ*(al).(21)MINumin(al)=∑n=2Nβn*(al)u(Hn)+(β1*(al)+βΩ*(al))u(H1)(22)s.t.βn−(al)≤βn*(al)≤βn+(al),n=1,…,N,(23)∑n=1Nβn*(al)+βΩ*(al)=1.(24)MAXumax(al)=∑n=1N−1βn*(al)u(Hn)+(βN*(al)+βΩ*(al))u(HN)(25)s.t.βn−(al)≤βn*(al)≤βn+(al),n=1,…,N,(26)∑n=1Nβn*(al)+βΩ*(al)=1.The resulting umin(al) and umax(al) are then used to generate a solution to the MAGDA problem. Different from the original ER approach, expert reliabilities are measured and included in the solution generated by the proposed method.The procedure of the proposed method is elaborated below:Step 1:Form a MAGDA problem.A facilitator selects T experts, identifies L attributes and N assessment grades, and lists M alternatives to form a MAGDA problem.Prepare for the proposed method in order to solve the MAGDA problem.The facilitator specifies w, ri(i = 1,…,L), λ(ei) (i = 1,…,L), u(Hn) (n = 1,…,N), andw¯E(T)(ei(al))(i = 1,…,L, l = 1,…,M).Collect assessments from experts.All experts independently give their assessments of alternatives on each attribute. After that, the facilitator organizes GAD under Assumption 1. Then, the experts independently update their assessments.Determine expert reliabilities.The precise expert reliabilities on any attribute are determined by Eq. (6) when expert assessments on the attribute before and after GAD are complete. When some or all assessments on the attribute before and/or after GAD are incomplete, the interval-valued expert reliabilities can be generated by solving the pair of optimization problems in Eqs. (8)–(12).Form the aggregated assessments of alternatives.The aggregated assessments of alternatives in any of the four situations can be generated according to Section 3.2.1.Generate a ranking order of the M alternatives.In the two situations where the belief degrees assigned to grades in the aggregated assessments of alternatives are precise or interval-valued, a ranking order of the M alternatives is generated by following the process discussed in Section 3.2.2.Finish the procedure.The ranking order of the M alternatives is considered as a solution to the MAGDA problem when the reliabilities of the T experts are included.In this section, an industry evaluation problem is solved by the proposed method as a real case to demonstrate its application to modeling a MAGDA problem with expert reliabilities, its detailed implementation process, and its validity. The evaluation result determines the ranking order of candidates of strategic emerging industries to be preferentially developed in Wuhu, a city in Anhui Province of China.A solution system developed in the Matlab environment is employed to analyze the industry evaluation problem.Strategic emerging industries in a region are characterized by intensive technologies, less consumption of resources, large growth potential, and good overall benefits to local economy. Such industries are the manifestation of the deep integration and the collaborative development of science and technology as well as industries. The development of the industries can contribute to the adjustment of industrial structure, the change of development mode and the sustainable development in the region. Thus, to evaluate and identify strategic emerging industries for a region is crucial to the cultivation and development of pillar industries and the sound and rapid development of its local economy.In this paper, we investigate the evaluation of strategic emerging industries in Wuhu, a city in Anhui Province of China. The city is an industry-cluster region in the north of the Yangtze River. The economic development of surrounding areas will be promoted by the economic development of the city. With a view to constructing a national advanced industry base and modern high-end industry system with international competitiveness, the development and reform commission of Wuhu has analyzed the industrial foundation and advantages of the city and identified six industries as the candidates of strategic emerging industries. These industries comprise equipment manufacturing, energy saving and environmental protection, biomedicine, electronic information, new material, and new energy. In the case study, the facilitator is an official from the development and reform commission of Wuhu. Four experts from the commission, a relevant department in Wuhu government, a relevant company, and a collaborative university help the facilitator evaluate the six industries on nine attributes. The attributes include industrial development space, industrial development foundation, effects of low-carbon and environmental protection, industrial effects of promoting science and technology, advantages of large-scale growth, industrial association, profitability, employment absorption capacity, and long-term input-output ratio. They are exclusive of each other.Suppose that the four experts are denoted by tj(j = 1,…,4), the six industries by Il(l = 1,…,6), and the nine attributes by ei(i = 1,…,9). The six industries are assessed on each attribute using the following set of assessment grades: Poor (P), Average (A), Good (G), VeryGood (V), and Excellent (E), say Ω = {Hn, n = 1,…,5} = {Poor, Average, Good, VeryGood, Excellent} = {P, A, G, V, E}. Step 1 is completed.After studying the documents concerning the nine attributes, the facilitator uses a way discussed in (Ölçer & Odabaşi, 2005) to generate the relative weights of the nine attributes, i.e., w = (0.15, 0.12, 0.15, 0.1, 0.08, 0.08, 0.08, 0.1, 0.14). It can also be determined by the facilitator that ri(i = 1,…,9) = (0.6, 0.48, 0.6, 0.39, 0.33, 0.33, 0.33, 0.39, 0.57) due to the positive correlation between riand wipresented in Section 2. The detailed process for calculating attribute weights and reliabilities is presented in Section B.1 of Appendix B of the supplementary material. In a similar way, the facilitator gives the weights of the four experts according to their different background, knowledge, and experience, which are presented in Table B.1 of Section B.1. The facilitator uses a probability assignment approach (Farquhar, 1984; Winston, 2011) to set u(Hn) (n = 1,…,5) to be (0, 0.25, 0.5, 0.75, 1). Further,w¯E(4)(ei(Il))= 1 (i = 1,…,9, l = 1,…,6) is decided, which means that the combined weights of the aggregated assessments of the four experts on each attribute for each industry are always 1. Differentw¯E(4)(ei(Il))may result in different RE(4)(ei(Il)) and further lead to different V(Il). Step 2 is completed.To find the solution to the industry evaluation problem, the assessments of the four experts on the nine attributes for the six industries need to be combined to generate the aggregated assessment of each industry. The assessments of the six industries are then applied to determine the minimal satisfaction of the six industries.The four experts gave their initial assessments on the nine attributes for the six industries, which are presented in Table B.2 of Section B.1. After GAD under Assumption 1 which lasted for about 80 minutes, the four experts updated their assessments, as can be seen in Table B.3 of Section B.1. Step 3 is completed.In Tables B.2 and B.3, there are one or more incomplete assessments on each attribute for each industry. In this situation, interval-valued rather than precise reliabilities of the four experts on each attribute for each industry can be determined by finding the solutions to the pair of optimization problems in Eqs. (8)–(12) with the assessments in Tables B.2 and B.3 and u(Hn) (n = 1,…,5). The results are shown in Table B.4 of Section B.2 in Appendix B of the supplementary material. Given [Rj−(ei(Il)),Rj+(ei(Il))] (j = 1,…,4) on attribute eifor industry Il, its average length is defined as(27)L¯R(ei(Il))=∑j=14(Rj+(ei(Il))−Rj−(ei(Il)))4.Then, the average length of the intervals of expert reliabilities on each attribute for each industry can be derived from the results in Table B.4 using Eq. (27), which is shown in Table B.5 of Section B.2. The average length is closely associated with the feasible region formed by the constraints given in Eqs. (9)–(12). In other words, the average length of [Rj−(ei(Il)),Rj+(ei(Il))] (j = 1,…,4) on attribute eifor industry Ilis greatly related toβΩ,i(0)j(Il)andβΩ,i(1)j(Il). The largerβΩ,i(0)j(Il)andβΩ,i(1)j(Il), the bigger the average length of [Rj−(ei(Il)),Rj+(ei(Il))]. For example, the average length of [Rj−(e2(I5)),Rj+(ei(I5))] is the greatest in Table B.5 becauseβΩ,2(0)1(I5)= 0.4,βΩ,2(0)2(I5)= 0.4,βΩ,2(0)3(I5)= 0.1,βΩ,2(0)4(I5)= 0.3,βΩ,2(1)1(I5)= 0.2,βΩ,2(1)2(I5)= 0.3,βΩ,2(1)3(I5)= 0.1, andβΩ,2(1)4(I5)= 0.3. There are two similar cases for the average length of [Rj−(e3(I5)),Rj+(e3(I5))] and that of [Rj−(e9(I3)),Rj+(e9(I3))]. On the contrary, due to the fact thatβΩ,8(0)1(I1)= 0.1,βΩ,8(0)3(I1)= 0.1,βΩ,8(0)4(I1)= 0.1,βΩ,8(1)1(I1)= 0.1,βΩ,8(1)3(I1)= 0.1, andβΩ,8(1)4(I1)= 0.1, the average length of [Rj−(e8(I1)),Rj+(e8(I1))] is the smallest in Table B.5. The average length of [Rj−(e2(I1)),Rj+(e2(I1))] is a similar case. Step 4 is completed.Table B.4 reveals that expert reliabilities on each attribute for each industry are interval-valued, which will result in the interval-valued aggregated assessment of each industry. After finding solutions to the two pairs of optimization problems in Eqs. (14)–(17) on the condition that the constraints in Eqs. (15) and (17) are replaced byRj−(ei(Il))≤ Rj*(ei(Il)) ≤Rj+(ei(Il)), we obtain the aggregated assessments of the six industries, which are shown in Table B.6 of Section B.2. The assessments in Table B.6 can effectively reflect the real situations of the six industries in Wuhu. We use equipment manufacturing (I1) and electronic information (I4) industries as examples to demonstrate this. As an industrial city, the proportion of manufacturing in the industries of Wuhu is the highest. Thus, the equipment manufacturing industry owns better fundament and provides more employment positions. Meanwhile, it is associated with so many industries. Although so, the manufacturing industry is still a traditional industry heavily dependent on resource consumption, which significantly compresses its development space and thus greatly reduces its long-term input-output ratio. More importantly, the manufacturing industry cannot effectively and efficiently promote the development of science and technology. Compared with the manufacturing industry, the electronic information industry is a newer one. It is an outcome of industrial transformation and upgrading in Wuhu and can contribute more to industrial innovation and economic development of Wuhu. Although its fundament, association with other industries, and employment capacity are not as good as the manufacturing industry, they are mostly at good level or more. Specifically, its development space, contribution to the development of science and technology, and long-term input-output ratio are also mostly at good level or more. Meanwhile, the electronic information industry is acceptable in other aspects. As a whole, it is rational that [β2−(I1),β2+(I1)] > [β2−(I4),β2+(I4)], [β5−(I1),β5+(I1)] > [β5−(I4),β5+(I4)], [β4−(I1),β4+(I1)] < [β4−(I4),β4+(I4)], and [β3−(I1),β3+(I1)] ≈ [β3−(I4),β3+(I4)] where the notation ‘≈’ denotes ‘approximately equal to’. Step 5 is completed.The aggregated assessments of the six industries can be quantified using u(Hn) (n = 1,…,5) to determine the expected utilities of the six industries. Because the aggregated assessments are interval-valued, the two optimization problems described in Eqs. (21)–(26) are solved to generate the expected utilities of the six industries, which are presented in Table 1. The minimal satisfaction of the six industries is then calculated using their expected utilities and Eq. (20), which determines the rankings of the six industries. Both of them are also presented in Table 1. As a consequence, we obtain a ranking order of the six industries as I5 ≻ I4 ≻ I2 ≻ I6 ≻ I1 ≻ I3 where the notation ‘≻’ denotes ‘superior to’. Note that the ranking order is not absolute but relative to the rule of minimal satisfaction. When the facilitator and the four experts cannot reach a consensus on the rationale of this decision rule, they can draw another ranking order from giving a further analysis of [umin(Il), umax(Il)]. Step 6 is completed.If the rule of minimal satisfaction is accepted by the facilitator and the four experts, the resulting ranking order of the six industries determines their preferential development order as strategic emerging industries in Wuhu, which is the solution to the industry evaluation problem. Otherwise, another solution will be generated after the facilitator and the four experts give a further analysis of [umin(Il), umax(Il)]. Step 7 is completed. It should be noted that the solution does not mean that only the new material industry (I5) should be developed in Wuhu but that more resources should be allocated to and more favorable policies should be made for the industry in order to support its development as priority.As can be seen in Section 3.2.1, Rj(ei(al)) contributes to B(ei(al)) and further to B(al) through RE(T)(ei(al)) in two steps. Because the overall reliability of B(ei(al)), i.e.,r^i= RE(T)(ei(al)) × riis used to combine B(ei(al)) with the ER rule, risets a bound within which RE(T)(ei(al)) can contribute to B(al). This means that riinfluences B(al), V(al), and further the final solution. For this reason, in the following we conduct sensitivity analysis for rito show the impact of changing rion the solutions to the industry evaluation problem.To facilitate such a sensitivity analysis, it is assumed that the ratios of ri(i = 2,…,9) to r1 are equal to (0.8, 1, 0.65, 0.55, 0.55, 0.55, 0.65, 0.95), which are the same as the ratios of wi(i = 2,…,9) to w1, as described in Section B.1. Under this assumption, 23 different values of r1 are selected by experiments, on the basis of which the expected utilities, minimal satisfaction, and rankings of the six industries are obtained and presented in Table B.7 of Section B.2. The movement of the minimal satisfaction of the six industries with variation in r1 is plotted in Fig. 1.It is clear that there are two stable intervals of r1 from 0.1 to 0.31 and from 0.32 to 0.78, in which the ranking order of the six industries remains as I5 ≻ I4 ≻ I2 ≻ I1 ≻ I6 ≻ I3 and I5 ≻ I4 ≻ I2 ≻ I6 ≻ I1 ≻ I3, respectively. Along with the increase of r1, the ranking of I6 has gradually increased. Specifically, I6 becomes the second best industry when r1 is limited to [0.8, 0.92] and further the best industry when r1 continues to increase to [0.93, 0.99]. However, I6 is replaced by I2 when r1 is further increased. Not only that, the entire ranking order of the six industries also has sensitively changed with variation in r1 from 0.93 to 1. As a whole, we can draw a conclusion that the rational estimation of attribute reliabilities is very important for generating solutions to MAGDA problems with expert reliabilities by the proposed method, especially when one or more attributes are profiled with high reliability.

@&#CONCLUSIONS@&#
This paper proposes a method to model and analyze MAGDA problems with distributed assessments based on the ER rule developed by Yang and Xu (2013). When using the ER rule to combine expert judgments on each attribute for each alternative and further to combine group assessments on each attribute for each alternative, the reliability of an expert is measured by a combination of the similarity between the assessment of the expert before GAD and the assessment of any other expert after GAD weighted by the initial reliabilities of the other experts. It should be noticed that any expert cannot benefit from obstinacy in such a reliability measure because to what degree an expert is reliable is judged from the viewpoints of other experts in view of their initial reliabilities. Specifically, we construct several pairs of optimization problems to cope with the situations of incomplete assessments and imprecise combined weights of aggregated group assessments.The proposed method is a new exploration to handle the reliabilities of experts in MAGDA, which are not involved in existing MAGDA methods in the ER context (e.g., Fu & Yang, 2010, 2011, 2012; Fu et al., 2014) and other group decision analysis methods with various fuzzy preference expressions (e.g., Choudhury et al., 2006; Dong et al., 2010; Herrera-Viedma et al., 2007; Li et al., 2014; Mata et al., 2009; Yan & Ma, 2015).Finally, the proposed method provides a new framework for handling MAGDA problems with expert reliabilities and attribute reliabilities. When historical data about the initial reliabilities of experts and attribute reliabilities can be provided, new approaches for estimating the two types of reliabilities need to be developed to extend the proposed method, which is expected to be more applicable. On the other hand, interval-valued belief distributions deserve more thorough consideration for wider and more generic applications.