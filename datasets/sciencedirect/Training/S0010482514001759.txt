@&#MAIN-TITLE@&#
Anonymization of DICOM electronic medical records for radiation therapy

@&#HIGHLIGHTS@&#
We extended an open-source code to process multiple EMRs automatically.We tested commercial optical character recognition (OCR) algorithm for the detection of burned-in text on a test image.OCR was unable to recognize the burned-in text reliably.We also developed and tested an image filtering algorithm to redact burned-in text from the test radiograph.Validation tests verified that PHI was anonymized and data integrity was preserved.

@&#KEYPHRASES@&#
Digital Imaging and Communication in Medicine (DICOM),Anonymize,Radiation oncology,Protected health information,

@&#ABSTRACT@&#
Electronic medical records (EMR) and treatment plans are used in research on patient outcomes and radiation effects. In many situations researchers must remove protected health information (PHI) from EMRs. The literature contains several studies describing the anonymization of generic Digital Imaging and Communication in Medicine (DICOM) files and DICOM image sets but no publications were found that discuss the anonymization of DICOM radiation therapy plans, a key component of an EMR in a cancer clinic. In addition to this we were unable to find a commercial software tool that met the minimum requirements for anonymization and preservation of data integrity for radiation therapy research. The purpose of this study was to develop a prototype software code to meet the requirements for the anonymization of radiation therapy treatment plans and to develop a way to validate that code and demonstrate that it properly anonymized treatment plans and preserved data integrity. We extended an open-source code to process all relevant PHI and to allow for the automatic anonymization of multiple EMRs. The prototype code successfully anonymized multiple treatment plans in less than 1min/patient. We also tested commercial optical character recognition (OCR) algorithms for the detection of burned-in text on the images, but they were unable to reliably recognize text. In addition, we developed and tested an image filtering algorithm that allowed us to isolate and redact alpha-numeric text from a test radiograph. Validation tests verified that PHI was anonymized and data integrity, such as the relationship between DICOM unique identifiers (UID) was preserved.

@&#INTRODUCTION@&#
The biological effect of ionizing radiation on humans has been researched intensively for more than a century. Some effects may occur years or even decades after exposure and may include an increase in the risk for developing cancer, cognitive deficits, fertility problems, and other chronic health issues [1,2]. Despite monumental research efforts and considerable progress, our knowledge of effects of radiation in humans is incomplete. To some extent, one may bridge the gaps in knowledge by extrapolating from experimental results from animals, in-vitro cell cultures, and subcellular structures [3]. However, the validity of such extrapolations to effects in humans is difficult to establish with certainty. An attractive alternative approach is to conduct clinical trials and epidemiological studies of populations of patients who received radiation exposures from diagnostic or therapeutic medical procedures [4].In radiation epidemiology studies, the process of reconstructing radiation dose from abstracted paper medical records introduces substantial uncertainties in the estimates of radiation dose [5]. This may involve the translation of patient records from foreign languages, transcription of handwritten records, and dealing with incomplete or missing data on the patient׳s anatomy and radiation treatment fields. In recent years, great strides have been made in standardizing the reporting of radiotherapy treatments, including terminology [6–8]. Recently, internationally standardized methods have emerged for the electronic storage and exchange of medical data for diagnostic radiology, such as the Digital Imaging and Communication in Medicine (DICOM) standards committee [9] and by Integrating the Healthcare Environment (IHE) group [10,11]. The standards include capabilities specifically for radiation oncology [12,13].In the future, investigations of radiation effects will increasingly utilize electronic medical records (EMRs) containing protected health information (PHI). For ethical and legal reasons, researchers are required to anonymize patient data before they can be made available to the public. In the United States this means complying with the Health Insurance Portability and Accountability Act of 1996 (HIPAA) [14]. To date several works have discussed techniques and methods for anonymizing DICOM image sets and generic DICOM files [15–21]. While DICOM Working Group 18 published a comprehensive list of tags to be anonymized [22], no publications are available discussing the anonymization of treatment plans for radiation therapy. In addition to this we were unable to find a commercial software product that met our requirements for the anonymization of treatment plans. These requirements included automatic anonymization of multiple EMRs and the anonymization of DICOM tags listed in DICOM supplement 142 [22], which is an extension of the DICOM standard specifically related to de-identification of patient records for the clinical trials. It arose due to the determination that DICOM confidentiality profile PS 3.15 did not sufficiently protect identities for patient records used in clinical trials.The objective of this work is to develop and test a prototype software code to anonymize EMRs for patient, while maintaining the integrity of the files and the data within them. We modified an existing open source DICOM anonymizer [23] following the recommendations from DICOM Supplement 142 for the anonymization of radiation therapy data. The software was validated for compliance with HIPAA and verified that the integrity of the data was maintained.The processing of private electronic health information will vary with the intended use and recipients of the data. For example the NIH classifies research involving human as Human Subjects Research (HSR) or Not Human Subjects Research (NHSR) using a decision making flowchart [24].Fig. 1 shows a flowchart that was based on the Department of Health and Human Services (DHHS) flowchart and simplified to focus on the objectives of this study. In general, the HSR requires more processing and administrative oversight than NHSR and consequently may be more complicated, computationally expensive, and time consuming. Therefore, in many cases in which it is not required, it will be preferable to anonymize the data in a manner that allows the investigation to be classified as NHSR.Table 1 lists the protected health information (PHI) that were deleted, or overwritten during the anonymization process. The list is a minimum set of attributes to be processed as recommended in DICOM Supplement 142 [22]. Depending on institutional practices, attributes which did not contain PHI at our institution could contain PHI at another institution. For example a comment field could contain the name of a patient or clinician. Additionally records generated by other radiotherapy information systems may use attributes that were not used here and they may have additional data stored in private tags (User defined attributes that are, by definition, not included in DICOM specifications).DICOM radiation therapy treatment plans typically consist of an image series, a treatment plan file, one or more dose files, and a structure set file. DICOM utilizes unique identifiers (UIDs) to identify and describe the relationship between files.Fig. 2 illustrates the various relationships between UIDs in DICOM treatment records. Instance UIDs are given to each individual file as well as each series and study (treatment plan). Reference UID tags are used to describe which files are meant to be associated with a particular tag. For example a structure set file contains contours for anatomical structures used in the treatment plan. These are stored in the form of coordinates that outline the structure on each image slice. Each DICOM file has a Service Object pair (SOP) instance UID which identifies that file. In the case of structure in the structure set file the referenced SOP instance UID is used to identify the image slice the coordinates are meant to correspond with. Anonymization codes should modify the instance UIDs to ensure that the data will not clash in a picture archiving and communications system (PACS), and also to ensure anonymity [17]. Importantly, the corresponding referenced UIDs must also be changed consistently across an entire EMR to preserve the relationship between various data files.We enhanced the DVTK anonymizer [23], which was already capable of anonymizing many PHI data items. We extended the code to process additional PHI and UIDs. Specifically we added processing of the attributes noted in Table 1 including the following UIDs: Frame Of Reference UID, Referenced Frame Of Reference UID, and Referenced SOP Instance UID. All of the attributes listed in Table 1 were overwritten or removed. For a given session (e.g., one execution of the code on a directory containing the medical record for one patient), the UIDs and references to those UIDs were anonymized but kept consistent. The code was also extended to automatically operate on a directory tree, meaning records for multiple patients were anonymized in one session. We also added object definition files, which includes DICOM-RT-ION related SOP Classes. The object definitions provided in the “standard installation package” for the DVTK Anonymizer lacked these definitions.The anonymization software was validated using DICOM-RT and DICOM-RT-ION treatment plans exported from a commercial radiotherapy treatment planning system (Eclipse; Varian Medical Systems, Inc., Palo Alto, CA). After each treatment plan was anonymized it was tested in three ways. First, it was re-imported into the treatment planning system to ensure the integrity of data and relationships between various data were preserved. For each plan, we checked key treatment beam parameters, the dose prescription, and dose values at 10 anatomical locations to verify that they had not changed during the anonymization process. This test also ensures that the treatment planning system does not re-associate the anonymized treatment plan with the original treatment plan, which would result in the re-identification of the anonymized treatment plan. Second, a script was used to output the metatag and name for each element that was anonymized. This list was compared to the list in Table 1 to ensure that elements containing PHI were anonymized. Finally, the anonymized EMRs were converted into text files and electronically searched for PHI to verify that all of the attributes in Table 1 had been anonymized.The EMRs used in this study were taken from NIH funded studies involving treatments for prostate cancer, medulloblastoma, and Hodgkin lymphoma. The prostate cancer EMRs consisted of proton therapy treatment plans for 13 patients as described by Fontenot et al. [25]. The medulloblastoma records consisted of 1 conventional photon therapy plan, 1 IMRT plan, and 1 proton therapy plan each for 2 patients treated with craniospinal irradiation for medulloblastoma, as described by Newhauser et al. [26] and Howell et al. [27]. The Hodgkin lymphoma records consisted of 1 IMRT treatment plan, 1 mantle field treatment plan, and 1 anterior posterior (AP)–posterior anterior (PA) treatment plan each for 1 patient. All plans were created according to the prevailing standard of care at The University of Texas MD Anderson Cancer Center (UT MDACC).In addition to the anonymization of encoded textual DICOM elements, one may need to detect and/or anonymize textual PHI which is burned into medical images. We implemented the mature and widely used open-source Tesseract optical character recognition (OCR) engine sponsored and hosted by Google [28] to explore this problem. This approach presented two challenges. First, the algorithm operated only on bi-tonal images, whereas our images were grayscale. This necessitated a binarization process, in which each pixel was converted to either white or black depending on a predefined threshold brightness value. The second challenge was that the OCR algorithm was optimized for typical office correspondence documents that are 8.5″×11″ (letter) or 8.5″×14″ (legal) sizes. Typically these documents are scanned at a resolution between 200 and 400dpi, resulting in an image that is about 1700×2200 pixels. Text in an 8 point font scanned at this resolution would be approximately 22 pixels tall. In contrast typically CT images are typically 512×512 pixels.The performance of the OCR algorithm was tested on a sample radiographic chest exam image with burned in text from UTMDACC (cf.Fig. 3). This image was 1465×800 pixels and the text height was approximately 7–9 pixels tall. This resolution is significantly less than the neural network in the OCR algorithm was designed to operate on, e.g., with accuracy dropping off rapidly below 8pt at 300dpi and at a text height of below about 8 pixels, the algorithm will remove most of the text during the noise removal process. Indeed, at this low resolution, the OCR algorithm was unable to reliably identify the text characters burned in our test image, indicating the need for alternative and/or additional image processing methods.The first strategy we investigated comprises two key additional steps; detecting a subregion of the image that contains suspected text then resampling the subregion at a high resolution (corresponding to a character cap height of 31 pixels), i.e., at the resolution the OCR algorithm was designed to operate. To accomplish this, we used the ImageJ software [29] from the National Institutes of Health because it provided many image processing functions and a scripting capability that were of relevance to this work. Specifically, we successfully isolated the text from the image by setting the brightness threshold to a lower value of 1 and upper value of 255, with a white background. We then resampled the image using bicubic interpolation to a total size of 5448×2975 pixels, corresponding to a 5-fold increase in the number of pixels per character height. This can be thought of as effectively amplifying the signal and noise, and preserving the signal-to-noise ratio (SNR). However, each of the characters in the interpolated image still contained defects (cf.Fig. 4b). Specifically, undesired features were present in various strokes, including gaps in the spine of the letter s; the vertical strokes of k, p, and 4; angled strokes of 1, 5, k, V, 2, A, and 4; the arches of m; the closed rounded stroke (bowl) of p; and the trailing outstrokes of k. In addition, there were openings in closed counters of A, 0, and e; the ears of p and m were missing, and other defects. However, using an interpolated image facilitated experimentation aimed at repairing pixel defects in the individual characters. Specifically, we used additional standard image preprocessing techniques, such as dilation (i.e., thickening by adding pixels to the edge of an object), erosion (thinning by removing pixels), smoothing, sharpening, despeckling and other mathematical image filtering algorithms. This overall method will be subsequently referred to as the interpolation-OCR method.The second strategy we tested was to detect sub-regions of the image possibly containing one or more alpha-numeric characters. We redacted (erased) these sub-region region(s) to remove PHI by reassigning the pixel values of a sub-region. This approach had the advantage that PHI could be detected and removed without the necessity to perform OCR. To implement this strategy, we began by filtering the original image and determining the bounding boxes of sub-regions containing alpha-numeric characters. Only the pixels inside the bounding boxes were overwritten with a visibly obvious redaction pattern, i.e., a black and white checkerboard pattern. With this approach, the redacted image remained identical to the original image, except in the redacted regions. This method will be subsequently referred to as the threshold-redaction algorithm.Fig. 5 shows the flow diagram for this threshold-redaction algorithm.The threshold-redaction algorithm began with identifying the areas of the original image containing alpha-numeric characters. First, the low-threshold filter, which is a binarization filter that converts a grayscale image to a binary image with a threshold value of 1/255, was applied to the original image and the negative of the result was taken (Fig. 4c). This low-threshold filter isolated the non-radiographic information (i.e., alpha-numeric characters and graticules) from the original image. Then, the high-threshold filter, which has a threshold value of 244/255, was applied to the original image. The high-threshold filter isolated the completely white pixels in the original image, i.e., the graticules (cf. Fig. 4d). Since the graticules shown in Fig. 4d are the interior of the graticules shown in Fig. 4a, a one pixel expansion was applied to of all white pixels in Fig. 4d to approximate the actual size of the graticules. After applying this pixel dilation to Fig. 4d, the resulting image was subtracted from that in Fig. 4c, creating a binary image (Fig. 4e) with white pixels where the original image contained alpha-numeric information.After identifying the pixels of interest, bounding boxes were generated to encapsulate these pixels. However, two image reduction steps were applied to Fig. 4e before the bounding boxes were determined. All lone white pixels were removed and the remaining white pixels underwent a one pixel expansion, which filled in the spaces between words and created fewer bounding boxes. Then, bounding boxes were determined via a built-in Matlab function (“regionprops”) that can be used to identify regions of connected white pixels in a binary image (Fig. 4f). Finally, after the bounding box regions were identified, the corresponding regions of the original image were redacted with a checker board pattern (Fig. 4g). The results of the threshold-redaction algorithm applied to the entire original image are shown inFig. 6.

@&#CONCLUSIONS@&#
