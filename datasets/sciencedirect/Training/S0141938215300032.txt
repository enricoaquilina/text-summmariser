@&#MAIN-TITLE@&#
Introduction to editable visual object and its description schema for mobile applications

@&#HIGHLIGHTS@&#
We analyze the drawbacks of current emoticon system.We introduce an editable visual object which can substitute the emoticon.We propose a schema based EVO description method.We propose a differential coding to transmit the EVO.We implement the prototype mobile application to verify the performance the proposed EVO.

@&#KEYPHRASES@&#
Editable visual object,Description schema,EVO,Prototype,Mobile applications,

@&#ABSTRACT@&#
With the spread of portable smart devices, social networking services are gaining popularity. At the same time, emoticons which can be used a primary tool to deliver the enriched personal feelings are also gaining popularity in the social networking services. Now, emoticon markets are much bigger than before since the territory of emoticons broadens the culture and social issues. However, provided emoticons from the service providers are difficult to express the exact personalized feeling. Thus, users cannot edit what they want to express. In this study, we propose a new concept of emoticons, an editable visual object, to resolve above problems. User can edit the components inside the proposed editable visual object and send it to express exact intention. Further, we propose an efficient editable visual object description schema to represent and transmit the editable visual object. To prove the performance and efficiency of proposed technique, we implement and test the prototype system for the mobile device. As shown in the test results, the proposed description method is at most 100 times superior to the compared screen capturing method in the view of transmission bandwidth. The proposed editable visual object can be exploited not only mobile applications, but also various fields such as education and medical field.

@&#INTRODUCTION@&#
Through the dialogue, people want to not only exchange information, but also sympathize with their thoughts and feelings. Since we could chat with someone via the computer, people was attempting to deliver their exact intention or enriched feeling by using simple drawing which is composed of alphabets or symbols such as :) and ;P. These are called texticons, and these are widely used in computer chatting and short message service (SMS) in the mobile phone. The position of texticons is changed to emoticons after smartphone generalization around 2010 [1–3]. Emoticons are now an essential component of mobile applications such as social networking service (SNS) and mobile messengers. Now, many people choose the mobile applications based on the diversity and design of included emoticons.As you can see from the survey results about mobile messenger application usage in Fig. 1, the proportion using emoticons in the mobile messenger chatting is gradually increasing. In the case of Kakaotalk which is the most commonly used mobile messenger in South Korea, the proportion of emotion usage is over 95%. The survey results also tell us the prospect that emoticon usage is not easily drop down. The size of emoticon market is also very huge. As shown in Fig. 2, the sales of global mobile messenger market in 2014 will be around 193 billion dollars, and the sales will be reached at 229 billion dollars in 2015. More than 1 billion persons are using mobile messenger, thus a great many emoticons are used in a day.The amount of emoticon usage is tremendously increased nowadays. The reasons can be found in the abstraction of feelings and intimacy which is the innate characteristics of emoticons. Users can express their complex feelings in easy way by using emoticons. Further, the receiver may feel intimacy when the sender uses emoticons in the case of simple reply.Emoticons have a lot of strong points mentioned above, however, they also have a few inevitable drawbacks:•It is difficult to find the well-suited one among lots of emoticons in the given situation.Sometimes, there is no suitable emoticon in the given situation.Most of emoticons are difficult to deliver the accurate information.Emoticons are difficult to express the specific actions that user want.Provided emoticons could not reflect the every user’s personalized preference.In this study, we propose a new concept of emoticons, the editable visual object. (From now, we refer an editable visual object as EVO.) Also, we propose an efficient way to describe EVO. EVO description method can be used for transmitting and storing EVO.The remainder of this paper is organized as follow. In Section 2, we propose EVO definition, description method, and transmission. More specifically, the definition and structure of EVO is presented in subSection 2.1. In subSection 2.2, the way how to describe EVO is proposed. In subSection 2.3, the efficient EVO transmission method is presented. In Section 3, we check the operation of EVO and its desciption schema by using the implemented mobile application prototype. Finally, Section 4 provides conclusion and future works.In this section, we first define the concept and structure of EVO and propose the efficient EVO description method. Also, we think about the efficient way of EVO transmission.One emoticon uses just one image to express one object, whereas EVO composes a set of component images to express one perfect object as shown in Fig. 3. Further, every component image in the EVO can be rotated, translated, and scaled (i.e. can be affine transformed). For example, in the case of “face” emoticon, every single emoticon is needed to express every facial expression such as smile, irritancy, sad, etc. In the case of “face” EVO, however, we need just one “face” EVO to express the whole facial expressions, since we can edit the angle, size, and position of face components such as eye, nose, and mouth. Also, we can express something by adding or removing the component images. For example, we can express sad by adding tear. Or we can express bold hair by removing hair component images.To make the EVO structurally, we define EVO is a set of EVOs or one image. It means EVO is recursively defined as shown in Fig. 4. The leaf of tree be a component image. Here, the component images positioned in the leaf is now called NEVO (Non-editable visual object) and NEVO has its own image and it can be rotated, translated, and scaled. According to the definition of EVO, EVO is now a group of EVO/NEVOs. For example, every component image in Fig. 3 are NEVOs such as ears, eyes, nose, mouth and face shape. EVO points a group of face component images here. If EVO is transformed in the affine space, every sibling EVO/NEVO is also transformed in the same way with their parent EVO.There are many advantages by defining the EVO recursively. First, the number of EVO does not need to be large because one EVO can alternate numerous emoticons in the same category by editing the EVO. Second, users can tailor the personalized EVO which reflects the user preference. Third, EVO can be used to deliver the information that user want to send.To store and transmit the EVO efficiently, well-structured EVO description method is needed. To design the EVO description schema, we refer to the schema design guideline of service descriptions in the MPEG User Description (MPEG-UD) standard which is one of the MPEG standard groups [7].Since both EVO and NEVO can be edited in a similar way because EVO is a group of EVO/NEVOs, EVO and NEVO can be described as the same schema format. By doing so, the implementation complexity becomes lower and the reusability becomes higher than maintaining two different schema formats for EVO and NEVO each. From now on, we call the schema which can contain EVO or NEVO data as an EVO schema or EVO description schema.The proposed EVO description schema is shown in Fig. 5. In the schema, there are three classes; Attribute, AffineTransformation, and ChildInfo. Attribute class describes the basic and unique identifications of given EVO/NEVO object, and it contains ID, Version, and ImageLink fields of a given object. Here, ImageLink field contains the location data of a designated image file of a given object. It means only NEVO has the ImageLink value. The second class is AffineTransformation class. This class has the editing information of a given object. The component fields of AffineTransformation class are StartX, StartY, EndX, EndY, Angle, IsFlip, Label and ActionCode. By using these component fields, the mobile application can draw the EVO/NEVO on the display. Here, we assume that ActionCode field is filled with the predefined code which matches with preset action of a given object. ChildInfo class has the sibling information of a given object. If a given object has siblings, their ID is recorded in ContainedEVO field inside the class. Among these component fields, ImageLink and ContainedEVO are mutually exclusive. If a given object is NEVO, it has a designated image and does not have siblings. On the contrary, if a given object is EVO, it does not have an image, but it has siblings. Thus, only one of ImageLink or ContainedEVO has the value.For better understanding, we want to explain the proposed EVO description schema by showing an example. If the user wants to express a watch, the system calls the EVO metadata which represents the watch. Here, E001 is the watch metadata. After retrieving E001, the system checks ContainedEVO field and retrieves every EVO metadata inside that field. In the example, N001∼N003 is retrieved. Thus, four objects (one EVO and three NEVOs) are initialized as shown in Fig. 6(a) when we call a watch from the mobile application. As you can see in the figure, each component field inside AffineTransformation class of all objects are different because they need to be laid on the different positions.Now, Let us think about the NEVO editing. If one user rotate the hour hand from 12 to 3, Angle field inside theN003object is changed from 0 to 90 degree because the orientation of an hour hand is changed to 90° as shown in Fig. 7. Likewise, other fields inside AffineTransformation class are changed according to the user’s editing.In the case of EVO editing, every NEVO image inside the parent EVO is influenced by the change of EVO object. However, the values inside NEVO object are not changed, because AffineTransformation data inside the EVO object are changed and these changes influence whole objects inside the parent EVO. For example, if one user vertically downsizes the watch to 50%, startY ofE001is altered from 0 to 0.5 as shown in Fig. 8. Naturally, whole objects inside theE001are vertically downsized because of this alteration. However, every field of N001∼N003 is not changed because the value of their parent EVO is already changed and these changes are affected to every image that the parent EVO has.As shown in Fig. 9, most of current emoticon transmission systems are ID based transmission [8]. Each mobile device has its own emoticon database. The emoticon database organizes the pairs of emoticon image and its ID. To send a specific emoticon, the application just transmits the ID of the emoticon that wants to send. When the application receives the ID of a specific emoticon, it searches the emoticon image in the database by using received emoticon ID and retrievethe emoticon image.The emoticon transmission system is very efficient in case of transmitting pre-defined images because every user has the exactly same emoticon database. However, this system is difficult to be directly applied in the case of EVO transmission. one EVO is composed of a group of EVO/NEVOs, and each component object can be freely manipulated what user prefers. Therefore, the EVO could not have the fixed image. It means the numbers of possibly generated images from one EVO are numerous, and giving the unique ID for each edited EVO image is inefficient way because it needs huge EVO database size.To solve this problem, we can think about two different solutions. The first solution is a screen capturing. To send edited EVO, the mobile application captures the edited EVO as one image and transmits that image. This solution is the easiest way to represent and transmit the edited EVO. However, this way is not efficient on the view of data size and transmission bandwidth because a whole image needs to be transmitted via data transmission network. Also, the receiver could not re-edit the received EVO because it is now just one image like an emoticon. Further, this method could not support the action of EVO.The second solution is a differential coding. In the case of differential coding, the application first finds the differential data between initial EVO and edited EVO. Then, it generates the differential codes from the differential data, and transmit that code. By doing so, the transmission overhead could be minimized. When the receiver application receives the code, it first calls the original EVO object from its database. Then, it restores the edited EVO which the sender intended by replacing the data inside the original EVO using the received differential code. The restored EVO also can be reused by the receiver because it is also represented as a schema. Fig. 10shows the conceptual way how to transmit the edited EVO from one to another.For better understanding, we want to give one example as shown in fig.. In the example, user A calls “face” EVO and edit its eyes. To transmit edited “face” EVO, the system send EVO ID and the changed data in the description metadata. These changed data is called the differential codes. When the system of user B receives this ID and differential codes, the system first call original “face” EVO by using the received EVO ID. Then, the system overwrites the metadata by using the received differential codes. According to the above sequence, the exactly same EVO is displayed to users (see Fig. 11).

@&#CONCLUSIONS@&#
