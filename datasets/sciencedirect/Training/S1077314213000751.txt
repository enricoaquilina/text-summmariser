@&#MAIN-TITLE@&#
Mean shift based gradient vector flow for image segmentation

@&#HIGHLIGHTS@&#
Classical GVF based algorithms face challenges such as over- or under-segmentation.Our MSGVF algorithm pursues a minimised combination of mean shift and GVF terms.The proposed algorithm is evaluated against two publicly accessible databases.MSGVF achieves better segmentation performance than the classical methods.

@&#KEYPHRASES@&#
Image segmentation,Mean shift,Gradient vector flow,Contour,Energy function,

@&#ABSTRACT@&#
In recent years, gradient vector flow (GVF) based algorithms have been successfully used to segment a variety of 2-D and 3-D imagery. However, due to the compromise of internal and external energy forces within the resulting partial differential equations, these methods may lead to biased segmentation results. In this paper, we propose MSGVF, a mean shift based GVF segmentation algorithm that can successfully locate the correct borders. MSGVF is developed so that when the contour reaches equilibrium, the various forces resulting from the different energy terms are balanced. In addition, the smoothness constraint of image pixels is kept so that over- or under-segmentation can be reduced. Experimental results on publicly accessible datasets of dermoscopic and optic disc images demonstrate that the proposed method effectively detects the borders of the objects of interest.

@&#INTRODUCTION@&#
Snakes or active contour models were first proposed by Kass et al. in 1987 [1]. Snakes or active contours refer to curves or surfaces that are defined within the image domain with external constraint forces, and driven by image forces towards the image features such as edges. Since their publication, these deformable models have received tremendous attention in the research community [2–5].According to the representation and implementation, there are mainly two groups of deformable models: parametric deformable models (PDMs) and geometric deformable models (GDMs) [6]. GDMs describe curves or surfaces as level sets of higher-dimensional scalar functions that evolve in an Eulerian style, while PDMs explicitly parameterise curves or surfaces in a Lagrangian fashion [6]. With remarkable success, these established models continuously target the following two major technical problems: initialisation (or capture range) [7,8] and topological changes [9,10]. On the other hand, there are also some interesting work related to nonparametric active contours, which may render the boundary settlement independent of the initialisation process, e.g. [11,12].GDMs are often used to address topological flexibility. For example, Caselles et al. applied curve evolution theory [13] and developed a geometric active contour model [14], while Malladi et al. introduced a geometric active contour model [15] based on the level set principle [16]. Han et al. [6] reported a topology-preserving level set method that achieved topology preservation using the simple point concept. However, GDMs still face a number of challenges in different aspects. For example, in a level set scheme (one example of GDMs), topological constraints on the evolving boundary need to be released in order for the scheme to deal with a higher dimensional space [17]. Furthermore, GDMs can be further improved in the detection of boundary gaps [18].PDMs have been widely used in boundary detection, motion detection and tracking, and object recognition. A number of algorithms have been established for various applications by formulating new forms of the external energy in the Snake model. These algorithms include balloons [19], distance potential force [20], diffusion Snakes [21], gradient vector flow (GVF) [22] and its generalisation [23], and further developments [24,25]. GVF and its variants have achieved tremendous success by attracting the active contour towards object boundaries from a relatively large distance. These approaches are also capable of converging to object cavities in some applications. In spite of this progress, evidence shows that the performance of PDMs needs to be improved in automatic initialisation and splitting [10].In recent years, numerous efforts have been made to provide potential solutions towards the capture range or/and topological change problems. A comprehensive survey has been reported in [26]. For example, a graph theory based approach was introduced by Li et al. [10] within the external force term in the Snake model to perform automatic Snake initialisation or splitting. Chuang and Lie [27] presented a downstream algorithm based on an extended GVF field model, where the downstream process starts with a set of selected seeds by considering local gradient direction information around each pixel. Yang et al. [28] proposed a robust colour GVF Snake model which combines robust estimation and colour gradients using an L2E robust estimation. Vasilevskiy and Siddiqi [29] demonstrated that their gradient flow model can be used to maximise the rate of the flux of a vector field in a two-or three-dimensional domain. This model can drive the vector field to go along with outstanding magnitudes.Paragios et al. [25] proposed an edge driven bi-direction geometric flow for boundary detection by combining the geodesic active contour flow [30] and the gradient vector flow model [22]. Tang and Acton [31] proposed a multiscale gradient vector flow to elude clutter and to reliably localise the vessel boundaries. Afterwards, Tang [32] presented a cancer image segmentation algorithm, where the first part uses an anisotropic diffusion filter for removing the noise and hairs, and the second part uses a multi-directional GVF Snake to segment the suspicious areas. A motion gradient vector flow model for tracking rolling leukocytes was introduced by Ray and Acton [33] and utilises the direction of leukocyte movement. Michailovich et al. [34] developed an energy functional based on the Bhattacharyya distance to drive curves towards the shape that embeds a maximal discrepancy between the empirical distributions of the photometric variable inside and outside the contours.In this paper, we propose a new type of dynamic energy force for Snakes combining local GVFs with mean shift. Our approach is largely different from [35] that pursued a smooth vector field, where the contour evolution relied on the summation of the current gradient vector and the mean difference of all the gradients. The proposed MSGVF scheme in our work seeks an optimal solution to a newly designed Euler–Lagrangian function that simulates the energy minimisation of the evolving contour. Our algorithm is developed in the way that both local (GVF) and global (mean shift) energy minimisation are balanced, whilst the smoothness constraint of the image pixels is kept. The proposed approach also significantly differs from those published in [24,36–39]: our method uses a Lagrange multiplier to integrate the classical GVF and the mass density function of the boundary into a combinatorial form. The boundary is considered as a solution of the introduced Partial Differential Equation (PDE), and we use mean shift as an optimisation approach to simplify the PDE computation. Comparably, the classical approaches investigated the distance between the two centroids of the previous and the present closed boundaries, where truncated Taylor series gives a good approximation to the parameters used in the classical Gradient Vector Flow. Mean shift was used as a stopping criterion for the segmentation, and theoretical analysis for the asymptotic properties was also given in the publications.The remainder of the paper is organised as follows. In the next section, the proposed Mean Shift based Gradient Vector Flow (MSGVF) algorithm is presented. Section 3 provides experimental results and performance analysis. Finally, conclusions and future work are given in Section 4.Snake (or active contour) models are used to detect object boundaries or edges, given an initial guess of the evolving contours by the user. The major challenge is to search for a global minimum over a non-convex functional under predefined constraints, which leads to the desired solution [1]. Both initial and boundary conditions appear very important as they significantly affect the search for a contour of both global and local minimums. This has been justified by the evidence that the evolving boundary can vanish into a single point at a global minimum of the potential [9].Classical Snake models consider a combination of internal and external energy, in which the boundary will stop evolving when an energy balance is obtained. The external energy force in the Snake model is restricted to a small area which is close to the real boundary. If it is far from the real boundary, the Snake may have difficulty in converging to the correct position due to image noise or distractions that violate the objective function. To address this, Xu et al. [22] proposed a GVF field map to represent the external energy force in the Snake model. This GVF term is sensitive to the object boundaries or edges appearing in the image and hence effectively pushes the Snakes towards the real edges.Let a Snake be a curve x(s)=[x(s),y(s)],s∈[0,1], which evolves in an image domain to reach a minimisation of the following energy function:(1)E(x)=∫0112α∂x∂s2+β∂2x∂s22+Eext(x)ds,where α and β are the weights that determine the tension and rigidity of the Snake respectively. The first order derivative∂x∂scauses stretching while the second order derivative∂2x∂s2leads to bending. The first two terms on the right-hand side of Eq. (1) are referred to as the internal energy of the Snake, and the third term is the external energy that attains small values at the feature points. In the presence of high gradients at image boundaries (e.g. step edges) the external energy is represented by −▽(Gσ(x,y)*I(x,y))2. In the case of line drawings, ±Gσ(x,y)*I(x,y) is used instead, where Gσis a two-dimensional Gaussian function with standard deviation σ.To obtain a minimisation, the contour should satisfy the following time-dependent function:(2)γ∂x∂t=∂∂sα∂x∂s-∂2∂s2β∂2x∂s2-▽Eext(x)=0,where γ is the coefficient. In GVF Snakes, the external energy of Eq. (2), −▽Eext(x), is replaced by a GVF field, which is defined as the solution of the following Euler equations using the calculus of variations [40]:(3)vt=μ▽2v-(v-▽f)|▽f|2,v0=▽f,where vtis the partial derivative of v with respect tot,▽2=∂2∂x2+∂2∂y2, and f indicates an edge map of the image and attains large values at feature points. Fig. 1illustrates an example of GVF segmentation, where the edges are enhanced via Gaussian filtering, and the GVF field map is calculated according to the solution of Eq. (3).The classical GVF Snake appears to be less effective in the presence of distractions or noise in the vicinity of a real boundary (see the experimental section). As one of the possible solutions to this problem, in the previous work, we proposed a mean shift based GVF strategy [24,38]: when the internal and external forces of the GVF Snake are balanced, we have the Euler equation as follows:(4)g1(d)C″(s)-g2(d-1)C⁗(s)+g3(d)V=0,where g1(d), g2(d−1) and g3(d) are the weighting functionals of the internal and external energy terms, respectively, C(s) is the contour that delineates the desired boundaries and d is the Euclidean distance between the presumed centroid of the real boundary and the estimated one of the snake.According to [39], after appropriate variations, Eq. (4) has a deformable form asα̃dC″(s)-β̃dC⁗(s)+γV=0, whereα̃=g̃1(d1),β̃=g̃2(d2),d1and d2 are two constants, andg̃1andg̃2are the variations of the functionals g1 and g2. The Euclidean distance between the two centroids, d, is proportional to the average mean shift of the entire contour [38]. This is motivated by the fact that upon the settlement of the Snake, these two centroids must be able to match.As discussed above, the settlement of Snakes relies on the interaction between the internal and external energy forces. If one of them has a larger force than the other, the Snake will penalise the other term and hence the Snake’s settlement may be biased, leading to over-or under-segmentation. In the situation where there exists strong image noise or distractions next to the target contour, a denoising process must be properly designed in order to handle the bias issue. Fig. 2illustrates dermoscopic images (a) with their blurred outcomes (b) using a Gaussian filter in order to reduce noise during the GVF segmentation procedure. However, a new challenge is that we have no prior information about the level of image noise and the locations of distractions and hence appropriate noise reduction may be very difficult to achieve.Another possible solution is to re-design the energy functional considering the combinatorial effects of the internal and external energy forces within the objective function, i.e. Eq. (1). As a result, the newly designed functional must be adaptive to different image circumstances. In particular, if the internal energy term dominates the evolution of the contour, the external energy term will be used to constrain the diffusion of the evolutionary contour in order to prevent over-evolution of the contour. Here, we take a close look at the evolution of the contour with numerical modelling, based on a mass density function that describes the evolution of a curve. This is a different view from the classical GVF strategies, using one of the fundamental theories in physics.The deformation of a region of interest can be considered as a map T+:Ω→R2with a continuously differentiable inverse T−. Let the mass density function of the region, surrounded by a continuous contour, be ρ. The mass of the region is given as follows:(5)mω=∫ωdT+ρ(T+,t),where m is the mass in the range ω at time t.Using the dynamical version T+0, ρ0 and ω0 of the parameters T+ respectively, ρ and ω, the right-hand side of Eq. (5) can be decomposed as follows [41]:(6)∫ω0dT+0ρ0(T+0)=∫ω0dT+0det(▽T+(T+0,t))ρ(T+(T+0,t),t),where the mass density function has an alternative form:(7)ρ(T+,t)=det(▽ρ0(q(T+,t))).Here, q is the inverse transform depending on the deformation map T+. For simplicity, we use a time-series function to describe the mass:(8)Q(t)=∫ω0dT+0det(▽T+(T+0,t))ρ(T+(T+0,t),t).We understand that the surrounding contour cannot stop evolving until an energy cost function has been satisfied. Therefore, we expect to find out in what circumstance the contour can be settled. In a noise-free image (almost impossible though), we are able to stop the evolution of the contour if the following condition is met [41]:(9)∂Q(t)∂t=0.Using Eq. (8), we have the following form, omitting the intermediate derivation:(10)∂Q(t)∂t=∫ω0dT+0det(▽T+(T+0,t))∂∂tρ(T+(T+0,t),t)+(▽·J)ρ(T+(T+0,t),t).In spite of its complexity, Eq. (10) delineates the progressive characteristics of the contour during its evolution. In other words, the right hand side of Eq. (10) must be of a global minimum absolute value when the contour actually stops moving. For simplicity, we here discuss about the case where (▽·J)ρ is positive definite, which is a common case in practice. As a result, the following inequality holds:(11)∂ρ∂t+(▽·J)ρ⩾∂ρ∂t,where J is a spatial velocity field that denotes the motion vector of the image points on the contour at time t with the following form:(12)J(T+,t)=∂T+∂t(q(T+,t),t).Let T+0 be a vector with non-negative components. Combining Eqs. (11) and (12) leads to:(13)∂Q(t)∂t⩾∫ω0dT+0det(▽T+(T+0,t))∂ρ∂t(T+(T+0,t),t).If the Snake settles on the correct boundary, both constraints Eqs. (2) and (9) must be satisfied at the same time. To jointly satisfy these two constraints in a single objective function, we consider applying the Lagrange multiplier rule [42]. This approach has the advantage of using one of the constraints as a regularisation term when the other is pursued. In other words, we seek an optimal value for the parameterλ∈Rsuch that:(14)∂∂sα∂x∂s-∂2∂s2β∂2x∂s2-▽Eext(x)-λ∫ω0dT+0det(▽T+(T+0,t))∂∂tρ(T+(T+0,t),t)+(▽·J)ρ(T+(T+0,t),t)=0.Let the first term of the left-hand side of Eq. (14) beFT1and the second termFT2. In our case, the curve x inFT1is closely related to the map function T+ inFT1. In fact, the latter determines the location of x in the image, and any change of T+ subsequently causes variations of x. In the meantime, the Lagrange multiplier λ can be updated as(15)λ=infs∈[0,1],T+0∈ω0FT1FT2,where the conditions of s and T+0 must be jointly satisfied. Substituting Eqs. (11)–(14), we have the following form:(16)∂∂sα∂x∂s-∂2∂s2β∂2x∂s2-▽Eext(x)-λ∫ω0dT+0det(▽T+(T+0,t))∂∂tρ(T+(T+0,t),t)⩾0.Let the left-hand side of Eq. (16) beL(t). Thus, we can re-write Eq. (16) according to [43]:Φ(t)=LTL=‖L‖2. Eventually, the numerical solution of Eq. (16) satisfies the following condition:(17)minΦ(t)=min(‖L‖2).Using such a combinatorial way (i.e. Eq. (16)) helps handling the segmentation problem in noisy images. This will be justified in the experimental section. However, seeking such a minimisation as Eq. (17) is non-trivial. First of all, compromising both the partial differential equation (PDE) and the mass function of a region during the contour evolution is not easy to achieve due to the different objectives. Secondly, an analytical solution to the PDE problem is extremely difficult to obtain as there are no prior information or boundary conditions to use. A fast and optimal solution to Eq. (17) is therefore pursued in the next subsection.To obtain an optimal solution to Eq. (16), we first investigate the two terms of the left hand side of Eq. (16), and seek corresponding solutions for individual local energy minimisations. These two different operations are intersectionally applied to the two energy terms before a global minimum is found. According to [22], the gradient vector flow field is defined as the vector field v(x,y) that minimises the following energy functional:E=∫∫μux2+uy2+vx2+vy2+|▽f|2|f¯v-▽f|2dxdy, where v(x,y)=[u(x,y),v(x,y)]. The solution to this minimisation is(18)μ▽2u-(u-fx)fx2+fy2=0μ▽2v-(v-fy)fx2+fy2=0where ▽2 is the Laplacian operator. Taking a closer look at the second term of the left-hand side of Eq. (16), we have:(19)det(▽T+(T+0,t))=Πreig(▽T+(T+0,t)),where r is the dimension and eig denotes the eigenvalues of ▽T+(T+0,t). The derivative ▽T+(T+0,t) can be approximated to be the difference of two neighbouring deformable shapes against the time interval:(20)▽T+(T+0,t)≈T+(T+0,t)-T+(T+0,t-△T)△T,where the initial state of ▽T+(T+0,t) is null and △T is the image sampling interval (a constant in this case).Now, we look at the parameterisation of ρ. The Euclidean distance between the centre of the mass and each point j on the image is represented as d((xj,yj),t). Similarly, the Euclidean distance between the centre of the region and each point i on the contour is D(xi,yi). Therefore, the mass density ρ is computed as follows:(21)ρ(T+(T+0,t),t)=∫jd((xj,yj),t)D(xi,yi).Thus, we have:(22)∂ρ∂t(T+(T+0,t),t)=∂∫jd((xj,yj),t)D(xi,yi)∂t≈αd¯(t)D(xi,yi),where α is a constant based on empirical results, andd¯(t)is the average moving distance of the centre of the mass over a short period. Eq. (22) shows that the variation of mass density ρ is proportional to the motion distance of the mass centre.We now attempt to work out an efficient technique in order to obtain an optimal numerical solution to Eq. (22). Techniques such as image moments [44,45], level sets [15], wavelets [46] or stochastic analysis [47] can be used to handle this problem in different circumstances. Most of these approaches require the objective functions to be parameterised. Moreover, these methods require significant computation efforts before convergence is reached. In our approach, which is significantly different from the classical approaches, we use a mean shift based algorithm that can achieve fast similarity search by examining the intensity distributions over two neighbouring iterations [48].It is worth pointing out that the proposed algorithm significantly differs from the classical approaches such as [24,35,38,39] in the sense that the convergence of the proposed algorithm relies upon the intensity histogram of the region outlined by the contour, the distance between each point within the region outlined by the contour and its mass centre and the distance between each point of the contour and its centre. However, the approaches presented in [24,35,38,39] only depend on the distance between each point of the contour and its centre. Evidence shows that the proposed algorithm leads to better performance than the others due to the joint action of the regional contents and the distances as mentioned.Fig. 3shows two exemplar images with corresponding intensity histograms and final segmentation results (the boundaries are shown in green colour). The mean shift analysis used in the energy minimisation is to enhance the discrimination capability of image pixels. Let K(ϕ) be a kernel and f(ϕ) be a multivariate kernel density estimation of the intensity values within the region outlined by the evolving contour (ϕ refers to the image points). Then,(23)f(ϕ)=1n∑i=1nKH(ϕ-ϕi),where ϕiindicate the neighbouring points, andKH(ϕ)=|H|-12KH-12ϕ, where H is a symmetric positive definite (l×l) bandwidth matrix and n is the number of image points. In a real application, the bandwidth matrix H can be diagonalH=diagh12,…,hl2, or proportional to the identity matrix H=h2I. Thus, we havef(ϕ)=1nhl∑i=1Kϕ-ϕih. We can use a radially symmetrical kernel that satisfies K(ϕ)=Ck,lk(∥ϕ∥2), where Ck,lis a normalised constant that enables K(ϕ) to be integrated to 1. As a result,(24)fh,k(ϕ)=Ck,lnhl∑kϕ-ϕih2.When the Snake settles, the intensity histograms over two neighbouring iterations will be similar. If this occurs, the Snake possibly stops moving, resulting in unchanged density estimations in this circumstance: ▽f(ϕ)=0. Therefore,▽f(ϕ)=2Ck,lnhl+2∑(ϕ-ϕi)k′ϕ-ϕih2=0. Introducing G(ϕ)=−k′(ϕ), we have:(25)▽f(ϕ)=2Ck,lnhl+2∑(ϕ-ϕi)Gϕ-ϕih2=2Ck,lnhl+2∑i=1nGϕ-ϕih2·∑i=1nϕiGϕ-ϕih2∑i=1nGϕ-ϕih2-ϕ=0.The mean shift is the last term of the right-hand side of Eq. (25), which can be further simplified as follows:(26)mh,G(ϕ)=12h2C▽fh,k(ϕ)fh,G(ϕ),where fh,G(ϕ) has a similar form to that of Eq. (24) but uses G instead of h. Referring to Eq. (22), we have(27)mh,G(ϕ)≈ckd¯(t),which indicates that the minimisation of mean shift is also equivalent to the minimisation of the mass density function of Eq. (22) (ckis a scalar). This mean shift procedure determines the grouping of the image points in the whole image domain, whilst having the benefit of efficiently reaching the convergence. Mean shift is parameter-free and its kernel can be modified so as to adapt to different applications. Consequently, when implementing Eq. (16), we include the computation of mean shift during each iteration for the region surrounded by the evolving boundary.Fig. 4illustrates that, as the iteration proceeds, the GVF, a non-conservative force based on the Helmholtz theorem, successfully approximates boundary concavities and is capable of topological transformation in a certain way. We also observe that the intensity histograms of the region outlined by the evolving contour become stabilised after a number of iterations. The mean shift will reach a minimisation that is evolutionarily stable, which affects the settlement of the Snake through the varied λ (see Eq. 15). Without this mean shift term for the regularisation purpose, the GVF would drive the Snake to continuously shrink and cause over-segmentation in this particular example.Algorithm 1Proposed mean shift based GVF image segmentation (MSGVF) algorithm.1: Initialise the contour and the corresponding parameters2: for Iterations i=1:m (m is normally larger than 500) do3:Employ the classical Snake (i.e. Eq. (2)).4:Compute the mean of the intensity histogram of each region surrounded by the evolving contour.5:Obtain the difference of the two means in two neighbouring iterations.6:Introduce the above difference into Eq. (22).7:Substitute Eqs. (19)–(22) and (26) into Eq. (16).8:Calculate λ using Eq. (15).9:Evaluate the left hand side of Eq. (16) for the differences over two consecutive iterations.10:Iterate steps 3–9 until Eq. (17) is satisfied or the difference between two consecutive iterations <0.001.11: end forThe proposed Mean Shift based GVF algorithm is shown in Algorithm 1. Looking at the energy function shown in Eq. (16), even though one of the two functionals converges, Eq. (16) can still be further optimised for a better settlement. The convergence properties of the energy function therefore can be divided into two parts.First, we examine the case of mean shift. Assume thatS⊆Rd,▽fh,k:S→Rand have continuous derivatives of 2nd order. ∀ηt∈S and ▽2Fh,k(ηt) (t=1,2,…) is a negative definite matrix. Fh,k(ηt) can be expanded using the Taylor series theorem given η=ηt+ξtdt∈S:(28)Fh,k(ηt+ξtdt)=Fh,k(ηt)+ξt▽Fh,k(ηt+θξtdt)T,where 0<θ<1. Let φ(θ)=λt▽Fh, k(ηt+θξtdt)Tdt. We then have [49]: limθ→0φ(θ)=ξt▽Fh,k(ηt+1)T▽Fh,k(ηt)>0. The derivative of φ(θ) is φ′(θ)=(ηt+1−ηt)T▽2Fh,k(ηt+θξtdt)T(ηt+1−ηt)<0. Therefore, φ(θ) is monotonically decreasing, ∀θ(0,1). This leads to Fh,k(ηt+1)>Fh,k(ηt). Hence, Fh,k(ηt) is strictly monotonically increasing and convergent, resulting inlimFh,k→Fh,k(η¯)=0, whereη¯∈S[49].Second, we investigate the convergence of the left hand side of Eq. (16), assuming that mean shift has reached its minimisation after a certain number of iterations. Referring to [50], one has(29)L(u+v)-L(v)=[μ|▽u|2+2μ▽v·▽u+|▽f|2|u|2+2|▽f|2(v-▽f)·u]+υ,where v+u∈S and υ→0 due to the slight variation in the mean shift iteration. Given the Gâteaux variation of the functional as∊L(v;u)=limρ→0L(v+δu)-L(v)ρ, we then have:L(v+u)-L(v)-∊L(v;u)=μ|▽u|2+|▽f|2|u|2+υ⩾0, which indicates that the left hand side of Eq. (16) is convex.To fully evaluate our proposed MSGVF algorithm in terms of the initialisation invariance and convergence accuracy we use a set of 100 dermoscopic images (30 invasive malignant melanoma and 70 benign) obtained from the EDRA Interactive Atlas of Dermoscopy [51] and the dermatology practices of Dr. Ashfaq Marghoob (New York, NY), Dr. Harold Rabinovitz (Plantation, FL) and Dr. Scott Menzies (Sydney, Australia). The benign lesions include nevocellular nevi and dysplastic nevi. Manual borders were obtained by selecting a number of points on the lesion border, connecting these with a 2nd-order B-spline and finally filling the resulting closed curve. Three sets of manual borders were determined by expert dermatologists and serve as a ground truth for the experiments.In addition, the algorithm was evaluated on a set of 40 retinal images obtained from the DRIVE database [52]. These images have been randomly selected from a screening database of 400 diabetic subjects aged 25–90. 33 of the images do not show any sign of diabetic retinopathy while in seven signs of mild diabetic retinopathy are apparent. Each image is a true colour image of 768 by 584 pixels. The field of view of each image is circular with a diameter of approximately 540 pixels.In our current implementation, the colour dermoscopic images are converted to grayscale using the CCIR 601 standard ( Luminance=0.2989×Red+0.5870×Green+0.1140×Blue). Colour information may be used in the future to improve the results. In the experimental evaluation, we used a PC with Intel (R) Core (TM)2 CPU (2.66GHz) and 2GB RAM. The algorithms we compare are the classical GVF algorithm [22], level set segmentation [10] (LS), mean shift constrained GVF (MGVF) [24,38,39] and the proposed MSGVF algorithm. For the two GVF based methods, the parameters have been set to: α (tension of the Snake)=0.05, β (rigidity of the Snake)=0.0, γ (step size in one iteration)=1.0, and κ (external force weight)=0.6. These parameters have been chosen due to their best resulting outcomes from these specific datasets.In this sub-task, the evaluation consists of four parts. First, the four algorithms are evaluated using the dermoscopic images where the lesion areas possess smooth and clear edges. This is the easiest case in the evaluation. Second, the performance of the overall algorithms is investigated in the presence of irregular edges in the lesion regions. This examination will bring certain challenges in terms of the algorithms’ capability in these “noisy” environments. Third, we examine how these schemes perform if the edges of the lesion areas look ambiguous. This test is more rigorous than the above tests in the way that a segmentation algorithm needs to effectively locate a vague boundary before the segmentation procedure starts. Finally, we evaluate the performance of the different algorithms (i.e. GVF, MSGVF and level set) using changed initial contours.In the first test, the various algorithms are evaluated in the presence of smooth and clear edges. Image examples of the experimental results are illustrated in Fig. 5. In general, the algorithms obtain similar outcomes. However, taking a closer look, we can observe that the proposed MSGVF algorithm has a better fit to the ground truth than the classical GVF method. For example, the 2nd and 3rd columns of Fig. 5 illustrate that the classical GVF algorithm leads to worse settlements, compared to the proposed MSGVF algorithm. Also, it can be noticed that the level set algorithm causes a significantly misplaced boundary on the first image of Fig. 5.In the second test, the lesion edges have irregular shapes that make accurate segmentation more difficult as the energy functions used in the iterations of these algorithms have to make more effort to handle various saddle points in the optimisation. Exemplar results for this group of images are presented in Fig. 6. We observe that MSGVF has the most consistent outcomes compared to the other methods. The classical GVF technique leads to some spikes on the final settlements as the evolution of the contour struggles to capture the curvatures. For columns 2 and 3, it is clear that the level set and MGVF methods exhibit difficulties in handling concave shapes. In contrast, the proposed MSGVF algorithm is successful in driving the contour to follow these shapes.In the third test group, the skin images have ambiguous edges where a segmentation algorithm needs to “define” a more clear boundary in the first instance. Examples of this group are illustrated in Fig. 7, together with the obtained segmentations. The classical GVF algorithm leads to local convergence and numerous spikes along the final contours. Columns 1 and 4 of the level set method show that this approach is not successful in capturing the geometric deformation in the images, compared to the proposed MSGVF algorithm.Finally, we investigate the case where the starting contours are changed before segmentation is performed. Two sample images are given in Fig. 8. It is observed that the proposed MSGVF algorithm has the most consistent and accurate segmentation results, whereas the other two methods lack this consistency, leading to failed converge onto the correct boundaries.As ground truth information is available for the complete dermoscopic image set, we can also evaluate the various algorithms in a quantitative form. For each image segmentation we record the number of True Positives TP (the number of pixels that were classified both by the algorithm and the expert as lesion pixels), True Negatives TN (the number of pixels that were classified both by the algorithm and the experts as non-lesion pixels), False Positives FP (the number of instances where a non-lesion pixel was falsely classified as part of a lesion by an algorithm) and False Negatives FN (the number of instances where lesion pixels were falsely classified as non-lesion by an algorithm). From this we can then calculate the sensitivity SE (or true positive rate):SE=TPTP+FNand the specificity SP (or true negative rate):SP=TNTN+FP.Table 1gives the sensitivity and specificity obtained by all algorithms over the image examples shown on Figs. 5–7 and compared to all three ground truth segmentations (median SE and SP based on all three manual segmentations are reported). It is observed that the proposed MSGVF has the highest sensitivity and specificity values, indicating the best segmentation capability. In Table 2we show the sensitivity and specificity obtained by all algorithms over the entire dermoscopic database and compared to all three ground truth segmentations (median SE and SP based on all three manual segmentations are reported). It can be seen that the proposed MSGVF performs significantly better with an median sensitivity of 86% while the other algorithms achieve a sensitivity of less than 81%. In addition, MSGVF sustains more consistent results as indicated by the lowest standard deviations of both sensitivity and specificity. As specificity is fairly similar for all algorithms, we can conclude that MSGVF provides the best segmentation on the given dataset.We perform the evaluation on this dataset in two parts. First, the classical GVF, level set segmentation and our proposed MSGVF algorithms are evaluated using the retinal images where the optic disc (OD) is clearly visible from the observer’s point of view which represents the simplest case in our evaluation. In addition, the performance of the algorithms is investigated in the presence of vague optic discs in the retinal images. These examinations allow the algorithms to be fully evaluated in different noisy environments. Second, we examine how the algorithms perform if the initial contours are varied. This is a rigorous test that fails a segmentation algorithm if it does not work in a consistent and stable manner.Examples of the first test are illustrated in Fig. 9. As can be seen, for all these images, the proposed MSGVF algorithm provides consistently accurate results compared to the other two algorithms. This can be attributed to the computation of mean fields in the domain of the proposed approach, which dynamically balances internal and external energy forces during the contour evolution. The poor performance of the classical GVF, MGVF and level set algorithms is due to the distraction of the blood vessels nearby the optic disc.One of the main challenges in image segmentation is whether or not the performance of a segmentation algorithm can be kept consistent for different initialisation circumstances. To validate this, we randomly specify the starting contours for the involved images. This is followed by the regular routine of the algorithms. Fig. 10demonstrates that despite varied initial contour position, the resultant segmentation borders are visually indistinguishable. When the initial contour is relatively far from the actual one, three approaches obtain similar segmentation results but it is clear that the proposed MSGVF algorithm has more consistent outcomes than the other algorithms.Table 3illustrates that the proposed MSGVF algorithm has the best specificity and sensitivity, compared to the other algorithms. It is worthy to point out that MGVF and level sets approaches lead to similar sensitivity results, both of which are better than that of the classical GVF. It is also observed that all of the tested algorithms share approximately the same specificity results (0.99–1.00). This indicates that all of them correctly exclude the areas that do not belong to the real regions of interest. To better measure the similarity between a segmented region and the ground truth, especially in the presence of a small segmentation area, we here apply an XOR operation. This XOR operation is defined as a ratio between the non-overlapped area and the size of the ground truthed segmentation region. The smaller XOR value is, the higher similarity between the segmentation and the ground truth is achieved. The last column of Table 3 shows that the proposed MSGVF algorithm has the least dissimilarity.

@&#CONCLUSIONS@&#
In this paper we have presented a novel variational framework for image segmentation. Both the accuracy and robustness of the proposed MSGVF algorithm have been validated against competing approaches including classical GVF and level set. Unlike these state-of-the-art techniques, the proposed method is fairly accurate as it obtains an optimal solution during the iterations for energy minimisation. The proposed algorithm integrates the classical GVF term with a mass density function. The final solution towards this integrated functional is based on a numerical optimisation procedure with the support of mean shift estimation.The main drawback of the proposed algorithm is that it involves a large amount of computation to achieve convergence. While it has been shown that numerical convergence of the evolving contour is guaranteed, the solution-rendering process is rather time consuming. An example of time consumption of different algorithms for a single image is illustrated in Table 4. Therefore, future work is directed towards reducing the complexity of the computation by optimising the implementation whilst using gradient descent methods.