@&#MAIN-TITLE@&#
Estimating the size of polyps during actual endoscopy procedures using a spatio-temporal characterization

@&#HIGHLIGHTS@&#
The approach segments a polyp by propagating an initial manual delineation.Polyp segmentation is performed by a combination of motion and appearance features.A defocus strategy estimates the camera distance and the actual polyp size.Four experts and the method did not show significant differences in endoscopy.The approach is robust to different types of noise and can be used in real scenarios.

@&#KEYPHRASES@&#


@&#ABSTRACT@&#
Colorectal cancer usually appears in polyps developed from the mucosa. Carcinoma is frequently found in those polyps larger than 10mm and therefore only this kind of polyps is sent for pathology examination. In consequence, accurate estimation of a polyp size determines the surveillance interval after polypectomy. The follow up consists in a periodic colonoscopy whose frequency depends on the estimation of the size polyp. Typically, this polyp measure is achieved by examining the lesion with a calibrated endoscopy tool. However, measurement is very challenging because it must be performed during a procedure subjected to a complex mix of noise sources, namely anatomical variability, drastic illumination changes and abrupt camera movements. This work introduces a semi-automatic method that estimates a polyp size by propagating an initial manual delineation in a single frame to the whole video sequence using a spatio-temporal characterization of the lesion, during a routine endoscopic examination. The proposed approach achieved a Dice Score of 0.7 in real endoscopy video-sequences, when comparing with an expert. In addition, the method obtained a root mean square error (RMSE) of 0.87mm in videos artificially captured in a cylindric structure with spheres of known size that simulated the polyps. Finally, in real endoscopy sequences, the diameter estimation was compared with measures obtained by a group of four experts with similar experience, obtaining a RMSE of 4.7mm for a set of polyps measuring from 5 to 20mm. An ANOVA test performed for the five groups of measurements (four experts and the method) showed no significant differences (p<0.01).

@&#INTRODUCTION@&#
Colorectal cancer is the seventh most likely cause of death worldwide [1] and frequently asymptomatic illness characterized by a set of malign polyps along the digestive tract [2,3]. Typically, this disease is discovered during an endoscopy procedure, in which case the polyp size is used as the main endoscopic sign that supports the decision of an immediate resection, i.e., if the polyp is smaller than 10mm [4,5], it is removed, otherwise a sample is sent to pathology and the procedure is re-programmed for an extirpation [2,3,5]. Usually, the polyp size is estimated by measuring the lesion with a linear colonoscopy probe or by using the aperture of the endoscopy forceps as a repair for comparison [6]. This estimation is a very difficult task, highly subjective and dependent on the expert training [7]. In addition, several technical problems may arise during the procedure, such as: (1) optical distortion (Barrel's effect), (2) difficult handling of the endoscope because of the bowel tone and (3) exacerbated physiological conditions like increased motility or secretion [7]. Current advances on video processing [8–10] open up actual possibility of identifying polyps during endoscopy, with some potential advantages, namely: (1) real time estimation, (2) less-invasiveness, i.e., no additional tool is needed, (3) low cost procedure, and (4) a lesion characterization that might be used as support to the diagnosis. However, developing automatic approaches for estimation of polyp size is challenging because of the high variability of both the endoscopy procedure and the polyp shape [11,12], interference light patterns due to the bowel motion and blurred captures because of the varying illumination conditions [7].Current approaches far proposed for segmenting and estimating the polyp size, use features derived from their geometry, appearance and size but difficulties in estimating these parameters limit the accuracy of these methods [13]. Aiming to delineate the polyp, Liu et al. [8] simulate a geometrical 3D intestinal tract, computed from a flow deformation map that matches a set of salient points from consecutive frames. Such method results computationally expensive and prone to errors because the salient points are hardly correlated. This strategy only predicts the presence/absence of the polyp, requiring an initial manual intervention. In [9], a per-frame polyp shape is estimated by using a set of classical geometrical and color descriptors, a strategy that fails under non controlled illumination conditions. In contrast, Bernal et al. [10] approximate the polyp shape by using per-frame static features that must follow a polyp appearance model. This characterization may fail if the polyp is blurred in the endoscopy video, as usually observed in real scenarios. For estimating the polyp size, Chadebecq et al. [7] introduced a prior RoI bounding the polyp and tracked the lesion using a temporal rigid transformation. Afterward, an infocus blur allowed a RoI size estimation. However, in real conditions the camera movements may be so rapid that the RoI easily losses the polyp.Recent strategies involve the fusion of video-endoscopy with ultrasound images.Nevertheless, such echo-endoscopy device is mainly indicated in case of extramural polyps, i.e., it makes possible to measure advanced stages of the polyp and its use is highly expert dependent [5]. Other strategies include the virtual endoscopy from CT images [14–16], a 3D reconstruction that requires long exposition to ionizing radiation, report low sensitivity rates [15–17] and is purely diagnostic and polyps finally must be removed during an endoscopy procedure.The main contribution of this work is a semi-automatic method that delineates the polyp and estimates its size in a video sequence, using a local spatio-temporal characterization and an automatic defocus strategy. In this approach, an initial manual delineation in a single frame is propagated using a per-pixel motion descriptor built while the camera is moving, assuming only a statistical dependence with the precedent frame. An additional Bayes strategy couples the per-pixel motion descriptor with prior motion information, approximating the shape during occlusion phases. The polyp size is then estimated from the resulting polyp delineation, using a focused estimation of the whole sequence with a calibrated camera model. This paper is organized as follows. In Section 2 describe the proposed strategy, in Section 3 present the evaluation and result of method, in Section 4 is the discussion of proposed approach and in Section 5 the conclusions and the future work.The present strategy segments, tracks and measures polyps during an endoscopy procedure. An initial manual polyp delineation in the first frame captures the main features to be used. This characterization and the motion history endoscopy coarsely follow the polyp in the sequence. Afterwards, a classical second order Kalman filter, a Bayesian tracking strategy, is used to refine the polyp segmentation, obtained from the spatio-temporal characterization. Once a polyp is identified and segmented, the polyp size is computed using an offline depth defocus strategy. The pipeline of the proposed approach is illustrated in Fig. 1and further described in the following subsections.In general, radial endoscopy distortion produces non-linear incremental deformations from the optical center to the outer regions, affecting the object relative size and position [18,19]. The wide-angle lens distortion (barrel's effect) was corrected by estimating the camera parameters using a bank of artificial images (see Fig. 1c). Assuming an orthogonal coordinate system, every point in the image spacexis related to the real worldx˜by a pinhole model defined asx=f/zx˜, where f is the focal length and z the distance from the object to the camera lens. This model estimates the focus camera length, the scale factor, the distortion coefficient and the optical center point. This nonlinear distortion was approximated by power series and corrected asrn=rd1+k×rd2, being k the radial distortion coefficient and rdthe image with the corrected distortion.A polyp is an intestinal protuberance whose appearance may be easily confounded with the surrounding tissues, leading most segmentation procedures to fail. The proposed approach starts by an expert delineation of the polyp contour in the first frame to capture specific polyp features. The polyp contourXtis represented as a parametric curve defined as:Xt=xti=0n,(x¯,y¯), wherexti=0nis a set of n points contouring the polyp with its centroid defined in(x¯,y¯). Such delineation defines a neighbour RoI around the lesion, the RoItwith size {RoIt=Xt+ξ}, being ξ a tolerance value. Afterwards, the histogram of the whole sequence was equalized and a Gaussian filter, with σ=0.7, was applied to remove the granular noise.During an endoscopy navigation, the expert always tries to track the polyp with translational movements, attempting to generate a depth perception by amplifying the motion of nearby structures11Classically known as motion parallax (right-left movements) [20] and kinetic depth perception (rear-front movements) [21].. Using a background subtraction strategy, the proposed approach estimates the region with more motion, within which the polyp shape is approximated by those pixels with the largest temporal variance [22]. For doing so, a per pixel history motion Mt(x, y) (reference model), storing those pixels that are relatively motionless and correspond to the background, is first calculated as:(1)Mtx,y=Mt−1x,y+signItx,y−Mt−1x,y,where Itis a particular frame at time t. A likelihood function Δt(x, y) measures the instantaneous pixel motion at time t w.r.t. the background history motion, being:(2)Δtx,y=Mtx,y−It(x,y).The lesion is then the set of pixels with a relevant motion defined by the bidirectionally likelihood function, i.e., in the forward and backward temporal directions of the whole video-sequence (causal and anti-causal analysis). The bidirectional computation of the motion pixels recovers the lesion at each time as:(3)Δtx,y=atΔtforwardx,y−1−atΔtbackwardx,y,whereα=t/Nis a temporal weight parameter. Finally, moving pixels that better represent the polyp shape are selected by simple thresholding the estimationΔtx,ywith a learned scalar parameter τ yielding the motion segmentation as:(4)Sbtx,y=Δtx,y≥τThe initial position of the RoItthat bounds the polyp delineation is then propagated to the rest of the image space and motion history sequences. For doing so, the motion history is correlated for every pair of consecutive frames [23], as:(5)RoItx,y=argmaxRoIt∑i=0(n−1)∑j=0(m−1)Δti,j×RoIt−1x−i,y−iwhere RoIt(x, y) is an estimation of the polyp location that corresponds then to that maximally correlated RoI.Such RoI in the motion history space is mapped to the image space, where a minimal per-pixel Euclidean distance w.r.t. the precedent RoIt−1, allows to obtain an additional polyp segmentation Sit(x, y), the intensity segmentation.Then, an improved segmentation is obtained by fusing the two mentioned segmentations as the intersection of the intensity Sit(x, y) and motion Sbt(x, y) (defined in the previous subsection):(6)Zt=Sitx,y⊕Sbtx,yAdditionally, a classical morphological operator removes the remaining noise, basically groups of isolated polyp regions. Finally, the obtained segmentation is transformed to a polar space, where a simple smoothing preserves the global shape.During an actual endoscopy procedure, a polyp may be missed because of some abrupt camera motions or presence of some digestive fluid that might partially occlude the intestinal tract. With a proper frame-rate capture, it is reasonable to assume a relatively smooth polyp motion, even when the polyp is partially occluded.A Bayesian strategy estimates and tracks the polyp, modeling the probabilityp(Xˆt|Zt)of the state of the polyp delinationXˆtat time t, given the spatio-temporal observationsZt=Z1,…,ZN. This model is assumed markovian, i.e., the current state of the system stores the relevant information. Such Bayesian strategy requires a model of the dynamics p(Xt|Xt−1) and a likelihood function p(Zt|Xt) that maps the estimated polyp to the spatio-temporal space. Once this information is available, the polyp delineation at a particular state, is calculated in two steps:-Prediction: A particular state Xtis computed by updating the previous beliefXˆt−1, after a prediction given by the Chapman–Kolmogorov equation:(7)Xˆt=∫pXt|Xt−1Xˆt−1dXt−1Update: The predicted belief Xtis adjusted after observations:(8)Xt∝XˆtpZt|XtFor the sake of computational efficiency, a second order Kalman filter models the polyp delineationXˆtby using the first and second statistical moments asXt∼Nμt,Σt2, where μtis the mean distribution andΣt2is the covariance matrix of the state t. This Kalman estimator is computationally optimal because it linearizes the system with a first order Taylor series expansion.A polyp size is estimated from the obtained temporal segmentation at a fixed depth position of the camera, as a function of the focused image22A well-known psychophysical theory states that the distance to the camera is a function of the image blur [24].and the pinhole camera parameters (see in Section 2.1).The depth was herein estimated by a defocus strategy [7] that assumes each frame is contaminated with an unknown Gaussian blur with standard deviation σo, proportional to the object distance to the camera. This unknown Gaussian blur is estimated by convolving the image with a known Gaussian blur and computing the difference between gradients of the original (unknown blur) and blurred (known blur) images. This gradient ratio Rtis proportional to the unknown standard deviation asσto=1/R2−1σtb, where σbis a known standard deviation of a blurred Gaussian.In an off-line posterior training step, the blur coefficients, a set of correspondences between the blur levels of a phantom image33An artificial grid phantom was adapted for this task.and actual camera depths (see in Fig. 2(a)), are computed. A single blur coefficient is then associated to the infocus breakpoint image IBof-line (the clearer cut-frame) and serves as a reference depth since this is the minimum estimated blurring with a unique depth correspondence. Such relationship – the blur coefficients – was herein used within the endoscopic RoItto estimate the unblurred polyp by computing the corresponding infocus RoI breakpoint. The unblurred polyp size (ϕ) is then estimated from the segmentation previously obtained.The dataset herein used is composed of a set of 16 endoscopy video-sequences captured using an Olympus EVIS EXERA (GIF-1TQ160) gastrovideoscope device, provided with a field of view of 140° and a focal length of (357.3, 325.5). Each sequence was recorded in color, with a spatial resolution of 720 per 480 pixels and a temporal resolution of 30 frames per second. Two different groups of videos were captured for training and evaluation. The first dataset is composed of 6 video-sequences that were captured under controlled conditions using an artificial phantom grid superimposed to a set of images captured at different angles, estimating thereby the intrinsic and extrinsic camera parameters. The depth function was trained with captures of the artificial phantom grid, as illustrated in Fig. 1(c). The grid is placed at different depth distances, using a custom platform that is displaced in steps of 1mm, with a maximum distance of 30mm. Additionally, as shown in Fig. 3, a tubular structure emulated the digestive tract while a set of spheres of known size, the polyps. Four navigations within this structure were recorded to test the proposed approach in controlled conditions. The second dataset included real endoscopic procedures and presence of polyp lesions. A total of 10 video-sequences were captured and four gastroenterologists annotated the videos, segmenting the polyps and estimating their size.The performance of the proposed approach was assessed in two different tasks: segmentation and estimation of the polyp size. Four expert gastroenterologists delineated and estimated the polyp size in phantom and real endoscopy sequences.Fig. 4illustrates the segmentation results in actual endoscopic videos. The yellow contour stands for the ground truth delineation. In the second row, the red polyp delineation is computed using an alternative tracking strategy introduced as a baseline, the classical exponentially weighted moving average EWMA [25], for which an actual polyp delineation is propagated along the sequence using the Bhattacharyya coefficient and a set of exponentially decreasing weights obtained from previous frames. Despite this strategy takes into account the motion history, and the polyp is relatively well localized within the analysis RoI, the method misses polyp changes resulting from abrupt camera movement, leading to a wrong segmentation. In contrast, in the third row, the blue delineation is obtained with the proposed approach, showing a reliable overlap during those periods with a relatively slow motion. When the camera abruptly moves, the polyp appearance and size result modified, but the proposed approach follows the lesion more accurately than the tracking observed with the EWMA.Two quantitative metrics were used for assessing the segmentation task: the Dice coefficient (DSC) and the Hausdorff distance (HD). The DSC(A, b) is2(A∩B)/A+B[26], where A and B represent the obtained polyp area and the expert ground truth delineation, respectively. The Hausdorff measure H(A, B) [27] computes the maximum distance between two sets of points as max(h(A, B), h(B, A)) andhA,B=maxa∈Aminb∈Ba−b22. In this case, each set of points represents the polyp delineation at each frame. This measure allows to indirectly assessing the compactness of the segmentation since outliers are penalized. In videos captured within the artificial tubular structure (see in Fig. 3) a DSC of 0.96 was obtained when the phantom polyps were segmented, under controlled illumination conditions. Table 1shows the performance obtained by the proposed approach and the EWMA tracking when segmenting 1040 frames.An additional comparison with the Hausdorff Distance allows the compactness of the polyp delineation to be assessed, since this measure penalizes those pixels far from the ground truth, reporting in such a case a small value. Overall, the proposed approach outperforms the baseline in terms of overlapping and compactness (small Hausdorff distance). Some segmentation errors may be caused a certain polyp occlusion is present or in cases in which abrupt motions may change the appearance, size and shape of the polyp.Estimation of polyp size is a challenging task and high intra and inter expert variability has been reported in previous work. The variance of 12 expert measuring 240 gastric lesions was reported [28], obtaining a mean difference of 11±17mm. Additionally, a kappa coefficient of 0.4 and an agreement of only a 50.0% in series with three gastroenterologists were also reported [4]. In consequence, a second experiment aimed to evaluate the accuracy of the estimated polyp size. This task is much more challenging because of the multiple sources of distortion, but also more useful from a clinical standpoint since the gastroenterologist usually has no reference to establish an actual polyp size. Results are shown in Fig. 5, the blue lower and upper boxes stand for the spread of the estimated sizes reported by four experts (interquartile range), while the maximum and minimum values are shown as the vertical dotted lines. A total of four endoscopy phantom sequences, with 4 spheres whose size varied between 5 and 15mm, were evaluated. A part of the experiment required the gastroenterologist to simulate a procedure with similar gestures to an actual endoscopy, the camera moved abruptly and the navigation patterns were complex. In spite of the controlled conditions, experts showed a large variability in their estimation, as illustrated in Fig. 5, where yellow diamonds correspond to the ground truth measure per video. Interestingly, results evidence a very large variability of the obtained measures with respect to the reference. In average, the standard deviation was about ±5.4mm, confirming the high inter expert variability. In contrast, the proposed method (green circles) systematically achieved estimations much closer to the actual value. In this case, the method accomplished an accurate segmentation of the phantom polyps and also a proper estimation of the break focus frame.Overall, it has been traditionally acknowledged that the expert estimation is the most reliable information source in real endoscopy procedures and therefore the ground truth reference. Fig. 6shows the obtained estimations by the proposed approach (green circles) and the gastroenterologists (interquartile range). In average, the gastroenterologists showed a variance of ±3.63mm with respect to polyps that varied between 5 and 20mm. In case of real endoscopies, the mean expert estimation – the red line – amounts to the ground truth. As illustrated in Fig. 6, the estimated size of the proposed approach is within the range of variability observed for the group gastroenterologists and no significant differences were found when statistically evaluated (ANOVA test with p<0.01).The quality and fidelity of measurements obtained for any method is always affected by a noise. The quality of the estimation was herein weighted by the noise as the SNR-like measurement, using a logarithmic scale and measuring the difference between the expected control data and the predicted values. This SNR-like measurement was defined asSNR­like=10log10σ2/RMSE,where σ2 is the largest delineation variance among the group of experts and RMSE is the root mean squared error, the computed error of the proposed approach w.r.t. the ground truth estimation. Table 2shows the results obtained by the proposed approach in terms of this SNR-like and RMSE measures. In summary, the proposed approach achieves a gain of 37.48dB, indicating that the proposed approach estimates the polyp, with a high degree of confidence, within the interval defined by the estimations of the experts. Table 2 also reports the mean and the standard deviation of the error (RMSE), indicating a high accuracy of the estimation in artificial videos and size estimation within the interval defined by expert variability, in real videos.

@&#CONCLUSIONS@&#
