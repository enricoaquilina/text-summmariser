@&#MAIN-TITLE@&#
On the decisiveness of a game in a tournament

@&#HIGHLIGHTS@&#
We suggest a measure of how decisive a particular game is in a sport tournament.We use entropy-related concepts to assess the uncertainty around the final winner.We study the decisiveness of the 2012 UEFA European Football Championship games.We analyze the recent UEFA decision to expand the Euro from 16 to 24 teams.We show that the 16-teams format has to be favored over the 24-teams format.

@&#KEYPHRASES@&#
OR in sports,Applied probability,Uncertainty modelling,Game importance,Entropy,

@&#ABSTRACT@&#
In sport tournaments in which teams are matched two at a time, it is useful for a variety of reasons to be able to quantify how important a particular game is. The need for such quantitative information has been addressed in the literature by several more or less simple measures of game importance. In this paper, we point out some of the drawbacks of those measures and we propose a different approach, which rather targets how decisive a game is with respect to the final victory. We give a definition of this idea of game decisiveness in terms of the uncertainty about the eventual winner prevailing in the tournament at the time of the game. As this uncertainty is strongly related to the notion of entropy of a probability distribution, our decisiveness measure is based on entropy-related concepts. We study the suggested decisiveness measure on two real tournaments, the 1988 NBA Championship Series and the UEFA 2012 European Football Championship (Euro 2012), and we show how well it agrees with what intuition suggests. Finally, we also use our decisiveness measure to objectively analyse the recent UEFA decision to expand the European Football Championship from 16 to 24 nations in the future, in terms of the overall attractiveness of the competition.

@&#INTRODUCTION@&#
Nowadays, major sport events regulate the life style of many people. Supporters, communities or even whole countries often stop any other activities when their teams are playing. All over the world, thousands of people regularly go to stadiums to attend sport competitions, while millions more follow them on television. It seems clear, however, that the popular craze for a given contest or game would depend on its importance. For instance, take the case of a tournament in which teams (or individual contestants) are matched two at a time, like in football (soccer), basketball or tennis. It seems natural to expect popular passion to be higher around games which might be decisive as to the final winner of the tournament, than around games which cannot dramatically change the eventual tournament outcome. In this paper, we define and investigate that notion of ‘decisiveness’ of a game in a tournament organized as described above.Comprehending and quantifying how decisive a game is within a tournament is important for many purposes. A game decisiveness measure should be a paramount component in a model aiming to explain the game attendance or television audience (Downward & Dawson, 2000; Jennett, 1984; Villa, Molina, & Fried, 2011), or even the game outcome (Audas, Dobson, & Goddard, 2002). Shortly before the game, its decisiveness can also motivate the referee assignment, with the best referees assigned to the most decisive games. At the team level, it could also influence the team lines-up, as coaches may be tempted to experiment with new tactics on non-decisive games whose outcomes do not matter.More generally, the overall attractiveness of a competition can be quantified through the number of games expected to be decisive. A competition with very few potentially decisive games, with an eventual winner known very early in the competition, would not be very attractive to the public, unlike a competition with numerous potential twists and turns (Goossens, Beliën, & Spieksma, 2012). This observation can be important at the time of deciding about the design of a tournament (Scarf, Mat Yusof, & Bilbao, 2009), that is, parameters such as the number of teams competing, the schedule, the rules for ranking, and qualification/elimination or promotion/relegation when applicable. Given that a competition format with more decisive games would definitely be more attractive for viewers, increasing that overall decisiveness of games could then be a driving factor. Cairns (1987), Bojke (2007), Goossens et al. (2012) investigated that concept. Finally, for television broadcasters, decisiveness must also be an important element when making decisions about which games to broadcast (Forrest, Simmons, & Buraimo, 2005), as games with low stake do not attract viewers. Given the importance of television in today’s sporting events, in terms of broadcasting contract and advertisement return, this is also an important fact to take into account.Incidentally, this makes it clear that one should be able to assess the decisiveness of a game well ahead of time, in particular with some other games still to be played before that particular game. Indeed, television stations usually have to choose their games for broadcast in advance, and sometimes even before the tournament starts, in the case of major tournaments like the football FIFA World Cup or UEFA European Championship. In such a situation, the effective decisiveness of the game on the day will depend on the uncertain outcome of other games yet to be played, and is thus essentially random. We will then be talking about the expected decisiveness of a game. This expectation is to be defined with respect to a joint probability distribution for the outcomes of the games remaining to play, that should be properly devised. Estimating the probabilities of seeing a team winning or losing (or drawing, if allowed) on a given game has been the topic of a huge literature in sports statistics. In particular, for the case of football, various models were investigated in Reep and Benjamin, 1968, Maher (1982), Baxter and Stevenson (1988), Kuk (1995), Dixon and Coles (1997, 1998), Dyte and Clarke (2000), Karlis and Ntzoufras (2003, 2009), Tena and Forrest (2007), Brillinger (2008), Geenens (2010), Flores, Forrest, and Tena (2012). Assessing and analysing those probabilities is not the purpose of this paper, though. Here, we will just make use of previously derived outcome distributions or models when we will need them, and we will therefore assume that the probability distribution of outcomes for games to come is known.Now, the way the tournament is organized (what we called above the tournament design) is also expected to play a paramount role in the decisiveness of any of its game. Scarf et al. (2009), Scarf and Mat Yusof (2011) defined two fundamental tournament designs. The first one is the classical round-robin: each competing team plays every other team a fixed number of times, earning points according to their results (in football, typically a win is worth 3 points and a draw is worth 1 point), and the winning team is the one with the largest number of points at the end of the tournament (with particular rules to break ties). Most of the major national football leagues in Europe (e.g. English Premier League, Spanish Liga, German Bundesliga) are played according to this design, with each team playing all the others twice, once at their home field and once away. The second fundamental tournament design is the knock-out: games are played in round, and only competitors winning in round k take part in round k+1, the others being definitely eliminated. At the end, the winner is the winning competitor at the final round, that is, the only undefeated competitor. Grand slam tennis tournaments are typically built according to this design. In football this is also the case for most of the European domestic cup competitions, like the celebrated FA Cup in England.Many other major sport competitions are designed as hybrid between these two fundamental structures. So, the FIFA World Cup is currently organized in two stages: the first one being 8 parallel simple round-robins (called ‘groups’), each matching 4 teams with the best two progressing to the second stage, this one being a knock-out tournament starting with the 16 teams qualified from the first stage. Between 1996 and 2012, the UEFA European Championship was a similar two-stage tournament, except that only 16 teams took part. The first stage therefore consisted in 4 groups, of which the best 8 teams (2 per group) go to play the second knock-out stage. It has, however, been announced (Union of European Football Associations, 2008) that from 2016, 24 teams would take part in the final tournament, which has attracted a lot of criticism. Detractors claim that this will lower the level of the tournament and decrease its intensity. In Section 4, we investigate how this fundamental change in the tournament design would affect the decisiveness of its games and consequently its overall attractiveness.The paper is organized as follows. In Section 2, we review the related notion of game importance and we point out some important drawbacks of it. These justify the definition of a different quantity to measure how decisive a game is/may be. We define such a game decisiveness measure in Section 3 and show how it addresses the shortcomings of the game importance measure previously proposed in the literature. In Section 4 we investigate further that notion of game decisiveness in practice on two real competitions: the 1988 NBA Championship Series, also considered in Schilling (1994), and the UEFA European Championship 2012. Section 5 concludes.The notion of decisiveness of a game, as we think of it, is different to the concept of how important a game is in a tournament as it was addressed previously in the literature. Among others, some of the works cited in Section 1 use various simple game importance measures in their respective framework. In the case of a football tournament for instance, Audas et al. (2002) call a game important if it is still possible at the time of the game for either of the opponents to win the tournament, assuming that all other teams will draw in the rest of their games. With that definition, game importance is binary, and most certainly lacks of nuance. Jennett (1984) measures the importance of a game for a competing team as the inverse of the number of games they have still to win to be crowned winner; whereas, Downward and Dawson (2000) suggest a slight refinement of the previous idea making use of the number of extra points necessary for a team to win the tournament. Goossens et al. (2012) define the importance of a match m asIm=2nmAm2,where Amis the total number of teams still competing for the final victory of the tournament at the time of the match, and nmis the number of teams in match m still in competition (nm=0, 1 or 2). A drawback of this is that it does not take into account the temporal position of the game in the tournament. Specifically, consider the game matching the last two teams remaining in competition, which should indeed be quite important. Then, Im=1, but this at any time in the competition. However, this game should be much more important if it was one of the very last of the competition, than if many other games were left for those two teams, with many occasions to catch up.Also, it does not take into account the strength of the matching teams. At the same stage of the competition (thus with the same number Am), a game matching two underdogs still in competition (but if early enough in the tournament, all teams are usually still alive) would be as important as a game matching the greatest two favourites of the competition. It seems, however, clear that the latter is more crucial than the former. Scarf and Shi (2008) reflects this by saying that some matches may only be important “on paper”, meaning that even if the two competing teams are still technically in competition at the time of the match, it is very unlikely that they will really be running for the final victory until the end of the tournament. This is actually where ideas based on probabilities come in. It turns out that the most widely used probability-based importance measure for a game so far has been the Schilling importance.Consider a tournament made up of n games altogether. The Schilling importance (Scarf & Shi, 2008; Schilling, 1994) of game k (k=1,…,n) for team i when assessed right after game k0 (k0=0,…,k−1) is defined asSi,k0,k=P(Vi|Wi,k,Hk0)-P(Vi|Li,k,Hk0),where Viis the event that team i is the eventual winner of the tournament, Wi,kand Li,kare the events that the outcome of game k is favourable or unfavourable to team i, andHk0represents the whole history of all matches played in the tournament up to and including game k0. Note that we define the case k0=0 as the prior situation, that is, right before the tournament starts. The importance of game k for team i is thus the difference in probability, assessed after game k0<k, of team i being the eventual winner whether the outcome of that particular tie is favourable or unfavourable to them. It must be stressed that the importance of a game can basically be defined this way even for teams not taking part of that game: the result of a particular tie can be favourable to a third team (it increases their probability of winning the tournament) or unfavourable to them (it decreases that probability). As a result, the above conditional probabilities of the third team winning the tournament are well defined, and so is the Schilling importance of that game for the third team. This definition has indeed some intuitive appeal, which explains its popularity.We can, however, point out some drawbacks. The first thing is certainly that it is not totally suitable for football tournaments, where draws are common. Indeed, it is not clear whether a draw must be considered as a favourable or unfavourable result, and in fact it will all depend on the exact situation the team find themselves in. Of course, as suggested above, an outcome favourable (or unfavourable) to a team should be one which increases (or decreases) their probability of winning the tournament. However, assessing those probabilities without knowing beforehand what is considered as a favourable/unfavourable outcome seems quite tricky, if not impossible, in practice. We note that Scarf and Shi (2008) somehow elude the question, as they merely define a favourable outcome as a win and an unfavourable outcome as a loss (p. 2412). Not only does this not take a draw appropriately into account, seemingly assuming that it is a ‘neutral’ result (which is not necessarily so), but this is also against the initial idea that one should be able to define the importance of a given game for all the teams competing in the tournament, not only the ones playing it. Indeed, a team cannot win or lose a game that they are not playing, which drove Scarf and Shi (2008) to admit that “… in practice it [the Schilling importance] might only be calculated for those competitors playing [the] match …” (p. 2408). Note that in the initial paper, Schilling (1994) did not consider draws as possible outcomes, as he was mainly considering basketball. Also, he studied a very specific type of tournament with only two competing teams (‘best-of-seven’ series). In that tournament, any game is consequently played by all the participating teams, and the question of how important a game is for teams not playing was not relevant.Another important stumbling block of the Schilling importance, not specific to football, is its linear nature in the probabilitiesP(Vi|Wi,k,Hk0)andP(Vi|Li,k,Hk0). However, it is obvious that a game getting Schilling importance 0.1 is much more important for team i whenP(Vi|Wi,k,Hk0)=1andP(Vi|Li,k,Hk0)=0.9for instance, than whenP(Vi|Wi,k,Hk0)=0.2andP(Vi|Li,k,Hk0)=0.1. In the former case the game is as decisive as can be, for it may crown the final champion. Hence, it will most certainly imply a high level of popular craze. In the latter case the game will probably not change the proceedings of the tournament anyway. In fact, getting the probability of final victory of a team substantially closer to 1 is really what matters. A game whose outcome can result in that is evidently decisive, and we claim that this is this decisiveness of a game, and not its importance as measured by Schilling’s measure, that should be assessed and analysed in the situations mentioned in Section 1. In the next section, we define such a game decisiveness measure.First and foremost, we argue that a game is or is not decisive towards the eventual victory in the tournament. Consequently, a measure of how decisive a game is should be a global measure at the tournament level, not specific to a team: a game cannot be decisive for a team and not for others, unlike what has been said for the game importance concept. If the outcome of a particular game can potentially increase by a large amount the probability of a given team winning the tournament, then this would in all likelihood decrease the winning probability of the other teams, so the game would be globally decisive as to the eventual winner.Define pi,kthe probability that team i win the tournament given the whole history of all matches played in the tournament up to and including game k, that is, in the notation of Section 2,pi,k=P(Vi|Hk). Suppose there are N teams in the tournament. Right after game k, we have for the final victory the discrete probability distribution pk=(p1,k,p2,k,…,pN,k) whose entropy is given by(3.1)ek=-∑i=1Npi,klogpi,k,(where it is understood that pi,klogpi,k=0 if pi,k=0, in agreement with limp→0plogp=0). The entropy of a probability distribution, strongly related to the general concept of Shannon’s entropy (Shannon, 1948) in information theory, is a classical measure of the uncertainty contained in the distribution. The entropy is minimum and equal to 0 when one of the probabilities pi,kis equal to one (and consequently all the others are 0). In our case, this happens when the eventual winner of the tournament is known. The entropy is also monotonic, in the sense that the higher the entropy, the less certainty we have about the outcome. In particular, it is maximum when all probabilities pi,kare equal to 1/N, in such a case(3.2)ek=logN.Note that, in definition (3.1) and consequently in (3.2), the logarithm can be taken to whatever base is appropriate. Here the natural choice seems to be working to base N, so that the maximum entropy is then(3.3)ek=logNN=1.In effect, this choice just yields an automatic scaling of the entropy to between 0 and 1, but is not important as such. With this choice, an entropy equal to 1 corresponds, in our context, to a totally undecided tournament, with all the competitors equally likely to win it. Hence, the entropy as defined by (3.1) can be seen as a measure of the uncertainty as to the eventual winner prevailing in the tournament right after game k. We will call ekthe tournament entropy after game k.Although it is obvious from its definition, we stress that the entropy is not linear in the probabilities pi,k. Increasing one of the probabilities pi,kby a small amount but very close to 1 would result in a drop in the entropy more important than moving that probability by the same small amount around 1/N, for instance. This is in total agreement with our idea of how much decisive a game may be as to the final victory in the tournament.Finally, note thate0=-∑i=1Npi,0logpi,0, where pi,0 is the prior probability of team i winning the tournament (that is, before the start of the tournament), can be used as a measure of the competitive balance in the tournament, see Horowitz (1997), Borooah and Mangan (2012). This prior entropy is essentially deterministic, as it does not depend on games yet to be played. This is why we denoted it by a lower-case letter e0, and we will stick to this convention in the coming sections as well. We keep capital letters for denoting random quantities. In this definition, the probabilities pi,0 have to be estimated in some way, but as stated in Section 1, it is not the purpose of this paper to explain how to do that. We therefore assume that those probabilities, as well as any other probability distribution we might need, are known.Now, as a mere consequence of the above observations and definitions, we propose to define a decisive game as one whose outcome can dramatically change the tournament entropy. This can be an important decrease in the tournament entropy, when the outcome of the game isolates one of the candidates for the eventual victory with a probability of winning much higher than the others. On the other hand, we think that a game can also be regarded as decisive if it could result in an important increase in the entropy. This would be the case if a team was close to winning the tournament before the game but loses everything due to an under-achievement on the day. It therefore makes sense to define the decisiveness of a game as the expected absolute value of the difference in tournament entropy that it can generate.Specifically, the decisiveness of game k (k=1,…,n) is defined as(3.4)dk=E(|Ek-ek-1||Hk-1).Note that this expectation is taken conditionally on Hk−1, i.e., with all results known up to and including the previous game k−1. The tournament entropy after game k−1 is therefore known as well, and that is why we denote it by the lower-case ek−1, in contrast with Ek, the random tournament entropy after game k yet to be played. This measure dkis therefore the decisiveness of the game as assessed on the day of the game, or right before the game is played. The expectation is calculated with respect to the probability distribution of outcomes on game k, given Hk−1, hence we can write more explicitlydk=|ek(W1,k)-ek-1|×P(W1,k|Hk-1)+|ek(T1,k)-ek-1|×P(T1,k|Hk-1)+|ek(L1,k)-ek-1|×P(L1,k|Hk-1)with W1,k, T1,kand L1,kbeing the events that the home team (or team mentioned as ‘Team 1’, if the game is played on neutral ground) win, draw or lose on game k, andek(W1,k),ek(T1,k)andek(L1,k)are the resulting values of the tournament entropy after game k for the three possible outcomes. Again, note that we assume in this paper that the probabilitiesP(W1,k|Hk-1),P(T1,k|Hk-1)andP(L1,k|Hk-1), that we will subsequently call the probabilities of W/D/L, are known. Also, note that we automatically consider in this expression the possibility of a draw for the outcome of the game. For sports which do not allow draws, it is clear thatP(T1,k|Hk-1)≡0for all k and this definition remains consistent.From the definition (3.4) and the facts about entropy that we stated above, it is clear that a game having decisiveness 0 is a game which cannot change the tournament entropy whatsoever, i.e. a game whose result cannot bring any information as to the eventual winner. Typically, that will be the case for games matching two teams whose probabilities of final victory are both 0. On the other hand, as the tournament entropy always lies between 0 and 1, the maximum decisiveness a game can get is 1. This is possible only in very particular circumstances, for instance, in a very simple tournament matching only two teams of exact same strength and being decided on one single game. Before the game, the winning probability distribution is (1/2,1/2), which has tournament entropy 1 (totally undecided tournament). After the game, the winning probability distribution will be either (1,0) or (0,1), and in both cases the tournament entropy is 0 (the winner is known). Thus, the absolute difference in entropy that this game will generate is always 1, and its decisiveness is therefore also 1. Indeed, it is hard to imagine a game more decisive than this one.Now, as pointed out in Section 1, it is often important and necessary to quantify the decisiveness of a game well ahead of time. Given the previous definition for dk, it is natural to define the expected decisiveness of game k (k=1,…,n) when assessed right after game k0 (k0=0,…,k−1), asdk0,k=E(|Ek-Ek-1||Hk0).Note that in this case, both Ek−1 and Ekare random, for k0<k−1. If k0=k−1, then we obviously recover the definition of the decisiveness of game k: dk=dk−1,k. Another particular case of interest is when k0=0. This yields the prior expected decisiveness of the game, that is, d0,kis the expected decisiveness of game k assessed before the start of the competition. Using the usual properties of conditional expectations, it can easily be seen thatdk0,k=E(|Ek-Ek-1||Hk0)=E(E(|Ek-Ek-1||Hk-1)|Hk0)=E(Dk|Hk0).Hence,dk0,kcan also be seen as the expectation of the random decisiveness of game k, Dk, given the information available up to and including game k0. That is, the best prediction we can make for the decisiveness of the future game k at the end of game k0. The concept of game decisiveness and the related notions are investigated further through several examples in the next section.Schilling (1994) illustrated the idea of game importance using the 1988 National Basketball Association (NBA) Championship Series, played between the Los Angeles Lakers and the Detroit Pistons. NBA Finals are ‘best-of-seven series’ tournaments: the two teams play against each other for as many games as needed for one team to win four games (no draw is allowed, so each game must be won by one of the teams and there can be at most seven games in a series). Home ground advantage rules set games 1, 2, 6 and 7 to be played in Los Angeles and games 3, 4 and 5 in Detroit.From their regular season records, Schilling (1994) estimated the probability of LA defeating Detroit at home at 0.763 (thus, the probability of Detroit winning away in LA is 0.237) and the probability of Detroit defeating LA at home at 0.554 (thus, the probability of LA winning away in Detroit is 0.446). He also assumed that the outcome of each game was independent of previous outcomes.1As stated in Section 1, it is not the purpose of this paper to discuss the suitability of this probability distribution for game outcomes in the considered situation, and we will just use it as is.1We will call Team 1 the LA Lakers and Team 2 the Detroit Pistons. Thus,P(W1,k)is the probability that the Lakers win game k, andP(W2,k)=P(L1,k)is the probability that the Pistons win game k. The schedule of the games and the information at hand is summarized in Table 4.1.At the start of the tournament, both teams need 4 victories to be crowned. Simple binomial and combinatorial arguments give p1,0=0.774 and p2,0=0.226, which are the prior probabilities (before the series begins) of LA and Detroit winning the Championship. The prior tournament entropy is therefore e0=−0.774×log2(0.774)−0.226×log2(0.226)=0.7705, which is quite large. This reflects the substantial uncertainty prevailing in this type of competition, despite LA being significantly stronger than Detroit (according to the probabilities calculated in Schilling (1994)).Now, for illustrative purposes, we detail some of the calculations leading to measures of how decisive each game was expected to be in that tournament. If LA wins Game 1, they will need 3 wins for 4 wins for Detroit. Using combinatorial arguments similar to above, we then get p1,1=0.843 and p2,1=0.157, which has tournament entropy 0.6275. This is a difference in tournament entropy of 0.1430. If, on the other hand, Detroit wins Game 1, we get p1,1=0.554 and p2,1=0.446, which has tournament entropy 0.9917 (close to maximum, very high uncertainty as both probabilities are close to 1/2). This is a difference in tournament entropy of 0.2212. As LA were to win Game 1 with probability 0.763 and lose it with probability 0.237, the expected absolute value of the difference in tournament entropy generated by Game 1, that is, the decisiveness of Game 1, isd1=0.1430×0.763+0.2212×0.237=0.1615.Note that, for Game 1, the decisiveness d1 is equal to the prior expected decisiveness d0,1.In order to quantify the prior expected decisiveness of Game 2, we have to consider four scenarios:•LA won the first game and the tournament entropy is 0.6275 after it. Then,–LA wins the second game. One can then find p1,2=0.906 and p2,2=0.094, with tournament entropy 0.4500, i.e. a difference in tournament entropy of 0.1774. This scenario happens with probability 0.763×0.763=0.582 (by the assumption of independence between game outcomes).Detroit wins the second game. One can then find p1,2=0.640 and p2,2=0.360, with tournament entropy 0.9428, i.e. a difference in tournament entropy of 0.3153. This scenario happens with probability 0.763×0.237=0.181.Detroit won the first game and the tournament entropy is 0.9917 after it. Then,–LA wins the second game. One can then find p1,2=0.640 and p2,2=0.360 (same as in the second scenario above), with tournament entropy 0.9428, i.e. an absolute difference in tournament entropy of 0.0488. This scenario happens with probability 0.181.Detroit wins the second game. One can then find p1,2=0.276 and p2,2=0.724, with tournament entropy 0.8502, i.e. a difference in tournament entropy of 0.1415. This scenario happens with probability 0.237×0.237=0.056.Hence, the prior expected decisiveness of Game 2 isd0,2=0.1774×0.582+0.3153×0.181+0.0488×0.181+0.1415×0.056=0.1771.Now, given that Detroit won the first game, the decisiveness of Game 2, as measured on the day, isd2=0.0488×0.763+0.1415×0.237=0.0708.This effective decisiveness of Game 2 was actually lower than expected, because of the somewhat surprising result on Game 1. With Detroit ahead, none of the possible outcomes on Game 2 would give a decisive advantage to any team. Even a second win of Detroit would not have made them very close to eventual winning. It was expected to have LA ahead after Game 1. In that case, Game 2 would have been more decisive: a (likely) second win for LA would have been an important step for them to the final victory (probability of final victory above 90%), but even a Detroit win would have been decisive precisely because it would have prevented LA from making that important step.The prior expected decisiveness, the expected decisiveness and the decisiveness of all the games of the tournament can be computed exactly in the same way. Those values are given in Table 4.2. Italicized values are the decisiveness of each game on the day, bold values show the expected most decisive remaining game at each point in the tournament.Prior to the tournament, the most decisive game was expected to be the 5th one. Of course, as already stressed in Schilling (1994), a game cannot be decisive at all if it is not played. If played, Game 7 will definitely be as decisive as can be, but there is a substantial probability that Game 7 will not be played. On the other hand, Game 4 will always be played but will potentially be the decider only under very particular circumstances. Overall, Game 5 ranks as the best compromise between likelihood of being played and likelihood of being decisive. Note that Game 5 in a best-of-seven series is indeed, heuristically, considered the most important one by the NBA followers.The 5th game remained the expected most decisive one after Game 1 and Game 2. Now, since the series went to the maximum number of games, the decisiveness of each game dramatically increased toward the end of the tournament, obviously reaching its peak on Game 7. Actually, Game 7 became the expected most decisive game after Game 4, when it became most likely that Game 7 would be played. From this analysis, it is clear that our notion of game decisiveness sheds much more of a nuanced light on the tournament proceedings than the Schilling importance. For instance, in this simple tournament, the a priori Schilling importance can only take on two values, depending on which team play at home. Our prior expected decisiveness offers much more than that.Here we study the 2012 UEFA European Football Championship, whose structure is much more complex than that analysed in the previous subsection. The Euro 2012 finals were hosted by Poland and Ukraine in June 2012 and featured 16 nations, including the two host countries automatically qualified. The other 14 finalists were determined through a qualification phase contested by 51 European countries. As briefly mentioned in Section 1, these 16 competing nations were randomly2Seeding applied.2divided into four groups. The qualified teams and the four groups are shown in Table 4.3.Each group was a simple round-robin tournament, with 3 points awarded for a win and 1 point for a draw. The top two teams in each of the four groups3Some tie-breaking criteria applied when two or more teams were equal on points.3qualified for the second stage, which was a knock-out tournament with 3 rounds (quarter-finals, semi-finals and final). The exact schedule of the games was set before the tournament, and games of the first stage are shown in Table 4.4. The tournament design, in particular the order the games were played, obviously influences the decisiveness of those games, so we have scrupulously followed that schedule in our study.First we need a model for estimating the probabilities of Win/Draw/Loss for each game of the tournament. We fit a simple model based on the UEFA coefficient of the competing nations as of November 16, 2011 (end of the qualifying phase). This coefficient (see Table 4.5) is the basis of the official UEFA national team ranking, and should be reasonably representative of the strength of the competing teams during the tournament. For a given game, say k, the difference in UEFA coefficients between Team 1 and Team 2, say Xk, is therefore a good indication of how much stronger (or weaker, for negative values) Team 1 is. Of course, many other predictors could be considered to quantify the strengths of the competing teams, or any other information potentially affecting the likelihood of the different game outcomes. We chose to use the UEFA coefficient only to keep the model simple and tractable, the focus being on the decisiveness of the Euro 2012 games and not on these probabilities. In any case, it will be seen that this simple model is doing well at predicting game outcomes, so at this point there is probably no need for more sophisticated procedures.Now, estimating the W/D/L probabilities for a given game characterized by a UEFA coefficient difference x is actually nothing else but a regression problem. We used kernel smoothing, which is a popular nonparametric regression method (Wand & Jones, 1995). Given the effective results of the 31 games played during Euro 2012, the W/D/L probabilities were estimated by(4.1)πˆ(x)=πˆW(x)πˆT(x)πˆL(x)=∑k=131Kx-XkhZk(W)Zk(T)Zk(L)+∑k=131Kx+XkhZk(L)Zk(T)Zk(W)∑k=131Kx-Xkh+∑k=131Kx+Xkh.Here,Zk=Zk(W),Zk(T),Zk(L)t, where Zk∈{0,1}3 andZk(W)+Zk(T)+Zk(L)=1, is the vector of indicator variables representing the result of game k, k=1,2,…,31. Explicitly,Zk(W)=1if game k ended with a win of Team 1 and 0 otherwise,Zk(T)=1if game k ended with a draw and 0 otherwise, andZk(L)=1if game k ended with a win of Team 2 (i.e. a loss of Team 1) and 0 otherwise. As the games were played on neutral field,4We actually disregarded the fact that Poland and Ukraine played their games at home, assuming that they did not take advantage of that. As both teams were among the weakest of the competition and were quickly eliminated, this seems to be a reasonable assumption here.4the roles of Team 1 and Team 2 can definitely be reversed and we get the result of 31 ‘pseudo’-games with differences in UEFA coefficients equal to −Xk, k=1,…,31, hence the double sums in the numerator and denominator of (4.1). In that expression, K is a weight function (here the Gaussian density), and h is the bandwidth, that we took equal to 6.897 (selected by cross-validation, see (Wand & Jones (1995, Section 3.3))).Intuitively,πˆW(x),πˆD(x)andπˆL(x)are just weighted averages of the corresponding binary values in Zkcharacterizing the observed outcome of each game, with weights decreasing with the distance between x and Xk. Nonparametric estimation avoids any difficulty in postulating and verifying parametric assumptions on the functional shape of those probability functions, like logit/probit models whose usage is most of the time justified only as because it is customary. It is straightforward to see thatπˆW(x),πˆD(x)andπˆL(x)always belong to [0,1], as they are just averages of 0/1 values, and automatically sum to 1 for all x, as there is only one component of Zkequal to 1. This way of estimating the probabilities of W/D/L for each game is very similar to (actually, even simpler than) the model developed in Geenens (2010).Moreover, this model shows some interesting prediction power: predicting a game result (Win, Draw or Loss, from Team 1’s perspective) by its most likely outcome as per our model fitted on all but that game (cross-validation), we get it right in 16 out of 31 games, i.e. 51.6% (we considered second stage knock-out games decided by penalty shoot-out as draws). As a comparison, the parametric logistic model fitted in Scarf and Shi (2008) reaches a percentage of correct predictions of 40%, while the best predictive model of Goossens et al. (2012) predicts the right outcome for 47.1% of the games. Admittedly, these rates cannot be readily compared, as those models were fitted and assessed on other data coming from different tournaments. However, this still suggests that our simple nonparametric model is indeed doing a good job.The estimated probabilities of W/D/L in function of x, the difference in UEFA coefficient between the teams competing in a given game, are shown in Fig. 4.1. As expected, the probability of winning a game (top panel) increases along with a favourable difference in UEFA coefficient. For a difference in UEFA coefficient of 15 points for instance (i.e. one of the teams is much stronger than the other), the probability that the favourite team win is almost 60%, the probability that the underdog win is close to 20%, and the probability that the game ends with a draw (middle panel) is slightly higher than 20%. Interestingly enough, this probability of draw is roughly constant (around 22%) and does not seem to be much influenced by the relative strength of the playing teams. It is also noticeable that, as per our model, no team ever gets a probability of winning outrageously close to 1: the maximum difference in UEFA coefficient was for the game Spain–Republic of Ireland (+14.540), which translated into a probability of Spain winning of ‘only’ 0.55. This reflects that, in such a tournament, all the teams are in fact close and strong enough, as the weaker European teams do not qualify for the finals. As a result, no game is very unbalanced, and on a game the weakest team of the two is always able to wrest a draw or even a win with reasonable probability.In each group, the first two teams qualify for the second stage. The exact ranking of the top two teams is important, as a team ranked first in a group will meet a team ranked second in another group, hence supposedly slightly weaker, in the quarter-finals. In each group, there are thus 12 possible group outcomes, that is, 12 possible ordered couples (first ranked team, second ranked team) going through, which gives 124=20,736 possible configurations for the quarter-finals. Indeed, the quarter-finals are set in advance: the team ranked first in Group A will meet the team ranked second in Group B (A1-B2), and then (in the obvious notation), B1-A2, C1-D2, D1-C2.From our model for the W/D/L probabilities, we found the probabilities of seeing each of the 12 ordered couples going out of each group (see Table A.1 in Appendix A). We assumed that each game outcome was independent of the others. It is stressed that this for sake of simplicity only. Taking into account some potential serial correlation in successive game outcomes would require a finer analysis, but would totally fit into this framework. Also, ties on points were broken ‘randomly’, i.e. if two teams tied for the second place for instance, then we assumed that each had probability 1/2 of going through. In fact, in official tournaments such ties are broken according to secondary criteria, like the number of goals scored and/or conceded. These are features that can hardly be predicted with sufficient reliability. Besides, it is often the case that those secondary criteria turn out to be in favour of a team or another by serendipity only. This somehow justifies our way of doing.Within each of the 20,736 possible quarter-finals configurations, we can also estimate the probabilities of each team advancing to the next round using the model. The probability of a draw was divided in two and each half was added to the probabilities of each team winning. This just makes it up for the possibility of seeing the game decided by penalty shoot out. Then, repeating the process, we can estimate the probability of each team being the eventual winner. Combining those probabilities with the probabilities assigned to each of the 20,736 possible quarter-finals configurations, we get the prior probabilities pi,0 of each team becoming the European Champion, see Table 4.5. Those probabilities are not based on Monte-Carlo simulations but are exact (under the model).It can be seen that those probabilities of becoming Champion are in very good agreement with the ranking based on the UEFA coefficients. It is somewhat expected, as the values pi,0 are derived from our model, itself based solely on the UEFA coefficients. On the other hand, some tournament designs may prevent the best teams (no matter how the ‘best teams’ are defined) to be the most likely to win. The effect of the tournament design on the probability of seeing the best teams effectively playing the first roles, and the related question of how fair a tournament design is, investigated in detail in Scarf et al. (2009), Scarf and Mat Yusof (2011). Our findings tend to show that the way the 2012 European Championship was organized was fair, in the sense that it gives the best teams the highest probabilities of being crowned. Finally, from the prior probabilities of winning pi,0, the prior tournament entropy of Euro 2012 can be computed:e0=-∑i=116pi,0log16pi,0=0.9259, quantifying the very high competitive balance in Euro 2012 (prior tournament entropy close to 1).Now, the outcome of each game of the first stage affects Table A.1’s probabilities of each group outcome. Updating those probabilities and combining them each time with the ones of seeing a team becoming champion for each of the 20,736 quarter-finals configurations, gives the updated probabilities of seeing any team becoming champion before and after any game of the first stage for its three possible outcomes. We are thus in position of computing the tournament entropy (3.1) at any time in the tournament, conditionally or not to the previous results. This allows us to find the prior expected decisiveness and the decisiveness of each game of the first stage of Euro 2012, in the same way as what we did in Section 4.1.We clarified earlier that we followed to the letter the Euro 2012 schedule. In particular, in such a tournament, the last two games in each group are always played simultaneously, this to avoid getting some teams (un) favoured over their competitors by knowing the result of the other game before playing. We took this into account in our study and computed the decisiveness of the fifth and the sixth game of each group as if it was the last game of the group, knowing the results only up to the fourth game. Those decisiveness measures are shown in Table 4.6.It is no real surprise that the first game of the tournament Poland–Greece was actually the least decisive of the first stage (and of the whole tournament). Games played very early leave much room for teams to catch up, so are usually not very decisive. In addition, in this case neither Poland nor Greece were real favourite for the final victory. Hence the result of that game was not expected to have much influence on the tournament proceedings, and got a very low decisiveness measure.On the other side, the most decisive games happened to be those of Group B and Group C, which is again not surprising: these are the groups which the four greatest favourites of the competition (Spain, Netherlands, Germany and Italy) belonged to. The game Spain–Italy, although played very early in the tournament (first game of Group C), was expected to be the sixth most decisive at the start of it and was the seventh most decisive at the time it was played. As a comparison, the second game in that group played on the same day, Republic of Ireland–Croatia, was one of the least decisive as none of these two teams were expected to make it to the quarter-finals anyway. Prior to the tournament, the most decisive games of the first stage was expected to be the last two games of Group B and Group C, namely Portugal–Netherlands (1), Croatia–Spain (2), Denmark–Germany (3) and Italy–Republic of Ireland (4).It is interesting to understand the discrepancies between prior expected decisiveness and decisiveness for some games. For instance, the game Croatia–Spain happened to be less decisive on that day than initially thought, whereas Italy–Republic of Ireland got more decisiveness and was actually the most decisive of the first stage. The reason is that, given the previous results, the game Croatia–Spain might have been be played for nothing (so no decisive at all). Indeed, Italy drew on their first two games, and in case of a new underachievement (either a draw or a loss) against the Irish, both Spain and Croatia would have been automatically qualified for the second stage even without playing. So the final ranking in that group was mainly decided by the result of Italy–Republic of Ireland, hence its very high decisiveness given that it directly concerned two of the favourites (Spain and Italy). Conversely, the game Sweden–France (last game of Group D) was initially expected to be rather decisive (9th highest prior expected decisiveness of the first stage) but on the day of the game it was no more the case: Sweden was already out (two losses in their first two games) and France was already almost qualified (only a very unlikely combination of circumstances could have prevented them from going through). As a result, on that day, the decisiveness of Sweden–France was close to that of the little decisive early games of the tournament.When it comes to the second knock-out stage, the prior expected decisiveness (see Table A.2 in Appendix A) is actually not very insightful, as those games can match many different couples of teams. Some observations can, however, be made. It is seen that the prior expected decisiveness of the four quarter-finals is around 0.0575, whereas that of the two semi-finals is close to 0.12 and that of the final is 0.2426. Although the quarter-finals get similar prior expected decisiveness, we still note that the one of QF2 and QF3 is slightly higher than that of the other two. Again, this is because those two quarter-finals will be played by the team ranked first in Group B and Group C respectively, both expected to be one of the four favourite teams.It is probably more relevant to take stock at the start of the second stage, when the final table is known. In a sense, this is a new tournament starting from this point. The expected decisiveness of each game of the second stage when assessed after Game 24, that is, on completion of the first stage and right before the quarter-finals, is shown in Table 4.7. We have also computed the expected decisiveness of the remaining games after each game of that second stage, and in particular we have got the decisiveness of each of those games on the day. It must be stressed that none of the first-stage games was more decisive than any of the quarter-finals. This is easily understood, as knock-out games are intrinsically more decisive toward the final victory than games being part of a round-robin sub-tournament, not to mention that the first stage games are played earlier in the tournament. We note that this is the case even if the decisiveness of the first quarter-final (QF1) was actually much lower than expected prior to the tournament: it matched Czech Republic and Portugal, whereas we could have expected to find there stronger teams like Russia and the Netherlands or Germany.It can also be noted that the expected decisiveness of the semi-finals and the final remained roughly constant over this second stage, except for the last two games. The decisiveness of the second semi-final (SF2) dropped from 0.1161 to 0.1021 after Spain qualified for the final. This can be understood as Spain was the strongest team of the competition, and finding them in the final somewhat devalued the second semi-final: no matter who their opponent in the final would be, Spain would be the great favourite anyway. If Spain had been eliminated, then SF2 would have been very decisive, in the sense that the winner would have then been largely favourite against Portugal in the final. Finally, we see that the decisiveness of the final itself slightly dropped (from 0.2459 to 0.2395) after the second semi-final. This is because Germany were eliminated against Italy, and the final would have been more uncertain between Spain and Germany than between Spain and Italy (at least according to our model based on the UEFA coefficients).In summary, the most decisive game of the Euro 2012 was found - naturally enough - to be the final, followed by the semi-finals, and then the quarter-finals. All the games of the first stage were less decisive than those 7 knock-out games, although the gap was not huge between the less decisive quarter-final (Czech Republic–Portugal, decisiveness 0.0422) and the most decisive first stage game (Italy–Republic of Ireland, decisiveness 0.0331). Out of the first stage games, the most decisive ones were mainly the latest games in the groups the favourite teams were in, this again in total agreement with what the intuition suggests. Some earlier games matching some favourites may also get a significant decisiveness index.Finally, in order to check the relevance of our decisiveness index, we have compared the decisiveness dkof the games as given in Tables 4.6 and 4.7 to the corresponding television audiences. We obtained the Euro 2012 audience results in the United States from Media International (2012). Although this may be surprising, we purposely chose to use the US results as those should be less biased than the audience results from the major European countries: in a given country, audiences are obviously higher when their team is playing, whatever the importance of the game. Also, given the time difference, the US audience was probably not much influenced by whether the game was played at night or in the afternoon, unlike in Europe (prime time games naturally get higher audience). Hence, we believe that the audience results in the US should be less affected by external factors and, therefore, should be more representative of the real popular interest that a given game generated. The last two games of each first round group were, nevertheless, excluded from this analysis, as they took place simultaneously and could only be followed by roughly half of the viewers willing to watch a game on that day, independently of the rest. Of course, a more involved analysis taking this and the above mentioned external factors into account could have been carried out, but this would probably go beyond what we had in mind here: to somehow evidence that game decisiveness and popular interest (for which we use television audience as a proxy) are strongly related. In this purpose, a simple linear regression model on the log–log scale was fit on the remaining 23 games to explain the television audience from the game decisiveness, see Appendix B. The R2 coefficient for this model was found to be 0.524, which is rather impressive for such a simple model for a phenomenon as complex as television audience. A substantial amount of television audience variability can, indeed, be explained by the difference in decisiveness of the games.It has been announced by UEFA that the 2012 edition of the European Championship would be the last one to feature 16 teams, and that from 2016 (the competition is held once every four years) the format would be expanded to 24 nations. This decision is far from having unanimous support among followers, those claiming that this will dilute the quality of play and lower the intensity of the tournament. The format would be of 6 groups of 4, followed by 4 knock-out rounds including the final. The main issue of this is that, to leave 16 teams going into the new ‘round of 16’ in the knock-out stage, four of the six teams ranked third in their group need to progress. As those are meant to be the ‘best’ four, this raises the question of how can one rank teams belonging to different groups and playing opponents of different strengths (and one can even wonder whether that makes sense at all to do so). One can also question the appropriateness of playing 36 games in the first stage to eliminate only 8 teams. Put this way, it can indeed be expected that the first stage will be a long series of games with low stake, and the second stage itself will feature teams of lower level. UEFA’s general secretary himself described the expansion as “not ideal”, lending to a lack of suspense for fans (Ziegler, 2012). Below, we objectively study what this expansion will imply in terms of decisiveness of the games.Of course, it is not possible to know which teams would qualify for a tournament featuring 24 nations in the future. So here we will study ‘ideal’ exactly balanced tournaments, matching teams of exactly the same strength. It will consequently be assumed that, on any given game, both Team 1 and Team 2 have a probability 1/3 of winning, and same probability 1/3 of drawing. A reviewer pointed out that it need not be so, and that any probability assignment such thatP(W1,k)=P(L1,k)=(1-p)/2andP(T1,k)=pfor some p∈(0,1) would make it for an exactly balanced game. Indeed, for x=0 (two teams of exact same strength) in Fig. 4.1, it is seen that the probability of a draw is 0.22, and this value may therefore be more realistic for p above in an exactly balanced tournament. However, we prefer using the equally likely outcome assignment. First, it can be understood that this p=0.22 reflects the observed frequency of draws in Euro 2012 (7 draws out of 31 games), so is specific to Euro 2012. In Euro 2004 for instance, the frequency of draws was 9 in 31 games, which would imply a ‘good’ value for p close to 1/3. In addition, the analysis is much simpler under this assumption. In particular, the decisiveness of each game equals its prior expected decisiveness, since everything always happens as expected. We will therefore stick to it.In any case, in the knock-out stage of such ‘ideal’ tournaments, each team has one in two chances of advancing to the next round, and clearly, every team is equally likely to be crowned champion. The tournament is thus totally undecided at its start, and the prior tournament entropy is 1 (maximum), whatever the number of teams participating. We can then study the tournament proceedings as we did above under this particular assumption of exact balance. All groups, games and teams are now symmetric and exchangeable. We have computed the decisiveness of the games for tournaments featuring 16 teams (current design of the European Championship) and 24 teams (suggested design, as described above). As a comparison, we have also done so for tournaments matching 8 and 32 teams, in their usual design and schedule.5An 8-teams tournament, with two groups of 4 followed by semifinals and the final, was the previous UEFA European Championship format, until 1992; a 32-teams tournament, with 8 groups of 4 followed by 4 knock-out rounds including the final, is the current format of the FIFA World Cup.5In particular, we have again taken into account the fact that the last two games in each group are played simultaneously, for all tournament designs.The analysis of the tournaments featuring 8 and 32 teams was in every respect similar to what we did for a 16-teams tournament in the previous subsections. For the 24-teams tournament, the fact that 4 out of the 6 teams ranked third in their respective group qualify for the second stage makes the analysis slightly different, but not really any more difficult. In fact, in this situation of an exactly balanced tournament, the way those 4 lucky thirds are selected does not matter at all. In our calculations, we just considered that a team ranked third in their group had a probability 2/3 of making it through. More care should however be taken if we were analysing a real tournament with teams of different strengths. Anyway, the decisiveness of the group games of the first stage for those tournaments is shown in Table 4.8.As suspected, the decisiveness of the games in a 24-teams tournament is much lower than for the other designs. The knock-out stage features 16 teams and is made up of 4 rounds, which means that a team going out the group stage is still far away from the final victory. This obviously explains why the overall decisiveness of the games tends to decrease with the number of teams. For instance, the group games are closer to the final in an 8-teams tournament than in a 32-teams tournament, hence are more decisive. This reasoning, however, does not hold for comparing 24-teams and 32-teams tournaments, and in fact, group games in a 32-teams tournament are more decisive than in a 24-teams tournament. This is precisely because, with 24 teams, third ranked teams can qualify for the second stage. Consequently, one or even two false steps usually do not prevent most of the teams from qualifying, and so the first stage games have very few influence on the rest of the tournament. This obviously translates into low decisiveness. As it happens, the last group games in a 24-teams tournament are barely more decisive than the very first games in a 16-teams tournament.The decisiveness of the knock-out games is also easily derived for each of the design we are considering. When 2k(k=1,2,3,…) teams take part in a knock-out round of an N-teams exactly balanced tournament, each as probability 2−kof final victory. This implies a tournament entropy of klogN2. After that round, there remain 2k−1 teams, each with probability 2−(k−1) of final victory, i.e. the tournament entropy is (k−1) logN2. Hence, each knock-out round as a whole reduces the tournament entropy by an amount of logN2. Dividing that entropy drop by the number of games in that round (k−1), we find the decisiveness measures shown in Table 4.9. Incidentally, this highlights that games at round k are always twice as decisive as games at round k−1.The final always gets decisiveness logN2, as logN2 is the tournament entropy before the final and the tournament entropy must be 0 after it (the winner is known). Thus, the final decisiveness depends on how many teams initially competed in the tournament, which may be a bit disconcerting at first sight. Indeed, it can be argued that, regardless of the number of teams on the starting line, the final should always be equally decisive as it matches the last two teams in competition and that the winner will be crowned champion. However, this is probably not the right way of looking at this. For illustration, consider again a very simple 2-teams ‘tournament’, which is then just the final. Absolutely everything will be decided on that game, hence it naturally gets decisiveness 1. On the other hand, in a tournament with more teams, the final may well decide which of the two teams still in competition will be crowned champion, but which exactly are these two teams depends on the previous games/ rounds. Hence the final remains the most decisive game, but it shares with other previous games the task of isolating the eventual champion, and is therefore comparatively less decisive than in the former case. It is, therefore, meaningful to see the final decisiveness decreasing along with the ‘size’ of the tournament, i.e. roughly the number of teams taking part in it.Now, we suggest to measure the overall attractiveness of a tournament through the sum of the decisiveness of all its games. As the decisiveness of a game is the expectation of the absolute value of the difference in tournament entropy that the game can generate, the overall sum of the decisiveness measures can be regarded as the total variation of the expected entropy over the tournament. The total variation (TV) of a function can be viewed as the vertical component of the arc-length of the graph of the function. Specifically, in our case, no matter the number of teams, the prior and the final tournament entropy are always 1 and 0, respectively. The total variation of the entropy over the tournament is therefore the length of the path the entropy will take to make it from 1 to 0. The longer that path, the more variation is observed in the entropy over the tournament, meaning a more attractive tournament with many high stake games and potentially many twists and turns. A very similar idea was previously proposed in Vecer, Ichiba, and Laudanovic (2007) to quantify the excitement generated by the evolution of the score within a game.Of course, tournaments like these ones have many more dimensions than just the race for final victory. Some games, and hence the entire tournament, may be attractive for the public for other reasons than just being decisive. For instance, a game matching two teams having a very strong historical rivalry usually raises popular passion even when there is few at stake. Therefore, measuring the overall attractiveness of a competition only through the decisiveness of its games may be a bit simplistic. As pointed out by a reviewer, this way of doing is, however, supported by the Uncertainty of Outcome Hypothesis in the sports economics (Rottenberg, 1956), stating that the interest in a competition should be an increasing function of its competitive balance. Therefore, and although the validity of this assumption has sometimes been questioned (Lemke, Matthew, & Kelebogile, 2009; Owen & Weatherston, 2004), the tournament entropy total variation, quantifying an overall decisiveness of games, seems a valid criterion for comparing the attractiveness of different tournaments. Nevertheless, it is acknowledged that this may only give a partial picture of the situation.Consequently, in Tables 4.8 and 4.9, the sum of the decisiveness of the games of the first stage and of the knock-out stage, respectively, are shown for the different tournament designs. It is now straightforward to find the total variation of the tournament entropy, say TV (ek), for each of them, see Table 4.10. It appears that the tournament entropy total variation for an exactly balanced design is maximum for the 16-teams design. This format shows the best compromise between a sufficiently large number of games and a sufficiently high decisiveness for most of them. In a 8-teams tournament all the games, including the first group games, are highly decisive. However, the second knock-out stage is too short, and altogether, the tournament entropy total variation turns out to be slightly lower than that of the 16-teams tournament. We have the reverse observations for the 32-teams format. Naturally, the group games are there less decisive but they are numerous, which yields all in all a reasonably attractive first stage which may imply significant variations in the tournament entropy. The second stage is attractive with many decisive games, as are knock-out games by definition. This format ranks third in terms of total variation of tournament entropy.Finally, the 24-teams tournament is the least attractive, in terms of our measure. As pointed out earlier, in that format the first stage is mostly non-decisive and it is very much like the tournament outcome hangs only on the knock-out stage. Indeed, the second stage entropy total variation is seen to be maximal for this design, but this is not sufficient to make it up for the very unattractive first stage. As a result, the overall value of TV (ek) is inferior to that of the other designs, in particular to that of the 16-teams format. It seems clear that this 24-teams tournament format has few to offer in comparison to the other designs.It must also be stressed that our assumption of ideal exactly balanced tournaments is, moreover, actually favourable to designs with many teams. Indeed, in reality, the 8 extra teams which would have taken part in the Euro 2012 for instance, would have most certainly been weaker than the 16 already qualified, for they failed to qualify in the first place. This would necessarily have decreased the competitive balance. So, although the second stage entropy total variation was higher for the 24-teams than for the 16-teams tournaments in Table 4.9, this would be unlikely the case in real tournaments. Typically the teams eliminated at the first stage of Euro 2012, hence weaker, would have made it to the second stage in a 24-teams format, and those games would not have been that decisive, after all. In summary, it seems safe to state that a tournament gathering 16 teams has definitely to be favoured over a 24-teams format, in terms of attractiveness of the competition.In this paper we have proposed a measure of how decisive a particular game is in a tournament in which teams are matched two at a time. Our decisiveness measure mainly differs from most of the previously suggested indexes of how important a game is, in that it is a global measure at the tournament level (not team specific). It takes into account the strength of the two playing teams and the temporal position of the game in the tournament in a natural way. In addition, although it is not football (soccer) specific, our measure can also naturally cope with possible draws that abound in football games. It is actually based on the effect that a given game can have on the uncertainty prevailing in the tournament as to the eventual winner. A natural way of quantifying that uncertainty is through the entropy of the probability distribution of final victory for the different teams, and our decisiveness measure is therefore based on the variation in that entropy that the game can generate. This idea was studied on two real tournaments, namely the 1988 NBA Championship Series and the 2012 European Football Championship. In both cases the measures we derived give objective and quantitative information on how decisive the different games were. Besides, they were in total agreement with what the intuition suggests and were easily interpretable. This type of information is important in many aspects, for instance as a decision informer for television stations when they have to choose their games for broadcast prior to an important tournament. Decisive games with high stake should attract more viewers than non-decisive matches, and this has, indeed, been confirmed to some extent by a basic analysis on the Euro 2012 television audience results. We have also suggested to quantify the overall attractiveness of a tournament design in terms of the total variation of the above mentioned entropy that the games can generate. This has allowed us to objectively analyse the recent UEFA decision to expand the European Championship from 16 to 24 nations in the future. Our findings show that, in terms of attractiveness through the overall decisive nature of the tournament games, the 16-teams format has definitely to be favoured over the 24-teams format.

@&#CONCLUSIONS@&#
