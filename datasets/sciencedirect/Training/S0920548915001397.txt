@&#MAIN-TITLE@&#
Capitalization of remote collaborative brainstorming activities

@&#HIGHLIGHTS@&#
We model brainstorming activities involving two remote teams.We develop tools supporting brainstorming activities on large tactile surfaces.The awareness of remote teams is essential.Annotation of videos which register the teams activities help to the capitalization of information.

@&#KEYPHRASES@&#
Brainstorming activity,Multi-touch device,Synchronous collaboration,Semantic Information System,

@&#ABSTRACT@&#
The capitalization of activities occurring during collaborative brainstorming sessions is a real challenge. It is still enhanced when two remote teams have to participate in the same work sessions. Activities which have tangible results like digital notes are easier to capitalize. However many other events may happen which can only be captured by videos. We use the mandatory system of video conference between two remote teams to capitalize non-tangible results like agreement or disagreement between participants. We developed a system for supporting remote collaboration. The paper describes the design of two main parts of this system. First it presents the resource channel i.e. the way the teams can exchange, display and synchronize data on large multi-touch devices. Then it presents the video channel i.e. the way people can be aware of the other team. The paper concludes with some observations about the current version of this system alloted to the capitalization of collaborative team activities.

@&#INTRODUCTION@&#
The motivation of our research is the design and the implementation of tools supporting brainstorming activities and in particular the capitalization of the collaboration results between remote teams. They have to create and share resources and to communicate about them. It is essential to capitalize tangible results results of the activities like digital notes that can be produced during common sessions, and also any kind of events thanks to the video registrations of the meetings.At the very beginning of a project, teams have to design a new product or define new concepts during several meetings. They collaborate during brainstorming activities where the main ideas, problems and solutions emerge from discussions between participants. The results of these activities should be capitalized and some reporting must be made from that.In our experiment, a classic scenario involves two remote teams (a Japanese one and a French one) that have to design a Web site useful for French visitors who want to discover Japan and some of its cultural aspects. Designers organize several meetings where they can discuss, produce ideas, agree on some results written on notes and categorized into clusters. They also have to discuss about cultural concepts and explain their meanings.These activities are usually conducted in traditional meeting rooms with pen and paper media. Results are generally written on post-it notes and then significant efforts are necessary to render these hand written notes into a digitally exploitable format.Previous attempts of computer-supported solutions did not encounter a huge success, because they introduced additional instruments that prevent the natural collaboration between participants.Technologies such as interactive tabletops, interactive whiteboards and handled devices (tablets and smartphones) are now widely diffused. Large devices look like physical configurations of traditional pen-and-paper environments and they could evidently be used to display virtual post-it notes. Inputs based on multi-touch gestures reproduce usual input and the collaboration between co-located groups of users is influenced and augmented. The drawback of this approach is that the design of graphical multi-user interfaces is much more complicated to achieve than mono-user interfaces. They generally result in a mashup, more or less dynamic of interfaces [1]. In Web-based Cooperative Information Systems, user groups with different roles cooperate through specialized interfaces. Cooperative interaction and user interface structures are usually rather complicated, and modeling has an important part in them [2].The capitalization of brainstorming activities involves two kinds of results. Firstly, ideas, propositions, etc. are written on digital notes and can be easily stored in an information system. Supporting tools only have to allow the creation, the organization, the sharing and the storing of these notes. Secondly, people can discuss about interesting things but without writing them. Some events may also occur like agreements between participants. The only way to capitalize these results is to film the sessions and store the videos. As we are interested by the collaboration between remote teams, they need to have a teleconference system to communicate and we use this opportunity for the capitalization.In this paper we describe the way we capitalize tangible and not tangible results. Section 3 presents the resource channel, i.e. the suite of applications running on interactive devices (table, whiteboard and tablet) that allows to share written resources. Then Section 4 presents the tools useful for audio-visual aid between teams. Section 5 describes a model of information used to store the brainstorming results. We conclude with some observations about an experiment that has been conducted at the University of Compiègne (UTC, France) and at the Chiba Institute of Technology (CIT, Japan).Our research is concerning the design of distributed systems facilitating the capitalization of brainstorming activities. Such systems are necessarily distributed because participants belong to remote teams and use different types of devices during their activities. Different tools can help to collaborative activities, but very few tools are designed for a group of users gathered together in the same room.When modeling such distributed systems and speaking about collaborative activities, it is necessary to describe with precision the use case diagrams and the type of activities taken into account in the scenarios. They influence deeply the implementation. [3] presents some patterns for software modeling.Scenarios consist of several steps where different kinds of activities are involved. We consider three types of activities. Firstly, participants are alone and prepare future collaborative sessions. Secondly, participants work during collaborative sessions involving one or more teams. Thirdly, some participants annotate the videos registered during collaborative sessions. The other dimension is the number of people that can use the same applications. Different cases are possible: two people using the same application at different moments or two people using the same application at the same time but in different places that leads to synchronization issues.Generally speaking, collaborative activities are activities produced by one individual for the benefit of other people. For example, people insert in a common repository a new document, annotate a document [4] or a fragment of a document produced by others. In this cases people use a tool designed for personal PCs or a Web application. It is a mono user context even if the actions of one user are visible by other users.Trello [5] or Kanban system like [6] are good examples of mono-user collaborative tools. They present a board which is a set of lists filled with cards, used by one person or shared within a team. Cards may have file attachment. Trello does not accept a hierarchy of cards but Kanban systems allow linking children tasks to their parent combining multi-level hierarchy of cards. Lists show progress of task achievement (to do, doing, done). Other sets that don’t necessarily represent tasks can also be added. Several people can be attached to shared cards. Comments about cards are also permitted. It is the only level of collaboration between people working on the same project. These tools are intuitive Web applications and have tablet and smartphone extensions. Different personal tools can be linked to these systems like agendas or mail managers. However from a collaborative point of view, they remain very poor.During brainstorming sessions, people can progressively agree on some definitions and on some decisions. Discussions and argumentations may require the study of external resources. However, results achieved by teams have to be capitalized in some way [7]. We propose that these results take the form of notes grouped by clusters similar to cards and sets of cards in the previous section.In co-located brainstorming sessions, participants are situated in the same room and their activities are always synchronous. At least one surface is designed to be the common support where all the participants can see and the notes interesting the team. Notes can be created directly on this surface but the main advantage of our system is that they can be added from tablet pcs and sent to the common display without disturbing current discussions.People manipulating notes displayed on a large interactive surface benefit from an efficient digital support for their activities [8] that brings real advantages (capitalization, reuse, interoperability with other applications, etc.). Digital devices allowing data storing and enhancing the exchanges between participants are a necessary support for teams involved in brainstorming sessions[9, 10]. The use of large collaborative devices helps and supports members [11] to produce new resources. Without this, too many efforts have to be deployed in order to write out again what has been written on sheets of papers.During remote brainstorming sessions, several co-located teams (at least two) participate to the same brainstorming activities. Their actions must be supported by specific software applications [12]. For example, two instances of the same application should run on peer systems located in two distant rooms. Teams involved in these sessions interact with the same type of graphical user interface communicating in real time and synchronized, i.e. all the actions on one common surface are reproduced on the common remote surface. A lock system prevents concurrent actions on the same element already selected elsewhere. A padlock graphical indication makes people understand that somebody else in the remote team has already selected an element.Our research does not deal with distributed software development, but this domain and our's face the same issue of awareness of remote teams. Communication and coordination problems due to spatial, temporal and cultural separation between team members appear [13]. The main expected benefits are improvements in efficiency and flexible access to a greater number of resources. Organizations require using their existing resources as effectively as possible, and also need to employ resources on a global scale from different sites and from partner organization throughout the world.When teams with different cultures have to collaborate some issues may appear. [14] presents a review of cultural issues in the specific domain of distributed software development. In the case of project development, people may need to explain some concepts of one particular culture to the other team. Our tool allows to write notes in different languages and its automatic note translation is a help to the common understanding.Our research can also be considered from an ecosystem point of view. We consider that people communicating about well identified subjects, creating and sharing different kinds of resources, and commenting different contributions, participate to the same ecosystem [15, 16].During remote brainstorming sessions, one team must see what the other one has produced and vice and versa. That is why we organized the synchronization of the resources between teams (we call this the resource channel). Members of teams communicate locally but also with members of the other teams. Video transmissions have to be installed for allowing exchanges in both directions between remote teams. People must be able to communicate and discuss as if they were in the same room. It is also important to see what happens in the remote room. We call this feature the video channel.Videos and notes produced during collaborative meetings must be stored and associated in some way in the same information system. A semantic indexing associated with a keyword indexing allow fine requests of resources. These three concepts, resource channel, video channel and information system are shown together in Fig. 1.We have developed a suite of applications for supporting brainstorming activities. The most important one runs on a large tactile device, either an interactive table or a white board. According to the different devices, the interaction between people is not exactly the same. A table has a horizontal display and people are standing around the table. A board (see Fig. 2)11The languages used during the experiment is out of the scope of the paper. We can precise that exchanges between people were in English. Technologically, the notes can be written in three different languages, English, Japanese and French. Each team can add elements in its own language. A note can be displayed in each of these languages.has a vertical display and generally people are sitting looking at the board. However, their dimension and their multi-touch characteristics allow the interaction of several people. Both situations need a moderator in order to organize the discussions.The applications run on different devices: a server, an interactive board or table and tablet pcs (see Fig. 3). When two distant meetings occur at the same time, two similar suites of modules run simultaneously in the different locations. The communication between applications and their functionalities (with eight participants we may have till ten applications) are managed by a multi-agent system [17]. Each application is independent and contains at least one agent.Agents are grouped inside containers. On the main container are running the agents provided by the platform and responsible for the logistics of the system. They maintain the white and yellow pages of the multi-agent system and know everything about the location of the different agents and the services they can deliver. They are also in charge of the good distribution of messages between agents.In the following description, the agent numbers refer to the numbers appearing in Fig. 3. In our system a specific federator agent (n∘1) is responsible of the communication with remote equivalent agent systems. It owns a list of the station addresses that it can reach, is able to connect with other platforms and transfer messages representing the actions of people on the main interactive device.Several agents run on the stations linked to the interactive surfaces, together with the applications allowing user interactions. The meeting agent (n∘2) recognizes users' actions. It delivers messages about these actions to the logistic agent that propagates them to the external platforms. The main actions of users consist of creating notes and clusters, moving elements, inserting notes into clusters and deleting elements. The persistence agent (n∘3) keeps locally the content and the position (coordinates, size, orientation) of the notes and clusters displayed on the large surfaces. It saves the brainstorming content after each user's action. Action and content are described in the following JSON22http://www.json.org/format:Another agent (n∘4) is responsible for the communication with the Information System for storing and indexing the brainstorming results.The tablet pc application allows users to prepare collaborative sessions, creating notes and clusters. It contains a personal assistant agent (n∘5)33Each participant may own a tablet with the appropriate application. There are as many personal assistant agents as tablets connected to the system.. Its main role is to send post-it notes written on tablet pcs to the corresponding meeting agent.Creating a note in this way has two advantages. It is an alternative way of adding notes during a meeting in a more comfortable way and it is the only way to write strings belonging to some languages, like the Japanese language, because the virtual keyboard of the tablet is adapted to the local language. With applications running on large screen stations, due to the programming language, the only way for writing words is to open a virtual keyboard. However, only some keyboards are developed and available which limits the available languages.Adding new elements to the main surface from tablet PCs could generate some perturbation if a specific protocol were not respected. These notes are not automatically visible on the main device (they would also appear on synchronized stations). The meeting agent stores them into a mail box and an alert indicates that new elements have been added to the mail box. Users, generally the moderator, can open the mail box and choose the most adequate instant to do that.The multi-agent system is implemented with a JADE platform44JADE stands for: JAVA Agent DEvelopment Framework. http://jade.tilab.com/. The server application contains the main container. Other applications build a secondary container which is linked to the main container. The set of containers forms the agent system. A JADE platform is very robust and can integrate dynamically new containers, new agents and observe the disappearance of someones.The main application running on large devices is built in Java using the MT4J library. It owns a high level API for touch events that can be attached to graphic elements. For example during a moving gesture, the object which is moved produces a sequence of events with all data concerning its position on the scene. The meeting agent listens all gesture events. Communication between graphic user interface and agents is based on the Observer design pattern implemented with the Java bean approach. For example when the meeting agent receives a message concerning the user interface, one of its property is modified that launches a notification received by the scene.During remote brainstorming sessions, members of one team have to communicate with members of other teams. Video transmissions have to be installed for allowing exchanges in both directions between remote teams. People must be able to communicate and discuss about the shared ideas written on post-it notes with all the participants, local and distant, in the same way as if all participants were in the same room. People can see what happens in the remote room only thanks to the video channel. It is interesting to consider several cameras in order to capture people themselves but also some other particular points of view. Moving from time to time the cameras may be interesting according to local events. Even if the main surfaces are synchronized, it is interesting to show the display to the other team. From a technical point of view, video streams of the same room are mixed into a unique one and broadcast[18].Recording video transmissions is also very important for a future exploitation. The sender of the stream is responsible for this. Sometimes important things are said and not necessarily transfered into a note and must be retrieved inside the videos. People can also add later a missing or forgotten information.A video channel is composed of a pair of components named Video Streamers, as shown in Fig. 4, that send and receive streams of video and audio via the Internet. A Video Streamer captures images by cameras installed in rooms, composes images from several cameras into a composite one, sends and receives video streams on line and saves the video streams. A Video Streamer also allows a user to operate a Video Switcher [19] for choosing and moving cameras. Operations on the Video Switch are recorded and used to annotate videos. A review of videos after brainstorming sessions shows why the switcher function has been used (presentation of a new participant, etc.).A Video Streamer sends video streams to a Video Streaming Server to exchange images between two co-located teams. The Video Streaming Server consists of a Video Cache and a Video Storage. The Sender function of a Video Streamer sends video streams to the Video Cache and the Receiver function receives video streams from the Video Cache to display them on a Viewer in real time. A Video Annotation is a description of an operation on the video streamer such as “start the video streamer”, “stop the video streamer”, and “put camera B view at bottom of the right side of the camera A view”. The Video Annotation Data Base is a server that saves these video annotations sent by video streamers.We actually developed two types of Video Streamers. The first type (Video Streamer-1 in Fig. 4) is supposed to be used by a team consisting of a mediator and several participants. Several cameras are deployed to convey different visual information of activities in brainstorming sessions to a remote team. A Video Switcher function is installed in this Video Streamer to dynamically compose several video images into a composite one. A Video Operator interface allows a mediator to operate the Video Switcher.Actions on the Video Operator produces annotations that are stored by the Video Annotation DB. Their description allows to associate them with the corresponding video stream stored by the Video Streaming Server. The Video Annotator receives action descriptions from the Video Operator and includes action timestamps. So, after a brainstorming session, participants can review video using a specific Viewer and retrieve the moment where annotations have been produced.The second type of of Video Streamers (Video Stream-2 in Fig. 4) is supposed to be used by a team consisting of one or two members. In this case, only one camera is enough for the communication with another remote site. Such a Video Streamer is a simpler system that substitutes the Video Switcher implemented by a hardware device with a Video Capture function implemented only by software.Originally, we prototyped the Sender, Receiver, Viewer and Capture elements using Skype and Ustream services. However, we noticed the limits of this first implementation. It was not possible to extend it to a real system compliant with the proposed design because it used closed services difficult to integrate into a system. Therefore, we newly implemented these elements.Proposed Video Streamer is developed using C# on Microsoft Windows using conventional libraries. We used Red5 Media Server55http://red5.github.io/as a Video Streaming Server, Open Broadcaster Software66https://obsproject.com/as the Sender component and Web Browser Control as the Receiver component to deal with Shockwave Flash Object77http://www.adobe.com/products/flash.html. HTTP is used for beginning and ending a session and RTMP is the protocol used to send and receive video streaming.A Video Switcher is mainly implemented using a Blackmagic Design ATEM Television Studio88https://www.blackmagicdesign.com/products/atemtelevisionstudio/device to compose several video streams from cameras into one video stream sent to the Video Streaming Server. We developed a Video Operator element to compose video streams, that provides a user interface for a mediator or a participant to operate with. Descriptions of these actions are sent to the Video Annotator. It transforms them into annotations stored by the Video Annotation DB into a MySQL database.Fig. 5shows the Video Viewer display that allows to review videos of brainstorming sessions. Video images of both teams captured at the same time99During the experiments, the small transmission delay of video streams was really acceptable to synchronize the imagesare shown in the bottom panel. The upper panel in Fig. 5 is an Annotation Table whose rows display the annotations data: timestamp, operation name, camera ID, display position of views. A user can select one data (for example, a time stamp or an operation) in a row of the table and then the video is positioned just as the corresponding event occurred during a session.An information system is also necessary for storing data related to brainstorming activities. We have chosen the MEMORAe Information System [20]. We show how its semantic model is coherent with our needs. An excerpt of this model is shown inFig. 6. The model is very rich but we only present the concepts related to our needs.Our application only creates notes and clusters of notes. These types respectively inherit of SimpleResource and CompositeResource. The main type of SimpleResource is Document. It encapsulates resources like PDF documents, archives or textual documents but it is useless to have specification for any kind of documents. In the model, any Note has a body which is a Resource because the model allows a note being an image or anything else. In our case a note body is an anonymous textual document. Anonymous means that this document can only be reached by the corresponding note. In the same way the body of a NoteCluster is a textual document. A NoteCluster is composedOf of Note and NoteCluster.Any resource has to be displayed by one or more applications. For example, a resource can be displayed by a web application and an application running on a tablet pc. Often they are created with one device and have to be displayed by different devices. As we are using interactive table top and whiteboard, it is necessary to store with a Note and a NoteCluster, other data added by the applications running on these devices like colors or data useful to locate the resources. These data are very dependent on the applications and are quite impossible to describe in the model. Each time we create a new application we do not have to modify the model. In order to reach this purpose, the model allows each resource to get one or more documents that contain these data. The relationship mcb2:hasSupportDocument whose domain and range are Resource and Document generally associates a textual document to a resource, formatted with a JSON1010JSON site: —http://www.json.org/structure.The videos taken during brainstorming sessions are also documents that have to be stored in the information system and linked in some way to the data (Note and NoteCluster) produced during sessions. They can be stored under the Document type. The Event concept not visible Fig. 6, allows to describe a brainstorming session as an Event and to link it to the resources concerning it. In particular, all the notes and clusters produced during a session are encapsulated inside a unique super cluster attached to the session event. The MEMORAe model gives the opportunity to find notes as any other documents but also from the event they were created in.In this section, we describe experiments conducted simultaneously at the University of Compiègne (UTC) in France, and at the Chiba Institute of Technology (CIT) in Japan. Two teams, one at the UTC and one at the CIT decided to collaborate on the preliminary design of a website for French travelers in Japan.Both teams are involved in a remote brainstorming session and use the system described above. They have to create and classify ideas about this project. Ideas are written on notes, grouped into clusters and displayed on an interactive device. Elements can be moved, zoom can be applied, etc. The actions of one team are transmitted in real time to the devices of the other team. At the UTC, people were working around an interactive table. A single camera directed on the table transmitted the scene showing people acting on table. People in the CIT could see and hear them from this stream.At the UTC the video stream from the CIT was displayed a large screen. The Japanese system integrated three camera streams. It was showing the device displaying the notes and the session moderator, other sitting participants to the sessions and a small device where notes could be written in Japanese. Sometimes the orientation of cameras was changed according to the discussions. UTC people could see how their actions on the table were repeated in real time on the main Japanese device. There was no real mediator as everybody could interact directly with the common surface.At the CIT, scenes were displayed on an interactive white board allowing only one interaction point. A priori, this allows only moving actions; zoom in, zoom out, rotation require two fingers. However, notes were designed in order to allow zooms and rotations. A handle at the top of a note and a squared zone at the bottom right make these actions possible also on a one-touch surface. Fig. 7shows cluster and notes with these characteristics. The mediator, was standing up near the white board moving and grouping elements according to the discussions with other team members (see Fig. 2). It is not easy and even undesirable for the moderator to create a new note. That implies: opening a virtual keyboard, typing on keys, and so on. Other participants had tablet pcs and, thanks to the specific application running on them, could create notes and send them to the white board.Session lasted about two hours without any communication problems between sites and without network problems. We are satisfied from this point of view. The resource channel was faster than the TV channel. In the first sessions, people felt that it was necessary to describe their own actions in order to inform the remote colleagues (I am moving the IZU note, I am deleting the mountain cluster and so on). After a while, it was not so necessary. At the beginning, people were concentrated more on the manipulation of the different elements than the elaboration of ideas.The main issue remains the production of notes. Japanese people can only use their tablet pc for that. It appears that it was more comfortable than to produce notes directly on the table as the French team tried to do with virtual keyboards. It is difficult to compare benefits of the large surface. One team used a table, the other team used a board. The use of a vertical surface is easier than the use of a horizontal one. Maybe because it is nearer to the usual practice. The role of the mediator is important for organizing discussions.The experiments had also a multicultural approach. Content of notes may be in relation with a cultural context. Discussions have been useful in order to explicit some concepts sometimes not well known and teams could complete notes with their specific approach.This paper presented the three dimensions concerned by the capitalization of brainstorming activities in a remote context. The resources produced during sessions must be stored in an information system (resource channel), sessions must be recorded (video channel) and the data persistence system must allow to link all stored elements. This requires a suite of applications allowing both the smooth progress of the sessions and the capitalization of resources. The design of the main application has been described. Video event annotations are associated with video streams. Replaying videos afterwards provides information regarding the cause and true nature of the events.Our system is part of an on-going research and we are currently investigating complementary aspects. The first thing is to find alternative ways for simplifying the creation of resources. First, we will study how to integrate a speech to text system for producing notes and its advantage. The multi-agent infrastructure allows easily to do it, however usability issues have to be analyzed. A second aspect we will investigate is the production of other event annotations concerning the resource channel. This could be automatic and also semi-automatic when it is decided by the moderator. This will facilitate the capitalization of other results occurring during collaborative brainstorming sessions.

@&#CONCLUSIONS@&#
