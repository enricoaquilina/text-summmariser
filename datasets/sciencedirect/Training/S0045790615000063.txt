@&#MAIN-TITLE@&#
Hindi phoneme classification using Wiener filtered wavelet packet decomposed periodic and aperiodic acoustic feature

@&#HIGHLIGHTS@&#
24 subband WP decomposition according to the auditory ERB scale.Proposed wavelet subband specific periodic and aperiodic decomposition.Wiener filter is used at frontend for noise minimization.Hindi phoneme classification task has been carried out.Proposed technique outperforms others classify voiced phonemes.

@&#KEYPHRASES@&#
ERB scale,WERB-SPADE,Wavelet packet sub-band,Phoneme classification,Hindi speech,Hidden Markov Model,

@&#ABSTRACT@&#
Wavelet packet (WP) acoustic features are found to be very promising in unvoiced phoneme classification task but they are less effective to capture periodic information from voiced speech. This motivated us to develop a wavelet packet based feature extraction technique that signifies both the periodic and aperiodic information. This method is based on parallel distributed processing technique inspired by the human speech perception process. This front end feature processing technique employs Equivalent Rectangular Bandwidth (ERB) filter like wavelet speech feature extraction method called Wavelet ERB Sub-band based Periodicity and Aperiodicity Decomposition (WERB-SPADE). Winer filter is used at front end to minimize the noise for further processing. The speech signal is filtered by 24 band ERB like wavelet filter banks, and then the output of each sub-band is processed through comb filter. Each comb filter is designed individually for each sub-band to decompose the signal into periodic and aperiodic features. Thus it carries the periodic information without losing certain important information like formant transition incorporated in aperiodic features. Hindi phoneme classification experiments with a standard HMM recognizer under both clean-training and multi-training condition is conducted. This technique shows significant improvement in voiced phoneme class without affecting the performance of unvoiced phoneme class.

@&#INTRODUCTION@&#
Speech can be greatly used as a medium in wireless authentication as well as a means in human–machine interaction or interface. Different methods have been developed and applied in the recent past to increase the recognition efficiency of the automatic recognition system (ASR). These techniques perform well in the controlled environment with keeping the same acoustic condition but the performance of these techniques deteriorate in presence of noisy environment or sensor mismatch condition. In this paper a robust feature extraction technique has been developed to increase the recognition efficiency as well as the intelligibility and quality of the speech signal in the clean and noisy environment.Mel Frequency Cepstral Coeffiecients (MFCCs) [1] is the most widely used front-end feature extraction technique. MFCC features represent the spectral shapes of input signals and shows very promising result in clean condition but the performance of MFCC deteriorates in the acoustic/sensor mismatch condition. To make features more robust in the complex auditory environment, researchers have studied and developed different features such as Perceptually Linear Prediction (PLP) [2] analysis, Gammatone Frequency Cepstral Coefficients (GFCCs) [3]. These features are modeled according to human auditory system. Auditory filters provide a better representation of speech in adverse environment than the short time Fourier transform (STFT) based features. STFT based techniques have uniform resolution property over the time frequency plane and for this reason it is very difficult to detect unvoiced phonemes especially stops. Stops are like a short event or burst and it is a very difficult task to detect them in the presence of noise or sensor mismatch condition. This type of problem was solved by considering WPs as the feature extraction technique [4–6]. WPs [4,7–9] can efficiently be used to model the slowly varying quasi-periodic signal like speech signal. For this reason, WPs are widely used in the field of signal compression, detection and classification.The periodicity and aperiodicity of sound is the main focus of research in this paper. Kajita and Itakura proposed a method based on sub-band autocorrelation (SBCOR) to extract periodicities present in the speech signals [10]. It can be concluded from the SBCOR technique that periodicity of the speech signals helps to improve the performance in noisy environment. However the speech signal consists of both the periodic properties like voiced parts of vowels and voiced consonants as well as the aperiodic properties like intrinsic variations in vowels and unvoiced phenomena such as fricatives and stops. To utilize the effect of aperiodic properties of the speech signal [11] proposed a feature extraction method known as Sub-band based Periodic and Aperiodic Decomposition (SPADE). By using the Gammatone filterbank they divided the input speech signals into periodic and aperiodic feature set in the time domain. The development of this technique has been inspired by the auditory comb filter assumption [12] and the study reported on auditory nerve characteristics in the time domain by Greenbarg et al. [13]. The auditory comb filter assumption suggests that the human auditory system can perceive both the periodic signals as well as the aperiodic signals. Aperiodic parts are the residue after the cancelation of the harmonic properties of the signal. To make more robust features, aperiodic properties of the speech signals should be taken into account. The decomposition of speech signal into periodic and aperiodic part helps to make features more effective without losing certain essential aperiodic information presented in speech signal. They have evaluated the performance of SPADE with AURORA-2J database in the presence of noise and claimed that proposed features have outperformed MFCC. Later Ishizuka and Nakatani [14] have expanded the SPADE analysis in frequency domain and have proposed new feature extraction technique named SPADE freQUEncy domain ENhancement (SPADE-QUEEN). They combined their proposed front end technique with different noise compensation techniques such as, spectral subtraction or Wiener filtering and studied the performance of robust front end technique with AURORA 2J database. Reported results have confirmed the robustness of SPADE combined with different noise compensation techniques.A lot of research have been carried out to develop English, Mandarin, Spanish Arabic ASR. But Hindi speech recognizer is still to achieve standard benchmark. A few work has been carried out for Hindi speech recognizer. Due to this reason only a small percentage of computer-literate Indians are able to take advantage of the new advancement in the computer technology. Hindi is a major Indian language belonging to the Indo European family and being spoken by more than 310 million people across the world. Some amount of research has been carried out to develop Hindi ASR. Improvements have been reported by researchers, but still the desired benchmarks could not be achieved. There are few researches on wavelet feature extraction technique to design Hindi ASR system. Ranjan [15] has explored discrete wavelet transform (DWT) as possible effective feature extraction technique for Hindi digit recognition. He has explored five types of wavelet based feature extraction for Hindi digits recognition. Farooq et al. [16] have developed WP sub-band based temporal features for robust Hindi phoneme classification. Sharma et. al. [17] have proposed new WP sub-band based feature extraction technique for unaspirated Hindi stop consonants classification. Recently Biswas et al. [18] have proposed a new robust auditory ERB like WP based acoustic feature extraction technique. They have reported significant improvement with WERBC in Hindi consonant recognition application. This ERB scale was originally designed to model human cochlear filtering [19]. The center frequency and the bandwidth of each gammatone filter in GFCC can be derived from the filters ERB. They have tried to mimic the response of human cochlea by partitioning the frequency axis analogous to the ERB scale. Due to the dynamic nature of the WP, exact bandwidth alike to the ERB scale cannot be obtained. The advantage of using WP is that it can divide the frequency axis and has uniform translation in time. Though they have got significant improvement in classifications of unvoiced phonemes such as stops with WERBC but STFT based methods outperformed wavelet features in case of voiced phonemes. Here in this work we tried to enhance the performance of WERBC for Hindi voiced phoneme class. Motivated by the performance of WP based feature and SPADE analysis [9,11,14], here we discuss a WP based feature extraction technique named Wavelet ERB Subband based Periodicity and Aperiodicity Decomposition (WERB-SPADE). Wavelet packet (WP) decomposition is carried out similar to the Equivalent Rectangular Bandwidth (ERB) scale frequency resolution [18]. Here we tried to take the advantage of auditory ERB like WP filterbank to extract the coefficients at a certain frequency of interest. This paper shows a wavelet based feature extraction technique that decompose speech signals into periodic and aperiodic features for each sub band using ERB like wavelet filter banks and comb filters. To make the WERB-SPADE features more robust against noise, each noisy frame is processed through classical Wiener filter [20]. Phonetically balanced standard Hindi speech database [21] is used to study the performance of WERB-SPADE feature extraction technique.The rest of paper is organized as follows: Section 2 describes the feature extraction procedure using ERB like admissible wavelet packet (AWP) decomposition proposed by Biswas et al. [18] and describes the detailed WERB-SPADE mechanism. Section 3 gives brief overview of Hindi speech database. The experimental framework adopted for this experiment and the performances are discussed in Section 4. And finally Section 5 draws the conclusion.It has been proved that the especially the basilar membrane of the auditory human system can perceive the speech signal according to a non-uniform bank of filter. The human ear can perceive the signal under a composite auditory environment by using the masking property which means that the high intensity sound will hide the lower sound. Hence, it is interesting to work with a new feature extraction technique based on human auditory system properties. Fig. 1shows the step by step illustration of WERB-SPADE feature extraction technique.A frame size of 16ms with 10ms skip rate is used to derive WERB-SPADE features. If a particular phoneme is shorter than phoneme duration then zero padding is used. Initially, hamming window is applied on each frame. Then each frame is processed through noise estimator. Voice activity detector (VAD) [22] is used as noise estimator. The output of VAD is a binary process based on comparison between input speech signal and the threshold value. If the measured value greater than the threshold then VAD=1 and considered it as a voiced frame. In the opposite case, VAD=0 and the signal frame is considered as a noisy frame and in that case the particular noisy frame is processed through classical Wiener filter to minimize the noise level.The detailed description of wavelet analysis is beyond the focus of this paper. Hence, we request interested readers to refer literature [4,23]. The 24 sub-band wavelet packet tree is derived which mimic the ERB scale division as shown in [18]. The mathematical relationship between the center frequency (fc) and the ERB of an auditory filter is given by:-(1)ERB=24.74.37fc1000+1Wavelet packet gives a balanced binary tree structure. In the tree, each subspace is indexed by its depth j and the number of subspaces p. The two wavelet packet orthogonal bases at a parent node(j,p)are given by the following forms:-(2)ψj+12p(k)=∑n=-∞∞h[n]ψjp(k-2jn)(3)ψj+12p+1(k)=∑n=-∞∞g[n]ψjp(k-2jn)whereh[n]andg[n]are low pass and high pass filter respectively which are given by the following equations:-(4)h[n]=ψj+12p(u),ψjp(u-2jn)(5)g[n]=ψj+12p+1(u),ψjp(u-2jn)In a lucid word we can say that WP decomposition achieved by using a pair of conjugate mirror filters. Thus decomposing signal into two frequency bands such as lower frequency band (approximation coefficients) and higher frequency band (detail coefficients). Low frequency band is used for further decomposition. By cascading the two channel filter bank into various levels the wavelet packet tree is formed. Hindi speech data is sampled at 16kHz, giving an 8kHz bandwidth signal. Admissible WP transform is used to divide a signal into ERB filter like 24-sub-bands. Full 3-level wavelet packet decomposition is used to decompose whole frequency band into eight sub-bands each of 1kHz. Further one level full WP decomposition is applied to lowest sub-band of 0–1kHz to decompose the frequency band into two sub-bands each of 500Hz. The lower frequency band of 0–500Hz is further divided into eight sub-bands each of 62.5Hz by using full 3 level WP decomposition. The resulting sub-band division finely emphasizes frequencies between 0–500Hz which normally contains large portion of signal energy. Next, 500–1000Hz and 1–2kHz frequency band is decomposed using full 2 level WP decomposition to produce sub-bands each of 125Hz and 250Hz respectively. Then 2–3kHz and 3–4kHz frequency band is decomposed using full 1 level WP decomposition to get sub-bands each of 500Hz. Four frequency bands 4–5kHz, 5–6kHz, 6–7kHz, and 7–8kHz is kept unchanged. Lastly, 24 total frequency sub-bands are achieved. From the Table 1[18] it can be noted that for the first 20 sub-band wavelet frequency partitioning are analogous to the auditory ERB scale but the last 4 sub-bands differs from the ERB scale. This is well known fact that voice signals ranges up to 4000Hz and most of the speech signal energy lies below 1500Hz as seen in Fig. 2. It has been noticed that generally most of the energy of vowel lies below 2kHz and in case of voiced consonants lies below 3kHz These wavelet packet filters is proved efficient to extract certain information from speech signal by employing ERB like frequency decomposition. The 24 sub-band wavelet packet tree is derived which approximate the ERB scale division as shown in Fig. 3.The detailed block diagram is given in Fig. 1. The outcomes of auditory comb filter hypothesis [12] and SPADE analysis in noisy speech recognition [11,14] have strongly inspired to develop this technique. The hypothesis can be implemented in WERB-SPADE by using comb filters and ERB like WP decomposition of acoustic speech signal. This mechanism can be executed by decomposing speech signal into dominant periodicity and aperiodicity, which is the residue power after the suppression of the dominant periodic power.Each comb filter is designed by calculating the dominant periodicity of each WP sub-band output:WΨ(x,k)i(ith sub-band of kth temporal frame) is used to find dominant periodicity to design the comb filter. autocorrelation analysis for pitch (F0) estimation [24] is used to find dominant periodicity individually for each wavelet sub-band. Comb filters are designed individually to take care of false periodicity detection in case of multi-pitch signals. It is expected that SPADE mechanism can detect periodicity reliably. The basic function of a comb filter for each ith sub-band of kth frame can be expressed as:(6)h(n,k)i=∑l=-LLαl×δ(n-Ti,k)whereδ(n)is an unit impulse function,(2L+1)is the length of the filter,αlis the filter coefficient satisfying∑l=-LLαl=1andTi,krepresents the dominant periodicity detected in each ith sub-band of kth temporal frame. In the next step, the signal in the frame is passed through the comb filtered using the periodicity detected in the last step. Each sub-band signal is decomposed by the Comb filter into periodic and aperiodic features. Comb filtering performed according to following equation:-(7)〈WΨ(x,k)i〉comb=h(n,k)i⊗(WΨ(x,k)i)Next, the power suppressed by the comb filter is considered as periodic feature, and the residual signal power considered as aperiodic feature of speech signal. The calculation of periodic and aperiodic feature power vector is given below:(8)api(k)=1N∑j=1N|〈WΨ(x,k)i〉comb|2and(9)pi(k)=1N∑j=1N|WΨ(x,k)i|2-api(k)where,pi(k)andapi(k)are periodic and aperiodic feature vector of ith sub-band of kth frame respectively, N is the number of confidents in ith sub-band. In the last step, the power vectors across the all sub-bands of the same frame is log transformed and cepstral coefficients is calculate using discrete cosine transform(DCT).(10)cr(k)=M2∑i=1Mlog(PVi(k))cosπrM(i-05)where M represents the number of sub-band (in our case 24),PVi(k)is the periodic power vectorpi(k)or aperiodic power vectorapi(k)andcr(k)is the rth cepstral coefficient of kth temporal frame. Finally lower 13 coefficients from each power vector are taken and concatenated to signal feature vector (26 features/frame) representing each temporal frame.A Hindi speech database is used to classify the phonemes. From this database, a total of 90 speakers is taken, out of which 58 are male and 32 are females. Each speaker uttered 10 phonetically rich sentence, out of which two sentences were common for all the speakers. Training is carried out with 70 speakers (45 male and 25 female) and rest kept for testing. The phonetically rich sentences were designed at TIFR, Mumbai, India. The speech data was recorded at CEERI, New Delhi, India with 16kHz sampling frequency and stored in the 16-bit PCM-encoded waveform format in monomode using two microphones: one good quality close-talking, directional microphone and another desk-mounted at a distance of 1 meter omni-directional microphone. Here we have worked with five Hindi broad category phoneme classes as shown in Table 2. Furthermore, six noise such as car, jet, volvo, babble, speech, and lynx are used. Noisex-92 database is used in this work. Three kind of test sets are prepared to evaluate the robustness of WERB-SPADE feature extraction technique. First one is test set A, contains clean test speech signal. Next speech signals mixed with car, jet and volvo noise at SNRs of −5dB to 20dB is named as test set B. Test set C contains speech signals mixed with babble, speech, and lynx noise at SNRs of −5dB to 20dB. In this experiment, two training sets are used to train the Hidden Markov Model (HMM) [25] based phoneme classifier. First training set is named as clean-condition training set containing only clean speech signals. Another one is multi-condition training set containing clean speech signal and speech signal from test set B. Thus we have two types of training set and three types of testing set to study the performance of WERB-SPADE feature extraction technique.Mainly four type of feature sets are extracted to study the performance of phoneme classification task. The methods adopted in this experiments are:•MFCC (Baseline): The feature set are derived using standard MFCC technique having 24 channel mel scale filterbank. A frame size of 16ms with 10ms skip rate has been used to analyze the speech signal. The 13 cepstral coefficients including energy coefficient have been derived per speech frame.GFCC (Baseline): For GFCC the filter channel center frequencies are distributed according to ERB scale. 24 channel gammatone filterbank have been used to derive the features using same frame rate adopted for MFCC. After log compression and DCT operation first 13 features have been taken per frame.WERBC: WERBC features have been derived using db24 mother wavelet. Keeping same frame rate as baseline method 13 features are derived for each frame.In addition, all feature sets include the delta and acceleration coefficients to get 39 acoustic features per frame.WERB-SPADE: Wavelet ERB sub-band signals processed through SPADE analysis to decompose speech signal into periodic and aperiodic features resulting 26 features per frame. Inclusion of delta and acceleration coefficients make it 78 features per frame.One model is created for every phones and each HMM model has five emitting states with 8 to 32 Gaussian mixture components1Optimal mixture components are chosen in between 8 to 32. Results are shown in this paper based on optimum mixture model1(according to the occurrence of phonemes in database) with diagonal covariance. Experimental setup adopted for this experiment is shown in Fig. 4. Phoneme classification accuracy (PCA) is calculated by the following equations:-(11)PCA(%)=100(%)-PER(%)(12)PER(%)=(IntraSubstitution+InterSubstitutions)TotalPhoneme×100=InterSubs(%)+IntraSubs(%)Initially, phone classification task is carried out with features which does not consider contextual information (delta and acceleration coefficients) appended in the feature vector. Table 3shows the average phone classification accuracy (Test set A) of all four methods under clean-condition training and multi-condition training. Relative percentage gain compared to the commonly used MFCC features are also shown in Table 3. Table 4shows the performance analysis with delta and acceleration analysis. As expected, systems trained with dynamic features shows better performance because it captures the dynamic informations presents in speech signal. From Tables 3 and 4, it is observed that MFCC is shown adequate efficiency in clean condition training but in multi-training condition performance of MFCC is dropped significantly. MFCC has poor efficiency in case of unvoiced phonemes and seems more vulnerable in presence of noise. Due to this there is some inadequacies in clean condition training using MFCC. But switching the training condition did not affect too much on auditory based GFCC features. GFCC is purely auditory based method and center frequencies are distributed according to the ERB scale, which can focus and separate target speech in composite auditory scene. This proves the effectiveness of ERB scale while working in noisy condition. Further WERBC feature outperformed baseline features because it has benefit of time–frequency wavelet analysis along with sub-band decomposition according to the ERB scale. As described in Section 2.2 we have focused to increase the frequency resolution in the low-frequency range. This is well known fact that the discriminative information of the speech signal is embedded in lower frequency bands. The speech production-perception hypothesis suggests that for an optimal communication design, maximum signal energy should be embedded in the lower frequency region where more perception (frequency discrimination) is available.Now changing the focus to wavelet SPADE based technique. WERB-SPADE outperformed WERBC features by a significant margin in every case. SPADE estimates periodicity reliably in each sub-band to successfully reveal the two important properties of the speech signals. Inclusion of aperiodic features helps to improve to recognition of unvoiced phonemes such as stops, fricative and nasals. Thus without losing the certain information about aperiodicity of signal, WERB-SPADE provides more robustness compared to WERBC. WERBC decomposed the speech signals in the number of sub-bands according to the ERB scale by utilizing the rich covering of time–frequency property that can enrich the features to represent the short term behavior of the speech in well manner compared to STFT based techniques. WP provides an effective way to produce sub-band dependent partitions of the observation space and representing each sub-band into periodic and aperiodic speech features through comb filtering helps to catch essential discriminative information embedded in speech signal in an effective way. Periodic signal power in speech considered to be more robust to noise than the simple power until and unless the interfering noise signal does not having stronger periodicity than the target speech. Thus despite of inclusion of noisy speech from test set B not having significant impact on Gaussian mixture during multi-condition training with WERB-SPADE features. From now on for better analysis of detailed performance of wavelet based techniques we consider the clean-training condition system trained with dynamic features. Detailed phoneme classification is shown in Table 5and extensive PER analysis of wavelet SPADE based techniques is demonstrated in Table 6.From Table 5 it can be noted that the performance of WERBC is significantly goes low with voiced phonemes such as aspirated voiced and vowel class. Voiced consonants are periodic in nature and simple WP decomposition might be less sufficient to extract the periodic structure embedded in speech signal. Another reason of this low classification rate might be explained by the fact that the burst spectrum arises in voiced stop and its voiceless counterpart is very similar causing misclassification towards unvoiced phonemes. From Table 6 it is clear that the percentage of inter substitution rate is quite low with WERBC for voiced phoneme classes. But WERB-SPADE shows a fine improvement in intra substitution rate. The classification performance of voiced phoneme is enhanced with wavelet SPADE based recognizer because it finely represents the speech by its periodic and aperiodic property. Thus periodic information embedded in voiced phonemes is captured efficiently by WERB-SPADE technique.The experimental results using different front end features with noisy speech (Test set B and Test set C) and under clean and multi-condition training are shown in Fig. 5. This clearly shows the improved performance of the WP derived features for Hindi phonemes over MFCC and GFCC features.WP derived features are less sensitive to interfering signal and can focus to the target speech in composite auditory scene to extract the coefficients at a certain frequency of interest. Further, the results clearly show the effectiveness of WERB-SPADE based features in the presence of noise. These methods could considerably enhance noise robustness by using the periodic information of the speech signal, because periodicity is essentially less affected by interfering signal. Addition of Winer filter make the features more robust in the presence of noise. Wiener filter is applied at front end to take care of noisy frame. The decomposition of WP sub-band into two feature set helps to reduce the impact of the signal power distortion in noisy environments. In addition, aperiodic features clearly reflects sound onset and frequency transitions in a frame.In this section we discuss the result achieved with WERB-SPADE with other wavelet based feature extraction techniques mentioned in literature which also evaluates performances on different Hindi speech database. To keep this study uniform we have adopted same experimental framework and same database to evaluate the performance of all feature extraction techniques. A frame size of 16ms with 10ms skip rate is used for all the feature extraction techniques. All feature sets include the delta and acceleration coefficients. For comparative study we choose three other wavelet based features mentioned below:i.Db8 5-level wavelet packet feature extraction technique [15].8-Band wavelet packet feature extraction technique [16].ERB like wavelet packet cepstral features [18].Table 7shows the comparative performance of different wavelet based feature extraction techniques. WERBC feature extraction technique have shown better classification rate compared to Db8 5-level WP and 8-level WP. It can be seen from this Table 7, WERBC outperformed other features especially in low SNR conditions. Non uniform WP decomposition similar like human inner frequency response is effective to target and focus the speech signal in complex auditory scene. If we consider average phone classification accuracy, WERB-SPADE shows relative gain of 3.98% over WERBC. WERB-SPADE shows best performance among all feature extraction technique in clean condition as well as in noisy condition. By considering the periodic and aperiodic property of speech signal WERB-SPADE is more efficient to capture the periodic information from voiced speech signal as well as aperiodic information from unvoiced part of speech signal. Periodic and aperiodic features produced by auditory ERB like WP decomposition made it more robust compared to other wavelet features.Here we discussed a robust front end WP based feature extraction method which capture the periodic information embedded in speech without losing important aperiodic information. The method uses WP sub-band decomposing using auditory ERB scale and each subband is processed through comb filter to derive periodic and aperiodic feature set. Hindi phone classification task is carried out to study the performance of features. WERB-SPADE is found to be more effective to recognize the phoneme compared to baseline features. SPADE based technique shows satisfactory improvement over WERBC to classify voiced phonemes such as vowels. Wiener filter at the front end make the features more robust in noisy condition. Although WERB-SPADE features exhibit effectiveness in the presence of noise but these features have larger number of parameter compared to other methods mentioned in literature. So computational cost could be an important factor in real time speech processing. This is necessary to find out a trade-off between feature dimension and performance to make it more effective in real time conditions.

@&#CONCLUSIONS@&#
