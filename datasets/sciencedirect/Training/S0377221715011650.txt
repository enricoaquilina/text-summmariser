@&#MAIN-TITLE@&#
A branch-and-bound algorithm for the maximum capture problem with random utilities

@&#HIGHLIGHTS@&#
We discuss about linear and nonlinear integer reformulation for the maximum capture problem with random utilities.We strengthen the best-know MILP formulation for this problem.We present a greedy algorithm to solve a new relaxation of this problem.We embed these algorithms in a branch-and-bound scheme to solve the integer problem.We computationally benchmark our algorithm with current MIP and MINLP formulation on a exhaustive dataset.

@&#KEYPHRASES@&#
Facility location,Branch and bound,Maximum capture,Random utility model,

@&#ABSTRACT@&#
The maximum capture problem with random utilities seeks to locate new facilities in a competitive market such that the captured demand of users is maximized, assuming that each individual chooses among all available facilities according to the well-know a random utility model namely the multinomial logit. The problem is complex mostly due to its integer nonlinear objective function. Currently, the most efficient approaches deal with this complexity by either using a nonlinear programing solver or reformulating the problem into a Mixed-Integer Linear Programing (MILP) model. In this paper, we show how the best MILP reformulation available in the literature can be strengthened by using tighter coefficients in some inequalities. We also introduce a new branch-and-bound algorithm based on a greedy approach for solving a relaxation of the original problem. Extensive computational experiments are presented, benchmarking the proposed approach with other linear and non-linear relaxations of the problem. The computational experiments show that our proposed algorithm is competitive with all other methods as there is no method which outperforms the others in all instances. We also show a large-scale real instance of the problem, which comes from an application in park-and-ride facility location, where our proposed branch-and-bound algorithm was the most effective method for solving this type of problem.

@&#INTRODUCTION@&#
In recent years, competitive facility location models have received considerable attention both due to their interesting theoretical aspects and their practical applications. These models extend conventional facility location models to a more complex scenario, in which (a) companies compete for their market share and (b) the choices of independent decision makers, such as customers, are considered. As an example, we can think of a company that wants to locate r new supermarkets in a geographical zone where some supermarkets are already located (the competitors). The competitive facility location problem consists of choosing, from a given set of available locations, the locations for these r new facilities such that the demand captured by them (i.e. market share) is maximized.This problem can be traced back to Hotelling’s (1929) optimal location of two competing facilities on a line segment, and it was later embedded within the location theory, initially by Slater (1975) and further developed by Hakimi (1983).In general, the literature considers that customers choose among different alternatives based on a given utility function that depends on a set of facility attributes (e.g., distance, transportation costs and waiting times, among others). The first deterministic model was proposed by ReVelle (1986), in which customers choose the closest facility among different competitors. However, these models imply an “all or nothing” assignment, in which the demand of a given point is assigned entirely to one facility. An alternative approach is proposed in the gravity-based model (Huff, 1964; Reilly, 1931), in which the demand captured by a facility is proportional to the “attractiveness” of the facility and inversely proportional to a power of the distance. Drezner and Eiselt (2002) and Berman, Drezner, Drezner, and Krass (2009) provide a comprehensive review of these different models.Another alternative approach to the “all or nothing” assignment is to estimate the market share obtained by each facility through a random utility model. In random utility models (e.g., logit or probit models; see McFadden, 1973 or Ben-Akiva and Lerman, 1985), the utilities of economic agents are essentially derived from their preferences among a set of discrete options. In this case, the problem can be stated as follows: given a set of customers and their respective demands, a set of open facilities (the competitors), and a set of available locations, the problem is to locate r new facilities such that the expected market share captured by the new facilities is maximized, where the market share captured by each selected facility is estimated through a random utility model (e.g. logit). This problem is referred to as the maximum capture problem with random utilities (or MCRU problem, for short) and it was first introduced by Benati and Hansen (2002) with the multinomial logit model (MNL) as the underlying random utility model. Recent applications for this model includes locating schools (Haase & Müller, 2012), preventive healthcare facilities (Haase & Müller, 2015; Zhang, Berman, & Verter, 2012), and siting park-and-ride facilities (Aros-Vera, Marianov, & Mitchell, 2013).Since the multinomial logit model is nonlinear by nature, modeling the MCRU problem usually results in nonlinear integer programing models, which in general are difficult to solve. Benati and Hansen (2002) have proposed different approaches to address the problem, namely concave programing, integer fractional programing and submodular maximization. The computational analysis presented in the cited paper shows that the concave programing, which is basically a branch-and-bound algorithm with a concave relaxation of the problem as dual bound, behaves better than the other two approaches.Alternatively, equivalent Mixed-Integer Linear Programing (MILP) formulations have been proposed by Benati and Hansen (2002), Haase (2009), Aros-Vera et al. (2013), and Zhang et al. (2012). These formulations were recently evaluated by Haase and Müller (2014) to provide a computational comparison of them, being the model by Haase (2009) the most efficient in practice.In this paper, we show how the MILP model introduced by Haase (2009) can be strengthened by using tighter coefficients in a class of inequalities. We also introduce a greedy algorithm for solving a relaxation of the MCRU problem, which is embedded into a branch-and-bound (B&B) algorithm to compute dual bounds. The success of a B&B algorithm relies basically on finding a good threshold between the quality of the bounds and the computational effort needed to calculate them. In fact, the obtained dual bounds are not necessarily sharper than the ones given by the known linear and nonlinear formulations of the problem, but they can be calculated much faster than the others. This allows to explore more nodes of the B&B tree, which in many cases is more effective than spending too much time computing better bounds. Moreover, the proposed B&B algorithm can be easily implemented and does not make use of any external solver, while all the other methods considered here do.To evaluate the algorithm, extensive computational results are obtained for instances from three different datasets, namely the UflLib repository, the randomly generated instances introduced by Haase and Müller (2014), and a relatively large size instance (82341 customers and 59 available locations) that comes from a real application in location of park-and-ride facilities in New York City (Holguín-Veras, Reilly, Aros-Vera, Yushimito, & Isa, 2012). The methods considered here for comparison are the concave programing approach introduced by Benati and Hansen (2002), the MILP formulation introduced by Haase (2009) (using the tighter coefficients proposed in this work) and the proposed B&B algorithm. Results show that the proposed B&B algorithm is competitive with other available methods on all instances, and the most efficient method for solving the large real instance mentioned above.The remainder of this paper is organized as follows. In Section 2, we present the notation and definitions used throughout this paper. In Section 3, we present some mathematical formulations for the MCRU problem found in the literature and show how the MILP model introduced by Haase (2009) can be strengthened by using tighter coefficients in a class of inequalities. In Section 4, we introduce a new B&B algorithm for the MCRU problem. The computational results are presented in Section 5. Finally, in Section 6 we draw some conclusions and present opportunities for future work.In this section, we give a formal description of the MCRU problem. Before describing the problem itself, we first explain the behavioral rationale underlying the customers’ decisions, in which the market share captured by a particular facility is based on the preferences of the customers, which results in a choice probability of selecting a particular facility.Let S be a set of customers and H be a set of open facilities. Each customer s ∈ S receives a utilityu˜slfor choosing the facility l ∈ H. Assuming that customers behave rationally, each customer selects the facility that provides the highest utility value. That is, a customer s ∈ S chooses a facility l ∈ H ifu˜sl≥u˜sh,∀h∈H.In random utility theory, the utilityu˜slobtained by customer s ∈ S choosing a facility l ∈ H has two components: a deterministic part vsland a random term ϵsl, such thatu˜sl=vsl+ϵsl. The deterministic part is typically referred to as the systematic component, because it is composed of a set of observable attributes (e.g., distance and time), whereas the random components represent the non-observable attributes. The joint density of the random vectorϵs={ϵs1,…,ϵsl},denoted by f(ϵs), allows us to state the probability of choosing an alternative. According to McFadden (1973), whenever the elements in ϵsare identically and independently distributed, they have equal variability among cases, and f(ϵs) follows a Generalized Extreme Value (GEV) distribution (i.e., Gumbel distribution), the model is referred to as the multinomial logit model, and the probability that a customer s selects a facility l from the given set H of open facilities is given by the following equation:(1)psl=evsl∑h∈HevshIn the MCRU problem, it is given a set L of available locations, a set A of open facilities (the competitors) and a set S of customers. For simplicity, we sometimes refer to an available location l, where a new facility can be located, as a facility itself. For each customer s ∈ S, it is given a positive demand dsand a utility vslfor choosing the facility located in l ∈ L ∪ A. The objective is to choose a subset L* ⊂ L of r locations where new facilities can be located, such that the expected demand captured by the new facilities is maximized, which is given by(2)∑s∈S∑l∈L*dspslAccording to (1), the probability that a user s ∈ S chooses a facility l ∈ L* is given by(3)psl=evsl∑h∈L*∪AevshNote that, w.l.o.g., we can assume that there is a single open facility (i.e.,|A|=1). If there is more than one open facility (i.e., |A| > 1), we can represent them as a single facility a such thatvsa=log(∑i∈Aevsi). Hence, for simplicity, we assume that there is a single open facility a. Note that higher values of vsarepresent a problem with stronger incumbent competitors.Given a subset H ⊂ L of open facilities, let ϕ(H, s, l) be the expected demand of customer s captured by the facility located in l, which is given by(4)ϕ(H,s,l)=dsevsl∑h∈H∪{a}evsh=ds∑h∈H∪{a}e(vsh−vsl)Because the total demand is split between the open facilities, we have(5)∑s∈S∑l∈H∪{a}ϕ(H,s,l)=∑s∈SdsTherefore, the MCRU problem seeks for a subset L* ⊂ L of r locations that maximizes∑s∈S∑l∈L*ϕ(L*,s,l)or, equivalently, minimizes ∑s ∈ Sϕ(L*, s, a). In the second case, we are minimizing the expected demand captured by the competitor a.In this section, we present some approaches based on mathematical formulations to solve the MCRU problem, namely the concave programing approach introduced by Benati and Hansen (2002) and the MILP formulation introduced by Haase (2009). Finally, we show how this last formulation can be strengthened by using tighter coefficients in a class of inequalities.Benati and Hansen (2002) have proposed different approaches to solve the MCRU problem, namely concave programing, integer fractional programing and submodular maximization, being the first one the most promising approach, according to the computational results presented in the cited paper. We now present the main idea behind the concave programing approach.Consider a binary variable xl, for each l ∈ L, with the interpretation thatxl=1if and only if a new facility is located in l (i.e., x is the characteristic vector of the solution). A natural formulation for the MCRU problem can be obtained by simply rewriting the statement of the problem using the x variables, which results in the following integer nonlinear programing model:(1.1)max∑s∈S∑l∈Ldsevslxlevsa+∑h∈Levshxh(INLPMCRU)s.t.∑l∈Lxl=r(1.2)xl∈{0,1},∀l∈LIn Benati and Hansen (2002) it is shown that the objective function of the continuous relaxation of (INLPMCRU) is concave. The authors use this fact to calculate an upper bound by relaxing the integrality constraints of (INLPMCRU) and then solving the problem by gradient optimization. To solve the original problem, this upper bound calculation is embedded into a branch-and-bound algorithm.As shown in the previous section, a natural formulation for the MCRU problem results in a nonlinear model. Alternatively, research efforts have been made on finding equivalent MILP formulations. Recently, Haase and Müller (2014) provided a computational comparison of the different MILP formulations in the literature, concluding that the formulation introduced by Haase (2009) outperforms the other models studied. In this section, we present the MILP formulation introduced by Haase (2009) for the MCRU problem and we show how one of its constraints can be strengthened.The variables x are used with the same interpretation as in (INLPMCRU) and we introduce a variable psl, for each s ∈ S and l ∈ L ∪ {a}, to represent the probability that the customer s chooses the facility located in l. To simplify the presentation of the formulation, we define the constantγsl=e(vsl−vsa),for each l ∈ L and s ∈ S. We now present the MILP formulation introduced by Haase (2009).(2.1)max∑s∈S∑l∈Ldspsl(MILPMCRU)s.t.γslpsa≥psl,∀s∈S,∀l∈L(2.2)psl≤γsl1+γslxl,∀s∈S,∀l∈L(2.3)∑l∈L∪{a}psl=1,∀s∈S(2.4)∑l∈Lxl=r,(2.5)psl≥0,∀s∈S,∀l∈L∪{a}(2.6)xl∈{0,1},∀l∈LConsidering the objective function, we see that constraints (2.1) are satisfied with equality whenxl=1. Thus,psl=γslpsa=evslevsa·evsa∑h∈Levshxh+evsa=evsl∑h∈Levshxh+evsa,which is precisely the probability that a customer chooses the facility located in l, according to Eq. (3).Constraints (2.2) state that the probability of a customer choosing a facility located in l can be positive only if the respective location is chosen (i.e., ifxl=0,thenpsl=0for each s ∈ S).In constraints (2.2), we can replace the coefficient of xlby any constant greater than or equal to the maximum value that pslcan achieve. Aros-Vera et al. (2013) proposed an analogous formulation, in which constraints (2.2) are presented with the constant 1 rather thanγsl1+γsl,which is clearly a weaker formulation. We now show that constraints (2.2) can be strengthened even further.Lemma 1Given a customer s ∈ S and a location l ∈ L, let L(s, l) ⊂ L be a subset of r locations such that l ∈ L(s, l) and vsh≤ vst for each h ∈ L(s, l)∖{l} and t ∈ L∖L(s, l). Then, L(s, l) is a subset of r locations that maximizes the probability that the customer s chooses the facility located in l.In contrast, suppose that H ⊂ L is a subset of r locations containing l such thatevsl∑h∈Hevsh>evsl∑t∈L(s,l)evst. Thus, there are locations h ∈ H and t ∈ L(s, l) such that vst> vsh, t ∈ L(s, l)∖{l} and h ∈ L∖L(s, l), which is in contradiction to the Lemma’s hypothesis.□As a consequence of Lemma 1,evslevsa+∑h∈L(s,l)evshis the sharpest upper bound on the value that variable pslcan achieve. Thus, replacingγsl1+γslbyγsl1+∑h∈L(s,l)γshin constraints (2.2) leads to a formulation for the MCRU problem which is stronger than (MILPMCRU).Below, we give an example in which replacingγsl1+γslbyγsl1+∑h∈L(s,l)γshin constraints (2.2) produces a strictly smaller value in the objective function of the linear relaxation of (MILPMCRU).Example 2Assume thatvsa=vsl,for each s ∈ S and l ∈ L. In this case, any subset of r locations is an optimal solution to the MCRU problem, in whichpsa=1r+1andpsl=1r+1,for each location l in the chosen subset, obtaining an optimal objective value ofrr+1∑s∈Sds. For the linear relaxation of (MILPMCRU), sinceγsl=1it has an optimal solution equal toxs=r|L|andpsl=1|L|+1for each s ∈ S and l ∈ L, obtaining an objective value of|L||L|+1∑s∈Sds. However, replacingγsl1+γslbyγsl1+∑h∈L(s,l)γshin constraints (2.2), we obtain the constraintpsl≤1r+1xl,for each s ∈ S and l ∈ L. Hence, the previous solution is infeasible and now the optimal solution isxs=r|L|andpsl=r(r+1)(|L|),for each s ∈ S and l ∈ L, obtaining an objective value equal to the optimal integer solution.In this section, we introduce a branch-and-bound (B&B) algorithm for the MCRU problem. We first present a greedy algorithm for solving a relaxation of the original problem, which is later embedded into a B&B algorithm to compute upper bounds in each node of the B&B tree.As in the previous formulations, our algorithm also represents a solution by a vector x ∈ [0, 1]|L|, with the interpretation thatxl=1if and only if a new facility is open in location l. To illustrate the concept behind our algorithm, we first present an example of how it works.Consider an instance of the MCRU problem in whichL={l1,l2,l3,l4}andS={s1,s2,s3,s4},we want to selectr=2locations and we have unitary demands (i.e.,ds=1for each s ∈ S). Table 1presents the deterministic utility vslfor each s ∈ S and l ∈ L ∪ {a}.We denote the subset containing the locations liand ljbyLi,j={li,lj}. Given a feasible solution Li, j, the expected demand of a customer s captured by the facilities located in liand ljis given by(6)∑l∈Li,jϕ(Li,j,s,l)=evsli+evsljevsli+evslj+evsaIn Table 2, we show the objective value of each feasible solution according to Eq. (6). As shown in this table, considering each customer independently, the only local optimal solutions for customers s1, s2, s3 and s4 are L1, 3, L1, 2, L1, 4 and L2, 3, respectively. The primary objective of our algorithm is to solve a relaxed problem in which we consider a local optimal solution for each customer and from this solution derive an upper bound for the global optimal value. In the given example,∑l∈L1,3ϕ(L1,3,s1,l)+∑l∈L1,2ϕ(L1,2,s2,l)+∑l∈L1,4ϕ(L1,4,s3,l)+∑l∈L2,3ϕ(L2,3,s4,l)=4×0.6¯=2.6¯is an upper bound on the global optimal value, which is ≈ 2.40 (the global optimal solutions are L1, 2 and L1, 3). Intuitively, considering all available locations (i.e., potential facilities) in decreasing order of deterministic utility provided to a customer s, the corresponding local optimal solution is obtained by selecting the first r potential facilities. Note that locations l1, l2, l3 and l4 appear in a local optimal solution 3, 2, 2, and 1 times, respectively, which leads to the fractional solutionx=(34,12,12,14).In our B&B algorithm, we first solve the relaxation of the original problem as described above, obtaining a vector x ∈ [0, 1]|L| and an upper bound on the optimal value. If x is integral, it corresponds to an optimal solution for the original problem, and the upper bound calculated is precisely the optimal value. Otherwise, we choose a fractional variable xland create a subproblem in which the constraintxl=0must be satisfied and another subproblem in whichxl=1must be satisfied. Thus, at any node of the B&B tree, we have a subset L0 ⊂ L of locations that are not allowed to be chosen and a subset L1 ⊂ L of locations that must be chosen. At the root node of the B&B tree, we have thatL0=L1=∅.Algorithm max_utility_greedy, presented below, maximizes the total expected utility received by each customer individually (i.e., it finds a local optimal solution for each customer). It considers two subsets of locations, L0 and L1, where locations in L0 are forbidden and locations in L1 are enforced. Given the subsets L0 and L1 as parameters, the algorithm returns an upper bound ub on the optimal value and a vector x ∈ [0, 1]|L|, possibly fractional, representing all the customer’s choices.Clearly, the algorithm max_utility_greedyterminates in polynomial running time. Moreover, Lemma 3 can be easily shown, which implies that the algorithm max_utility_greedyis correct.Lemma 3Let(ub,x)be the solution returned by the max_utility_greedyalgorithm, and letoptbe the value of an optimal solution for the corresponding MCRU subproblem, in which the locations in L0are forbidden and the locations in L1are enforced. The following properties are satisfied:(a)∑l∈Lxl=r;xl=0for each l ∈ L0;xl=1for each l ∈ L1;ub≥opt;If x is integral, thenub=opt.We first present a greedy heuristic for finding a feasible solution for the MCRU problem that leads to a lower bound on the optimal value. This heuristic has been studied in Benati and Hansen (2002), proving that it provides an ρ-approximation, withρ=ee−1.Given subsets L0 ⊆ L and L1 ⊆ L, the algorithm greedy_heuristic, presented below, returns a feasible solution for the corresponding instance of the MCRU problem (i.e., a subset H ⊆ L of r locations such that L1 ⊆ H andL0∩H=∅).The choice of the next element to be included in H is made (in line 3) by selecting a location that provides the highest increase in the objective function.The method that we propose here to solve the MCRU problem is a standard B&B procedure which invokes max_utility_greedy and greedy_heuristic algorithms as subroutines for calculating the upper and lower bounds, respectively. We skip the unnecessary implementation details and focus only on the main aspects of the algorithm.At each step, we have a set of live nodes, which correspond to the nodes that were not explored yet and are children of some explored node. Initially, the set of live nodes contains only the root node, which has no fixed variables. The choice of the next node to be explored is made by taking one live node with the maximum upper bound, aiming to decrease the global upper bound as soon as possible. After removing a node η from the set of live nodes, two new nodes γ0 and γ1 are created as children of η. A variable x(η)lwith the most fractional value is selected (ties are broken by taking the first one in lexicographical order) and then all nodes in the subtrees rooted in γ0 or γ1 will consider location l as forbidden or enforced, respectively. Naturally, if a node provides an integer solution or an upper bound which is not larger than the value of a known feasible solution, we do not add his children to the set of live nodes. The algorithm stops when either global upper and lower bounds are equal or the given time limit is exceeded.Before adding a node to the set of live nodes, we could call greedy_heuristic to find a feasible solution, with the respective fixed variables, to attempt to increase the global lower bound. We decided not to implement this approach, because empirical tests revealed that this approach slows the procedure rather than speeding it up.We now present computational results for instances obtained from two different datasets, namely the UflLib repository and the randomly generated instances introduced by Haase and Müller (2014), and also for a relatively large size instance (82341 customers and 59 available locations) that comes from a real application in location of park-and-ride facilities in New York City. The methods considered here for comparison are the concave programing approach introduced by Benati and Hansen (2002), the MILP formulation introduced by Haase (2009) (using the different coefficients, proposed in this work, for inequalities (2.2)) and the B&B algorithm introduced in Section 4.We divide the presentation of the results into three parts. We first compare the presented relaxations, aiming to establish which one provides the best dual bound among them. We then compare the presented exact methods, aiming to establish which one is the most efficient in practice in terms of running time, regardless of the quality of the dual bounds. In these first two parts, we use the two datasets mentioned above. Finally, we apply the exact methods to solve the real problem instance which comes from an application in park-and-ride facility location in New York City.Before presenting the results, we first describe some implementation details, as well as the machine configurations and the datasets.We have implemented the MILP formulation introduced by Haase (2009), which is the most efficient MILP formulation for the MCRU problem, according to the computational study in Haase and Müller (2014). Besides this formulation as it was introduced, we consider here two other versions of it which differ only by the coefficient in constraints (2.2), as explained in Section 3.3. One of them is due to (Aros-Vera et al., 2013), while the other one was introduced in this work and, as shown in Lemma 1, it has the tightest coefficient among these three formulations. We denote the above three approaches by (H09), (AV13) and (FMY15), respectively. We solved these formulation using IBM-ILOG CPLEX 12.6 under default settings.We have also implemented the concave programing approach introduced by Benati and Hansen (2002), as described in Section 3.1. More precisely, we embedded their nonlinear model in our B&B algorithm, replacing the calls of max_utility_greedy by their concave relaxation. To solve this nonlinear relaxation, we used the method-of-moving-asymptotes (MMA) algorithm (Svanberg, 2002), implemented in NLopt 2.4.2 library (Johnson, 2014). We denote this approach by (CP).The branch-and-bound algorithm presented in Section 4, which calls the MAX_UTILITY_GREEDY algorithm to compute upper bounds, was implemented in C++ programing language and compiled using GCC 4.4.6. We denote this approach by (MUG).The same notation is used to designate an exact method as well as its corresponding relaxation, being clear by the context which of them is referred to. All computations were made in machines running Linux 2.6.32 under x86_64 architecture, with two quad-core Intel Xeon E5-2650 processors and 146 Gb of RAM.Our first dataset was generated as in Haase and Müller (2014). That is, we randomly locate |S| customers and |L| locations over a rectangular region of 30 × 30. We set a cost cslequal to the distance from each customer s ∈ S to each location l ∈ L. To represent the competitors, we also randomly locate ⌈|L|/10⌉ points in the region, and we set the cost csaequal to the minimum distance between each customer s ∈ S to these points. We generated instances with 50, 100, 200, and 400 customers; and 25, 50, and 100 locations. We denote this dataset by HM14.We now describe the dataset which corresponds to the ORlib instances, taken from the UflLib repository (Hoefer, 2003), for the uncapacitated warehouse location problem. Since these instances were constructed for a slightly different problem, we only considered the demand and the cost from each customer for each facility csa. To introduce competition, for each customer s, we also randomly choose a subset of ⌈|L|/10⌉ facilities and set csaequal to the minimum cost among this subset. We omitted the instances cap71, cap72, cap73 and cap74 because they are too small and can be solved by all algorithms in a few seconds. We denote this dataset by ORlib.Finally, we describe the dataset generated from a real instance of the MCRU problem. The instance was obtained from the NYMTC (2009) and it corresponds to an improved version of the location of park-and-ride facilities in New York City, presented in Aros-Vera et al. (2013). The data include 82341 trips from 3600 origins in New York, New Jersey and Connecticut to 317 destinations in Manhattan, representing the demand in the morning peak. The “facilities” available are park-and-ride locations which can be selected among 59 candidate locations (state-owned available parking lots). That is, each customer (a trip from one origin to another destination) chooses between the incumbent solution (a direct auto trip) or a given facility (an auto trip from origin to the park-and-ride, and a transit trip from the facility to its destination). Hence,|S|=82341and|L|=59. The generalized costs used in the logit function consist of direct auto trip costs (including travel time, tolls, and auto costs) from an origin to the park-and-ride location, plus transit costs (travel times and waiting time) from that location to the destination. The incumbent cost only considers the direct auto trip from the origins to the destination. We denote this dataset by P&R-NYC.For each instance, we have solved the problem forr=2,3,…,10. The deterministic part of the utility function is given byvsl=−θ·csl,for each location, and byvsa=−α·θ·csa,for the competitors. Parameter θ represents the sensitivity of customers about the perceived utility and parameter α allows us to vary the competitiveness of the incumbent competitors. In each part of the experiments, we have considered a specific choice of parameters θ and α, which is described latter on.Although we proved that the linear relaxation (FMY15) dominates (H09), which in turn dominates (AV13), as explained in Section 3.3, we are still interested in comparing these three relaxations to establish how they differ from each other in practice. For this analysis, we have considered different values for θ and α, specificallyθ=0.001×(1.2)i,fori=1,2,…(up toθ=10) andα=0.2×i,fori=1,2,…(up toα=10).In Fig. 1 we show the results for relaxations (FMY15), (H09) and (AV13), while in Fig. 2we show the results for the relaxations (FMY15), (CP) and (MUG). We plot the gap between the value of each relaxation and the best-know feasible solution, for the different values of θ and α (in the horizontal axis). In these figures we present the numerical results for only one instance (a representative) from each dataset. For the other instances in each dataset basically the same pattern with no significant variations is obtained.As Figs. 1 and 2 show, the quality of the relaxations strongly depends on the dataset and the values of the parameters α and θ. It can be seen in Fig. 1 that the relaxations (FMY15) and (H09) are very close to each other, while (AV13) is significantly weaker.As Fig. 2 shows, for the HM14 dataset, the (FMY15) relaxation obtained gaps close to zero for all values of parameters α and θ, while (CP) and (MUG) relaxations obtained similar gaps in many cases, achieving a gap of ≈ 70 percent, depending on the values of these parameters. On the other hand, for ORlib dataset, the (CP) relaxation obtained gaps very close to zero for all instances, while the relaxations (FMY15) and (MUG) obtained similar gaps, achieving a gap of ≈ 20 percent, depending on the parameters θ and α.Considering the time spent by each method to solve the corresponding relaxation, the (CP) was the slowest one, with an average time of 32.4 seconds per instance, while (FMY15) spent 15.72 seconds per instance, in average, and the time spent by (MUG) was negligible (less than a second for all instances). In the first two cases, the dispersion of the time was considerable high, with 15–20 percent of the instances being solved in less than a second.The success of a B&B algorithm relies basically on finding the best balance between the quality of the bounds and the computational effort needed to calculate them. As Figs. 1 and 2 show, (MUG) does not provide an upper bound sharper than the considered linear and nonlinear formulations. On the other hand, the upper bound given by (MUG) can be calculated much faster than the others, allowing to explore more nodes of the B&B tree, which in many cases is more effective than spending too much time computing better bounds, as the next section shows.We now compare the performance of the exact methods considered in this paper. For this analysis, we have considered θ ∈ {1, 5, 10} and α ∈ {0.01, 0.1, 1}, representative of the different behavior observed in Figs. 1 and 2. This results in a total of 972 instances from HM14 and 891 instances from ORlib. We have given a time limit of one hour per instance.Note that all the methods considered here have in common that each one of them solves a relaxation embedded in a B&B algorithm. In the case of (CP) and (MUG), the B&B algorithm was implemented as explained in Section 4.3, while in the MILP approaches ((AV13), (H09) and (FMY15)) we have used CPLEX, which provides its own branch-and-cut implementation, as well as other advanced techniques (presolving, some different general purpose cutting planes generation, more sofisticated branching strategies, etc...). None of these techniques was used in our B&B algorithm.In Fig. 3, we present the performance profiles (see Dolan & Moré, 2002) of the different methods on HM14 and ORlib. Each curve plots the fraction of instances solved by each method before a given time (in horizontal axis). Further details are provided in Tables 5 and 6.As Fig. 3 shows, in both graphs clearly there are two different curve patterns, where (MUG) and (CP) follow the same pattern, while the MILP formulations follow another pattern.For the HM14 dataset, although the MILP formulations have solved more instances than the other two methods, for almost 70 percent of the instances(MUG)was the fastest method. On the other hand, for the ORlib dataset, the MILP formulations were the slowest ones, being unable to solve any of the largest instances (capa, capb and capc). Comparing only the MILP formulations, (FMY15) and (H09) obtained similar performances for the HM14 dataset, while (FMY15) could solve ≈10 percent more instances than (H09) for the ORlib dataset. For both datasets, (AV13) was slower than the other two MILP formulations.Although the curves representing (MUG) and (CP) in Fig. 3 follow a similar pattern, further analysis shows that the performance of (CP) strongly relies on the quality of the relaxation in the root node of the B&B tree, while this behavior is not observed in the (MUG) method. This is also explained by the fact that the lower bound found by the greedy_heuristic algorithm is optimum in almost all cases and it is very close to the optimal in the other cases. Hence, the quality of the relaxation plays an important role. For example, for instances in HM14 withα=0.1,in which the initial gaps reach the peak (see Fig. 2), the (CP) method could solve only 156 of the 324 instances, while (MUG) solved 229 instances (≈46 percent more than (CP)) among this same subset of instances. This can be explained by the fact that, in general, the (CP) method spends considerably much more time solving its corresponding relaxation than (MUG), allowing it to visit only a small number of nodes of the B&B tree.We conclude fromthe presented experiments that there is no method which overcomes the others in all instances and, for each method considered here (apart from (AV13)), there is a subset of instances for which the respective method is the most efficient. For HM14 instances, (MUG) was more efficient than (CP), while for the ORlib it was the opposite. Considering only the MILP formulations, (FMY15) provided the tightest relaxation and was more efficient than the others.We now compare the performance of the exact methods presented on a real instance of the problem, which comes from an application in park-and-ride facility location. Since utilities of each customer are linearly correlated with the travel time of each trip, for this analysis we have considered θ ∈ {0.5, 1, 2} and α ∈ {0.5, 1, 2}, resulting in a total of 81 instances. We have given a time limit of 8 hours per instance. For all instances in this dataset, all the MILP formulations could not solve even the linear relaxation . Hence, we limit the analysis to the other two methods, namely (MUG) and (CP).In Table 3 the results are grouped by the value of r, while in Table 4 the results are grouped by the values of α and θ.As Table 3 shows, for the instances with r from 2 to 8, (MUG) solved all the 63 instances, while (CP) solved only 41 instances ( ≈ 35 percent less). In all cases, the initial gap obtained by (CP) was tighter than (MUG). On the other hand, (MUG) could visit much more nodes of the B&B tree than (CP) and, in most cases, it was also much faster than (CP).Considering the instances grouped by the values of α and θ (see Table 4), we observe that the choice of these parameters strongly influences the results, which was predictable if we consider the analysis presented in Section 5.3. For example, forα=0.5,the (CP) method solved all the instances in the root node of the B&B tree (i.e., the relaxation found an integer solution) in a few seconds, while forα={1,2}andθ=2it could not solve (in 8 hours) the relaxation for any of the 18 instances. This shows that the performance of the (CP) method is very sensitive not only to the input size but also to the numbers which appear as input (the utility function). This discrepancy is not observed in the (MUG) method. Moreover, appart from 3 rows (2nd, 4th and 5th) of Table 4, (MUG) was considerably faster than (CP) and it could solve a greater number of instances as well.From Tables 3 and 4, we conclude that the performance of the (MUG) method is more related to the value of r than to the values of the parameters θ and α, while the (CP) method behaves in the opposite way. As observed, (CP) was able to visit a very small number of B&B nodes and, as a consequence, it can solve the problem only in the cases in which the initial gap is very close to zero. Instead, the (MUG) method calculates the dual bounds very quickly, allowing it to solve the problem also when the initial gap is not so tight.In this work, we have introduced a strengthened version of the MILP formulation presented in Haase (2009), which was the most efficient MILP formulation for the MCRU problem, according to the computational experiments presented by Haase and Müller (2014). As our computational results showed, the proposed strengthened MILP formulation provided slightly better dual bounds and also could solve more instances to optimality than the other MILP formulations.We have also introduced a greedy algorithm for solving a relaxation of the MCRU problem, which is embedded into a branch-and-bound (B&B) algorithm to compute dual bounds. Considering all the exact methods discussed in this work (MILP formulations, a concave programing approach and our B&B algorithm), we concluded that there is no method which overcomes the others in all instances and, for each method considered here, there is a subset of instances for which the respective method is the most efficient. The proposed B&B algorithm was the most efficient method for solving a dataset which comes from an application in location of park-and-ride facilities in New York City. Moreover, this algorithm can be easily implemented and does not make use of any external solver, while all the other methods considered here do.Note that the MCRU problem still has some simplifications compared to other facility location problems. There are two natural extensions to this family of facility location problems. One extension is to replace the cardinality constraint by a budget constraint, assuming that an opening cost is associated to each location and the total cost of the chosen locations cannot exceed a given budget. For this problem, our B&B algorithm can be adapted in a natural fashion, solving a knapsack problem to calculate the dual bounds. We leave further details and computational experiments for this variant of the problem for a future work. Another extension is to consider capacity constraints, which requires that the total expected demand captured by each facility do not exceed its given capacity. Such constraints can easily be incorporated into the MILP models, although maybe these models would become very hard to solve in practice. For this variant of the problem, even finding a feasible solution seems to be NP-hard.

@&#CONCLUSIONS@&#
