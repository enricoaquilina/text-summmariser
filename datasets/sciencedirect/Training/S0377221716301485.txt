@&#MAIN-TITLE@&#
Forward thresholds for operation of pumped-storage stations in the real-time energy market

@&#HIGHLIGHTS@&#
We develop the idea of forward thresholds for operations at pumped-storage plants.We argue that using forward thresholds leads to efficiency and financial gains.A multistage stochastic programming framework is developed to optimize the thresholds.Tractability issues are discussed and a novel solution methodology is proposed.We show stability, quality, and superiority vs deterministically obtained thresholds.

@&#KEYPHRASES@&#
Stochastic programming,OR in energy,Large scale optimization,Metaheuristics,Energy markets,

@&#ABSTRACT@&#
Pumped-storage hydroelectric plants are very valuable assets on the electric grid and in electric markets as they are able to pump and store water for generation, thus allowing for grid-level storage. Within the realm of short-term energy markets, we present a model for determining forward-looking thresholds for making generation and pumping decisions at such plants. A multistage stochastic programming framework is developed to optimize the thresholds with uncertain system prices over the next three days. Tractability issues are discussed and a novel method based on an implementation of the scatter search algorithm is proposed. Given the size of the multistage stochastic programming formulation, we argue that this novel method is a more accurate representation of the decision process. We demonstrate model stability and quality, and show that the forward thresholds obtained using a stochastic programming framework outperform the forward thresholds from a deterministic model, and thus can lead to efficiency gains for both the generation unit owner and the overall system in the real-time market.

@&#INTRODUCTION@&#
As capital costs of renewable generation assets continue to decrease and an increasing portion of electrical demand is satisfied by renewable sources, significant attention is being given to storage of electricity. A sizeable share of renewable generation, like wind and solar, is intermittent, and thus those resources become more valuable if one is able to store their output efficiently. Pumped-storage hydroelectric plants are generation assets that can generate power by using water to turn their turbines. They are highly valued on an electric grid because they are also able to pump water and keep it in a reservoir for future use. Hence, they can be used by system operators to balance the load, and can be thought of as huge batteries offering the ability to store energy.Gains in efficiency at a pumped-storage plant can stem from mechanical and engineering improvements that lead to the plant using less power to pump the water. Financial gains can also be achieved by utilizing the plant more efficiently in day-to-day operations. This study focuses on the latter aspect.Units that participatein an energy market are most often dispatched based on the “marginal cost” of generating one extra unit of energy. As we discuss in Section 2, this measure of cost is difficult to define for pumped-storage units. As a result, energy price thresholds, which act as a measure of the value of the water, are used by some generation owners to dispatch pumped-storage units. Hence, while thresholds are used in industry, to the best of our knowledge, the current practice is to compute these thresholds using deterministic models and analyses. In this paper, we introduce a stochastic programming framework to compute high-quality thresholds by explicitly considering the stochasticity in the real-time energy prices. We establish the superiority of thresholds determined from the proposed stochastic framework over their deterministically determined counterparts. In the process, we also offer a new approach to obtaining high-quality solutions for large-scale problems of this kind, which are otherwise intractable, using either large-scale decomposition schemes or dynamic programming. Furthermore, we argue that the formulation we solve is a more accurate model of the real-world process because of the way decisions are carried out in practice. We also present an overview of the models and scenario generation methods we developed for the locational marginal prices which we take to be uncertain, and we empirically analyze our modeling framework through stability and quality testing, as well as simulations of real-time operations.We describe the problem and the business case in more detail in Section 2. In Section 3, we give a literature review of related energy applications. We propose our modeling methodology in Section 4, and our algorithm to solve the problem in Section 5. In Section 6, we describe the process used to model energy prices, generate scenarios, and offer evidence of stability and quality. Section 7 deals with the computational performance of the algorithm and discusses the impact the proposed thresholds are expected to have on the operations of the plant. Finally, we conclude with closing remarks in Section 8.The assumed market environment is referred to as “two-settlement” as it has a day-ahead (DA) and a real-time (RT) component, and each part is cleared, or settled, separately. The market operator is an independent entity responsible for clearing wholesale transactions on the market, such as PJM who operates the world’s largest wholesale market. In the day-ahead market, cost curves are submitted by generation owners, and an hourly generation schedule is awarded by the market operator for the next-day operations. The real-time market is the “day of operations” market. Generation owners are paid based on the deviation of their units’ generation from the day-ahead schedule. Specifically, any real-time generation shortage (excess) from the day-ahead award has to be bought from (sold to) the market.The dispatching (or operating at a certain output level) of generation units is primarily based on the incremental or “marginal” cost of generating an additional megawatt hour of electric power. Our focus in this research is on determining a coherent dispatching cost for pumped-storage stations for use in the real-time market. Accurately assessing a generation unit’s marginal cost is essential for its profitability and the efficient operation of the market as a whole. Throughout this paper, we assume the electricity market setup is similar to PJM, in which units are dispatched in a least-cost order.If the estimated cost of generation at power plants is not their true cost, generation units could come online “out-of-merit.” If a particular generation unit is underpriced, its place in the bid stack would be lower than it should be, meaning that it would generate electricity when cheaper resources are not doing so. In the same vein, if a generation unit is overpriced, it would be bypassed in favor of more expensive units. In both of these cases, a waste of resources occurs, and the owner of that generation unit is hurt financially, while the market is not as efficient and cost-effective as it could be.We explain settlements of the day-ahead and real-time energy markets using a simplified example. In the day-ahead case, the hourly award for a particular generation unit is multiplied by the hourly day-ahead locational marginal price (LMP) to arrive at the payment for that unit. In the real-time case, the payment for a specific unit is expressed as the product of the hourly deviation in output of that unit from the day-ahead award and the hourly real-time LMP.Assume that unit c is a conventional thermal generator with a marginal cost of generation of 35 dollars per megawatt hour, and unit p is a pumped-storage plant. Assume day-ahead awards for unit c and unit p are given in Table 1a. Positive numbers for awards indicate that energy is supposed to be generated and sold to the market, and negative ones mean that energy is expected to be bought from the market for pumping. Suppose that in real-time, the two plants have the outputs shown in Table 1b. The differences may arise because the plants’ generation is limited by unexpected technical issues or, more commonly, because of the generators’ exploitation of the real-time LMPs to capture more revenue.The day-ahead payments, for hour h, are given in Table 2a, and are calculated asLMPhDA·GENhDA. The real-time payments in Table 2b, are calculated asLMPhRT·(GENhRT−GENhDA). Positive numbers indicate payment to, and negative numbers payment from, the generation unit’s owner. These reflect only revenue, or the “exogenous” component of the profit. From the generation owner’s standpoint, there is also the marginal cost per megawatt generated, or the “endogenous” component of the profit.Taking both components into account, we can see that the decision to generate 200 megawatt hours under the day-ahead award in hour 2 for unit c was actually a good one even though the generation owner gets penalized 6000 dollars in the real-time market. Had it generated at its day-ahead award of 400 megawatt hours, it would not have made or lost any money in real-time. This would have cost the generation owner 14000 dollars (400 megawatt hours times its cost of 35 dollars/megawatt hour), resulting in a net cost of 14000 dollars for the hour. By generating only 200 megawatt hours, unit c gets penalized 6000 dollars, but internally its cost is only 7000 dollars (200 megawatt hours times its cost of 35 dollars/megawatt hours), which results in a net cost of 13000 dollars for the hour. This example illustrates the benefit of knowing the marginal cost of generation for real-time operations. While that is known for the conventional unit c, it needs to be estimated for the pumped-storage unit p.From the real-time perspective, the main reference point is the day-ahead award. The real-time decision problem then becomes whether to deviate from day-ahead awards and, if so, by how much. To capture market compensation for a pumped-storage station one could generate more or pump less than the day-ahead award if the LMP is “high,” and do the opposite if the LMP is “low.” Decision makers can estimate the exogenous or market compensation that such policies would yield. However, a decision made without considering the endogenous component of the profit, or what it would marginally cost to have a certain megawatt hour output, could lead to suboptimal results.While it is easy to determine the marginal cost of a coal or natural gas power plant, as it is based mainly on the cost of the fuel, the task of determining the cost of generation at a pumped-storage plant can be complex. We seek to determine a threshold for the LMP above which it is profitable to generate, and another one below which it is profitable to pump. Because of the efficiency losses incurred between the pumping and generation, these two thresholds are related by the plant’s efficiency rating, which is defined as the ratio of the potential power of an amount of water to the power used to get that water into storage.The “fuel” a pumped-storage plant uses is its stored water. The marginal cost of generation could be defined as the market price paid to purchase the electricity used to pump the water. The cost estimate could be computed as a simple weighted-average of the amount of energy the plant uses for pumping by the corresponding LMP at the time of the pumping. However, because of its backward looking nature, this approach is flawed. The issue is that there is typically a time lag between pumping and generation, and the operating environment might change, due to a change in the load conditions or expected weather patterns.The pumped-storage plant only pumps water in anticipation of generating electricity with the water later on when the price is higher. This suggests that the decision makers must determine under what prices or LMPs they expect to be generating in order to know the maximum acceptable price for pumping. This is indeed what is used by some generators, and what we adopt in this paper while considering stochasticity in the LMPs. The main characteristics of the “forward thresholds” we develop are that they are:•forward-looking: they consider future conditions,anchored: they give a sense whether the real-time LMP is high or low,hedged: they consider the stochasticity in the LMPs,day-long: they expire after a day allowing them to be consistent, but also to incorporate new information as it arrives.Optimization under uncertainty is an established paradigm for modeling energy market problems. It has proven useful due to the inherent randomness of the load, and increasingly the availability of renewable resources, and therefore uncertainty of the prices on the system. For recent examples, see (Morales, Zugno, Pineda, & Pinson, 2014), where the authors explicitly deal with day-ahead market scheduling of generators given the real-time market uncertainties used in a stochastic program, or (Zugno & Conejo, 2015), where the topic is day-ahead energy and reserve scheduling using robust optimization.There are a few studies using stochastic programming to deal with problems involving pumped-storage units. Dentcheva and Römisch (1998) develop a short- and a medium-term mixed-integer stochastic program for optimal power generation considering a system including conventional hydro and pumped-storage plants. Of those two, the short-term model is closest to our work as it optimizes the dispatch of units that are online on an hourly or daily basis. Although it is a multistage stochastic program, the solution procedure, based on Lagrangian relaxation, supports a modest number of scenarios and daily granularity.Vespucci, Maggioni, Bertocchi, and Innorta (2012) develop a stochastic program for the optimal daily operation of a system that contains pumped-storage as well as wind power plants and considers the randomness in the wind. They perform two cases studies. In the first one, a multistage model is formulated and solved in which the scenario tree contains three stages and seven scenarios, and in which the granularity is six hours. The second case study deals with a two-stage model and nearly 500 scenarios. Similarly, García-González, de la Muela, Santos, and González (2008) formulate a two-stage stochastic program that uses wind power in the off-peak hours for pumping at pumped-storage stations. Their focus is on wind power and using pumped-storage to help integrate the renewable source into the system. Due to the sequential nature of the decision process in short-term pumped-storage unit operations in energy markets, it is natural to adopt a multistage framework. Additionally, as compared to the three papers just cited, there is a need to be more granular when including uncertainties that are highly variable by hour of the day (LMPs), and to use a larger number of scenarios to increase model fidelity. Hence, in this study, we present a model and solution technique that allows us to solve instances with a substantial number of scenarios, and where the granularity is hourly.Jacobs et al. (1995) present SOCRATES which is a system for the optimal scheduling of Pacific Gas & Electric’s generation. A stochastic programming model is formulated and solved to schedule the large hydroelectric component of their fleet including a pumped-storage plant. The planning is done to minimize costs over a two-year horizon with monthly time steps. Lu, Chow, and Desrochers (2004) develop a deterministic model for weekly scheduling of a pumped-storage unit. A deterministic price forecast drives a mixed integer programming model for pumped-storage scheduling in (Borghetti, D’Ambrosio, Lodi, & Martello, 2008). In addition to the fact that Jacobs et al. (1995) use monthly granularity, and Lu et al. (2004) and Borghetti et al. (2008) use a deterministic price forecast, the three studies adopt a medium- to long-term planning framework whereas our paper has a short-term operational perspective.Fleten and Kristoffersen (2008) introduce a model that has some similarity to ours in that it restricts conventional hydroelectric generation to comply with the day-ahead market commitments. Their seven-stage stochastic program is given day-ahead awards and schedules a system of hydroelectric units over one week with daily granularity. Their model is for short-term production planning of a system of hydroelectric units, where the focus is on the allocation of water among the reservoirs. In this way, the output of their model prescribes a daily production plan to follow in light of expected conditions on the system.Densing’s dissertation work (Densing, 2007) is similar to our model in that it uses multistage stochastic programming to model the operations at pumped-storage plants, along with a parameter for the value of the water which is closely related in interpretation to the thresholds we use. However, his models differ from ours on several levels, foremost being that he maximizes the long-term value of the plant with monthly granularity.We tackle a problem similar to that in the work of Fleten and Kristoffersen (2008) and Densing (2007) in trying to get the most value out of the pumped-storage’s generation, but our intent is to give the decision makers a set of high-quality thresholds to use in real-time operations. Hence, instead of prescribing fixed generation and pumping amounts, we intend to let the decision makers be more flexible and decide on those amounts for each hour of the day using the thresholds as a guide. Due to unexpected changes in the system LMPs that might occur at any point in time, and in order to increase the fidelity of the model, we use hourly granularity.We model the decision maker’s problem when dispatching a pumped-storage plant in the real-time market given day-ahead awards for the next day, LMPs for the current and subsequent hours, and the water inventory. The decision maker needs to decide on real-time operations in relation to day-ahead awards. If we assume that generation and pumping thresholds as defined in Section 2.2 exist, such a decision is made while staying consistent with the thresholds and maximizing exogenous profits. We refer to the day of operations as day 1; so, the day the model is run becomes day 0. Assuming the information about the uncertain LMPs is given by the stochastic process {ξt: ∀t}, we denote byξtthe vector of random prices up to, and including, hour t.We focus on real-time operations of day 1 since we want to select the thresholds to use for that day. This suggests that our horizon should be 24 hours. However, terminal conditions expressed by constraints on the ending upper-reservoir level are an issue since hard conditions for hour 24 would significantly bias our results. Instead, we model additional hours at the end of the horizon. So, in addition to the planning horizon which remains 24 hours long, we include 48 hours which capture end-of-horizon effects. This provides a smoother ending, as it takes up to three days for some of the largest pumped-storage stations to cycle the water in the reservoir. Since the main focus is not on hours 25–72, we model the uncertainty in those hours using expected values conditional on the state in hour 24. Sections 6.1 and 6.2 describe how we model the LMPs, and generate scenarios from that model.The multistage stochastic program has stages 0–24. In the initial stage (0), the choice of thresholds is made. Stages 1–23 involve realizations of the random LMPs in hours 1–23 of day 1. Finally, stage 24 contains the realization of the random LMP in hour 24 of day 1, along with the 48 hourly expected values of the LMPs for hours 25–72, i.e., days 2 and 3, conditional on realized values for hours 1–24.Since we take the perspective of the unit’s owner, and the day-ahead awards are provided by the market operator, they are assumed to be given and fixed. The market operator takes as input bids from generators across the system, and couples these with demand forecasts and system constraints to produce day-ahead LMPs and awards. We use a mixed integer programming model to mimic this process as detailed in (Vojvodić, 2016).Modeling 72 hours of real-time operations requires 72 hours of day-ahead awards. Assuming the PJM market setup, the timing is such that day-ahead awards for day 1 are known at 4 p.m. of day 0 as illustrated in Fig. 1. We assume that the model is to be run after 4 p.m., but at that point the decision maker only knows day 1’s day-ahead awards. We have to keep in mind that day-ahead awards for days 2 and 3 depend on the expected water capacity available at the end of days 1 and 2 respectively, and thus on the operations during days 1 and 2.The question is what day-ahead awards to include in the model and how. The day-ahead awards for day 1 should be included explicitly as parameters since that information is available before the model is run. The day-ahead awards for day 2 should be included as well since they eventually become available as we progress through the scenario tree (after 4 p.m. or hour 16 of day 1). However, they should not be fixed parameters since they depend on the estimate of the water level at midnight of day 1 submitted by the plant owner at noon that day.Let λstbe the reservoir level (megawatt hour) in hour t under scenario s. The day-ahead award for any hour t of day 2 can be written as a function of the expected value at noon of the reservoir level at midnight. The expected value at noon of the reservoir level at midnight depends on the reservoir level at noon (λs, 12) and on the expected generation and pumping in hours 13–24. The latter depend on the expected real-time LMPs, which in turn depend on the history of the realized real-time LMPs. Hence, we represent the day-ahead award for generation at any time t, of day 2, under scenario s, by some functionS:setofscenariosRR:setofday1hours(1--24),whichhavereal-timepricesRE:setofday2hours(25--48),whichhaveexpectedreal-timepricesD:setofday3hours(49--72),whichhaveexpectedday-aheadpricesB(s,t):bundleofscenariosthatscenariosbelongstoattimetwhereξs, 12 denotes the LMPs for hours 1 to 12 in scenario s. The pumping award is similarly denoted byϕs:probabilityofscenariosLMPstR:RTLMPinhourt,scenarios∈S;includesRTLMPrealizations($/MWh)fort∈RR,andRTLMPexpectationsfort∈RELMPstD:expectedDALMPinhourt∈D,scenarios∈S($/MWh)Gt,Pt:DAgeneration/pumpingawardinhourt∈RR(MWh)G¯,P¯:maximumgeneration/pumpingcapacity(MWh)Gδ,Pδ:maximumhourlychangeingeneration/pumping(MWh)C:coefficienttolimitcapacitywhenbothgenerationandpumpingoccurwithinthesamehour,whereCisbetween0and0.5L¯:upper-reservoirmaximumlevel(MWh)L72:endingupper-reservoirlevel(MWh)Ue:efficiencyofpumped-storageunitM:sufficientlylargescalar.The day-ahead awards for day 3 become known after hour 16 on day 2, which is included in our model’s ending conditions, but only in an expected value sense. Hence, we do not include day-ahead awards for day 3 in our model because they do not become known during the model’s 24-hour planning horizon. Day 3 is instead modeled using a day-ahead framework, whereby the LMPs considered change from real-time to day-ahead, and the decision variables are not real-time but day-ahead generation and pumping. Including day 3’s day-ahead awards as decision variables in the model will ensure that there is enough water available to take advantage of any expected conditions that might occur in those hours. Fig. 2summarizes the structure of the scenario tree used for the multistage stochastic programming formulation.It is natural to model the real-time decision problem as an MSSP because of its sequential nature. Below, we introduce the MSSP formulation.SetsS:setofscenariosRR:setofday1hours(1--24),whichhavereal-timepricesRE:setofday2hours(25--48),whichhaveexpectedreal-timepricesD:setofday3hours(49--72),whichhaveexpectedday-aheadpricesB(s,t):bundleofscenariosthatscenariosbelongstoattimetParametersϕs:probabilityofscenariosLMPstR:RTLMPinhourt,scenarios∈S;includesRTLMPrealizations(dollar/megawatthour)fort∈RR,andRTLMPexpectationsfort∈RELMPstD:expectedDALMPinhourt∈D,scenarios∈S(dollar/megawatthour)Gt,Pt:DAgeneration/pumpingawardinhourt∈RR(megawatthour)G¯,P¯:maximumgeneration/pumpingcapacity(megawatthour)Gδ,Pδ:maximumhourlychangeingeneration/pumping(megawatthour)C:coefficienttolimitcapacitywhenbothgenerationandpumpingoccurwithinthesamehour,whereCisbetween0and0.5L¯:upper-reservoirmaximumlevel(megawatthour)L72:targetendingupper-reservoirlevel(megawatthour)Ue:efficiencyofpumped-storageunitM:sufficientlylargescalarDay 2 DA awardsftg(λs,12,ξs,12):DAgenerationawardinhourt∈RE,scenarios∈S(megawatthour)ftp(λs,12,ξs,12):DApumpingawardinhourt∈RE,scenarios∈S(megawatthour)Decision variablesγst:generationinhourt∈{0}∪RR∪RE∪D,scenarios∈S(≥0,megawatthour)πst:pumpinginhourt∈{0}∪RR∪RE∪D,scenarios∈S(≥0,megawatthour)τg:generationthreshold(dollar/megawatthour)λst:reservoirlevelattheendofhourt∈{0}∪RR∪RE∪D,scenarios∈S(≥0,megawatthour)υstg:binaryvariablewhichindicatesthatγst>0,fort∈RR∪RE∪D,s∈Sυstp:binaryvariablewhichindicatesthatπst>0,fort∈RR∪RE∪D,s∈Sαst:binaryvariablewhichindicatesthatτg≤LMPstR,fort∈RR∪RE,s∈Sμst:binaryvariablewhichindicatesthatUeτg≤LMPstR≤τg,fort∈RR∪RE,s∈Sβst:binaryvariablewhichindicatesthatUeτg≥LMPstR,fort∈RR∪RE,s∈SBoundary conditionsγs,0=G0:initialgenerationinhour0,scenarios∈Sπs,0=P0:initialpumpinginhour0,scenarios∈Sλs,0=L0:initialreservoirlevelinhour0,scenarios∈SObjective function(1.1)πst≤υstpP¯t∈RR∪RE∪D,s∈SOperational constraintsCapacity limits(1.2)γstG¯+πstP¯≤3−(C+1)(υstp+υstg)t∈RR∪RE,s∈S(1.3)υstg+υstp≤1t∈D,s∈S(1.4)γst≤γs,t−1+Gδt∈RR∪RE∪D,s∈S(1.5)γst≥γs,t−1−Gδt∈RR∪RE∪D,s∈SRamp limits(1.6)πst≤πs,t−1+Pδt∈RR∪RE∪D,s∈S(1.7)πst≥πs,t−1−Pδt∈RR∪RE∪D,s∈S(1.8)λst≤L¯t∈RR∪RE∪D,s∈S(1.9)λst=λs,t−1−γst+Ueπstt∈RR∪RE∪D,s∈SFlow and upper-reservoir constraints(1.10)λs,72≥L72s∈S(1.11)τg−LMPstR≤(1−αst)Mt∈RR∪RE,s∈S(1.12)Ueτg−LMPstR≤(1−μst)Mt∈RR∪RE,s∈SThreshold constraints(1.13)τg−μstLMPstR≥0t∈RR∪RE,s∈S(1.14)Ueτg−βstLMPstR≥0t∈RR∪RE,s∈S(1.15)αst+μst+βst=1t∈RR∪RE,s∈S(1.16)γst≥αstGtt∈RR,s∈S(1.17)πst≤αstPt+(1−αst)P¯t∈RR,s∈S(1.18)γst≤μstGt+(1−μst)G¯t∈RR,s∈S(1.19)πst≤μstPt+(1−μst)P¯t∈RR,s∈S(1.20)γst≤βstGt+(1−βst)G¯t∈RR,s∈S(1.21)πst≥βstPtt∈RR,s∈S(1.22)γst≥αstftg(λs,12,ξs,12)t∈RE,s∈S(1.23)πst≤αstftp(λs,12,ξs,12)+(1−αst)P¯t∈RE,s∈S(1.24)γst≤μstftg(λs,12,ξs,12)+(1−μst)G¯t∈RE,s∈S(1.25)πst≤μstftp(λs,12,ξs,12)+(1−μst)P¯t∈RE,s∈S(1.26)γst≤βstftg(λs,12,ξs,12)+(1−βst)G¯t∈RE,s∈S(1.27)πst≥βstftp(λs,12,ξs,12)t∈RE,s∈S(1.28)γs′t=γstt∈RR,s∈S,s′∈B(s,t),(1.29)πs′t=πstt∈RR,s∈S,s′∈B(s,t)Non-anticipativity constraints(1.30)λs′t=λstt∈RR,s∈S,s′∈B(s,t)(1.31)υs′tg=υstgt∈RR,s∈S,s′∈B(s,t)(1.32)υs′tp=υstpt∈RR,s∈S,s′∈B(s,t)(1.33)γst,πst,λst≥0t∈RR∪RE∪D,s∈S(1.34)υstg,υstp∈{0,1}t∈RR∪RE∪D,s∈SNon-negativity and binary constraints(1.35)αst,μst,βst∈{0,1}t∈RR∪RE,s∈S(1.36)υstg(1.37)υstpConstraints (1.2) and (1.3) limit the generation and pumping by their capacities. Note that the binary variablesαst=0,andRRhave to be 1 if there is any generation or pumping, respectively, in hour t of scenario s. Generation and pumping can both occur within the same hour during real-time operations, and constraints (1.4) restrict the generation and pumping capacities in such a scenario. This accounts for additional time it takes to shut down a generator or a pump and start pumping or generating, respectively. In the day-ahead market, it is not possible to have a pumping and a generation award in the same hour as captured by constraints (1.5). Constraints (1.6)–(1.9) limit the ramp, i.e., the change in generation and pumping, in each adjacent hour. Constraints (1.10) enforce the capacity for the upper-reservoir, and constraints (1.11) express the inventory balance constraints. Ending conditions for all scenarios are enforced by constraints (1.12). Parameter L72 is the target value of the amount of potential energy in the reservoir at the end of day 3. This parameter can be estimated by the decision maker based on experience.To understand the threshold constraints it is useful to refer to Fig. 3, which shows real-time generation or pumping on the x-axis and the real-time LMP on the y-axis. In interpreting the graphs, one can think of pumping as negative generation. There are three subfigures each depicting a different day-ahead award situation. The day-ahead awards and the two thresholds are marked on the appropriate axes. Under the assumption that τgaccurately captures the value of the future usage of the current water in the reservoir (in dollar/megawatt hour), the real-time decision sets that lead to economic gains are shown as green areas while the ones leading to losses are shown as red.We use thresholds to constrain real-time generation and pumping to values for which no losses occur, and yet obey the threshold form of the operating policy. To do so, we use binary variables αst, μst, and βst, whose values are enforced with constraints (1.13)–(1.17). In order to explain the green and red areas in Fig. 3 and the remaining threshold constraints, given that the generation threshold represents the value of the future usage of the water, we present the following assumptions for rational decision making that is consistent with avoiding unnecessary monetary losses.Assumption 1If the real-time LMP is greater than the generation threshold, in order to avoid losses, the decision maker would, in real-time:1.1generate at least the day-ahead generation award if there is one for the hour;pump at most the day-ahead pumping award if there is one for the hour;not pump if there is no day-ahead award for the hour.With the definitions of the binary variables above, Assumption 1 leads to constraints (1.18) and (1.19) for day 1, and (1.24)–(1.25) for day 2. Note that ift∈RE∪Dthe constraints are redundant.Assumption 2If the real-time LMP is less than the generation threshold and greater than the pumping threshold, in order to avoid losses, the decision maker would, in real-time:2.1generate at most the day-ahead generation award if there is one for the hour;pump at most the day-ahead pumping award if there is one for the hour;neither pump nor generate if there is no day-ahead award for the hour.Assumption 2 leads to the constraints (1.20) and (1.21) for day 1, and (1.26)–(1.27) for day 2.Assumption 3If the real-time LMP is less than the pumping threshold, in order to avoid losses, the decision maker would, in real-time:3.1generate at most the day-ahead generation award if there is one for the hour;pump at least the day-ahead pumping award if there is one for the hour;not generate if there is no day-ahead award for the hour.Assumption 3 yields constraints (1.22) and (1.23) for day 1, and (1.28)–(1.29) for day 2. Constraints (1.18)–(1.29) enforce a threshold policy and capture requisite behavior in that context.Constraints (1.30)–(1.34) enforce the principle of non-anticipativity which implies that at any point in the scenario tree, the decisions that share the same history up to that point have to be the same. Note that these constraints are enforced only overftp(λs,12,ξs,12)because anyftg(λs,12,ξs,12),corresponds to a leaf node in the scenario tree. Moreover, we note that including analogous constraints for αst, βst, and μstis unnecessary. Non-anticipativity constraints for these variables are already enforced by constraints (1.13)–(1.16). Lastly, constraints (1.35), and (1.36)–(1.37), enforce non-negativity and binary conditions, respectively.The multistage stochastic program is not solvable as formulated above due to several reasons. The day-ahead-award functions,t+1andt+1respectively, work as a pair of lookup functions, which makes the model intractable given continuous λs, 12 variables. Instead, given the conditional expected value at noon of the midnight upper-reservoir level, in order to estimate the day-ahead awards for day 2, we use an outside model (Vojvodić, 2016) which gives the awards ahead of the time at which we solve the optimization model to decide on the threshold values.There is also an issue with the size of the model. Arguably, we cannot use a coarser granularity than hourly because the decisions and the compensation are hourly, and we need to capture hourly variations in LMPs and corresponding decisions. Similarly, we should use a 24-hour planning horizon in the scenario tree because the decision on the threshold is daily, and so it should consider at least a day of operations. If we represent the uncertainty with only two branches per stage, which is an unrealistically small number of branches given the significant variability in the short-term LMPs, we would end up with more than 4 billion variables and almost 11 billion constraints.There are a number of decomposition algorithms for multistage stochastic integer programs (see, for example, Carøe and Schultz (1999), Lulli and Sen (2004), Singh, Philpott, and Wood (2009), and Løkketangen and Woodruff (1996), as well as Louveaux and Schultz (2003), Schultz (2003), and Sen (2005)). To our knowledge such decomposition algorithms are not capable of handling a 24-stage problem of the scale we describe. We could attempt to generate a smaller but representative scenario tree by matching, or nearly matching, certain characteristics of the underlying stochastic process, such as moments and temporal correlation; see, e.g., Høyland, Kaut, and Wallace (2003) and Kaut and Wallace (2011). Or, we could apply schemes that reduce the number of scenarios in the tree from a large set of scenarios, again with the goal of obtaining a representative tree; see, e.g., Dupačová, Consigli, and Wallace (2000), Dupačová, Gröwe-Kuska, and Römisch (2003), Heitsch and Römisch (2009), and Pflug and Pichler (2012). However, we did not pursue this for reasons we discuss further below (see Section 6.3) having to do with obtaining good thresholds with respect to reasonable operations policies for the pumped-storage unit.Another option we considered is to model the problem using stochastic dynamic programming. This would allow us to keep the sequential structure of the decision process, but requires some discretization for the state variables which would include the LMP, the water level, as well as the last hour’s pumping and generation. We arrived at the conclusion that in order to obtain a sufficiently fine discretization of these variables, the state space would need to grow extremely large making the solution process very time consuming.We propose a solution procedure that decomposes optimization of the first stage decision of the univariate threshold, τg, from the subsequent scenario-dependent operational decisions. In Section 5.1, we detail how we treat the operational decisions, given a fixed value of the first stage decision regarding the threshold. In Section 5.2, we then discuss a scatter-search heuristic to optimize τg. Section 5.1 deals with operational decisions by breaking the problem into individual scenarios, yielding as many “one-scenario problems” as there are scenarios in the scenario tree. We solve each one-scenario problem for a given τg, using a rolling-horizon scheme which preserves non-anticipativity in the multi-stage stochastic program. Having solved each one-scenario problem in this manner, we compute the expected cost of operating under the specified threshold, τg. While the rolling-horizon scheme for the operational decisions is, in general, suboptimal for the multi-stage stochastic program, the scheme is arguably a more accurate model of how decision makers behave in practice, and hence we prefer to select τgunder this model for computing expected cost. Because we iterate through time, addressing the operational problems by solving integer programs (IPs) which represent the problem that the decision maker faces at each hour, we call this the sequential IPs algorithm. We describe the methodology using a bottom-up approach, starting with a single IP which represents a specific hour in Section 5.1.1, and then moving on to the one-scenario problem in Section 5.1.2.At the beginning of hour t, we assume that the decision maker is able to accurately estimate the real-time LMP for hour t. For any hour t, the decision about real-time operations is made considering the real-time LMP for hour t and the conditional expected values of the subsequent hours’ LMPs. After the decision for hour t is made, time advances and the process is repeated for the next hour,Rt0. Generalizing, every hour, the decision maker knows the current realization of LMP and the expected values of future LMPs conditional on the current LMP. In this way, each scenario is evaluated using a deterministic rolling-horizon approach. This not only models the decision process in a computationally tractable manner, but it also closely represents the situation the decision maker faces in reality. In practice, the real-time decision in any hour is not made based on a scenario tree with finitely many outcomes as in a multistage stochastic program, but based on the current (this hour’s) observed LMP and the future expected LMPs. The MSSP formulation would be appropriate only if the decision maker were able to quickly solve MSSPs in real-time during each hour of the day, a highly unlikely proposition given the dimensions of these models. Said another way, our goal is to find a high-quality threshold, τg, and if our model of how the pumped-storage unit operates is overly optimistic (i.e., the solution to the full multistage stochastic program), then our threshold may not perform well in practice.Every hour, we also need information on operations from the previous hour. The ending water level from the previous hour is required in order to know the remaining water capacity available. The previous generation and pumping have to be known so that we know the range of possible decisions with respect to the ramping constraints. If this information is relayed through ramping and inventory balance constraints ((1.6)–(1.9) and (1.11)), we effectively link the realizations of the random variable at different time periods and make the formulation anticipative. We propose breaking the one-scenario problem down into separate IPs. We solve the IPs separately and sequentially, transferring information between them. Non-anticipativity conditions are enforced within a scenario in the sense that a decision for a particular hour is made based on the realized real-time LMPs up to that hour and future expected LMPs. Once that IP is solved and the decision variables are fixed, the information needed is transferred to the next hour’s IP, which is then ready to be solved. A partial scenario tree illustrating this is given in Fig. 4.The information transfer is between the first node of the IP which represents time t and the first node of the IP which represents timeRt0. In terms of the analogy of the decision maker deciding and advancing through time, we transfer only the information about the decision at the first node because only that decision is implemented. The nodes containing the conditional expected LMPs are there to help decide how much, if anything, should be generated or pumped at time t. Since we are considering 24 hourly “realizations” of real-time LMPs, we include 24 IPs within each scenario, where a partial scenario is depicted in Fig. 4.In reality, to make a decision about any hour’s real-time operations, the decision maker considers current real-time conditions, and for hours for which day-ahead awards are known, day-ahead awards and expected future real-time conditions. With enough foresight, the decision maker also considers the expected day-ahead conditions for future hours for which day-ahead awards are not available; specifically, the hours included in the model to handle ending conditions. The goal is to capture real-time revenue, but the day-ahead opportunities have to be assessed as well to make sure that there is enough water in the reservoir to adequately handle the expected future conditions.Within a scenario, the first IP we solve begins with the hour ending at 01:00 a.m. of day 1 (hour 1) and ends with the hour ending at midnight of day 3 (hour 72). We take the real-time LMP at hour 1 as realized and the subsequent LMPs as expected. We aim to optimize profit over the 72-hour horizon, but since at the time this IP is solved we only know the day-ahead awards for hours 1–24, we can model only those hours with respect to the real-time framework. Hence, we use expected real-time LMPs for hours 2–24. Hours 25–72 are modeled with respect to the day-ahead framework, and therefore we use expected day-ahead LMPs for hours 25–72.The transition to the next IP advances the clock in that when we solve the second IP, we take the real-time LMP at the hour ending at 02:00 a.m. as realized and the subsequent LMPs as expected. Since the day-ahead awards for day 2 are not known yet, we have the same breakdown between a real-time modeling framework (hours 2–24) and a day-ahead modeling framework (hours 25–72). We keep the end of the time horizon constant at hour 72; i.e., for each starting hour we only include hours through the end of day 3. This is consistent with the planning horizon we discussed earlier for the MSSP formulation, and allows us to only have to specify one value for the parameter L72, the upper-reservoir water level we want to have at the end of day 3.After 16:00 on day 1 (after the 16th IP is solved), the day-ahead awards for day 2 are available. We assume these day-ahead awards are input data. We estimate them using a similar exogenous model (Vojvodić, 2016) as the one for estimating day-ahead awards for day 1, which uses estimated available capacity at midnight as input. Since the day-ahead bidding process closes at noon, we take the expected value at noon of the midnight upper-reservoir capacity as input.When we solve the 17th IP, we now have day-ahead awards for hours 17–24 of day 1 (17–24) as well as hours 1–24 of day 2 (25–48) and, hence, we use a real-time modeling framework for those hours. Hours 1–24 of day 3 (49–72) are still valued with respect to the day-ahead logic. Fig. 5illustrates the process described.We adopt the convention that the hour with the realized real-time LMP is indexed by t0. In the single IP formulation,Dt0stands for the set of expected real-time hours. With every IP, setsLMPs,t0RandLMP¯stR(of day-ahead hours) are updated depending on the hour t0 that the IP represents. Within a single IP, the scenario is fixed. Therefore, we drop the scenario index from the decision variables. However, the random LMPs keep their scenario index to indicate explicitly their scenario-dependency. Consequently, within the IP for scenario s and time t0,t∈Rt0,represents the realized real-time LMP,LMP¯stDrepresents the expected real-time LMP at timet∈Dt0andτ^grepresents the expected day-ahead LMP at timet0(τ^g,LMPs,t0).The separation of IPs by scenario and by hour means that the solutions we obtain for the same hour t in different scenarios will usually differ. Since most of the variables are time- and scenario-dependent, this is fine. On the other hand, as we indicate above, the generation threshold, τg, must stay fixed across scenarios and time periods, and this is why we treat it as an input parameter in our single IP formulations. As we discuss in Section 5.2, we use a heuristic to (approximately) optimize τg, using optimal values from the sequence of IPs and multiple scenarios to form the objective function. As a result, we have a parametrized model where the fixed-value threshold is a parameter denoted byLMPs,t0=(LMPs,t0R,LMP¯s,r1R,LMP¯s,r2R,⋯,LMP¯s,rNR,LMP¯s,d1D,LMP¯s,d2D,⋯,LMP¯s,dMD),Rt0={r1,r2,⋯,rN},. We refer to the single IP model for a fixed s and t0 as SEQIPDt0={d1,d2,⋯,dM}whereLMPs,t0=(LMPs,t0R,LMP¯s,r1R,LMP¯s,r2R,…,LMP¯s,rNR,LMP¯s,d1D,LMP¯s,d2D,…,LMP¯s,dMD),Rt0={r1,r2,…,rN},andDt0={d1,d2,…,dM}. Here,Rt0={t0+1,…,24}andDt0={25,…,72}if 1 ≤ t0 ≤ 16, andRt0={t0+1,…,48}andDt0={49,…,72}if 17 ≤ t0 ≤ 24; see Fig. 5. For future use, we defineLMPsto be the matrix with rowsLMPSwhere each row represents a timet0∈{1,2,…,24},andτ^gto be the collection of the matricesLMPsforγtd:desiredRTgenerationinhourt∈{t0}∪Rt0(≥0,MWh)πtd:desiredRTpumpinginhourt∈{t0}∪Rt0(≥0,MWh)γt+,γt−:positive/negativedeviationbetweendesiredandactualRTgeneration(≥0,MWh)inhourt∈{t0}∪Rt0πt+,πt−:positive/negativedeviationbetweendesiredandactualRTpumping(≥0,MWh)inhourt∈{t0}∪Rt0υtgd:binaryvariablewhichindicatesthatγtd>0,fort∈{t0}∪Rt0υtpd:binaryvariablewhichindicatesthatπtd>0,fort∈{t0}∪Rt0. The updated formulation as a function ofmin∑t∈{t0}∪Rt0[γt++πt++γt−+πt−]−ϵ[LMPst0R[(γt0−Gt0)−(πt0−Pt0)]+∑t∈Rt0LMP¯stR[(γt−Gt)−(πt−Pt)]+∑t∈Dt0LMP¯stD[γt−πt]]follows.Additional decision variablesγtd:desiredRTgenerationinhourt∈{t0}∪Rt0(≥0,megawatthour)πtd:desiredRTpumpinginhourt∈{t0}∪Rt0(≥0,megawatthour)γt+,γt−:positive/negativedeviationbetweendesiredandactualRTgenerationinhourt∈{t0}∪Rt0(≥0,megawatthour)πt+,πt−:positive/negativedeviationbetweendesiredandactualRTpumpinginhourt∈{t0}∪Rt0(≥0,megawatthour)υtgd:binaryvariablewhichindicatesthatγtd>0,fort∈{t0}∪Rt0υtpd:binaryvariablewhichindicatesthatπtd>0,fort∈{t0}∪Rt0Objective function(2.1)πt−πtd+πt+−πt−=0t∈{t0}∪Rt0Linking constraints(2.2)γt≤υtgG¯t∈{t0}∪Rt0∪Dt0(2.3)πt≤υtpP¯t∈{t0}∪Rt0∪Dt0Operational constraintsCapacity limits for actual operations(2.4)γtG¯+πtP¯≤3−(C+1)(υtp+υtg)t∈{t0}∪Rt0(2.5)υtg+υtp≤1t∈Dt0(2.6)γtd≤υtgdG¯t∈{t0}∪Rt0(2.7)πtd≤υtpdP¯t∈{t0}∪Rt0Capacity limits for desired operations(2.8)γtdG¯+πtdP¯≤3−(C+1)(υtpd+υtgd)t∈{t0}∪Rt0(2.9)γt≤γt−1+Gδt∈{t0}∪Rt0∪Dt0(2.10)γt≥γt−1−Gδt∈{t0}∪Rt0∪Dt0Ramp limits(2.11)πt≤πt−1+Pδt∈{t0}∪Rt0∪Dt0(2.12)γt≥γt−1−Gδt∈{t0}∪Rt0∪Dt0(2.13)πt≤πt−1+Pδt∈{t0}∪Rt0∪Dt0(2.14)πt≥πt−1−Pδt∈{t0}∪Rt0∪Dt0Flow and upper-reservoir constraints(2.15)λt≤L¯t∈{t0}∪Rt0∪Dt0(2.16)λt=λt−1−γt+Ueπtt∈{t0}∪Rt0∪Dt0(2.17)λ72≥L72Threshold constraints (included for hour t based on the values ofτ^gandLMPst0RorLMP¯stR.) Fort∈{t0}∪Rt0:Generation(2.18)☆ifLMPs,t0R>τ^g:γtd≥Gt(2.19)☆ifτ^g>LMPs,t0R:γtd≤GtPumping(2.20)☆ifLMPs,t0R>Ueτ^g:πtd≤Pt(2.21)☆ifUeτ^g>LMPs,t0R:πtd≥PtNon-negativity and binary constraints(2.22)γt,πt,λt≥0,t∈{t0}∪Rt0∪Dt0,γtd,γt+,γt−,πtd,πt+,πt−,≥0,t∈{t0}∪Rt0(2.23)υtg,υtp∈{0,1},t∈{t0}∪Rt0∪Dt0,υtgd,υtpd∈{0,1},t∈{t0}∪Rt0Constraints (2.4)–(2.7) and (2.11)–(2.17) in the sequential IP formulation replicate constraints (1.2)–(1.5) and (1.6)–(1.12) in the MSSP formulation, respectively. Note that we do not have non-anticipativity constraints in the sequential IP formulation. However, implementing non-anticipativity by solving a sequence of IPs can induce infeasibilities relative to the desired threshold policy. For a given IP, the best decision given that hour’s conditions may lead to the next IP becoming infeasible due to the combined effect of the variables whose values are transferred to the next period and therefore fixed, and the ramping and threshold constraints. To address this, we introduceγtdandπtdrepresenting desired real-time generation and pumping to use in the threshold constraints. The desired and actual operations variables are linked by constraints (2.2) and (2.3). Constraints (2.8)–(2.10) represent upper bounds on the values these desired variables can take. Note that this issue does not arise in the absence of the threshold constraints; hence, we do not need these extra variables for the hours with the day-ahead variables.The objective function (2.1) changes to a preemptive multi-objective one in which minimizing differences between desired and actual real-time operations takes precedence over maximizing the real-time market compensation. To find the optimal threshold, it is important to stay as close as possible to the desired operations dictated by the threshold constraints. The parameter ϵ > 0 represents the tradeoff coefficient, a number much smaller than one.Since the threshold is fixed within any single IP, we can fix the constraints (1.13)–(1.17) before solving the IP, and exclude the binary variables αt, μt, and βtfrom the formulation. Depending on the relationship between the real-time LMP (realized or expected),τ^g,andUeτ^g,constraints (1.18)–(1.29) are replaced by one or two of the inequality constraints involvingγtdandπtdfrom (2.18)–(2.21). Finally, constraints (2.22) and (2.23) represent non-negativity and binary restrictions.The function (2.1) is the objective of the single IP because as we mentioned, the first priority is for the decisions to be as consistent with the threshold as possible, and the second priority is to maximize market compensation. Once the optimal decisions regarding those criteria are made, another function is used in order to evaluate the threshold because we do not want to include the differences between desired and actual operations in the evaluation. Another reason is that by simply summing the functions (2.1) fort0=1,2,…,24and averaging across scenarios, we are counting the contribution of some of the hours multiple times. Within a scenario, the threshold should be evaluated by the quality of the decisions it yields for the 24 realized hours of day 1 and the 48 expected hours of days 2 and 3. Consequently, the function used for the evaluation is:F(τ^g,LMPS)=∑s∈Sϕs[∑t∈RRLMPstR[(γ^st−Gt)−(π^st−Pt)]+∑t∈RDLMP¯stR[(γ^st−Gt)−(π^st−Pt)]+∑t∈DLMP¯stD[γ^st−π^st]].The first term in the definition of F corresponds to the 24 “realization nodes” (dark nodes in Fig. 5), while the second term correspond to the “expected real-time nodes” (medium nodes in the last row of Fig. 5), and the third term corresponds to “expected day-ahead nodes” (light nodes in the last row of Fig. 5). The valuesγ^standπ^stdenote the values of the decision variables we obtain by solving SEQIP in scenario s and time t. The sequential IPs procedure, outlined in Algorithm 1,is used to evaluate the objective function F at a specific thresholdτ^g.In order to find the best threshold, we use a scatter search heuristic (Laguna & Martí, 2003; Martí, Laguna, & Glover, 2006) to search over the space of possible thresholds. The scatter search has two distinct components. Once it identifies a solution, the intensification phase explores the candidates around it in search of the best solution in the neighborhood. Note that we are optimizing a function that is not typically convex, and can have many local optima as illustrated by Fig. 6. Thus, the diversification phase explores a broader set of solutions and identifies those that are most different from the best solutions found for inclusion in the “reference set.” This set keeps track of potential optimal solutions.The particular application of the scatter search to our problem is described in Algorithm 2. “Best solutions” refer to the solutions with the largest values of the function F. If we consider|N|solutions indexed by i, we denote the ith solution asτ^ig,the best solution asτ^g*,and the associated function valueF(τ^g*,LMPS)=maxi∈NF(τ^ig,LMPS).The scatter search algorithm requires as parameters the number of “elite” solutions to keep in the reference set (RS) from iteration to iteration, b1, the number of “different” solutions to introduce inRSat the beginning of each loop, b2, and the number of random solutions to generate in the initialization phase and at the end of each loop, p. It begins by generating p random solutions from a specified range. The range should be large enough so that it includes the optimal threshold. The thresholds and the associated function values are stored in a setPof potential solutions. Before we enter the outer loop, we initializeRSwith the b1 best solutions fromPas measured by the function values. At the beginning of the outer loop, the contents ofRSare saved in a different set,RSo,andRSis augmented with the b2 “most different” solutions fromP. We take “most different” to mean the furthest away from all the solutions already inRS. The inner loop represents the intensification phase in which randomly weighted convex combinations are taken of all possible pairs of thresholds inRS.RSis repopulated with the bestb1+b2of those thresholds. If the b1 best thresholds do not change in an iteration, the inner loop is exited; otherwise, it is repeated. The diversification phase takes place after the inner loop, where p new random solutions are generated and evaluated. The b2 worst solutions are taken out ofRS. If the b1 best solutions did not change during the course of an iteration of the outer loop, the algorithm is done; otherwise, the outer loop is repeated.We base our case study on a large US pumped-storage unit. The generation and pumping capacities are 2000 megawatt and 1800 megawatt, respectively. The generation and pumping ramp are respectively 900 megawatt hours and 800 megawatt hours in either direction. The efficiency parameter of the pumped storage plant is 0.8, and the capacity of the upper-reservoir is equivalent to 11000 megawatt hours of potential power.All of the market data we use is sourced from PJM (PJM, 2014). The loads we use for the day-ahead award model are adjusted PJM historical loads that represent loads of a particular PJM “market participant”; i.e., an owner of one or more generation units that serves load and participates in the PJM market. We use the particular market participant because it operates the pumped storage station on which our study is based. The data we use as a basis to develop the stochastic models governing LMPs are the historical hourly real-time LMPs of a particular node in the PJM system. The literature on modeling electricity prices is vast and we do not review it here, although Weron (2006) and Cuaresma, Hlouskova, Kossmeier, and Obersteiner (2004) form the basis for our approach.There are several characteristics that LMPs are known to exhibit. First, they generally follow a trend throughout the day, with lower prices in the early morning hours and higher prices during the morning and afternoon peak. Depending on the time of the year, there is also a valley in the early afternoon hours. LMPs are also generally higher in magnitude during the weekdays as opposed to weekends. Second, LMPs are usually autocorrelated in their deviations from the expected value. If in a particular hour the LMP is higher than the expected value for that hour, the next hour’s LMP is more likely to be higher than its expected value as well. Lastly, in the case of real-time LMPs, it is important to note the presence of spikes or jumps. These usually correspond to unexpected load increases possibly due to weather-related events or to unexpected outages of generation or transmission assets.Our motivation to develop probabilistic models for LMPs lies in our need for scenarios for the decision-making model for optimizing generation thresholds that we have proposed. In practice, the decision maker would probably have access to load and LMP forecasts from the market participant’s meteorology or analytics group and could use those as scenarios. However, for our study, we need an efficient scenario generation procedure in order to produce realistic scenarios. In the interest of brevity, we only touch upon these procedures, with full details available in (Vojvodić, 2016).We use data over several years (May 2005 to December 2013), but we break down the data into separate monthly data sets and develop different forecasting models for each month of the year. The monthly separation captures the seasonal effect of LMPs. Within each month, we first smooth the data by replacing any prices above three standard deviations from the mean by the mean price plus three standard deviations. The prices identified as jumps are transformed into percentage deviations from the average LMP for the hour, and are classified into an on-peak or an off-peak group depending on the hour in which they occurred. We fit distributions to those two groups of percentage deviations, and use the data sets of jumps to obtain empirical frequencies, rh, for the occurrence of jumps in hour of the day h.The smoothed data sets are used to develop regression models for the LMP for a certain hour-of-the-day and day-of-the-week. Lastly, time series models are developed using residual data sets obtained from the regression. We model the residuals as ARMA(p, q) time series, where p and q vary depending on the month of the year. This captures the autocorrelated nature of LMPs.The procedure to generate a single scenario s starts with a large number of iterations used to warm up the time series simulator. A single realization of the real-time LMP for scenario s and time t(d, h) is denoted byLMPs,t(d,h)R,and is composed of three different components:LMPs,t(d,h)R=Hs,d,h+Js,d,T(h)+Ss,t(d,h).Here, t(d, h) is a function that returns the time period for the optimization model (t(d,h)=1,…,72) corresponding to day d and hour h, and T(h) is a function that returns the on- or off-peak period corresponding to hour h. Regression is used first to obtain the expected contribution Hs, d, h, of the day of the week d and hour of the day h, to the real-time LMP. Next, a uniform random number, ηs, d, h, is generated and compared to the frequency of occurrence of jumps, rh. If ηs, d, his larger than rh, the increase due to jumps, Js, d, T(h), is set to 0. Otherwise, the percent increase due to jumps, JPT(h) is drawn from the distribution corresponding to the appropriate on- or off-peak period, and multiplied by Hs, d, hto yield the increase due to jumps:Js,d,T(h)=JPT(h)Hs,d,h.Lastly, a normally distributed error ϵt(d, h) is generated and used to calculate the time series component, Ss, t(d, h):Ss,t(d,h)=c+∑i=1pϕiSs,t(d,h)−i+∑i=1qθiϵt(d,h)−i+ϵt(d,h),where c is a constant, p and q are the number of autoregressive and moving-average terms to include respectively, ϕiand θiare the ith autoregressive and moving-average coefficients, respectively, andSs,t(d,h)−iandϵt(d,h)−irefer to previous values of the time series component and of the random error term, respectively, which we obtain either from the warm up process or the previous iterations.Iterative application of the above procedure generates the realizations of the real-time LMP sample paths. After forming each sample path, a collateral procedure generates expected values of the LMPs. Generation of these conditional expected real-time LMPs involves two major differences. First, the random error term is taken to be 0, yielding a value of the time series component (Ss, t(d, h)) that progressively tends to 0 as time advances. Second, instead of being sampled from the distribution, the increase due to jumps is taken as an expected value. When the time comes to generate conditional expected day-ahead LMPs, we use the same logic, except that we do not include the increase due to jumps. For day-ahead LMPs, we assume that jumps are already accounted for in the expected LMPs due to proactive planning by the market operator, who aims to ensure all expected events are accounted for.In the rest of this section, we focus on the month of July to generate the scenarios needed for our analysis. We initially tried eight runs with 50 scenarios each, and then increased the number of scenarios, first to 100, and finally to 250, in order to obtain stable results, based on tests for stability using ideas of King, Wallace, and Kaut (2012) and Kaut and Wallace (2007), as we describe below.In-sample stability refers to the internal consistency of the model. If we generate|N|different scenario sets, we can then solvemaxτ^igF(τ^ig,LMPSi),whereLMPSiis the ith scenario set,i∈N. We denote byτ^ig*the optimal solution for the ith problem. If the following holds, we have in-sample stability:F(τ^ig*,LMPSi)≈F(τ^jg*,LMPSj)∀i,j∈N,i≠j.In other words, when we establish in-sample stability, it should not matter which scenario set we use because they should all yield similar optimal values.We generate 30 sets of scenarios, each with 250 scenarios, and we use our scatter-search optimization procedure to solve for the thresholds. Across the 30 sets, we obtain 15 different best thresholds ranging from 58.0 to 60.2 dollars. The minimum value of the function F is 696,686.69 dollars, the maximum 732,688,05 dollars, and the average 713,970.10 dollars. The largest deviation between any two results (the maximum and minimum) is 5.17 percent, which we deem small enough to be able to say that we do have in-sample stability.If the different optimal solutionsτ^ig*yield similar values of the evaluation function when the “true” distribution of LMPs (LMP) is used, then we have out-of-sample stability. In symbolic terms, we wish to assess whether:F(τ^ig*,LMP)≈F(τ^jg*,LMP)∀i,j∈N,i≠j.Since we do not have the true distribution ofLMP, we evaluate each of the 15 uniqueτ^ig*values obtained using 10,000 newly generated scenarios. The minimum value of the function F is 712,922.22 dollars, the maximum 714,894.60 dollars, and the average 714,161.87 dollars. In this case, the largest deviation between the function values for any two thresholds is 0.28 percent, which allows us to claim that we have out-of-sample stability. We note that the in-sample range between the minimum and maximum values is wider, which is probably due to sampling error as the in-sample values represent averages over many fewer scenarios.We perform quality tests to estimate the optimality gap of the obtained generation threshold. In order to perform the analysis, we use the multiple replications procedure introduced in (Mak, Morton, & Wood, 1999) and (Bayraksan & Morton, 2006) to construct a confidence interval on the optimality gap.We assess the quality of the candidate thresholdτ^g*=59.1,obtained using a newly generated set of scenarios. We then use the 30 sets of 250 scenarios that we generated and used for the stability testing and a significance level of 0.05. For every one of the 30 scenario sets, we calculate the corresponding gap by taking the difference between the objective value using the best threshold for the scenario set under consideration and the objective value evaluated usingτ^g*with the same scenario set. We average the 30 gaps, to obtain a point estimate for the optimality gap, and we estimate the variance. The estimate of the optimality gap is 1124.83 dollars and the one-sided 95 percent confidence interval is [0, 1424.42]. As a reference, this bound on the optimality gap is about 0.2 percent of the estimated objective function value atτ^g*. We deem this deviation small enough to be able to claim that the optimization procedure generates high quality solutions.It is necessary to tune the values for the three parameters in the scatter search procedure in Algorithm 2, b1, b2, and p. These parameters affect the speed of the heuristic and its accuracy in finding good solutions. We found thatp=10,b1=3,andb2=3work well. In order to save computational time, we restrict the initial range of possible solutions to a 15 dollars initial range. We used Python and Pyomo (Hart, Laird, Watson, & Woodruff, 2012) to code and run the optimization procedure with Gurobi, version 6.5 (Gurobi Optimization, Inc., 2015) as the IP solver on an Intel Xeon 2.4 gigahertz with 64 gigabyte of RAM. The computational run time metrics of the algorithm to solve for a threshold over 41 sets of 250 scenarios (i.e., 41 runs) are given in Table 3.We round the thresholds to the first decimal in the algorithm. We are reasonably confident that our heuristic produced optimal or near-optimal solutions for the set of scenarios under consideration, and for reasons discussed in Section 6.3, near-optimal solutions in out-of-sample tests. Executing Algorithm 1 for a given threshold over a fixed set of 250 scenarios takes about 440 seconds. Considering the 15 dollars range and that we round the thresholds to one place after the decimal point, there are 150 candidate thresholds. If we enumerated the thresholds one by one, it would take 66,000 seconds. So, our scatter search algorithm reduces the solution time by about 64 percent.An alternative solution procedure would be to generate an expected value scenario, with a data set denoted byLMPE, and useLMPEinstead ofLMPSin Algorithm 1. We call a threshold found this way the forward threshold based on the expected-value scenario (FTEV). In the remainder of this section, we compare the FTEV obtained for different months, weeks, and days to the forward thresholds incorporating uncertainty with scenarios (FTS); i.e., thresholds obtained using the approach we propose.While violations of the threshold policy when running Algorithm 1 did occur occasionally, the number of hours with positive values ofγt+,γt−πt+,orπt−was typically quite low in a 250-scenario instance. We notice a consistent difference in the values of the thresholds as well as the dominance of FTS in the simulations below. In most cases, for the same set of scenarios, the FTEV is larger in magnitude than the FTS. As illustrated below, we also find that FTS performs better in simulations. One possible explanation for this is that the LMP distributions are skewed to the right due to the spikes in their values, which translates into LMP expected values that are higher than the corresponding medians. As such, the thresholds obtained using FTEV tend to be more conservative than those obtained using FTS, in the sense that higher thresholds will lead to a less frequent release of water for generation. The lower thresholds using the latter approach lead to faster inventory turnover, and since the plant is using the water more frequently, it is capturing more market compensation.In order to have varied data sets that represent days over the year, we consider a weekday and a weekend day in several different months from different seasons. For the weekday we picked Tuesday and for the weekend day, Saturday. We run simulations for six different months of the year (January, March, May, June, August, and November), which yields 12 distinct cases or day-and-month combinations. For each case, we used Algorithms 1 and 2 to compute the FTS with 250 scenarios and FTEV with the expected value scenario with identical initial conditions (initial upper-reservoir level and real-time generation and pumping, and day-ahead awards). Next, using the scenario generation approach described in Section 6.2, we generated anywhere from 5000 scenarios for each combination of day and month. Finally, for each of the cases, we ran two simulations. In one simulation, the threshold is fixed at the value of FTS and in the other one it is fixed at the value of FTEV. For every day and month combination, the same scenarios are used in the two simulations; i.e., we use common random numbers to reduce the variance of the estimate of the difference.Table 4 displays the results of our simulation experiments, and the comparison of FTS and FTEV is shown in Table 5. The “Overall” columns in Table 4 are equal to the sum of the realized real-time market compensation of the day of operations (day 1), the expected real-time market compensation of the next day (day 2), and the expected day-ahead market compensation of the day after that (day 3). We deemed it important to look at the overall market compensation because it takes into account more than just immediate short-term benefit. For example, if a threshold was superior on the “day of operations” but performed relatively poorly over the next two days, we would be cautious in recommending its use because it would put too much emphasis on short-term rewards.Focusing on Table 5 and taking into account that the point estimates for the delta terms are obtained by subtracting FTEV from FTS, we can see that there is only one case (August Tuesday) which indicates an advantage for FTEV, and another one (May Tuesday) in which the lower bound of the 95 percent confidence interval is not positive. This suggests that the FTS yields superior performance when used in operations. If we consider the average delta as a measure of a daily average over the 12-day period, we can see that using the FTS would result in an average real-time market compensation 27,723.31 dollars higher per day of operations than if we used the FTEV.Stringing several days together in a week-long simulation, although more complicated and time consuming, allows us to capture the multiday effect of using FTS and FTEV. For our particular implementation, we focused on a week in January. We used three days to warm up the process and seven days to collect the results, resulting in simulation data sets that are 10 days long, starting on a Monday. Our results are for the week-long period starting on a Thursday and ending on the following Wednesday. We assumed the same initial conditions for the starting day in every case.The 10-day LMP data are obtained using our LMP models. The day-ahead awards for the starting day are obtained using our day-ahead model (Vojvodić, 2016), and are the same for both the FTS and FTEV cases. For both FTS and FTEV, the day-ahead awards for days 2 through 10 are generated within the simulations using the respective expected value at noon of the previous day of the upper-reservoir’s level at midnight.Similarly, the FTS and FTEV thresholds to use for day 1 of the simulations were computed using Algorithms 1 and 2, and 250 scenarios and the expected-value scenario, respectively. The FTS and FTEV thresholds for days 2 through 10 were computed within the simulations. For each of the FTS and FTEV, we used the respective expected value at 5 p.m. of the previous day we obtained for the upper-reservoir, generation, and pumping levels at midnight.In Table 6, we summarize the average real-time market compensations for the day of operations using the two approaches and show the comparison between them. Due to the fact that obtaining the thresholds is computationally time consuming, the results are based on 60 independent and identically distributed replications of the week. Consequently, the 95 percent confidence intervals are not as tight as in the previous case; nonetheless, along with the point estimates for the deltas between the FTS and the FTEV approaches, they suggest that using the FTS yields a more substantial market compensation.

@&#CONCLUSIONS@&#
