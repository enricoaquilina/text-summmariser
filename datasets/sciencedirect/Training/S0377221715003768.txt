@&#MAIN-TITLE@&#
Bi-Objective Multi-Mode Project Scheduling Under Risk Aversion

@&#HIGHLIGHTS@&#
New model for stochastic multi-mode resource constrained project scheduling.Objectives makespan and cost considered simultaneously.Risk aversion addressed by multivariate stochastic dominance constraints.An exact solution technique is developed.

@&#KEYPHRASES@&#
Project scheduling,Multi-objective optimization,Stochastic optimization,Risk aversion,Stochastic dominance,

@&#ABSTRACT@&#
The paper proposes a model for stochastic multi-mode resource-constrained project scheduling under risk aversion with the two objectives makespan and cost. Activity durations and costs are assumed as uncertain and modeled as random variables. For the scheduling part of the decision problem, the class of early-start policies is considered. In addition to the schedule, the assignment of execution modes to activities has to be selected. To take risk aversion into account, the approach of optimization under multivariate stochastic dominance constraints, recently developed in other fields, is adopted. For the resulting bi-objective stochastic integer programming problem, the Pareto frontier is determined by means of an exact solution method, incorporating a branch-and-bound technique based on the forbidden set branching scheme from stochastic project scheduling. Randomly generated test instances, partially derived from a test case from the PSPLIB, are used to show the computational feasibility of the approach.

@&#INTRODUCTION@&#
The Resource-Constrained Project Scheduling Problem (RCPSP) has turned out as a useful and flexible modeling approach in several branches of project management (see, e.g., Brucker, Drexl, Möhring, Neumann, and Pesch, 1999). For situations where projects have to be carried out under limited resources, the RCPSP model allows the determination of optimal schedules with respect to an objective such as the makespan, i.e., the total project completion time. Despite the RCPSP’s large versatility, however, there are aspects of real-life project scheduling that are not covered by the classical formulation of this problem, which has led to different extended versions. Three of the most important aspects of this kind are: (i) the necessity to take uncertain activity durations into account, (ii) the case where for single activities of a project, there is a choice between different modes, and (iii) the occurrence of further objectives in addition to the makespan, for example, cost (or profit) not considered as a constraint, but as another objective.A large number of articles (cf. the surveys Hartmann and Briskorn, 2010; Herroelen and Leus, 2005) have dealt with these three complicating aspects in separation from each other, which has led to (i) stochastic, (ii) multi-mode or (iii) multi-objective generalizations of the RCPSP, respectively. However, a work addressing all three aspects in a combined model seems to be missing. To develop such a model and a suitable solution technique is the first aim of the present paper.The second aim concerns the aspect of risk aversion. The most common approaches of stochastic project scheduling suppose a risk-neutral project manager, i.e., a decision maker optimizing expected values of outcomes. However, in the practice of project management, this is often not sufficient: special care needs to be taken to avoid extreme values of time and cost, even if their occurrence has a comparably small probability. To represent risk aversion in our optimization model, we shall resort to an approach recently developed in other fields, namely stochastic optimization under multivariate dominance constraints (see Dentcheva & Ruszczyński, 2009). This method fixes a reference solution (e.g., a state-of-the-art solution) and solves then an optimization problem on the constraint that the solution to be proposed stochastically dominates the reference solution. Contrary to the standard applications of this method, the optimization problem under consideration will be bi-objective in our case. Its entire efficient frontier – including so-called non-supported solutions – will be determined.In total, we shall formulate a stochastic multi-mode RCPSP under risk aversion with the two objectives makespan and cost, and compute its Pareto frontier by means of an exact optimization method. The proposed method will make use of (i) an algorithm for optimization under multivariate dominance constraints, developed by Homem-de Mello and Mehrotra (2009), and of (ii) a problem-specific branch-and-bound technique for stochastic project scheduling investigated by Stork (2001). It will be shown that by a suitable modification and integration of these algorithms and by putting them into the context of the well-known epsilon-constraint method for multi-objective optimization, instances of nontrivial size of the considered complex problem can still be solved to optimality.The paper is organized as follows. Section 2 gives a survey on related work and on the features distinguishing our approach from the available literature. Section 3 formulates the investigated bi-objective stochastic optimization model in mathematical terms, and Section 4 presents the suggested solution algorithms. In Section 5, computational results are presented. Section 6 contains concluding remarks.Methods of stochastic project scheduling have been intensely investigated in the literature, starting with works by Radermacher, Igelmund, Möhring, Stork and others (see, e.g., Igelmund and Radermacher, 1983; Möhring and Stork, 2000; Stork, 2001). Contrary to deterministic project scheduling problems, where a solution is described by a vector of starting times of activities, a solution to a stochastic project scheduling problem is a (dynamic) policy. It turns out that optimization on the class of all dynamic scheduling policies for a given stochastic scheduling problem is usually not a viable approach, partly because of the computational complexity of finding the optimal policy, partly because of the difficulties related to the description and practical implementation of a general dynamic policy. Therefore, different subclasses of policies have been proposed. Among them, let us mention the class of early-start policies (ES policies), the class of activity-based priority policies, and the class of resource-based priority policies. A thorough classification and description of project scheduling policies can be found in Stork (2001). In the present paper, we shall choose the framework of ES policies.Recent research in stochastic project scheduling focuses on several issues, some of which will be outlined in the following. Ballestin (2007) discusses the circumstances under which it is advisable to use stochastic instead of deterministic scheduling methods and develops algorithmic solution techniques. Zhu, Bard, and Yu (2007) address the problem of setting target due dates by using a two-stage stochastic programming framework. Tereso, Araujo, Moutinho, and Elmaghraby (2008) investigate dynamic programming as well as diverse metaheuristic algorithms on a special stochastic resource allocation problem in project scheduling.Ballestin and Leus (2009) present a comprehensive investigation of the RCPSP under stochastic activity durations, considering diverse objective functions such as the expected makespan, the makespan standard deviation and the probability of meeting a due date. As the computational solution technique, a greedy randomized adaptive search procedure (GRASP) is applied. Their study is of special relevance for the topic of the current paper, since they explicitly address the issue of risk aversion. From the numerical results on correlations between the different objective function values, they conclude that it suffices to focus on the expected makespan (which would be a risk-neutral consideration), since the risk-related measures are strongly correlated with the expected makespan anyway. Let us emphasize, however, that the investigations in Ballestin and Leus (2009) refer to the single-mode RCPSP, and that “cost” is not taken into account as an objective. In the present paper, we will turn to the multi-mode RCPSP, representing the total cost of the activities in the chosen modes as a separate objective function. This leads to a natural tradeoff not only between makespan and cost, but (as we shall argue in Section 3.4) also between low-risk, medium-expected-effort solutions on the one hand and high-risk, low-expected-effort solutions on the other hand. In such a context, the decisions preferred by a risk-averse decision maker may be completely different from those that are optimal under a risk-neutral stance.Ashtiani, Leus, and Aryanezhad (2011) show that by introducing a preprocessing phase where some sequencing decisions are already made a priori while the remaining decisions are made dynamically, the performance of solution algorithms for the RCPSP with stochastic activity durations can be considerably improved. Deblaere, Demeulemeester, and Herroelen (2011a) combine the deployment of a scheduling policy with the determination of a vector of predictive starting times of the single activities. A “policy execution cost” composed of expected penalties for earliness and tardiness of the single activities is minimized.Leus and Herroelen (2004) and Leus (2011) focus on ES policies and use resource flow variables to represent resource-allocation decisions, which allows the derivation of theoretical results on optimal ES policies. Furthermore, in Leus (2011), an alternative to the “forbidden set branching scheme” from Stork (2001) for enumerating feasible ES policies is proposed by the introduction of a binary branching strategy. Artigues, Leus, and Nobibon (2013) turn from stochastic optimization to robust optimization by minimizing, instead of the expected makespan, the maximum absolute regret over a set of scenarios for the durations of the activities. The two last-mentioned articles are especially interesting in the context of the present paper since we rely here on ES policies as well. Furthermore, let us note that also Artigues et al. (2013) implicitly presupposes a risk-averse attitude of the decision maker, but the model in Artigues et al. (2013) puts less emphasis on the “average situation” than the model presented here where the goal of avoiding too risky decisions is balanced with that of keeping the expected makespan low.In the absence of resource constraints, multi-mode versions of the project scheduling problem have been investigated under the terms time-cost tradeoff problem or activity crashing problem, a problem class for which also stochastic variants exist (see, e.g., Gutjahr, Strauss, and Wagner, 2000). For the resource-constrained deterministic problem variant, a wealth of literature is available. Most but not all of these articles rely on heuristic solution techniques (see, e.g., Bouleimen and Lecocq, 2003; Coelho and Vanhoucke, 2011; Deblaere, Demeulemeester, and Herroelen, 2011b; Jozefowska, Mika, Rozycki, Waligora, and Weglarz, 2001). Much less well-investigated is the stochastic multi-mode problem variant: only very few articles dealing with this subject can be found. Tereso, Araujo, and Elmaghraby (2004) and Tereso et al. (2008) treat the resource allocations to the activities as decision variables; different resource allocations incur different costs. The “work contents” of the activities are considered as random variables. Chen, Zhang, Liu, and Liu (2010) consider a stochastic project scheduling problem with uncertain activity durations where each activity i is associated with a set Miof execution modes. A solution is given by a permutation of the activities and a vector of execution modes. A serial schedule generation scheme is used to compute a concrete schedule for the activities, given a solution and a realization of the random variables. As the objective function, the expected net present value of the resulting cash flows is chosen. The model is solved by means of the ant colony optimization metaheuristic. The present paper has some features in common with Chen et al. (2010), but differs from Chen et al. (2010) by (i) considering makespan and cost as two separate objective functions whose Pareto frontier is to be determined, by (ii) replacing the (risk-neutral) expected-value consideration by a risk-averse consideration, and (iii) by solving the resulting problem exactly instead of heuristically.Also Muller (2011) presents a multi-mode stochastic project scheduling problem. In their formulation, however, also non-renewable resources are considered, and uncertainty does not reside in the duration of the activities, but instead in the non-renewable resource requirements of each mode. In the model, the stochastic aspect is dealt with by a chance constraint. A branch-and-cut technique is used for the computational solution of the resulting conic quadratic integer program. As in Chen et al. (2010), the model is single-objective.Godinho and Branco (2012) study a multi-mode stochastic scheduling problem with a weighted sum of expected cost and expected tardiness as the objective function. Compared to Chen et al. (2010), their model does not consider resource constraints. On the other hand, it provides additional flexibility in the considered scheduling policies insofar as the execution modes need not to be fixed in advance, but are allowed to be determined dynamically. A special (restricted) class of policies is defined to represent the dependence between starting times of activities and chosen modes. A metaheuristic called “electromagnetism heuristic” is used for the computational solution. As the two former-mentioned articles, the papers stick to a risk-neutral, single-objective consideration.Several articles on multi-objective versions of the RCPSP have been published. We shall not go into detail concerning this strand of the literature, since most of these papers deal with deterministic models and have therefore not too much in common with the present investigation. Some articles include robustness issues in the multi-objective model. As an example, let us mention Abbasi, Shadrokh, and Arkat (2006), where the first objective is makespan and the second objective is a floating-time criterion related to schedule reliability. The authors use a weighted-sum approach to deal with the two objective functions. Closer to the present investigation is Kilic, Ulusoy, and Serifoglu (2008) where a bi-objective model with expected makespan and expected total cost as objectives is presented. The authors apply a multi-objective genetic algorithm for the solution of the model. Contrary to the model in the present paper, Kilic et al. (2008) does not consider resource constraints, and it restricts the consideration to expected values, i.e., does not assume a decision maker with a risk-averse preference structure.Let us start by outlining the simple deterministic RCPSP. After that, three (cumulative) extensions leading to the complete model under consideration shall be explained step by step. We adopt the notation in Ballestin and Leus (2009) and Leus (2011). A project consists of a set V = {0, … , n + 1} of activities, where 0 (project start) and n + 1 (project end) are dummy activities. For each activity i, its duration di≥ 0 is given. Dummy activities do not take time, that is, d0 = dn+1 = 0. The vector (d1, … , dn) of durations of non-dummy activities is denoted by d. Precedence constraints are given by a set A ⊂ V × V of pairs (i, j) of activities i, j ∈ V, where (i, j) ∈ A means that activity i must be completed before activity j can start. We assume that A forms a precedence relation, which is a strict partial order on V (an irreflexive and transitive relation). A representation by an activity-on-node graph is used. The graph with node set V and edge set A is denoted by G(V, A) or, whenever we would like to add the information on the durations assigned to the nodes, by G(V, A, d).Moreover, it is supposed that resource constraints with respect to a certain number of renewable resource types are given. The availability of resource type k is defined byak∈N(k = 1, … , K). During its execution, activity i consumes rikunits of resource type k (i = 1, … , n; k = 1, … , K). The dummy activities 0 and n + 1 do not consume resources.A schedule s consists of a vector (s0, … , sn+1) of starting times of activities 0, … , n + 1. Schedule s is called time-feasible if it satisfies the constraints si+ di≤ sj∀(i, j) ∈ A. For a given schedule s, letA(s,t)={i∈V|si≤t<si+di}denote the set of activities that are in progress at time t (t = 0, 1, … ). Schedule s is called resource-feasible if∑i∈A(s,t)rik≤akfor all k and t. A schedule is feasible if it is both time-feasible and resource-feasible. The most usual objective function considered for the RCPSP is the makespan, given by dn+1 (the time of the event “project end”).The resource constraints can be represented by means of minimal forbidden sets. For any given precedence relation E, a set U ⊆ V of activities is called a forbidden set if it is an anti-chain of E (i.e., if (i, j) is not contained in E for any two activities i, j ∈ U), and ∑i∈Frik> akfor at least one k ∈ K. Informally speaking, a forbidden set consists of activities that cannot be executed simultaneously, given the resource constraints, although they could be executed simultaneously with respect to the time constraints. An inclusion-minimal forbidden set is called a minimal forbidden set (MFS). The family of MFSs with respect to E will be denoted byF(E). Using the notion of MFSs, we can express resource-feasibility by saying that a schedule s is resource-feasible if and only if there is noU∈F(A)such thatU⊆A(s,t)for some t.The RCPSP will be successively extended in this paper in three respects: First, the deterministic RCPSP is generalized to the stochastic RCPSP (S-RCPSP). From the different alternatives studied in the literature, we choose the use of early-start policies for this generalization and focus on the (expected) makespan as an objective function. Second, a multi-mode variant of the problem will be considered. This introduces (expected) cost as a second objective function. The two objective functions shall not be aggregated, but considered simultaneously in a bi-objective consideration. Third, instead of a risk-neutral interpretation of the problem, where the expected values of makespan and cost would be the only relevant criteria for the decision, we shall assume a risk-averse decision maker. Risk aversion both refers to makespan and cost. Since these two quantities are stochastically correlated, a difficult bi-objective stochastic optimization problem under risk aversion is obtained. Few solution concepts are known for such problems. We shall adopt the recently developed concept of optimization under multivariate stochastic dominance constraints (Dentcheva & Ruszczyński, 2009). This approach assumes that to a concrete given problem instance, an acceptable reference solution is known. A constraint is added to the problem formulation requiring that the output solution stochastically dominates the reference solution based on a given multivariate stochastic dominance relation. In this way, too risky solutions are excluded from consideration even if they look attractive from a pure expected-value point of view.The resulting problem will be called the Risk-Averse Multi-Objective Stochastic Multi-Mode RCPSP or short RAMOS-MRCPSP. Its basic structure is as follows:min(E[makespan(X)],E[cost(X)])s.t.XstochasticallydominatesX0where X0 is the reference solution and the bi-objective minimization is interpreted in the sense of the determination of the Pareto-efficient solutions. Dealing with two objectives in such a formulation is a novel feature of this paper compared to previous publication on optimization under multivariate stochastic dominance constraints, which have a single objective function in the upper line. In the following three subsections, the gradual extension of the RCPSP to the RAMOS-MRCPSP will be specified in precise formal terms.In the stochastic extension of the basic RCPSP, the deterministic durations diare replaced by random durations Di(i = 1, … , n), which gives a random vector D = (D1, … , Dn). The random variables Dican be correlated. It will be assumed that the joint distribution of the durations Diis a finite discrete distribution represented by a set of N equally likely11A generalization of the presented approach to the case of scenarios with given probabilities that need not to be equal is possibly not too difficult. Let us mention, however, that the equiprobable case is of prevailing practical relevance insofar as it is the case one faces whenever an underlying probability distribution is approximated by drawing a sample of scenarios according to the given distribution.scenarios ω1, … , ωN. Thus, each scenario ωνis supposed to occur with probability 1/N. In scenario ων, the vector of durations isDν=(d1ν,…,dnν). We assumediν∈N0for all i and ν.By employing a scenario-based model, we choose a mainstream approach from the stochastic programming literature. One of the advantages of this approach is that it can represent correlations between random variables. Very frequently, activity durations are not independent; in construction applications, e.g., weather conditions or events on the labor market introduce positive correlations. While a simulation model for generating reasonable sample realizations even for correlated durations may be easy to set up, a combination of such a simulation component with an optimization algorithm can be too time-consuming. This makes it advantageous to separate the simulation from the optimization by means of a priori sample generation. For the latter, well-developed methodology exists. Of course, this approach comes at the price that the stochastic model considered during the optimization is only an approximation to the “true” stochastic model.To describe solutions, we consider the family of early-start policies (ES policies).22A main motivation for this choice is that ES policies allow elegant mixed-integer programming formulations based on resource flows (Leus, 2011; Leus & Herroelen, 2004). We do not require this type of formulations in the present approach, but they could possibly be helpful in future attempts to improve the optimization algorithms. From the viewpoint of the achieved expected makespan, ES policies seem to be at least competitive (if not better) compared to usual alternatives as activity-based or resource-based policies (see Stork, 2001). Let us mention, however, that by the more complex preprocessor policies (PP policies), quality improvements over ES policies have been obtained (Ashtiani et al., 2011).Let T(E) denote the transitive closure of relation E. An ES-policy is determined by a set X ⊆ (V × V)∖A of activity pairs with the properties thatF(T(A∪X))=∅and that the graph G(V, A ∪ X) is acyclic. Such an X is called a sufficient selection. In less formal terms, a sufficient selection is an extension of the precedence constraints achieving the purpose that no resource-infeasible subset of activities can be started simultaneously anymore. In this way, the resource constraints are reduced to time constraints with respect to the extended precedences. We are looking for the “best” extension of the precedences serving this purpose. The ES policy determined by sufficient selection X is the mapping of each possible duration vector d = (d1, … , dn) to a feasible schedule s(X, d), where s(X, d) is given by the starting times si(X, d) = length of the longest path from 0 to i in G(V, A ∪ X, d) (cf. Artigues et al., 2013 for details).In the stochastic case, the makespan Dn+1 under the chosen ES policy becomes a random variable. A well-investigated version of the stochastic RCPSP consists in minimizing the expected makespanE[Dn+1].In addition to the previous assumptions, we shall assume from now on that for each activity i, the project manager can choose an execution mode (short: mode) from a finite set Mi. The mode defines the specific way how activity i is performed. In particular, the following assumptions are made:•The durations of the activities depend on the mode, i.e., we have Di= Dim(m ∈ Mi). The realizations of the random variable Dimin scenarios ω1, … , ωNare denoted bydim1,…,dimN,respectively.To each mode m ∈ Mi, an (execution) cost Cimis assigned. Also the cost Cimis a random variable. Its realizations in scenarios ω1, … , ωNare denoted bycim1,…,cimN,respectively.The resource consumptions rikcan depend on the mode: rik= rik(m) for m ∈ Mi.A solution X = (p, m) of the stochastic multi-mode RCPSP obtained in this way contains two components: (1) an ES-policy given by the sufficient selection p, and (2) a vector m = (m1, … , mn) assigning to each activity i a mode mi∈ Mi(i = 1, … , n).LetM=M1×…×Mndenote the set of all mode combinations m. Set rik(m) = rik(mi) (i = 1, … , n; k = 1, … , K). By Πm, we denote the set of sufficient selections for the given graph G(V, A) and the given mappingE↦F(E)of precedence relations to MFSs under mode combination m. Note that since the resource consumptions depend on m, also the set of MFSs for a given precedence relation E can depend on m, and hence also the set Πm. Then the search space of the extended problem isX={(p,m)|p∈Πm,m∈M}.For the sake of consistency with the usual framework of expected utility theory, we formulate the objective functions as functions to be maximized, settingf1ν(p,m)=−(makespanofsolution(p,m)inscenarioν),f2ν(p,m)=−(costofsolution(p,m)inscenarioν).The makespan gν(p, m) of solution (p, m) in scenario ν can be obtained as the solution value of the critical path problem, and from this value, the first objective can be immediately computed throughf1ν(p,m)=−gν(p,m).Concerning the second objective, observe thatf2ν(p,m)only depends on m:(1)f2ν(p,m)=f2ν(m)=−∑i=1n∑j=1micijνmijwith mij= 1 if mi= j and mij= 0 otherwise (j = 1, … , |Mi|; i = 1, … , n). We have the obvious constraints∑j=1|Mi|mij=1(i = 1, … , n). By collecting all costs in a column vector,cν=(c11ν,…,c1,|M1|ν,……,cn1ν,…,cn,|Mn|ν)′,and doing the same for the decision variables mij, we can rewrite (1) as the inner product33Abusing notation, we interpret m alternatively as the vector (m1, … , mn) of integer mode indices or as the vector of binary mode indicator variables (mij). Since the information content of both representations is the same, this does not cause any ambiguity. In particular,Mcan be considered as the set of binary variables (mij) satisfying ∑jmij= 1 for all i.(2)f2ν=−(cν)′m.In total, the following bi-objective stochastic optimization problem is obtained:(3)max(F1(p,m),F2(m))s.t.p∈Πm,m∈Mwhere F1(p, m) and F2(m) denote the random variables with valuesf1ν(p,m)andf2ν(m),respectively, with ν being drawn uniformly at random from {1, … , N}.Obviously, (3) is still under-specified as a (bi-objective) mathematical program, since it is not clear (i) in which sense the random functions should be maximized, and (ii) how to deal with the presence of two objective functions. The simplest way to address (i) would be to take expectations, i.e., to replace the objective function line of (3) by max  (E[F1(p, m)], E[F2(m)]). For this variant, the set of Pareto-efficient solutions could be determined, which would then answer also question (ii) above. However, relying only on expectations of benefits would be a risk-neutral standpoint which we do not adopt in this paper.Whereas in single-mode stochastic project scheduling, minimization of the expected makespan usually also keeps the variance of the makespan and hence the risk of very high makespan realizations low, which makes a risk-neutral consideration sufficient (cf. Ballestin and Leus, 2009), in multi-mode stochastic project scheduling, tradeoffs between expected values and risks are notorious to occur in practice. For example, many activities can be carried out either (i) in a cheap, but not very reliable mode (e.g. “quick-and-dirty”-programming in software engineering, or building under improper time pressure in construction), or alternatively (ii) in a sound, but more expensive mode. In case of option (i), both expected cost and expected makespan are typically low, but as a consequence of possibly necessary re-work and laborious ex-post corrections, the variances of cost and makespan can be high. Contrary, in case of option (ii), both expected cost and expected makespan will be comparably higher; however, the variances of cost and makespan can be kept low. In such a situation, a risk-neutral decision maker (looking only at expected values) will prefer option (i), whereas a risk-averse decision maker will prefer option (ii).For dealing with multi-objective stochastic optimization problems under risk aversion, the use of multivariate stochastic dominance constraints has recently been proposed by Dentcheva and Ruszczyński (2009). In the special case of two objective functions, this approach works as follows: A bivariate stochastic order ≽ on the set of two-dimensional random vectors and a deterministic objective function h(x) are fixed. Moreover, for the given problem instance, a reference solution with random (bivariate) outcome Y is chosen. The reference solution should be conservative with respect to risk. One tries now to improve the reference solution without sacrificing its property of being not too risky. In formal terms, as a concretization of the (under-specified) problemmax{(f1(x,ω),f2(x,ω))|x∈X},the problem(4)maxh(x)s.t.(f1(x,ω),f2(x,ω))⪰Y,x∈Xis introduced. In this paper, we extend this approach by modifying (4) to a bi-objective problem in the sense of the Pareto-efficiency concept as follows:(5)max(E[f1(x,ω)],E[f2(x,ω)])s.t.(f1(x,ω),f2(x,ω))⪰Y,x∈XIn other words, instead of the auxiliary objective function h(x), we insert the two expectations of f1 and f2, and look for the resulting Pareto frontier. In this way, we can allow ourselves to be risk-neutral in the objective function line because too risky solutions are already filtered out by the stochastic dominance constraint.In the literature on optimization under multivariate stochastic dominance constraints, a standard choice for the multivariate stochastic order is the increasing positive linear concave order (cf. Dentcheva and Ruszczyński, 2009; Gutjahr and Pichler, 2013; Müller and Stoyan, 2002). For random variables X = (X1, … , Xq) and Y = (Y1, … , Yq), this order is defined by(6)X⪰PlinY⇔v′X⪰(2)v′Y∀v∈Pwhere ≽(2) denotes second-order stochastic dominance44A possible way to define (univariate) second-order stochastic dominance is by the definition X≽(2)Y iff E[u(X)] ≥ E[u(Y)] for each nondecreasing, concave utility function u for which the expectations exist.and for the domainPof weight vectors v, the default choice isP=R+q. Homem-de Mello and Mehrotra (2009) generalize this definition by allowingPto be an arbitrary polyhedral setP⊆R+q. We adopt this latter, more flexible dominance relation in the present work. More specifically, in our context where q = 2, we setP={(1,w)′|a≤w≤b}with constants a and b (0 < a ≤ b): Observe that except in the degenerate case where one of the objectives gets weight zero, one may assign weight 1 to the first objective without loss of generality, and that a polyhedral set on the real line is an interval. In this way, we arrive at the problem(7)max(E[F1(p,m)],E[F2(m)])s.t.(F1(p,m),F2(m))⪰PlinYp∈Πm,m∈Mwhere Y = (F1(p0, m0), F2(m0)) is the vector composed of the objective function values of the reference solution (p0, m0).Example 1To illustrate the used stochastic dominance concept, let us give the following simple example. Assume that two solutions (p0, m0) and (p1, m1) are compared under N = 4 equiprobable scenarios and produce in scenarios 1–4 the values below for makespan and cost. Moreover, assume that the weight w for cost is in the interval [a, b] = [0.1, 1].makespancost(p0,m0):2,10,2,43,2,8,1(p1,m1):4,5,5,51,2,3,4For the purpose of this example, we apply the following criterion (see Roman, Darby-Dowman, & Mitra, 2006) for second-order stochastic dominance in the case of equiprobable scenarios: Sort profits (i.e., negative costs) in nondecreasing order and cumulate the resulting values successively from left to right. Then dominance w.r.t. ≽(2) holds between the original vectors iff dominance w.r.t. the ordinary partial order onRNholds between the resulting vectors. (In less formal terms, this means that the first solution dominates the second one w.r.t. ≽(2) if it as least as good in the respective worst case, at least as good in the average of the two worst cases, in the average of the three worst cases, etc., and finally also in the average of all cases.) Setting w = 1 (i.e., giving makespan and cost the same weight 1), we obtain:weightedsumssortedandcumulatednegatives(p0,m0):5,12,10,5−12,−22,−27,−32(p1,m1):5,7,8,9−9,−17,−24,−29We see that (p1, m1)≽(2)(p0, m0) under w = 1. Now consider w = 0.1, i.e., the case where cost is only given 10 percent of the weight assigned to makespan. Then we getweightedsumssortedandcumulatednegatives(p0,m0):2.3,10.2,2.8,4.1−10.2,−14.3,−17.1,−19.4(p1,m1):4.1,5.2,5.3,5.4−5.4,−10.7,−15.9,−20.0Now the two solutions are mutually incomparable: a risk-neutral decision maker would choose the first one, which has the better expected value, while a risk-averse decision maker might choose the second one, which is better in the worst case. In total, for [a, b] = [0.1, 1], the second solution does not dominate the first solution w.r.t.⪰Plin. So if (p0, m0) is the reference solution, (p1, m1) is not feasible for (7). Note that even if the second solution would dominate the first one both for w = a and w = b, it would not yet be guaranteed that dominance also holds in the sense of⪰Plin,that is, for all weights w with a ≤ w ≤ b. In the next section it will be shown how testing for⪰Plinis possible without trying infinitely many values of w.Problem (7) is solved in the sense of the determination of its Pareto frontier. This notion is defined in the usual way: For two pointsz=(z1,z2)∈R2andw=(w1,w2)∈R2,let us write w≻z if wi≥ ziwith at least one inequality being strict. (Note the difference between the deterministic dominance relation ≻ and the stochastic dominance relation⪰Plin!) For two objective functions f1 and f2 to be maximized, element x of the feasible setXis called Pareto-efficient (short: efficient) if there is noy∈Xwith (f1(y), f2(y))≻(f1(x), f2(x)). The set S of all efficient solutions is called the Pareto set, and the imagef(S)⊆R2of this set in the objective spaceR2is called the Pareto frontier.Remark 1The proposed method requires the definition of a reference solution. There are several ways to find such a solution. One way would be to generate a set of promising solution candidates by some heuristic technique, to assess them by simulation and/or discussion among experts, and to select the most attractive among them. Another alternative would be to apply a (max–min or min–max-regret) robust optimization approach. A third alternative applies to the situation of a project with fixed structure that is carried out repeatedly under different circumstances; in this case, the reference solution may simply be based on a field-tested standard project plan. Of course, the last-mentioned alternative requires that the project manager has already applied the technology of planning by ES policies in the past, such that the standard plan is available in terms of a formal ES policy.It can happen that the reference solution turns out as “too good” in the sense that as after the restriction to the solutions dominating it, only few solutions (or even only the reference solution itself) remain, while the project manager would prefer to choose from a larger set of solution candidates. An option for dealing with this situation will be presented in Section 5.We shall provide an exact solution algorithm for problem (7), but in view of the enormous complexity of the problem, it is clear that some restrictive assumptions on the size of the problem instance have to be made. In particular, we shall assume that the setMof possible mode combinations is not yet too large to be completely enumerated. This assumption is frequently realistic in practice: Even if the number n of activities is large, it is often the case that only a small subset of them can be executed in different modes, which means that|Mi|=1for most activities.Whereas we assume that complete enumeration of the mode combinations m is still feasible, we cannot assume the same for the sufficient selections p. Their number is growing with an order ofO(2n2)in the number n of activities, i.e., very fast. Thus, an efficient integer-programming-based algorithm will be required as part of the solution procedure concerning this component of the solutionX=(p,m).To deal with the multi-objective aspect of the problem, we shall apply a simple algorithmic framework based on the epsilon-constraint method. (For variants of the epsilon-constraint method, the reader is referred to Laumanns, Thiele, and Zitzler, 2006.) Note that E[F2(m)] only depends on the mode combinationm∈M. The proposed framework procedure is described in Algorithm 1 below.Algorithm 1(Framework Procedure).1.Set S = ∅.Go through all possible levels h of E[F2(m)] in descending order (i.e., ascending order of expected costs −E[F2(m)]). For each h:(a)Solve(8)maxp,mE[F1(p,m)](9)s.t.E[F2(m)]=h(10)(F1(p,m),F2(m))⪰PlinY(11)p∈Πm,m∈MIf a solution (p, m) to (8)–(11) exists and if there is no (p′, m′) ∈ S with(E[F1(p′,m′)],E[F2(m′)])≻(E[F1(p,m)],E[F2(m)]),add (p, m) to S.In Algorithm 1, by the formulas in Section 3.3,(12)E[F1(p,m)]=−1N∑ν=1Ngν(p,m),E[F2(m)]=−1N∑ν=1N(cν)′m.The loop in the procedure above can be organized as follows: First, sort all mode combinations m w.r.t. their expected costs. With each possible cost level −h, one or several mode combinations m are associated. For each of these m, find the sufficient selection p maximizing E[F1(p, m)] subject to the constraints (10)–(11). The mode combination m giving the best objective function value, together with the corresponding p, specifies the solution (p, m) for the current level h. Evidently, the overall procedure generates the entire Pareto frontier.For fixed m, this gives the following subproblem:(13)minp∑ν=1Ngν(p,m)(14)s.t.(−[gν(p,m)],−[(cν)′m])⪰Plin(−[gν(p0,m0)],−[(cν)′m0])(15)p∈Πmwhere [ξν] denotes a random variable with equiprobable realizations ξ1, … , ξN.For an efficient determination of the Pareto frontier, it should be observed that many (if not most) mode combinations m will not produce a feasible solution to (13)–(15). In particular, mode combinations with too high expected costs will not be able to dominate the reference solution, but also low-cost modes may fail to give a solution satisfying (14) in view of possibly large makespan values. Thus, when tackling problem (13)–(15), it is advisable first to test whether a feasible solution exists at all (as we shall see, this decision problem is comparably easier), and to invest the runtime for determining the optimal solution only in the case that feasibility has already been checked. We shall describe these two steps in the following two subsections.For judging whether (14) can be satisfied by a suitable sufficient selection p, we use the criterion below for second-order stochastic dominance given in Homem-de Mello and Mehrotra (2009): Let ξ and ζ be (univariate) random variables with equiprobable realizations ξνand ζν, respectively (ν = 1, … , N). Then the statement ξ≽(2)ζ is equivalent to∑μ=1N(ζν−ξμ)+≤∑μ=1N(ζν−ζμ)+(ν=1,…,N).Therefore, (6) can be written in the discrete finite equiprobable case asX⪰PlinY⇔∑μ=1N(v′Yν−v′Xμ)+≤∑μ=1N(v′Yν−v′Yμ)+(ν=1,…,N)∀v∈P,where Xνand Yνis the ν-th realization of X and Y, respectively. In our case, the stochastic dominance relation (14) refers to the random vectors X = N · (F1(p, m), F2(m)) and Y = N · (F1(p0, m0), F2(m0)) with realizations Xν= ( − gν(p, m), − (cν)′ m) andYν=(−gν(p0,m0),−(cν)′m0)=:(αν,βν),where the numbers ανand βνare constants, since the reference solution is given. Thus, in view of v = (1, w), problem (13)–(15) is feasible if and only if(16)∃p∈Πm:∑μ=1N(αν+wβν+gμ(p,m)+w(cμ)′m)+−∑μ=1N(αν+wβν−αμ−wβμ)+≤0∀ν=1,…N,w∈[a,b].For deciding whether (16) holds, we use Algorithm 1 from Homem-de Mello and Mehrotra (2009) in a modified form. Actually, this algorithm is already designed for optimization problems (as opposed to decision problems), so it would be tempting to apply it directly to (8)–(11). However, since our constraints contain the makespan values gμ(p, m), this would require the solution of an optimization problem within the (non-linear) constraints of another optimization problem, which is difficult. For this reason, we choose a slightly different path by first applying Homem-de-Mello’s and Mehrotra’s algorithm only for deciding on feasibility, using an auxiliary objective function, and introducing the true objective function (13) afterwards (details will be described in the next subsection). The modification of the algorithm required in our context is given below as Algorithm 2.Algorithm 2(Feasibility Test).1.Set s = 0, w = a, ν = 1, and W0 = {(w, ν)}.Solve the problem(17)minpmax(w,ν)∈Ws[∑μ=1N(αν+wβν+gμ(p,m)+w(cμ)′m)+−∑μ=1N(αν+wβν−αμ−wβμ)+](18)s.t.p∈ΠmIf the solution value is > 0, stop with the answer “false” to (16). Otherwise, letp^be the optimal sufficient selection.Letα^μ=−gμ(p^,m)andβ^μ=−(cμ)′m. For ν = 1, 2, … , N, solve(19)minw,yψν(w,y):=∑μ=1Nyμ−∑μ=1N(αν+wβν−α^μ−wβ^μ)+(20)s.t.a≤w≤b(21)yμ≥αν+wβν−αμ−wβμ(μ=1,…,N)(22)yμ≥0(μ=1,…,N)As soon as for some ν in this loop, a negative solution value is obtained, go to Step 4.If in Step 3, the solution values have been nonnegative for all investigated ν = 1, … , N, stop with the answer “true” to (16). Otherwise, let ν be the index for which a negative solution value has been obtained, and let (w, y) be the corresponding solution. Add w ≕ wsand ν ≕ νsto Wsby setting Ws= Ws∪ {(ws, νs)}.Set s = s + 1 and go to Step 2.Let us now comment the single steps of Algorithm 2 in detail:Step 1:The overall algorithm gradually extends a subset Wsof the set [a, b] × {1, … , N} of all pairs (w, ν) for which the inequality in (16) has to be satisfied. Using s = 0, 1, … as the iteration counter, we initialize W0 as {(a, 1)}.Let relax(Ws) denote the relaxation of (16) to the weight-index pairs (w, ν) in Ws. Then relax(Ws) is solvable if and only if (17)–(18) has a solution value ≤ 0. So if the solution value of (17) and (18) is positive, relax(Ws) and therefore also (16) is false. Of course the converse does not hold: If the solution value of (17) and (18) turns out as nonpositive, which means that aπ^∈Πmexists such that the inequality in (16) is satisfied at least for all (w, ν) ∈ Ws, we have still to check whether there is not any other pair (w, ν) for which it is violated (this is done in Step 3). To solve (17) and (18), we use a branch-and-bound technique which will be presented later.This step tries to disprove that the just foundp^∈Πmsatisfies the requirement of (16) by searching a weight w and a corresponding scenario index ν such that the inequality in (16) is violated. The fact that (19)–(22) can be used for this purpose results as in the proof of Theorem 1 in Homem-de Mello and Mehrotra (2009): The inequality in (16) is violated for the givenp^if and only if there exists an index ν such that(23)minw∈[a,b](∑μ=1N(αν+wβν−αμ−wβμ)+−∑μ=1N(αν+wβν−α^μ−wβ^μ)+)has a negative value. The objective function in (23) is a difference of two convex functions in w. To obtain a concave minimization problem, one introduces the auxiliary variables y1, … , yNdefined as yμ= (αν+ wβν− αμ− wβμ)+ (μ = 1, … , N). When substituting them in (23), it suffices to impose the constraints (21) and (22) on them, since they are automatically minimized under these constraints. In this way, (23) turns into (19)–(22). Whenever a solution (w, y) with a negative solution value of (19) is found, we know that the corresponding w violates the ν-th condition of (16) for the givenp^and thus disprovesp^as a solution of (16). If no such (w, y) is found,p^solves (16).It is clear that we can stop (with answer “true”) if all solution values of (19) have turned out as nonnegative. Otherwise, we have to cut offp^from the set of candidate solutions and to repeat the procedure. Sincep^violates the constraints of (16) w.r.t. weight w and index ν, it is sufficient to add the pair (w, ν) to the set Wscontaining the pairs w.r.t. which (17) and (18) is solved.This step closes the loop which, by the finiteness of Πm, is terminated after a finite number of iterations.What remains to be done is to specify how the problems (17) and (18) and (19)–(22) can be solved computationally.Problem (17) is solved by branch-and-bound as follows.Branching strategy: The “forbidden set branching strategy” (Stork, 2001) is used. With each node of the branch-and-bound tree, a partial solution represented by a selection X ⊆ (V × V)∖A is associated. Selection X resolves some, but in general yet not all given MFSs. The forbidden set branching scheme arranges all MFSs in a fixed order and assigns the first level of the tree to the first MFS, the second level to the second MFS, etc. The node with associated partial solution X is split into successor nodes, where each successor is obtained from one particular additional precedence resolving the MFS corresponding to the current level: For MFS U, the set of these precedences is {(i, j) | i, j ∈ U, i ≠ j}. As soon as the procedure has reached the level of leaves (the level below that corresponding to the last MFS), all MFSs have been resolved, such that a sufficient selection p representing a complete solution is obtained. The objective value of such a solution p in (17) can be computed directly. This produces an upper bound.Bound computation: We look for a lower bound in a node corresponding to a subset X of the precedences. Let p be a sufficient selection associated with a leaf of the subtree rooted in the considered node. Then X ⊆ p. Let gμ(X, m) denote the length of a critical path in the graph with edge set T(A ∪ X) under scenario ωμand mode combination m. (This is consistent with the definition of the makespan gμ(p, m).) Because of X ⊆ p, we have that gμ(X, m) ≤ gμ(p, m) for all μ = 1, … , N. Thereforemax(w,ν)∈Ws(∑μ=1N(αν+wβν+gμ(X,m)+w(cμ)′m)+−∑μ=1N(αν+wβν−αμ−wβμ)+)is a lower bound for the objective function in (17). If X = p, then this bound coincides with the objective function value. To reduce the computation time, it is possible to use a simple pruning strategy suggested in Stork (2001): Let U be the MFS that is used for branching on the node associated with set X. Whenever (i, j) ∈ T(A ∪ X) for i ∈ U and j ∈ U, then it is optimal to resolve G by choosing the branch (i, j), which does then not imply an extension of X.According to the solution approach in Homem-de Mello and Mehrotra (2009), problems (19)–(22) can be reformulated equivalently to the following binary mixed integer program (MIP):(24)minw,y,e,h,z∑μ=1Nyμ−∑μ=1Neμ(25)s.t.a≤w≤b(26)yμ≥αν+wβν−αμ−wβμ(μ=1,…,N)(27)eμ−hμ=αν+wβν−α^μ−wβ^μ(μ=1,…,N)(28)Mzμ≥eμ(μ=1,…,N)(29)M(1−zμ)≥hμ(μ=1,…,N)yμ≥0,eμ≥0,hμ≥0(μ=1,…,N)zμ∈{0,1}(μ=1,…,N)with M a sufficiently large number. This is immediately seen, since constraints (28) and (29) ensure that either eμ= 0 or hμ= 0, so (27) can only be satisfied ifeμ=(αν+wβν−α^μ−wβ^μ)+andhμ=(αν+wβν−α^μ−wβ^μ)−. The above MIP contains N binary variables; if the number N of scenarios is not too large, the problem can be solved by a commercial MIP solver. (In our experiments, we use CPLEX for this purpose.)If, for a certain mode combination m, the feasibility test described in the last subsection has produced the result that subproblem (13)–(15) possesses a feasible solution, we are left with the task of solving the optimization problem itself. For this purpose, an extension Algorithm 3 of Algorithm 2 can be applied. The idea is to minimize a weighted sum of the original objective function and a penalty term (obtained from the auxiliary objective function used in Algorithm 1) penalizing feasibility violations. The weight is adapted iteratively. We first present the algorithm and prove then its validity.Algorithm 3(Solution of the Subproblem).1.Set s = 0, w = a, ν = 1, and W0 = {(w, ν)}. Choose some ε > 0.Solve the problem(30)minp{ϵ∑μ=1Ngμ(p,m)+max(w,ν)∈Ws[∑μ=1N(αν+wβν+gμ(p,m)+w(cμ)′m)+−∑μ=1N(αν+wβν−αμ−wβμ)+]+}(31)s.t.p∈ΠmLetp^denote the optimal solution.Letα^μ=−gμ(p^,m)andβ^μ=−(cμ)′m. For ν = 1, 2, … , N, solve (19)–(22). As soon as for some ν in this loop, a negative solution value is obtained, go to Step 4.If in Step 3, the solution values have been nonnegative for all investigated ν = 1, … , N, returnp^and stop. Otherwise, let ν be the index for which a negative solution value has been obtained, let (w, y) be the corresponding solution, letδ=∑μ=1N(αν+wβν−α^μ−wβ^μ)+−∑μ=1N(αν+wβν−αμ−wβμ)+≥−ψν(w,y)>0,and set ε = min (ε, ρδ/Tm), where ρ is a constant with 0 < ρ < 1 and Tmis an upper bound for∑μ=1Ngμ(p,m)(p ∈ Πm). Add w ≕ wsand ν ≕ νsto Wsby setting Ws= Ws∪{(ws, νs)}.Set s = s + 1 and go to Step 2.Note that as (17), also (30) is a nondecreasing function of the makespan gμ(p, m). Therefore, problem (30) and (31) can again be solved based on the forbidden set branching scheme, as described in Section 4.1.1.Proposition 1If the feasibility criterion (16) is satisfied, then Algorithm3terminates after a finite number of iterations with an optimal solution of (13)–(15).The proofs of the propositions are given in Appendix A.In order to reduce the runtime of Algorithm 1, the following bounds can be helpful:Proposition 2Letg¯(p,m)=(1/N)∑ν=1Ngν(p,m)andc¯=(1/N)∑ν=1Ncν. Then(F1(p,m),F2(m))⪰Plin(F1(p0,m0),F2(m0))implies that for all w ∈ [a, b]:(32)(1/w)g¯(p,m)+c¯′m≤(1/w)g¯(p0,m0)+c¯′m0=:Cw,(33)c¯′m≤c¯′m0+(1/w)(g¯(p0,m0)−g¯(∅,m)).Because of (32), only mode combinations m for which c′m ≤ Cwhave to be enumerated. For w = b, the best (i.e. lowest) upper bound Cwis obtained. For each m satisfying the condition above, one can check then whether (33) is fulfilled. Therein, it is optimal to set w = b ifg¯(p0,m0)≥g¯(p,m),and to set w = a otherwise. Only if also (33) holds, it is necessary to execute Algorithms 2 and 3.Example 2The following very small example illustrates some basic ideas of the proposed algorithms. Consider n = 4 activities with precedences A = {(1, 2), (3, 4)}. Let the durations and costs be given byD=[(5,2,7)(2,4,6)(3,8,4)(1,6,5)(1,6,5)(3,6,7)(4,3,2)(8,2,1)]andC=[(1,2,3)(2,4,6)(3,1,4)(2,1,3)(5,5,5)(4,4,4)(6,7,8)(5,8,9)],respectively. Therein, lines are activities, columns are modes, and the three consecutive values in the entries of D and C refer to N = 3 scenarios. Furthermore, assume that there are three MFSs (the same in both modes), namely {2, 3}, {1, 2, 4} and {1, 3, 4}. The two last MFSs are already resolved by A, so we can restrict ourselves to the sufficient selections {(2, 3)} and {(3, 2)}. As the reference solution, we choose the mode combination m0 = (2, 1, 1, 2) together with the sufficient selection p0 = {(2, 3)}. The weight interval is chosen as [a, b] = [0.2, 1].Algorithm 1 starts by sorting the mode combinations according to their expected costs. Obviously, the mode combination with lowest expected cost is m = (1, 2, 2, 1) with an expected cost value of 15. Therefore, in the first iteration of Algorithm 1, this mode combination is investigated. To test whether a solution to (8)–(11) exists, Algorithm 2 is called. Algorithm 2 sets W0 = {(0.2, 1)} and determines then the optimal sufficient selectionp^w.r.t. (17), based on the valuesα1=−14,α2=−20,α3=−16,β1=−15,β2=−18,β3=−24,which are the negative makespan and the negative cost values, respectively, of the reference solution in the three scenarios. (The last can easily be checked by observing that the reference solution executes the four activities in sequential order.) The best sufficient selection w.r.t. (17) turns out to bep^={(3,2)},with assigned negative makespan and negative cost values ofα^1=−7,α^2=−12,α^3=−12,β^1=−13,β^2=−14,β^3=−18.This gives a solution value of −10.4 ≤ 0 in (17). The nonpositive solution value indicates that the found(p^,m)satisfies the condition for dominating the reference solution at least for w = 0.2 and ν = 1. Next, the program in Step 3 of Algorithm 2 tests whether for(p^,m),there is any other w ∈ [a, b] or ν ∈ {1, … , N} for which the dominance condition is not satisfied. If this should hold, the set of considered weights or scenarios would be extended. In our example, it is not the case, so Algorithm 2 decides that for mode combination m = (1, 2, 2, 1), a solution dominating the reference solution exists.As a consequence, Algorithm 3 is called in order to maximally improve (for fixed m) the value of the expected makespan, if this is possible, keeping the dominance constraint satisfied. In our example, however, such an improvement cannot be achieved. Therefore, the found solution(p^,m)is inserted into the list of efficient solutions. Evidently, for its expected makespan and its expected cost, we obtain the values (7 + 12 + 12)/3 = 10.333 and (13 + 14 + 18)/3 = 15, respectively. The next dominating solution occurs four iterations later for m = (1, 2, 1, 1). In this case, the optimal expected makespan results as 10, which is better than that of the previous solution. Therefore, also this solution is added to the list of efficient solutions, together with its expected cost value of 16. A third efficient solution is found for m = (2, 2, 1, 1) (expected makespan 9.333, cost 18).It is evident that in our approach, the stochastic dominance constraint does not assume the same preference structure as the final selection according to Pareto efficiency, since the former takes a risk-averse position, whereas the latter acts in a risk-neutral manner. Thus, at least from the perspective of expected utility theory (which is, however, not the only possible way to interpret stochastic dominance relations), the two steps of the decision process presume different types of utility functions. In this perspective, the proposed approach has to be considered as a pragmatic approximation to a more complex procedure.55This procedure could work as follows: First, the proposed algorithm has to be executed in a modified variant where it produces all solutions satisfying the stochastic dominance constraint (such a modification is possible, but at the price of a considerable runtime increase). Then, to the resulting candidate set of solutions, some multi-criteria decision making method determining nondominated solutions with respect to a setUof possible utility functions has to be applied. This could, for example, be Robust Ordinal Regression (Branke, Greco, Slowinski, & Zielniewicz, 2009). ForU,the set of utility functions generating the stochastic dominance relation⪰Plinhas to be taken. Although this procedure would be ideal from a theoretical point of view, its runtime requirements are certainly extremely high.It should be emphasized that also other well-established approaches in optimization, such as Chance-Constrained Programming, follow the pragmatic idea of filtering out, in a first step, all those solution that do not conform with a requirement A to a sufficiently high degree, and selecting then the final solution according to another requirement B, without considering A anymore.To test the described approach, two sets of instances were generated. Since already the single-objective deterministic MRCPSP and the single-objective, single-mode S-RCPSP, which are both special cases of the RAMOS-MRCPSP considered here, are computationally challenging problems, it is obvious that we can only hope to solve small instances of the RAMOS-MRCPSP to optimality. For both sets of instances, a random test instance generator described below was used. The structure of the precedence graph G(V, A) was fixed in advance in both cases. The smaller instances have n = 10 activities and are built on the graph in Fig. 1. To get somewhat larger instances, the first MRCPSP instance from the well-known PSPLIB (Kolisch & Sprecher, 1997) was taken. It contains n = 16 non-dummy activities. Again by varying the concrete parameters with the help of the test instance generator, the second set of instances was created, building on the graph G(V, A) from the PSPLIB example case.For activity durations Dimas well as for costs Cim, uniform distributions on certain intervals[D̲im,D¯im]and[C̲im,C¯im],respectively, were considered. In each test instance, the intervals assigned to each activity and each mode were generated randomly, as indicated below. A basic mode 1, a cheap mode 2 and an expensive mode 3 were distinguished. From the set of n activities, disjoint subsets NCh, NExand NChExwith pre-defined cardinalities nCh, nExand nChExwere randomly selected. Activities in NChcan be executed in modes 1 or 2, activities in NExcan be executed in modes 1 or 3, and activities in NChExcan be executed in modes 1, 2 or 3. The remaining activities can only be executed in the basic mode 1.The generation of the intervals[D̲im,D¯im]was controlled by pre-defined parametersDM,D¯M,DL,D¯L,CM,C¯M,CLandC¯L. In the basic mode, withU(a,b)denoting a random number uniformly selected from [a, b], we choseD̲i1=U(D̲M,D¯M),D¯i1=D̲i1+U(D̲L,D¯L),C̲i1=U(C̲M,C¯M),C¯i1=C̲i1+U(C̲L,C¯L).The intervals for the cheap and for the expensive mode were generated from the intervals of the basic mode by the following transformations: For the cheap mode,•[D̲i1,D¯i1]was replaced by[θχD̲i1,θ(D¯i1+(1−χ)D̲i1)]withθ=U(1,κ1)andχ=U(0,1),and[C̲i1,C¯i1]was replaced by[γC̲i1,γC¯i1]withγ=U(κ2,1).Thus, in the cheap mode, the durations tend to increase in mean value and variance, and the costs tend to decrease. For the expensive mode, the intervals were transformed in an analogous, but converse way.A single resource type was assumed. The resource requirements ri1 of the activities were generated from a uniform distribution on an interval[R̲,R¯].The reference solution (p0, m0) for a test instance was determined as follows: The mode combination m0 was obtained by taking only the basic mode 1 for all activities. The sufficient selection p0 was obtained by generating only a single scenario ω1 and by solving the resulting deterministic RCPSP, i.e., by determining the sufficient selection with minimal makespan to the given m and ω1.To denote the test instances and their variants, we use in the following the code n/a1/[a, b]/seed, containing number of activities, availability of the resource, endpoints of the interval restricting the relative weight of the second objective, and used seed for the random generation of the instance.The following parameter values for the instance generation were used: nCh= 2, nEx= 2, nChEx= 3 (this gives 22 · 22 · 33 = 432 mode combinations),[D̲M,D¯M]=[5,20],[D̲L,D¯L]=[0,30],[C̲M,C¯M]=[5,20],[C̲L,C¯L]=[0,30],[R̲,R¯]=[1,5],κ1 = 2, κ2 = 0.5. For a1, the values 5, 6 and 7 were tested, and for the interval [a, b] of the weights, the alternatives [a, b] = [0.1, 1.0] and [a, b] = [0.5, 0.7] were compared. On a PC with 2.4 gigahertz Quad Core Processor and 8 GB System Memory, a MATLAB R2007b implementation required 8.5 minutes computation time per test instance in the average.Fig. 2shows the obtained Pareto frontiers for some selected instances. Let us give some comments. Typically, the Pareto frontiers contained comparably few elements. Interestingly, in many cases the covered ranges of expected makespan and expected cost were nevertheless rather large (see, e.g., the two plots in the upper row of Fig. 2). However, also cases occurred (see, e.g., the left plot in the medium row of Fig. 2) where one of the objectives covered only a small range. Of course, these properties depend on type and quality of the reference solution.The influence of the interval [a, b] of the weight w of the cost objective in the stochastic dominance relation is seen by a comparison of the left and the right plots in the first two rows of Fig. 2. In the upper row (instance 11), we see that a reduction of this interval from [0.1, 1.0] to [0.5, 0.7] simply extends the Pareto frontier by adding three points at the right end. It is clear that a restriction of the interval [a, b], which means that the decision maker can estimate the relative importance of the two objectives in a more specific way, will increase the chance that a solution dominates the reference solution and will thus tend also to “enlarge” the Pareto frontier, but the concrete from of this extension cannot be predicted. In the medium row of Fig. 2 (instance 13), the restriction of the interval [a, b] has the consequence that two new nondominated points at the left end of the Pareto frontier arise, the second of which displaces the previous leftmost point from the frontier.The two plots in the bottom row of Fig. 2 illustrate the influence of the resource availability: Compared to the first plot in the upper row, 10/6/[0.1, 1.0]/11, we reduce here the availability a1 from 6 to 5 (left plot) and increase it to 7 (right plot). It can be seen that the shape of the frontier remains roughly similar, but of course the reduction of a1 tends to increase the makespan, whereas the enlargement of a1 tends to decrease it.Now we used the following parameter values for the instance generation: nCh= 2, nEx= 2, nChEx= 2,[D̲M,D¯M]=[10,20],[D̲L,D¯L]=[0,30],[C̲M,C¯M]=[5,20],[C̲L,C¯L]=[0,30],[R̲,R¯]=[1,5],κ1 = 2, κ2 = 0.5. For a1 and for the interval [a, b] of the weights, the same choices were tested as in the case of the smaller instances. The average computation time per test instance increased now to 2.6 hours.The obtained results were qualitatively similar to those of the smaller instances. Fig. 3shows two Pareto frontiers as an example. As it can be seen, the frontiers contain few elements, but the covered ranges of the objective functions are large enough for making the differences of practical relevance. Again, the reduction of the interval [a, b] extends the Pareto frontier, in this case now by adding a new point at the right.Admittedly, instances with n = 16 activities are still rather small. However, let us mention that in the area of stochastic real-time systems, to which the approach presented here is applicable in principle, instances of this size can already be realistic. (For related problems in this area, cf. Manolache, Eles, and Peng, 2001; Mills and Anderson, 2011; Tidwell, Bass, Lasker, Wylde, Gill, and Smart, 2011.) It should be emphasized that although the computation of the optimal ES policy for 16 jobs takes about 2 hours, the execution of the found ES policy only requires milliseconds of computation time and can therefore also be integrated in a real-time system with very restrictive time limits.As mentioned in Remark 1, it is possible that the reference solution is already very good, with the consequence that a too small Pareto frontier results. (In the extreme case, the Pareto frontier may even degenerate to the reference solution itself.) In the literature on stochastic dominance constraints, a conceptually simple way to overcome this problem has been proposed, namely to decrease the quality of the reference solution in a controlled way in order to increase the number of efficient solutions (see, e.g., Armbruster and Luedtke, 2011). In the method proposed here, this can be done by using a multiplicative tolerance level, applied to the reference solution. For this purpose, we replace in (7) the outcome vector Y of the reference solution (with components negative makespan and negative cost) by the vector Γ · Y where Γ > 1. An example of the effect is shown in Fig. 4, which is based on the same test instance as Fig. 3, left plot: We see that by allowing a 5 percent tolerance (Γ = 1.05), the cardinality of Pareto frontier increases from 4 to 6, and by a 20 percent tolerance (Γ = 1.2), it further increases to 8.As seen from the computation times reported below for n = 16, there is little hope that instance sizes beyond n = 20 can be solved exactly. Heuristics or metaheuristics will be needed to cope with medium-sized or large instances. A development and comprehensive test of a bi-objective metaheuristic for the problem under consideration is outside the scope of this paper. However, to illustrate the applicability of the proposed approach also for somewhat larger instances, the presented algorithms have been modified by solving problems (17) and (18) and (30) and (31) only heuristically. For this purpose, a Variable Neighborhood Search (VNS) algorithm has been implemented. (We omit here the implementation details for the sake of brevity, mentioning only that for the “move-or-not” decision, a Simulated-Annealing-based acceptance rule has been used, as in many modern VNS implementations.) Evidently, for those mode combinations m for which a feasible sufficient selection can be found in this way, the solution value produced by the heuristic modification of Algorithm 3 yields an upper bound for the true solution value of (13) and (15).To evaluate the quality of the solution, we compute also a lower bound. It can be shown by a short derivation that each lower bound on the solution value of (30) and (31), divided by ε, yields also a lower bound for (13)–(15). A lower bound of the former kind, however, can easily be obtained by terminating the branch-and-bound procedure for the solution of (30) and (31) already after a certain number of iterations. The resulting gap to the upper bound produced by the VNS measures the solution quality achieved for the current mode combination m. Let us emphasize, however, that even if the gap vanishes, we have no guarantee that the current solution is Pareto-efficient: Since also Algorithm 2 is solved now only heuristically, it could happen that some mode combination is not recognized as possessing a feasible solution, and such a “lost” solution could dominate the current solution. Therefore, the computed gaps provide only a partial assessment of the quality of the Pareto frontier; in a strict sense, they only apply to each cost level (defined by a mode combination) in separation from the others.The parameters of the VNS procedure were tuned in such a way that the computation times for the test instances of size n = 16 were in the same order of magnitude as those required for the exact solution. Nevertheless, it turned out that already for these generous computation times, the heuristic modification did usually not provide the exact Pareto frontier. In the instance corresponding to the left plot of Fig. 3, all four mode combinations containing Pareto optima were found, but in two of the four cases, the corresponding sufficient selections were slightly suboptimal (makespan gaps of 1.18 percent and 0.80 percent, respectively). In the instance corresponding to the right plot, four of the five Pareto optima were reproduced exactly, but one was missed.Now, two larger test instances where generated: First, the graph of Fig. 1, serving as the precedence graph for the n = 10 instances, was concatenated with the precedence graph for the n = 16 instances taken from the PSPLIB test case by turning the terminal node of the first graph into a non-dummy node and appending the second graph to it. The produced graph for n = 27 activities was extended to a problem instance by the test instance generator described in the beginning of this section, using[R̲,R¯]=[1,7],a1 = 7, [a, b] = [0.5, 0.7] and all other parameter values as for the n = 16 instances. We call this instance n27. Second, the last MRCPSP test case of size n = 30 contained in the PSPLIB was taken and extended to a test instance n30 for our problem by the same generation procedure (with the same parameters) as forn27.The Pareto frontiers produced by the heuristic algorithm for n27 and n30 are shown in Tables 1 and 2 (Appendix B), respectively. It can be seen that for n27, very small gaps (hardly exceeding 1 percent) are obtained. For n30, the gaps are considerably larger (around 30 percent), which is probably due to the much higher degree of parallelism in the precedence graph of n30 compared to n27. However, it is important to note that the large gaps for n30 do not necessarily mean that the produced heuristic solutions are poor. There are indications for the conjecture that the computed lower bounds are rather weak in this case, such that the true optimum is nearer to the upper than to the lower bound. In this context, it is also interesting to compare the dominance-constrained problem with its relaxation obtained by dropping the stochastic dominance constraints. For n30, the gap between the (found) expected makespan of a proposed-efficient solution of the dominance-constrained problem and the (found) expected makespan after relaxing is only around 4 percent in the average. On the other hand, the lower bound obtained for the relaxed problem is usually also almost 30 percent below the found solution value. This suggests that the solution quality achieved by the presented approach is not essentially worse than that achieved by heuristic solutions of the simpler expected makespan minimization problem.

@&#CONCLUSIONS@&#
Real-life project scheduling is a complex process that can often not be adequately represented by standard models from the project scheduling literature. One of the drawbacks can be that these models typically do not take uncertainty and risk aversion, multiple available execution modes, and multiple objectives simultaneously into account. The present paper provides a first model integrating all these features, as well as an exact solution technique for the determination of the Pareto frontier. The approach relies on optimization under multivariate stochastic dominance constraints and provides also a prototype for the application of this method in connection with Pareto analysis. A branch-and-bound technique for the optimization of early-start policies developed in the stochastic project scheduling literature has been used as an essential solution component. Although the instances that could be solved to optimality are comparably small, they show the principal viability of the approach.The next natural step of research will be the development of heuristic solution techniques able to cope with large problem instances. Multiobjective evolutionary algorithms such as the NSGA-II, combined with mathematical programming routines in a “matheuristic” fashion, are obvious candidates for solution approaches of this kind. In this context, the solution method proposed in this paper will be valuable insofar as it can provide, for comparison purposes, a benchmark of instances whose exact solutions are known. Another topic future research should address is the situation where instead of early-start policies, other classes of stochastic scheduling policies such as activity-based priority policies, resource-based priority policies or preprocessor policies are used. Furthermore, as an alternative to the optimization under stochastic dominance constraints, also other risk-averse decision making approaches, e.g., the use of the conditional value at risk (CVaR), should be investigated.Proof of Proposition 1First we show that the algorithm terminates after a finite number of steps. Letp^sdenote the solutionp^of iteration s, and let δsand εsdenote the values of δ and ε as determined in iteration s, respectively. For abbreviation, setΦw,ν(p)=[∑μ=1N(αν+wβν+gμ(p,m)+w(cμ)′m)+−∑μ=1N(αν+wβν−αμ−wβμ)+]+.If the algorithm does not stop in iteration s, then δs, wsand νsare defined, andΦws,νs(p^s)=(δs)+>0. Moreover, the solutionp^scannot solve (30) and (31) in any later iteration s′ > s. This is seen as follows: By the assumption that (16) holds, there is a feasible solution p* withmax(w,ν)∈WsΦw,ν(p*)=0for all s. For s′ > s, the objective value of p* in (30) becomesϵs′∑μ=1Ngμ(p*,m)+max(w,ν)∈Ws′Φw,ν(p*)≤ϵs+1Tm<δsin view of the update equation of the ε values. On the other hand, recalling that W0 ⊆ W1 ⊆ … , one obtainsϵs′∑μ=1Ngμ(p^s,m)+max(w,ν)∈Ws′Φw,ν(p^s)≥max(w,ν)∈Ws+1Φw,ν(p^s)≥Φws,νs(p^s)≥δs,and thereforep^scannot be optimal in iteration s′. We conclude that the solutionsp^s(s = 0, 1, …) are pairwise different. Therefore, since allp^sare contained in Πmand Πmis finite, the algorithm must terminate after a finite number of iterations.For the solutionp^s*obtained in the last iteration s*, solving (19)–(22) in Step 3 of Algorithm 3 does not find a pair (w, ν) disproving the claim that(p^s*,m)stochastically dominates (p0, m0), sop^s*is feasible for (13)–(15) (cf. the comments to Step 3 of Algorithm 2). In particular,max{Φw,ν(p^s*)|a≤w≤b,ν=1,…,N}=0,and hence the “max” term in (30) vanishes. For any other solution p′ that is feasible w.r.t. (13)–(15), this term vanishes as well. So the assumption that∑μ=1Ngμ(p′,m)<∑μ=1Ngμ(p^s*,m)would contradict the optimality ofp^s*for (30) in iteration s*. This shows the optimality ofp^s*for (13).□By definition, the stochastic dominance condition in the proposition is equivalent toF1(p,m)+wF2(m)⪰(2)F1(p0,m0)+wF2(m0)∀w∈[a,b].Since second-order stochastic dominance implies superiority w.r.t. the expected values, it follows thatE[F1(p,m)]+wE[F2(m)]≥E[F1(p0,m0)]+wE[F2(m0)]∀w∈[a,b].SubstitutionE[F1(p,m)]=−g¯(p,m)andE[F2(m)]=−c¯′mand division by w yields (32).As to (33), note thatg¯(p,m)≥g¯(∅,m)because of ∅ ⊆ p. Therefore, (32) givesc′m≤Cw−(1/w)g¯(∅,m),hence (33) follows by insertion.□