@&#MAIN-TITLE@&#
An approach for prevention of privacy breach and information leakage in sensitive data mining

@&#HIGHLIGHTS@&#
It prevents homogeneity, skewness, similarity and background knowledge attacks.The privacy is ensured while publishing sensitive data.Only fewer partitioning need to be done for a stronger privacy requirement.It gives better efficiency over the previous approaches.

@&#KEYPHRASES@&#
Anonymization,Data mining,Privacy,Privacy preserving,Privacy preserving techniques,Sensitive data publishing,

@&#ABSTRACT@&#
Government agencies and many non-governmental organizations often need to publish sensitive data that contain information about individuals. The sensitive data or private data is an important source of information for the agencies like government and non-governmental organization for research and allocation of public funds, medical research and trend analysis. The important problem here is publishing data without revealing the sensitive information of individuals. This sensitive or private information of any individual is essential to several data repositories like medical data, census data, voter registration data, social network data and customer data. In this paper a personalized anonymization approach is proposed which preserves the privacy while the sensitive data is published. The main contributions of this paper are three folds: (i) the definition of the data collection and publication process, (ii) the privacy framework model and (iii) personalized anonymization approach. The experimental analysis is presented at the end; it shows this approach performs better over the distinct l-diversity measure, probabilistic l-diversity measure and k-anonymity with t-closeness measure.

@&#INTRODUCTION@&#
The data collected by public organizations and private organizations are increasing every day and stored in electronic repository. The data being collected includes private or sensitive data. More and more data mining techniques are becoming now a days and this can be used for assisting decision making process. The data mining techniques are used to extract the hidden knowledge from huge data collections in the form of trends, models and patterns. While doing the data mining process the personal data of any individual need to be protected from privacy concerns [1–4]. Privacy means the individual’s personal information known as sensitive data has to be protected while publishing the data. In Schoeman [5] point of view three possible privacy definitions are proposed.•Privacy is the right of a person. The person can decide which personal information to be communicated or published to others.Privacy is restricted access to an individual and to any or all the features associated with the person.Privacy is that the management over access to data or information relating to oneself.In the above definitions the knowledge inferred is the Controlled Information Release, means that the personal data need to be hide while publishing for research and other purposes [6]. The Microdata or sensitive data is the individual’s private data like salary, age, medical information, etc. A Microdata set can be viewed as a file with n records, where each and every record contains m attributes [7]. The attributes can be classified as follows.The attribute that unambiguously identify the individual is the identifier. Examples are name, social security number, passport number, etc.The attributes that identify the individual with some degree of ambiguity is the quasi-identifier. Examples are age, gender, address, telephone number, etc.The attributes that contains the sensitive information of an individual is the confidential outcome attributes. Examples are salary, health condition, religion, etc.The attributes that do not fall in any categories above are the non confidential outcome attributes.The paper is organized as follows: The definition of the data collection and publication process is given in Section 2. In Section 3, the privacy framework model is described and the personalized anonymization approach is discussed. Finally in Section 4 the experimental analysis is presented with example. The efficiency factor is compared with distinct l-diversity measure, probabilistic l-diversity measure and k-anonymity with t-closeness measure.The data collection and data publishing phases are described in Fig. 1. Here, in the data collection phase, the data are collected by the data publisher from the record owners. In the data publishing phase, the collected data are released by the data publisher to a researcher or to the public or to the data miner, called the data recipient. For example, a hospital collects the data from their patients and publishes the collected records to the external agency or medical centre for further research. In Fig. 1 John, Peter, Raj, Mary and Christy are the patients, who are the data owners. The hospital is the data publisher who collects the data from the data owners (patients like John, Peter) and publishes to the data recipient (medical centre). The data receiver can now apply the data mining algorithms or techniques on the received data to get the knowledge or patterns in order to do further actions.The problem here is the data publisher (medical centre, in this example) can have the medical data of the patients which contains the sensitive data. This sensitive data need to be protected to preserve the privacy of the patient.Numerous researches have been done to address the problems in privacy preservation data mining. In general, five phases of several approaches can be classified [8,9]. First, based on the distribution of data, it can be categorized as centralized or distributed data [10]. In a centralized database environment, all the data are stored in a single database; whereas, in a distributed database environment, data are stored in different databases. The second phase is about the modifications that are applied on data. The approaches like perturbation, swapping, aggregation, sampling, suppression, noise addition and more are the data modification approaches. The third phase is about the data mining algorithms [11]. This phase deals with the data mining algorithms such as decision tree, clustering, rough sets, association rule, and regression [12,13]. The fourth phase is concerned with data hiding; whether it is the raw or aggregate data that need to be hid. Data hiding refers to the cases where the sensitive data from original database like identity, name, and address that can be linked, directly or indirectly, to an individual person are hided [14–16]. The last phase is the privacy preservation techniques.The techniques like generalization, data distortion, data sanitation, blocking, cryptographic [11], and anonymization [17,18], are the some of the privacy preserving techniques used to ensure the privacy of individuals while mining the sensitive data. The five phases of approaches in privacy preserving data mining are shown in Fig. 2which is called privacy framework.The k-anonymity [19] is proposed as privacy preserving data mining technique for protecting sensitive information leakage or publishing of sensitive information. In the literature it is observed that the k-anonymity technique protects against identity disclosure, but in case of attribute disclosure it does not afford adequate protection. Like k-anonymity technique many other privacy preserving data mining techniques are also proposed, few are Data Perturbation Approach, Blocking Based Technique, Cryptographic Technique, Condensation Approach, Randomized Response Technique, and Hybrid Technique.From study [20–23] it is understand that the existing privacy preserving data mining techniques do not protect the following privacy issues:i.Homogeneity attack.Skewness attack.Similarity attack.Background knowledge attack.To address these privacy issues a personalized anonymization approach is proposed. This approach consists of three phases:(1)Choosing a dimension on which to partition.Choosing a value to split.Checking if the partitioning violates the privacy requirement.(Top-Down Greedy algorithm for strict multidimensional partitioning)Anonymize (partition)if (no allowable multidimensional cut for partition)return φ : partition→summaryelsedim←choose dimension()fs←frequency_set(partition, dim)splitVal←find_median(fs)lhs←{t Є partition : t.dim⩽splitV al}rhs←{t Є partition : t.dim>splitV al}return Anonymize(rhs)UAnonymize(lhs)end allLet P be a set of tuplesP is partitioned into r partitions{P1,P2,…,Pr}for every Piif Pi(1⩽i⩽r)find = falsefor every Q Є Parent(P) and |Q|⩾nif D[Pi,Q]⩽tfind = trueif find==falsereturn falsereturn trueend allIn this approach the n and k parameters plays the crucial role. The depth of observer’s background knowledge is defined by n. Smaller the n means the observer can know the smaller group of records sensitive information. The amount of sensitive information can get by observer from the released data is defined by the parameter t. Smaller the t means a stronger privacy requirement. Therefore the privacy and utility level is affected by choosing parameters n and t. Choosing smaller t and larger n attains more privacy and less utility

@&#CONCLUSIONS@&#
