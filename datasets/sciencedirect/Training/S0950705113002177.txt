@&#MAIN-TITLE@&#
Solving high dimensional bilevel multiobjective programming problem using a hybrid particle swarm optimization algorithm with crossover operator

@&#HIGHLIGHTS@&#
A crossover operator can enhance the information exchange between particles.The algorithm directly simulates the decision process of bilevel programming.The proposed algorithm is a feasible and efficient algorithm for solving HDBLMPPs.

@&#KEYPHRASES@&#
High dimensional bilevel multiobjective programming,Particle swarm optimization,Pareto optimal solution,Crossover operator,Elite strategy,

@&#ABSTRACT@&#
In this paper, a hybrid particle swarm optimization with crossover operator (denoted as C-PSO) is proposed, in which a crossover operator is adopted for enhancing the information exchange between particles to prevent premature convergence of the swarm. The C-PSO algorithm is employed for solving high dimensional bilevel multiobjective programming problem (HDBLMPP) in this study, which performs better than the existing method with respect to the generational distance and has almost the same performance with respect to the spacing. Finally, we use four test problems and a practical application to measure and evaluate the proposed algorithm. Our results indicate that the proposed algorithm is highly competitive with respect to the algorithm representative of the state-of-the-art in high dimensional bilevel multiobjective optimization.

@&#INTRODUCTION@&#
Bilevel programming problem (BLPP) arises in a wide variety of scientific and engineering applications including optimal control, process optimization, game-playing strategy development, transportation problem, and so on. Thus the BLPP has been developed and researched by many scholars. The reviews, monographs and surveys on the BLPP can refer to [1–11]. Moreover, the evolutionary algorithms (EA) have been employed to address BLPP in papers [12–16].For the multiobjective characteristics widely existing in the BLPP, the bilevel multiobjective programming problem (BLMPP) has attracted many researchers to study it. For example, Shi and Xia [17,18], Abo-Sinna and Baky [19], Nishizaki and Sakawa [20] presented an interactive algorithm for BLMPP. Gao et al. [21] proposed aλ-cut and goal-programming-based algorithm to solve fuzzy-linear multiple-objective bilevel decision problems. Eichfelder [22] presented a method for solving nonlinear bilevel multiobjective optimization problems with coupled upper level constraints. Thereafter, Eichfelder [23] developed a numerical method for solving nonlinear non-convex bilevel multiobjective optimization problems. In recent years, the metaheuristic has attracted considerable attention as an alternative method for BLMPP. For example, Deb and Sinha [24–26], as well as Sinha and Deb [27] discussed BLMPP based on evolutionary multiobjective optimization principles. Based on those studies, Deb and Sinha [28] proposed a viable and hybrid evolutionary-local-search based algorithm, and presented challenging test problems. Sinha [29] presented a progressively interactive evolutionary multiobjective optimization method for BLMPP.Particle swarm optimization (PSO) is a relatively novel heuristic algorithm inspired by the choreography of a bird flock, which has been found to be quite successful in a wide variety of optimization tasks. Due to its high speed of convergence and relative simplicity, the PSO algorithm has been employed by many researchers for solving BLPPs. For example, Li et al. [30] proposed a hierarchical PSO for solving BLPP. Kuo and Huang [31] applied the PSO algorithm for solving bilevel linear programming problem. Gao et al. [32] presented a method to solve bilevel pricing problems in supply chains using PSO. Zhang et al. [33] presented a new strategic bidding optimization technique which applies bilevel programming and swarm intelligence. Recently, Zhang et al. [34] investigated the BLMPP using an improved PSO. However, it is worth noting that the papers mentioned above are either for bilevel single objective problems or for low dimensional BLMPPs. The high dimensional BLMPP has seldom been studied using PSO so far. There are probably two reasons for this situation. One reason is that the added complexities associated with solving each level, and the other reason is that the PSO confront the problem of premature convergence.In this paper, a C-PSO algorithm is proposed, in which a crossover operator is adopted for enhancing the information exchange between particles to prevent premature convergence of the swarm. The C-PSO algorithm is employed for solving the HDBLMPP in this study, which has not been reported in other literatures. For such problems, the proposed algorithm directly simulates the decision process of bilevel programming, which is different from most traditional algorithms designed for specific versions or based on specific assumptions. The HDBLMPP is transformed to solve high dimensional multiobjective optimization problems in the upper level and the lower level interactively by the C-PSO. For one time of iteration, a set of approximate Pareto optimal solutions for HDBLMPP is obtained using the elite strategy. This interactive procedure is repeated until the accurate Pareto optimal solutions of the original problem are found. The rest of the paper is organized as follows. In Section 2, the problem formulation is provided. The proposed algorithm for solving high dimensional bilevel multiobjective problem is presented in Section 3. In Section 4, some numerical examples are given to demonstrate the feasibility and efficiency of the proposed algorithm. The C-PSO algorithm is applied for solving a practical problem in section 5, while the conclusion is reached in Section 6.Letx∈Rn1,y∈Rn2,F:Rn1×Rn2→Rm1,f:Rn1×Rn2→Rm2,G:Rn1×Rn2→Rp,g:Rn1×Rn2→Rq.The general model of the HDBLMPP can be written as follows:(1)minxF(x,y)s.t.G(x,y)⩾0,minyf(x,y)s.t.g(x,y)⩾0,where F(x,y) and f(x,y) are the upper level and the lower level objective functions, respectively. G(x,y) and g(x,y) denote the upper level and the lower level constraints, respectively. In this study, the high dimensional BLMPP is considered, namely that the n1>3 or n2>3. LetS={(x,y)|G(x,y)⩾0,g(x,y)⩾0},X={x|∃y,G(x,y)⩾0,g(x,y)⩾0},S(x)={y|g(x,y)⩾0}, and for the fixed x∊X, letS¯(X)denote the weak efficiency set of solutions to the lower level problem, the feasible solution set of problem (1) is denoted as:IR={(x,y)|(x,y)∈S,y∈S¯(X)}.Definition 2.1For a fixed x∊X, if y is a Pareto optimal solution to the lower level problem, then (x,y) is a feasible solution to the problem (1).If (x∗,y∗) is a feasible solution to the problem (1), and there are no (x,y)∊IR, such that F(x,y)≺F(x∗,y∗), then (x∗,y∗) is a Pareto optimal solution to the problem (1), where “≺” denotes Pareto preference.For problem (1), it is noted that a solution (x∗,y∗) is feasible for the upper level problem if and only if y∗ is an optimal solution for the lower level problem with x=x∗. In practice, we often make the approximate Pareto optimal solutions of the lower level problem as the optimal response feed back to the upper level problem, and this point of view is accepted usually. Based on this fact, the PSO algorithm may have a great potential for solving BLMPP, and it has been proved that the PSO can be as a new way for solving BLMPP by Zhang et al. [34]. In the following, the algorithm based on C-PSO is presented for solving HDBLMPP.The PSO algorithm is a member of the wide category of swarm intelligence methods for solving global optimization problems. PSO can be easily implemented and it is computationally inexpensive, it has been found to be quite successful in a wide variety of optimization problems [35–41]. Some improved PSO algorithms can refer to [42–49]. From these studies, it can be seen that almost all the algorithms they used are the improved versions of PSO. The main reason for developing these improved versions of PSO is that the premature convergence in the PSO is inevitable, particularly for the problems with high dimensionality. Usually, the original PSO create a new solution using its past solution, its previous best solution and the global best solution. The only information it borrows from the other particles is the global best solution. In C-PSO, the crossover operator of the real-coded genetic algorithm is implemented on swarm members by borrowing the concept of linear combination of two vectors, one vector is the swarm member and the other vector is selected randomly from elite set (see Algorithm: step 3). Note that, the crossover probability is 100% in this study. The crossover operator can improve the information exchange between particles and prevent the premature convergence of swarm. For the ith particle at iteration k, the C-PSO algorithm can be described in the following:Suppose that the search space is D- dimensional, the velocity and position are represented asvik=(vi1k,vi2k,⋯,viDk)andxik=(xi1k,xi2k,⋯,xiDk), respectively. Its personal best position is presented aspik=(pi1k,pi2k,⋯,piDk)and the global best position is noted aspgk=(pg1k,pg2k,⋯,pgDk). At each step, the particle is updated according to the following equations:(2)xik¯=pi*(xik)+(1-pi)*(aik)(3)vik+1=ω*vik+c1*ξ*(pik-xik¯)+c2*η*(pgk-xik¯)(4)xik+1=xik+vik+1where xidenotes the ith particle’s position. ξ, η and piare random number distributed uniformly on (0,1) respectively. ω, c1 and c2 are constants. aiis selected randomly from Ai(Aiis the elite set which is introduced in following part, see Algorithm: step 3).The process of the proposed algorithm for solving HDBLMPP is an interactive co-evolutionary process. We first initialize population, and then solve high dimensional multiobjective optimization problems in the upper level and the lower level interactively using C-PSO algorithm. For one time of iteration, a set of approximate Pareto optimal solutions for problem (1) is obtained by the elite strategy which was adopted in Deb et al. [50]. This interactive procedure is repeated until the accurate Pareto optimal solutions of problem (1) are found. The details of the proposed algorithm are given as follows:AlgorithmStep 1. Initializing.Step 1.1. Initialize the population P0 with Nuparticles which is composed by ns=Nu/Nlsub-swarms of size Nleach. For the kth (k=1,2,⋯,ns) sub-swarm, the jth particle’s position is presented as: zj=(xj,yj) (j=1,2,⋯,nl) and the corresponding velocity is presented as:vj=(vxj,vyj)(j=1,2,⋯,nl), zjand vjare sampled randomly in the feasible space, respectively.Step 1.2. Initialize the external loop counter t:=0.Step 2. For the kth sub-swarm, (k=1,2,⋯,ns), each particle is assigned a non-domination rank NDland a crowding value CDlin f space. Then, all resulting sub-swarms are combined into one population which is named as the Pt. Afterwards, each particle is assigned a non-domination rank NDuand a crowding value CDuin F space.Step 3. The non-domination particles assigned both NDu=1 and NDl=1 from Ptare saved in the elite set At.Step 4. For the k-th sub-swarm, (k=1,2,⋯,ns), update the lower level decision variables.Step 4.1. Initialize the lower level loop counter tl:=0.Step 4.2. Update the jth (j=1,2,⋯,Nl) particle’s position with the fixed xjand the fixedvyjaccording to the Eqs. (2)–(4).Step 4.3. tl:=tl+1.Step 4.4. If tl⩾Tl,go to step 4.5. Otherwise, go to step 4.2.Step 4.5. Each particle of the ith sub-swarm is reassigned a non-domination rank NDland a crowding value CDlin f space. Then, all resulting sub-swarms are combined into one population which is renamed as the Qt. Afterwards, each particle is reassigned a non-domination rank NDuand a crowding value CDuin F space.Step 5. Combined population Ptand Qtto form Rt. The combined population Rtis reassigned a non-domination rank NDu, and the particles within an identical non-domination rank are assigned a crowding distance value CDuin the F space.Step 6. Choose half particles from Rt. The particles of rank NDu=1 are considered first. From the particles of rank NDu=1, the particles with NDl=1 are noted one by one in the order of reducing crowding distance CDu, for each such particle the corresponding sub-swarm from its source population (either Ptor Qt) is copied in an intermediate population St. If a sub-swarm is already copied in Stand a future particle from the same sub-swarm is found to have NDu=NDl=1,the sub-swarm is not copied again. When all particles of NDu=1 are considered, a similar consideration is continued with NDu=2 and so on till exactly nssub-swarms are copied in St.Step 7. Update the elite set At. The non-domination particles assigned both NDu=1 and NDl=1 from Stare saved in the elite set At.Step 8. Update the upper level decision variables in St.Step 8.1. Initiate the upper level loop counter tu:=0.Step 8.2. Update the ith (i=1,2,⋯,Nu) particle’s position with the fixed yiand the fixedvxiaccording to the Eqs. (2)–(4).Step 8.3. tu:=tu+1.Step 8.4. If tu⩾Tu,go to step 8.5. Otherwise, go to step 8.2.Step 8.5. Every member is then assigned a non-domination rank NDuand a crowding distance value CDuin F space.Step 9. t:=t+1.Step 10. If t⩾T, output the elite set At. Otherwise, go to step 2.In step 4 and step 8, the global best position is chosen at random from the elite set At. The criterion of personal best position choice is that, if the current position is dominated by the previous position, then the previous position is kept; otherwise, the current position replaces the previous one; if neither of them is dominated by the other, then we select one of them randomly. A relatively simple scheme is used to handle constraints. Whenever two individuals are compared, their constraints are checked. If both are feasible, non-domination sorting technology is directly applied to decide which one is selected. If one is feasible and the other is infeasible, the feasible dominates. If both are infeasible, then the one with the lowest amount of constraint violation dominates the other. Notations used in the proposed algorithm are detailed in Table 1.In this section, four examples will be considered to illustrate the feasibility of the proposed algorithm for problem (1). In order to evaluate the closeness between the obtained Pareto optimal front and the theoretical Pareto optimal front, as well as the diversity of the obtained Pareto optimal solutions along the theoretical Pareto optimal front, we adopted the following evaluation metrics:This metric used by Deb et al. [50] is employed in this paper as a way of evaluating the closeness between the obtained Pareto optimal front and the theoretical Pareto optimal front. The GD metric denotes the average distance between the obtained Pareto optimal front and the theoretical Pareto optimal front:(5)GD=∑i=1ndi2nwhere n is the number of the obtained Pareto optimal solutions by the proposed algorithm and diis the Euclidean distance between each obtained Pareto optimal solution and the nearest member of the theoretical Pareto optimal set.This metric is used to evaluate the diversity of the obtained Pareto optimal solutions by comparing the uniform distribution and the deviation of solutions as described by Deb et al. [50]:(6)SP=∑m=1Mdme+∑i=1n(d¯-di)2∑m=1Mdme+nd¯wheredi=minjF1i(x,y)-F1j(x,y)+F2i(x,y)-F2j(x,y),i,j=1,2,⋯,n,d¯is the mean of all di,dmeis the Euclidean distance between the extreme solutions in obtained Pareto optimal solution set and the theoretical Pareto optimal solution set on the mth objective, M is the number of the upper level objective function, n is the number of the obtained solutions by the proposed algorithm.The C-PSO parameters are set as follows: the ω=0.7298 and c1=c2=1.49618. All results presented in this paper have been obtained on a personal computer (CPU: AMD 2.80GHz; RAM: 3.25GB) using a c# implementation of the proposed algorithm.Example 1Example 1 is taken from [28]. Here x∊R10, y∊R10. In this example, the population size and iteration times are set as follows: Nu=400, Tu=50, Nl=40, Tl=20, and T=60.For Example 1, the lower level problem of this example has multimodalities, thereby making the lower level problem difficult in finding the upper level Pareto optimal front. Fig. 1shows the graphical results produced by the method in [28] and our C-PSO in the first test problem. Table 2shows the comparison of results between the two algorithms considering the metrics previously described. It can be seen that the performance of C-PSO is better with respect to the generational distance, although it places slightly below the method in [28] with respect to spacing. By looking at the Pareto fronts of this test problem, some non-dominated vectors produced by the method in [28] are not part of the true Pareto front of the problem, however, the C-PSO is able to cover the full Pareto front.Example 2Example 2 is taken from [28]. Here x∊R10, y∊R10. In this example, the population size and iteration times are set as follows: Nu=400, Tu=50, Nl=40, Tl=20, and T=80.For the Example 2, the upper level problem has multimodalities, thereby causing an algorithm difficulty in finding the upper level Pareto optimal front. Fig. 2shows the graphical results produced by the method in [28] and our C-PSO in the second test problem. Table 2 shows the comparison of results between the two algorithms considering the metrics previously described. It can be seen that the performance of our C-PSO is better than the method in [28] with respect to the generational distance. On the other hand, our C-PSO and the method in [28] almost have the same performance with respect to the spacing. From the Fig. 2, it obvious that the obtained Pareto front produced by C-PSO is very close to the theoretical Pareto optimal front and C-PSO is able to obtain a good distribution of solutions on the entire range of the theoretical Pareto optimal front. Moreover, all corresponding lower level Pareto optimal fronts are given.Example 3Example 3 is taken from [28]. Here x∊R10, y∊R10. In this example, the population size and iteration times are set as follows: Nu=400, Tu=50, Nl=40, Tl=20, and T=60.Fig. 3shows the graphical results produced by the method in [28] and our C-PSO in the third test problem. Table 2 shows the comparison of results between the two algorithms considering the metrics previously described. It can be seen that the performance of our C-PSO is better than the method in [28] with respect to the generational distance and the spacing. Obviously, some non-dominated vectors produced by the method in [28] are relatively sparse in some regions of the true Pareto optimal front of this problem compared with our C-PSO, and some non-dominated vectors produced by the method in [28] are slightly off the true Pareto front of the problem. Graphically, it can be seen that the C-PSO is able to cover the entire Pareto front of this problem. It is also interesting to note that the Pareto optimal fronts for both the lower and upper level lie on constraint boundaries and every lower level Pareto optimal front has an unequal contribution to the upper level Pareto optimal front.Example 4Example 4 is taken from [28]. Here x∊R1, y∊R9. In this example, the population size and iteration times are set as follows: Nu=400, Tu=50, Nl=40, Tl=20, and T=40.Fig. 4shows the graphical results produced by the method in [28] and our C-PSO in the fourth test problem. Table 2 shows the comparison of results between the two algorithms considering the metrics previously described. It can be seen that the performance of our C-PSO is better than the method in [28] with respect to the generational distance. With respect to the spacing, our C-PSO and the method in [28] almost have the same performance. By looking at the Pareto fronts of this test problem, fewer non-dominated vectors produced by the method in [28] are slightly off the true Pareto front of the problem. For our C-PSO, it can cover the entire Pareto front of this problem. Moreover, three obtained lower level Pareto optimal fronts are given when y1=1, y1=1.5 and y1=2. It can be seen that only one Pareto optimal point from each participating lower level problem qualifies to be on the upper level Pareto optimal front.In a company, the CEO’s goal is usually to maximize net profits and quality of products, whereas a branch head’s goal is to maximize its own profit and worker satisfaction. The problem involves uncertainty and is bilevel in nature, as a CEO’s decision must take into account optimal decisions of branch heads. We present a deterministic version of the case study from [51] in Eq. (4). Fig. 5shows the obtained Pareto optimal front of this practical problem by the C-PSO. Note that, Zhang et al. [51] only obtained a single optimal solution x=(146.2955,28.9394) and y=(0,67.9318,0) which lies on the maximum of the F2 using weighted sum method. In contrast, a set of Pareto optimal solutions is obtained by the C-PSO. However, the fact that the single optimal solution in [51] is included in the obtained Pareto optimal solutions illustrates the feasibility of proposed algorithm. In this problem, the population size and iteration times are set as follows: Nu=100, Tu=50, Nl=20, Tl=10, and T=40.maxxF(x,y)=(x1+9x2+10y1+y2+3x3,9x1+2x2+2y1+7y2+4x3)s.t.G1(x,y)=3x1+9x2+9y1+5y2+3y3⩽1039G2(x,y)=-4x1-x2+3y1-3y2+2y3⩽94minyf(x,y)=(4x1+6x2+7y1+4y2+8y3,6x1+4x2+8y1+7y2+4y3)s.t.g1(x,y)=3x1-9x2-9y1-4y2⩽61g2(x,y)=5x1+9x2+10y1-y2-2y3⩽924g3(x,y)=3x1-3x2+y2+5y3⩽420x1,x2,y1,y2,y3⩾0

@&#CONCLUSIONS@&#
