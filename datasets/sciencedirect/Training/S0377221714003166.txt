@&#MAIN-TITLE@&#
A heuristic for BILP problems: The Single Source Capacitated Facility Location Problem

@&#HIGHLIGHTS@&#
We apply the Kernel Search to the Single Source Capacitated Facility Location Problem.We find the optimal solution for 165 out of 170 instances with a proven optimum.We outperform the best heuristics for the SSCFLP available in the literature.We achieve an average gap equal to 0.64% on 100 new very large-scale instances.The heuristic can be easily adapted to any Binary Integer Linear Programming problem.

@&#KEYPHRASES@&#
Single Source Capacitated Facility Location Problems,Binary Integer Linear Programming,Heuristic algorithms,Kernel Search framework,

@&#ABSTRACT@&#
In the Single Source Capacitated Facility Location Problem (SSCFLP) each customer has to be assigned to one facility that supplies its whole demand. The total demand of customers assigned to each facility cannot exceed its capacity. An opening cost is associated with each facility, and is paid if at least one customer is assigned to it. The objective is to minimize the total cost of opening the facilities and supply all the customers. In this paper we extend the Kernel Search heuristic framework to general Binary Integer Linear Programming (BILP) problems, and apply it to the SSCFLP. The heuristic is based on the solution to optimality of a sequence of subproblems, where each subproblem is restricted to a subset of the decision variables. The subsets of decision variables are constructed starting from the optimal values of the linear relaxation. Variants based on variable fixing are proposed to improve the efficiency of the Kernel Search framework. The algorithms are tested on benchmark instances and new very large-scale test problems. Computational results demonstrate the effectiveness of the approach. The Kernel Search algorithm outperforms the best heuristics for the SSCFLP available in the literature. It found the optimal solution for 165 out of the 170 instances with a proven optimum. The error achieved in the remaining instances is negligible. Moreover, it achieved, on 100 new very large-scale instances, an average gap equal to 0.64% computed with respect to a lower bound or the optimum, when available. The variants based on variable fixing improved the efficiency of the algorithm with minor deteriorations of the solution quality.

@&#INTRODUCTION@&#
A Binary Integer Linear Programming (BILP) problem is a linear programming problem where all variables are constrained to take a binary (either 0 or 1) value. In the Single Source Capacitated Facility Location Problem (SSCFLP), a specific BILP problem, we are given a set I of customers. Each customeri∈Ihas a demanddito be served. We are also given a set J of potential locations where one facility could be opened. For the sake of brevity, hereafter we refer to each potential locationj∈Jas facility j. A fixed opening costfjand a capacitysjare associated with each facilityj∈J. Assigning customer i to facility j, i.e. supplying its whole demand from j, costscij. The SSCFLP consists in selecting which facilities to open from set J and how to assign customers in set I to the selected facilities while minimizing the sum of opening and assignment costs. Each customer demand must be fully satisfied and each facility, if opened, cannot supply more than its capacity. The additional requirement that differentiates the SSCFLP from the multi source Capacitated Facility Location Problem (CFLP) is that each customer has to be supplied by exactly one facility, whereas in the CFLP any customer can be supplied by more than one facility. The single source constraint makes the problem much harder to solve (see Klose & Drexl (2005)). Given a set of open facilities, the problem of supplying customers from those facilities in the CFLP is a linear program (specifically, a transportation problem). On the contrary, for a given set of open facilities, the associated assignment problem in the SSCFLP is a particular case of the Generalized Assignment Problem (GAP) which isNP-hard itself (e.g., see Fisher, Jaikumar, & Van Wassenhove (1986)).The single source assumption is a critical issue in several real-life applications. We mention, among others, the problem of finding the location of drilling platforms and the consequent allocation of oil wells to platforms studied in Devine and Lesso (1972), the capacitated concentrator location problem described in Pirkul (1987) and the distribution systems mentioned in Díaz and Fernández (2002).We introduce the following binary variables. Letxij=1ifcustomeriisassignedtofacilityj,0otherwise;andyj=1iffacilityjisopened,0otherwise.Then, the SSCFLP can be stated as the following BILP problemSSCFLP Model(1)minimize∑i∈I∑j∈Jcijxij+∑j∈Jfjyj(2)subject to∑i∈Idixij⩽sjyjj∈J(3)∑j∈Jxij=1i∈I(4)xij⩽yji∈I,j∈J(5)xij∈{0,1}i∈I,j∈J(6)yj∈{0,1}j∈J.Objective function (1) minimizes the total cost given by two components. The first term computes the total cost of assigning the customers to the facilities. The second term is the total cost of opening the facilities. Inequalities (2) establish that the total demand of customers assigned to each facility must not exceed its capacity. Assignment constraints (3), along with (5), ensure that the demand of each customer is supplied by exactly one facility. Constraints (4), that are redundant in (1)–(6), yield a much tighter linear relaxation than the equivalent formulation without constraints (4) (e.g., see Yang, Chu, & Chen (2012)). Constraints (5) and (6) define the decision variables. Finally, without loss of generality, it is assumed thatcij⩾0,i∈I,j∈J;fj⩾0,j∈J;sj>0,j∈J;di⩾0,i∈I, and∑j∈Jsj⩾∑i∈Idi.Facility location problems have received a great deal of attention in the literature as they appear in many different areas. A non-comprehensive list of applications includes distribution, transportation and telecommunication problems. Interested readers are referred to the survey by Klose and Drexl (2005), the book edited by Mirchandani and Francis (1990) and the more recent book edited by Eiselt and Marianov (2011) for an overview on this class of problems.As the SSCFLP belongs to the class ofNP-hard problems (e.g., see Yang et al., 2012), most of the solution approaches appeared in the literature are heuristics. Among them, solution methods based on a Lagrangean relaxation of the SSCFLP play a dominant role. These methods mainly differ from each other in the set of constraints that are relaxed (i.e., the capacity constraints (2), or the assignment constraints (3), or both) and in the way feasible solutions are generated from the solutions of the relaxed problem. For instance, Hindi and Pienkosz (1999) compute a lower bound dualizing constraints (3) in a Lagrangean fashion, and find feasible solutions by means of a procedure that combines a greedy heuristic with a restricted neighborhood search. Also Cortinhal and Captivo (2003) obtain lower bounds dualizing constraints (3) whereas a local search procedure and a tabu search algorithm are proposed to compute upper bounds. Chen and Ting (2008) propose a hybrid algorithm that combines a Lagrangean heuristic with an ant colony system, and also a multiple ant colony system for the SSCFLP. For an overview of Lagrangean relaxation-based techniques for solving facility location problems we refer to Galvão and Marianov (2011), where special emphasis is given to the SSCFLP. Among the other heuristics proposed in the literature, we mention the tabu search heuristic for the SSCFLP introduced by Filho and Galvão (1998), and the heuristics proposed by Delmaire, Díaz, Fernández, and Ortega (1999), namely a reactive GRASP heuristic, a tabu search heuristic, and two different hybrid approaches that combine elements of the GRASP and of the tabu search methodologies. Rönnqvist, Tragantalerngsak, and Holt (1999) consider a repeated matching algorithm which essentially solves a series of matching problems until certain convergence criteria are satisfied. Ahuja, Orlin, Pallottino, Scaparra, and Scutellà (2004) present a Very Large-scale Neighborhood Search algorithm (VLNS) for the SSCFLP, whereas Contreras and Díaz (2008) develop a scatter search algorithm. To the best of our knowledge, the best heuristics are the VLNS developed by Ahuja et al. (2004) and the hybrid algorithm designed by Chen and Ting (2008). In both papers, computational results are reported for instances with up to 100 facilities and 1000 customers.Among the exact methods, we mention the paper by Holmberg, Rönnqvist, and Yuan (1999) who propose an algorithm consisting of a Lagrangean dual heuristic (used to compute a lower bound) coupled with a strong primal heuristic (used to compute an upper bound), within a branch-and-bound framework. Computational results are reported for instances involving up to 30 facilities and 200 customers. Díaz and Fernández (2002) develop an exact algorithm in which a column generation procedure for finding upper and lower bounds for the SSCFLP is incorporated within a branch-and-price framework. They solve instances with up to 30 facilities and 90 customers. To the best of our knowledge, the most recent exact approach proposed in the literature is the cut-and-solve algorithm (see Climer & Zhang, 2006) introduced in Yang et al. (2012). The authors solve to optimality instances with up to 80 facilities and 400 customers.The Kernel Search is a heuristic proposed for the solution of Mixed Integer Linear Programming (MILP) problems with binary variables. The general idea of the heuristic is to identify subsets of the decision variables and solve to optimality, whenever possible, the resulting restricted problems by means of a general-purpose MILP solver used as a black-box. In its original form, the heuristic was successfully applied to the multi-dimensional knapsack problem in Angelelli, Mansini, and Speranza (2010) and to a portfolio selection problem in Angelelli, Mansini, and Speranza (2012). Some improvements were introduced in Guastaroba and Speranza (2012a) where the Kernel Search was applied to the index tracking problem. Some further enhancements were proposed in Guastaroba and Speranza (2012b) where the Kernel Search was applied to the CFLP.The idea of fixing the value for some of the variables inspired several successful algorithms recently proposed for the solution of MILP problems. The so called soft variable fixing mechanism (intuitively, variables to be fixed are not chosen explicitly but selected implicitly adding a linear constraint to the MILP model) leads to the local branching algorithm proposed by Fischetti and Lodi (2003). The Relaxation Induced Neighborhood Search (RINS) introduced by Danna, Rothberg, and Pape (2005) is based on the intuition that, given an incumbent solution, many variables take the same value in the linear relaxation and in the incumbent solution. When performing a tree search, at some nodes of the global branch-and-cut tree the RINS algorithm fixes the variables with the same values in the incumbent and in the current linear relaxation solution (hard variable fixing). Finally, in the variable neighborhood decomposition search proposed by Lazić, Hanafi, Mladenović, and Urošević (2010) the two approaches are combined: hard variable fixing is used in the main scheme, whereas soft variable fixing is adopted in the local search.Contributions of the paper. The Kernel Search framework is applied in Angelelli et al. (2010) to a BILP problem with only one set of binary variables. It was used to solve MILP problems where a continuous variable is associated with each binary variable in Angelelli et al. (2012) and Guastaroba and Speranza (2012a). Guastaroba and Speranza (2012b) extended the heuristic to a MILP problem where a large number of continuous variables are associated with each binary variable.In this paper, we further develop the Kernel Search framework in the following ways. Firstly, we extend the heuristic to a general BILP problem and apply it to the SSCFLP. Secondly, we propose two variants of the standard framework aiming at improving the efficiency of the algorithm. Both variants are based on hard variable fixing. The selection of the variables to be fixed is guided by the information provided by the optimal solution of the linear relaxation. Guastaroba and Speranza (2012a) proposed a refinement procedure that aims at improving the best solution found solving the sequence of restricted problems. The idea of the refinement procedure is to set to 1 some binary variables on the basis of their values in the optimal solutions of the restricted problems, and then solve to optimality the MILP problem restricted to the remaining variables. Different from Guastaroba and Speranza (2012a), the variants proposed in the present paper make use of the information retrieved from the optimal solution of the linear relaxation to fix some binary variables either to 1 or to 0. This allows us to perform variable fixing for all the restricted problems in the sequence.An important contribution of the current paper is to the solution of the SSCFLP. Indeed, extensive computational experiments show that the Kernel Search significantly outperforms the best heuristics for the SSCFLP known in the literature. Optimal solutions to benchmark instances are provided in Holmberg et al. (1999) for 71 instances ranging from 10 to 30 facilities and from 50 to 200 customers. Optimal solutions are also reported in Yang et al. (2012) for 20 instances ranging from 30 to 80 facilities and from 200 to 400 customers. 12 large-scale benchmark instances, taken from the CFLP literature, were first solved in Hindi and Pienkosz (1999) with a heuristic algorithm. These instances comprise 100 facilities and 1000 customers and we solved them to optimality with a general-purpose MILP solver, namely CPLEX. As mentioned above, the most successful heuristics available in the literature are those proposed by Ahuja et al. (2004) and Chen and Ting (2008). Both papers report computational experiments for the 71 instances provided in Holmberg et al. (1999) and the 12 instances considered in Hindi and Pienkosz (1999). The average error with respect to the optimal solution reported in Holmberg et al. (1999) is 0.03% for the best VLNS implemented in Ahuja et al. (2004), whereas the hybrid algorithm designed in Chen and Ting (2008) achieved an average error of 0.02%. On the large-scale instances proposed in Hindi and Pienkosz (1999), the average error for the former two heuristics with respect to the optimal solution, computed with CPLEX, is 0.08% and 0.05%, respectively. The standard Kernel Search solves to optimality almost all the aforementioned benchmark instances within fractions of a second for the small and medium-scale instances, and within few minutes for the larger instances. The error computed for the only two instances that are not solved to optimality is 0.01%. The standard Kernel Search solves very large-scale instances ranging from 300 to 1000 facilities and from 300 to 1000 customers in approximately 1hour of average computing time. Optimal solutions are found with CPLEX for 43 out of the 100 very large-scale instances. To the best of our knowledge, instances of this size have never been tested before for the SSCFLP. The standard Kernel Search solves to optimality 40 out of the latter 43 instances, whereas the average error on the remaining 3 instances is smaller than 0.08%. Computational results show that both the Kernel Search and the variants outperform CPLEX, tested with several different settings, both in terms of solution quality and computing time.Structure of the Paper. In Section 2 the general Kernel Search framework for BILP problems is presented. A detailed description of the Kernel Search implemented for the SSCFLP along with its variants is provided in Section 3. Section 4 is devoted to the computational analysis. Finally, in Section 5 some concluding remarks are drawn.In this section we provide a description of the Kernel Search that can be applied to any BILP problem. We also introduce the basic concepts and definitions that will be used in the rest of the paper.We consider BILP problems with several sets of binary variables (for example,x,yand z) and assume, without loss of generality, that the BILP is a minimization problem. We refer to the BILP problem including all the binary variables as the original problem. We call restricted problem the BILP problem restricted to a subset of the binary variables.We say that a binary variable is promising if it is likely that it takes value 1 in an optimal solution of the original problem. We refer to kernel as a set of promising variables. We distinguish between the kernel of each set of binary variables and the kernel of the original problem. The promising variables belonging to a given set (for example, x) compose its individual kernel. The kernel of the original problem is the union of the individual kernels of all the sets of variables and is referred to as the global kernel. All individual kernels, and therefore the global kernel, vary during the algorithm.At the beginning of the Kernel Search the linear relaxation of the original problem is solved. The promising variables of each set compose its initial individual kernel. The union of the initial individual kernels of all sets of variables form the initial global kernel. All the variables of each set not included in its initial individual kernel are partitioned into ordered groups, called individual buckets.The nodal part of the algorithm is the solution of a sequence of restricted problems. The first BILP problem in the sequence is restricted to the initial global kernel. Then, any subsequent BILP problem is restricted to the current global kernel, given by the union of the current individual kernels of all sets of variables, and one individual bucket for each set of variables. The current individual kernel of a set of variables is the previous current individual kernel from which some variables are dropped – those that are no longer promising – and some are added – those that have become promising.Any feasible solution of a restricted BILP problem in the sequence is a heuristic solution of the original problem and provides an upper bound on its optimal solution that is used as a cut-off value for all the following restricted BILP problems. The Kernel Search stops when a given stopping criterion is met.The general scheme of the Kernel Search for BILP problems is sketched in Algorithm 1.The initial individual kernel may be chosen as the set of variables in the basis of the optimal solution of the linear relaxation. The sequence of buckets may be built by ordering the variables out of the basis using the reduced costs coefficients, from the smallest to the largest. The current individual kernel may be updated as follows. A variable belonging to an individual bucket that takes a positive value in the optimal solution of a restricted BILP problem may be considered to have become promising. Conversely, if a promising variable belonging to the current individual kernel has not taken a positive value in the optimal solution of a certain number of restricted BILP problems, then it may be considered to be no longer promising.Algorithm 1General Scheme of the Kernel Search for BILP problems.1: Solve the linear relaxation.2: For each set of variables, identify the initial individual kernel and the sequence of individual buckets.3: Build the initial global kernel.4: Solve a BILP problem on the initial global kernel.5: Repeat the following until a stopping criterion is met(a)build the current global kernel;(b)solve a BILP problem on the current global kernel plus one individual bucket for each available set of variables;(c)for each set of variables, update its current individual kernel.In this section we describe the standard Kernel Search, and some variants, we implemented for the SSCFLP.We consider the SSCFLP formulation (1)–(6). We denote as BILP(J,I×J) the BILP problem that takes into consideration the whole set of facilities J and, for each facility, the whole set of customers I (i.e., the original problem). We denote as LP(J,I×J) the linear relaxation of BILP(J,I×J), i.e. constraints (5) and (6) are substituted byxij∈[0,1],i∈I,j∈J, and byyj∈[0,1],j∈J, respectively.In the SSCFLP a set of two-index binary variablesxij(assign customers to facilities) is associated with each one-index binary variableyj(open the facility or not). This characteristic has a crucial importance in the design of the Kernel Search for the SSCFLP. Indeed, the (initial and current) individual kernel for set of variables x has to be consistent with the (initial and current) individual kernel for set of variables y. The same reasoning also applies to the individual buckets.We denote asK(y)andK(x)the generic individual kernel for variables y and x, respectively. Each facility inK(y)can serve only a subset of all the customers, andK(x)does not contain any variablexijifyjis not inK(y). We denote as K a generic global kernel. Global kernel K is given by the union of the individual kernelsK(y)andK(x). The first restricted BILP problem solved considers the variables in the initial global kernel only, as detailed later. We denote asK⋃Athe set of variables on which a generic subsequent BILP problem is solved that contains the current global kernel K and a set of additional variables A.In the first phase of the Kernel Search, referred to as the initialization phase, problem LP(J,I×J) is solved. Let (yLP,xLP) denote its optimal solution. If (yLP,xLP) is integer, then it is an optimal solution to the original problem and the Kernel Search stops. Otherwise, the optimal solution of LP(J,I×J) provides a lower bound on the optimal cost and information that can be used to identify the promising variables. The Kernel Search continues sorting all the facilities in J. Even if alternative sorting criteria could be used, our experience showed that the following is the most effective one. Letcˆ(yj)be the reduced cost of variableyjin the optimal solution of LP(J,I×J). The facilities are then sorted in non-increasing order of the total demand they serve in the optimal solution of LP(J,I×J), i.e.∑i∈IdixijLP, and for those facilities not selected in the optimal solution, i.e. all j such thatyjLP=0, in non-decreasing order ofcˆ(yj)values. This sorting criterion aims at creating a list L where the facilities that are most likely chosen in an optimal solution of the original problem are ranked in the first positions, whereas the least likely are in the last positions.Afterwards, for each facility a subset of the customers is selected as follows. Letcˆ(xij)be the reduced cost of variablexijin the optimal solution of LP(J,I×J). The subset of customers associated with facility j is chosen by setting a thresholdγand then selecting all pairs(i,j)such that the reduced costcˆ(xij)does not exceedγ.Subsequently, global kernel K is initialized. SetK(y)initially includes the variables corresponding to the first m facilities in list L, where m is a given parameter. SetK(x)is composed, for each facility belonging toK(y), of the variablesxijassociated with the corresponding subset of customers. The remaining|J|-mfacilities are partitioned into NB sets denoted asB(y)h,h=1,…,NB. Given this partition, a sequence of individual buckets denoted as{B(y)h}h=1,…,NBis created for the vectory. Particularly, we choose a priori parameter lbuck and then create a sequence of disjoint buckets, all with cardinality equal to lbuck except possibly the last one that may contain a smaller number of facilities. The number of buckets generated with this procedure isNB≔|J|-mlbuck. A sequence of NB individual buckets for the vectorx, denoted as{B(x)h}h=1,…,NB, is created similarly to what has been done for the individual kernels. Hence, setB(x)his composed, for each facility belonging toB(y)h, of the variablesxijassociated with the corresponding subset of customers.An example of the initial individual kernels and the sequences of individual buckets for a SSCFLP instance with 5 facilities and 6 customers is shown in Fig. 1. Note that thexijvariables in the gray area are not considered by the Kernel Search.As stopping criterion of the Kernel Search we adopt the maximum number of restricted problems to solve. Hence, we introduce parameterNB‾⩽NBrepresenting the number of buckets to be analyzed by the Kernel Search.Upper boundzHis initialized by solving problem BILP(K) restricted to the variables corresponding to the initial global kernel. Before solving problem BILP(K) it is checked whether each customer in I is linked to at least one facility inK(y). If the check fails, setK(x)is modified by adding, for each facility inK(y), the variablesxijcorresponding to each customer not served by any facility.In the second phase, referred to as the solution phase, a sequence ofNB‾restricted problems is solved. Specifically, at each iteration h, whereh=1,…,NB‾, setK⋃Ais created by adding the variables belonging to the current individual bucketsB(y)handB(x)hto the variables in the current global kernel K. The aforementioned procedure to check that each customer is linked to at least one facility in the restricted problem is run. Then, the restricted BILP(K⋃A) problem is solved after the introduction of two supplementary constraints aiming at reducing computing times. The constraints set a cut-off value to the objective function and constrain the solution of the restricted problem to include at least one facility from the corresponding current individual bucket. In fact, we are interested in those solutions that improve upon the current upper boundzHand include at least one new facility from the current individual bucketB(y)h. If the restricted BILP(K⋃A) problem is feasible, then its optimal solution improves the best found so far. In this case, at least one facility from its current individual bucket is selected in the optimal solution of BILP(K⋃A), i.e. new promising variables have been identified, and the current individual kernelK(y)is modified to include them. The set including these facilities is denoted asB(y)h+. Conversely, if a facility in the current individual kernel has not been selected in the optimal solution of BILP(K⋃A) and also in p of the restricted problems solved since it has been added to the kernel, where p is a given parameter, then that facility is assumed to be no longer promising and is removed from its individual kernel. The set including these facilities is denoted asB(y)h-. Thus, at the end of iteration h the current individual kernelK(y)is given by the individual kernel at the beginning of iteration h plus the facilities inB(y)h+, minus the facilities inB(y)h-. The current individual kernelK(x)is updated similarly. If a new facility is added toK(y), then the corresponding subset of customers is added to the current individual kernelK(x). Conversely, when a facility is removed fromK(y), then the corresponding subset of customers is removed from the current individual kernelK(x). When the last bucket (i.e., bucketNB‾) has been analyzed, the algorithm ends.The Kernel Search fails in two cases. The first case is when no feasible solution for LP(J,I×J) is found. This implies that no feasible solution for the original problem exists either. The second case is when no feasible solution for any restricted BILP problem is found. This means that either no feasible solution for the original problem exists or that the Kernel Search has not been able to find any of them. The latter case might occur when the capacity of the facilities included in each restricted problem is not sufficient to fulfill the demand of all the customers.The efficiency of the Kernel Search can be improved by means of variable fixing. Here, we see the case where some binary variables are fixed to 1. Once LP(J,I×J) is solved, set J is partitioned into two subsetsJ(1)andJ⧹J(1). SetJ(1)contains all the indices of variablesyjthat took value 1 in the optimal solution of LP(J,I×J), whereasJ⧹J(1)contains all the remaining indices. This first variant, denoted in the following as Kernel Search(1), is based on the idea of reducing the number ofyjvariables in all the restricted problems solved by the Kernel Search fixing to 1 those that took value 1 in the optimal solution of the linear relaxation. Hence, the sequence of restricted problems is obtained from (1)–(6) by fixing to 1 eachyjwithj∈J(1).The rest of the algorithm described in the previous section remains unchanged. Note that even ifJ(1)=J, i.e. allyjvariables are fixed, the former problem is stillNP-hard as it reduces to a particular case of the GAP.In the second variant, referred to as Kernel Search(0–1), once LP(J,I×J) is solved, set J is partitioned into three subsets:J(1),J(0)andJ. The indices of variablesyjthat took value 0 in the optimal solution of the linear relaxation compose setJ(0), whereas setJincludes all the indices not included either inJ(1)or inJ(0). In addition to fixing to 1 theyjvariables with indices inJ(1), in the Kernel Search(0–1) theyjvariables with indices in setJ(0)are set to 0. Therefore, the sequence of restricted problems is obtained from (1)–(6) by fixing to 1 eachyjwithj∈J(1), and to 0 eachyjvariable withj∈J(0).Due to constraints (2) in the SSCFLP model, fixing one variableyjto 0 implies a remarkable reduction in the number of binary variables of the optimization model, as the|I|assignment variablesxijassociated with each of those facilities are forced to take value 0. Even ifJ=∅, i.e. allyjvariables are fixed either to 1 or to 0, the former problem remainsNP-hard as it reduces to a particular case of the GAP.This section is devoted to presentation and discussion of the computational experiments. They were conducted on a PC Intel Xeon with 3.33gigahertz 64-bit processor, 12.0gigabyte of RAM and Windows 7 64-bit as Operating System. The algorithms were implemented in Java. The LP and BILP problems were solved with CPLEX 12.2. After preliminary experiments, we set the following CPLEX parameters. We chose the sifting algorithm as LP optimizer (parameter RootAlg), the pseudo reduced costs to drive the selection of the variable to branch on at a node (parameter VarSel), and we set the emphasis on finding optimal solutions with less effort applied to finding feasible solutions early (parameter MIPEmphasis). We decided to not perform probing (parameter Probe) in order to save computing time, and to generate flow cover (parameter FlowCovers) and mixed integer rounding cuts (parameter MIRCuts) moderately. All the other CPLEX parameters were set to their default values.In order to provide further insights into the effectiveness of the proposed heuristics, we solved all the instances without an optimal solution available in the literature with CPLEX 12.2 using 3 different settings. We considered CPLEX with all the parameters set to their default values with the exception of parameter MIPEmphasis that was set to feasibility (this variant is referred to as CPLEX Setting-A, henceforth). CPLEX Setting-B has the same parameter settings of CPLEX Setting-A with the exception that the RINS heuristic is applied every 20 nodes (i.e., parameter RINSHeur was set equal to 20). CPLEX Setting-C differs from CPLEX Setting-A as the local branching heuristic is turned on (parameter LBHeur). The latter two settings are chosen as they correspond to two approaches available in CPLEX that, as mentioned in Section 1, use variable fixing. Finally, we set a time limit equal to 7200seconds to the solution of each instance for any CPLEX setting.The present section is organized as follows. In Section 4.1 we briefly describe the testing environment we used. In Section 4.2 we report some issues related to the implementation of the heuristics, whereas in Section 4.3 we motivate the introduction of the variants by means of some examples. Finally, Section 4.4 provides the computational results.The proposed heuristics were tested on four groups of instances: three groups are composed of benchmark instances available in the literature, and one group is formed of benchmark instances taken from the literature on the CFLP. Altogether, the heuristics we implemented were tested on 227 instances, ranging from small-scale (i.e., 16 facilities and 50 customers) to very large-scale (i.e., 1000 facilities and 1000 customers). A summary of the instances tested in this paper is shown in Table 1. Instances in the same group are further classified into sub-groups according to their size. In column “References”, we report the main references where optimal solutions (Opt.) or best upper bounds (Heur.) can be found.The first group of instances is composed of a subset of those belonging to the OR-Library, publicly available at http://people.brunel.ac.uk/∼mastjjb/jeb/orlib/capinfo.html. These instances were originally proposed for the CFLP, and some of them are not feasible when the single source constraint is introduced. Hence, we restricted our experiments to the set of feasible instances that is composed of 24 small-scale (data sets from OR1 to OR3) and 12 large-scale instances (data set OR4). Even though the 24 small-scale instances can be solved by CPLEX in negligible computing time, we performed experiments on these in order to have a large set of instances with known optimal solutions to assess the performance of the heuristics. Data set OR4 includes instances consisting of 100 facilities and 1000 customers that are, to the best our knowledge, the largest-scale instances tested so far in the literature. Best upper bounds can be found in Ahuja et al. (2004) and Chen and Ting (2008). Optimal solutions are not available from the literature for these instances but we solved them to optimality within few minutes, by using CPLEX.The second group of benchmark instances comprises five sets of small/medium-scale instances randomly generated by Holmberg et al. (1999), each with different size and ratio between the total capacity of the facilities and the total demand of the customers. Optimal solutions for this group of instances are reported in Holmberg et al. (1999) and Yang et al. (2012), whereas heuristic solutions are published in Ahuja et al. (2004) and Chen and Ting (2008).The third group is composed of 20 medium/large-scale instances randomly generated by Yang et al. (2012). They are classified into four sub-groups which differ in problem size and in the ratio of the total capacity of the facilities over the total demand of the customers. Optimal solution values can be found in Yang et al. (2012).The fourth group considers the 100 instances in TBED1 tested in Avella and Boccia (2009) for the CFLP and publicly available at http://www.ing.unisannio.it/boccia/CFLP.htm. All of them turned out to be feasible for the SSCFLP. These are very large-scale instances ranging from 300 to 1000 facilities and from 300 to 1000 customers. As these instances have never been tested before for the SSCFLP, we solved them by means of CPLEX with the 3 settings mentioned above. Whenever CPLEX found an optimal solution, the latter was used to measure the quality of the solutions found by the heuristics. In all the remaining cases, the heuristics are validated using the optimal solutions reported in Avella and Boccia (2009) for the CFLP as lower bounds.The four groups of instances, along with the optimal solution values, when available, or the best lower and upper bounds, are publicly available at the web page https://sites.google.com/site/orbrescia/instances/instances_sscflp.The implementation of a Kernel Search framework involves an accurate calibration of its parameters. In Guastaroba and Speranza (2012b) a thorough analysis and computational comparison of different parameter settings is provided. In this paper, after extensive preliminary experiments and based upon the results reported in Guastaroba and Speranza (2012b), we made the following choices. All the settings concern both the Kernel Search algorithm and the Kernel Search(1) and Kernel Search(0–1) variants.SetK(y)is initialized selecting all the facilities with positive value in the optimal solution of LP(J,I×J) (i.e., parameter m). The subset of customers associated with each facility is selected as follows. Once LP(J,I×J) is solved, parameterγis set equal to the median of the reduced costs of variablesxijassociated with the facilities composing the initial individual kernelK(y), i.e. we setγ≔median{cˆ(xij)|i∈I,j∈K(y)}. Then, all the customers such thatcˆ(xij)⩽γcompose the subset associated with facility j. After some preliminary experiments, we chose to adopt the median instead of the average of the reduced costs used in Guastaroba and Speranza (2012b) since, especially for the medium and large-scale instances of the SSCFLP, we realized that the distributions of the reduced costs were strongly skewed with some extreme values that affected the computation of the average. This led to an over-estimation of parameterγand, as a consequence, an overly large number of variablesxijconsidered in the restricted problems. Each individual bucketB(y)hhas a cardinality equal to the number of facilities used to initialize setK(y), i.e. we setlbuck≔m. Therefore, the number of individual buckets built is equal toNB≔|J|-mmand we decided to analyze all the buckets generated, i.e. we setNB‾≔NB. Finally, we set parameter p equal to 2.During some preliminary tests conducted on the large-scale instances, we observed that often CPLEX quickly found the optimal (or a slightly sub-optimal) solution of the restricted problems and spent excessive computing efforts trying to prove the optimality of the solution at hand. Hence, we set a time limit equal to 900seconds for the solution of each restricted problem. If CPLEX does not terminate within the allowed computing time, then the best solution found so far, if any, is used to update the individual kernels and the upper bound. The maximum computing time constraint is set on the solution of the restricted problems, only. No time limit is introduced for the solution of LP(J,I×J).There are some issues related to the solution of LP(J,I×J) which deserve particular notice, since they may have a substantial impact on computing times. On the one hand, the presence of the redundant constraints (4) in the SSCFLP formulation (1)–(6) does yield a much tighter linear relaxation. Indeed, we found that for some of the small-scale instances in data sets OR1–OR3 the optimal solution of the linear relaxation was integer if constraints (4) were introduced. On the other hand, the number of constraints (4) to be included in the SSCFLP model increases quite rapidly as the size of the instance grows, leading to linear programming problems that CPLEX cannot solve within reasonable computing times. Therefore, we decided as follows. In our computational experiments, we solved LP(J,I×J) including constraints (4) for the OR-Library, Holmberg and Yang instances, whereas we did not include them for the solution of the TBED1 instances. The solution of any restricted BILP problem does include constraints (4), even for the TBED1 instances. In fact, given the parameter settings mentioned above, the size of all the restricted problems was manageable, thus not requiring the removal of constraints (4).In this section we report part of the preliminary analysis we conducted when designing the two variants described in Sections 3.2 and 3.3. The goal of the analysis was to identify a relationship between the optimal solution of the linear relaxation and the optimal solution of the original BILP problem. To this aim we randomly selected 10 instances in the Holmberg data set and compared the optimal values for variablesyjin the BILP problem and in its linear relaxations. Particular attention was paid to determine a relationship between those variablesyjthat took value 0 or 1 in the linear relaxation and their values in the optimal solution of the original problem. The findings of this analysis are reported in Table 2.In the fourth column of Table 2 we report, for each instance, the number of times a binary variableyjthat took value 1 in the optimal solution of the linear relaxation took a different value (i.e., took value 0) in the optimal solution of the original problem. Similarly, in the last column we show, for each instance, the number of times a variableyjwhose optimal value was 0 in the linear relaxation took value 1 in the optimal solution of the original problem. For only few variablesyjwe found a difference between the optimal solution of the linear relaxation and that of the original problem. This suggests that the variants based on variable fixing may significantly improve the efficiency of the procedure with, hopefully, minor worsening of the solution quality.This section is devoted to the illustration and comment of the computational results. As the goal of this paper is to provide a tool for solving medium/large-scale instances that cannot be solved easily to optimality, the main part of this section concentrates on the medium/large-scale instances. Whenever possible, the quality of the solutions found by the heuristics proposed in this paper was validated by direct comparison with the optimal solution values, denoted asz∗, either available in the literature or found with CPLEX. When commenting the instances solved also by other heuristics, we compared the performance of the Kernel Search (and the two variants) with the upper bounds, denoted aszUB, found by the best performing heuristic available in the literature. Finally, when optimal solutions were not available in the literature and could not be found with CPLEX, we used the optimal solution values for the CFLP as lower bounds, denoted aszLB, to validate the performance of our heuristics.In Tables 3, 4, 6 and 7we provide a summary of the computational results for each group of instances. We decided to report in the present section only the detailed computational results for the OR4 data set (see Table 5) since it comprises benchmark instances for the SSCFLP without, to the best of our knowledge, optimal solutions previously published in the literature. All the detailed computational results are reported in Tables 8–11 in Appendix A.For the OR-Library and Holmberg data sets we report only the performance of the Kernel Search, given the negligible computing times reported. For all the remaining instances the performance of the Kernel Search(1) and Kernel Search(0–1) is also shown.In Table 3 we report the computational results for data sets OR1, OR2 and OR3. The performance of the Kernel Search is evaluated comparing the solution values found by the heuristic, denoted aszH, with the optimal solution values computed with CPLEX. For each data set we report statistic Opt. Gap % that refers to the average error with respect to the optimal solution value. The error for each instance is computed as 100(zH-z∗)/z∗, and then averaged over all the instances belonging to the same data set to obtain statistic Opt. Gap %. Statistic Worst Gap % shows the worst error computed out of all the instances in the data set. Finally, statistic CPU (seconds) shows the average computating time in seconds. The results for these data sets show that the Kernel Search found the optimal solutions for these small-scale instances in negligible computing time (computing times for CPLEX are similar).Table 4 compares the performance of the Kernel Search with that of the VLNS proposed in Ahuja et al. (2004) and the LH-ACS introduced in Chen and Ting (2008) for the OR4 data set and the Holmberg instances. For each data set we report the best implementation of the VLNS proposed in Ahuja et al. (2004). For each heuristic we report the number of times it found the optimal solution in column # Opt. For the Kernel Search we also report statistic # Impr. that counts, for each data set, the number of times that the Kernel Search found a better solution than the best upper bound available in the literature, i.e. the best solution among those found by the different VLNS implementations in Ahuja et al. (2004) and the LH-ACS in Chen and Ting (2008). The figures reported in Table 4 show that the Kernel Search outperforms the other heuristics. Indeed, the Kernel Search found the optimal solution for all the OR4 and Holmberg instances. The number of improvements achieved by the Kernel Search with respect to the best known upper bound is particularly remarkable for the OR4 data set, where the Kernel Search improves the upper bound for 8 out of the 12 instances in the data set. A smaller number of improvements is achieved for the Holmberg instances (8 improvements out of 71 instances) as for the remaining 63 instances the best upper bound corresponds to the optimal solution value. Average computing times are negligible for all the Holmberg instances, whereas it took less than 35seconds, on average, to solve the instances in the OR4 data set. A thorough validation of the performance of the Kernel Search is provided for the OR4 data set in Table 5. We found that CPLEX with any of the tested settings could solve to optimality the instances in the OR4 data in less than 2minutes, on average. The results do not show remarkable differences in terms of computing time among the different settings. Note that the Kernel Search found the optimal solution for the instances in the OR4 data set in, on average, slightly more than half a minute of computing time.As the size of the instances in both the Yang and the TBED1 data sets is large, in Tables 6 and 7we report also the performance of the Kernel Search(1) and Kernel Search(0–1) variants. Specifically, Table 6 reports the average results for the Yang data set. The Kernel Search found the optimal solution for 18 out of 20 instances. The error reported for the 2 remaining instances is approximately equal to 0.01% (see Table 10). Computing times are, on average, less than 17minutes and 8 instances were solved within 1minute and a half (see Table 10). We report three further statistics for the two variants. As the optimal solution for these instances is known, for each variant in columns # Gap<0.1%, # Gap<0.5% and # Gap<1% we show the number of times it found a solution whose error with respect to the optimal solution value was smaller than 0.1%, 0.5% and 1%, respectively. As expected, the quality of the solutions found by the Kernel Search(1) variant is slightly worse than the Kernel Search, but the improvements in terms of computing times are remarkable. Specifically, the Kernel Search(1) variant found the optimal solution for half of the instances composing the data set. Moreover, the average optimality gap was always smaller than 0.34% and statistic Opt. Gap % took a value smaller than 0.1% for 14 instances out of 20, a value smaller than 0.5% for 16 instances out of 20 and a value smaller than 1% for 19 instances out of 20 (see Table 10 for further details). Statistic Opt. Gap% for the only instance which reported an error larger than 1% was equal to 1.49%. On the other hand, savings in terms of computing times are valuable. Indeed, the average computing time spent by the Kernel Search(1) variant is approximately 25% smaller than the processing time required by the Kernel Search. More importantly, in several cases the Kernel Search(1) variant found the optimal solution (or a near-optimal) in much less computing times than the Kernel Search. For example, see the figures related to instances 30_200_4, 60_200_4, 60_300_4 and 80_400_2 in Table 10. The trade-off between the efficiency of the procedure and the quality of the solution found is even more evident observing the results reported for the Kernel Search(0–1) variant. With respect to both Kernel Search and Kernel Search(1), the deteriorations in terms of solution quality are noteworthy, but the algorithm is quite faster. Particularly, the Kernel Search(0–1) variant found the optimal solution for only 3 instances out of 20. However, the average error is less than 1% (see Table 10), statistic Opt. Gap % is never larger than 3.25% and for 12 instances out of 20 it is smaller than 1%. Computing times are, on average, 76% and 68% smaller than those reported by the Kernel Search and the Kernel Search(1), respectively. We also highlight that for some instances the Kernel Search(0–1) variant found a solution much faster than the other two heuristics with almost negligible deteriorations in terms of solution quality (see the figures related to instances 60_200_2, 60_200_4, 60_200_5, 60_300_2, and 80_400_5 in Table 10).In Table 7 we report the average statistics for the TBED1 data set. Detailed computational results are shown in Table 11. As for this set of instances neither optimal solutions nor upper bounds are available in the literature, the performance of the heuristics is assessed as follows. 43 out of 100 instances were solved to proven optimality within the computing time limit of 7200seconds by CPLEX (with one or more of the tested settings). They are denoted with the symbol (∗) in Table 11. For each of the latter instances we computed statistic Opt. Gap %. For all the remaining instances, we computed the gap with respect to lower boundzLBas 100(zH-zLB)/zLB. We then averaged over all the instances in the same data set to calculate statistic LB/Opt. Gap % reported in Table 7. The Kernel Search found the optimal solution for 40 out of the 43 instances with proven optimal solution (see Table 11). The average error for the 3 remaining instances is roughly equal to 0.08%. Particularly, the Kernel Search has a very good performance for the instances in groups TB1 and TB2 where it always found the optimal solution, when available. The figures in Table 7 show that statistic LB/Opt. Gap % is, on average, smaller than 1.07% for every group of instances. Additionally, for 58 instances out of 100 the LB/Opt. gap is smaller than 0.5%, and 76 instances were solved within a 1% LB/Opt. gap (see Table 11). Average computing times are quite larger than for the previous instances, but still reasonable given the size of the instances. The performance reported by the Kernel Search(1) variant is quite similar. Indeed, the average LB/Opt. Gap % is slightly larger for almost all the data sets, and computing times are slightly smaller. The not remarkable saving in terms of average computing times is due to the fact that, even after fixing some of theyjvariables to 1, the resulting problem is still hard to solve. It is worth highlighting the performance of the Kernel Search(1) variant for the TB5 group of instances in terms of reduction of the LB/Opt. Gap % and especially of the Worst Gap % compared to the Kernel Search. Finally, even though the gaps reported by the Kernel Search(0–1) variant are worse than for the other heuristics, they are actually quite small. In fact, the average LB/Opt. Gap % is never larger than 1.10%, 70 instances out of 100 were solved within a 1% LB/Opt. gap (see Table 11), and the Worst Gap % is always smaller than 2.70%. Kernel Search(0–1) found the optimal solution for only 7 out of the 43 instances with proven optimality, but the average error for the remaining instances is relatively small (it is approximately equal to 0.23%). On the other hand, computing times are much smaller than both the Kernel Search and the Kernel Search(1) variant with an average reduction larger than 80%.As far as a comparison with CPLEX is considered, any heuristic reported an average LB/Opt. Gap %, computed over all the instances in TBED1 data set, smaller than that achieved by CPLEX with any setting (see Table 11). It is clear from Table 7 that Kernel Search outperforms CPLEX in terms of statistics LB/Opt. Gap % and Worst Gap %, especially for data sets TB4 and TB5. A similar performance is achieved by the Kernel Search(1) variant, with the exception of slightly larger average gaps reported for data set TB1. The Kernel Search(0–1) variant is outperformed by CPLEX for data sets TB1 and TB2. Conversely, the latter heuristic variant significantly outperforms CPLEX, with any setting, for data sets TB4 and TB5. As far as computing times are taken into consideration, each heuristic, in particular the Kernel Search(0–1) variant, is significantly faster than CPLEX with any tested setting.

@&#CONCLUSIONS@&#
The Kernel Search presented in this paper is a heuristic with a very simple and general structure, applicable to any Binary Integer Linear Programming problem. The heuristic relies on the high performance of commercial softwares for the solution of Linear Programming and Mixed Integer Linear Programming problems and is based on the solution of subproblems restricted to subsets of variables. The heuristic has been applied to the Single Source Capacitated Facility Location Problem that is considered to be a hard problem in the class of facility location problems because of the restriction that each customer can be served by one facility only. The results show that, although the heuristic does not include any step that explicitly considers the specific structure of the problem, the Kernel Search performs extremely well. Extensive computational experiments on benchmark instances show that the Kernel Search outperforms the best heuristics for the Single Source Capacitated Facility Location Problem available in the literature. The Kernel Search found the optimal solution for 165 out of 170 instance with a proven optimum. The error in the remaining instances is negligible. The proposed heuristic is able to solve new very large-scale instances, with up to 1000 facilities and 1000 customers. We also introduced variants of the heuristic based on variable fixing. Computational results showed that the variants may improve the efficiency of the algorithm with minor deteriorations of the solution quality.Simpler versions of the Kernel Search have been shown to perform extremely well on other hard combinatorial problems. The heuristic has a strong potential for applicability to real world problems, due to the small implementation effort required and the implicit flexibility.