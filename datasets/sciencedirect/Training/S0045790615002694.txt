@&#MAIN-TITLE@&#
Image preprocessing with a parallel optoelectronic processor

@&#HIGHLIGHTS@&#
We use a parallel optoelectronic processor for image preprocessing.We extend the processor to improve its parallelism and to make it more compact.We adapt several preprocessing operators for the processor.We write a compiler and simulator for evaluating the presented algorithms.

@&#KEYPHRASES@&#
Parallel image processing,Parallel optical processing,High-performance computing,Image preprocessing,Parallel processing,

@&#ABSTRACT@&#
In this paper we use and extend a parallel optoelectronic processor for image preprocessing and implement software tools for testing and evaluating the presented algorithms. After briefly introducing the processor and showing how images can be stored in it, we adapt a number of local image preprocessing algorithms for smoothing, edge detection, and corner detection, such that they can be executed on the processor in parallel. These algorithms are performed on all pixels of the input image in parallel and, as a result, in steps independent of its dimensions. We also develop a compiler and a simulator for evaluating and verifying the correctness of our implementations.

@&#INTRODUCTION@&#
In the last two decades many researchers advocated optical interconnects between and inside silicon chips to address the limitations of transferring data with wires [1]. It may be possible to extend the idea in optical interconnects for parallel digital optical processing with many small and independent electronic processing elements that use optics for communication. We presented a free-space optoelectronic processor to evaluate this idea and showed that such a processor, while reducing the wiring complexity and achieving higher parallelism compared to electronic processors, could provide acceptable expressive power [2].The idea of using optics for computation was first investigated more than five decades ago [3] and various techniques were presented since [4–6], the most promising of which rely on Fourier optics and optical vector–matrix multiplication [7]. However, because of their analogue nature and vulnerability to noise, implementation challenges, the need for transferring data between the electronic memory and the processor in each cycle, and, more importantly, their limited expressive power, such processors face many challenges for competing with today’s electronic processors. In addition to the reduced implementation challenges and the integration of memory, which are discussed at length in [2], the power of our processor in expressing a wide range of computational tasks is a great advantage over the past parallel optical processors. Despite the simplicity of the processor’s operands (large binary matrices) and operations (bitwise NAND and complement), after defining a syntax for expressing procedures for the processor, we presented the parallel implementation of basic arithmetic operations and used it to perform the Miller–Rabin primality test in parallel [2].Image processing applications could be an interesting target for our processor: due to the nature of the data, many image processing tasks could benefit considerably from parallelism (such as [8]). An optical processor has the additional benefit that it may be possible to transfer images optically to the processor, without the bottleneck of electronic buses. Furthermore, the integration of the memory in our processor and the high speed of accessing it (loading and storing large binary matrices in each processor cycle), make it feasible to summarise the images (e.g., with edge detection or extraction of local features [9]) as much as possible before transferring them from the processor. This would reduce the amount of data that needs to be transferred and processed electronically.In this paper, we study the possibility of using the optoelectronic processor presented in [2] for image processing, specifically for some common local preprocessing steps, such as smoothing and edge detection. We show that the expressive power of the processor is adequate for the studied preprocessing algorithms and demonstrate how these algorithms can be adapted for execution on the processor. This paper is organised as follows: In Section 2, we review the studied processor and show how to extend it to transfer images and to store data more compactly in its data planes. In Section 3, we use the procedures described in Section 2 to implement image processing algorithms for smoothing and edge detection. In Section 4, we evaluate the presented procedures with a compiler that compiles them to processor instructions, in terms of the number of instructions and the number of required data planes, and compare it with previous parallel and optical image processing proposals and discuss its implementation issues, and finally, in Section 5 we conclude this paper.The processor [2] has three main components: two light sources, several two-dimensional optoelectronic Data Planes that contain a large number of Cells, and an electronic circuit that controls these data planes for storing data and performing logical operations. In Section 2.1, after explaining the behaviour of cells and data planes, we show how the processor can perform computation on its data planes. Then in Sections 2.3, we introduce extended data planes to store images more compactly and image planes to transfer images to the processor. In Section 2.4, we briefly explain how to use processor data planes to store matrices of numbers and describe procedures for expressing algorithms for the processor.The processor relies on many simple optoelectronic processing elements, called Cells. Each cell stores a single bit and depending on its state, can block the light. Cells are aligned in 2-dimensional rectangular optoelectronic Data Planes (Fig. 1); the processor uses these planes for storing data and performing computation. Although the cells in a data plane are independent, they all decode and follow the instructions in the common 2-bit instruction bus of the data plane.Depending on the signals in the control bus, the cells in a data plane can be in one of the four states shown in Table 1. To implement these states, each cell should detect and block the light. Note the there is a slight difference between the behaviour of the cells as presented in Fig. 1 and those in [2]; while in filter state, those cells whose bits are zero (instead of one) block the light.The bits held by the cells in a data plane form a binary matrix. These matrices, i.e., the data stored in data planes, are the operands of the operations supported by the processor.In the processor, several data planes are packed between two light sources (Fig. 2). Each data plane is like a register in conventional processors; the processor controls the state of the data planes via their control bus to transfer data between them or to perform logical operations.To copy the a data plane onto another plane, the source data plane can be put into the filter state, the destination into the record state, and the rest of the data planes into the transparent state. Then turning on the light source closer to the source plane (relative to the destination plane) transfers the bit in each cell of the source plane to its corresponding cell in the destination plane.The NAND operation on data planes can be implemented similarly: the first operand is transferred to the destination plane, as in the copy operation. Then this operation is repeated for the second operand, except that the destination plane is put into the combine state instead of the record state. After this operation, each bit of the destination plane contans the bitwise NAND of the corresponding input bits.Note that in each cycle only two planes are active: the source plane, which is in the filter state and the destination plane, which is in the record or combine state; all other planes are in the transparent state and are not involved in the operation.We use an extension of the processor described in [2], in which each cell stores 8bits instead of 1. Also the control bus of data planes, now called extended planes with this extension, is extended to 5-bits; three additional bits indicate which of the 8 flip-flops in their cells should be selected (Fig. 3). In the rest of this section, when only one of the data planes in an extended plane is intended, we simply use the term “data plane” as before.After extending data planes as just explained, at least in their basic form, processor instructions remain intact: the processor merely maps data planes 0 through 7 to the first extended plane (if each extended cell has 8bits), 8 through 15 to the second, and so on. When both the source and destination of a processor instruction are in the same extended plane, the processor can either move one of them to a temporary data plane in another extended plane and perform the operation optically in the next cycle, or perform it electronically, without using the optical interconnection.However, specific instructions may be introduced to use this extension more efficiently. If the processor can move all eight bits of an extended plane to another in a single cycle (for instance, by dedicating a different wavelength to each of the eight bits), faster variants of processor instructions may be introduced that can operate on whole extended planes. Thus, in addition to decreasing the number of data planes, extended planes make it possible to perform instructions on several virtual data planes (depending on the number of bits in extended cells) in the same processor cycle, as mentioned earlier. However, another probably much more important benefit of extended planes is that they make it possible to perform instruction electronically (actually shifting operations have the same property as well). The reason this is so important is that it makes it possible to perform several instruction in parallel in each processor cycle, as shall be explained next.In each processor cycle, the controller loads an instruction and changes the state of the data planes to perform it. Since the optical interconnection is shared by all of the data planes, in each cycle there is exactly one source and one destination and the rest of the data planes are in the transparent state and inactive. However, transparent data planes can perform purely electronic operations simultaneously without disturbing the optical data movement. Thus, all electronic operations can be performed in parallel (provided their operands are disjoint); this can possibly achieve remarkable speed-up. To benefit from parallel electronic operations, in each cycle the processor (the controller, to be more precise) reads at most one optical instruction and as many purely electronic operations with disjoint operands as possible and executes them simultaneously.For processing images, they first need to be transferred to the processor via special data planes called image planes, whose main purpose is transferring data in and out of the processor. Ideally, it should be possible to transfer the frames optically to the processor without the bottleneck of electronic buses. For this purpose, each cell of an image plane should convert the analogue input image and store it in its flip-flop array. It is also possible to transfer previously captured frames electronically to microdisplay-like image planes. The main difference between such image planes and regular data planes is that the data inside image planes can be electronically accessed using matrix addressing (the addressing scheme used in flat panel displays). Since transferring images using serial electronic buses and matrix addressing is slower than processor cycles, frames can be transferred to image planes while the processor is processing previous frames.With the simple operands and the limited bitwise SIMD-like operations of the studied processor, the expression of non-trivial computations is very difficult. Procedures address this complexity by introducing a simple but powerful abstraction layer on top of the processor. Procedures can describe algorithms for the processor; their main operands are matrices of numbers. For execution on the processor, these matrices are mapped to built-in processor data planes and such procedures are translated into a series of processor data plane instructions (Fig. 4). We use the same syntax for procedures as in [2]. To make the paper self-contained, we briefly describe the syntax of these procedures and highlight their few syntactical extensions in this paper.Number matrices (number arrays in [2]), like A, are stored in|A|binary matrices, which can be stored in processor data planes;Aiindicates the ith binary matrix of A and holds the ith bit of all numbers in the matrix A.A0andA|A|-1hold the least and the most significant bits of all numbers in the matrix, respectively. All numbers of constant matricesx‾(for the constant integer x) are equal to the integer x; for instance,127‾indicates a number matrix all of whose numbers are 127. A matrix array, declared asA[1··n], is a syntactic sugar for specifying n (a constant) number matrices; for the constant i (1⩽i⩽n),A[i]can be used to access the ith number matrix in A. This notation is especially convenient for passing several images to procedures. Procedures may call other procedures. The only control flow statements inside procedures are for loops; the body of these loops are repeated for different values of loop’s induction variable.In this paper, we use the procedures described in [2] for arithmetic operations without repeating them here. These procedures perform arithmetic operations on all numbers of operand matrices simultaneously: denoting the number in the ith row and jth column of R asR(i,j),R(i,j)isA(i,j)+B(i,j)for every numberR(i,j)in R, after the statementR←A+B. Among other procedures introduced there,ConditionalArray()(used asConditional()in this paper) is especially important as it is used to implement conditional expressions; inR←Conditional(C,A,B), the numbers of the matrix R are selected from either A or B depending on the corresponding number in number matrix C: for every number in R,R(i,j)isA(i,j)ifC(i,j)is non-zero andB(i,j)otherwise. Also,UShift(P),DShift(P),RShift(P), andLShift(P)move the numbers in the matrix P up, down, right and left, respectively.It may sometimes be required (or more convenient) to perform floating point arithmetic; just as integers, matrices of floating point numbers can be stored in several data planes. Then, procedures for performing floating point operations can be implemented, just as their integer counterparts [2], without changing the architecture of the processor. Actually, the simultaneous use of number matrices of different data types or sizes in procedures without extending the processor, is one of the convenient advantages of the studied processor.In this section we demonstrate how local image preprocessing algorithms can be expressed using procedures (as described in Section 2.4) to be executed on the optoelectronic processor explained in Section 2. The reason we confine ourselves to local algorithms, in which the value of each output pixel depends only on the neighbourhood of the corresponding input pixel, is that otherwise the size of the input image would have appeared in the complexity of the procedures, due to the slow shifting operations of Section 2.4. Therefore, we did not include algorithms like Canny for edge detection, which have a global step (note that although Canny is chiefly local, its thresholding step is not). Also, it is not our intention to cover the complex algorithms available for the selected preprocessing steps. Instead, we try to demonstrate the process of devising number matrix procedures for image processing applications for some simple algorithms; many of the more complex algorithms could be converted using similar techniques. The performance of the resulting procedures, however, may depend on many factors.Most local algorithms can be converted to procedures by shifting the data planes and using the techniques used in vector processors to convert control flow to data flow (see [10], or more recently [11]), which basically convert conditional statements to masked uniform operations. The performance of the result depends on the divergence of the input statements (non-uniform array accesses may be translated toO(n)operations for arrays of size n, for instance). There is also the overhead of floating point types or trigonometric functions (which are usually implemented very efficiently in the hardware, unlike the presented processor). Some of these overheads may be hidden by the parallelism in the processor (millions of cell operations in each cycle), the high frequency of optical devices, and executing some of these operations natively in extended data planes. Despite this, the performance of the processor may not be competitive with other processors, even for some local algorithms.We start this section with two simple noise removal algorithms and show how to perform discrete convolution using the processor.The median smoother removes noise from images by replacing each pixel with the median of its and its neighbours’ values. Procedure 1 shows the implementation of this algorithm for the optoelectronic processor. Given an input image I, MedianSmoother() initialises the N matrix array to hold the input image and the input image shifted in a direction. For each pixel, the corresponding pixels of these matrices hold the value of the pixel in the input image and its neighbours (Fig. 5); the size of N could be grown to include more distant neighbours for each pixel. Then it callsSort()to sort the values of each pixel and its neighbours; more precisely, it sortsN[1](i,j),N[2](i,j), …,N[5](i,j)for each pixelI(i,j)of the image. After this step, the matrixN[3]contains the median of the neighbours of each pixel.Procedure 11: procedure MedianSmoother(I)2:N[1··5]: matrix array to store the neighbours of each pixel3:N[1]←I4:N[2]←LShift(I)5:N[3]←UShift(I)6:N[4]←RShift(I)7:N[5]←DShift(I)8:Sort(N[1··5])9:returnN[3]10: end procedureSort() (Procedure 2) uses the bubble sort algorithm to sort the numbers in the corresponding pixels of the matrices in N. Note that the sorting procedure is done for all of the pixels in parallel and the number of processor instructions it translates into (O(n2)) does not depend on the number of numbers in the matrices, but the size of the array N, i.e., n (which is 5 inMedianSmoother()). The body of the inner loop of Sort() is especially interesting: in the bubble sort algorithm two numbers are swapped if the first is larger than the other. To achieve this in Procedure 2, after the assignment in lines 4 and 5, each number inN1is the smaller of the corresponding numbers inN[j]andN[j+1], andN2is the greater of the two. Note that the limits of the loops may be slightly modified to implement insertion sort.Procedure 21: procedure Sort(N[1··n])2:fori=1to ndo3:forj=1ton-1do4:N1←Conditional(N[j]<N[j+1],N[j],N[j+1])5:N2←Conditional(N[j]⩾N[j+1],N[j],N[j+1])6:N[j]←N17:N[j+1]←N28:end for9:end for10: end procedureProcedure 3 implements the averaging smoother; it replaces the value of each pixel with the average value of the pixels in thek×krectangle centred at that pixel. The process of calculating the sum of the pixels in the neighbourhood of each pixel is demonstrated in Fig. 6.Procedure 31: procedure AveragingSmoother(I,k)2:S←0‾3:L←I4:fori=1to⌊k/2⌋do5:L←UShift(L)6:end for7:fori=1to⌊k/2⌋do8:L←RShift(L)9:end for10:fori=1to kdo11:C←L12:forj=1to kdo13:S←S+C14:C←LShift(C)15:end for16:L←DShift(L)17:end for18:returnS/(k×k)‾19: end procedureThe loops in lines 3–8 of Procedure 3 shift the numbers in C such that for each pixel in I, the corresponding pixel in L is the lower left pixel of thek×krectangle centred at the original pixel (part a in Fig. 6). Then, starting from L, the numbers in thek×kneighbourhood of each pixel is added to S row by row in lines 9–16 (parts b and c in Fig. 6); this is done in parallel for all numbers in the number arrays. Since the number of processor data plane instructions necessary for calculating the sum of two number matrices isO(|M|)(|M|is the number of binary matrices of the operand matrices), Procedure 3 is translated intoO(k2|M|)data plane instructions.Averaging, and many other image processing operators like the Gaussian filter, is a special case of discrete convolution, where the value of each pixel is determined based on its neighbours and a convolution mask [12]. Given the image f and the convolution mask h, the discrete convolution of an image can be calculated as in Eq. (1), where O is the set of the neighbours of the pixel(i,j). In this equation,h(m,n)is the coefficient of the pixel(i+m,j+m)for calculating pixel(i,j)of the resulting image,f′(i,j).(1)f′(i,j)=∑(y,x)∈Oh(y-i,x-j)f(y,x)Procedure 4 calculates the convolution of an image for the mask h. Note thath(m,n)‾is defined as described in the previous paragraph and c is the sum of the coefficients in the mask h. Once again, the calculation of convolution is performed in parallel for all pixels of the image: first the image is shifted to point at the lower left pixel of thek×ksquare centred at each pixel. Then, the contribution of each neighbour to the value of each pixel is calculated row by row. AsAveragingSmoother(), Procedure 4 is translated intoO(k2|M|)data plane instructions.Procedure 41: procedure Convolution(I,k,h,c)2:S←0‾3:L←I4:fori=1to⌊k/2⌋do5:L←UShift(L)6:end for7:fori=1to⌊k/2⌋do8:L←RShift(L)9:end for10:fori=1to kdo11:C←L12:forj=1to kdo13:S←C×h(i,j)‾14:C←LShift(C)15:end for16:L←DShift(L)17:end for18:returnS/c‾19: end procedureNow the averaging smoother can be described as a convolution mask, whereh(m,n)is 1 for each-k/2⩽m,n⩽k/2.Edge detection is one of the most common and important preprocessing steps in image processing applications. Edges, usually identified as the pixels with abrupt changes in the intensity compared to their neighbours, have both magnitude and direction. Sometimes, e.g., for sharpening images, only the magnitude suffices; the Laplace or the Roberts operators address this need.The Roberts operator is one of the oldest methods for edge detection. The algorithm is demonstrated in Procedure 5. Hereh1andh2are Roberts’2×2convolution masks [12]. Like Procedures 4 and 5 is translated intoO(k2|M|)data plane instructions. The Laplace operator can be implemented similarly with different convolution masks. Procedure 5 uses Abs() which should return a matrix whose numbers are the absolute value of the numbers in the input matrix. For the input I, Abs() can be defined asConditional(I⩾0,I,-I).Procedure 51: procedure Roberts(I)1:h1,h2: Roberts convolution masks1:T1←Abs(Convolution(I,2,h1,1))1:T2←Abs(Convolution(I,2,h2,1))1:returnT1+T21: end procedureWhen the direction of the edges are required, Prewitt, Sobel, or Robinson operators can be used. Instead of finding the horizontal and vertical gradients of each pixel, calculating their arctangent, and then discretising the angle, Procedure 6 rotates Prewitt operator convolution mask and selects the direction that yields the highest magnitude [12]; Sobel and Robinson can be implemented similarly, with different convolution masks.For each pixel in Prewitt, the magnitude and the direction of the largest convolution should be selected. InPrewitt(), starting fromh1, each of the masks are tried and usingConditional(), the values of D and E for the pixels whose new convolution is larger than the largest value seen so far, are updated. Given the fixed number of calls toConvolution(), this procedure is translated intoO(k2|M|)processor data plane instructions.Procedure 61: procedure Prewitt(I)2:h1,h2,…,h8: Prewitt convolution masks3:D: Edge direction4:E: Edge magnitude5: # the first direction6:D←1‾7:E←Convolution(I,3,h1,1)8: # the second direction9:E2←Convolution(I,3,h2,1)10:D←Conditional(E2>E,2‾,D)11:E←Conditional(E2>E,E2,E)12: # repeat for other directions13: # …14:returnD,E15: end procedureWe conclude this section with the simple Moravec corner detector and a note about the SUSAN edge and corner detector [13]. The Moravec operator for each pixel is defined as [12]:MO(i,j)=18∑k=i-1i+1∑l=j-1j+1f(k,l)-f(i,j)Procedure 7 shows the parallel implementation of this operator for the studied processor. The procedure is clear enough and quite similar to the previous procedures presented in this section.Procedure 71: procedure Moravec()2:S←0‾3:L←RShift(UShift(i))4:fori=1to 3 do5:C←L6:forj=1to 3 do7:S←S+Abs(C-I)8:C←LShift(C)9:end for10:L←DShift(L)11:end for12:returnS/(k×k)‾13: end procedureAs pointed out in the beginning of this section, many of the more complex preprocessing and local image processing algorithms could be described using number matrix procedures, as demonstrated in this section. In such algorithms, the neighbourhood of the pixels are analysed. This can be done for the studied processor by trying each of the pixels in the neighbourhood of the pixels row by row by shifting data planes, as in Procedure 3. The SUSAN edge detector [13], for instance, identifies edges based on the USAN (Univalue Segment Assimilating Nucleus) area for each pixel, by summing up the value of a function on the neighbourhood of each pixel. For detecting corners, SUSAN further finds the centre of the gravity of each USAN; for real corners the centre of gravity of each USAN should not be near its nucleus (i.e. the pixel owning the USAN). The centre of the gravity can be identified by averaging the location of the pixels in each USAN, again using the same technique. SUSAN also requires that all of the pixels in the straight line between the nucleus and the centre of the gravity of each USAN to be inside the USAN. The equivalent number matrix procedure can test to see whether the pixels in the neighbourhood of each pixel that lie on the line to the centre of the gravity of the USAN are inside the USAN.To evaluate the procedures presented in previous sections, we wrote a simulator to execute the instructions introduced in Section 2.2, and a compiler to compile procedures of Section 3 into the instructions expected by the simulator. Here we briefly introduce these programs; more details about them accompany their source package.1Available online at http://litcave.rudi.ir/umo.tar.gz.1The simulator stores a number of binary matrices (representing the data planes of the processor) in its memory and reads and executes a stream of instructions, resembling those supported by the processor. The compiler translates statements in a language similar to the procedures of the previous section to processor instructions that can be simulated by the simulator. To reduce the number of data planes used in procedures and the number of instructions the input program is translated into, the compiled instructions are optimised. Three main optimisations are performed: (i) dead code elimination and liveness analysis, (ii) data plane coalescing, (iii) assignment propagation. For more details about these optimisations, the reader may consult the document included in compiler’s source package.In our evaluations, we assume that processor data planes are large enough to contain whole images (actually this is of the main goals of the presented processor to make the dimensions of data planes scalable to use optics’ parallelism as much as possible). Otherwise, the images have to be broken into sub-images smaller than processor data planes and the algorithms have to be repeated for each of these sub-images, making the complexity of the presented procedures proportional to the ratio of the size of images to the size of data planes. These sub-images have to be merged after being transferred from the processor; it may be necessary for these sub-images to overlap a few pixels on their boundaries for easier merging.Table 2shows some statistics for seven procedures (some of them for different number of neighbours), after being compiled into processor instructions. Its second column indicates the number of data planes used by any of these procedures and its third column shows their number of instructions. One interesting fact about these procedures is that they require very few data planes and thus a processor with about a hundred data planes (or only thirteen extended 8-bit data planes) can execute most of them. Also note that increasing the number of neighbours considered in median filter increases both the number of data planes and the number of resulting instructions almost quadratically relative to the number of neighbours. This is mainly because all of the neighbours are kept in an array and sorted using anO(n2)sorting algorithm.The performance of these procedures depends on the actual speed of the processor. If the processor performs f data plane instructions per second, a procedure, which is compiled into i instructions, finishes in(i/f)th of a second. Note that here we ignore the time required for transferring the image, which is slower than other instructions. Thus, some overhead may be considered for that operation. Note however that image planes may be transferred while the computation is taking place and thus, except for the first input image, this overhead may be removed in practice.If the area of each data plane is c in pixels, then for a processor with speed f Hertz, an algorithm with i processor instructions can processcf/ipixels per second. We demonstrate the expected performance of the Prewitt operator for 720p (1280×720) data planes for different processor frequencies in Fig. 7(note that both axes grow logarithmically). At the switching frequency of 10MHz (the current state of the art for electro-optic switches and photo-detectors are much higher than this [14,15]) the processor can perform the Prewitt operator at the rate of 1Gpix/s.Table 3shows at what frequency the presented processor reaches the performance reported for some of the studies in the literature for the specified algorithms. In this figure we assume that data planes have1280×720cells (720p data planes). As mentioned earlier, the state of the art for optical switches and photo-detectors is much higher than the frequencies stated in the third column.Almost all of the past optical image processing methods are based on Fourier optics [20]. The main disadvantages of these methods and edge detectors such as [21] are, as pointed out in the Introduction, their analogue nature and vulnerability to noise, limitations on the magnitude of the values of the pixels, the need for transferring data between the electronic memory and the processor in each cycle, and the difficulty of implementing different image processing algorithms or modifying the ones available. In this paper, we presented techniques for adapting various image preprocessing algorithms to the studied digital optoelectronic processor. The studied algorithms are described in concise and readable algorithmic procedures, which are easy to understand and modify.Compared to the past parallel optical processors in general, the most notable features of the processor studied in this paper are the integration of memory and its expressive power, which is the main focus of this paper too. Most of the past parallel optical processors perform a single operation (like addition [22,23], discrete Fourier transform [6], or vector–matrix multiplication [24]). The studied processor, however, implements parallel arithmetic operations and can perform algorithms with conditional statements. We studied the feasibility of this processor for parallel image processing and demonstrated how some common preprocessing algorithms can be adapted for the processor. The processor can perform these algorithms in parallel and in time independent of the resolution of the input image, given that the data planes are large enough to store the image.Several aspects of the studied processor make it easier to realise in practice compared to many of the optical processors in the literature: simple interconnects and compactness (the data planes can be packed close to each other in contrast to the processors based on lenses or complex interconnects), digital operation, and memory integration (refer to [2] for a more detailed discussion). The integration of memory addresses one of the main challenges facing optical processors, especially if they are to be used with the current electronic processors [25]: almost all of the past optical processors are stateless in that the data should be transferred to and from the processor in each cycle, via slow (compared to the size of the data planes) electronic buses [20]. This becomes a bottleneck, as large matrices should be transferred in each cycle. In the studied processor, on the other hand, data planes that store data are accessed in each processor cycle. Thus, transferring data is needed only for the initial inputs and the final outputs, and not for the intermediate data used in algorithms. Also inputs and outputs may be transferred while the processor is processing, to reduce this overhead further.Regarding the implementation of the processor, the commercially available transmissive microdisplays [26] are very similar to processor data planes; each pixel should include a photo-receiver to detect the light. The aperture ratio, distance between cells, and the distance between data planes should be decided based on light diffraction and electronic crosstalk. One of the main problems with MEMS or liquid crystal microdisplays is their slow switching speed. Promising optical switches and photo-diodes based on technologies like Graphene may address this limitation in near future [14,15].

@&#CONCLUSIONS@&#
