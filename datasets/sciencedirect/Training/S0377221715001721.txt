@&#MAIN-TITLE@&#
Scatter search with path relinking for the flexible job shop scheduling problem

@&#HIGHLIGHTS@&#
Neighborhood structures for Flexible Job Shop Scheduling Problem (FJSP) are proposed.New dissimilarity measures for solutions of the FJSP are defined.A new Scatter Search with Path Relinking (SSPR) algorithm is proposed for the FJSP.The experiments show that SSPR compares favorably with the state-of-the-art.

@&#KEYPHRASES@&#
Scheduling,Flexible job shop,Scatter search,Path relinking,Neighborhood structures,

@&#ABSTRACT@&#
The flexible job shop scheduling is a challenging problem due to its high complexity and the huge number of applications it has in real production environments. In this paper, we propose effective neighborhood structures for this problem, including feasibility and non improving conditions, as well as procedures for fast estimation of the neighbors quality. These neighborhoods are embedded into a scatter search algorithm which uses tabu search and path relinking in its core. To develop these metaheuristics we define a novel dissimilarity measure, which deals with flexibility. We conducted an experimental study to analyze the proposed algorithm and to compare it with the state of the art on standard benchmarks. In this study, our algorithm compared favorably to other methods and established new upper bounds for a number of instances.

@&#INTRODUCTION@&#
The job shop scheduling problem (JSP) is a simple model of many real production processes. It is one of the most classical and difficult scheduling problems and it has been studied for decades (Meeran and Morshed, 2014). However, in many environments the production model has to consider additional characteristics or complex constraints. In this work we consider the possibility of selecting alternative routes among the machines, which is useful in production environments where multiple machines are able to perform the same operation (possibly with different processing times), as it allows the system to absorb changes in the demand of work or in the performance of the machines. This problem is known as the flexible job shop scheduling problem (FJSP). It was first addressed by Brucker and Schlie (1990) and it has been object of intensive research since then.Initially, researchers proposed hierarchical approaches, in which the machine assignment and the scheduling of operations were studied separately (Brandimarte, 1993). However, most of the works in the literature consider both subproblems at the same time. Mastrolilli and Gambardella (2000) developed two neighborhood structures to improve the TS algorithm proposed by Dauzère-Pérès and Paulli (1997). More recently, Ho et al. proposed a learnable genetic architecture (LEGA) (Ho, Tay, and Lai, 2007). It is also remarkable the hybrid genetic algorithm combined with a variable neighborhood descent search (hGA) developed by Gao, Sun, and Gen (2008). Other approaches as the climbing depth-bounded discrepancy search (CDDS) algorithm proposed by Hmida, Haouari, Huguet, and Lopez (2010), the hybrid harmony search and large neighborhood search (HHS/LNS) by Yuan and Xu (2013) or the hybrid genetic algorithm combined with tabu search (GA + TS) proposed by González, Vela, and Varela (2013) also obtain good results on standard instances. Bozejko, Uchronski, and Wodecki (2010) present a parallel approach with two double-level parallel metaheuristic algorithms based on neighborhood determination (TSBM2h), with good results on one standard benchmark. Gutierrez and Garcia-Magario (2011) combine a modular genetic algorithm with repairing heuristics (MGARH), and obtain new upper bounds in one standard benchmark as well. Just to have a general picture of the state of the art in FJSP, we could said that TS, hGA, CDDS, HHS/LNS, TSBM2h, MGARH and GA + TS show the best performance among the aforementioned methods. However, none of them dominates the others in the sense of obtaining the best solutions or taking the lowest time for all benchmarks. Also, the performance of some of these methods strongly varies with the benchmark and some of them have not been evaluated on all the common benchmarks. For example, MGARH is among the best for one particular benchmark while it has not been evaluated on others; and hGA is also the best method for one benchmark, while it is clearly not so good in others.In spite of that metaheuristics have been widely applied to scheduling problems, a powerful method as scatter search with path relinking has been rarely used in flexible environments. Maybe this is due to the difficulty of defining a tight distance between schedules. As far as we known, only in Jia and Hu (2014), where the authors combine path relinking with tabu search and consider multiobjective optimization, a distance is defined for the FJSP.In this paper we propose new neighborhood structures for the FJSP with makespan minimization. We define feasibility and non improving conditions as well as algorithms for fast estimation of neighbors’ quality. We also define a dissimilarity measure between two solutions which takes into account the flexible nature of the problem. These new structures and the dissimilarity measure are incorporated into a hybrid metaheuristic which uses scatter search with path relinking and tabu search as improvement method. We conducted an experimental study to analyze our proposal and to compare it with the state of the art.The remainder of the paper is organized as follows. In Section 2 we formulate the problem and describe the solution graph model. In Section 3 we define the proposed neighborhood structures. Section 4 details the new dissimilarity measure and the metaheuristics used. In Section 5 we report the results of the experimental study, and finally Section 6 summarizes the main conclusions of this paper.In the job shop scheduling problem (JSP), there are a set of jobs J = {J1, …, Jn} that must be processed on a set M = {M1, …, Mm} of physical resources or machines, subject to a set of constraints. There are precedence constraints, so each job Ji, i = 1, …, n, consists of nioperationsOi={oi1,⋯,oini}to be sequentially scheduled. Also, there are capacity constraints, whereby each operation oijrequires the uninterrupted and exclusive use of one of the machines for its whole processing time.In the flexible JSP (FJSP), an operation oijis allowed to be executed in any machine of a given set M(oij)⊆M. The processing time of operation oijon machine Mk∈ M(oij) ispoijk∈N. Notice that the processing time of an operation may be different in each machine and that a machine may process several operations of the same job. The goal is to build up a feasible schedule which consists in assigning both a machine and a starting time to each operation in the set O = ∪1 ≤ i ≤ nOi, in such a way that all constraints hold. The objective function is the makespan, which should be minimized. The FJSP is NP-hard as it is a generalization of the JSP which has proven to be NP-hard (Garey, Johnson, and Sethi, 1976).A solution can be alternatively viewed as a pair (α, π) where α represents a feasible assignment of each operation oij∈ O to a machine Mk∈ M(oij), denoted α(oij) = k, and π is a processing order of the operations on all the machines in M compatible with the job sequences.LetPJoijandSJoijdenote the operations just before and after oijin the job sequence andPMoijandSMoijthe operations right before and after oijin the machine sequence in a solution (α, π), if they exist. The starting and completion times of oij, denotedStoijandCoijrespectively, can be calculated asStoij=max(CPJoij,CPMoij)(if an operation is the first in its job or in its machine sequence, the correspondingCPJoijorCPMoijis taken to be 0) andCoij=Stoij+poijkbeing k = α(oij). The objective is to find a solution (α, π) that minimizes the makespan, denoted asCmax(α,π)=maxoij∈OCoij.We define the following solution graph model for the FJSP. In accordance with this model, a machine assignment α and a feasible operation processing order π can be represented by an acyclic directed graph G(α, π) = (V, A∪R(α, π)), where each node v in V represents either an operation of the problem, labeled with the assigned machine Mk, or one of the dummy nodes start and end, which are fictitious operations with processing time 0.The set A contains conjunctive arcs representing job processing orders and the set R(α, π) contains disjunctive arcs representing machine processing orders. The arc (v, w) is weighted with the processing time, pvk, of the operation in v on the assigned machine Mk. If w is the first operation in the processing order of its job, J(w), there is an arc (start, w) in G(α, π) with weight 0 and if w is the last operation in the job processing order, there is an arc (w, end) with weight pwk, k = α(w). Fig. 1shows a solution graph for a problem with 3 jobs and 3 machines.The set R(α, π) is partitioned into subsets Rk(α, π), where Rk(α, π) is a minimal set of arcs defining a processing order for all operations requiring the machine Mk.The makespan of the solution (α, π) is the cost of a critical path in G(α, π), i.e., a directed path from node start to node end having maximum cost. Bold-face arcs in Fig. 1 represent a critical path. Nodes and arcs in a critical path are also termed critical. We define a critical block as a maximal subsequence of consecutive operations in a critical path requiring the same machine. Notice that with this definition, a critical block may contain more than one operation of the same job. This makes a difference w.r.t. other definitions in the literature, as for example those given in Mastrolilli and Gambardella (2000) or in González et al. (2013), and has some influence in the critical block length and neighborhood size, as we will detail later.The concept of critical block is important as most neighborhood structures proposed for job shop problems rely on exchanging the processing order of operations in critical blocks (Amico and Trubian, 1993; Mati, Dauzere-Peres, and Lahlou, 2011; Van Laarhoven, Aarts, and Lenstra, 1992). The structures proposed in Section 3.1 include moves of this type as well, but as we shall see, in the FJSP we have to introduce an additional type of move to deal with the machine assignment subproblem.To formalize the description of the neighborhood structures, we introduce the concepts of head and tail of an operation v, denoted rvand qvrespectively, which are calculated as follows:rstart=qend=0rv=max(rPJv+pPJvk1,rPMv+pPMvk)k=α(v),k1=α(PJv)rend=maxv∈PJend,k=α(v){rv+pvk}qv=max(qSJv+pSJvk2,qSMv+pSMvk)k=α(v),k2=α(SJv)qstart=maxv∈SJstart,k=α(v){qv+pvk}Abusing notation, SJstart(PJend) denotes the set consisting of the first (last) operation processed in each of the n jobs. A node v is critical if and only if Cmax= rv+ pvα(v) + qv.In this section we propose several neighborhood structures for the FJSP, some of them focus on the sequencing subproblem and so they rely on changing the processing order of operations on a machine, while others deal with the assignment subproblem, hence their moves consist in changing the machine assignment of an operation. For these structures we prove conditions of feasibility and non-improvement, and propose methods for fast estimation of the neighbors quality. We also analyze different strategies for combining these structures.We propose two structures, termed NπandNrπ,which extend some of the structures defined by Amico and Trubian (1993) to the FJSP. In both cases a neighbor is created by moving a critical operation to another position in its critical block, keeping the machine assignment. They are based on the following results.Proposition 1Let S = (α, π) and S′ = (α, π′) be two feasible schedules such that S′ is obtained from S so that it keeps the processing order of all operations in a critical path in S. Then, Cmax(S′) ≥ Cmax(S).Therefore, we will only consider changes in the processing orders of operations in a critical path to get potentially improving schedules. Let us now consider the portion of the graph in the left side of Fig. 2where all the operations of the block (v u1 … un w) have the same machine assigned and w belongs to different job than the other operations. Discontinuous arrows represent potential alternative paths. Moving w just before v (right side of Fig. 2) requires checking that none of these paths exist, otherwise there would be a cycle in the resulting graph. The following result gives a sufficient condition for no cycles.Proposition 2Let S = (α, π) be a feasible schedule and let (B′ v B w B′′) be a sequence of consecutive operations in the solution graph G(α, π) all of them assigned to the same machine, where B, B′ and B′′ are themselves sequences of operations such that any of them may be null. Let (α, π′) be a schedule created from S by moving w just before v. Then, G(α, π′) has no cycles if the following condition holds:(1)rPJw<rSJu+pSJuk1+C∧J(u)≠J(w),∀u∈(vB),where C = 0 if SMz= PJw, andC=min{pSJzk2,pSMzk1}otherwise, being z = SJu, k1 = α(SJu), k2 = α(SJz).A similar result can be proven with regards to the insertion of operation v just after w. So, we can define the following neighborhood structure.Definition 1Nπstructure. Let operation v be a member of a critical block B. In a neighboring solution v is moved to another position in B, provided that the sufficient condition of feasibility given in Proposition 2 holds.In order to reduce the effective size of the neighborhood, we propose the following condition for non-improvement, which can be efficiently evaluated.Proposition 3Let S = (α, π) be a solution and (B′ v B w B′′) a critical block in G(α, π), where B, B′ and B′′ are sequences of operations of the form B = (u1, …, un),B′=(u1′,⋯,un′′)andB′′=(u1′′,⋯,un′′′′),with n′, n′′ ≥ 1. Even if the schedule S′ = (α, π′) obtained from S by inserting w just before v is feasible, the makespan of S′ cannot be lower than the makespan of S.An analogous result can be established for a neighbor created by inserting an operation v after an operation w. Therefore, a move in Nπmay only produce an improvement in the makespan if an internal operation is moved either before the first or after the last operation of the critical block, or if an operation at the extreme of a critical block is moved to another position in the block. Hence, we can define the following reduced neighborhood structure.Definition 2Nrπstructure. Let v be an operation in a critical block B. If v is internal to B, then a neighboring solution is obtained by moving v before the first or after the last operation in B. If v is the first or the last operation in B, a neighboring solution is obtained by moving v to another position in B. In both cases, the sufficient condition of feasibility given in Proposition 2 must hold.Fig. 3shows an example where a neighbor of the schedule of Fig. 1 is created withNrπ. In this case, o23 is inserted after o32 and the makespan improves.Let us now introduce the new neighborhood, termedN2π,which extends that proposed in Van Laarhoven et al. (1992).Definition 3N2πstructure. Let v and w be consecutive operations of the same machine. In a neighboring solution the processing order of v and w is reversed, provided that the sufficient condition of feasibility given in Proposition 2 holds.In accordance with Proposition 1, many of the neighbors generated byN2πwill be non improving ones and so this structure will not be useful for tabu search. However, it may be good for path relinking, as we will see in Section 4.4.Notice that, for any of the defined structures, the order π′ of the selected neighbor can be built by reconstructing only a portion of π. For example, if the neighbor is created with Nπby inserting v after w, or by inserting w before v, the sequences of operations before v and after w in π remain in π′ (similar reconstruction is detailed in Mattfeld (1995) for the classical JSP).Changing the machine assignment of one operation may give rise to an improved schedule. This possibility was already exploited in Mastrolilli and Gambardella (2000) where the authors consider a set of moves, called k-insertion. A k-insertion assigns an operation v to a new machine Mk∈ M(v) and then looks for the optimal position for v in the machine sequence of k.We propose here a simpler and less time consuming method: given a solution S = (α, π), a neighbor is obtained by assigning a new machineMk′∈M(v)to a critical operation v. The new position for v in the machine sequence ofMk′is chosen in such a way that the topological order of the graph after the move remains identical, that is, the order π is the same after the new assignment; so ensuring feasibility. Notice that changing the machine of non-critical operations cannot produce an immediate improvement in the makespan. This structure is defined as follows.Definition 4Nαstructure. Let S = (α, π) be a schedule, let v be a critical operation and let α<v, k > be the assignment obtained from α after reassigning v to a new machine Mk∈ M(v), k ≠ α(v). Then, (α<v, k >, π) is a neighboring solution.As an example, let us consider that the operation o12 can be processed on the machine M3 in the schedule of Fig. 1. If o12 switches from M1 to M3, as o12 is after o22 in the topological order, then o12 is inserted after o22 in the new machine sequence of M3. The result is the schedule of Fig. 4, whose makespan is better than that of the original schedule.As we have done for the sequencing subproblem, we define the neighborhoodN2αto be used in path relinking. This structure is the same as Nαexcept that the operation v may not be critical.We also consider combinations of the previous structures to be used at different points of the proposed algorithm. For example, in the tabu search algorithm (see Section 4.5) it is convenient a neighborhood structure with a high chance of generating improving schedules. So, we define the following structure for this purpose.Definition 5Nrαπ=Nα∪NrπHowever, in the path relinking procedure the priority is not only to reduce the makespan but also to reduce the distance between two solutions. For this reason, some of the neighbors discarded by NαorNrπmay be very attractive in terms of distance or dissimilarity. This consideration leads us to define the following structures.Definition 6Nαπ= Nα∪NπN2απ=N2α∪N2πIn Section 4.4 we will describe how to integrate these structures in the path relinking procedure.To estimate the makespan of the neighbors created withNrπ,NπandN2πwe propose to use a direct extension of the procedure lpath given in Amico and Trubian (1993) for the classical JSP. Let (α, π′) be a schedule obtained from (α, π). In order to estimate the makespan of (α, π′), the procedure takes as input a sequence of operations requiring the same machine (x Q1…Qq y) in π′, where Q1…Qqis a permutation of the operations O1…Oqappearing as (x O1…Oq y) in π. It is important to notice that the heads of operations before x and the tails of operations after y do not change in the neighbor. So, for each i = 1…q, the procedure estimates the cost of the longest path from node start to end through Qi, and the maximum of these values is taken as the makespan estimate for the neighboring schedule. This estimate is not necessarily a lower bound. Additionally, forN2πit may happen that the processing order of critical operations is not changed, and in that case the estimate can be refined a little bit more, as it cannot be lower than the makespan of the original schedule. For additional details on the lpath procedure we refer the interested reader to Amico and Trubian (1993).Let us now discuss the estimate of the neighbors created with NαandN2α. Given a schedule S = (α, π) and an operation x with k = α(x), assigning x to another machineMk′∈M(x)produces a feasible schedule S′ = (β, π) whereβ=α<x,k′>,i.e., β(y) = α(y) for all y ≠ x and β(x) = k′. As before, the heads of the operations before x and the tails of the operations after y do not change, and the head and the tail of x after the move are given by the following expressions:(2)rx′=max{rPJx+pPJxk1,rPMx+pPMxk′}qx′=max{qSJx+pSJxk2,qSMx+pSMxk′}where k1 = α(PJx) and k2 = α(SJx). Therefore, the makespan of S′ = (β, π) can be estimated asCmaxe(S′)=rx′+pxk′+qx′. In this case the estimate is a lower bound on Cmax(S′).Additionally, in the case that x is not critical (as it may occur in theN2αstructure), the makespan cannot be lower than that of the original schedule, therefore in that case the estimate can be refined asCmaxe(S′)=max{rx′+pxk′+qx′,Cmax(S)}.In Section 5.2 we report some experimental results showing the accuracy of the proposed estimates.Scatter Search (SS) is a population-based evolutionary metaheuristic recognized as an excellent method at achieving a proper balance between intensification and diversification in the search process. SS was first proposed by Glover (1998) and it has been successfully applied to a number of problems, in particular to scheduling (González, Vela, Varela, and González-Rodríguez, 2015; Nowicki and Smutnicki, 2006; Sels, Craeymeersch, and Vanhoucke, 2011; Yamada and Nakano, 1996).The SS five-method template proposed in Glover (1998) has been the main reference for most SS implementations to date, including ours. This template consists of (1) a diversification-generation method, (2) an improvement method, (3) a reference-set update method, (4) a subset-generation method and (5) a solution-combination method.Algorithm 1starts by creating an initial set of solutions P which are improved using TS (Tabu Search). Then, a reference set RefSet is obtained selecting the best solutions from P. The algorithm stops after a given number of iterations without improvement. At each iteration, a pair of solutions from RefSet (selected according to the subset generation method) is combined using PR (Path Relinking) to generate a new solution, which is also improved by TS. Then, the reference set update method is applied. Additionally, if all possible pairs of solutions in RefSet have already been combined without introducing any new solution to the set, a diversification phase is applied. Further details on the algorithm are given in the following sections.The definition of “distance” between two solutions in the presence of flexibility is not straightforward. Although having properties of a metric is desirable, a dissimilarity measure can be quite effective without being a metric, that is, a distance (Goshtasby, 2012).In this paper we propose for the FJSP that the “difference” between two solutions S1 and S2 (denoted by d(S1, S2)) is an ordered pair of integer numbers, one representing the dissimilarity in the sequencing subproblem (denoted by dπ(S1, S2)) and the other one representing the distance on the assignment subproblem (denoted by dα(S1, S2)). The first one is an extension of the disjunctive graph distance, or Hamming distance, defined by Mattfeld (1995) for the classical JSP, as the number of pairs of operations requiring the same machine which are processed in different order in S1 and S2. This definition in the flexible case does not fulfill the triangle inequality, and then it is not a distance but a dissimilarity coefficient(Webb, 2002). Regarding the assignment distance dα(S1, S2), it is defined as the number of operations having a different machine assignment in S1 and S2.Considering these two measures, dαand dπ, we will adopt a lexicographic approach and define a precedence relation between two pairsd1=(d1α,d1π)andd2=(d2α,d2π)as follows:(3)d1≺d2⇔d1α<d2α∨(d1α=d2α∧d1π<d2π)We will use this precedence relation to compute the minimum “difference” (i.e., the maximum similarity) as min ≺(d1, d2) = d1 if d1≺d2 and min ≺(d1, d2) = d2 otherwise. The relation min ≺ can be naturally extended for an arbitrary number of elements and also the max ≺ relation can be defined accordingly.In Jia and Hu (2014), the authors define the distance between two solutions as the number of operations that are located at different positions on the coding strings. So, for a problem instance with 10 machines and 10 jobs each one with 10 operations, the maximum distance between two solutions would be 100. Hence, the PR (Path Relinking) procedure may only visit a maximum of 100 candidate solutions in the path from one solution to another. However, with our definition, the maximum dπwould be 450011In the worst case all 100 tasks are performed on the same machine, so considering that all pairs of tasks belonging to different jobs may be processed in different order in the two schedules, the maximum dissimilarity is calculated as (100 × 99)/2 − 10 × (10 × 9)/2 = 4500.and the maximum dαwould be 100. In this way, a strategy such asN2απwill allow for a fine-grain exploration of the search space.As suggested in Martí, Laguna, and Glover (2006), the reference set must contain a collection of high quality and diverse solutions. To achieve this, an initial set P is generated with PSize random solutions which are all improved using TS. Then, the reference set RefSet (of size RSSize) is built taking solutions from P one at a time such that, if possible, each solution fulfill the condition dπ(S, SRS) > MinDπor dα(S, SRS) > MinDαfor all SRSalready in RefSet, being MinDπand MinDαparameters. Firstly, half of the solutions are taken from the best ones in terms of makespan and the remaining are taken from the most distant22The distance of a solution S to a set of solutions is given by the minimum distance from S to a solution of the set.to the solutions already included in RefSet. If RefSet cannot be completed with solutions fulfilling the above condition, then the remaining ones are selected at random.For subset generation, each pair of solutions in RefSet is combined to obtain a new solution (as explained in Section 4.4), unless they have not changed since the last time they were selected together. TS is then applied to the new solution and RefSet is updated in accordance with the reference set updating method (see Section 4.6). If no new solution is added to RefSet after combining all possible pairs of solutions, the diversification process is applied: the set P is rebuilt starting with the best solution so far, and new PSize − 1 solutions are generated at random. These schedules are then improved by TS, and finally a new RefSet is obtained from P as described in Section 4.2.As solution-combination method we use PR. This metaheuristic has been successfully applied to the classical job shop scheduling problem. For example, Nowicki and Smutnicki (2005) improve their famous TSAB metaheuristic by introducing a new initial solution generator based on PR. Also, Nasiri and Kianfar (2012) combine TS and PR using two different neighborhoods.PR combines two solutions, referred to as initial (Sini) and guiding (Send) solutions, to obtain a new solution. Starting from Sini, it repeatedly applies moves so that each single move produces a solution which is closer to Sendthan the current one. In our algorithm, Siniis always the best of the two solutions taken from RefSet. In principle, the moves are those of Nαπ(see Definition 6).Let S be a solution and Sendbe the guiding solution of the PR algorithm. The following Propositions 4 and 5 detail how the dissimilarity measures change between two consecutive solutions of the trajectory, depending on the neighborhood used.Proposition 4Let Sπ∈ Nπ(S). Then, dα(Sπ, Send) = dα(S, Send)It is trivial as the neighborhood Nπdoes not change any machine assignment.□On the other hand, a single move of Nπmay reverse several processing orders of operations, hence dπ(Sπ, Send) may be several units lower or higher than, or even equal to, dπ(S, Send).Proposition 5Let Sα∈ Nα(S). Then, one and only one of the following conditions holds:•dα(Sα, Send) = dα(S, Send) − 1∧dπ(Sα, Send) ≥ dπ(S, Send)dα(Sα, Send) = dα(S, Send)∧dπ(Sα, Send) = dπ(S, Send)dα(Sα, Send) = dα(S, Send) + 1∧dπ(Sα, Send) ≤ dπ(S, Send)As Nαonly changes the machine assignment of one operation, then dα(Sα, Send) − dα(S, Send) is 1, 0 or − 1, if the operation has the same machine assigned in S and Send, or it has different assignment in Sendthan in both S and Sα, or it has the same assignment in Sαand Send, respectively.If dα(Sα, Send) − dα(S, Send) = −1, then dπ(Sα, Send) ≥ dπ(S, Send) due to the fact that any pair of operations processed in the same order and the same machine in S and Sendremain in Sαand new pairs may be processed in Sαin different order than in Senddue to the new machine assignment. Analogous reasoning can be done if the value of the expression above is 1 or 0.□From all the above, to select the next move in the PR algorithm, we start exploiting Nαπin the following way: the best solutions in each of Nα(S) and Nπ(S) in terms of distance to the guiding solution Sendare considered. Then, the best of these two solutions,Sα*andSπ*,is selected considering the estimated makespan and the proximity to Send. In order to escape from local optima, similarly to TS, a neighbor obtained by reversing recently reversed arcs or by changing recent assignments is discarded, unless it is the closest to the guiding solution found so far.Even with this mechanism, local optima may be so deep that Nαπmay have difficulties to obtain an improving move. For this reason, we have considered the less restrictive neighborhood structureN2απ(see Definition 7). Thus, as soon as Nαπfails to reach a solution closer to the guiding solution maxFails times, the neighborhood structure changes toN2απfor the remaining of the path relinking procedure33Notice thatN2απ(S)contains at least one solution closer to Sendthan S. This guarantees that Algorithm 2 finishes in a finite number of iterations.. An alternative to the above would be using onlyN2απin the path relinking algorithm. However, it is better to start using Nαπ, since it is a more refined structure which guides the path through promising neighbors, and useN2απonly to complete the path when Nαπgets stuck into local optima in terms of distance.The search finishes when the guiding solution is reached. Then, as proposed by Nowicki and Smutnicki (2006), the algorithm returns the solution with the best makespan that is located between 1/4 and 3/4 of the created trajectory, unless a solution improving the best solution so far is found out of this range.This way of building a path from the initial to the guiding solution is also quite different from that proposed in Jia and Hu (2014) and it generally builds a longer path. This can be seen in the example given in that paper where the path has only two intermediate solutions whereas our method would generate at least six.The proposed PR algorithm is detailed in Algorithm 2, where TL denotes the Tabu List, and ¬Tabu(S′, TL) means that the move from S to S′ is not in TL.As improvement method we use TS (Tabu Search). This is an advanced local search technique with a solid record of good empirical performance in problem solving, in particular in scheduling (González, Vela, González-Rodríguez, and Varela, 2013; Nowicki and Smutnicki, 2005).The general scheme of our TS is similar to that proposed in Amico and Trubian (1993). In the first step the initial solution is evaluated. Then, it iterates over a number of steps. In each iteration, the neighborhood of the current solution is built usingNrαπ(see Definition 5) and one of the neighbors is selected for the next iteration. The selection rule chooses the neighbor with the best estimated makespan, discarding suspect-of-cycle and tabu neighbors. The tabu search finishes after a number of maxImproveIter iterations without improvement, returning the best solution reached so far.Instead of storing actual solutions in the tabu list, those arcs which have been reversed or the assignments that have been changed to generate a neighbor are stored. Thus a new neighbor is marked as tabu if it requires reversing at least one arc or changing a machine assignment included in the tabu list, unless its estimated makespan is better than the best makespan found so far.The length of the tabu list is usually of critical importance, since it allows for an equilibrium between intensification and diversification. All TS algorithms try to manage this equilibrium with different proposals based on controlling the number of iterations for which a solution can keep its tabu status. We use here the dynamic length schema and the cycle checking mechanism based on witness arcs used, among others, by Amico and Trubian (1993), and extended it by adding the information about changes in the machine assignment of operations.The time given to each tabu search must be short enough for the overall computational time of the scatter search algorithm not to be prohibitive. For this reason, we do not use any more diversification techniques in the TS procedure proposed here.Let SBand SWbe the best and worst solutions in RefSet respectively. Each solution returned by PR is improved by TS. Then, for the sake of quality and diversity, the resulting solution S replaces SWeither if Cmax(S) < Cmax(SB), or if Cmax(S) < Cmax(SW) and for all SRS∈ RefSet it holds that dπ(S, SRS) > MinDπor dα(S, SRS) > MinDα.As we have mentioned, metaheuristics have been widely applied to solve the FJSP. In this work, we borrowed some ideas from existing methods and include a good number of new ones. For example, we used SS and TS templates similar to those proposed in Glover (1998) and Amico and Trubian (1993) respectively. On the other hand, the proposed neighborhood structures are quite different from other structures defined for the FJSP in Mastrolilli and Gambardella (2000), González et al. (2013), Yuan and Xu (2013). However, if we will restrict to the JSP, we could observe that some sequencing structures are in fact extensions of some classic structures: Nπextends the structure NB proposed in Amico and Trubian (1993) andN2πextends the structure H′ defined in Van Laarhoven et al. (1992). At the same time, the structure H defined in Nowicki and Smutnicki (1996) is a restriction of H′, in much the same way asNrπrestricts Nπ(removing moves for which it is known a priori that they will not improve the makespan). For the sequencing structures we established feasibility and non-improvement conditions, as well as a procedure to estimate the makespan of the neighbors, which are inspired in proposals given in Amico and Trubian (1993), Mattfeld (1995) for the classic JSP. Also, the proposed assignment structures NαandN2αare simpler and less time consuming versions of the k-insertion structure proposed in Mastrolilli and Gambardella (2000). A key point of our algorithm is the new fine grain dissimilarity measure for solutions. With this measure and the neighborhood structures NαπandN2απ,the trajectories between two solutions are much larger than, for example, those obtained from the coarse grain measure defined in Jia and Hu (2014), which allows PR to explore more solutions in each run.We have conducted an experimental study to evaluate our proposals and to compare the algorithm, termed SSPR, with the state of the art. In this study, we have considered the four benchmark sets most widely used in the literature, namely, DPdata(Dauzère-Pérès and Paulli, 1997), BCdata(Barnes and Chambers, 1996), BRdata(Brandimarte, 1993) and HUdata(Hurink, Jurisch, and Thole, 1994), making a total of 178 instances with different sizes and flexibility (the average number of possible machines per operation).SSPR was implemented in C + + and the target machine was Intel Core 2 Duo at 2.66 gigahertz and 2 gigabytes RAM. We run SSPR 10 times for each instance and register the best and average makespan. To compare different methods, we indicate whether or not a method was able to reach the best known solution for each instance and report the Relative Percentage Deviation (RPD) defined as:RPD=((Algsol−LB)/LB)×100where Algsolis the value of the objective function obtained by a given algorithm for a given instance, and LB is a lower bound on the optimal solution. We consider here the lower bounds reported in Mastrolilli and Gambardella (2000) for all 178 instances.In the next sections we report and analyze the results of our experimental study. Firstly, we describe how we have done the parameter tuning. Then, we analyze the proposed neighborhood structures and compare SSPR with its TS component running alone. In the last section, we present an exhaustive and fair comparison of SSPR with the current best methods.We have performed a preliminary study considering different values of the parameters and using similar run times for each configuration tested. Below, we summarize the parameters of the SSPR algorithm and the tested values for each one of them.RSSize defines the number of solutions of RefSet. This number is usually lower than 20, as indicated by Glover in Glover (1998). Here we tried RSSize = 8 and RSSize = 10 because these are typical values in the literature (see Nowicki and Smutnicki, 2006 and Yamada and Nakano, 1996).PSize defines the number of solutions in the initial set P. In Glover, Laguna, and Martí (2003) it is suggested that PSize = max(100, 5*RSSize). However, the diversification phase that we have proposed will need to rebuild the set P several times during an execution. As this process is computationally expensive, we considered a smaller size for P. In particular we tested sizes 20 and 100.maxFails is a parameter that defines the number of times PR chooses a non-improving neighbor with Nαπbefore switching toN2απ. We considered the values 1, 5 and 20.maxImproveIter is the maximum number of iterations without improvement in each run of TS and establishes its stopping condition. TS is embedded in the scatter search core and so it is issued many times during an execution of SSPR, for this reason we cannot choose values as high as in a TS algorithm running alone. We considered values of 100, 500, 2000 and 10,000.MinDαand MinDπare two parameters that control the minimum distance allowed between solutions in RefSet, and hence they should ensure diversity in the set. We tested values of 5, 20 and 50 for MinDπ, and values of 1, 3 and 5 for MinDα.From this preliminary study, we have chosen RSSize = 8, PSize = 20, maxFails = 5, maxImproveIter = 2000, MinDπ= 20 and MinDα= 3, as this was the combination that reached the best results in average. As stopping criterion we choose a number of 250 iterations of SSPR without improvement. This value results in reasonable convergence patterns, as shown in Fig. 5, which details the evolution of the best and average makespan using the chosen configuration for one run on the 02a instance of the DPdata benchmark. Notice the four times the diversification phase is issued with a sudden increase in the average makespan of the solutions in RefSet.To analyze the neighborhood structures we considered all instances in the HUdata benchmark. Firstly, we have evaluated the percentage of neighbors created byNrπand Nαin the TS procedure. Table 1illustrates that this percentage strongly depends on the flexibility of the instance; which is reasonable as the number of neighbors created with Nαis in direct ratio with the number of machines suitable for each operation on the critical path.Then, we analyzed the influence of the size and shape of the instances on the length and the number of neighbors of the critical blocks. The results summarized in Table 2show clearly that these values depend on the instance size but mainly on the quotient n/m. This is reasonable as for instances with few machines and many operations, critical paths most certainly go through many disjunctive arcs. We also made some experiments to compare our definition of critical block with that considered in Mastrolilli and Gambardella (2000) and in González et al. (2013), i.e., not allowing several operations of the same job in the same critical block. The results (not reported here) were slightly better with our definition as the number of generated neighbors was lower, and this fact allowed our algorithm to obtain better results in slightly less time.Finally, in order to assess the makespan estimation procedure, we have registered the actual and estimated makespan of about 300 million neighbors. Table 3summarizes the percentages of coincidences and discrepancies, in this last case showing the relative errors. As we can observe, the accuracy of the estimation is high, especially for Nα. In these experiments we have also observed that the accuracy is in inverse ratio with flexibility.It is well known that tabu search is a very efficient metaheuristic at solving scheduling problems (see for example Nowicki and Smutnicki, 2005 or González et al., 2013). Here we have carried out some experiments to assess if the scatter search with path relinking shell is capable of improving the performance of the tabu search running alone. To this end, we compared the results of SSPR with those from tabu search, giving both algorithms the same time. In the experiments, we have opted to set the same stopping criterion as in SSPR (2000 iterations without improvement), and to launch tabu search starting from random solutions as many times as possible in the time taken by SSPR. We have tried other settings with worse results for TS.We have used the DPdata benchmark for this comparison. To obtain similar run times we have had to launch tabu search from 300 to 600 times, depending on the particular instance. In 16 of the 18 instances the best makespan reached by tabu search was worse than that reached by SSPR, and in the remaining 2 instances the results were the same. The mean values are summarized in Table 4. From these results it may be fair to consider that SSPR outperforms tabu search running alone.Finally, we have conducted experiments to compare SSPR with the best algorithms we have found in the literature, namely: TS, hGA, HHS/LNS, CDDS, GA + TS, TSBM2h and MGARH from Mastrolilli and Gambardella (2000), Gao et al. (2008), Yuan and Xu (2013), Hmida et al. (2010), González et al. (2013), Bozejko et al. (2010), Gutierrez and Garcia-Magario (2011) respectively.Tables 5–7show the results of the experiments in DPdata, BCdata and BRdata benchmarks respectively. We indicate for each instance its flexibility and the lower bound reported in Mastrolilli and Gambardella (2000). Then, for each method we report the best and average (between parentheses) makespan. We also report the average runtime in seconds of a single run of SSPR. At the bottom of each table we show the average of the best and the mean RPD for each algorithm, the number of instances for which a method reaches the best known solution, and the sum of average Computer-Independent CPU time. CI-CPU time values have been obtained from the normalization coefficients of Dongarra (2013). As indicated in Yuan and Xu (2013) “it should be noted that the comparison between CPU time is meant to be indicative, because we do not have access to other information that influences the computation time, such as the operating systems, software engineering decisions, and coding skills of the programmer.”In the DPdata benchmark (Table 5) SSPR performs the best in all metrics considered, improving previous best known solutions in 13 out of the 18 instances. Notice that the mean RPD of SSPR is better than the best RPD of the remaining methods in average.The results on the BCdata set are shown in Table 6. In this case, we include the results from TSBM2h reported in Bozejko et al. (2010) and omit results from HHS/LNS, as only the average RPD for the best solutions (22.43) is given in Yuan and Xu (2013) for this data set. Overall, SSPR is the best of the six algorithms in all metrics, and improves the previous best known solution in 4 of the 21 instances.Table 7 shows the results on BRdata. This is the only table that includes results from MGARH, as this is the only set considered in Gutierrez and Garcia-Magario (2011). In this case, SSPR obtains the best known solution in all instances, it is the second best considering the average makespan and the best one considering the best makespan, as indicated by RPD values.From the CI-CPU times reported in Tables 5–7, we can observe that SSPR is the best on DPdata and BCdata. However, it appears as the worst one for BRdata due to the parameters chosen, which make SSPR to run for too long time in most of the cases. This is clear as SSPR reaches the best solution in the first iteration for most of these instances with negligible time. In Hmida et al. (2010) the authors did not provide the time taken by HHS/LNS on these instances as they consider these times not relevant for similar reasons.For HUdata set, we only report summary results of RPD (detailed results from SSPR on all benchmarks considered here are openly available on the web44Repository section in http://www.di.uniovi.es/iscop.). Table 8reports results reached by TS, hGA, CDDS, HHS/LNS and SSPR. We give the average value of the RPD of the best makespan and average makespan across each of the three subsets of 43 instances: edata, rdata and vdata. It is remarkable that the RPD values of the best and average solutions obtained by SSPR are better than those obtained by all other algorithms.Overall, for all 129 instances in HUdata, SSPR reaches a solution equal to or better than the solution given by TS in Mastrolilli and Gambardella (2000). Being the makespan of these solutions equal to the lower bound in 82 instances and lower than the upper bounds reported in Mastrolilli and Gambardella (2000) for 41 instances.Results from other methods are not included in Table 8 for different reasons. No results were given for GA + TS and MGARH in González et al. (2013) and Gutierrez and Garcia-Magario (2011) respectively. In Bozejko et al. (2010) the authors only report results for instances la01 to la15 of the rdata set, and in all cases these results are equal or worse than those obtained by TS.Summarizing, we have considered 178 instances of the FJSP and in 175 of them we have reached the best known solution. Moreover, we have found new upper bounds for 13 instances of DPdata, 4 instances of BCdata and 41 instances of HUdata.55Remember that the upper bounds we considered for HUdata are those from TS reported in Mastrolilli and Gambardella (2000) as, to our knowledge, detailed results from other methods on this benchmark set have not yet been published. So, we do not know whether or not a better upper bound was reached by other method for some of these instances.To further avail the quality of the proposed method, we have done some statistical tests to analyze differences between SSPR and other algorithms. As we have multiple-problem analysis, we used non-parametric statistical tests. First, we run a Shapiro–Wilk test to confirm the non-normality of the data. Then we used paired Wilcoxon signed rank tests to compare the medians of the RPD values between SSPR and each one of the other methods, provided that results for single instances are available, that is, we have considered the set BRdata ∪ BCdata ∪ DPdata and the methods TS, hGA, CDDS and GA + TS. In these tests, the level of confidence used was 95 percent and the alternative hypothesis was “the difference between the errors of SSPR and the method tested is smaller than 0.” The p-values obtained with these tests (TS: 4.027e − 08, hGA: 2.133e − 05, CDDS: 1.404e − 06, GA + TS: 7.364e − 04) show that there exist statistically significant differences between SSPR and the other tested methods in these benchmarks. In summary, we can conclude that SSPR is significantly better than some methods of the state of the art.

@&#CONCLUSIONS@&#
We devised a new algorithm for the flexible job shop scheduling problem with makespan minimization. The algorithm, termed SSPR, combines scatter search and path relinking with tabu search. From a thorough analysis of the problem and the schedules, we have obtained useful insights that allowed us to define some new neighborhood structures and methods to accurately estimate the makespan of the neighbors. Also, we have defined a novel fine grain dissimilarity measure for schedules. All these elements were incorporated in different components of the SSPR algorithm, which was evaluated and compared with the state of the art on the most commonly used benchmarks, showing clear improvements over existing methods in the literature considering the time taken and the makespan of the schedules together. In particular, SSPR was able to improve the best known solution in 58 of the 178 FJSP instances considered.We believe that the main reasons for the good performance of SSPR are the combination of the diversification provided by the scatter search and path relinking shell combined with the intensification provided by the tabu search, together with the fact that the neighborhoods are specifically tailored to deal with flexibility. Also, the proposed dissimilarity measure is another strong point of SSPR as it allows PR to search over paths of diverse and potentially good candidate solutions of the search space.