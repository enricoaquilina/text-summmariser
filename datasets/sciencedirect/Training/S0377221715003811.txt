@&#MAIN-TITLE@&#
Decentral allocation planning in multi-stage customer hierarchies

@&#HIGHLIGHTS@&#
Novel approach to allocate scarce resources in multi-level customer hierarchies.Applicable for decentral allocation decisions based on customer profitability.Facilitates supply chain planning, e.g. allocation planning and demand fulfillment.New application of standard econometric tools, e.g. Theil index and Lorenz curve.

@&#KEYPHRASES@&#
Supply chain management,Demand fulfillment,Allocation planning,Customer hierarchies,Customer heterogeneity,

@&#ABSTRACT@&#
This paper presents a novel allocation scheme to improve profits when splitting a scarce product among customer segments. These segments differ by demand and margin and they form a multi-level tree, e.g. according to a geography-based organizational structure. In practice, allocation has to follow an iterative process in which higher level quotas are disaggregated one level at a time, only based on local, aggregate information. We apply well-known econometric concepts such as the Lorenz curve and Theil’s index of inequality to find a non-linear approximation of the profit function in the customer tree. Our resulting Approximate Profit Decentral Allocation (ADA) scheme ensures that a group of truthfully reporting decentral planners makes quasi-coordinated decisions in support of overall profit-maximization in the hierarchy. The new scheme outperforms existing simple rules by a large margin and comes close to the first-best theoretical solution under a central planner and central information.Many manufacturing firms are faced with the problem of ensuring that their planned product supply matches customer demand. This demand fulfillment problem is often challenging since purchasing and production need to be planned with sufficient lead time. Customer demand, by contrast, is often volatile and changes over time, and not all customers are of equal importance or profitability. Hence, an up-front allocation of scarce supply to the most important customer segments is beneficial.Consider a manufacturer who makes a single, quasi-continuous product to stock (MTS) and sells it to a large number of customers via a multi-level sales and distribution system across continents, countries, and local sales areas (customer hierarchy). The constituent nodes of this hierarchy form the setN⊆Z≥0,with each nodek∈Nrepresenting a particular customer segment. The uppermost level with the root node k = 0 (representing the whole world) will be referred to as level 0. The leaf nodesl∈L⊂Nof the hierarchy will be referred to as base customer segments or simply customers. Each customerl∈Lhas demanddl∈R≥0and entails a profit per unitpl∈R≥0. Intermediate nodesi∈I:=N∖Lrepresent aggregate customer segments like countries or continents which are characterized by aggregate demanddi∈R≥0and aggregate profitabilitypi∈R≥0. This overall hierarchy setting is depicted in Fig. 1 whereDidenotes the set of (immediate) successor nodes of a nodei∈I.Besides dland plat each leaf nodel∈Lof the hierarchy also the total available supply0<S≤∑l∈Ldlis given. The focus in this paper is on the following problem: Determine allocationsxl∈R≥0to the leaf nodes l to maximize total profits∑l∈L(pl·xl)in the hierarchy, subject to the constraints 0 ≤ xl≤ dland∑l∈Lxl≤S. In addition, also specify the allocations to all intermediate nodes xifori∈I.By comparison, allocation would be easy if a central planner was available. For her, the hierarchy would be ‘flat’, i.e. she would have full information and access to all leaf node customer segments. Then, she would only consider a simple continuous linear knapsack problem comprising all leaf nodes. This problem could be solved with the greedy approach first described by Dantzig (1957), i.e. by serving the leaf nodes in decreasing order of pland by setting xl≔ dluntil running out of supply. The allocations to the intermediate nodes i would merely be a consequence which results from summing the allocations to all successor nodes in the sub-treeDi. We will consider this approach as a first-best benchmark to our original problem and refer to it as Optimal Central Allocation (OCA).In practice, there are typically multiple decentral planners present at the intermediate nodes. They only have decentralized information regarding demand and profit per unit of their immediately following nodes. Then, the allocation has to occur in a top-down manner by first setting the allocations to the intermediate nodes at the first level below the root node and then working further downwards until reaching the leaf nodes. This approach corresponds to solving a set of continuous linear knapsack problems. Since each of these resulting decentral problems is of the same type as the single problem under OCA, the same greedy solution approach can be used per individual knapsack problem. We will refer to this decentral solution approach as decentral average margin allocation (DAMA) since subsequent nodes are served in decreasing order of average profits. However, many firms even fail to exploit differences in customer profitability in such a decentral setting. They perform a mere quantity-based allocation at each intermediate node, e.g. available supply is split proportionally to demand (proportional allocation; PA).Surprisingly, this problem has not received much attention despite its preeminence in business. Most major manufacturing firms are faced with the challenge to serve a geographically dispersed customer base where margins differ and where some products are short at times. Apple Inc., for example, has repeatedly shifted its international roll-out of its tablet computer due to heavy demand and better margins in its domestic market (Paul & Madway, 2010). Roitsch and Meyr (2015) describe how a leading European refinery operator set up a hierarchical product allocation system based on DAMA to optimize margins by splitting scarce volumes between business units, sales districts and different types of contracted customers.This paper will show that these existing decentral schemes DAMA and PA leave money on the table. We present the ADA scheme under which overall profit comes very close to the first best OCA benchmark with a central planner. To the knowledge of the authors, this allocation problem in multi-stage customer hierarchies was first characterized by Vogel (2013); our paper carves out the key insights developed there. We make the following contributions:We extend the simple resource allocation problem for ‘flat’ customer segments to multi-level hierarchies and limited information transparency. To solve the resulting set of nested continuous linear knapsack problems, we propose a non-linear approximation of the total profit function in the customer hierarchy, which is otherwise piece-wise linear. The resulting approximation allows for a less data intensive, decentral representation of the allocation problem: rather than employing a central planner who requires comprehensive information from the leaves of the hierarchy, a very good allocation can be performed by a group of decentral planners who only need local data if they use our approximation function. Our new Approximated Profit Decentral Allocation (ADA) scheme helps to coordinate their decentral allocation decisions.The remainder of this paper is organized as follows: First, similarities and differences to related literature areas will be pointed out (Section. 2). Then, key model assumptions will be stated (Section. 3) and disadvantages of the existing allocation schemes will be discussed (Section. 4). In Section. 5, ADA will be derived while in Section. 6 results of numerical experiments will be reported. Last, Section. 7 contains conclusions and further research needs.Our allocation problem in multi-stage hierarchies can be related to the following research areas:Demand fulfillment and available-to-promise (ATP). Likewise, the Demand Fulfillment literature also addresses the problem which orders to serve if supplies are short. While most papers also allow customer classes to differ in terms of profitability, these classes are typically ‘flat’. Hence, hierarchical settings with distributed decision making are not modeled. For MTS environments, it is often proposed to reserve or allocate quotas (so-called available-to-promise quantities, ATP) upfront based on expected demand per customer class to be able to serve more profitable orders from higher-order customer classesupon order arrival by gradually consuming these quotas (“push-based” ATP, see Ball, Chen & Zhao, 2004). Summaries of this stream of literature can be found in Fleischmann and Meyr (2003) or Pibernik (2005). Deterministic linear programs for this ATP allocation planning and consumption logic were introduced by Meyr (2009); a first stochastic variant for ATP allocation was described in Quante (2009).Our paper adds predominantly to this literature area, not only by formalizing the ATP reservation problem in a customer hierarchy, but also by proposing a novel solution approach which is suited for distributed decision making.Revenue management. There is a close relationship between ATP and some aspects of Revenue Management (RM), hence also to our problem setting. In general, the RM literature primarily discusses pricing, capacity reservation, and overbooking to resolve shortage situations in service industries (for an overview, see Talluri & van Ryzin, 2004). Harris and Pinder (1995) were the first to apply such tactics to manufacturing environments, but especially pricing decisions are often not available in practice for the allocation planning problem in MTS settings. Ball et al. (2004) and Quante (2009) highlight that ATP allocation problems, and thus also our problem, are structurally similar to the basic RM problem of allocating a given capacity to multiple booking classes which represent different customer segments. But with most conventional RM approaches being based on a central planner, they neither consider hierarchical settings nor distributed decision making with decentral information.Capacity allocation. When implementing rule-based allocation, especially in decentral settings with human decision makers, it may turn out to be difficult to ensue that the allocation rule is being followed strictly if incentives are not aligned. This aspect may be investigated in a follow-up paper and a good starting point is the capacity allocation literature (for an introduction, see Lariviere, 2011).In contrast to our assumptions in this paper, the actual allocation scheme is taken as given in capacity allocation. This literature rather focuses on the induced behavior of the planners and proposes ways to align incentives of decentral planners. As an example consider PA, the predominant allocation scheme used in industry, which is prone to manipulation: if shortage situations can be anticipated and if higher-level sales managers in the customer hierarchy cannot verify the information they receive from planners at lower levels, the latter have an incentive to bias their demand signals upwards in order to obtain a larger allocation. This shortage gaming behavior has been shown to be a major source of the bull-whip effect in supply chains (see Lee, Padmanabhan, & Whang, 1997).Most capacity allocation papers only study quantity-based allocation without exploiting differences in customer profitability. Their setup is also different from ours by not addressing hierarchical settings.Multi-stage customer hierarchies. In fact, only few aspects of multi-stage customer hierarchies are discussed in the literature. Formal hierarchy models based on a standard mathematical tree have a long tradition in organizational economics, e.g. Radner (1992) or van Zandt (2003). Some aspects of decentral coordination and allocation problems in hierarchies are covered in the budgeting literature (e.g., see Maier & van der Weide, 1976). Today, multi-level or hierarchical planning and related allocation problems are discussed primarily in connection with Advanced Planning Systems (APS; e.g., Meyr (2012)). Often, their focus lies on aggregate production planning and related disaggregation schemes for multiple and interdependent types of resources. An early example with aggregation and disaggregation of workforce and inventory planning is Zoller (1971).Our problem is different as we only focus on one type of resource and on the problem of distributed decision making in hierarchies. Furthermore, most of the APS literature is limited to quantity-based allocation without considering customer heterogeneity (for an exception, see the oil industry case study in Roitsch & Meyr (2015)).Measurement of inequality. Yet, to effectively exploit customer heterogeneity, it is beneficial to quantify its magnitude. Determining the level of heterogeneity in a customer group is structurally identical to the problem of measuring (income) inequality. A well-known graphical depiction of inequality is the Lorenz curve which shows the proportion of income earned per share of the total population. However, most quantitative inequality measures, including the simple variance, can only be applied to hierarchical settings if a central planner has full transparency down to the leaf nodes.For decentral quantitative inequality measurements in hierarchical multi-level structures, it is desired to split total inequality into a component describing inequality within each of several hierarchically related income classes as well as into a term describing the level of inequality between them (Conceição, Galbraith & Bradford, 2001). It has been shown that only Theil’s index (Theil, 1967) possesses this additive decomposability property as well as a resulting self-similar form which permits a decentral bottom-up calculation of total inequality. In our paper, we propose to use Theil’s index to determine the level of customer heterogeneity in a multi-stage customer hierarchy with decentral planners.We simplify and refine our decentral planning problem setting with the help of the following assumptions: All leaf nodesl,l′∈Lare strictly heterogeneous withpl′≠plif l′ ≠ l. Thus, the base segments actually represent distinct customer classes with heterogeneous profits. W.l.o.g., each individual demand unit within a particularl∈Lis assumed to fetch the same profit per unit pl. Any customer segment with heterogeneous profitabilities could easily be subdivided into finer sub-segments until the within-segment heterogeneity approaches zero.Forecast errors are absent and demand dland profit per unit plare known to the decentral planner at each leaf node l who is incentivized properly to report this information truthfully to the immediate parent node.Planners at intermediate nodes at higher levels of the customer hierarchy then calculate aggregate demand and aggregate profit per unit. Aggregate demand diat nodei∈Iis simply the sum of the demands at all direct successor nodesk∈Di(1)di:=∑k∈Didk∀i∈I.Customer profitability, however, is a non-summable parameter. While several aggregation schemes are possible (e.g. using the median), an intuitive choice is to use the demand-weighted arithmetic mean to determine the aggregate profit per unit at the next higher hierarchy level. For any intermediate nodei∈I,the average profit per unit can be calculated in a recursive manner according to the following:(2)pi:=∑k∈Dipk·dkdi∀i∈I.Overall demand d0 and the average profit per unit p0 can be calculated iteratively after evaluating (1) and (2), respectively, for all other i.In our problem, only one allocation period is examined with one supply arrival and its subsequent allocations, i.e. stock-holding or backlogging are not considered. Furthermore, the timing of the arrivals of the individual customer orders within this single allocation period will be neglected. This means only the overall demand of an allocation period needs to be considered. We allow to serve each customer segment only from its own quota at the node and we prevent both “stealing” from other nodes and nesting of customer segments. This means that our setting is restricted to dedicated allocation and quota consumption.During allocation, no quantities will be retained at anyi∈I. All available quantities will ultimately be allocated to the leaf nodes. W.l.o.g., it will also be assumed that there are no minimum quotas which must be fulfilled at any leaf node.The total profit TPjattributable to allocation scheme j amounts to(3)TPj:=∑l∈Lpl·xlj,wherexljdenotes the allocation to leaf node l by allocation policy j.The following will illustrate the need for a better decentral scheme like ADA by pointing out performance issues of PA and DAMA against the first-best benchmark OCA. For convenience and w.l.o.g., instead of looking at a full hierarchy, the allocation to a sub-tree below any intermediate node i will be considered in the following. The relevant set of leaf nodes below i will be referred to asLi.Consider PA first. Below node i, all successor nodesk∈Disimply receive the same fraction of their prior demand reports(4)xkPA:=min{dk;dkdixiPA}∀k∈Di.This is repeated at each lower level until allxlPAwithl∈Lihave been determined. Since customer heterogeneity is not exploited, this low-effort scheme will be considered as the worst-case benchmark.By contrast, the DAMA scheme explicitly considers differences in customer profitability and serves successor nodes at the current and at lower levels in a greedy manner. First sort the successor nodesk∈Diin decreasing order of profit per unit pk. Then, the allocation to node k amounts to(5)xkDAMA:={dk,ifk<n*,xiDAMA−∑k′=1n*−1xk′DAMA,ifk=n*,0,ifk>n*where n* is the largest integer such that0≤xiDAMA−∑k′=1n*xk′DAMA<dn*+1.As a reference,consider applying OCA at node i. This implies that the planner has at least full information regarding the full sub-tree below i. When applied to sub-trees below the root node, the result of OCA is optimal for the allocation within that sub-tree, but not necessarily for the entire customer hierarchy. The planner at i will first determine diand pidirectly across the elements of the setLi.(6)di:=∑l∈Lidl;pi:=∑l∈Lipl·dldi.Then,xlOCAfor alll∈Lican be determined with the same greedy approach as in (5). AllocationsxiOCA,i∈I,to the intermediate nodes result from aggregation of thexlOCA.In practice, OCA (usually with i = 0) is rarely used due to its very high information requirements: If a large number of base customer segments exist, the resulting amount of detailed data points can no longer be managed by a single planner. Furthermore, managers often only have limited transparency beyond neighboring stages of the customer hierarchy. They can also only supervise reports from a limited number of subordinates effectively, e.g. to prevent them from cheating.However, using a decentral approach and turning to DAMA may lead to results which fall significantly short of the best case OCA allocation. Note that DAMA will not even be the worst case scheme. On an average, PA or a random allocation may perform worse as differences in profit per unit are ignored.To illustrate drawbacks associated with DAMA vs. OCA, a simple three-level example hierarchy is shown in Fig. 2a. Fig. 2b displays the total profit at the root node both under DAMA and OCA for a given amount of supply units S ≤ d0, where d0 = 20.The central planner under OCA serves the leaf nodes in strictly decreasing order of profit per unit. Hence, total profit as a function of the available supplies is piece-wise linear and concave (bold line in Fig. 2b). Under DAMA, the decentral planner at the root node would always serve intermediate node a up to the maximum aggregate demand da= 10 before serving the sub-tree below node b, since pa> pb. She is unaware of the marginal effect of an additional unit of supply to either sub-tree below a or b on effective total profits. Hence, total profit under DAMA falls short of the central best-case benchmark OCA for a supply 5 < S < 20 (dashed line in Fig. 2b).The left side of Fig. 3 illustrates the already familiar problem of a manager at node i who has to allocate her given supply xiamong the successor nodes inDi. When applying the OCA scheme to this sub-tree, the manager at node i is able to determine the actual piece-wise linear total profit functions πkdownstream of each intermediate nodek∈Di. πkis shown as the bold line in the right-hand part of Fig. 3.Under DAMA, πkis approximated by a simple linear functionπ¯kwithπ¯k(xkDAMA)=pk·xkDAMA(dashed line in Fig. 3). Here, only two parameters are required for each nodek∈Di: dkfor the maximum permissible allocation and pk, which corresponds to the slope of the linear function.However, this simple approximation under the DAMA scheme entails a significant aggregation error and neglects the heterogeneity of customer classes. The main idea behind ADA is to find a non-linear, continuous, and concave functionπ˜k(dotted line in Fig. 3) which provides a better approximation of πkthanπ¯k.Proposition 1π˜k,given by(7)π˜k(xk;θk):=eθkxkdk−1eθk−1·dk·pk,θk<0,is a suitable approximation of the real profit function πk.It has to be shown thatπ˜kfulfills the following properties (the superscript ADA atxkADAwill be dropped in the following):(8)π˜k(0)=0,π˜k(dk)=pk·dk,∂π˜k∂xk>0,∂2π˜k∂xk2<0.The first two properties result directly from entering xk= 0 and xk= dkinto (7). The last two properties can be verified via differentiation.□π˜krequires one additional parameterθk∈R<0(besides pkand dkcompared to DAMA) which characterizes the level of customer heterogeneity in the tree below k. For a good approximation of πk, the value of θk< 0 can be set by exploiting an analogy from the econometric relationship between Lorenz curves and income inequality. Note that the properties in (8) correspond to those of a Lorenz curve which has been flipped at the 45° line. Analytical functional specifications of Lorenz curves can be categorized by the number of parameters, with more parameters typically improving the fit to the actual distribution. To limit the amount of information to be passed on in the customer hierarchy, (7) is based on the single-parameter Lorenz curve form proposed by Chotikapanich (1993)(9)η(λ;θ):=eθλ−1eθ−1,θ>0.Here, the value of θ can be derived from the Theil indexTHwhich measures the level of inequality in populationH. By analogy, the level of customer heterogeneity Tkbelow node k in a customer hierarchy can also be determined with Theil’s index (Proposition 2), and a similar relationship leads to the parameter value for θk(Proposition 3).Proposition 2The level of customer heterogeneity downstream of any successor nodek∈Dican be quantified iteratively and decentrally via(10)Tk=∑j∈DkdjdkpjpkTj+∑j∈Dkdjdkpjpklnpjpk,withTj=0∀j∈L.This follows from applying Theil’s index of income inequality to the situation in a multi-stage customer hierarchy: consider a populationHof n individuals, indexed by h = 1, … , n, and assume that each person has an income of yh. Let g denote different income classes, letGbe the set of all income classes and letHgbe the set of individuals who belong to income class g so that each person is assigned to exactly one income class. Income class g has ngmembers (so that∑g∈Gng=n) and the average income among the persons inHgequalsμg=∑h∈Hgyhng. The average income of the entire population is thusμH=∑h=1nyhn. Within income class g, the level of income heterogeneity is defined as (Conceição et al., 2001):(11)Tg:=∑h∈Hg1ngyhμglnyhμg,g∈G.Considering the weighted sum of the inequality contributions Tg within each income class g as well as the level of income inequality among the|G|income classes leads to an iterative formula for the level of total inequalityTHin that populationH(e.g., see Conceição & Galbraith, 2000):(12)TH:=∑g∈GngnμgμHTg+∑g∈GngnμgμHlnμgμH.To calculateTH,only the aggregate values ofn,μHas well as ng, μg, Tgare required. Essentially, this permits a bottom-up calculation of total inequality across all hierarchical levels.We exploit the analogy between inequality in populationHand heterogeneity at a node k in the customer hierarchy. Substituting(13)g→j,ng→dj,μg→pj,Tg→Tj,G→Dk,n→dk=∑j∈Dkdj[from(repetitive)applicationofEq.(1)],μH→pk=∑j∈Dkpj·djdk[from(repetitive)applicationofEq.(2)]into (12) leads to (10). The size of the entire populationHcorresponds to total demand dkdownstream of node k. Each income class g corresponds to a non-root node j, which may either be an intermediate or a leaf node. In the latter case, Tj= 0 for allj∈Lsince all the demand units in leaf nodes were assumed to fetch identical profits per unit.□It remains to give the relationship between θkand Tk:Proposition 3The parameter θk< 0 in (7) is fully determined by Tk of (10). More specifically, first define(14)T(θk):=ln(θk(eθk−1))+θk(eθk−1)+θk−1.Then, the equation(15)T(θk)−Tk=0has a unique solution for θk< 0.The bijective relationship between the Chotikapanich Lorenz curve parameter θ > 0 and the corresponding Theil indexTHwas derived in Rohde (2008). For our case with θk< 0, it suffices to show thatT(θk)is strictly decreasing on the domain ( − ∞; 0), i.e. its first derivative with respect to θkis strictly negative. A formal proof can be found in Vogel (2013).□While equation (15) unfortunately does not have a closed-form solution, θk< 0 can easily be determined via standard root finding techniques, e.g. bisection.It remains to solve the allocation problem with the help ofπ˜. Consider again the decision maker from Fig. 3 at node i. To facilitate notations, it is helpful to directly index the individual nodes in this set, soDi={1,…,k,…,K}.Proposition 4Using the ADA scheme, the allocation decision at node i, Problem Φi, is equivalent to a continuous, nonlinear knapsack problem, with(16)Max.∑k=1Kπ˜k(xk)(17)subjectto∑k=1Kxk≤xi(18)0≤xk≤dk∀k=1⋯KΦi can be solved to optimality with the recursive relaxation algorithm byBitran and Hax (1981).See appendix.□To conclude, aggregation and allocation by decentral decision makers in multi-level customer hierarchies with the ADA scheme can be summarized as follows:Bottom-up aggregation.•For each leaf nodel∈L: Each planner reports truthfully the demand dl, profit per unit pl, and level of customer heterogeneity expressed as Tl= 0 to his immediate superior at the next higher level in the customer hierarchy.For each intermediate nodei∈I: Aggregate all reports dk, pk, Tkfrom all immediate successor nodesk∈Diinto di, pi, and Tivia (1), (2), (10), respectively. Unless i = 0, report these values to the next higher level.Top-down allocation using ADA.•For any intermediate nodei∈I,calculate θkfor allk∈Diusing (15) and numerical root finding. Determine the xk(k∈Di) by solving Problem Φiusing the algorithm given in the appendix.Terminate once all values xl,l∈L,have been determined.Final remarks. While DAMA derives from PA by introducing the average profit per unit as an additional parameter to the objective function of each decentral planner, ADA builds upon DAMA by also considering the sensitivity to differences in customer heterogeneity in the objective function of each planner. All parameter exchanges in the customer hierarchy relate to local information only, this makes ADA suitable for decentral decision making. Introducing customer heterogeneity into the decentral planners’ objective functions better approximates the objective function of a central planner and thus improves overall coordination.Note that the allocation specified by ADA is an optimal solution to Problem Φi, but not necessarily to the original resource allocation problem from Section 1: First, the true, piecewise linear total profit function has been approximated with the help of a continuous (flipped) Lorenz curve. Second, this approximation function was fitted to capture the level of heterogeneity in each sub-treek∈Dimeasured by Tkjust via one single parameter θk.In this section, the performance of ADA will be benchmarked against the existing schemes PA, DAMA, and OCA by varying key parameters of the customer hierarchy. Stochastic simulation will be used for this initial presentation, leaving a full factorial design and an analytical determination of properties for further research.First, assumptions regarding the test environment will be summarized (Section 6.1). In the experiments, both the level of supply scarcity (Section 6.2) and the size of the hierarchy (Section 6.3) will be varied. Furthermore, the impact of different levels of overall customer heterogeneity will be analyzed (Section 6.4).Our problem instances are characterized by a particular hierarchy size, an associated group of input data sets, and a shortage rate. We use balanced and symmetrical hierarchies with m = 3, 4, and 5 levels. Each intermediate node has the same number of descending nodes and|Di|=4(i∈I) successor nodes per intermediate node are chosen. For the three hierarchy sizes studied, this implies 16, 64, and 256 leaf nodes (|L|) and 21, 85, and 341 total nodes (|N|), respectively.Each input data set has been created with randomly generated, uniformly distributed values dland plfrom the interval [0; 100] for each leaf node, which also determines the level of customer heterogeneity. Aggregate values are calculated by repetitive application of (1), (2) and (10), respectively. In total, 100 such input data sets with random overall levels of customer heterogeneity have been generated for each hierarchy size.Supply at the root node of each problem instance is a · d0, with a ranging from 1.0 to 0.1 at a step-size of 0.1 and 1 − a denoting the shortage rate (SR).The objective of each problem instance consists of allocating the available supply to the leaf nodes of the hierarchy to maximize total profit summed over all|L|leaf nodes. Performance of PA, DAMA, and ADA will be measured with the Relative Loss of total Profit (RLP) compared to the best-case OCA scheme. Using Eq. (3), RLPjfor allocation scheme j is given by(19)RLPj:=1−TPjTPOCA.Unless noted otherwise, the average RLPjcalculated over the 100 randomly generated input data sets per hierarchy using allocation policy j will be reported, referring to this metric as ARLPj. Where appropriate, we indicated plus/minus one std. deviation of ARLPjvia error curves or error bars.Since DAMA allocates based on aggregate average profitπ¯k,it can be expected that the performance advantage of ADA increases with the actual shortage rate. In practice, weak shortages often result from temporarily increased demand (e.g. seasonal products). Medium shortage rates can be attributed to raw material supply restrictions and severe shortage rates of up to 100 percent may result from sudden plant outages.As a starting point, assume a three-level hierarchy and perform decentral allocation using PA, DAMA, and ADA. For each allocation scheme and each input data set, different levels of supply scarcity will be tested by varying the shortage rate between 0 percent and 90 percent. We report ARLP per allocation scheme and shortage rate in Table 1. Fig. 4displays the same data as well as the respective ARLP value plus/minus one standard deviation.As expected, all decentral allocation schemes fall short of the OCA benchmark, since the ARLP values are positive. Independent of the level of shortage, ARLP is highest for the quantity-based allocation scheme PA. Not surprisingly, there is indeed a performance advantage to be gained by explicitly considering (aggregate) profits per unit in the allocation decision under DAMA and ADA. ADA outperforms both PA and DAMA, indicating a significantly better allocation, as the ARLP values remain small and on an average below 5 percent for the problem instances in the three-level hierarchy. Furthermore, the variance is significantly smaller than under DAMA and PA.This simulation confirms the expectation that the benefits from ADA generally increase with the level of shortage. However, it is interesting to note that the relative gap between ADA and DAMA in terms of ARLP narrows at very high levels of shortage ( ≥ 80 percent). This can be explained with the ‘all-or-nothing’ allocation under the DAMA scheme at high shortage rates. In most cases, only one successor node (the one with the highest aggregate profitability per unit) will receive an allocation at each allocation step under high supply scarcity, while the nodes with smaller aggregate profitabilities do not receive any quantities at all. Once the leaf nodes have been reached, only a small number of them are ultimately served, but these are among the more profitable ones, and the profit loss to an optimal scheme is comparably small. This effect can also be observed for the small example hierarchy of Fig. 2a. Its total profit curve (Fig. 2b) coincides for DAMA with that for OCA for supplies of up to five units, i.e. shortage rates ≥ 75 percentThus, from a managerial point of view, intelligent allocation as done by ADA seems less important in the extreme situations of very low or very high shortages. However, it is of particular practical relevance in the ‘standard’ case of medium shortages.We argued earlier that decentral allocation is relevant especially for hierarchies with many nodes. Given limitations on effective span of control, many hierarchy levels may be needed. In practice, sales organizations often have up to five levels (root node, continent, country, sales district, sales area). This experiment is to test the assumption that explicit consideration of customer heterogeneity in rather large hierarchies improves the advantage of ADA over DAMA and PA.We report ARLP for the ADA, DAMA, and PA allocation schemes and a three, four, and five-level hierarchy, assuming shortage rates of 20 percent and 90 percent. Choosing both a rather low and a particularly high shortage rate was motivated by the results of the first experiment. Here, performance differences between the schemes first gradually increased with the level of shortage and then, in the case of DAMA compared to ADA, became smaller again for extreme levels of shortage.The results are depicted in Fig. 5, with error bars depicting plus/minus one standard deviation. Regardless of the hierarchy size and the shortage level, the performance of ADA is again best, followed by DAMA. For both profit-based schemes, ARLP increases with the size of the hierarchy. Things are different for the quantity-based PA scheme. There is only little variation between the ARLP values for the three-level and the five-level hierarchy at both shortage rate settings. These small differences in ARLP observed are due to the performance of the optimal OCA scheme for the different input data sets. Consider Eq. (19): The purely quantity-based PA scheme will on an average result in total profits ofTPPA=d0·p0·(1−SR)for each input data set, which is unaffected by the hierarchy size. By contrast, TPOCAis strongly related to the distribution of the randomly drawn values of the profit per unit and demand per leaf node in each individual input data set.This simulation confirms the intuition. The usage of ADA only leads to comparably small losses in optimality which are almost independent of the hierarchy size. The advantage over DAMA increases with the number of hierarchy levels. ADA manages to direct scarce resources highly accurately to their most profitable usage even over a rather extended sequence of decentral decisions. This is obviously not the case for DAMA – at a shortage rate of 20 percent, its advantage to the purely quantity-based scheme PA falls from16.1−5.0=11.1percentage points for the three-level hierarchy to16.5−13.4=3.1percentage points for the five-level hierarchy.We justified the need for a new decentral scheme with the desire to exploit differences in customer heterogeneity in customer hierarchies, expecting ADA to perform significantly better than DAMA and PA with increasing levels of heterogeneity. Lacking sufficient real-world data regarding actual differences (and corresponding values of T0), we will at least perform a simulation experiment to illustrate the magnitude of the effects.The test setting is similar to the first experiment. Since each of the 100 randomly generated input data sets implies a certain (random) level of customer heterogeneity in the customer hierarchy, the latter will be measured with Theil’s index at the root node of the hierarchy (T0). Rather than reporting ARLP over all 100 input data sets, we now present a scatter chart of the relative profit loss (RLP) for each individual input data set.Recall from the first experiment (Fig. 4) that the std. deviation of the DAMA results is significantly wider than for the other two decentral schemes. While on an average, DAMA performed strictly worse than ADA, some DAMA results were at least as good as ADA for rather low and for very high shortage rates. In these cases, the lower std. deviation line of DAMA overlaps with ADA in Fig. 4. Hence, to better focus in this experiment on the correlation between customer heterogeneity and resulting ARLP and to distinguish the three decentral schemes more clearly in the scatter plot, we chose a shortage rate of 50 percent where the difference of the average performance between the three decentral schemes can be expected to be highest.In Fig. 6, RLP is shown for each input data set, with the horizontal axis corresponding to the associated value T0 at the root node.This more disaggregate illustration clearly shows the cost under PA of not considering differences in profitability if the customer hierarchy is very heterogeneous. This graph also shows that the performances of the profit-based schemes ADA and DAMA do not seem to correlate with the level of customer heterogeneity. But, as in the previous experiments, not only is the relative profit loss to OCA smallest for ADA on an average over all input data sets for any given range of customer heterogeneity. Also its variation is significantly smaller. Overall, this simulation experiment again confirms the expectation that the advantage of ADA over other decentral schemes increases with T0.This paper addresses the problem of allocating scarce supply in a multilevel customer hierarchy in which customer segments differ in terms of demand and profitability. This problem is trivial for an omniscient central planner, but not if multiple subsequent allocation decisions need to be made by decentral planners at the intermediate nodes, as in many sales and distribution hierarchies.The proposed ADA scheme for this setting not only outperforms the existing decentral allocation, but also comes close to the best-case result made of a central planner. ADA is particularly helpful if the level of shortage is medium (its benefit increases with the degree of shortage, but may decrease for extremely high shortage rates), if there are many levels and thus nodes in the hierarchy, and if the leaf nodes of the hierarchy are characterized by a high degree of heterogeneity in terms of profits per unit. With truthfully reporting individuals, the main benefit of the new scheme is better coordination: It ensures that decentral planners with decentral information make decisions which are significantly more consistent with the overall objective of profit maximization than existing schemes.The findings in this paper are subject to some simplifying assumptions. Relaxing them leads to the following model enhancements which may be studied as part of future research:If input data is subject to forecast errors, it may be beneficial to update the allocation at regular intervals, e.g. to benefit from an improved forecast accuracy and to incorporate possible additional supply arrivals. Under a nested consumption strategy, highly profitable orders could be served by ‘stealing’ from neighboring lower-profitability leaf nodes in case their own quotas have already been depleted (see the Revenue Management literature). Furthermore, conditions should be established to ensure that each decentral planner has proper incentives to properly apply ADA, in particular to send truthful reports. This has two aspects: First, in contrast to proportional allocation where biased reports have obvious effects on the overall allocation, under ADA, lying with respect to dk, pk, and Tkhas complex interdependent effects which are difficult to anticipate. Second, the suitability of common compensation schemes, e.g. profit sharing, to ensure truthful reporting by the decentral planners needs to be established.Another next step is to verify the experimental results in several case studies to understand the parameter ranges which are relevant in practice, in particular evaluating the actual range of customer heterogeneity in different industries.Problem Φiconstitutes a non-linear optimization problem with a concave objective function, which is additively-separable in the xk. With shortage situations and di> xi, constraint (17) will be fulfilled with equality by an optimal solution. This type of problem belongs to the class of continuous, nonlinear knapsack problems; a recent review is in Patriksson (2008).Bitran and Hax (1981) introduced a recursive relaxation procedure and proved that it leads to an optimal solution. Their main insight is to solve a series of relaxed problems which do not contain individual bounds on the variables xk, i.e. (18) will initially be ignored. Each relaxed problem is then a rather simple non-linear optimization problem with an explicit solution. If any of the resulting optimal allocationsxk☆of the relaxed problems violate the upper or lower bound of the original Problem Φi, thesexk☆can be fixed at either the upper or lower bound, respectively. Then, the corresponding optimal allocations to these nodes have been found, and the respective nodes are not required in any subsequent iteration of the procedure. Subsequent iterations proceed in the same manner, albeit with a reduced size of the relaxed problem. The algorithm terminates after at most K iterations with an optimal solution to Φiif in any subsequent iteration a solution vector of the reduced relaxed problem has been found where none of the original upper and lower bounds are violated. In the following, first the relaxed problems will be described in more detail and it will be shown how to derive the explicit solution. Afterwards, the entire recursive procedure can be stated more formally.Solution to the relaxed problem: The relaxed problem, referred to as ProblemΨi(J,ξ),derives from Problem Φiby making following four changes:1.Constraints on the lower and upper bounds (18) are deleted.Linear constraint (17) has to hold with equality.Allocation to a subsetJof the successor nodes is considered, i.e.J⊆Di={1,2,…,K}. As a shorthand notation,n=|J|for the number of elements inJ.Available resources xiin (17) are replaced by ξ.ProblemΨi(J,ξ)thus has a concave objective function and linear constraints, i.e.(20)Max.∑k=1nπ˜k(xk)s.t.∑k=1nxk=ξ.Necessary and at the same time sufficient conditions for a feasible solutionx= (x1, … , xn)Tto be an optimal solution are given by the Karush–Kuhn–Tucker (KKT) conditions (provided a few technical regularity conditions are simultaneously satisfied). As only a single linear constraint is present in ProblemΨi(J,ξ),the KKT conditions simplify to(21)π˜k′(xk)−λ=0∀k=1,2,…,n,(22)∑k=1nxk−ξ=0,with an unknown Lagrange multiplierλ∈R. Obtain for theπ˜k′in (21) with (7)(23)π˜k′(xk)=θk·pkeθk−1·e(θkxkdk),θk<0,∀k=1,2,…,n.(21) and (23) imply(24)θk·pkeθk−1·e(θkxkdk)=λ,k=1,2,…,n.It is easy to show that for θk< 0,π˜k′(xk)>0for all k = 1, 2, …, n. Hence, λ > 0 due to (24) and(25)lnθk·pkeθk−1+θkdkxk=lnλ,k=1,2,…,n.Rewrite (25) as,(26)ak·xk−bk=−xn+1,k=1,2,…,n,with abbreviations(27)ak=θkdk,bk=−lnθk·pkeθk−1,xn+1=−lnλ.Together with the linear constraint from (22), a non-homogeneous system of linear equations in n + 1 unknowns is given by,(28)a1x1−b1=−xn+1a2x2−b2=−xn+1⋮anxn−bn=−xn+1x1+x2+⋯+xn=ξ.The explicit solution to (28) is as follows:(29)xi=bi−xn+1ai,i=1,…,n,ξ=∑i=1nbi−xn+1ai,hence, these x can be computed by:(30)xn+1:=∑i=1n(biai)−ξ∑i=1n1aiandxi:=bi−xn+1ai,i=1,…,n.Summary. Following Ibaraki and Katoh (1988), the relaxation procedure for Problem Φican now be summarized as follows:1.Initialize ProblemΨi(J,ξ)by setting the parameters of Problem Φi, i.e.J:={1,…,K}and ξ ≔ xi.Solve problemΨi(J,ξ)with the approach outlined above to obtain a set of solutionsx^swiths∈Jand determine the following sets and values:(31)J+:={s∈J|x^s>ds},J−:={s∈J|x^s<0}(32)Δ+:=∑s∈J+(x^s−ds),Δ−:=−∑s∈J−x^sIf allx^sare already within the bounds given by (18), an optimal solution for all elements inJhas been found. Then setxs☆:=x^s∀s∈Jand abort the procedure. Else, if Δ+ ≥ Δ−, the optimal value for all xswiths∈J+is at the upper limit; setxs☆:=ds∀s∈J+and adjust both the set of variables in scopeJ:=J∖J+as well as the constraintξ:=ξ−∑s∈J+ds. If Δ+ < Δ−, the optimal value for all xswiths∈J−equals zero; setxs☆:=0∀s∈J−and adjust the set of variables in scopeJ:=J∖J−. Return to step 2 for an additional iteration with at least one variable less in scope.

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
