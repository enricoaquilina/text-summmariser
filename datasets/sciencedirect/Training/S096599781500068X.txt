@&#MAIN-TITLE@&#
Computerized control system and interface for flexible micromanipulator control

@&#HIGHLIGHTS@&#
A GUI for commercial micro- and nanomanipulators was developed.Multiple control options include point-and-click movement and mouse following.Tip detection using image processing corrects for the manipulator’s error.The GUI provides faster and more accurate control even for inexperienced users.

@&#KEYPHRASES@&#
Automation,Computer interface,Graphical user interfaces,Image processing,Micromanipulators,Microactuators,

@&#ABSTRACT@&#
Micro- and nanomanipulators are essential for a broad range of applications requiring precise micro- and nanoscopic spatial control such as those in micromanufacturing and single cell analysis. These manipulators are often manually controlled using an attached joystick and can be difficult for operators to use efficiently. This paper describes a system developed in MATLAB to control a well-known, commercial micromanipulator in a user friendly and versatile manner through a graphical user interface (GUI). The control system and interface allows several types of flexible movement controls in three-axis, Cartesian space, including single movements, multiple queued movements, and mouse-following continuous movements. The system uses image processing for closed loop feedback to ensure precise and accurate control over the movement of the manipulator’s end effector. The system can be used on any electronic device capable of running the free MATLAB Runtime Environment (MRE) and the system is extensible to simultaneously control other instruments capable of serial communication.

@&#INTRODUCTION@&#
Micro- and nanomanipulators provide the ability to maneuver and position micro- and nanoscale objects to precise locations and orientations. Used in conjunction with optical and electron microscopes, these ultrahigh-precision positioning instruments enable functions critical for many micro- and nanoscale applications, such as manufacturing and biomedicine. In manufacturing, manipulator systems have been employed to automate the maneuvering and positioning of small objects in order to produce patterns, structures, and devices. For example, Cappelleri et al. developed caging grasps for micro assembly capable of accurately positioning micro objects using an array of probes [1,2].In biomedicine, manipulators are commonly utilized to maneuver and position small probes inside living cells and tissue. Cell injection is a large area of research; Wang et al. developed a method of carrying out cellular injection using probes at a high rate and with minimal user intervention [3]. Grippers are used in addition to pipettes for biological applications. For example, Kim et al. developed a nanonewton microgripper to analyze the properties of biomaterials [4].The goal of micro- and nanomanipulator automation is to create a system requiring only minimalistic intervention, optimally none, to carry out a specific desired function. In this way, automation of predefined tasks increases precision and throughput while reducing variability and time. Most automation requires computer vision algorithms to access the position of manipulation targets. Wang et al. also developed high-throughput automatic injection systems and demonstrated their use on zebrafish embryos [5–7] and contributed image processing techniques for injection automation [8]. Mattos et al. developed image processing techniques to improve their automated injection process of blastocyst cells [9–13].However, situations exist, especially in the development and utilization of new tools and techniques, where the automation and control of these manipulators, and other related equipment, needs to be flexible and adaptable. For example, in our own work towards developing carbon nanotube (CNT)-based probes for single cell analysis [14–20], micro- and nanomanipulators are routinely used to maneuver the functional end of the probes in order to interface with single living cells in an undetermined manner, often requiring on-the-fly repositioning or customized movements based on qualitative visual feedback. Here, the tips of CNT-based probes are manually maneuvered in Cartesian space by the manipulator’s joystick and positioned within the intracellular environments of single living cells under an optical or fluorescence microscope to perform functions or analysis with tertiary instruments.New probe-based single cell analysis techniques, as well as traditional cell physiology techniques such as patch clamp electrophysiology, involve continuous interactions with multiple instruments simultaneously. The user is required to often switch attention and focus between the microscope, the micro- or nanomanipulator, tertiary instruments (e.g. electrophysiology amplifier), and computer screen (often displaying the field of view from a microscope camera and/or graphical user interface of tertiary instruments), making the work difficult and laborious. Although many commercial microscopes and tertiary instruments come equipped with some form of graphical user interface (GUI) for use on standard computer workstations, no such interface has been provided for micro- or nanomanipulator control. Moreover, no interface exists as an expandable platform for the inclusive control of multiple instruments.The purpose of this paper is to present a new system layout developed in MATLAB to provide an intuitive and accessible GUI for micro and nanomanipulator control through a standard computer workstation. Through the GUI, a user with minimal prior knowledge can directly control the manipulator or select from customizable control functions for real-time control with a mouse. The system and GUI can be adapted to multiple applications with relative ease and configured to include control over additional instruments as needed. The computer-based system is intended to provide a user-friendly, expandable control platform for micro- and nanomanipulators over a wide range of applications in both research and education.A typical configuration for performing micro- or nanomanipulator operations, as shown in Fig. 1, was used to develop the Manipulator Control system. The system consists of four primary components: a manipulator and its control unit (Eppendorf TransferMan NK 2), a microscope (Zeiss Observer.A1m), a camera (Point Grey Chameleon), and a computer (Dell with Intel Core i5-2400 @ 3.1GHz) to interface with all of the controllable components. The software was developed in MATLAB R2011a. The microscope is mounted on a vibration isolation table in order to minimize detrimental vibrations during manipulation operations. The computer and manipulator controller are located near the microscope but separated from the vibration isolation table. Each system component is a commercially available device with no hardware modifications.While each of the system components can be reasonably interchanged and the control software adapted to the new equipment, the current implementation assumes a number of things about each of the components. The camera must be a device recognizable by MATLAB, which requires that it provide video information and accept computer commands through MATLAB’s Image Acquisition Toolbox. This restriction prevents cameras with proprietary communication protocols from being used with the GUI. The camera utilized in this particular hardware configuration was selected because the manufacturer provides control drivers, which specifically allow for open interfacing. There are however many microscope cameras which use restrictive or proprietary communication and control schema. To access information from more restrictive camera systems, it would be necessary to run a separate executable from the control software or develop device drivers which can allow MATLAB to interface with the camera.The control scheme of the manipulator controller and its method of digital communication are critical to the design of the GUI. The selected control unit utilizes an absolute positioning system, wherein all movement commands sent to the manipulator are interpreted as a request to place the needle tip at the specified location in three-dimensional space by travelling at a specified velocity along each axis. The control software is designed to generate movement commands according to this control scheme. However, coordinate information is maintained both for the current position of the needle and the movement location, so that it would be possible to extend the software to support a manipulator which utilizes a relative positioning system. Additionally, the means by which the system is calibrated has been managed in such a way that it could be readily adapted to a relative positioning system. The manipulator selected has a range of travel of approximately 20mm along each axis and can travel at up to 7.50mm/s. The finest possible resolution of movement is approximately 40nm. This allows for sufficient movement of the manipulator tip over a wide range of magnifications while also providing fine resolution for accurate manipulations at high optical magnifications. The Eppendorf TransferMan control unit is programmed to receive serial communication. Besides movement commands and coordinate requests, the control unit can receive commands to perform a number of other functions including connecting and disconnecting or toggling between manual and computerized control.The schematic view of the system, shown in Fig. 2, illustrates the flow of information between components. The host computer controls the manipulator and camera using the control program developed in MATLAB. The computer interfaces with the manipulator controller over the serial port and with the camera over a USB port. Information from the camera is sent to the computer, which sends and receives commands to the manipulator controller, and visual feedback from the movements is visible through the camera. In this way, a closed loop is created in the system. The microscope used for developing the software does not have any form of computer control, so this aspect of the system is not directly managed by the host software. More sophisticated commercial microscope systems do exist which provide programmatic control of the X, Y, and Z stage position.Program flow is broken into three primary components: initialization, main loop execution, and termination. Program initialization consists primarily of the creation of the main control window and all of the control mechanisms for each of the graphics objects. After the end of the program initialization step, the graphics object is fully defined and the program enters the main loop.The main loop of the program, shown in Fig. 3, acts as a control scheme and continuously queries the graphics object for the current state of information. Given a change in the state of the graphics object, reference functions are called to carry out different actions based on the observed update in the state of the system. Such system changes are generated by user input in a variety of means. An example of this process might be the user pressing an interface button, which results in the execution of a callback function, which acts as an interrupt at the current point of program execution. In general, these callback functions can be executed at any time, but one callback cannot interrupt another callback. Within the callback, some element of the system is updated, such as changing the state of a figure object’s value. The main loop then observes this update in the figure object when a check function is called. This check function is contained within the GUI object class and is used to observe the current state of some part of the system, possibly as newly updated by user input.The hierarchy of program flow, as shown in Fig. 3, is established to allow for multiple control schemes. The main loop has multiple sub-procedures that are invoked differently depending on which control scheme is currently active. In the loop, the system checks for movement, updates the tip coordinates, updates the graphics displays and restarts. If the user terminates the program, the loop terminates and the shutdown procedure is called. The series of movement checks in the main loop is the aspect of the program that enables control of the manipulator, and is designed in such a way as to allow multiple control schemes.The first type of control checked in the movement cycle is continuous movement control, which allows for intuitive user control of the manipulator. In this control scheme, the program continually monitors the position of the mouse in the control window and sends commands to the manipulator to move to the queried position. This control scheme does not use any image processing feedback in order to provide real-time control with minimal movement and command lag. It does not check for completion of movements, so that the move command always corresponds to the exact desired position, without requiring completion of a possibly outdated command.The second type of movement control checked in the main loop is driven by a series of user-specified point movements, which can be generated in a number of ways as described in the User Interface Layout section. This type of movement checks that the previous movement has been completed before starting the next movement. Furthermore, if feedback is enabled, the software adjusts the end effector position before the next move is loaded such that its observed position falls within a pre-defined distance from the commanded position. This is accomplished through loading the currently defined movement again using a new coordinate transform, which utilizes the calculated position data generated by tip detection in a proportional feedback control scheme.In the design of the GUI layout, the major requirements were to provide convenient access to all of the GUI’s functionality while maintaining an easy-to-learn and easy-to-use interface. To meet these requirements, the layout was designed to mimic the layouts found in common computer applications. As such, the GUI’s largest component is the main viewing area that displays the microscope image, while the GUI’s functions are accessible using buttons surrounding the viewing area and options are contained in a drop-down menu. The GUI, as shown in Fig. 4, allows for easy and quick control of the manipulator while providing visual feedback. The GUI window is broken into four regions: the menu and three control panels (Image Display, Manipulator Control, and Image Control). The menu is used to configure the video display and manipulator connection, along with providing logging control options. The Microscope Video dropdown provides controls for the zoom level, the camera utilized (as selected from an automatically generated list of available connected cameras), and management of various properties for the field of view display. The manipulator dropdown allows the user to select the port over which to establish serial communication with the manipulator (the list of available ports is automatically generated based on the detected available ports).The largest control panel is the Image Display Panel, and acts as the primary control region for the system. The video feed from the selected camera is displayed on this panel, and it is here that the user generates coordinates for manual movement commands. The panel to the right of the display panel is the Image Control Panel. This region contains the capture camera sub-panel and is used to initialize the camera connection, as well as capture camera images and initialize camera recording. Also contained in this panel is the tip detection sub-panel, where the user can configure and load the template image and scanning parameters. This is also where the user can start tip detection and modify the feedback parameters.The panel at the bottom of the GUI is the Manipulator Control Panel. This panel provides Manipulator Controls and is broken into three sub-panels. The leftmost sub-panel is dedicated to displaying coordinate data for each of the possible frames. The data in this panel is continuously updated based on operational mode. The middle section of the Manipulator Control Panel contains all of the movement controls. The left column of buttons and controls are used for connecting to the manipulator and configuring the movement speed and vertical step size (used in continuous movement control). The vertical step size represents the distance in micrometers that the end effector will move when the user scrolls the mouse wheel one tick or presses the up or down arrow key on their keyboard. This is also where the user can enable feedback control if tip detection is enabled. The right column provides a set of different movement types, which includes six different button types, which will be described below. The rightmost section of the Manipulator Control Panel is currently empty but has been reserved for future expansion. The small panel along the bottom of the figure is used to provide system feedback to the user, indicating what is currently being done by the system or describing the type of input the user needs to provide.The sequence of events to initialize control of the system using the GUI is as follows:1.System is started and user configures video feed and manipulator connection using the menu controls.User connects to the camera using the Image Control Panel and to the manipulator using the Manipulator Control Panel.User positions the end effector under the microscope’s field of view by physically positioning it or using the Eppendorf manipulator’s manual controller.With all connections established and calibrated, the user can now carry out manipulation tasks.The movement control sub-panel of the Manipulator Control Panel contains six different movement control schemes:1.Manual Calibrate XY Center: Prompts the user to indicate the location of the tip in the field of view. This information is used to define the image-manipulator transformation, using a purely translational model. After obtaining the transformation, the tip is moved to the center of the image. This process can be carried out whenever the operator desires to calibrate the GUI and the hardware systems, and should only need to be carried out once each time the system is initialized.Preconfigured Movement: Prompts the user to select an excel spreadsheet file containing a series of Cartesian coordinates. These coordinates are loaded into the program as a list of movement commands to be immediately executed by the manipulator.Single Move: Prompts the user to select a point in the camera field of view. The tip is moved to that point.Return to Zero: Returns the tip to the center of the image.Multi-Move: Prompts the user to specify a series of points using mouse clicks. When the user is finished and presses the “Enter” key, the manipulator moves to each of these points in series.Continuous Move: This is a toggle-able control scheme for Manipulator Control. While active, the tip of the manipulator is continuously driven to the currently detected mouse position within the field of view. This is done by repeatedly polling the current position of the mouse and sending the detected position as movement command to the manipulator. The system does not check that the last movement is completed, so that it is possible to smoothly control the device. In this scheme, movement is bounded by the field of view of the Image Display Panel. This scheme does not use feedback, even if enabled, in order to minimize response delay and provide the user the same “feel” as if using the manipulator joystick.Manual XY calibration is necessary because some manipulators, including the Eppendorf TransferMan NK 2, allow manual adjustments to the probe that are not measured by the device. For example, setting the probe to a different approach angle will change the tip’s location relative to the manipulator’s actuators. Once the XY position is calibrated, no other calibration is required because the movement scale factor is automatically calculated by the software using information such as camera resolution, Image Display Panel size and zoom level. The user only needs to ensure that the GUI is set to the correct zoom level and scaling calibration is handled automatically to further maintain ease-of-use.The interface allows for other simple commands for ease-of-use purposes. All movements can be immediately stopped by pressing the “Esc” key. Another movement cannot be started while a previous movement is still being executed. The movement speed affecting all movement types can be changed at any time between movement commands. This movement speed, adjustable in the GUI, represents the maximum movement speed in micrometers/second that the end effector will be moved. When Continuous Move is enabled, the tip can be moved more slowly if the user moves their mouse slower than the specified speed and if the mouse is moved abruptly the end effector will follow at the set speed. This limit is useful if the user wishes to limit the speed of objects being manipulated.

@&#CONCLUSIONS@&#
