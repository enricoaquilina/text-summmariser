@&#MAIN-TITLE@&#
Hybrid weighted bit flipping low density parity check decoding

@&#HIGHLIGHTS@&#
Multiple erroneous bits corrected per iteration.Lower decoding complexity compared to existing parallel algorithms.Percent reduction in decoding iterations ≈45%.Percent reduction in decoding time ≈40%.No degradation in error correcting performance.

@&#KEYPHRASES@&#
Bit flipping (BF),Error correction codes,Low density parity check codes (LDPC),Parallel bit flipping,

@&#ABSTRACT@&#
Graphical abstract

@&#INTRODUCTION@&#
Belief propagation (BP) decoding algorithms like sum-product (SP), min-sum, and normalized min-sum (NMS), allows low density parity check (LDPC) codes to exhibit performance close to the Shannon limit [1–6]. Despite their excellent performance BP based LDPC decoders are often criticized for their large memory requirements. The standard bit flipping algorithm is simpler in computation, but may lead to significant performance loss in terms of bit error rate (BER). To reduce the computation complexity without significant loss of error correcting performance, weighted bit flipping (WBF) and improved modified-WBF (IWBF) LDPC decoding schemes were proposed [7,8]. Reliability ratio based-WBF (RRWBF) decoding method was proposed to further improve the BER performance [9]. Implementation efficient RRWBF (IRRWBF) decoding was proposed to reduce the number of computation in RRWBF decoding without affecting its decoding performance [10]. However, due to their serial nature these bit flipping decoding methods converge slowly. Parallel bit flipping method were introduced for reducing the decoding latency [11–17]. These parallel decoding methods often rely on using a pre-defined threshold of number of bits to be flipped in each of their iterations. These thresholds are often dependent on signal-to-noise ratio and must be changed based on the signal transmission conditions. This signal condition adaptive response requires additional computation and resources.In this paper, Hybrid Weighted Bit Flipping (HWBF) LDPC decoding scheme is proposed. Initially the proposed scheme acts as parallel bit flipping algorithm. As the decoding progresses the number of erroneous bits is reduced and the proposed de3coding method starts behaving like serial bit flipping decoding. Therefore, the proposed decoding method is termed “Hybrid”. The method of finding the most un-reliable bit positions is similar to the IRRWBF decoding. This is done to reduce the number of initial computations to a minimum. The number of bits flipped in parallel is then computed based on the row and column weight of the parity check matrix. The relation between the error terms is used to find the number of erroneous bits that can be corrected in parallel. Based on this relation, the proposed scheme can detect and correct a maximum of 3 erreneous hard decision bits in an iteration. When the amount of error is reduced, the number of bits flipped in parallel is also reduced to avoid flipping the non-erroneous bits. It is shown that the number of bits flipped in parallel is adaptive with respect to SNR.It is shown that, as compared to IRRWBF decoding, the number of iterations required for successful decoding is reduced by more than 50% with the use of proposed HWBF decoding. The proposed decoding algorithm was simulated using LDPC code specified in 802.11n wireless communication standard [18]. The simulation result shows that the error correcting performance of the proposed codes is superior to that of original IRRWBF decoding for the same number of decoding iterations. With the same decoding performance, the number of iterations is reduced and hence, the total decoding time of the proposed HWBF LDPC decoder is smaller as compared to IRRWBF. The key features like smaller decoding time, high throughput and acceptable BER performance, increases the importance of the proposed design for implementing LDPC decoders in energy conservative mobile environments.In this manuscript, following convention are used to denote the variables, matrices and constants. Variables: Lowercase, italic text with lowercase subscripts, e.g.,imx. Matrices: Uppercase and bold text, e.g., H is the parity-check matrix. Constants: Uppercase and italic text with italic text subscripts, e.g.,Wcdenotes column weight (number of non-zero entries per column). The symbols used in IRRWBF decoding algorithm are summarized in Table 1.In LDPC codes, K bit information vector is encoded to generate N bit codeword. After mapping the codeword using suitable modulation techniques like BPSK, the codeword is transmitted. The received vector, r, is noise added version of codeword. The received vector is converted to binary equivalent hard decision vector,zn, by threshold comparison operation. In standard LDPC BF decoding, received vectors participate in a check process, where the syndrome is calculated (Appendix A). All the un-satisfied check sends the “flip” signal to the hard-decision vector or the variable node they are associated with. The bit flipping algorithm then modifieszn; flipping one bit at a time using some pre-defined criterion; until all the syndromes of the modifiedznbecomes zero. The error correcting performance of standard bit flipping method is much inferior to its message passing counterpart and hence, it is not suitable for practical applications.During the initialization step, the standard weighted bit flipping (WBF) algorithm, finds the most unreliable message node associated with each check node computation. The probability of hard decision bit,zn, being valid, is determined by the absolute value of its soft value. In each check node computation, the message node with smallest absolute value is considered most unreliable. The decoding processes commonly employ variable node analysis where the syndrome vector is combined with some form of weight vector to generate an error vector [6,7]. This information is then used to compute the error contributed from each check node to the variable node. The hard decision bit associated with largest value in the error vector is flipped. This procedure is repeated till a valid codeword is found or the number of iterations has reached a maximum value. In the improved weighted bit flipping algorithm (I-WBF), modifications are made to calculate the error term when different message nodes have same probability of being flipped [8]. In such condition, the message node with lower value of absolute magnitude,|rn|is flipped (Appendix B). This is achieved by an additional term in error correction based on a weighting factor, α, which has to be optimized for each value of SNR. The value of α is not computed mathematically and hence, requires assumption and approximations based on a particular environment. This can severely degrade the decoding performance.The dependence on weighting factor was removed in reliability ratio based weighted bit flipping (RRWBF), by introducing a reliability ratio, normalized by factor β, while computing the error termEn[9] (Appendix C). Rest of the decoding algorithm is same as the standard weighted bit flipping algorithm. To reduce the computation steps and the decoding time, the computation of β was replaced by computing the initialization vectorTm[9], in implementation efficient RRWBF (IRRWBF) [10] (Appendix D). The operations performed at each stage in ith iteration are shown in Table 2. The initialization step is performed only once and hence, it is independent of iteration number. In every iteration, only one bit is flipped in decision step, therefore the convergence is slower due to the serial nature of IRRWBF.The standard bit flipping algorithm and its variant flip one bit in each of its iteration and therefore, converge slowly. In real time systems, fast convergence is essential for small decoding time and high throughput. In [11] and [12] multiple bits were flipped in parallel for reducing the decoding latency. In the first approach, the number of “flip” signals associated with each variable node is counted and all the variable nodes with total “flip” signals above a threshold are flipped. In this case, the threshold has to be re-calibrated with change in signal-to-noise ratio. In the second approach, the geometry of the parity check matrix was used to determine the number of variable nodes that are flipped in parallel. The number of bits flipped in parallel is given by total number of un-satisfied checks divided by column weight,Wc, of the parity check matrix. In [13], an improved parallel bit flipping algorithm (IPWBF) was proposed based on bootstrapping and delay-handling procedure to delay flipping of high reliability bits. In all the above mentioned methods, a set of check nodes associated with un-satisfied check are flipped in parallel. In the parallel bit flipping methods discussed above, the faster convergence is obtained with higher computation complexity and in some cases, with degradation in error correction performance.In IRRWBF bit flipping algorithm, the error vector computed in the variable node step of IRRWBF decoding can be arranged in ascending–descending order to find a set of most un-reliable variable nodes. Amongst this set of most un-reliable nodes, pre-defined number variable nodes can be chosen and the associated hard decision bits can be flipped. As the signal-to-noise (SNR) increases, the number of unreliable bits decreases and hence, the number of hard decision bits that must be flipped should be reduced. Assuming that p bits are flipped in parallel, the actual number of erroneous bits will be less than p for high SNR value. Hence, the number of bits flipped in parallel bit flipping algorithm must be adaptive to SNR. In a real time system, estimation of SNR can lead to additional latency, lowering the overall throughput. Instead, the row and column characteristics of parity check matrices can be employed to determine the exact number of bits that can be flipped in parallel.The number of operations required for finding the largest value in the error vector, in a set of N error terms, is given byN−1. One operation is required to find the hard decision bit associated with largest value in the error vector. Hence, N operations are required in decision step of IRRWBF decoding as shown in Table 2. Using additional p operations, a set of sorted maximum error terms with p elements can be constructed. Let this set of maximum error terms be given asEn,max:(1)En,max={En,1,En,2,En,3,…,En,p′,…En,p}where,En,jdenotes that the nth error term in the variable node vector,Eni, and is the jth largest error term.En,1is the largest error term in the error vector andEn,1>En,2>En,3,…>En,p′…>En,p;1⩽p′⩽p.Similarly, let the set of hard decision bits associated with each of the elements of set of maximum error terms,En,max, be given aszn,max:(2)zn,max={zn,1,zn,2,zn,3,…,zn,p′,…zn,p}where,zn,p′denotes that the hard decision bit associated with(p′)th error term,En,p′, in set of maximum error terms,En,max.In the decision step of standard IRRWBF decoding,zn,1associated withEn,1is flipped. If the flipping ofzn,1does not affect the other values of setEn,maxthe next largest error term will beEn,2. Similarly, if flipping ofzn,2does not affect the other values of setEn,maxthe next largest error term will beEn,3. In effect, the values ofzn,1andzn,2can be flipped in parallel. In a similar fashion, it can be assumed that if all the elements of set of maximum error terms,En,max, are independent of each other, then all the p elements ofzn,max, can be flipped in parallel. In case the elements of setEn,max, are related, flipping of some of the elements in setzn,max, will affect the other elements of the set. Hence, such element must be excluded from parallel flipping. Therefore, in a generalized case, the relation between the elements of setEn,max, must be established to determine which elements in setzn,max, can be flipped in parallel.The nth error term is associated with nth hard decision bit. The column weight of the parity check matrix, H, can be used to determine the number of check nodes or the syndrome elements connected with a given error term or the hard decision bit. Hence, nth error term is associated withWc,nnumber of syndromesm, elements. To understand the co-relation between the elements of set of maximum error terms,En,max, the relation between different error terms under different erroneous hard decision bit condition, must be considered. The relation can be developed by using the geometric properties of the parity check matrix, like row and column weight related with specific error conditions.Let eth,(e′)th and(e″)th hard decision bits be erroneous inzn. Each erroneous hard decision bit will produce some non-zero syndrome values in the check node step of IRRWBF. For the ith iteration, the set of check node with non-zero syndrome values connected with one or more erroneous hard decision bit amongst eth,(e′)th and(e″)th hard decision bit, be given asC(e),C(e′)andC(e″), respectively. Similarly, let the set of check nodes connected only to eth,(e′)th and(e″)th hard decision bits be given asC′(e),C′(e′)andC′(e″).In the variable node step of IRRWBF decoding, the non-zero syndrome values combined with initialization vectors will produce positive values in some of the elements of error vectorEn. The error terms associated with eth,(e′)th and(e″)th erroneous hard decision bits can be given as(Ee)th,(Ee′)th and(Ee″)th elements of error vectorEn. For simplicity, it can be assumed that(Ee)th>(Ee′)th>(Ee″)th. Hence,(Ee)th,(Ee′)th and(Ee″)th are same asEe,1,Ee′,2andEe″,3in the setEn,max.For the ith iteration, let eth,(e′)th and(e″)th erroneous hard decision bits be associated withWc,e,Wc,e′andWc,e″non-zero syndrome values in,smi. Let number of check nodes connected to all three erroneous hard decision bit, eth,(e′)th and(e″)th hard decision bit be given asWc,e∩e′∩e″. Let number of check nodes connected only to eth and(e′)th and not to(e″)th, be given asWc,e∩e′. Similarly, the nodes connected only to(e′)th and(e″)th/ethand(e″)th, will be given asWc,e′∩e″/Wc,e∩e″. Let the number of check nodes connected only to a single erroneous node be given asWc′,e,Wc′,e′andWc′,e″.The check node computations are modulo-2 sum or XOR operation between the input elements. For a correct code word, the check nodes always evaluates to zero after XOR operation. In XOR operation even number of non-zero inputs evaluates to zero output. Hence, if the even numbers of inputs for any check node computations are erroneous, the final check node output will remain zero which is same as original. In other words, the check nodes connected to even numbers of erroneous bits will remain zero, while those connected to odd numbers of erroneous bits will be non-zero. Check nodes corresponding toWc,e∩e′,Wc,e′∩e″andWc,e∩e″, also corresponds to check nodes connected to even numbers of erroneous bits and hence, will remain zero. On the other hand, check nodes corresponding toWc,e∩e′∩e″also corresponds to check nodes connected to odd numbers of erroneous bits and hence, will become non-zero. The check nodes connected only to a single erroneous node will also be non-zero. Letϕxbe the number of check nodes connected only to x number of erroneous bits. Hence, the number of check nodes connected only to 1 erroneous bit is given as(3)ϕ1=Wc′,e+Wc′,e′+Wc′,e″where,(4.a)Wc′,e=Wc,e−Wc,e∩e′−Wc,e∩e″−Wc,e∩e′∩e″(4.b)Wc′,e′=Wc,e′−Wc,e′∩e−Wc,e′∩e″−Wc,e∩e′∩e″(4.c)Wc′,e″=Wc,e″−Wc,e″∩e−Wc,e″∩e′−Wc,e∩e′∩e″However, sinceC(e)∩C(e′)=C(e′)∩C(e),C(e)∩C(e″)=C(e″)∩C(e)andC(e′)∩C(e″)=C(e″)∩C(e′), we haveWc,e∩e′=Wc,e′∩e,Wc,e∩e″=Wc,e″∩eandWc,e′∩e″=Wc,e″∩e′. Hence, (3), can be re-written as:number of check nodes connected to a single erroneous node only,φ1, is given as(5)ϕ1=(Wc,e+Wc,e′+Wc,e″−2×(Wc,e∩e′+Wc,e∩e″+Wc,e′∩e″)−3×Wc,e∩e′∩e″)number of check nodes connected to all three erroneous nodes,ϕ3, is given as(6)ϕ3=(Wc,e∩e′∩e″)Based on the parity check matrix geometry, letUybe an estimate of the number of unsatisfied check nodes or the non-zero syndrome bits because of the y number of erroneous hard decision bits. Hence, estimated number of un-satisfied check nodes (3 erroneous hard decision bits),U3(7)U3=ϕ1+ϕ3=(Wc,e+Wc,e′+Wc,e″−2×(Wc,e∩e′+Wc,e′∩e″+Wc,e∩e″+Wc,e∩e′∩e″))LDPC codes are commonly defined by the Tanner graph, where the girth is defined as the length of smallest cycle in the graph. The relation between the decoding error performance and the girth of parity check matrix has been well established in the existing literature [1–7,19–22]. In [1–7,19–22], it was shown that for good decoding performance, the LDPC parity check matrices must be free from cycles of length 4. In other words, any two given columns cannot have more than one common non-zero element. Hence, if either ofWc,e∩e′,Wc,e′∩e″orWc,e∩e″is non-zero,Wc,e∩e′∩e″will become zero. Similarly, ifWc,e∩e′∩e″is non-zero,Wc,e∩e′,Wc,e′∩e″andWc,e∩e″will become zero. It can also be seen that the maximum value ofWc,e∩e′,Wc,e′∩e″,Wc,e∩e″andWc,e∩e′∩e″is 1.Let only two hard decision bits, eth and(e′)th be erroneous. Hence,C(e″)can be assumed as empty set andWc,e″,Wc,e∩e″,Wc,e′∩e″, andWc,e∩e′∩e″will become zero. Therefore, it can be shown that the estimated number of un-satisfied check nodes for two erroneous hard decision bits can be given as(8)U2=(Wc,e+Wc,e′−2×Wc,e∩e′)Similarly, the estimated number of un-satisfied check node for single erroneous hard decision bit, eth, can be given as(9)U1=Wc,eIn Section 3.1, it was concluded that if all the elements of set of largest error terms,En,max, are independent of each other, then all the p elements ofzn,max, can be flipped in parallel. In other words, it can be concluded that a set of p un-related erroneous hard decision bits can be flipped in parallel. Further, in previous section, the relation between the number of unsatisfied check nodes and the number of erroneous bits was established using (7), (8) and (9). Conversely, this relation can be used to determine the number of erroneous hard decision bits which can be flipped in parallel.Based on the received vector, r, let the actual number of unsatisfied check nodes (the number of non-zero check nodes) be given byWu. If the actual number of unsatisfied check nodes,Wuis equal to the estimated number of unsatisfied check nodes,U1, using (9) it can be conclude that, there is only one erroneous bit orp=1. Hence, with only one erroneous hard decision bit, flipping only the first element in setzn,maxwill reduce the syndrome to all zero vector and produce the corrected codeword. In this case, the decision step is identical to the original IRRWBF decoding method.IfWu≠U1, using (7) and (8), it can assumed that there are more than one erroneous hard decision bits. IfWu(actual value)=U2(estimated value), using (8), it can be concluded thatp=2. Similarly, ifWu(actual value)=U3(estimated value), using (7), it can be concluded thatp=3. IfWu(actual value)≠U1orU2orU3(estimated value), it can be assumed that there are more than three erroneous bits, and in this case, it can be assumed thatp=3. The hard decision bits associated with the p largest error terms can be flipped in parallel, which will reduce the syndrome to a vector with all zero elements, and produce the corrected codeword.From the above discussion, it can be concluded that for small SNR values the number of erroneous bits will be large and the proposed decoding method will flip more number of bits in parallel similar to existing parallel bit flipping decoding methods. Due to improvement in SNR, the number of erroneous bits will decrease and the proposed decoding method will flip smaller number of bits eventually flipping just one bit per iteration similar to existing serial IRRWBF decoding method. Hence, in a way the proposed decoding method is a “Hybrid” of parallel and serial bit flipping decoding. Fig. 1shows the steps performed in the proposed HWBF bit flipping algorithm. Based on the relations developed between the number of erroneous hard-decision bits and the unsatisfied check nodes (actual and estimated), the proposed scheme can detect and correct a maximum of 3 erreneous hard decision bits in an iteration. Actual number of bits flipped and correct in parallel is determined by the relation between the estimated and actual number of unsatisfied check nodes.The proposed HWBF decoding comprises of initialization, check node, variable node and decision step. The initialization step is performed once and requiresMWrcomputations. The check node step is performed every iteration and requiresMWrcomputations in first iteration and requiresWcoperations in each iteration thereafter. The variable node is also performed every iteration and requiresNWccomputations in first iteration and requiresWrWcoperations in each iteration thereafter. The proposed HWBF decoding computes the largest error term in the decision step.Therefore, in proposed HWBF decoding, the total number of operations required till decision step when only one largest error term is calculated, is given asOp=[2MWr+NWc+Ni+Wc(i−1)(1+Wr)]Since,MWr=NWc; and in generali≫1; andWr≫1(10)Op=[3NWc+i(N+WcWr)]Using the most significant digit (MSD) sorting-based methods, the next two largest error terms can be determined with a maximum of N operations. Hence, the construction ofEn,maxwith three elements will require additional N computations. The computation ofU1,U2, andU3requires the computation ofWc,e∩e′,Wc,e′∩e″,Wc,e″∩e,C(e∩e′),C(e′∩e″), andC(e″∩e). For analytical purposes, it can be assumed that on an average the column weight isWcandWc,e=Wc,e′=Wc,e″≈Wc.C(e∩e′)is computed by comparing two sets ofWcelements and, hence, will requireWccomparison operations. Therefore, the computation ofC(e∩e′),C(e′∩e″), andC(e″∩e)requires a total of3Wccomparison operations. The computation ofU1,U2, andU3requires six addition and two subtraction operations. Therefore, the total number of operations required in the proposed algorithm,Op, is given by(11)Op=[3NWc+i(N+WcWr)]+(N+3Wc+8)(i)Op=[3NWc+i(2N+WcWr+3Wc+8)]The number of bits flipped in each iteration dictates the number of iterations taken for convergence and the actual decoding complexity. Therefore, the total number of computations is equalized with respect to the number of bits flipped in each iteration. For the proposed decoding scheme, three bits are flipped per iteration in the best case scenario, and one bit is flipped per iteration in the worst case scenario. Hence, for correcting i erroneous bits,i/3and i decoding iterations are required in the best and worst case scenario respectively. On an average,2×i/3decoding iterations are required for correcting i erroneous bits. Let the number of operations required for correcting μ number of erroneous bits in proposed HWBF decoding be given byOp(μ)respectively. Therefore, from (11)(12)Op(μ)=[3NWc+(2i/3)(2N+WcWr+3Wc+8)]For i iterations, the total number of computations,Oc, in IRRWBF decoding is given by [23,24]Oc=[2MWr+NWc+Ni+Wc(i−1)(1+Wr)]In general,i≫1andWr≫1; therefore [22,23],(13)Oc=[3NWc+i(N+WcWr)]In the IRRWBF decoding algorithm, i decoding iterations will be required to correct i erroneous bits. Let the number of operations required for correcting μ number of erroneous bits in IRRWBF be given byOc(μ). Therefore, from (13)(14)Oc(μ)=Oc=[3NWc+i(N+WcWr)]Using (12) and (14), it is evident that when compared with the IRRWBF decoding method, the proposed HWBF decoding requires1/3×[N+Wc(Wr+1)+16]more operations per iteration. However, the small increase in computation complexity as compared to serial IRRWBF, significantly reduces the number of decoding iterations and the total decoding time in proposed HWBF decoding.The decision step in the parallel BF decoding methods consists of finding the error terms above a pre-defined threshold. To find the number of bits flipped both the modified improved weighed bit-flipping algorithm, MIWBF [12] and IPWBF [13] require M additions and one real division (to calculate p), and [(p−1)N−p(p+1)/2+1] more real comparisons for each iteration when compared with the standard BF algorithm. Here, M is the number of rows in H andM=N−K; K is the number of message bits; and p is the number of bits flipped in parallel. To flip three bits in parallel, i.e.p=3, MIWBF and IPWBF requires [3N−K−4] additional computations. However, as shown earlier, the HWBF decoding requires only [N+3Wc+8] additional computations as compared to IRRWBF decoding. In [6] the relation between Min–Sum (MS) decoding and serial and parallel BF decoding is presented. In [7], it is shown that the parallel BF decoding has smaller computation complexity as compared to MS decoding. Fast Weighted Bit Flipping Algorithm (FWBF) [17] uses the same decoding procedure as MIWBF and uses additional operations to achieve multiple bit flipping for reducing the number of iterations. Since, the number of computations is proposed HWBF decoding is less than MIWBF, it can be concluded that proposed HWBF decoding requires lesser number of computations as compared to FWBF decoding. Hence, for the same number of decoding iterations, the number of operations required in the HWBF decoding is less than any parallel decoding method.

@&#CONCLUSIONS@&#
