@&#MAIN-TITLE@&#
A single machine scheduling problem with two-dimensional vector packing constraints

@&#HIGHLIGHTS@&#
A single machine scheduling problem with two-dimensional vector packing constraints is considered.A recovering beam search approach and a matheuristic procedure are proposed.The combination of the two approaches reaches the best results.Seven new bounds were obtained on the original 2-constraint vector packing instances.

@&#KEYPHRASES@&#
Scheduling,Two-dimensional vector packing,Recovering beam search,Matheuristics,

@&#ABSTRACT@&#
We consider a scheduling problem where jobs consume a perishable resource stored in vials. It leads to a new scheduling problem, with two-dimensional jobs, one dimension for the duration and one dimension for the consumption. Jobs have to be finished before a given due date, and the objective is to schedule the jobs on a single machine so that the maximum lateness does not exceed a given threshold and the number of vials required for processing all the jobs is minimized. We propose a two-step approach embedding a Recovering Beam Search algorithm to get a good-quality initial solution reachable in short time and a more time consuming matheuristic algorithm. Computational experiments are performed on the benchmark instances available for the two-dimensional vector packing problem integrated with additional due dates to take into account the maximum lateness constraints. The computational results show very good performances of the proposed approach that remains effective also on the original two-dimensional vector packing instances without due dates where 7 new bounds are obtained.

@&#INTRODUCTION@&#
Scheduling problems are well studied in the literature since the 1950s and several books and recent review papers show the wide variety of problems considered today (Brucker, 2007; Hartmann and Briskorn, 2010; Pinedo, 2012; Ruiz and Vázquez-Rodriguez, 2010). In the same way, bin packing and vector packing problems have received a great attention in the literature and some survey papers are dedicated to these problems (De Carvalho, 2002; Lodi, Martello, and Vigo, 2002). In this paper, we introduce a new category of scheduling problems where vector packing constraints have to be considered together with the scheduling problem. These packing constraints are known in the literature as two-dimensional vector packing constraints (the problem may also be called two-constraint bin packing problem). We can refer to (Alves, de Carvalho, Clautiaux, and Rietz, 2014; Caprara and Toth, 2001; Garey, Graham, Johnson, and Yao, 1976; Spieksma, 1994) for resolution methods of this problem with m dimensions.The origin of the problem comes from the production of chemotherapy drugs for cancer treatment by intravenous injection. In (Mazier, Billaut, and Tournamille, 2010), the authors describe this particular production environment and present a resolution method for a static or dynamic environment. In this production environment, the jobs to perform are called “preparations” and the raw materials are called monoclonal antibodies (“products” in the following). The monoclonal antibodies bind to specific cancer cells and induce an immunological response against the target cell. These products can be stored in vials for a long time before use, under specific storage temperatures and conditions. For some antibodies, freezing at − 20 degree Celsius or − 80 degree Celsius in small aliquots is the optimal storage condition. However, once a vial is opened or once the active agent has been mixed with a solute, it must be used before a given time limit, in order to keep intact the properties of the anticancer active agents. The maximum delay of use after opening depends on the agent and may vary between several hours to several days. In the meantime, the product has to be stored in a freezer or in a fridge for temperature and darkness reasons. If the time limit of use is exceeded, the monoclonal antibodies have lost their properties and they have to be destroyed according to a specific process. In other words, the time period between the starting time of the first preparation using a product in a vial and the completion time of the last preparation assigned to the same vial cannot be greater than the life time of the product. Furthermore, without loss of generality we assume that the total consumption associated to one vial cannot be greater than the total volume of the vial and we also assume that two different vials cannot be assigned to the same preparation. We have here the two dimensions of the vector packing problem.The cost of these products is very important. In Tours, the UBCO production center (described in Mazier et al., 2010) produces around 150 preparations per day. A preparation has an average cost of 400 euros, but it can reach 15,000 euros in certain cases. It is clear that the saving of these products may have an economic impact, absolutely not negligible. In the problem that we consider, one objective function is related to the waste of products, which we want to minimize. Notice that in such a context, the deadline for the use of the raw material becomes a variable of the problem, which is directly related to the production scheduling decisions: each time the life duration or the capacity of the vial is exceeded, a new vial is opened. Another version of this problem has been studied in Billaut (2011) and Billaut, Esquirol, and Tournamille (2011).Furthermore, because each preparation has to be delivered to a patient for a given due date, another objective of the problem is to minimize the maximum lateness related to these due dates.The same type of problem arises in concrete production because once prepared, the concrete has to be used within a given amount of time. Similarly, in food production, after the food is out of the freezer, it has to be used within a given time limit. Another possible application of this study arises for the resources management in the cloud environment (Padhy and Patra, 2013). For cloud providers, the problem is to allocate resources dynamically in the form of virtual machines to end users. Each task needs a virtual machine, i.e. a given quantity of RAM and of CPU. The tasks assigned to a resource cannot require more RAM and more CPU than the available quantity. Our problem, while different, presents also some similarities with parallel batch scheduling problems. But to the best of our knowledge, the problem that we consider in this paper has never been considered in the literature before.The paper is organized as follows. In Section 2, the notations are introduced and the problem is formally defined. An MILP model is given. In Section 3, a recovering beam search and a matheuristic algorithm are proposed. These methods are tested on two dimensional packing benchmark instances, with due dates considerations and without due dates, for a comparison with methods dedicated to this problem. The results presented in Section 4 show that the proposed methods have very good performances, even without due date considerations. In this latter case, 7 new bounds are obtained with respect to the available literature. Section 5 presents the conclusions and some future research directions.We consider a simplified version of the problem of chemotherapy drugs production, assuming that there is only one machine and only one type of product (raw material). We have a set of n jobs to schedule on a single machine. To each job Jj∈ {1, …, n} is associated a processing time pj, a consumption bjand a due date dj. Without loss of generality, the jobs are supposed to be numbered in EDD order, i.e. d1 ≤ d2 ≤ ⋅⋅⋅ ≤ dn. The life duration of the product after opening is equal to T and the volume of one vial is equal to V. We assume without loss of generality that pj< T and bj< V, ∀j, 1 ≤ j ≤ n. The number of vials is not limited but supposed to be bounded by n. We denote by Cjthe completion time of Jj, Ljthe lateness defined by Lj= Cj− djand the maximum lateness is defined by Lmax  = max 1 ≤ j ≤ nLj. We assume that the maximum lateness is bounded by a given value Q.(1)Lmax≤QWe also assume that the remaining quantity of product in the last opened vial is lost at the end of the time horizon. Therefore, minimizing the quantity of lost product is equivalent to minimizing the number of vials that are opened. That is the reason why the problem is a mix between a scheduling problem and a two dimensional vector packing problem. Without due dates (or with extremely large due dates), the problem is exactly a two dimensional vector packing problem and thus clearly strongly NP-hard. With a big value of T and a big value of V, the problem is the classical single machine problem with the Lmax  minimization. In the following, we call a bin, the set of jobs performed with the same vial. It is well known from the literature (Spieksma, 1994) that a trivial lower bound on the number of bins is the following:(2)LB=max(⌈∑j=1npj/T⌉,⌈∑j=1nbj/V⌉).We illustrate the problem by a numerical example.We consider a set of six jobs, T = 10 and V = 10.j123456pj344531bj125314dj7911131416Schedule (J1, J3, J5, J2, J4, J6) is represented in Fig. 1. In this two dimensional Gantt chart, a job Jjis represented by a rectangle with the duration pjon the x-axis and the consumption bjon the y-axis. Jobs of the same bin are connected by the south-west corner of the rectangle. The first job of a bin is put on the x-axis. In Fig. 1, one can see that job J1 is the first job of the bin composed by jobs {J1, J3, J5} and job J2 is the first job of the bin composed by jobs {J2, J4, J6}. Job J2 cannot be included in the first bin because the duration of this bin would exceed T. The maximum lateness of this sequence is equal to Lmax  = max ( − 4, 5, −4, 6, −4, 4) = 6 and this schedule requires two bins. Notice that schedule (J1, J2, J3, J4, J5, J6) is optimal for the Lmax , but requires three bins (see Fig. 2).Proposition 1In a bin, the jobs are scheduled in EDD order.This condition is clear because the order in a bin does not modify the number of bins that are used, and tends to improve the Lmax  value.We now propose an MILP formulation of the problem where the aim is to minimize the number of bins, assuming that the Lmax value is bounded.We denote by uk∈ {0, 1} a boolean variable equal to 1 if bin k is used, and 0 otherwise and by xj, k∈ {0, 1} a boolean variable equal to 1 if job Jjis assigned to bin k, and 0 otherwise. The problem can be formalized by a binary linear program as follows.(3)minimize∑k=1nuksubject to(4)∑k=1nxj,k=1,∀j∈{1,…,n}(5)∑j=1npjxj,k≤Tuk,∀k∈{1,…,n}(6)∑j=1nbjxj,k≤Vuk,∀k∈{1,…,n}(7)∑h=1k−1∑i=1npixi,h+∑i=1jpixi,k≤dj+Q+M(1−xj,k),∀j∈{1,…,n},∀k∈{1,…,n}(8)uk+1≤uk,∀k∈{1,…,n}Constraints (4) ensure that each job is performed by using one vial (is assigned to one bin). Constraints (5) and (6) correspond to the temporal and capacity limits. Constraints (7) suppose that job Jjis in bin k and correspond to the bound on the Lmax :∑h=1k−1∑i=1npixi,his the completion time of the k − 1th bin,∑i=1jpixi,kis the completion time of job Jjin its bin (remember that the jobs are numbered in EDD order). Constraints (8) ensure that the bins are used in their index increasing order. This model contains n(n + 1) binary variables and n2 + 4n constraints.Two original resolution methods are proposed for solving the problem. The first one is a recovering beam search algorithm and the second one is a matheuristic algorithm.The Beam Search algorithm is a truncated branch-and-bound method where a subset of w nodes at each level are selected for branching. w is called the beam width. This method was first proposed in Ow and Morton (1988). For the selection of nodes, each node is evaluated by a combination of a lower bound (LB) and an upper bound (UB), generally a weighted sum V = (1 − α) LB + αUB. Because the selected nodes are not necessarily the best at a given level of the tree, among the set of possible nodes of a pure branch-and-bound algorithm, a recovering phase is applied in the Recovering Beam Search (RBS) algorithm. The aim of this phase is to recover from wrong decisions jumping to a better node at the same level of the search tree. For a detailed description of RBS we refer to Della Croce, Ghirardi, and Tadei (2004). Fig. 3illustrates the exploration of the tree in RBS with a beam width of 2.The RBS method has already been successfully used in the literature for solving scheduling problems (Della Croce et al., 2004; Dong, Huang, and Chen, 2009; Esteve, Aubijoux, Chartier, and T’kindt, 2006; Ghirardi and Potts, 2005; Rakrouki, Ladhari, and T’Kindt, 2012; Valente, 2010). In order to apply the RBS approach, it is necessary to specify its main components, namely: branching scheme, lower bound, upper bound and recovering step. In this problem, a node of the search tree is defined by a partial sequence S(σ) of the set σ of scheduled jobs, a setσ¯of unscheduled jobs, a lower bound LB(σ), and an upper bound UB(σ).At the root node, the initial sequence of unscheduled jobs is determined as follows. Starting from the EDD sequence, the following steepest descent algorithm is used to reduce the number of bins, without violating the constraint on the Lmax. In a first phase, the job in position k = n is swapped with the smallest job among its predecessors (the job Jjwith minimum pj× bjvalue), if it is feasible, and then the process iterates with the job in position k − 1. In a second phase, the job in position k = n is inserted in a bin scheduled before, that can accept it without violating the bounds and without violating the feasibility constraint. And the process iterates with the job in position k − 1.The branching scheme is the typical n-ary branching: the sequence is constructed by adding one job at a time starting from position 1 and the search tree is such that a node at level k indicates which is the job placed in position k. For the lower bound computation, we denote by Bin(S) a function that computes in O(n) time the number of bins used by a partial sequence S and the sum of jobs processing times and of jobs consumptions in the last bin (respectively called RestP(S) and RestB(S)). Algorithm 1provides the lower bound value computed at a generic node of the search tree.Basically the lower bound is the trivial lower bound expressed by Eq. (2) updated in order to take into account the set of bins already filled by the partial sequence.For the upper bound computation, Algorithm 2provides the upper bound value computed at a generic node of the search tree, where a partial sequence S(σ) has already been defined. LetSfather(σ¯)denote the sequence of the jobs inσ¯obtained by keeping for these jobs the same order they had in the upper bound of the father node in the search tree. Also, letS(σ)//Sfather(σ¯)denote the concatenation of subsequences S(σ) andSfather(σ¯).The rationale here is to keep for the jobs inσ¯the same order they had in the previous branch of the search tree (in other words, the order of the unscheduled jobs is the same as in the root node at lower levels of the tree). If the sequence provided by the upper bound computation is unfeasible, then, UB(σ) = ∞ and correspondingly the related search tree node is discarded. The evaluation of a node is given by V(σ) = (1 − α)LB(σ) + αUB(σ). Preliminary testing indicated that best results were obtained with α = 0.2. Typically, there is a huge number of solutions with the same value of upper and lower bounds. In order to make a difference between solutions having the same value at a level of the tree, a second-level evaluation has been used. Let us define the “surface of a bin”, denoted by Surf(k), as follows:Surf(k)=∑Jj∈BkpjbjWhenever two sequences have the same value of V(σ), we break ties by selecting the sequence with the smallest surface of the last bin.The recovering phase is composed by two types of neighborhood called SWAP and EBSR (extraction and backward shift reinsertion) (Della Croce et al., 2004). Consider two jobs Jiand Jjin S(σ) = π1Jiπ2Jjπ3, with Jibefore Jj. SWAP generates sequence π1Jjπ2Jiπ3 and EBSR generates sequence π1JjJiπ2π3. More precisely, considering a node S with a sequence σ of scheduled jobs and a sequenceσ¯of unscheduled jobs, for any job Jiin σ, and for any job Jjinσ¯,the SWAP operator is tested, and the best feasible neighbor improving UB(σ) is kept. Then, after this phase, the EBSR operator is applied for any job Jiin σ and for any job Jjinσ¯and again, the best feasible neighbor improving UB(σ) is kept. No further attempt is made after applying EBSR operator.Matheuristics constitute a combination of exact methods and metaheuristics that exploit the strength of both approaches within a “hybrid” procedure. A distinguishing feature is the exploitation of nontrivial mathematical programming tools as part of the solution process. We refer to Della Croce, Grosso, and Salassa (2013) for a general description of matheuristics.Here, we propose a Variable Partitioning Local Search (VPLS) procedure which can be seen as a matheuristic neighborhood search approach based on a partial re-optimization of a variables partitioning. This approach can be also considered as a generalized k − opt neighborhood search procedure. The VPLS framework can be seen as a local search approach for MIPs, specially suited for 0–1 variables, using a generalization of the k-exchange neighborhood.Consider a general MIP formulationmincTXs.t.AX≤b,X∈{0,1}where Xt= (x1, x2, …, xn) is a vector of n variables of the problem andX¯t=(x1¯,x2¯,…,xn¯)is a feasible solution to the MIP. If this is the case, it is always possible to define a subset S of a defined size of variables indices {1, 2, …, n}. The neighborhoodNS(X¯)consists of all solutions of the MIP where the jth variable is equal to the value of the jth variable inX¯for all j ∉ S, namelyNS(X¯)={X|xj=xj¯,∀j∉S}. The resulting neighborhoodsNS(X¯)can then be searched for an improving solution using a MIP-solver both optimally or approximately. The main idea stems in representing the MIP as a permutation problem where variables belonging to the current solution are partitioned into two sets. A first set of variables with indexes in S is then reoptimized by means of an MILP solver generating a permutated assignment, while variables in the second set {xj, ∀j∉S} keep the same assignment as in the current solution.For the considered problem, the incumbent solution returned by the RBS algorithm induces correspondingly a sequence of the bins where we assume that γ bins are used. The neighborhood exploration works as follows. Starting with the first bin, consider the rth bin in the sequence along with bins r + 1, r + 2, …, r + H − 1 with item set S = Sr∪Sr + 1∪⋅⋅⋅∪Sr + H − 1. Solve the problem of rescheduling the items in S so thatw(Sr+H−1)=∑j∈Sr+H−1wjis minimized, where we use wj= max {bj, pj} (this performance measure has been selected experimentally).The rationale is to empty as much as possible bin r + H − 1. If a (sub)sequence with w(Sr + H − 1) = 0 is obtained, then one bin is saved, γ is reduced by one unit and the process can restart with r = 1. Alternatively, the new subsequence is kept anyway as the space of bin Sr + H − 1 has been optimized and will be used in the next iterate. The approach is then iterated for r = 1, 2, …, γ − H + 1. Whenever r = γ − H + 1 is reached, the process restarts with r = 1 until a time limit is exceeded. The problem of rescheduling the items in S is done by solving by means of an ILP solver the following ILP model adapted from the one above in order to take into account the fact that bins 1, …, r − 1 and r + H, …, γ are not rescheduled and that the objective is to minimize the weight of the items assigned to bin r + H − 1.(9)minimizezsubject to(10)∑k=1γxj,k=1,∀j∈{1,…,n}(11)∑j=1npjxj,k≤T,∀k∈{1,…,γ}(12)∑j=1nbjxj,k≤V,∀k∈{1,…,γ}(13)∑j=1nwjxj,k¯≤z(withk¯=r+H−1)(14)xj,k=x¯j,k,∀j∈{1,…,n},∀k∈{(1,…,r−1)∪(r+H,…,γ)}(15)∑h=1k−1∑i=1npixi,h+∑i=1jpixi,k≤dj+Q+M(1−xj,k),∀j∈{1,…,n},∀k∈{1,…,γ}with wj= max {pj, bj}, ∀j, 1 ≤ j ≤ n.Constraints (10) ensure that each job is performed by using one of the γ vials and correspond to constraints (4) of the previous model. Constraints (11) and (12) indicate the temporal and capacity limits of the γ vials and correspond to constraints (4) and (5) of the previous model. Constraints (13) link to the objective function z temporal and capacity consumption of vial r + H − 1. Constraints (14) indicate that the assignment of items to bins 1, …, r − 1 and r + H, …, γ is kept as it is in the incumbent solution. Finally, Eq. (15) matches constraints (7) of the previous model.Fig. 4displays the matheuristic neighborhood search approach proposed.A pseudo-code of this procedure is depicted below.As there are no known instances for this problem, we present computational experiments on the set instances from the literature for the two dimensional vector packing problem to which we added correspondingly the jobs due dates. The tests have been performed on a PC Intel Dual Core i5, CPU 1.7 Gigahertz and 4 Gigabytes RAM. The RBS method has been coded in C language and CPLEX v12.5 has been used for solving the MILP models.The instances introduced by Caprara and Toth (2001) are grouped in 5 main classes, each class containing 10 instances for each value of n (30 instances per class in total with n ∈ {50, 100, 200}), which makes a total of 150 instances. These instances are available at:www.or.deis.unibo.it/research_pages/ORinstances/ORinstances.htm.For each instance, the value in the first column is associated to the processing time and the value in the second column is associated to the vial consumption. Due dates have been randomly generated. We denote by P the sum of processing times:P=∑j=1npj. For each job Jj, a due date is randomly generated in [αP(1 − β), αP(1 + β)] where α and β are two coefficients belonging to interval [0, 1]. For the generation of the due dates, α and β have been fixed to 0.5.For each data set, the EDD sequence has been computed for findingLmax*,the optimal value of the maximum lateness. For each instance, the bound Q is defined byQ=ηLmax*with a given coefficient η ∈ {1, 1000}. The value of η = 1 imposes that the solution is optimal regarding the Lmax . On the other side, the large value for η is equivalent to neglect the constraint on the Lmax  and the problem becomes equivalent to the original two dimensional vector packing problem. We denoted by RBS the results of the recovering beam search algorithm standalone and by “RBS-MH” the two-phase approach applying first RBS and then the matheuristic algorithm using the RBS solution as initial solution. For the matheuristic algorithm, we set H = 4 after some preliminary experiments.Table 1reports the computational results for η = 1. In this case, the solution has to be optimal for the maximum lateness. For each class and for each value of n, columns LB* and UB* of the table denote the best known lower and upper bounds respectively available for the two dimensional vector packing problem with no constraint on Lmax . These bounds were taken from Monaci and Toth (2006). Column “EDD” and column “Desc” indicate the sum of the number of bins obtained for the 10 instances by EDD and by the descent after EDD, respectively. Also, column UB indicates the sum of the number of bins obtained for the 10 instances by the related method, column CPU(s) for RBS indicates the average computation time and column Ttb(s) for RBS-MH indicates the average time for obtaining the best solution (time-to-best). Note that for RBS a time limit of 120 seconds has been imposed while for the matheuristic algorithm a time limit of 1800 has been imposed, so that globally RBS-MH runs at most for 1920 seconds. Enlarging such limit does not seem to improve substantially the solution quality. Note also that for each iteration of the matheuristic algorithm a time limit of 60 seconds is imposed.From the results, if we compare the values of the proposed approaches to the best feasible solutions (indicated by the entry UB*) known for the two dimensional vector packing problem, we notice that the solution quality of the combined RBS-MH method is particularly good on classes 1, 9, still well performing on class 7 and with partial degradation on classes 6, 10. Also, the time-to-best is typically significantly inferior to the 600 seconds of CPU time. Notice, however, that the strong constraint on Lmax  does not necessarily guarantee that the UB* values are reachable. The performances of RBS standalone are weaker, but require limited time. Notice also, that additional tests not reported here indicate that the performances of RBS are much better than the standard list scheduling EDD (earliest due date) sequence.We consider in this subsection the case η = 1000. In this case, due dates are not considered and hence the original vector packing instances are solved. Correspondingly, constraint (15) becomes redundant and the bins selected for rescheduling are no more required to be consecutive. Hence, the following simpler ILP model can be considered in the matheuristic.(16)minimizezsubject to (10), (11), (12), (14) and(17)∑j=1nwjxj,k¯≤zforachosenk¯∈IFurther, a more general matheuristic approach could be devised as no sequencing constraint is present anymore. The approach works as follows. First, H disjoint subsets of bins with H bins in each subset are selected and optimized in order to empty as much as possible one bin in each subset. Then the H disjoint emptied bins are re-optimized always trying to empty as much as possible one of them. The approach is iterated until a time limit expires. A pseudo-code of this approach is depicted below.Table 2provides the same entries of Table 1 for the original two dimensional vector packing problem that is the case with no constraints on the due dates. In column “UB (opt)” we indicate in parentheses the number of times the method can certify an optimal value (equality with the lower bound).The results show that RBS-MH is competitive with the state of the art procedures being superior on class 1, comparable on classes 7, 9 and inferior on classes 6, 10. We point out, in particular, that as far as class 1 is concerned, two new upper bounds were established for n = 100 and five new upper bounds were established for n = 200. The corresponding solutions are available athttp://www.di.unito.it/~grosso/newbests2CBP.txt.Also, the CPU time required by RBS-MH is on the average well below 400 seconds. We point out that it is hard to get a full comparison to the recent work of Alves et al. (2014) where most of the results with n = 200 are missing and detailed solution values of each instance are not available. However, it appears from the instances approached by both algorithms that Alves et al. (2014) reaches better results (71 optimal solutions vs 43 over 80 instances) at the expense though of a much larger computational effort (on class 9 with n = 50, for instance, approximately 400 vs 1.2 seconds).

@&#CONCLUSIONS@&#
We considered the problem of scheduling activities which consume perishable raw materials that induce a deadline on their use once started, where the deadline is a part of the decision process. The problem has been modeled as a single machine scheduling problem with additional duration and consumption constraints. The problem can also be seen as a two dimensional vector packing problem combined to the single machine problem with the requirement that the maximum lateness of the resulting single machine sequence does not exceed a given threshold. A two-phase procedure has been proposed where in the first phase a fast Recovering Beam Search approach has been applied and in the second phase a more time consuming matheuristic procedure using the RBS solution as initial solution has been proposed. The two procedures have been tested showing very good performances within reasonable time on benchmark two dimensional vector packing instances suitably integrated to handle the maximum lateness requirement. The proposed procedures have also been tested on the original two dimensional vector packing instances showing to be competitive with the state of the art procedures and finding 8 new best bounds. As a future research direction, it would be worthy to search for improved lower bounds taking into account the presence of the due dates and to study the corresponding problems for different values of α and β. Another research direction could be to adapt the proposed approach to the original problem discussed in Mazier et al. (2010), where several parallel machines (pharmacy technicians) and several types of cytotoxic drugs have to be taken into account. Another research direction could be to consider that more than one vial can be assigned to the same preparation. It would lead to another model, presenting less similarities with the two dimensional vector packing problem, but with undoubtedly potential applications.