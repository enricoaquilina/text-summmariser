@&#MAIN-TITLE@&#
A method to assist in the diagnosis of early diabetic retinopathy: Image processing applied to detection of microaneurysms in fundus images

@&#HIGHLIGHTS@&#
A new approach for microaneurysm detection is tested in two public image databases.Normalization of grayscale content is an essential preprocessing stage.Coarse segmentation for candidate selection is based on morphologic processing.Principal component analysis and Radon transform are used during feature extraction.The number of features to extract is very small with only two features.

@&#KEYPHRASES@&#
Morphological processing,Eye fundus image,Principal component analysis,Radon transform,

@&#ABSTRACT@&#
Diabetes increases the risk of developing any deterioration in the blood vessels that supply the retina, an ailment known as Diabetic Retinopathy (DR). Since this disease is asymptomatic, it can only be diagnosed by an ophthalmologist. However, the growth of the number of ophthalmologists is lower than the growth of the population with diabetes so that preventive and early diagnosis is difficult due to the lack of opportunity in terms of time and cost. Preliminary, affordable and accessible ophthalmological diagnosis will give the opportunity to perform routine preventive examinations, indicating the need to consult an ophthalmologist during a stage of non proliferation. During this stage, there is a lesion on the retina known as microaneurysm (MA), which is one of the first clinically observable lesions that indicate the disease. In recent years, different image processing algorithms, which allow the detection of the DR, have been developed; however, the issue is still open since acceptable levels of sensitivity and specificity have not yet been reached, preventing its use as a pre-diagnostic tool. Consequently, this work proposes a new approach for MA detection based on (1) reduction of non-uniform illumination; (2) normalization of image grayscale content to improve dependence of images from different contexts; (3) application of the bottom-hat transform to leave reddish regions intact while suppressing bright objects; (4) binarization of the image of interest with the result that objects corresponding to MAs, blood vessels, and other reddish objects (Regions of Interest—ROIs) are completely separated from the background; (5) application of the hit-or-miss Transformation on the binary image to remove blood vessels from the ROIs; (6) two features are extracted from a candidate to distinguish real MAs from FPs, where one feature discriminates round shaped candidates (MAs) from elongated shaped ones (vessels) through application of Principal Component Analysis (PCA); (7) the second feature is a count of the number of times that the radon transform of the candidate ROI, evaluated at the set of discrete angle values {0°, 1°, 2°, …, 180°}, is characterized by a valley between two peaks. The proposed approach is tested on the public databases DiaretDB1 and Retinopathy Online Challenge (ROC) competition. The proposed MA detection method achieves sensitivity, specificity and precision of 92.32%, 93.87% and 95.93% for the diaretDB1 database and 88.06%, 97.47% and 92.19% for the ROC database. Theory, results, challenges and performance related to the proposed MA detecting method are presented.

@&#INTRODUCTION@&#
According to the International Diabetes Federation (IDF), 366 million people were diagnosed with diabetes in 2011. It is expected that the number will increase to 522 million in 2030. In addition, 183 million people (50%) with diabetes are not diagnosed [1]. Due to the prolific increase in diabetes, based on current estimates, a minimum of 3 million people will need to be evaluated every day by the year 2030 (35 tests per second).Diabetes can increase the risk of contracting any type of eye disease, but the main cause of blindness associated with diabetes is diabetic retinopathy (DR) [2]. DR causes damage to the blood vessels within the retina. Commonly, it affects both eyes and can lead to progressive vision loss if it is not treated. More than 75% of all people, who have had diabetes for more than 20 years, will have some form of DR, according to [3]. From the USA National Diabetes Report [33], during 2005–2008, of diabetic adults aged 40 years or older, 28% people had DR that may result in vision loss, and 4.4% people had advanced DR that could lead to severe vision loss.These complications can be prevented if tests are performed appropriately and regularly at least once per year. The vast majority of patients, who develop DR, have no symptoms until the last stage of the disease, where it could be too late for effective treatment. Therefore, detection and early medical intervention is critical. In terms of cure rates in first world countries, we will expect a 15% reduction of the diagnosed DR with vision loss. At third-world countries, we could expect 30% reduction of the diagnosed DR with vision loss, given the time, cost and irregular visits to the ophthalmologist.To diagnose DR, a retinography is performed, which consists in capturing images of the inside of the eye (retina) by dilating the pupil (mydriatic) or without dilation. Usually, ophthalmologists recognize DR based on features, such as the areas of the blood vessels, exudates, microaneurysms (MAs), hemorrhages and texture [4]. Hemorrhages and MAs are the first observable injuries that indicate a diabetic retinopathy and they are known as red lesions.According to a study, conducted and published in [5,6], half of 205,000 ophthalmologists that exist globally are located in six countries (China, USA, Russia, Japan, Brazil and India). It is also mentioned that there are 23 countries that have less than one ophthalmologist for each million inhabitants; 30 with less than four; 48 countries with less than 25 for every million people; 74 with less than 100 and only 18 countries have more than 100 ophthalmologists for every million citizens. For the case of underdeveloped countries, the economic level is still a disadvantage that avoids the generation of professionals in this field. For the case of developed countries, the level of population which exceeds 60 years of age doubles the rate of professionals that arise each year. In addition, it is expected that the number of ophthalmologists will grow only 2% while the increase in the population with diabetes will be 54% [2] for 2030. Furthermore, the examination time takes from 15 to 30min in each eye, as well as an additional delay because of the need of dilatation of the pupil for a fundus eye exam.For the aforementioned reasons the development of an automatic system of pre-diagnosis is necessary to perform a rapid assessment of the retina and to indicate if there is any type of lesion that should be treated by a specialist. In addition, the algorithm of detection and classification of lesions must be simple to facilitate its subsequent mass deployment. The simplification of the pre-diagnosis, early and preliminary diagnosis will benefit from algorithms that require less computing resources.Statement of the problem: In short, the only way to diagnose non-Proliferative Diabetic Retinopathy is through the study of eye background images. In addition, the growth in the number of ophthalmologists is much lower than the growth of diabetics. For this reason, this work focuses on the development of an algorithm, which is capable of detecting red lesions which are visible on background eye images. Also, the algorithm is based on techniques of morphology and principal component analysis with a small number of features. These arguments encourage the future implementation of devices for autonomous diagnostic that will help to reduce the number of people who go to an ophthalmologist without apparent diabetic retinopathy.The rest paper is organized as follows. Section 2 reviews the relevant and recent related work in detection of lesions in color fundus images. Section 3 gives a detailed overview of the proposed algorithm for detection of candidates to MAs. The proposed classification stage to discriminate between real MAs and false positives is explained in Section 4. Section 5 provides the experimental results obtained by following the proposed approach as well as comparisons. Conclusions are presented in Section 6.According to [8,9], the detection of lesions on color background images is performed in two major stages, (1) Extraction of candidates to MAs and (2) Classification of candidates as MAs or normal regions.Most of the current algorithms perform processing using only the green channel of the RGB image. The first stage requires a preprocessing to reduce noise and improve contrast. Then red areas (darker regions in one-channel images) on the image are extracted and segmented to obtain candidates for red lesions (regions of interest—ROI), followed by segmentation for removal of blood vessels to reduce the number of false positives that may appear during the stage of candidate extraction. After detection of candidates for red lesions, different features are extracted and selected on those regions. In the second stage, a classification algorithm is applied to categorize these features within candidates for red lesions (abnormal) and non-candidates (normal). The general process for detection of red lesions is shown in Fig. 1.Different methods for preprocessing have been applied for detection of red lesions such as CLAHE (Contrast Limited Adaptive Histogram Equalization), lighting and brightness correction, normalization, shadow correction, etc. The extraction of candidates is usually based on morphological processing techniques, region growing algorithms, Wavelet transform, Radon transform, Curvelets, among others. All these techniques are commonly applied to grayscale images; however, we noted that injuries can be distinguished by color, size and shape. In order to have a basis of comparison, Receiver Operating Characteristic (ROC) graphics have been used in recent years with minor modifications.Objectives, results and disadvantages of important related articles are discussed below. Not all research projects, mentioned below, used a standard database that works as the basis for comparison; however, some databases that can be used to standardize research results have been developed in the past years.Some methods rely on the use of fluorescein angiography (FA) where a fluorescent dye is injected into the bloodstream to highlight blood vessels in the back of the eye so that they can be photographed. After the test, the pupils may remain dilated for up to 12h. and urine is darker and orange in color for a few days. Possible reactions due to the test are nausea, vomiting, swelling of the larynx, hives, difficult breathing, fainting and cardiac arrest. Thus, the use of FAs represents a disadvantage.Detection of MAs in FAs using morphological methods is performed in [10]. In this work, a sensitivity is not reported. The disadvantages of this method are the use of FAs, few images, and very slow processing time. Spencer et al. proposed a method in [11] for detection of MAs in digital images using adaptive filters. It has the disadvantages of using FAs, and the requirement of image amplification by a factor of at least four times to obtain good results. Detection of MAs in FAs is also presented in [12]. This method is divided into three stages. In the first stage, lighting and tone correction are used. In the second stage, adaptive filters, top-hat bilinear transformation, gray-level thresholding, and a region growing algorithm are used. Finally, in the third stage, an analysis of candidates is executed. A sensitivity of 82% was reached, it failed to detect 13 MAs on 13 images. Its disadvantages are the use of FAs, conflict with threshold levels, and high computation time. In the work by Cree et al. [13], the sensitivity is 82%, there is not human intervention and there is an improvement in speed; however, FAs are used and there is conflict with threshold levels. In [14], each candidate is classified according to its intensity and size by the application of a set of rules derived from 102 training images. A sensitivity of 81% and a specificity of 93% are achieved. The main disadvantage is that sensitivity and specificity are too low to implement the algorithm as a diagnosis tool. In [15], an algorithm of recursive segmentation, based on region growing and the “Moat Operator” technique, is presented. Regions of interest (optical disc, blood vessels and fovea) are automatically detected. The sensitivity and specificity of the detection of exudates in 30 images were 88.5% and 99.7%, and 14 images were used for detection of MAs and bleeding with sensitivity of 77.5% and specificity of 88.7%. Niemeijer et al. [16] proposed a method which consists of three stages: preprocessing, extraction of candidates, and the classification stage where each pixel has to be classified. A total of 14,906 candidates were extracted and 33 (9.48%) injuries were missed. The disadvantages of the method are that large lesions are not always segmented, analysis time is approximately 15min per image. A method is proposed in [17] and it consists of three stages: pre-processing, screening of candidates and classification. Preprocessing involves contrast normalization. At the stage of candidate detection, different techniques are used such as region growing, top-hat operation, normalization of contrast, and exclusion of vessels. A sensitivity of 85.4% and a specificity of 83.1% are obtained. The execution time goes from 58 to 100s. The disadvantages are that the sensitivity and specificity are low for an efficient diagnostic tool. The purpose of the work in [18] is detection of MAs by execution of 4 stages: preprocessing, screening of candidates, extraction of characteristics and classification of candidates. A post processing stage was added during the classification. The post processing performs segmentation of blood vessels. Sensitivity decreases when there are more than 20 MAs. A sensitivity of 89% and an average of 2.92 false positives per image were obtained. By adding a post processing stage, an average of 2.17 false positives were obtained. Quellec et al. [19] proposed an algorithm for MA detection based on the matching of an artificial template of a lesion within the sub-bands generated by the wavelet transformation of the image under analysis. A sensitivity of 83.62% was obtained through the use of a training database of 3 images with 39 injuries. In addition, a sensitivity of 82.94% was obtained during validation with 32 images and 761 injuries. It is exclusively used for detection of MAs. A method for detection of red lesions is presented in [20]. To avoid the classification of fovea as red injury, lighting equalization in the green channel of the image is applied. In the next stage, the digital Curvelet transformation is applied to improve the image and, through manipulation of the transformation coefficients, red objects are separated. Then, these lesions are labeled as candidates. Finally, false positives are reduced by subtracting the structure of the blood vessels from the candidates. A total of 89 images were tested and a sensitivity of 94% and specificity of 87% are reported. It presents the disadvantage of high computation time with approximately 3min per picture. In [21], detection of bleeding is accomplished by applying (1) preprocessing and correction of brightness and contrast, (2) template matching with a correlation of coincidence, (3) extraction of bleeding candidates. Also, there is region growing to rebuild the form of hemorrhage and estimate the size of the lesion. A sensitivity of 85% and an average of 4 false positives per image are reported. The disadvantage is that the number of false positives by image is not low. In [22], MA detection is achieved through the profile of the local rotation of the transversal section focused on the local maximum of the preprocessing pixels. Detection of peaks is applied to each profile and a set of attributes such as size, height and shape of the peaks are calculated. Statistics measurements of these attributes as well as changes in the orientation of the cross section are the set of features for a Bayesian classifier. Sopharak et al. [23] performed MA detection by coarse segmentation using mathematic morphology and fine segmentation using naïve Bayes classifier. A total of 18 MA features are extracted for classification. Sensitivity, specificity, precision and accuracy are 85.68%, 99.99%, 83.34% and 99.99%. The MA detection problem is modeled in [24] as finding blobs (regions of interest). Several region descriptors are introduced to characterize these blobs. A semi-supervised based learning approach is proposed to train a classifier to detect true MAs. The performance is evaluated on the Retinopathy Online Challenge (ROC) competition database. In [25], two approaches to improve MA detection are presented. An approach is presented for MA candidate extraction based on their visibility and spatial location. An adaptive weighting approach for ensemble-based MA detection is also presented. This approach assigns weights to the candidates based on their contrast and their spatial location. Results showed that this approach is competitive with selection-based ensemble approaches and outperforms other individual detectors. Tavakoli et al. [26] presented a different algorithm for MA detection in FAs based on Radon transform (RT) and multi-overlapping windows. At the first step, the optic nerve head (ONH) was detected and masked. In the preprocessing stage, top-hat transformation and averaging filter were applied to remove the background. In the main processing section, the whole preprocessed image was divided in to sub-images and then the vascular tree was segmented and masked by applying RT in each sub-image. After detecting and masking retinal vessels and ONH, MAs were detected by using RT and thresholding. Performance was evaluated on three different retinal images databases, the Mashhad Database with 120 FA images, Second Local Database with 50 FA images and Retinopathy Online Challenge (ROC) database with 22 images. Automated DR detection demonstrated a sensitivity and specificity of 94% and 75% for Mashhad database and 100% and 70% for the Second Local Database, respectively.The proposed approach to solve the problem of detecting candidates on retinal fundus images, where candidates are regions possibly corresponding to microaneurysms (MAs), is separated into three different stages, one preprocessing stage (to reduce non-uniform illumination and to normalize the gray scale intensities) and two selection stages (to analyze grayscale content and shape), which are depicted in Fig. 2.Digital grayscale images are denoted as functionsfr,con the two-dimensional discrete spacer,c∈Z2(r stands for row and c stands for column).Some of the main limitations for an appropriate detection of MAs on background images of the eye are due to original image properties such as low contrast and non-uniform illumination, where the last artifact is manifested as a gradual decrease of illumination levels on regions located further away from the optical disc. Based on preliminary work and references, it is observed that the red (R)fRr,cand green (G)fGr,cchannels contain most of the image information, and this is due to the nature of these images where the range of blue intensities is poor. In [27], the spectral reflectance model of the human eye is explained, which allows to understand why the green channel contains most of the information. Illumination plays a key role in the detection of lesions from the background, with the result that non-uniform illumination (a characteristic of retinal fundus images) generates significant errors during segmentation. The left part of Fig. 3shows the G channel of a fundus image along with its intrinsic effect of non-uniform illumination. The information contained in the red and green channels might be combined to reduce non-uniform illumination by considering that the proportion of the green and red components is expected to be constant independently of illumination. The computation of the ratio of the green component valuefGr,cover the red onefRr,cis computed for each pixelfGr,c/fRr,cto obtain a new image where the effect of non-uniform illumination has been diminished as it is observed in the right side of Fig. 3.The algorithm should be tolerant to different contexts under which fundus images are captured (illumination, retina pigmentation, etc.), and an improvement of the dependence of these images from different contexts can be achieved by normalizing the image grayscale content. After analyzing statistical properties of the histogram of multiple images, it is found that most of the grayscale I content lies in the rangeμI−2σI,μI+2σI, where μIis the average image grayscale value and σIis the corresponding standard deviation. It is important to normalize an image so that all images have their grayscale contents lying in similar ranges. This normalization is achieved by a translation of μIto a new value μn, chosen to be 128 (the median of the dynamic range), and a scaling of the histogram standard deviation σIto a new value σn=35 (empirically found by testing a set of images). The grayscale transformation is given by(1)Iar,c=σnσIIbr,c−μI+2σI+μn−2σnwhereIar,candIbr,care the image grayscale values at positionr,cafter and before normalization. Normalization is useful during thresholding.Techniques of morphological processing have been extended to grayscale images and these techniques are used for binarization of images of interest as well as detection of regions of interest. The book by González et al. [28] and the paper by Haralick et al. [29] are fundamental references on morphological image processing. After extracting the vertical and horizontal cross-sectional profiles,fr,c=constantandfr=constant,y, from a segment of a preprocessed fundus image, it is observed that red lesions (such as MAs) and other dark regions (such as blood vessels) correspond to the local minima of the function, fmin. Fig. 4shows vertical and horizontal cross-section profiles on a small segment of a preprocessed fundus image containing MAs and blood vessels.To achieve segmentation of red regions (MAs and blood vessels), bright regions, corresponding to local maxima offr,c, have to be removed; and dark regions, corresponding to local minima offr,c, have to be emphasized. Because of the fact that opening of gray-level images suppresses bright regions while closing suppresses dark regions where the area of the suppressed region is smaller than the area of the specified structuring elementbr,c, these operations can be combined for removal of local maxima (background removal) and extraction of local minima (extraction of red regions).The erosion of a gray-level imagefr,cby a structuring elementbr,cat locationr,cis obtained by selecting the minimum value of f⊖b inside the region of intersection over which both functions f and b are defined according to(2)f⊖br,c=minx,y∈bfr−x,c−y−bx,yThe dilation of a gray-level imagefr,cby a structuring elementbr,cat locationr,cis defined by finding the maximum value of f⊕b inside the common region between both, function f and structuring element b, according to(3)f⊕br,c=maxx,y∈bfr−x,c−y+bx,yBy considering flat structuring elements with zero entries, eroding or dilating of a gray-level image with a structuring element consists in finding the minimum or maximum value of the image inside the region bounded by the intersection of the image and the structuring element. Fig. 5shows the results of erosion and dilation over the cross-sectional profile of an image segment.Erosion and dilation can be combined to obtain two different morphological operations, opening and closing. The opening of a grayscale imagefr,cby a structuring elementbx,yis given byf∘b=f⊖b⊕b. Similarly, closing offr,cbybr,cisf•b=f⊕b⊖b. Examples of cross-sectional profiles of images after application of these morphological operations are shown in Fig. 5. Depending on the size of the structuring element, the upward peaks on a two-dimensional surface are clipped by the opening operation while the downward peaks are clipped by the closing operation. The bottom-hat transformation combines image subtraction and closing with the objective that those removed objects by the closing operation (downward peaks) remain after subtraction. The bottom-hat transformation of a grayscale imagefx,yby the structuring elementbx,yis defined as its closing minusfx,yaccording to(4)Bhatf=f•b−fSince MAs and blood vessels are associated to downward peaks in fundus images, the application of the bottom-hat transform to fundus eye images leaves all the reddish regions (corresponding to dark regions in one-channel images) intact while suppressing bright objects. This is a step which is necessary before applying thresholding to obtain a binary image.Binarization of the image of interest is achieved through the use of thresholding with the result that objects corresponding to MAs, blood vessels, and other reddish objects are completely separated from background pixels and these regions are labeled as Regions of Interest (ROIs). Fig. 6shows the results of applying the bottom-hat transform, followed by binarization, to a fundus eye image. It is observed that dark regions (corresponding to MAs, blood vessels and noise) in the original gray-level image are enhanced by the bottom-hat transform and binarization. According to the previous description, this stage for extraction of candidates to MAs is based on intensity gray levels.One impairment of this stage is that very thin vessels might be separated into multiple isolated regions which might be misclassified as candidates to aneurysms. To reduce the likelihood of the occurrence of these misclassifications, it was found that instead of only using the two-dimensional bottom-hat transform on the image of interest, the application of one-dimensional bottom-transform to every row of the image as well as to every column of the image gives as a result suppression of vertical thin vessels for the first case (rows) and suppression of horizontal thin vessels for the second case (columns) with the consequence of reducing the segmentation of thin vessels into multiple isolated regions with potential to be labeled as aneurysms. Fig. 7shows the results of applying the one-dimensional bottom-hat transform, followed by binarization, to every row (middle column) and to every column (right column), along with the results of applying the two-dimensional bottom-hat transform (left column) as before. It can be observed how some horizontal vessels, extracted by the two-dimensional bottom-hat transform (left), are eliminated by the application of the one-dimensional bottom-hat transform over every column (middle) while some vertical vessels are suppressed by applying the one-dimensional bottom-hat transform over each row (right).The next stage in the process of extraction of candidates to aneurysms (coarse segmentation) consists in removing blood vessels from the set of regions of interest and this task is achieved by applying the hit-or-miss Transformation on the binary image. The hit-or-miss transforms is a morphological operation applied to binary images for detection of the location of objects with specific shapes so that other objects without the shape of interest (like blood vessels) will be removed. The task of the hit-or-miss transformation during extraction of candidates to MAs is twofold: finding the location of each one of the objects with round shape while removing objects with non-circular shape such as blood vessels. Since a MA on a binary image has an irregular shape surrounded by a black background and with maximum average diameter of 19pixel, the modeling of such an object as a binary image is characterized by an inner body of white pixels surrounded by a frame composed of black pixels with don’t care condition between the inner body and the black frame. The requirement of don’t care conditions provides the binary model with the flexibility to match MAs with different irregular shapes and sizes. Another interpretation for this binary morphological operation is based on the erosion of the binary imagefr,cwith the red lesion model used as a structuring elementbr,caccording to(5)f⊖b=p|bp⊆fwhere bpis the translation of the structuring elementbr,cto locationp. Eq. (5) represents the erosion of the image by the structuring element and it is defined as the set of all possible locationsp=r,csuch that if the structuring element bpis located at locationpthen the structuring element is completely contained infr,c. Thus, the locus of pointspwithin regions of interest constitutes the detection of the location of shapes of interest. An example of the structuring element b, and how this element is used to detect the location of shapes of interest is shown in Fig. 8. Application of the hit-or-miss transform (lower middle) generates the set of all those points where the structuring element (upper part) matches the binary image (lower left). Because of the size of the white inner body in the structuring element, noise regions (small white regions) are not matched by the structuring element so that noise is being removed. In addition, the structuring element is designed not to match blood vessels by exploiting the fact that blood vessel regions do not contain a surrounding black frame. From the example shown in Fig. 8, it is observed that even though there are two aneurysms with different irregular shapes, these lesions are matched by the structuring element because of the flexibility offered by don’t care conditions.The hit-or-miss transformation generates the set of all locations where the structuring element matches a region of interest; however, it does not recover the complete shape of the region of interest which is central to subsequent stages of classification. To recover the complete shape of regions of interest, at all locations of interest, an algorithm for extraction of connected components is used. The result of applying this algorithm is also shown in Fig. 8 (lower right). Another motivation for extraction of connected components is reconstruction of those red lesions that might be partitioned into multiple regions after applying the bottom-hat transform and binarization. Letfr,cbe a binary image containing one or more connected components, then another segment of the same size as f is initializedx0r,cwith all its elements being black background, except those elements at locations where it is known there is a white connected components such as the case of the images generated by the hit-or-miss transform. The goal is to start with the initial imagex0r,c(result of the hit-or-miss transform) and eventually extract all the connected components by performing the following iterative process,(6)xk=xk−1⊕b∩fwherebr,cis a suitable structuring element for extraction of connected components. The iterative process is finished when xk=xk−1 with xkcontaining all the connected components.The set of three-output images generated by the bottom-hat transform stage is delivered to the hit-or-miss transformation (shape-based classification stage) to eliminate vessels and reddish noise and the resulting images, after extraction of connected components, are combined through the logic AND operation as it is presented in the right part of Fig. 9.The preprocessing stage (median filtering, reduction of non-uniform illumination, normalization of grayscale content) is essential to the success of MA detection because this stage reduces background variations, noise, and the dependence of fundus images from different contexts under which these images are captured. Normalization of grayscale images plays a key role in image thresholding since it provides the algorithm with the capability of selecting one single threshold value for any context, otherwise manual selection of a threshold would be required for each patient or context.The process for candidate extraction (coarse segmentation) depends on different parameters such as (1) the dimensions of the structuring element (SE), shown in Fig. 10, used to compute the hit-or-miss transform, and (2) the threshold value for binarization after the bottom-hat transform. The SE is characterized by a surrounding black frame with inner and outer radii empirically determined by varying these dimensions during computation of the hit-or-miss transform over a set of randomly chosen images until most of all real MAs are included among the candidates extracted by the application of the hit-or-miss transform to all images. It was determined that the optimum size of the SE is 25×25pixel with an inner radius of 9pixel and an outer radius of 11pixel. The don’t care region is introduced to provide the SE with the flexibility to match MAs of different and irregular shapes. The size of the white region is intended to be small but different to 1pixel to avoid the matching between the SE and noise. A combination of SEs with different sizes is also recommended since small SEs are useful when it comes to select candidates which are close to each other or candidates close to vessels, but big SEs have to be used to detect MAs of large sizes. If a set of SEsSE1,SE2,…,SEnis used during multiple applications of the hit-or-miss transform, the resulting binary imagesI1,I2,…,Inare combined through an OR logical operation.In the same manner, the optimum threshold value used for extraction of reddish regions, MAs and vessels, is empirically determined by gradual changes of the threshold value while experimenting on a set of training images until the set of extracted candidates includes most of all real MAs.The selection of candidates to microaneurysms (MAs) leaves some False Positives (FP), most of these corresponding to small segments of vessels. To distinguish real MAs from FPs, two features are extracted from a candidate.One of the features is a regional descriptor that discriminates round shaped candidates, corresponding to MAs (one example of a MA is shown in the first row of Fig. 11), from elongated shaped ones, corresponding to vessels (one example is shown in the second row of Fig. 11). Since a vessel shape can take on different orientations and sizes, the feature has to be as invariant as possible to rotation and scaling. Pre-processing of the image patch (examples of patches, corresponding to candidates, are shown in the left column of Fig. 11), containing a candidate, is required previous to feature extraction where this stage consists of contrast stretching, so that the patch gray level intensities occupy the entire dynamic range (middle column in Fig. 11), followed by binarization of the contrast-enhanced gray-level patch (right column in Fig. 11).Each point inside a candidate region is expressed as a two-dimensional vectorxi=xi1xi2T, and all the n points in a candidate region, contained in a 2×n matrixX=x1x2,…,xn, can be used to compute (1) the centroid of the regionxc=1/n∑i=1nxiand (2) two eigenvectors e1 ande2 of the region which provide the two dominant and orthogonal directions of the set of points. The proportion between the lengths of the object along the two eigenvector directions depends on the object shape. For the case of vessel regions, the ratio of the maximum length over the minimum length has to be greater than the same ratio corresponding to aneurysm objects.Principal Component Analysis (PCA) computes a new orthonormal basis to represent the set of region pointsXwhere the two basis vectors e1 ande2 have directions along the maximum changes inX[30]. PCA re-expressesXas a linear combination of the new basis according to the linear transformation(7)Y=ETXc=e1Te2Tx1−xcx2−xc⋯xn−xcwhere each column ofXcis a region pointxiafter being translated to the region centroidxc, the columns of the 2×2 matrixEare a new set of orthonormal basis vectors to represent the columns ofXc, each eigenvectoreiTis a row ofET, each column in the new 2×n matrixY=y1y2⋯ynis a projection of each column vector ofXcon toe1 ande2, the first component ofyiis a projection on to eigenvectore1, and the second component ofyiis a projection on to eigenvectore2.The maximum and minimum values ofYalong the direction of eigenvectore1 are given by(8)y1max=maxi∈1,2,…,nyi1y1min=mini∈1,2,…,nyi1and the maximum and minimum values ofYalong the direction of eigenvectore2 are given by(9)y2max=maxi∈1,2,…,nyi2y2min=mini∈1,2,…,nyi2The four features computed through Eqs. (8) and (9) are used to estimate the length of the candidate region along the directions ofe1 ande2, according to(10)length1=y1max−y1minlength2=y2max−y2minFinally, the lengths of the candidate region are used to compute the following feature(11)r=maxlength1,length2minlength1,length2which is to be used for classification of the region according to a rule which establishes that if r is greater than a threshold, empirically determined, then the region is characterized by an elongated shape corresponding to a vessel and, otherwise, the region corresponds to a MA.PCA solves the problem of finding the orthonormal matrixE, which contains the principal components ofXcby finding the eigenvectors of the covariance matrix(12)CX=1nXcXcTSinceCxis a symmetric matrix, it can be diagonalized by an orthogonal matrix of its eigenvectors,(13)CX=EDETwhereDis a diagonal matrix. PCA selects a normalized direction along which the variance ofY=ETXcis maximized. Again, it finds another orthonormal direction along which variance is maximized, and this continue until all directions are found. To achieve this, the co-variances between separate components ofyhave to be zero, so that the covariance matrixCY=1nYYTis diagonalized,(14)CX=1nYYT=1nETXcXcTE=ETEDETE=Dwhere Eqs. (6) and (12) were used.The first feature does not work on those candidates that arise when two vessels intersect in one point as it is observed in Fig. 12. In this case the ratio of the two lengths of the object, along the principal eigenvector directions, is close to unity so that classification, based on the first extracted feature, fails.In this case, the histogram of projections of the region onto one axis x′ (blue and vertical axis in the right part of Fig. 12) is used to detect vessel crossings. The projection of a two dimensional region x′ onto a rotated axis x′ with respect to the original axis x is a line integral evaluated along the direction of rotated axis y′. The Radon TransformRθx′offx,yis the line integral of f parallel to the y′ axis and perpendicular to the x′ axis with the last axis having an angle θ with respect to axis x[26],(15)Rθx′=∫−∞∞fx′cosθ−y′sinθ,x′sinθ+y′cosθdy'where x=x′cosθ−y′sinθ and y=x′sinθ+y′cosθ are parametric equations, and parameter θ is the angle between the rotated axesx,yand the original axes (x′, y′).Fig. 13shows the radon transformRθx′of the candidate regionfx,yonto axis x′ at four different values for orientation parameter θ, 20° (blue line), 30° (red line), 110° (green line) and 120° (magenta line). By varying θ and obtaining multiple plots of the radon transformRθx′of a vessel crossing, it is found that most of these plots are characterized by a valley between two peaks as it is the case shown in Fig. 13.The second feature, extracted from the candidate, is a count of the number of times that its radon transform, evaluated at the set of discrete values {0°, 1°, 2°, …, 180°} of θ, is characterized by a valley between two peaks.Other possibilities to explore when it comes to detection of vessel crossings might be convolution, Fourier Transform and Wavelet Transform.The architecture of the classifier consists of a hierarchical system of classifiers which consists of a structure of two levels of classification as it is shown in Fig. 14, where the activation function is the unit step function. At the highest level of the hierarchy there is one perceptron whose purposes are (1) to discriminate between ROIs with round shape, corresponding to MAs, and ROIs with elongated shape, corresponding to vessels; and (2) to enable/disable the output of a second perceptron at the second level of the hierarchical system of classifiers. At the first hierarchy level, the first perceptron analyzes the first feature (ratio) of the candidate to determine if the region is not a MA otherwise the second perceptron analyzes the next feature (count of the number of times that the ROI radon transform is characterized by a valley between two peaks) to distinguish if the region corresponds to a vessel crossing or to a MA. Each perceptron is characterized by one input feature and it is trained with the perceptron algorithm. A set of patches of 19×19pixel, corresponding to real MAs, are extracted from multiple images so that a training set of MAs is built. In the same way, a second training set of patches, corresponding vessels or vessel crossings, is obtained to train both perceptrons.This implementation might be replaced by an if statement; however, the use of perceptrons introduces the advantages of learning the thresholds for classification through the perceptron algorithm which consists in automatically finding the optimum location of the vertical hyper-planes (thresholds).

@&#CONCLUSIONS@&#
