@&#MAIN-TITLE@&#
Investigating new calibration methods without feature detection for TOF cameras

@&#HIGHLIGHTS@&#
We introduce a parameter-free calibration model for a TOF camera (IRD map).This model partially compensates certain aberrations from the pinhole model.The IRD is computed by 1 or 2 depth images of a flat surface.Introducing featureless calibration procedures for TOF sensors (blank planes).Satisfying calibration for low-resolution sensors.

@&#KEYPHRASES@&#
Range cameras,Time of flight,Calibration,General camera models,

@&#ABSTRACT@&#
We propose to represent a time-of-flight (TOF) camera by the map of "internal radial distances" (IRD), associating an intrinsic distance to each pixel, as an alternative for the classic pinhole model. This representation is more general than the perspective model and appears to be a natural concept for 3D reconstruction and other applications of TOF cameras. In this new framework, calibrating a ToF camera comes down to the determination of this IRD map. We show how this can be accomplished by images of flat surfaces, without performing any feature detection. We prove deterministic calibration formulas, using one or more plane images. We also offer a numerical optimization method that in principle needs only one image of a flat surface. This paper has been recommended for acceptance by Peter Sturm.

@&#INTRODUCTION@&#
This article refers to a new group of cameras using the principle of time of flight (TOF). They belong to the class of so-called range cameras that add depth information to 2D images. Two types of TOF cameras are currently used. A first group uses a modulation wave of a near infrared light source (NIR wavelength=about 1μm). For such systems, each pixel on the TOF sensor is able to measure the distance D to a single world point by means of a phase shift calculation. In contrast, a second group of TOF cameras is directly based on the time needed for a light pulse to travel back and forth to a world point at a distance D.Both TOF camera types satisfy the same geometric model: every pixel provides a measurement of a distance D (in world units) to the detected world point, with an actual accuracy (expressed as 6σ) of about 15mm/m (Fig. 1). Unfortunately, most current TOF cameras suffer from a low resolution, disturbing the possibility for sharp feature detection. Recently, some high spatial resolution types appeared on the market (up to 1024 by 1280), but still these can be considered as exceptional. Furthermore, the cost for a higher pixel density is often a reduction of the accuracy of the depth measurements, due to, e.g., multipath errors and light correlation or “wiggling” errors ([1,17]. For an overview of the state of art of these range cameras, we refer to [16].Due to the availability of depth information, much simpler procedures arise for computations regarding 3D structure and reconstruction. Typical issues of classical stereo vision, such as feature detection, the correspondence problem, the epipolar geometry, etc., might disappear in the future when the technology delivers more accurate range cameras. Of course, there is no such a thing as a free lunch, and the former stereo vision procedures are replaced by new challenges, e.g., the problem of depth calibration. Indeed, the distance measurements that are provided by a TOF camera are affected by errors from different causes. We refer to Pattinson [17] for an extensive description of the nature of these distance errors. Several calibration techniques have been proposed to remove the systematic TOF errors ([12]), often in concordance with the choice of a specific error model. For example, in Lindner and Kolb [13], the distance errors are approximated by B-splines; in Kahlmann et al. [11] lookup tables have been used; and Fuchs et al. [5,6] determine parameters in a polynomial error model.However, the main share of the intrinsic calibration is the task to map the camera pixels into a spatial reference frame (relative to the camera). This is called lateral calibration for range cameras, and it is the subject of this article. Lateral calibration is a necessary step for obtaining accurate 3D information from the TOF depth measurements and is analogous to the classical intrinsic calibration of optical cameras: removing non-linear lens distortion and determining the intrinsic parameters (principal point, focal length, aspect ratio). Since most authors tend to use the classical pinhole model for TOF cameras, the lateral calibration is commonly done by known techniques in the spirit of Zhang [21] (see, e.g., [10,13]). The current lateral calibration methods for TOF cameras, even if they use the provided depth information, stick to the traditional calibration grid or chess pattern (implying corner detection, etc.) (e.g., [2,15]). Several publications use a parallel setting that combines an accurately calibrated 2D camera with a TOF camera, which offers us besides data fusion also the opportunity to calibrate the TOF camera ([7,14,20]).However, there are two important drawbacks for using the classical chess patterns for calibrating TOF cameras:1.The detection of corners is not reliable for low-resolution sensors, especially for slanted or distant positions of the calibration board ([8]).Feature extraction in TOF images is very difficult and unstable for certain materials, certainly when the amount of reflected light is small and the contrast is bad ([9]).This article has two main purposes:1.We prove that the lateral calibration of a TOF camera can be done without feature detection and without preparing calibration objects, only using images of flat surfaces. In Penne et al. [19], the same conclusion has been obtained, albeit by a different calibration algorithm. In this article, we present an efficient probabilistic optimization (Section 6.2) that can be validated and that can compete with state-of-the-art calibration methods (Section 7.2). Furthermore, we obtain the theoretical result that provides deterministic formulas for the intrinsic (pinhole) parameters by means of one or two depth images of a flat surface (Sections 4 and 6.1).We suggest to replace the pinhole model and its calibration matrix K by a parameter-free pixel map, the internal radial distance map (IRD) (Fig. 2). In principle, this IRD represents the depths of the sensor pixels w.r.t. the camera center, but they also have the potential to compensate errors (such as lens distortions or structural depth errors). Up to a global factor, the IRD can be computed by means of a system of linear equations, and it is the key of our theoretical calibration results (Section 4). As a motivation for our proposal, we show in Section 5.3 how to perform planar segmentation of depth images by means of this IRD (up to scaling), without determining the calibration matrix K.In Section 2, we introduce the IRD d that attributes to each pixel (u,v) the internal distance d(u,v) between the camera center C and the sensor point puvassociated with (u,v). Section 2 elaborates the relation between the IRD d and the classical calibration parameters of the pinhole model. In addition, in Section 3, we show conversely how the calibration matrix K can be computed from the IRD d, even in case this pixel map d is only known up to a global scale factor. As a matter of fact, the internal distance map d represents the intrinsic calibration of a TOF camera in a more natural way than the traditional calibration matrix K does. Indeed, given a TOF image with depth D(u,v) in each pixel (u,v), the ratios d/D can be seen as a scale factor between the homogeneous camera coordinates of the image point p and the 3D coordinates of the world point P. Besides their importance in reconstruction tasks, the d/D ratios appear to be the key values in other applications such as in image segmentation ([18]) or in the computation of surface normals ([16]).Due to the coplanarity constraint as presented by Penne et al. [18], we obtain an interesting theoretical result stating that the lateral calibration of a TOF camera (finding the IRD d up to a global factor) can be done by a linear deterministic method using two images of a plane (Section 4) or a quadratic deterministic method using only one image of a plane (Section 6.1).In the synthetic experiments of Section 5, we simulate the linear method for computing the calibration matrix K of a pinhole TOF camera. The accuracy and precision of the obtained intrinsic parameters increases with the number of considered images of flat surfaces (as expected) but also with decreasing camera resolution. The good performance of our method for TOF cameras with low resolution is interesting because the classical calibration techniques using feature detection are less successful in these cases. Furthermore, we observed that the determination of the global scale factor of the IRD d is a sensitive step in our calibration procedure. On the other hand, this global factor may be needed for finding the calibration matrix K but is not necessary in certain applications. We illustrate this in Section 5.3, where we use the coplanarity constraints of Section 4 in two experiments for planar segmentation, one with simulated and one with real data. In these experiments, we obtained the IRD d (up to a global factor) directly as solution of our linear method, without computing K. We refer to Penne et al. [18] for the presentation of a planar segmentation algorithm that relies on the same coplanarity constraints, but assuming an initially calibrated TOF camera such that the IRD d was obtained by means of the available matrix K.Regardless of the philosophy of this article viewing the lateral calibration of a TOF camera as determining a (homogeneous) IRD d, there still might be interest for determining the classical calibration matrix K anyway. The method of Section 4 provides a linear deterministic method using at least two images of a plane, while Section 6.1 provides a quadratic deterministic method using at least one image. Predicted by our simulations, these deterministic methods are not very precise yet and have limited practical use. Only the linear method, applied for a low-resolution camera (65×50, Section 5.2), and in combination with a non-linear optimization, could deliver an effective calibration result.Finally, in Section 6.2, we design a numerical optimization for determining simultaneously the intrinsic parameters and the extrinsic plane equation (of the viewed flat surface) by means of a maximum likelihood estimation (MLE). Simulations as well as experiments with real images (after removing distortion) prove that this method is both accurate and stable (Section 7). Furthermore, it stands comparison with state-of-the-art calibration methods.Let C be the center of a time-of-flight camera. In other words, the TOF sensor provides range information that can be presented as the distance D(u,v) between this (virtual) point C and the world point P that is observed in the pixel associated with image coordinates (u,v). Now we introduce the internal radial distance map (IRD) d ([16,18]). This map provides the distances from the center C to the pixels of the TOF sensor in pixel units.11In case the aspect ratio of the sensor differs from 1, we agree to measure d(u,v) in horizontal pixel units.It can be represented as a function on the pixel grid (Fig. 2):(1)duv=||C−puv||where puvis the pixel with coordinates (u,v). Notice that the IRD function d is an intrinsic property of the TOF camera, independent from its position in the world, and independent from the received signal as reflected by the environment.If P is a world point that is recorded by a TOF sensor in a pixel associated with the image point puv=(u,v), the TOF measurement D(u,v) and the IRD d(u,v) can be easily combined to recover P from puv. We perform this reconstruction in the standard camera reference system with origin in the center C, having Z equal to the focal axis, while X and Y are parallel to the pixel image axes U and V, using world units. If P=(x,y,z) and puv=(xp,yp,zp) in this coordinate system, then (Fig. 3)(2)xyz=DdxpypzpOn the other hand, in the classical pinhole model (neglecting lens distortions), the intrinsic camera parameters are given by the calibration matrix K:(3)K=fsu00τfv0001with focal length f in horizontal pixel units, aspect ratio τ, skewness s, and pixel coordinates (u0,v0) for the principal point. Observe that for each pixel point puvon the sensor, the 3D coordinates in the camera reference frame can be computed by(4)xpypzp=f⋅K−1uv1Thus, both the IRD d and the calibration matrix K represent the intrinsic camera settings, and they are related by the following formula:(5)duv=f⋅K−1uv1From now on, we assume rectangular pixels (s=0). In this case, Eq. (5) is simplified as (Fig. 3)(6)duv=u−u02+v−v02τ2+f2and Eq. (2) can be written as(7)Puv=Duvduvu−u0,v−v0τ,fThe presentation of Eq. (5) serves perfectly well to compute the IRD d from a given calibration matrix K. Thus, the lateral calibration of a TOF camera provides the IRD d, which in its turn is useful for reconstruction purposes (Eq. (2)) or other applications (e.g., image segmentation by Penne et al. [18]).In Section 3, we will show how to obtain the pinhole calibration K once we know the IRD d. The equivalence between K and d suggests that lateral calibration can be alternatively accomplished by the direct computation of the IRD d, without first determining the calibration matrix K. Actually, we will present such a method in this article. However, why should we bother to search for the individual internal distances d(u,v), which comes down to computing H×B values (corresponding to the camera resolution, one value for each pixel)? The classical pinhole calibration only needs 3 to 5 parameters and generates the whole IRD (Eq. (5)). However, we have some motivations to compute the d(u,v) in Eq. (7) by a direct procedure instead of by means of Eq. (6).1.Because a TOF camera is a device that both transmits as receives signals, the pinhole model might be less adequate. The IRD might be generated by another model. In fact, this map of pixel distances can be regarded as a parameter-free calibration, providing more accurate reconstructions when it is directly obtained from measurements, rather than generated by the calibration matrix K.The IRD might compensate other effects that are not taken into account by K, such as radial distortion, or the systematic “wiggling” errors that are known to be present in TOF measurements ([1]). In this way, the IRD could be used as a parameter-free model in the spirit of [3,4], generalized to a model covering both lateral as depth calibration.From our simulations and real experiments, we observed that in many cases we succeed to determine the internal distances d only up to a global scale factor, which we will refer to as a homogeneous IRD (HIRD). In these cases, the estimation of the intrinsics (especially the principal point) appear to become inaccurate. However, some applications do not need the exact scale factor, and only need the HIRD. For example, applications that are supported by the planarity test of Section 4 ([18]).Since we assumed rectangular pixels (s=0), the squared IRD turns out to satisfy a simple relation for three equidistant pixels on a horizontal or vertical line. Indeed, using Eq. (6), we can consider three equidistant pixels on a horizontal line, (u1,v), (u2,v) and (u3,v), and write down the following three expressions for the squares of di=d(ui,v):(8)u1−u02+v−v02/τ2+f2=d12(9)u2−u02+v−v02/τ2+f2=d22(10)u3−u02+v−v02/τ2+f2=d32Next, if we combine these equations as follows: (8) −2⋅ (89) + (8910) then, with u3−u2=u2−u1=Δu:(11)d12−2⋅d22+d32=u12−2u22+u32=2Δu2only depends on the space between these equidistant horizontal pixels, and not on their absolute positions. In particular, if we consider three consecutive horizontal pixels (Δu=1):(12)d12−2⋅d22+d32=2In a similar way, we can consider three equidistant vertical pixels: (u,v1), (u,v2), and (u,v3), with v3−v2=v2−v1=Δv. Here we observe (di=d(u,vi))(13)τ2d12−2⋅d22+d32=v12−2v22+v32=2Δv2which simplifies for consecutive pixels (Δv=1):(14)d12−2⋅d22+d32=2/τ2In Section 2, we observed that, if wanted, the knowledge of the IRD enables us to obtain the calibration matrix K in the classical pinhole model. Now, under the restriction of rectangular pixels (s=0), the previously obtained quadratic relations give rise to explicit formulas for the intrinsic parameters of the TOF camera, even if IRD is only determined up to global factor: a homogeneous IRD (HIRD).Indeed, let δ be a given HIRD. Thus, the exact IRD d is proportional to δ: d=aδ. Then we can proceed as follows:1.Determine the global IRD factor a from three consecutive horizontal pixels:(15)a2=2δ12−2⋅δ22+δ32Consequently, from now on, the IRD d is known to us.Determine the aspect ratio τ from three consecutive vertical pixels:(16)τ2=2d12−2⋅d22+d32Determine the first coordinate u0 of the principal point from two horizontal pixels, (u1,v) and (u2,v). This can be done by subtracting Eq. (8) from Eq. (9):(17)u22−u12−2u0Δu=d22−d12Determine the second coordinate v0 of the principal point from two vertical pixels, (u,v1) and (u,v2):(18)v22−v12−2v0Δv=τ2d22−d12Finally, the focal length f can be obtained from any pixel (u,v), with d=d(u,v):(19)f2=d2−u−u02+v−v02/τ2Because the IRD map represents the distances from a virtual camera center to the sensor plane, the rescaling of HIRD represents the radial distances to arbitrary frontal planes (perpendicular to the focal axis). In this section, we assume the availability of TOF images obtained from the reflection by one or more flat surfaces (e.g., walls). We will prove that two such images (of non-parallel planes) enable us to compute the (synthetic) TOF images of these frontal planes by solving a system of linear equations. From this HIRD, we can obtain the intrinsic camera parameters, at least theoretically (Section 3).To achieve this goal, we will compose a system of homogeneous linear equations in the unknown d(u,v). If the image of this planar object does not occupy the whole sensor, then our equations will only contain the unknowns d(u,v) for the pixels puvthat are covered by this image part, yielding only a partial HIRD. We use linear equations of the d/D ratios for coplanar and collinear point sets. For generalizations and proofs of these equations, we refer to Penne et al. [18]. Let P1,P2,P3,P4 be points on a flat surface, observed by a TOF sensor with distances D1,D2,D3,D4, and with internal radial distances d1,d2,d3,d4 for the corresponding pixels p1,p2,p3,p4, respectively. Then, if these four pixels make a rectangle in the image (ordering p1,…,p4 in counterclockwise sense):(20)d1D1−d2D2+d3D3−d4D4=0In case p1,p2,p3 are three equidistant collinear points in the image (with p2 the midpoint), then(21)d1D1−2d2D2+d3D3=0A domino is a collection of 6pixels, arranged in two rows of three pixels:(22)p1=uvp2=u+1,vp3=u+2,vp4=u,v+1p5=u+1,v+1p6=u+2,v+1If the six pixels of such a domino receive the reflected signal of a flat surface, then we can apply the coplanarity constraint (20) of Section 4. More precisely, for each choice of 15 possible 4-tuples out of 6, we haveLemma 1The 15 coplanarity equations of a domino have rank 3, and are generated byd1D1−2d2D2+d3D3=0d4D4−2d5D5+d6D6=0d1D1−d2D2+d4D4−d5D5=0This lemma describes a special case of a general procedure to generate all coplanarity conditions of a pixel grid by one rectangular coplanarity constraint (Eq. (20)) and some well-chosen midpoint collinearity constraints (Eq. (21)). If the complete set of H×B pixels has been covered by the image of a plane, then we can write downHB4coplanarity constraints. However, this system of linear equations appears to suffer from many duplicates and redundant equations. More precisely:Proposition 2The system of homogeneous linear coplanarity equations for the IRD d of a sensor of H∙B pixels has rank equal to H∙B−3.First notice that every arbitrary plane α can be used to construct a solution of this system of equations, not only the sensor plane. Indeed, if d(u,v) is equal to the distance from the camera center C to the point of intersection of the central ray through this pixel puvwith the plane α, then the coplanarity constraints are also valid for this d. In particular, we can choose α equal to the plane determined by the flat object that has been photographed, yielding the solution d(u,v)=D(u,v).This means that the solution space of the homogeneous linear system contains the subspace corresponding to all choices for α. Because each such plane is determined by the arbitrary choice of three radial distances d1,d2,d3, this subspace has dimension 3. As the number of unknowns equals B⋅H, the rank of the system is at most H⋅B−3.In order to prove the proposition, it suffices to find H⋅B−3 linearly independent coplanarity constraints. To this end, we start with a rectangular constraint associated with the four pixels located at the left top of the image (pixels (0,0),(1,0),(0,1),(1,1)). Next, for each row v (0≤v≤H−1), let us consider B−2 midpoint constraints associated with consecutive triples of pixels (u,v),(u+1,v),(u+2,v), with 0≤u≤B−3. Furthermore, for the first two columns, we consider H−2 midpoint constraints as well, using three vertical consecutive pixels:(i,v),(i,v+1),(i,v+2), with i=0,1 and 0≤v≤H−3. In total, we considered 1 square condition and H(B−2)+2(H−2)=HB−4 midpoints constraints. These HB−3 equations can be easily seen to be linearly independent because they span the whole pixel grid in a shellable fashion. A system of equations is called “shellable” if there is at least one unknown that occurs in exactly one equation and if this property recursively holds after deleting the involved equation. Indeed, in our case, the pixels in the rightmost column are covered by just one midpoint constraint. Thus, we can “shell off” the pixels column per column, from right to left, until we are left with the first two columns. Finally, the pixels of the first two columns are shellable from bottom to top. Observe that a shellable system of equations is linearly independent.Thus, one image of a wall or other flat surface is not sufficient to determine the HIRD of our TOF camera. More “plane images” do not improve this situation if the planes are parallel to each other. Indeed, if the plane–camera position in the second image is parallel to the first image, then the second TOF distances D′(u,v)=k⋅D(u,v) are proportional to the first one: D'(u,v)=k⋅D(u,v), for a constant k. Consequently, the coplanarity constraints set up for D' are equivalent to those set up for D. On the other hand, the coplanarity constraints for a non-parallel image always increase the rank of the system by 2. We conclude in the following:Proposition 3The system of homogeneous linear equations for the IRD d of a sensor of H∙ B pixels, that is obtained from the planarity constraints of two images of a flat surface covering the whole pixel grid has rank equal to•H⋅B−3, if both planes or camera positions are parallel.H⋅B−1, if both planes or camera positions are not parallel.The system of linear equations of Proposition 3, combined with the closed formulas of Section 3, provides a theoretical procedure for calibrating a distortionless, noise-free pinhole model of a TOF camera by means of two images of non-parallel planes.In this section, a simulation of the linear method presented in Section 4 is performed. We simulate a TOF camera with resolutions 12×10pixels (differentiated resolutions have been investigated as well). We construct 8 images of non-parallel planes intersected by the focal axis at a distance in the range between 3m and 5m and compute the HIRD using 2, 4, 6, or 8 planes. The angles of view for the simulated cameras are kept identical for the different resolutions to guarantee that the same area of the observed planes is covered by the different cameras. Once we obtained the HIRD from the system of equations as described in Section 4, we compute the pinhole intrinsics by the procedure of Section 3.The radial distances D of the TOF image are simulated by disturbing the exact values by Gaussian noise. This noise is gradually increased by letting the standard deviation σ vary from 0mm to 5mm. In order to achieve the restricted noise level of s=5mm for a distance of about 4m, it is assumed that the used TOF image is the result of the mean or the median of a shoot of 50 to 100 images.The results for the 12×10 sensor are shown in Fig. 4as the average percentage errors between the obtained calibrations and the true values, over 100 trials. The standard deviations are also shown. Note that the results are given in logarithmic scale, meaning that a value of 0 corresponds to 1% error and a value of 1 corresponds to 10%.Observations:•As expected, higher levels of noise lead to worse results. Also, more calibration planes improve the results.The estimation of the principal point is more sensitive to noisy measurements than the estimations of both the focal length and the aspect ratio. These present errors below 10% when using more than two planes in a 12×10 TOF sensor, even for the highest noise level.For the highest noise level, the estimation of the principal point in a 12×10 TOF sensor is inaccurate even when using 8 calibration planes.The previous observations have also been made in the experiments with different sensor resolutions (8×6, 12×10, 24×20, 65×50). Furthermore, we observed a clear drop of accuracy of the estimated calibration parameters for increasing resolution. For the highest resolution, acceptable results were obtained only when σ≤1 mm, and this relative to a simulation distance of 3 to 5m. We believe that the reason for this is that the relative errors on the radial distances with respect to the inner pixel distances increases with the resolution.The noise level and resolution of the simulation show the practical limitation of our linear method for calibrating a TOF camera. Therefore, we introduce two actions that improve the procedure. First, for higher resolutions, we can use a subgrid of the sensor pixels. This enlarges the distances between the points that are combined in the same equation (in space as well as on the sensor), decreasing the impact on errors on radial distances. In Table 1, we give the results of a simulated 65×50 sensor, where we used non-consecutive pixels in Eqs. (20) and (21) (skipping 10pixels, in vertical and horizontal direction). We selected 4 planes from the previous simulation (at a distance in the range between 3m and 5m) and assumed a known aspect ratio (τ=1). Due to this subgrid idea, a noise level up to σ=0.5 cm seems to be tractable for this resolution if we wish a reliable computation of the principal point, and up to σ=1.5 cm as far as the focal length is concerned. This performance is comparable with the observations for the low-resolution sensor of Fig. 4.Furthermore, we can improve the linear method by an additional numerical (non-linear) optimization. The goal is to minimize the error between the estimated IRD,d^, and the IRD computed using Eq. (6), d:(23)u^0,v^0,τ^,f^=minu0,v0,τ,f∑jd^j2−uj−u02+vj−v02τ2+f22.An initialization can be provided by the quadratic equations of Section 3. As shown in Table 2, due to this optimization, we can significantly increase the feasible noise level for the simulated 64×50 sensor (using the same noisy images of the 4 virtual planes as in the experiment without optimization), and the gain in precision is most striking in the computation of the principal point.If our concern is the computation of the pinhole calibration parameters then the simulations of Section 5.1 already proved that the linear method is not precise nor accurate for realistic noise levels (σ equal to 1% of average TOF measurements). Furthermore, we observed that the results get worse for higher sensor resolutions, on account of the decreasing inner pixel distances. The only reasonable calibration result that we obtained in practice was for the TOF camera in our lab with the lowest resolution (IFM 64×50). By means of the strategy given by Table 2, leaving a gap of 10 between consecutively processed pixels and adding a non-linear optimization, we computed that u0=23.92, v0=31.36, and f=79.35, using 7 distance images of a wall, assuming τ=1. Notice that we did not remove any lens distortion in this experiment, which seemed to be not necessary, probably due to the low-resolution and small FOV. The manufacturer of this camera type claims a focal length equal to 80, pretty close to our computed value. Also note that it was not possible to compare with state-of-the-art calibration techniques such as that of Zhang [21] on account of the low resolution of this camera, making the corner detection in the luminance image highly inaccurate, producing absurd values for the intrinsics.We were not able to repeat this success of the linear method for TOF cameras with higher resolution, even if we removed radial distortion, even if we used a sparse subgrid. We conclude that in general, the linear method will only be of practical use provided at least one of the following conditions:•The TOF sensors become more accurate.We find a more stable method to compute the HIRD.We find a more stable method for deriving the intrinsics from the HIRD.In Section 6.2, we will give an alternative lateral calibration method, also using the TOF image of a flat surface, also avoiding feature detection, but without computing the IRD, completely based on a non-linear optimization. This method will be validated as an accurate calibration procedure, also for high sensor resolutions (Section 7.2).A major bottleneck in the use of the linear method as a pinhole calibration tool is due to the scaling of HIRD to IRD. The computation of the scale factor is unstable because it depends on the squared inverse of the HIRD. However, for some applications we do not have to go the whole way in calibrating the camera, as the HIRD seems to be sufficient. For example, the HIRD may be used for segmenting planar surfaces in TOF images, using the coplanarity condition in Eq. (20) because it is valid for any scale factor. This idea of segmentation was explored by Penne et al. [18], but using an alternative calibration method. In this section, we perform a simulation in the segmentation of planar surfaces using the linear calibration method presented in Section 4.The segmentation is performed by computing the coplanarity error using Eq. (20), and afterwards thresholding the obtained values, as in Penne et al. [18]. The connected regions are identified and each region is assigned a different label, corresponding to a planar surface.A test image containing four planar regions is generated by selecting four planes and computing the radial distances for each plane. For each pixel, the visible plane is the one that yields the smallest distance. Calibration is performed using 8 planes, for TOF sensors of different resolutions. For each simulated TOF sensor, Gaussian noise is added both to the calibration measurements and the final test image.We started simulating a TOF sensor with resolution 12×10 pixels and perform the segmentation after injecting different levels of noise. Results are shown in Fig. 5, where both the coplanarity errors and the final labeling are shown. It can be seen that even for the highest noise level, the segmentation is nearly perfect. Note that the pixels that yield a coplanarity error higher than a specified threshold are not considered for the labeling. This means that, when noise is considered, these pixels are not labeled as belonging to a plane. In Fig. 6, they are shown in dark blue.After increasing the sensor resolution, we observed a degrading of the obtained labeling. This is coherent with our previous observation that higher sensor resolution leads to poorer calibration results (Section 5.1). However, for a 24×20 TOF sensor, even at the highest noise level, the method was able to correctly identify the four planes. At the highest resolution (36×30) of our simulation, it was possible to segment the planar regions only with a noise level up to 3mm. However, given the fact that even for a 24×20 TOF sensor the estimation of the intrinsic parameters is poor under realistic noise levels (Section 5.1), the segmentation results that we obtained by means of the HIRD are satisfactory. Consequently, these observations confirm that the HIRD is more accurately estimated than the intrinsic parameters.We used a 110×150 PMD nano-TOF sensor for performing the real experiments. We acquired 11 images of a flat wall in different viewing angles for computing the HIRD and tested the planar segmentation on two different images of a setup with 3 planes. Since computing the HIRD for all the 110×150 pixels would have excessive computational costs, we selected pixels in a regular grid and performed the computation for those. The labeling for the whole image is obtained using the neighboring pixel labels.Fig. 6 shows the results for the two test images. In Fig. 6a and d, the intensity images are shown for the same setup observed from two different views. The coplanarity error is computed for the sampled pixels (Fig. 6b and e) where it can be seen that higher errors are obtained in areas corresponding to the plane transitions. This result allows to obtain the labeling in Fig. 6c and f, that show the correct identification of the planes observed by the sensor.Note that if the sampling of pixels is very sparse, small planar segments may be missed. However, for TOF sensors with low resolution, this method is perfectly adequate.In Section 4, we saw how to determine the internal radial distances up to a global scalar (HIRD) by means of a homogeneous linear system composed by coplanarity equations for at least two plane images. We also showed how the HIRD yields the pinhole parameters (Section 3). In this section, we explore the possibility to carry out the lateral calibration of a TOF camera by means of only one image of a flat surface. We present two solutions. The first one is a deterministic procedure, providing formulas for the intrinsic calibration parameters (u0,v0,τ,f) of a TOF camera using the quadratic equations of Section 3. Although this can be considered as an interesting theoretical result, we observed a poor performance of this solution in simulations and real experiments. The second solution uses a maximum likelihood estimation, implying a numerical optimization. This method appears to be more robust and performs well in simulations and real experiments.Consider four consecutive pixels on a horizontal line:(24)p1=uv,p2=u+1,v,p3=u+2,v,p4=u+3,vwith distances Di=D(pi) as measured by the TOF image of a flat surface. From Section 4, we find two linear midpoint equations in the unknown IRD di=d(pi). Furthermore, if we assume zero skewness, Section 3 provides us from two quadratic equations. Summing up:(25)d1D1−2d2D2+d3D3=0(26)d2D2−2d3D3+d4D4=0(27)d12−2d22+d32=2(28)d22−2d32+d42=2RemarkIn principle, these four pixels do not need to be consecutive or lie on a horizontal line, as long as they are equidistant. However, in this case the relations become a little more complicated, taking the distance r between the subsequent pixels into account, expressed moreover in u pixel units, which might involve the use of the aspect ratio τ.If we combine Eq. (25) with Eq. (27), and Eq. (26) with Eq. (28) respectively, then we get(29)2d2D2−d3D32=2d22D12−d32D12+2D12(30)2d3D3−d2D22=2d32D42−d22D42+2D42Finally, subtracting these equations from one another gives a straightforward relation between d22 and d32. In combination with Eqs. (27) and (28), we also find expressions for d12 and d42 in function of d32:(31)3D22−2D12−1D42d12=6D32−3D22−3D42d32+6D22−6D42(32)3D22−2D12−1D42d22=3D32−1D12−2D42d32+2D12−2D42(33)3D22−2D12−1D42d42=6D22−3D12−3D32d32+6D22−6D12One can check that these three relations satisfy the subtraction of the squares of Eqs. (25) and (26), implying that the original system with Eqs. (25),…,(28) suffers from redundancy and can be reduced to an equivalent system with three equations.If we consider the next pixel on this horizontal row, p5=(u+4,v), with measured world distance D5 and unknown internal distance d5, then we can add another midpoint and quadratic relation for the triple (p3,p4,p5). These can be combined to obtain five expressions for the squared IRD, d12,d22,d32,d42,d52, in terms of the measurements D1,…,D5.In order to obtain an estimation of the intrinsic parameters that uses information from the whole IRD, the optimization scheme defined in Eq. (23) is used. Initialization is obtained by the quadratic equations of Section 3.Experiments were performed using a simulated TOF sensor with resolution 65×50pixels, principal point (u0, v0)=(30, 27), zero skewness (s=0), focal length f=80pixels, and an aspect ratio of τ=1.2. We computed the radial distances D to a pre-defined plane, to which zero-mean Gaussian noise with different standard deviations was added. We started by using consecutive pixels but found the results to be very unstable. Increasing the relative distance between pixels lead to improved estimations and Table 3shows the results obtained for the maximum possible horizontal displacement between pixels.As expected, results degrade with increasing noise. The fact that the estimation of v0 and τ is consistently worse may be explained by the occurrence of a mutual compensation. On the other hand, the focal length seems to be accurately estimated even for the highest considered noise level. At this level, the other estimations become very inaccurate, suggesting that this method cannot be used with real images. Indeed, we performed some tests with a real data set but did not succeed in obtaining acceptable results.We observed that increasing the number of calibration images did not provide better results. Also, for the lowest level of noise, we noticed that even if the initial estimation is poor, the optimization step leads to the convergence to a good solution.The method devised in Section 6.1 relies on equations whose terms depend on the squared inverse of the measurements Di. This is the reason why the estimation is extremely sensitive to measurement noise, as shown in the synthetic experiments.In this section, we propose an alternative method for estimating the intrinsic parameter matrix K by means of one image of a flat surface. Rather than deterministic formulas, the procedure in this section makes use of a numerical optimization. The main idea is to maximize the probability that the reconstructed points belong to a planar surface. Besides computing the intrinsic parameters, the method implicitly estimates the equation of the plane that is observed by the sensor.Suppose we have the noisy measurements Di=Xi+ni, where Xiare the true unknown values for the radial distances and niis Gaussian additive noise. A probability function can be defined as(34)PD1…DN=e−12σn2∑i=1NXi−Di2,where σn2 is the noise variance. The constraint is that the points reconstructed using Xiand the true intrinsics belong to the 3D plane viewed by the sensor. Defining a plane by П=[a b c 1]T, it is known that a 3D point (x, y, z) belongs to П if it satisfies(35)ax+by+cz+1=0.Knowing that a point is reconstructed as in Eq. (7), the plane equation can be written as(36)aui−u0+bvi−v0τ+cfXiduivi+1=0,which can be rearranged as(37)Xi=−duiviaui−u0+bvi−v0τ+cf.If we define a parameter vector as θ=[a b c u0v0τ f], a probability function can be defined as(38)PD1,…,DNθ=e−∑i=1N−dui,viaui−u0+bvi−v0τ+cf−Di2,and d(ui, vi) is computed as in Eq. (6).We wish to find the set of parametersθ^under which the data {Di} are most likely, which can be done using the Maximum Likelihood (ML) method:(39)θ^=argmaxθPD1,…,DN|θ.In case there are more calibration images, a similar approach can be considered. For each added image, 3 extra parameters related to the plane equation must be estimated. Thus, if we define the parameter vector corresponding to the calibration image j as θj=[aj bj cj u0v0τ f], and considering that the probabilities corresponding to each image are independent, we can redefine Eq. (39) to include a product of probabilities for all M calibration images:(40)θ^=argmaxθ∏jMPD1j,…,DNjθj,where D1,…,Njare the measurements corresponding to image j and θ is now defined as θ=[a1b1c1a2b2c2 ⋯ aM bM cM u0v0τ f].The following section reports a set of experiments using synthetic and real data that are useful for assessing the proposed calibration method.Two different experiments were conducted in order to assess the precision and accuracy of the proposed method. The first one is a simulation of a TOF sensor observing a 3D plane, and the calibration is performed after injecting different levels of noise in the measurements. Since our intent is to analyze the performance of the method under different noise levels, we perform experiments using only one calibration image. The second experiment is the calibration of two real TOF sensors with that acquire several sets of images, each corresponding to a different position of the blank calibration board. We also acquired images of a checkerboard pattern in order to compare for these TOF cameras the calibration by Zhang's method [21].A similar TOF sensor as the one in Section 6.1.1 was simulated. The radial distance D (u, v) from the camera center to the plane П=[1,1,1, − 300]Twas computed for each pixel (u, v), being this the only measurement used for calibrating the sensor.The maximum likelihood method requires an initialization of the parameter vector, θi=[ai bi ci u0iv0iτi fi]. The intrinsic parameters (u0i, v0i, τi) were initialized by setting the principal point to the geometric center of the sensor and the aspect ratio to 1. The initialization fifor the focal length is computed by a simplified version of the calibration algorithm presented by Penne et al. [19]. More precisely, since the sensor is observing a plane, a reconstructed line of pixels must originate a set of collinear 3D points. Thus, the focal length fiis computed by reconstructing the horizontal middle row of image pixels using all integer values for fibetween 50 and 300. The value of ficorresponding to the set of points that yields the smallest collinearity error is considered for initialization. Using these initial intrinsic parameters, the 3D points are reconstructed and a 3D plane is fitted using a standard fitting algorithm. The parameters of this estimated plane are used as initialization values for ai, bi, and ci.Gaussian noise with zero mean was added to the measurements D, with a standard deviation equal to 0.01%, 0.1%, 1%, and 5% of the average distances D. The error distributions of 50 independent runs of the method for each noise level are shown in Fig. 7. Note that the first two graphics in the top row correspond to the plane, where the first is the percentage error between the norms of the estimated and the original plane, and the second is the angular error between the normal vectors. The remaining errors are percentage errors computed between the estimated and the original intrinsics.It can be seen that with the lowest level of noise, the method is able to very accurately recover the plane equation and the intrinsic parameters, leading to negligible errors. For higher noise levels, the method is still able to produce accurate results, presenting average errors below 2% for a noise level of 1%.We tested our calibration method with real data acquired by two different MESA SR4000 TOF cameras: one with a field-of-view (FOV) of 44×35, which we refer to C1, and the other with a 69×55° FOV (C2). We acquired 15 images of a checkerboard pattern for calibration using Zhang's method [21] and 13 depth images of a planar surface in different orientations (varying from −30° to 30°, with a step of 5°) and distances for calibration using your method, with each camera. For C1, we also acquired a set of 6 validation images. Note that for each position, 50 images were acquired and the median values were considered. We decided to work with the median depth image in favor of the mean of the acquired images because it is generally assumed that the nature of TOF measurement errors is not Gaussian, including sporadic outliers ([12,17]).Although the theoretical minimum of required images is 1, with the intent to assess the performance of the method when more data is provided, we tested it with an increasing number of calibration images, up to 13, for both cameras. For each possible number of images, at most 50 calibration sets were randomly selected and the results are shown in Figs. 8 and 9for cameras C1 and C2, respectively. Remark that the initialization step was performed as described in the previous synthetic experiment using one of the images in the calibration set.Also, prior to calibration, we undistorted the depth images according to a simple 1-parameter model for radial distortion: R=r(1+k∙r2), such that our calibration method can compete with one of the available chess board calibration tools that automatically remove lens distortion. In order to determine the distortion parameter k for both cameras, we used images of plumb lines as a reference.Finally, because depth noise increases with distance, a normalization was performed by dividing the terms of the sum in Eq. (38) by the corresponding Di, serving as a weighting parameter that favors less noisy estimates.Figs. 8 and 9 show that increasing the number of calibration images lead to smaller standard deviations, meaning that the algorithm's precision increases. Moreover, varying the number of calibration images produces similar results, suggesting that there is consistency in the data and the point of convergence is a well-defined minimum.We also calibrated both C1 and C2 with a state-of-the-art method [21] that requires images of a checkerboard pattern with known dimensions. In order to compare both methods, we used the obtained calibrations for reconstructing the 3D points as in Eq. (7), and, with a standard fitting algorithm, finding the plane that best fits to the point cloud. For each reconstructed point, the geometric distance to the fitted plane is computed and a median of all the distances obtained for each image provides an error metric. For each calibration set, the images that are not part of it are used for computing this error. Then, the average error is computed for all sets corresponding to the same number of calibration images. These average errors are shown as a function of the number of calibration images, both for our and Zhang's method in Fig. 10. For the set of 6 validation images acquired for C1, we performed similarly and included the results in Fig. 10a. It can be seen that increasing the number of images leads to smaller average errors, indicating that the accuracy of the method increases. Also, using our method with more than 2 images consistently originates smaller errors than Zhang's method, that used 15 calibration images.The results show that the camera with the narrowest FOV originated the smaller errors. This can lead to the conclusion that its calibration was more accurate, which can be explained by the fact that it is less affected by radial distortion, and thus its removal is more effective.Another comment is that we empirically found out that calibrating using the original images (without distortion removal) lead to much higher standard deviations, indicating that the results are less precise. Thus, the quality of the calibration obtained with this algorithm highly depends on the amount of distortion present in the images. Notice that the linear method tested in Section 5 makes use of the IRD model, decreasing the need to remove radial distortion, because this non-linear effect is partially compensated by the model.As a final remark, we observed that providing initial values that are considerably distant from the real initialization still resulted in the convergence to the same point, meaning that the probability function is locally convex and not affected by local minima.The last experiment was performed with the intent to analyze how different surface angles affect the algorithm accuracy. We divided the calibration data set acquired with camera C1 into two sets of images, one containing images with angles up to 10° and the other with angles starting at 20°. For all possible sets, calibration was performed and the distance to the best-fitted plane of the validation images was computed. Results in Fig. 11show that although the results do not vary significantly, using images acquired with higher angles w.r.t. the plane surface provide a smaller average error. This can be explained by the fact that acquiring images with close to fronto-parallel surfaces may affect the sensor's depth measurements due to the reflection of light.In this work, we presented advances in the calibration of TOF cameras by means of images of a flat surface, without performing feature extraction. More precisely, we presented a deterministic lateral calibration by solving a system of linear equations by means of two images of a plane, or by solving a system of quadratic equations by means of one image of a plane, and a probabilistic method with numerical optimization that requires only one image.We observed that the deterministic linear method is too unstable for the moment with respect to the practical error margins of the current TOF sensors. The computation of the IRD for obtaining the intrinsic pinhole parameters is not sufficiently accurate yet, except for very low resolutions, in addition with a non-linear optimization. However, we discovered that the HIRD is more accurately recovered, that is, the IRD up to a global scale factor. This HIRD appears to be suitable for the segmentation of planar surfaces in the scene. Synthetic and real experiments prove that good segmentation results can be obtained.We further investigated calibration procedures for TOF cameras by means of one image, and derived non-linear equations that allow the computation of the intrinsic parameters. However, these equations show that the computation of the IRD depends on the squared inverse of the measured radial distances, being extremely sensitive to noise and inadequate for performing the calibration. In order to tackle this problem, we came up with a method based on the idea of maximizing the probability that the reconstructed points belong to a planar surface. This is solved using a maximum likelihood estimation approach, leading to the computation of both the intrinsic parameters and the observed plane equation. Synthetic experiments suggested that this method was robust, providing good results for significant error levels. Also, real experiments showed that the method's precision increases with the inclusion of extra calibration images. Despite being slightly different from the estimations computed using a state-of-the-art method, our results seem to be more accurate since smaller errors were achieved. More precisely, the method of Section 6.2 yields a calibration that proves to be more accurate than Zhang's method when applied with more than two images, as validated in Section 7. This method has moreover the significant advantage of not requiring feature extraction which can be a problem with certain materials and in certain types of environment with low illumination ([9]). We observed that the quality of the calibration highly depends on prior distortion removal.As future work, the algorithm should include distortion estimation, avoiding the need for a pre-processing step. A possible way to achieve this is to design stable procedures for computing a general parameter-free IRD, compensating lens distortions as well as systematic errors of the TOF measurements.The main contributions of this work are the introduction of the IRD, leading to two theoretical calibration results (deterministic procedures by 1 or 2 featureless images), but also offering a useful planar segmentation algorithm, and the general study on calibration methods using only images of flat surfaces and no feature extraction. The proposed methods are innovative, simple and provide acceptable calibration results, which could be used in alternative to methods that require feature extraction.

@&#CONCLUSIONS@&#
