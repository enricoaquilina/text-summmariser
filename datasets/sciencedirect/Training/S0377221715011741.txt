@&#MAIN-TITLE@&#
Multicriteria optimization in humanitarian aid

@&#HIGHLIGHTS@&#
We review the literature on multicriteria optimization in humanitarian aid.Application area: all phases of disaster management.Objective functions are classified and discussed, as well as solution methods.Available articles are presented and classified.We conclude with an outline of future research directions.

@&#KEYPHRASES@&#
Humanitarian aid,Humanitarian logistics,Disaster management,Multicriteria decision making,Multiple objectives,

@&#ABSTRACT@&#
In the recent past, the global public has been alarmed by several natural disasters with tremendous consequences. The OR/MS community has reacted by developing quantitative methods to support humanitarian aid, which have become well-established in the areas of disaster operations management and humanitarian logistics. An especially rapidly growing strand of literature in these areas uses multicriteria optimization methods, which is natural in view of the ubiquity of multiple objectives in disaster operations. The article reviews recent literature on the application of multicriteria optimization to the management of natural disasters, epidemics or other forms of humanitarian crises. Different optimization criteria as well as multicriteria decision making approaches applied in this field are discussed and examined. The available literature is classified according to several attributes, and each paper is presented in some detail. Possible future research directions are outlined.

@&#INTRODUCTION@&#
In the last years, the world has witnessed several devastating disasters. Among them, the 2010 Haiti earthquake disaster and the 2011 Japanese earthquake and tsunami disaster possibly received the highest media attention, but these are only two examples from a longer list of catastrophes with tremendous impacts. Worldwide, the number of natural disasters has steadily increased since the 1970s, which is mainly due to growing frequencies of storms and floods. The Emergency Events Database (EM-DAT), containing data on the occurrence and effects of technological and natural disasters from 1900 to the present day, recorded 341 climate-related disasters per year on average since 2000, which is an increase of 44 percent, compared to the average over the years 1994–2000, and more than twice the average over the years 1980–1989 (CRED, 2015). Climate-related as well as geophysical disasters entail a huge amount of harm to humans. Its alleviation by humanitarian aid requires forceful efforts, intelligent planning and well-organized deployment of available resources, including efficient use of donations.The scientific community, especially also the operations research community, has accepted the challenge to support these activities by developing pertinent models, methods and techniques, as shown impressively by the increase of the number of research articles on humanitarian logistics in the last decade (Kunz & Reiner, 2012). One of the subfields with an especially fast recent development concerns the use of multicriteria optimization methods in humanitarian aid. This is not surprising, since multiple objectives are a distinguishing feature of humanitarian logistics compared to commercial logistics, as it is well-recognized in the literature. For example, Huang, Smilowitz, and Balcik (2012) state that “humanitarian relief is complicated by the presence of multiple objectives beyond minimization of costs”, and Holguín-Veras, Pérez, Jaller, Van Wassenhove, and Aros-Vera (2013) observe that “while in the commercial [logistics] case, minimization of logistics cost is the primary motivation, in the humanitarian case other factors come into play, most notably the impacts on human suffering.” Thus, it is very natural to build on the well-established methodology of multicriteria optimization to provide decision makers (DMs) in humanitarian aid with suitable decision support.The present review surveys the literature on quantitative decision making approaches to humanitarian aid that use genuine multicriteria optimization methods. We did not restrict ourselves explicitly to the most recent time. Nevertheless, it turned out that the large majority of all articles in the indicated area appeared within the last eight years. Therefore, it is likely that the coming years will still see substantial innovations.To clarify the scope of this review, some remarks are in place. We scanned the literature for articles containing the terms “multicriteria” or “multi-objective”, together with one of the terms “humanitarian aid”, “humanitarian logistics”, “disaster” or “catastrophe”. For each candidate article, we checked whether it addressed multicriteria optimization (in the sense of the standard textbook by Ehrgott, 2005). More precisely, we considered articles using one of the multicriteria optimization concepts listed in Section 3 below. We did not include articles where a weighted sum of functions with fixed weights was optimized, though the boundaries between such approaches and “proper” multicriteria optimization approaches may be fluid. If weights were systematically varied, the article was included. Generally, our distinction between papers that are “multicriteria” (and should therefore be included) and those that are not, has been based rather on the applied solution technique than on the nature of the problem.With respect to the term “humanitarian aid”, we relied on the Web definition “Humanitarian aid is material or logistical assistance provided for humanitarian purposes, typically in response to humanitarian crises including natural disaster and man-made disaster” (Humanitarian Aid, 2015). Evidently, this definition largely overlaps with that of humanitarian logistics as addressed in the standard book by Tomasini and Wassenhove (2009), but it may also encompass activities that are usually not considered as logistical, such as medical treatment. We only included a paper if at least one of its considered objectives had a humanitarian (rather than financial or military) motivation. Moreover, we further restricted the scope of the review by three additional constraints: First of all, only the case of natural disasters was considered. Secondly, we did not consider papers dealing with development cooperation, even if they also touch disaster-related issues. Third, we excluded articles where the focus is rather on risk assessment than on disaster management (e.g., papers dealing with the decision on whether to evacuate or not, given a certain flood level).Optimization in humanitarian aid and disaster operations management has been addressed by several surveys, starting with the meanwhile classical review by Altay and Green (2006). Related and more recent surveys have been given in Caunhye, Nie, and Pokharel (2012), Galindo and Batta (2013), Hoyos, Morales, and Akhavan-Tabatabaei (2015), Kunz and Reiner (2012), Liberatore, Pizarro, de Blas, Ortuño, and Vitoriano (2013), Ortuño et al. (2013), Özdamar and Ertem (2015) and Simpson and Hancock (2009). None of these surveys, however, is focused on multicriteria optimization models, although some of them, as Caunhye et al. (2012), emphasize the importance of such models. Ortuño et al. (2013) mention multicriteria decision making in a special paragraph and give some references, but do not discuss them. In the present review, we shall strive for more completeness and describe each cited article in some detail.The fact that a review as the one given her is still missing would not be a sufficient justification for a new survey if multicriteria approaches would not be of utmost importance for the considered field of humanitarian aid. Actually, there are few other application areas of operations research for which a multicriteria viewpoint is more relevant. The goal of humanitarian aid is certainly not to make profit, so any method or technology that reduces the question of how to organize humanitarian aid to an optimization problem with a monetary objective seems clearly inadequate. On the other hand, humanitarian aid does involve the investment of money, either received from public funds or from private donors, and any actual investment entails opportunity costs with respect to alternative humanitarian operations that cannot be funded simultaneously. Therefore, the cost criterion cannot be neglected either. This shows that in humanitarian aid, at least two substantially different criteria play an inevitable role, and as soon as one tries to specify the non-monetary criterion in more detail, it often turns out that it splits into several partial criteria that are conflicting as well. Thus, operations research approaches to humanitarian aid have an intrinsic multicriteria character from the very beginning.The review is organized as follows: Section 2 presents and discusses the most usual types of objective functions applied in the models of the surveyed literature. Section 3 outlines the used concepts from multicriteria decision making. Section 4 is the core of the survey, it lists the found articles, describes them and classifies them according to several attributes. In Section 5, we suggest topics for future research. Some concluding remarks are given in the final Section 6.A large variety of optimization criteria have been employed in the literature on operations research approaches to humanitarian aid. Gralla, Goentzel, and Fine (2014) distinguish three main groups of criteria, namely (I) efficiency criteria, (II) effectiveness criteria, and (III) equity criteria. In our classification, we refine this scheme by partitioning the group “effectiveness” into the subgroups response time, travel distance, coverage, reliability and security. “Efficiency” means cost-efficiency and will be represented in our scheme by the group cost. In total, this produces seven groups of criteria which we discuss below. A few articles use criteria not contained in one of the groups; these criteria will be outlined in the recapitulations of the respective articles.Cost: The general term cost comprises several measures of efficiency or “economy” of the humanitarian aid operation. One cost category which is often used in the examined papers refers to logistics costs. This category includes different operational costs, among them: (i) fixed costs for the procurement of equipment as vehicles, etc., (ii) supply-side traveling costs, which are variable costs incurred in the transportation of goods or people by the aid-delivering organization, (iii) facility-related costs, as facility setup or opening costs, warehousing costs or inventory holding costs, and (iv) costs incurred for human resources, as wages for employed personnel. Of course, in models where the costs for purchasing relief goods on international or local markets cannot be considered as fixed, also this cost component matters.Usually, cost both occurs as an objective function (or soft constraint) and as a hard constraint: To some extent, the amount of money invested into a certain humanitarian operation can be determined by the DM, but more often then not, there is a hard budget limit that cannot be exceeded. (Large non-governmental organizations try to get some flexibility in the distribution of their available money over diverse operating places in order to avoid hard budget constraints for the single places, but this flexibility is restricted by earmarked donations.) In such situations, the cost objective may often be judged as less important compared to other objectives, although through the budget constraint, cost has nevertheless an enormous influence on the solutions obtained.Response time: After the occurrence of a disaster, the prompt delivery of humanitarian aid is crucial for the affected population. This fact is reflected in several papers of the surveyed literature. The importance of response time may vary for different areas and can be weighted by priorities assigned to areas, for example depending on the degree of damage. Response time measures such as latest arrival time and average arrival time (investigated, e.g., in Campbell, Vandenbussche, & Hermann, 2008) are not automatically minimized by the minimization of the total driving time for delivery routes; rather than that, a tradeoff between arrival times and route durations can occur, which makes it advisable to consider response time as a separate objective.Travel distance: The notion “travel distance” can refer to different things: we have to distinguish between supply-side and demand-side travel distance (cf. the distinction between supply-side and demand-side members of an emergency supply network in Sheu and Pan, 2014). Supply-side travel distances are already taken into account in our classification by the objective groups cost, response time and, in the case of dangerous transportation routes, also reliability and security. Demand-side travel distances, on the other hand, are traversed whenever beneficiaries have to go themselves to some shelter or distribution point, either by walking, by driving own vehicles, or by using still operative public transport. Obviously, it is crucial that also these distances are reasonably small. Thus, the demand-side travel distance measures the quality of the supply system in terms of the effort of the affected population required to take advantage of the offered aid. As supply-side travel distances are covered by other objective functions in our classification, the term travel distance will only refer to demand-side travel distance below. In some cases, also demand-side travel time is used as a criterion; we shall capture this objective under the same category.Coverage: Coverage measures the degree to which necessary relief goods or services (including medical services) are provided to the population in need. The most obvious way to represent coverage quantitatively is by indicating the percentage of the volume of supplied goods, compared to the overall amount of required goods, and analogously for services. In some papers, this percentage is determined separately for each of several affected areas, and an overall coverage measure is then derived from the local measures. A slightly different way to define coverage adopts an approach from the facility location literature by determining the percentage of people for which the distance to the next shelter or distribution center does not exceed a certain pre-defined threshold. Obviously, this latter measure also takes account of an equity concern. In the present survey, we will nevertheless classify an objective function of this kind as a coverage objective rather than as an equity objective, being aware that the distinction is not sharp. Since our notion of “services” extends to rescue operations and medical treatment, we include also objectives as the minimization of (avoidable) casualties in the category “coverage”.Reliability: In a disaster situation, the supply with humanitarian aid should be reliable, which means that the beneficiaries should be able to confide in it no matter how the natural or the socio-economic environment will possibly change. Besides incomplete information, it is uncertainty on future events that diminishes the reliability of a supply plan. Earthquakes may have aftershocks making supply pathways impassable, flood levels may continue to rise, or decreasing donations may impair the budget of a non-governmental aid organization. It can be said that the reliability criterion does not aim at something substantially different from what the other criteria address. Rather than that, a reliability measure captures the probability of being able to steadily succeed with reference to certain other criteria (as coverage or response time) in view of an uncertain short-term or long-term future.11In engineering, a broadly accepted definition of reliability is “the probability that a device, product or system will not fail for a given period of time” (Kapur, 2014).In the surveyed literature on multicriteria models for humanitarian aid, reliability is only rarely introduced as a separate objective. As a typical example among the few exceptions, let us mention Vitoriano, Ortuno, Tirado, and Montero (2011). The authors consider a delivery plan as reliable if it is likely that all arcs of the chosen routes can be traversed during the humanitarian operation, and they define therefore the reliability function as the probability that none of the used arcs fails.Security: Even if a humanitarian operation has not to be carried out in a war zone, its security is often threatened by the possibility of ransacking attempts. Vehicle transports can be assaulted, and depots or distribution centers can be plundered. It is therefore important to safeguard an aid distribution plan by organizing it in such a way that the main distribution channels and locations are well-protected. Articles taking this objective into account as a formal optimization criterion are very rare, however. As for the reliability objective, a noticeable exception is Vitoriano et al. (2011).Equity: It is a natural requirement that the distribution of humanitarian aid (of whatever form) should be fair, which means that it should not privilege certain groups of people and discriminate others. Distributional fairness is usually captured by the concept of equity. However, the literature deplores that “it is not clear how equity should be modeled” (Huang et al., 2012). In their review of equity measurement in facility location, Marsh and Schilling (1994) recall and discuss 20 different equity measures and note that there is little agreement on which measure to choose. According to Marsh and Schilling (1994), in practice, equity measures are typically not applied to individuals, but rather to groups of individuals defined based on spatial, demographic or other attributes. In the literature on humanitarian aid, the most usual way to partition a population into groups for equity considerations is with respect to spatial criteria: a group is a country, a district, a population node or some other geographical or administrative unit. In principle, however, also other groups (e.g., ethnic groups, or parts of the population related to gender, income or age) can be considered. The aim is then to organize the humanitarian aid in such a way that none of these groups is systematically disadvantaged.The simplest manner to address equity is to consider the worst case value of a measure of disutility over all groups of people as an objective function. This objective complements the objective function given by the sum of disutility values over all groups, which is an (un)effectiveness measure, being low if the provided aid is effective.22Simple examples are the objectives of the p-center and the p-median problem, respectively, in facility location: the former objective is defined as the worst-case distance to the nearest facility, whereas the latter objective is the sum of these distances.In our literature review, taking the worst case over all groups turned out as the most frequent pathway to the representation of equity.33From a theoretical viewpoint, the worst-case measure can be justified by means of Rawls (1971) famous theory of the “veil of ignorance” behind which people have to agree on general rules without being able to get to know their own particular situation to which the same rules will be applied, which favors min-max-type considerations.Special cases of objective functions of this type are latest arrival time or smallest demand satisfaction rate (Gralla et al., 2014). An alternative is to employ measures expressing deviations from average values, such as the variance, the standard deviation, or the sum of absolute deviations. Also the range between best and worst value can be used as a criterion. More complex equity measures, such as the Gini index, Schutz’ index or Theil’s index, are widely applied in the literature on income distributions, but rarely in humanitarian logistics.Distress: By the term “distress”, we subsume psychological or social costs, which are addressed only in a minority of the surveyed articles. However, in addition to judging the efficiency of a humanitarian operation in monetary terms, it should also be evaluated with respect to the extent by which it averts or reduces deprivation, pain, affliction, hardship, negative emotions and social disturbances on the side of the affected population. Hu and Sheu (2013) and Sheu and Pan (2014) address feelings as stress, anxiety, grief and depression. Holguín-Veras et al. (2013) introduce the concept of deprivation costs as an attempt to quantify the suffering of disaster victims lacking vital commodities.It is evident that all these types of psychological or social costs are more difficult to measure than physical or economic quantities as response times, distances, or monetary costs. In Holguín-Veras et al. (2013), an attempt is made to quantify deprivation costs (the negative consequences on wellbeing resulting from the lack of urgent goods as water, food etc.) on an economic scale: conceptually, the deprivation cost of a certain commodity is seen as a nondecreasing, convex function of the time that has passed since the need for this commodity has been completely satisfied for the last time, and the value of this function is defined through the willingness to pay for obtaining the commodity. This does not yet fully answer the question of how to empirically estimate deprivation cost functions, a question for which the authors of Holguín-Veras et al. (2013) refer to further research. Also in Hu and Sheu (2013), psychological cost is seen as a function of the waiting time (here: the waiting time until debris removal and disaster recovery); the authors build on some methods for the assessment of psychological distress that have been proposed in the psychological literature and the literature on technological hazards.In this section, we shall shortly outline some concepts from the area of Multicriteria Decision Making (MCDM) that we found applied in the surveyed articles.Pareto optimization: If DMs face a problem involving several conflicting objectives, Pareto optimization can considerably alleviate their cognitive burden by reducing the (possibly huge) set of feasible decisions to a much smaller subset of alternatives from which it may then be easier to choose the option that best fits their preferences. This method is especially useful when an a priori aggregation of the different objective functions to a single one is considered difficult, questionable or even impossible in practice. A typical example is a conflict between monetary and non-monetary objectives, e.g., costs and human lives; few DMs in humanitarian aid would be willing to feed an optimization tool with a number indicating the amount of money that should be invested for saving a human life. Of course, the tradeoff between conflicting objectives can finally not be escaped, but it can be valuable if in a first step, a computerized system already filters out the many alternatives that are dominated by some other alternative in all objectives. Pareto optimization relies on the determination of the set of Pareto-optimal solutions, that is, solutions that cannot be improved in any objective without deteriorating another objective. Pareto-optimization is especially prominent in multicriteria combinatorial optimization, see Ehrgott and Gandibleux (2000).A disadvantage of Pareto optimization is that only a small number of objectives can be handled. For a larger number of objectives, the set of Pareto-optimal solutions typically grows beyond a size for which this set is still helpful in the decision-making process. Moreover, it is very difficult to visualize the Pareto frontier (the image of the set of Pareto-optimal solutions in the space of objectives function values) if more than three objectives are present, and already for three objectives it is not quite easy.The term multi-objective optimization is frequently seen as equivalent to Pareto optimization. Therefore, we use both terms synonymously in the present paper. It should be noted that in this sense, multicriteria optimization is much broader than multi-objective optimization.Lexicographic optimization: In cases where objective functions of strongly varying degree of importance are involved, lexicographic optimization can be a computationally fast way to arrive at reasonable solutions. The method starts with categorizing the objectives into a hierarchical order of decreasing priority levels. The objective with highest priority is optimized first. After that, the objective with second-highest priority is optimized on the additional constraint that the value of the first objective remains optimal. Of course, this is only meaningful if there are multiple optimal solutions on the first priority level. The procedure is repeated then for the subsequent priority levels.In the area considered in this survey, lexicographic optimization is usually not applied in its “pure” form, but rather in the following modification for a bi-objective problem: first, the more important objective is optimized. Then, the less important objective is optimized on the constraint that the more important objective remains nearly optimal within a certain tolerance range. In this way, the set of solution candidates for the second optimization step is enlarged.It is clear that lexicographic optimization cannot capture tradeoffs between different objectives, which makes it possibly less attractive for researchers thinking in terms of multi-attribute utilities. To overcome the drawback that as a stand-alone technique, lexicographic optimization can accept arbitrarily poor values of lower-priority objectives, the method is often combined with goal programming (see below).Scalarization: Scalarization is the reduction of a “vector” optimization problem, i.e., a problem involving multiple objectives, to a “scalar” (single-objective) optimization problem. This is often done implicitly in other multicriteria decision making approaches, including Pareto optimization, as part of their computational solution procedure (typically in an iterative manner). However, scalarization can also be applied as a stand-alone method. Most frequently, weighted sums or weighted Tchebycheff distances are used to aggregate the objective functions. While the former alternative fails to find so-called “unsupported” Pareto-optimal solution points unless special convexity conditions are satisfied (which is often not the case in humanitarian logistics problems), the latter alternative can also find those Pareto-optimal solutions that are not optimizers of some weighted sum. Of course, in both alternatives, the obtained solutions depend on the choice of the weights. As mentioned in Section 1, we include scalarization models in this survey only when weights are systematically varied.Goal programming: In Goal Programming (GP), developed by Charnes, Cooper and Ferguson (see, e.g., Charnes & Cooper, 1977), the DM defines target values for each of the single objectives (goals). GP is conceptually very different from Pareto optimization since in GP, also dominated solutions can in principle be accepted as solutions if they match the goals. This consideration is grounded in Simon’s well-known “satisficing” logic (see, e.g., Simon, 1972): it is assumed that DMs will be satisfied if their goals are achieved, no matter whether another solution with better objective function values can be reached or not. The fact that there are usually multiple solutions meeting the goals calls for a selection method. According to Tamiz, Jones, and Romero (1998), the two main alternative ways to do the selection are (1) the optimization of an achievement function, aggregating the (weighted) deviations from the target values, and (2) the lexicographic GP method, where GP is combined with lexicographic optimization as described above.In the articles surveyed here, it seems that mainly two factors were strong motives for the eventual choice of the easy-to-handle GP paradigm, namely either a larger number of objectives, or the additional complexity involved by a stochastic optimization model.Compromise programming. Contrary to GP, Compromise Programming (CP), originally proposed by Yu (1973) and Zeleny (1973), always produces a Pareto-optimal solution. It starts with determining the ideal point, which is the vector of the best-possible values of the different objectives, considered separately from each other. Usually, this point is not attainable by any feasible solution. The idea of CP is to determine that feasible point in the space of objective function values that is as close as possible to the ideal point. Obviously, this procedure depends on a definition of “closeness”, i.e., on the choice of a mathematical distance measure. Different distance measures have been used in the literature, in particular those derived from the norms L1, L2 and L∞, which lead to the Manhattan distance, the Euclidean distance and the Tchebycheff distance, respectively. We found few papers adopting the CP approach; the motivations for using it seem to be of a similar kind as in the case of GP.Analytic Hierarchy Process: The Analytic Hierarchy Process (AHP; see, e.g., Saaty, 2008) considers finite and usually rather small sets of discrete decision alternatives. The aim is to rank these alternatives through a process of splitting the overall goal into a hierarchy of subgoals, criteria and subcriteria. Based on this hierarchy, pairwise comparisons between the subcriteria of each higher-level criterion on the one hand, and between the alternatives with respect to each (sub)criterion in the other hand, are carried out by the DM. This produces an assignment of rating values to the single alternatives in the considered set. In our review, we found only two papers (Bozorgi-Amiri & Asvadi, 2015; El-Anwar, El-Rayes, & Elnashai, 2009) using the AHP.In this subsection, we start the discussion by referring to a few publications that do not fully fit into the scope of this review, but provide important information for our thematic context by studying diverse objective functions for disaster relief.The article by Holguín-Veras et al. (2013) is of special interest in our context because of the theoretical effort it makes to identify a suitable objective function for post-disaster humanitarian logistics. The authors distinguish two different cost types, logistics cost and deprivation cost, where the latter measures the amount of suffering of the victims of a disaster caused by the lack of necessary goods. It is argued that deprivation cost increases with deprivation time according to a monotonous convex function. By the supply of the required goods, the level of deprivation can be re-set (in the ideal case) to the value zero, but starts again to rise during the time after an instance of supply. A model for post-disaster humanitarian aid should consider several time instances where deliveries take place, and the overall service quality should be measured by total deprivation cost, for which the more traditional measures response time (in the form of penalties or of constraints) and coverage are only proxies. Finally, the authors aggregate deprivation cost and logistics cost to a single objective function called social cost, based on considerations from welfare economics. The article gives a fresh impetus by a refined quantification of the victim-related part of the objective evaluation, taking time-related aspects of supply into account, which is a clear progress compared to “static” service quality measures.Also Huang et al. (2012) do not yet come up with a multicriteria optimization algorithm (the authors mention this as a topic of future research). The aim of the article is to modify the classical split delivery vehicle routing problem (SDVRP) to three alternative versions, having efficiency, efficacy and equity, respectively, as objective functions. Efficiency is defined as transportation cost (this gives the classical SDVRP), efficacy is measured as the sum of demand-weighted arrival times of the relief packages to be delivered, and equity is expressed by the degree of variation of efficacy in the diverse demand nodes. To operationalize the last quantity, the authors propose again three alternatives. The first two of them are maximum deviation and standard deviation, whereas the third uses the sum of disutilities over time of the current uncovered demand in the demand nodes, based on a convex disutility function. In the case of time-critical (non-periodic) delivery, this third variant of the equity objective function favors routing plans where the most urgent needs are satisfied as soon as possible, and the remaining time is used to gradually approach complete coverage of the overall demand.Gralla et al. (2014) aim at the determination of a multiattribute utility function for the objectives (attributes) relevant in the earliest stage of response, the week after a disaster. For preference measurement, conjoint analysis to evaluate alternative aid delivery plans is used. Conjoint analysis can handle piecewise linear, additive utility functions. Contrary to Holguín-Veras et al. (2013), where disutility is quantified from the viewpoint of the beneficiaries, Gralla et al. (2014) elicits preference statements from field experts in humanitarian logistics whose preferences are assumed to be sufficiently aligned with those of the beneficiaries. As attributes, the authors consider (i) total cargo delivered, (ii) total delivered of each type of item (shelter, health, water, food), (iii) total delivered to high- and low-priority locations, (iv) speed of delivery, (v) cost. Total cargo is measured in percent of requested cargo, so it is a coverage measure. Speed of delivery is obviously a response time measure. The conjoint analysis produces the part-worth utilities by which each attribute level contributes to the overall utility. The coverage objective turned out as the most important objective, followed by the response time objective. The cost objective turned out as least important one.Campbell et al. (2008) present an evaluation of two alternative objective functions for response time. The authors argue that the arrival time of relief supplies at the beneficiaries is critical for their survival rate and the amount of suffering. In contrast to the well-known approach of minimizing total length of delivery tours, this work focuses on service-based objectives, striving for fast and fair deliveries of relief supplies. For the traveling salesman problem (TSP) and the vehicle routing problem (VRP), the authors investigate the impact of minimizing the maximum arrival time (minmax), compared to minimizing the average arrival time, or equivalently the sum of arrival times (minsum). They present integer programming formulations for the envisaged routing problems and examine the differences between the classical total duration objective, the minmax objective and the minsum objective for different variants of TSP and VRP, providing also theoretical results.Rekik, Ruiz, Renaud, Berkoune, and Paquet (2013), finally, describe a network design and humanitarian aid distribution problem in the aftermath of a disaster. They present four models for different decisions: number of facilities to open, location of facilities among a predefined set of humanitarian aid depots, allocation of resources to the facilities, and distribution of humanitarian aid, respectively. Two kinds of objectives are addressed: while the network design models aim at maximizing the coverage of the affected population, the distribution problem minimizes the total transportation time. The models are integrated in a decision support system which incorporates geographical maps and allows DMs to analyze different solutions interactively.A hierarchical classification of decision making criteria for the special case of shelter location is given by Nappi and Souza (2015). Optimization algorithms with respect to these criteria are not considered.Let us now turn to articles that explicitly deal with multicriteria optimization approaches in humanitarian aid. We shall subdivide the papers guided by the application type, i.e. disaster lifecycle phase, and further classified by the used methodology.First, we review articles where the used optimization method falls into the class of deterministic optimization. An overview is given in Table 1. Later, in Section 4.3, papers relying on methods of optimization under uncertainty (as stochastic, robust or fuzzy optimization) will be addressed. We would like to emphasize that an assignment of an article to the subsection on deterministic optimization does not imply that the underlying model itself is fully deterministic: Several of the reviewed papers using models with stochastic components manage to “encapsulate” stochasticity by closed-form expressions for probabilities, expected values or stochastic bounds, such that deterministic optimization techniques suffice to solve the model. This holds for Doerner, Gutjahr, and Nolz (2009), Liberatore, Ortuño, Tirado, Vitoriano, and Scaparra (2014), Nolz, Semet, and Doerner (2011), Ortuño, Tirado, and Vitoriano (2011), Rottkemper, Fischer, and Blecken (2012), Sheu (2007) and Vitoriano et al. (2011). We shall discuss these papers already in the present Section 4.2. In contrast to these approaches, Section 4.3 will deal with articles that use stochastic, robust or fuzzy optimization in a narrower sense.In the following section papers treating deterministic problems of the mitigation phase, the preparedness phase, or combining measures for the preparedness and the response phase will be discussed.Pareto optimization: In Doerner et al. (2009), a location analysis for public facilities in disaster-prone regions with respect to three objectives is presented. The first objective is a weighted mean of a minisum facility location criterion and a maximum coverage location problem (MCLP) criterion. This objective is not yet related to possible disasters, it simply aims at a good access of the population to public services in “normal” times. In tsunami-prone areas, however, certain candidate locations can be exposed to the risk of being hit by future tsunamis. Although the probability that this happens may be very small, it should be traded off against other advantages of the location under consideration. The minisum objective function is computed by determining the shortest distance from each population center to the nearest facility. The MCLP consists in minimizing the number of population members that are not able to reach a facility within a predefined reasonable walking distance. In this respect, the MCLP objective is a measure of equity and minisum is a utilitarian coverage measure as we classify it. The second objective is therefore to minimize the overall risk by possible tsunami events. For each single facility, a risk measure is obtained as the product of the long-term risk per user of the facility (depending on location and safety level of the facility) with the predicted number of users of the facility. The third objective minimizes costs of construction and maintenance of the buildings as well as additional costs for special construction methods protecting from damage by disaster events. A solution approach based on the NSGA-II algorithm is compared with a decomposition technique where the region under consideration is partitioned into smaller sub-regions and the problem is solved for each subregion separately. Both approaches are tested on two real-life instances from southern Sri Lanka.A covering tour problem for the distribution of drinking water after a natural disaster formulated in Nolz, Doerner, Gutjahr, and Hartl (2010) is extended in Nolz, Doerner, and Hartl (2010) where a heterogeneous vehicle fleet suitable for specific road categories is considered. Trucks, cars and donkeys are available to distribute drinking water in a developing country in a post-disaster situation. Since roads could have been partly destroyed and some mountainous regions might be difficult to reach even under normal circumstances, the authors divide the arcs of a street network into three categories according to their accessibility for the considered vehicles. A memetic algorithm is adapted to the real-world problem setting and a case study of a disaster-prone region in a province in the northwest of Sumatra, Indonesia, is presented.In Nolz et al. (2011) the authors add a risk aspect to the problem addressed in Nolz et al. (2010). In addition to a coverage criterion and a travel distance criterion, the risk of delivery tours for disaster relief supplies is minimized. Risk means the threat that delivery tours become impassable after a natural hazard event, which we classify here as a reliability criterion. The authors emphasize that in a post-disaster situation, it is crucial to plan delivery tours for drinking water in such a way that they remain accessible in case of aftershocks or increasing water levels after floods. They develop correlated and uncorrelated risk measures to capture the differences of natural hazards and incorporate them into a multi-objective integer program. In a two-phase solution approach, first, potentially Pareto-optimal solutions are generated by a memetic algorithm. Second, an enrichment procedure is applied to generate a broader range of potentially Pareto-optimal alternatives by a multi-objective labeling algorithm. The suggested approach is tested on real-world data from a province in Ecuador and the results for different risk measures are analyzed.Chanta and Sangsawang (2012) use the classical objective functions of the MCLP and of the p-median problem, respectively, to determine the locations of shelters for flood disasters. The resulting bi-objective combinatorial optimization problem is solved (in the sense of the determination of the Pareto front) by means of the epsilon-constraint method. The authors report results for a case study referring to the Nonthabury province in the central part of Thailand.Zhang, Dong, and Frank Chen (2013) investigate how to locate emergency facilities while minimizing two objectives, the total distance between facilities and demand nodes, weighted by the degree of demand for rescue services, and the maximal weighted distance between a facility and a demand node. The authors formulate a bottleneck Steiner tree problem, where a set of terminals (demand nodes) needs to be interconnected via a network, and additional Steiner nodes (facilities) can be added. In specific cases, facilities can be located at demand nodes. An upper bound on the number of facilities to be constructed is given. However, the location of facilities is not restricted to predefined candidate nodes. The authors treat the bi-objective problem by the stochastic diffusion search metaheuristic.Lexicographic optimization:Koyuncu and Erol (2010) deal with optimal resource allocation in the case of a large influenza pandemic. Besides infection control by social distancing and other measures, interventions mainly aim at pharmaceutical approaches (vaccines and antivirals) as well as on hospital treatments. The authors focus on the two last-mentioned classes of interventions. They develop a mathematical model for the optimal allocation of resources, taking geographical parameters such as different exposure rates in different regions into account, and distinguishing between compartments of the population defined by age group and risk level. In a lexicographical manner, three objective functions are minimized. In the order of decreasing importance, these are: the number of deaths, the number of cases, and the number of morbidity days. A case study for Turkey distinguishes an optimistic, a most likely and a pessimistic disaster scenario. The results show that the available budget per person has a strong influence on the outcome. Optimal solutions tend to focus rather on preventive vaccination and on antiviral treatment than on hospital resources. A stochastic generalization is mentioned as a topic of future research.Rottkemper and Fischer (2013) base their work on the model presented in Rottkemper et al. (2012) (described below) dealing with a situation where the condition of the affected community worsens rapidly in the aftermath of a disaster and unforeseen events can lead to the occurrence of additional demand. As in Rottkemper et al. (2012), it is assumed that a relief network has been established, on which a single item is transported between a global, a central and several regional depots. The authors develop multiple scenarios that are solved before a crisis occurs in order to develop decision rules that can support DMs in a disaster situation. The decisions to be made concern the questions which amounts of relief items to replenish or relocate at which point in time, and where to stock the relief items. The two objective functions to be minimized are total operational costs and unsatisfied demand, where, as in Rottkemper et al. (2012), operational costs include transportation costs as well as inventory holding costs. Contrary to Rottkemper et al. (2012), the two objective functions are not aggregated by a weighted sum, but an extension of a lexicographic approach (prioritizing the unsatisfied-demand objective over the cost objective) is applied. The authors generate scenarios which represent different future developments of a malaria epidemic in Central Africa.Scalarization:Esmaeili and Barzinpour (2014) investigate a three-objective urban disaster management problem, where the first objective is to maximize the coverage of the population inside the municipal region, the second objective is to minimize facility setup costs, transportation costs, inventory holding and shortage costs, and the third objective is to maximize the coverage of the population outside the municipal region. The latter refers to demand from a neighbor region that does not belong to the same municipal authority, but still has to be considered in the context of humanitarian aid. An evolutionary algorithm where the fitness function combines the three objectives and adds a barrier function is applied and compared to an LP-relaxation of the mixed-integer programming formulation.Goal programming:Barzinpour and Esmaeili (2014) establish a two-echelon relief chain by locating emergency management facilities, determining their inventory level and allocating beneficiaries to them. The authors formulate a mixed-integer linear program with three objectives. The first objective is to maximize the coverage of the population, the second objective is to minimize facility setup costs and the third objective is to minimize transportation costs, inventory holding costs and shortage penalty costs for inventory. The authors divide the affected region into different zones, either using municipal boundaries or virtual ones and compare the impact of the zoning approaches. Demand for each zone is calculated based on population and damage severity estimated proactively for earthquakes. A goal programming approach is used to solve the multicriteria problem, where the goals are derived from expert judgments of municipal authorities. The authors apply their method to an earthquake case study of an urban district in Tehran, Iran. Results show that collaboration between subregions in the context of virtual zoning instead of obeying municipal boundaries, can improve solution quality with respect to all objective functions.Analytic Hierarchy Process:Bozorgi-Amiri and Asvadi (2015) deal with the location of a relief logistics center (RLC). First, criteria and possible locations for the RLC are defined. The aim is to rank the possible locations. The main criteria are availability, risk, technical issues, cost, and coverage. Based on pairwise comparisons, criteria are evaluated, as well as the suitability of the possible locations with respect to the criteria. Contrary to standard AHP applications, interval estimates are used instead of crisp ones to fill the comparison matrices. Two methods, lexicographic goal programming and two-step logarithmic goal programming, are applied to obtain the rank scores. The authors illustrate the method by a numerical example with 22 possible locations in the city of Tehran, the capital of Iran.In the following section papers related to deterministic post-disaster problem settings of the response phase and rehabilitation phase will be discussed.Pareto optimization:Saadatseresht, Mansourian, and Taleai (2009) optimize the evacuation of a region after an emergency with respect to two objective functions, namely (i) the weighted distance between affected places and assigned safe places, and (ii) a function measuring an appropriate allocation of the population to safe places compared to their capacities. The authors propose a solution approach which consists of three steps. First, safe areas are designated. Then, building blocks are allocated to candidate safe areas and shortest paths, respecting traffic and safety constraints between building blocks and the safe areas, are determined. Finally, building blocks are definitely assigned to safe areas. The assignment is based on the distances between building blocks and safe areas, the capacities of the safe areas, and the numbers of population members in the building blocks. Designation of candidate safe areas and shortest paths is performed by a geographic information system (GIS) network analysis tool, and the NSGA-II algorithm is used to solve the bi-objective problem. The authors apply their approach to a case study from Tehran, Iran.Nolz et al. (2010) address a covering tour problem for the distribution of drinking water after a natural disaster. The authors present a bi-objective problem where two different formulations for the second objective are investigated. As in Doerner et al. (2009), the first objective is a combination of the minisum facility location criterion and the MCLP criterion. For the second objective, the following two alternatives are considered: alternative 1 takes the overall travel time as a criterion, whereas alternative 2 takes the latest arrival time at a population center point instead. A hybrid method, based on a genetic algorithm, variable neighborhood search and path relinking, is developed to solve the problem heuristically. The algorithm is tested on real world data from the province Manabí in Ecuador, and results on small instances are assessed by comparison to results produced by an exact epsilon-constraint method. The objective of alternative 2 typically leads to shorter delivery tours, reaching the last supplied customer earlier.Another aspect is addressed by Falasca and Zobel (2012) who deal with the assignment of volunteers to tasks in humanitarian logistics based on their abilities but also according to their preferences. The authors formulate an integer programming model for the assignment of both individual volunteers and volunteer groups to tasks with the aim of balancing the level of task fulfillment and satisfaction of volunteers. Two objective functions are to be minimized. The first one represents total shortage costs which result from task shortages occurring when a given time block remains unassigned. The second one, satisfaction of volunteers, represents the number of undesired assignments; it expresses the preferences of volunteers for performing specific tasks in specific time blocks. This kind of objective function is not included in our classification. The DM’s evaluations with respect to each objective are represented in the model through the use of fuzzy membership functions. These membership functions allow the exploration of the consequences of decisions on the volunteer scheduling process.Abounacer, Rekik, and Renaud (2014) address a location-routing problem where the number and positions of humanitarian aid distribution centers are determined and the transportation of relief items from these distribution centers to demand nodes is planned. Three objectives are considered: (i) minimization of the total transportation time including back and forth travel times, docking times, and loading and unloading times of all products, (ii) minimization of the number of people (personnel) needed to operate the selected distribution centers (we classify this as a cost objective), and (iii) minimization of total uncovered demand. The authors apply an epsilon-constraint method to handle the multi-objective problem. The exact solution algorithm is finally modified to an approximation method in order to reduce computation time.Also Chang, Wu, Lee, and Shen (2014) deal with the emergency logistics to transport resources from supply nodes to demand nodes in the aftermath of a disaster. Resources are dispatched via routing schedules determined for a number of vehicles departing from multiple depots. Three objectives are to be minimized, namely the unsatisfied demand, the delivery time, and the total transportation costs. The authors propose a multi-objective genetic algorithm encompassing greedy search, and apply it to an earthquake case study for Taiwan.Wang, Du, and Ma (2014) face an open location-routing problem with split deliveries in a post-earthquake situation. In the open location-routing problem, vehicles are allowed to wait at their last node without returning to the start node. The problem encompasses the location of distribution centers and the allocation of affected areas to the distribution centers as well as vehicle routing with split deliveries in the available transportation network. Three objectives are addressed, namely minimization of the maximal travel time, minimization of the total cost, including the opening costs of distribution centers and vehicle travel costs, and maximization of the minimum route reliability for all vehicles. The authors define reliability of a route as the probability that drivers can deliver relief items to all demand nodes on that route; this probability is computed based on the probabilities for traversing the single links in the network successfully. The authors propose two evolutionary algorithms to solve the proposed model and evaluate the performance of the solution methods in an earthquake case study for China.Rath and Gutjahr (2014) extend classical formulations of the warehouse location routing problem in order to make them applicable in a disaster response context. Relief commodities arrive at supplier points (international airports, harbors, local suppliers) and are transported from there to intermediate warehouses, where they are stored. From the warehouses, they are delivered to the beneficiaries, who live in a given set of population nodes, by means of a limited fleet of vehicles. Decisions are necessary about where to open warehouses, how to assign the beneficiaries to the warehouses, and how to plan the vehicle tours for the supply. The first two objective functions are related to cost: objective function 1 expresses the strategic costs for medium-term decisions, and objective function 2 captures short-term operational costs such as warehousing costs. The third objective function measures the uncovered demand. For computing the Pareto front of the resulting multi-objective mixed-integer programming problem, the epsilon-constraint method is applied. The occurring single-objective subproblems have the form of multiple-depot, multiple-trip capacitated team orienteering problems. After the design of an exact solution algorithm, which works for small instances only, this algorithm is modified to a “matheuristic” in the sense of Boschetti, Maniezzo, Roffilli, and Röhler (2009), i.e., an algorithm hybridizing mathematical programming with metaheuristic features (here: elements of Variable Neighborhood Search). As an illustration example, results on test instances concerning the province Manabí in Ecuador are provided.A different application type is investigated by Sun, DePuy, and Evans (2013) who concern themselves with the allocation of patients to hospitals in the case of an influenza pandemic. The authors propose a series of three models with consecutively increasing complexity. The first model is still single-objective, the objective function being total travel distance of the patients to the hospitals assigned to them. Hospital capacities with respect to equipment as normal beds and intensive care unit beds are taken into account, whereas personnel capacities are not yet regarded. It is assumed that the demand for each day of the planning horizon can be predicted by an epidemiological model. Assignment decisions have to be made for each day, considering the different patient types and their corresponding lengths of stay. The second model adds the maximum travel distance as a second objective function, which takes the equity aspect into account. Moreover, the extended model includes constraints on the personnel capacities (doctors, nurses, lab technicians) of the hospitals. The bi-objective nature of the model is treated by constraining the second objective function to certain values which are systematically varied. In the third, most refined model variant, model 2 is extended by the possibility of resource shifts between hospitals. A case study concerning the Louisville-Jefferson County in Kentucky illustrates the approach.Scalarization: One of the classical papers in this group is Viswanath and Peeta (2003) where a multi-commodity maximal covering network design problem for emergency response after an earthquake is formulated. The authors minimize total routing cost while maximizing the total demand covered, where a population node is covered if it can be accessed via a link. Since bridges are considered to be the weakest links on critical routes after an earthquake, survivability of routes is enhanced by retrofitting bridges to strengthen their ability of withstanding earthquakes. Budget constraints are introduced including costs for repair operations. The authors introduce a problem reduction technique to reduce computational times, assuming that critical routes are usually restricted to a limited geographical region around an origin-destination pair. Valid inequalities are formulated and incorporated in the proposed model solved using CPLEX. The authors perform a vulnerability analysis to evaluate the level of connectivity of origin-destination pairs after an earthquake. Experimental results for a case study of an earthquake-prone region in Indiana are presented.Sheu (2007) proposes an approach that starts by predicting the time-varying relief demand in each affected area for the first few days after a disaster event. Relief demand is considered as stochastic, but by the use of a safety buffer concept, the forecast formula can build on deterministic confidence bounds. An essential part of the approach is a hybrid fuzzy-clustering technique partitioning the affected areas based on four attributes into groups, where each group contains areas with comparable urgency. Concerning the logistics part, the author considers a 3-layer relief network with relief suppliers, distribution centers and relief-demanding areas. Objective functions are time-varying relief demand fill rate and time-varying distribution cost for each group of affected areas, which are aggregated to a weighted sum by weights that depend on time and on group. A comprehensive numerical study for an earthquake disaster in Taiwan is presented.El-Anwar et al. (2009) address the assignment of families displaced by a disaster to a certain number of alternative housing projects. In view of very long recovery periods after some disasters, the housing projects go beyond the aim of offering only temporary housing; they are intended to be sustainable for the case of a longer or even permanent stay. The authors propose to evaluate the housing alternatives with respect to four metrics, namely environmental performance, social welfare, public expenditure and safety (where the last refers to possible post-disaster hazards and is therefore, in the terminology of this review, rather a reliability measure). From each metric, a corresponding utility function is derived, which can be linear or nonlinear in the value of the metric. The authors apply a mixed-integer linear programming solver in order to compute worst-case and best-case values for each metric, on which the computation of the utilities is based. AHP methodology is utilized to enable the DMs to make pairwise comparisons between the utility functions, to determine weights and to check their consistency. From this information, an overall sustainability index is computed. Whereas one variant of the optimization model ignores location information, a second variant takes information on the number of families preferring a certain zone for their housing into account. The proposed method is applied to an application example concerning a possible hurricane event in the Gulf Coast region (U.S.).In Rottkemper et al. (2012), situations where unforeseen incidents can lead to sudden changes in demand are considered. A relief network distributes or relocates a single item between a global, a central and several regional depots. Total operational costs on the one hand (fixed and variable transportation costs and inventory holding costs), and unsatisfied demand on the other hand are to be minimized. A weighted-sum scalarization is used to obtain a single objective function. The authors divide demand into a certain part occurring from the sustained operations, and an uncertain part arising with some probability in the future. However, rather than estimating this probability, the authors work with two different types of weights, one for unsatisfied certain demand, the other for unsatisfied uncertain demand. A larger probability of uncertain demand is taken account of in the model by assigning a larger weight to the latter term. Penalty costs for unsatisfied certain and uncertain demand are increasing in each period of the planning horizon. A mixed-integer programming model is formulated and solved repeatedly on a rolling horizon basis, incorporating new information arising during the relief operation. The authors conduct a case study of an outbreak of malaria for a province in Burundi. A sensitivity analysis for the weights of the penalty terms for unsatisfied demand illustrates the trade-off between the two objective functions.Hu and Sheu (2013) model a post-disaster debris reverse logistics system that includes transport, recycling and disposal of debris. The three objectives of the considered multi-period problem are to minimize total reverse logistics costs, environmental and operational risk-induced penalty costs, and psychological costs of disaster recovery, measured as a function of waiting time for removal of debris. The authors formulate a multicriteria linear programming model for post-disaster debris management, consisting of four stages: on-site debris processing, debris processing at temporary sites, mass and advanced debris processing, and reproduction of construction products. Recycled material can be incorporated into the reproduction process, which provides construction material for disaster-affected locations. Experimental results computed by CPLEX are presented for a case study based on the Wenchuan earthquake 2008 in China.Sheu and Pan (2014) consider the design of an emergency supply network consisting of three interdependent sub-networks: a shelter network, a medical network and a distribution network, which are constructed in three consecutive stages in the indicated order. Moreover, they introduce psychological cost as an additional objective function in addition to operational cost and travel distance. Psychological cost, defined by negative emotions as grief, depression and anxiety, is seen as a consequence of the stress situation of a stay in the affected area, in a shelter or in a medical center. It is assumed as growing with the duration of the stay. Interviews have been carried out to quantify psychological cost in the diverse situations on a certain scale. The three objective functions are aggregated by a weighted sum, the weights being varied in a scenario analysis. For a real-world case study referring to an area in Taiwan, a centralized and a decentralized planning variant are compared. In the decentralized variant, the government and a local non-governmental organization plan their supply networks independently from each other, and the two resulting networks are then joined. In the centralized variant, the planning process aims at a joint network from the beginning.Goal programming:Vitoriano et al. (2011) present a network-flow-based optimization model for the transportation of relief goods in the response phase of a disaster. A heterogeneous fleet is considered. Coverage is addressed in two ways: by an objective function measuring simultaneously equity, and by another objective function referring to a prioritized demand node. The objectives are operationalized in the form of linear functions. This is difficult in the cases of reliability and security; for these cases, approximations based on the worst case on the one hand and an independence assumption on the other hand are derived, which splits each of these two objectives into two variants. Equity is defined in terms of the maximum deviation of the relative coverage of the demand from 100 percent over the single demand nodes. In this way, the coverage aspect is already addressed by the equity measure, which makes it unnecessary to introduce a specific coverage objective. In total, eight objective functions are obtained. Evidently, this is a too large number to make Pareto optimization a feasible option. Consequently, the authors decided to use a goal programming approach, which is well-suited for dealing with this number of objectives efficiently. As in Liberatore et al. (2014), the approach is illustrated at the hand of data from the Haiti 2010 earthquake disaster.Ortuño et al. (2011) provide a lexicographical goal programming formulation for humanitarian aid distribution. The problem setting includes the design of vehicle routes between nodes with a certain quantity of goods available for pick-up or a certain demand of these goods, and the choice of vehicle types to perform the distribution. The highest priority objective is to deliver the planned quantity of goods, while the second priority level comprises six objectives: operation cost, time of response, ransack probability, reliability, equitable distribution of goods and priority of a node. The priority objective selects a node that needs more attention because of special conditions and tries to supply this node at least with a given percentage of its demand. As the authors mention, the demand-related objectives equity and priority are directly opposed to each other, since prioritizing a single privileged node violates equity. The authors present a decision support system for humanitarian logistics operations called HADS (Humanitarian Aid Distribution System), which is developed in a free and accessible way via a web platform. The system is validated on a real operation carried out during a food crisis in Niger.Compromise programming:Liberatore et al. (2014), finally, are concerned with the recovery of damaged transportation elements as roads, bridges or tunnels, which may be impassable by debris or destroyed after a disaster. Reconstruction activities of this kind are often already urgently needed soon after the onset of a disaster to ensure that the distribution of relief commodities is not impeded. In order to simultaneously address the mentioned distribution aspect, the model contains a commodity flow model as a component. The other component of the model is the recovery model by which, under budget constraints, decisions on the restoration of certain arcs are made. Decisions on flows and recovery measures are evaluated with respect to six attributes: maximum arrival time, total served demand, ransack probability, global security, arc reliability and global reliability. A three-level lexicographic optimization is used: on the first (most important) level, the total served demand is maximized. On the second level, a compromise programming approach is applied to take the other objectives into account: the point with minimum weighted Tchebycheff distance to the ideal point is identified. Since there may still be multiple optimal solutions, the compromise programming technique is repeated on a third level of the lexicographic procedure, this time using the 1-norm (sum norm) distance instead of the Tchebycheff distance. A Haiti 2010 disaster case study is chosen to illustrate the approach.An overview of the articles where methods of optimization under uncertainty are used is given in Table 2. We partition these articles into the three groups using stochastic, robust and fuzzy optimization, respectively.In the following section papers treating stochastic problems of the mitigation phase, the preparedness phase, or combining measures for the preparedness and the response phase will be discussed.Stochastic optimization:Stepanov and Smith (2009) determine optimal evacuation routes from population nodes (sources) to shelters (destinations) through a road network, the links of which can be congested. The last property makes the simplest evacuation policy, namely transportation from source nodes to destinations along shortest paths, suboptimal in the general case. The demand in the source nodes (evacuees deciding to leave their homes in order to reach the shelters) is assumed to occur according to Poisson processes with known intensities. Road segments are modeled as servers in a queuing system whose service rates depend on the numbers of vehicles. This allows a fairly accurate representation also of the stochastic features of the evacuation process. As explicit objective functions, the authors consider (excess) total travel distance and (excess) clearing time, the latter being a response-time-related criterion. Implicitly, the maximum probability of a blocking of a road by congestion, which can be classified as a reliability criterion, is considered as a third objective. The route between a source-destination pair is chosen from the set of the k shortest paths between source and destination. An illustration example shows the application of the method.Salmerón and Apte (2010) develop a two-stage stochastic optimization model for the prepositioning of assets (warehouses, medical facilities, shelter space, ramp space for aircraft, supplies) in anticipation of a future natural disaster event. It supposes probabilistic information on demand, transportation times and survival rates to be available, and represents stochasticity by random scenarios. Strategic (first stage) decisions are on location and capacity level of assets; operational (second stage) decisions have to be made based on the concrete information that becomes known after the disaster has occurred. The first (more important) objective is to minimize the expected number of casualties. After the solution referring to this objective function has been determined, the optimal solution value is increased by a small tolerance factor, and the second objective function, representing the unmet transfer population, is minimized on the constraint that the value of the first objective does not exceed the tolerance threshold. Optimization is done under a given budget constraint. The model is evaluated on a test case from the literature, assuming a hurricane that can possibly strike six areas with different severities. Five scenarios with assigned probability estimates are considered. The authors perform a sensitivity analysis with respect to some central parameters, and they compute the value of the stochastic solution (VSS), i.e., the relative improvement achievable by solving the more complex stochastic model instead of the corresponding simpler deterministic model.Coffrin, Van Hentenryck, and Bent (2011) extend a two-stage stochastic programming model for hurricane preparedness originally introduced in Van Hentenryck, Bent, and Coffrin (2010), referring to the last mile distribution of a single commodity. A stochastic model is defined by a set of scenarios with assigned probabilities. Each scenario describes which sites have been destroyed and which have remained intact, as well as demands and travel times. First-stage decisions, to be made before the occurrence of a disaster, are required on the amounts of the commodity stored at each site, and on the allocation of customers. Second-stage decisions refer to the actual delivery plan. Since they can use the information that has become available after the disaster, the delivery plan (the solution of a multi-depot, multi-vehicle routing problem) has to be determined separately for each scenario. As objective functions, unsatisfied demand, response time, and storage costs are taken into account. Repositories are considered as capacitated, and a homogeneous fleet is assumed to be available. The optimization is carried out under budget constraints. Compared to Van Hentenryck et al. (2010), two decomposition strategies are used in order to keep the number of variables and the computation time feasible for the case of large instances: First, repositories are clustered geographically, which decreases the number of variables. Secondly, the weighted-sum aggregation of the objective functions is replaced by a lexicographic treatment. Satisfied demand is considered as the most important objective, which is optimized first. Then, routing time is optimized under the constraint that satisfied demand remains maximal. The budget constraint guarantees that the value of the third objective remains acceptable. Experimental results for benchmarks concerning the U.S. infrastructure are provided. The authors note that the approach is currently deployed at Los Alamos National Laboratory and activated each time a hurricane of category at least 3 threatens the U.S.Bozorgi-Amiri, Jabalameli, and Mirzapour Al-e Hashem (2013) deal with the choice of relief distribution centers (DCs), the pre-positioning of relief commodities, and the transportation of these commodities between suppliers, DCs and affected areas in the case of actual demand. Uncertainty on costs and demand is represented by a scenario-based model where the probabilities assigned to the scenarios are estimated by expert guesses. Some decisions (concerning DC location and pre-positioning) have to be made before, others (concerning transportation) after the occurrence of a disaster, such that a two-stage stochastic optimization model is obtained. For its treatment, the authors choose a robust optimization approach based on Mulvey’s technique. The first objective function refers to cost and is composed of a term representing the expected value of total cost, and of two other terms, penalizing total cost variability and expected inventory overloading, respectively. The second objective function minimizes the maximum shortness at demand points. To cope with the bi-objective nature of the model, a compromise programming approach is adopted. The authors apply their method to an earthquake case study for a region in Iran. The proposed stochastic model is compared to a deterministic variant, which shows that cost savings can be achieved by considering uncertainty.Related to the papers in the present group is also the article by Mortazavi, Kuczera, and Cui (2012) who address severe draughts that may affect urban water supplies, possibly to a disastrous degree. A mix between short-term and long-term options (mainly addressing storage of water) to cope with this threat is investigated. Three objectives are considered: minimization of the frequency of water restrictions (which is a coverage measure), present value of costs, and environmental stress on the river system. Uncertainty is implicitly represented through a stochastic model by building on a simulation system that produces a time series of hydroclimatic values and demands. Basing the optimization on such a time series is not “stochastic optimization” in a classical sense, but by the choice of the length of the time series, the sampling uncertainty can be controlled, which goes beyond deterministic optimization. The authors argue that a simulated time period of 100–500 years is too short to achieve a sufficient degree of reliability. Therefore, they use a time series over 10,000 years as the input for their (heuristic) multi-objective optimization procedure. The latter applies the epsilon dominance multi-objective evolutionary algorithm to determine an approximation to the Pareto frontier. An extensive hypothetical case study for the city of Sydney (Australia) illustrates the approach.In Khorsi, Bozorgi-Amiri, and Ashjari (2013), two objective functions are considered: the first objective is to minimize the maximum total amount of weighted unsatisfied demand in the affected areas, and the second objective is to minimize total expected cost of the preparedness phase as well as the response phase. Costs of the preparedness phase include setup, procurement and holding costs, while costs of the response phase include transportation, inventory holding and shortage costs. Discrete scenarios from a set of possible disaster situations are used to represent uncertainty. The authors apply their method to an earthquake case study in Tehran, Iran.Robust optimization:Najafi, Eshghi, and Dullaert (2013) address the transportation of both relief commodities and injured people in the response phase after an earthquake. Three objective functions are considered hierarchically: minimize total weighted waiting time of unserved injured persons, minimize total weighted lead time of commodities, and minimize total number of vehicles utilized. The number of injured people, the amount of commodity demands, and the capacities of hospitals over the whole planning horizon are uncertain. To cope with this problem, the authors propose a robust solution approach for a stochastic model with uncertain right-hand sides based on the technique by Bertsimas and Sim. They apply their hierarchical solution approach to an exemplary study of a region in Iran.Rezaei-Malek and Tavakkoli-Moghaddam (2014) consider the choice of a pre-positioning strategy in combination with the distribution of goods in the response phase. A scenario-based approach is used to represent uncertainty about demands, roads, transportation time etc. in a future disaster. First-stage (i.e., pre-disaster) decisions are on locations of warehouses and quantities of relief items. Second-stage decisions depend on the actual scenario and concern the distribution plan: they determine the quantities of items to be delivered to the single demand points. The first objective function is the expected response time over all scenarios. The second objective function measures total cost. Coverage is not addressed by a separate objective function, but by a penalty for unsatisfied demand added to the cost objective. Equity is taken into account by a fairness level constraint. The robust optimization paradigm by Mulvey has been chosen to deal with the uncertainty in objective functions and constraints. A special feature of the paper is the use of the reservation level Tchebycheff procedure (RLTP) (Reeves & MacLeod, 1999), a modification of the interactive weighted Tchebycheff procedure by Steuer and Choo (1983). The RLTP is an algorithm gradually reducing the set of currently nondominated solutions by eliciting preference information from the DM in interactive steps. A case study for a possible Seattle earthquake, originally developed in Mete and Zabinsky (2010), illustrates the technique.In the following section papers related to post-disaster activities under uncertainty of the response phase and rehabilitation phase will be discussed.Stochastic optimization:Zhan and Liu (2011) formulate a bi-objective stochastic optimization model where the first objective is expected total travel time of the relief supplier (since supplier-side travel time is addressed, we count this as a cost-type objective function), and the second objective function is the quotient of expected unmet demand and expected demand, obviously a coverage criterion. Uncertainty concerns demand, supply and availability of transportation links, and is represented by a set of random scenarios with associated probabilities. A chance constraint referring to the relation between the amount of transported commodities and the supply is added. A goal programming approach is used to deal with the two objective functions.Tricoire, Graf, and Gutjahr (2012) deal with the choice of distribution centers (DCs) for relief commodities and of delivery tours supplying the DCs from a central depot. Demand in population nodes is assumed as uncertain and modeled stochastically. DCs have fixed given capacities, as well as vehicles. The model considers two objective functions: The first objective is cost (sum of opening costs for DCs and of transportation costs), and the second is expected uncovered demand. Contrary to basic covering tour models supposing a fixed distance threshold, uncovered demand is measured according to the more general model assumption that the percentage of individuals who are able and willing to walk to the nearest DC can be represented by a nonincreasing function of the distance to this DC. The demand of those individuals who stay at home, but also the demand of those individuals who are not supplied in a DC because of DC capacity and/or vehicle capacity limits, contribute to the total uncovered demand. Because of the uncertainty on the actual demand, total uncovered demand is a random variable, the expected value of which defines the second objective function to be minimized. The solution approach is a branch-and-cut algorithm iteratively evoked by a procedure based on the epsilon-constraint method for the computation of the Pareto front of the bi-objective problem. The distribution of the actual demand in each of the population nodes is approximated by a sample of randomly generated scenarios. To test the approach, the data of the Senegal real-world application case from Doerner, Focke, and Gutjahr (2007) is used.Liu and Guo (2014) deal with earthquake disasters and point out that for this type of catastrophes which is characterized by high unpredictability, pre-positioning sufficiently large capacities for relief operations is usually uneconomical or even infeasible. This puts the focus on post-disaster relief logistics. Relief commodities are to be transported to the affected areas by different transportation tools including helicopters, and temporary facilities for storing the supplies have to be established. Uncertainty on the actual demand, represented by a stochastic model based on scenarios, is assumed. In a first stage, decisions have to be made on facility locations, mobilization levels of relief supplies, and deployment of helicopters. The second decision stage determines a concrete transportation plan dependent on the scenario. The first objective (to be maximized) is minimum expected fill rate over all affected areas. The second objective (to be minimized) is expected cost. A lexicographic optimization approach, viewing the coverage objective as more important as the cost objective, is applied. However, when minimizing cost, not only optimal, but also slightly suboptimal solutions with respect to coverage are taken into account. The allowed deviation from optimality is determined by a tolerance factor. The authors develop a decomposition-based heuristic solution technique. The method is applied to a test case emulating features from the Great Wenchuan earthquake 2008.Rath, Gendreau, and Gutjahr (2015), finally, address the delivery of relief items to beneficiaries in the response phase of a disaster under uncertainty on the availability of roads. Uncertainty is represented stochastically by a set of random scenarios for the state of the transportation network, which allows the modeling of correlations between failures of different roads, dispensing with the simplifying assumption that roads fail independently. A two-stage stochastic programming model is formulated, where in the first stage, decisions on the locations of distribution centers have to be made, and in the second stage (based on current information on road availability) the transportation flows have to be organized. Objective functions are expected total cost and expected covered demand. The unique feature of this model is that it applies Pareto optimization to a two-stage stochastic program incorporating two objectives also in the second decision stage, which makes the computational solution rather challenging. Even outside the humanitarian logistics literature, this type of optimization problems is still largely unexplored (see Gutjahr & Pichler, 2013). The use of a homogeneous fleet of vehicles is compared to that of a heterogeneous fleet.Robust optimization:Najafi et al. (2013) address the transportation of both relief commodities and injured people in the response phase after an earthquake. Three objective functions are considered hierarchically: minimize total weighted waiting time of unserved injured persons, minimize total weighted lead time of commodities, and minimize total number of vehicles utilized. The number of injured people, the amount of commodity demands, and the capacities of hospitals over the whole planning horizon are uncertain. To cope with this problem, the authors propose a robust solution approach for a stochastic model with uncertain right-hand sides based on the technique by Bertsimas and Sim. They apply their hierarchical solution approach to an exemplary study of a region in Iran.Fuzzy optimization:Tzeng, Cheng, and Huang (2007) propose a fuzzy multicriteria linear programming model for a relief distribution system with respect to three objectives: minimizing costs, minimizing travel time and maximizing the satisfaction of demand nodes, some of which might be difficult to reach. Costs of the distribution system include setup and operational costs of transfer depots as well as costs for transporting relief commodities from supply nodes via transfer depots to demand nodes. To cope with dynamic data, a multi-period model is considered, where parameters and variables are time-related. In order to achieve a fair distribution of relief material to all demand nodes, the least satisfaction value of each item in each time period is summed up. The authors solve their fuzzy linear programming model by LINGO and evaluate the experimental results on an earthquake case study for a region in Taiwan.Barzinpour, Saffarian, Makoui, and Teimoury (2014) formulate a bi-objective possibility linear programming model where the first objective is to minimize transportation costs, setup costs and penalty costs for supply shortage, and the second objective is to maximize satisfied demand. Facilities are to be set up and relief goods are to be distributed to beneficiaries in damaged areas, based on fuzzy numbers for transportation cost, setup cost, inventory and demand. The location-allocation problem is addressed in a periodic manner where in each period distribution centers are made (in)active and inventory can be relocated. The authors use Zimmermann’s method for fuzzy optimization and transform their problem into a single-objective linear program with a max–min operator. Computational results for a genetic algorithm, a simulated annealing procedure and the exact solution of the proposed model by LINGO are compared and evaluated. The experimental results are based on instances relating to the province South-Khorasan of Iran.Whereas some types of investigations are obviously well-covered by the reviewed articles, other types of research questions have been addressed less frequently. Let us first look at the objectives taken into consideration in the reviewed multicriteria optimization models. Our survey shows that almost all articles include a cost objective, typically together with one or several of the objectives response time, travel distance and coverage. Less well-represented are reliability, security and equity, so a discussion of these criteria may be appropriate.Some articles address reliability, but not too many; this is even true for the subset of articles using stochastic optimization. In the last-mentioned subset, the envisaged objective is usually the expected value of some performance measure, which corresponds to a risk-neutral attitude. To take account of a risk-averse stance, as it appears more appropriate for life-critical disaster situations in uncertain natural environments, one might go beyond expected values (e.g., by resorting to risk measures as the value-at-risk or the conditional value-at-risk), or one might include, in addition, some application-specific reliability objective.44The limitation of not taking risk aversion into account does not directly apply to robust optimization approaches which are implicitly risk-averse and may even propose over-conservative decisions. Further research in robust optimization approaches to the considered area might try to make the influence of the degree of risk aversion more explicit.Moreover, future research should develop quantifications of reliability that are not restricted to simplifying independence assumptions for failure events (e.g., the assumption that transportation links fail independently from each other), even if this complicates the mathematical treatment. Reliability estimates based on realistic simulations (including rare-event simulation technologies) would be highly desirable.Most current papers addressing reliability of relief focus on reliability of routes: they quantify the probability that an arc in the transportation network can be completely crossed, based on expected damage (see Hoyos et al., 2015; Özdamar & Ertem, 2015). Future research should try to establish more comprehensive measures for the reliability of relief, incorporating also other aspects of the supply chain. Possibly, to assess reliability in this broader sense, queuing systems modeling, the consideration of bullwhip effects and congestion effects, as well as agent-based simulation predicting the behavior of people could be fruitful. Moreover, since reliability is directly affected by natural events as aftershocks or flood level rises, interdisciplinary cooperation with meteorologists, geophysicists and hydrologists is needed for the development of adequate models and assessment techniques. Finally, reliability of the supply delivered by NGOs is also heavily influenced by the continuity or decrease of donations, an aspect rarely dealt with in current models.As presently available quantitative methods for humanitarian logistics developed out of their commercial logistics counterparts which, however, can build on much more stable and reliable contextual situations, it may be that reliability is still an underestimated aspect in humanitarian aid models.Another aspect which is rarely dealt with is security. As seen from the research on homeland security (a field that is closely related to humanitarian aid), quantitative modeling approaches to cope with the security issues will presumably not only encompass probabilistic, but also game-theoretic concepts. Including the security aspect in decision support systems for humanitarian aid is essential as soon as the application area is not restricted to “pure” natural disasters, but also needs to be extended to man-made crises. However, also natural disasters may happen in unstable regions or war zones, and even secure areas can become dangerous after a disaster event when resources get scarce and conditions are in disorder. Looting and other forms of criminality, administrative chaos, corruption, and possible obstruction by special groups influence the degree of security in terms of reasonable operating conditions.Increased efforts in further research seem desirable as well for the equity objective. A particular issue discussed in Marsh and Schilling (1994) deserves special attention in the context of our topic: the requirement that an equity measure should be easy to understand and to interpret. This is especially important for a multicriteria optimization approach to humanitarian aid because when being concerned with tradeoffs between different objectives functions, the DM should have full clarity about what certain numerical values of an objective function mean. For example, when trading off the effectiveness of alternative delivery plans for life-critical goods (how many beneficiaries can be supplied?) against their equity (how fair is the distribution across the districts of a country?), equity may even have a price in terms of reducing the expected total number of human lives saved. For making such difficult decisions, the responsible persons would certainly wish that the meaning of “a unit more of equity” is completely transparent.55In a more general multicriteria decision making context, Wenstøp (2005) has argued for the importance of representing consequences of decisions in an easy-to-understand, “vivid” form instead of using non-intuitive, “cold” numbers.There seems to be no general agreement about the question whether the consideration of an equity criterion is necessary at all. To some extent, this disagreement mirrors the philosophical debate between the classical utilitarian position (holding that we ought to bring about “the greatest good for the greatest number”) and the theories of justice emphasizing that the overall amount of good has to be distributed in a fair way (see, e.g., Le Grand, 1987). In humanitarian logistics, an example for the utilitarian viewpoint is the paper by Holguín-Veras et al. (2013) who argue that by an appropriate consideration of deprivation costs of individuals in a relief commodity delivery model, the specification of a separate equity criterion becomes redundant. As we have seen, other authors insist on the importance of taking equity issues into account. However, in a discussion of this seeming contradiction, we should be aware that it is necessary to separate different decision levels and different decision areas. Whereas humanitarian decision makers on a high decision level have to think about equity issues, people concerned with operational decisions as routing plans simply try to optimize their operational objectives under priorities and constraints that have already been fixed on the higher level before. Of course, this generates a nontrivial interplay between the decision levels, and, as far as we can see, articles addressing this interplay by quantitative models are still missing.Looking at the methods applied for giving multicriteria decision support, we see that the determination of Pareto-optimal solutions has become a mainstream approach in the reviewed field. Also other MCDM methods, however, are well-represented in the reviewed literature. It may be worth mentioning that with the exception of Gralla et al. (2014) (where no optimization is performed), we found no article within the scope of our survey using methods related to Multiattribute Utility Theory (MAUT), a well-established approach to multicriteria decision making in other areas of application. A possible reason may be that the preference elicitation in MAUT (usually based on pairwise comparisons, similarly as in the AHP) is demanding and is perhaps considered as unpractical in the stress situation of disaster response. Nevertheless, there may be phases in the disaster life cycle for which this argument does not hold. In addition to MAUT, also ELECTRE methods (Figueira, Mousseau, & Roy, 2005) or PROMETHEE methods (Brans, Vincke, & Mareschal, 1986), both often used for environmental MCDM problems, seem still to be widely unexplored in the field of humanitarian aid.Since irregular demand and other uncertainties belong to the constituent characteristics of humanitarian logistics compared to commercial logistics (see Kovács & Spens, 2007), it can be expected that the importance of models representing uncertainty will still grow in the considered area of research in the course of the next years. A closely connected issue is the multi-period nature of decisions in humanitarian aid, which would make stochastic-dynamic (or robust-dynamic) optimization models advisable. The extension of such models to multiple objectives, however, raises enormous challenges (cf. Gutjahr & Pichler, 2013). While stochastic dynamic optimization has been well-developed for areas as financial engineering where only one objective matters, hardly any general techniques can be adopted from other fields for the multicriteria situation. The applications in humanitarian aid may possibly stimulate methodologically oriented research on this topic, the results of which can also be useful in fields as energy/environment or healthcare.Interestingly, in the reviewed literature, the model components used to predict the behavior of beneficiaries are typically rather simple. A topic for future research may be the inclusion of more realistic models for client behavior, as they have been established, e.g., in the literature on competitive facility location or in that on evacuation logistics. For first steps in this direction, see Burkart, Nolz, and Gutjahr (2015) and Gutjahr and Dzubur (2015). In general, there is a need for papers that explicitly consider the diverging interests of multiple and sometimes competing stakeholders, such as various humanitarian organizations with different missions or religious mandates, different political interests, private company interests, donor interests, and the interests and needs of beneficiaries.Let us conclude our discussion of possible future research with the probably most important issue: A majority of the reported methodological approaches still lack concrete application in real-world contexts on a routine basis. Experiences from more extensive case studies would be required. While several authors try their approaches on instances of the situations they model using real-world data from disaster-prone regions, demonstrations of the appropriateness of the proposed methodologies by an assessment of the results of their implementation in real operations are often missing, and would be extremely valuable. Few papers meet these expectations. As two exceptions, let us mention Ortuño et al. (2011) and Coffrin et al. (2011). In Ortuño et al. (2011), the authors present a decision support system for humanitarian logistics operations called HADS (Humanitarian Aid Distribution System), which is developed in a free and accessible way via a web platform. The system is validated on a real operation carried out during a food crisis in Niger, where the authors compare the solutions generated by their system to the results gathered from the real operation. In Coffrin et al. (2011), experimental results on a two-stage stochastic programming model for hurricane preparedness of benchmarks concerning the U.S. infrastructure are provided. The authors note that the approach is currently deployed at Los Alamos National Laboratory and activated each time a hurricane of category at least 3 threatens the United States.A main difficulty contributing to the lack of concrete applications in real-world contexts lies in the fact that in order to implement methods of the considered types in such a way that they can be used by humanitarian aid organizations, decision support systems with efficient data handling components, appropriate visual user interfaces and comfortable interactive components are needed. The development of such systems requires close interdisciplinary cooperation. While the incorporation of different information sources in one system is still a challenging matter as well as the difficulty of accessing reliable data in time, some systems have been developed to cope with the latter issue. Copernicus, the Emergency Management Service of the European Commission, provides timely and accurate geospatial information derived from satellite remote sensing and completed by available in situ or open data sources. Copernicus is a user driven program and the information services provided are freely and openly accessible to its users (Copernicus, 2015). The emergency events database EM-DAT contains core data on the occurrence and effects of more than 21,000 technological and natural disasters from 1900 to the present day. It is compiled from various sources, including UN agencies, the US Office of Foreign Disaster Assistance (OFDA), national governments, the International Federation of Red Cross and Red Crescent Societies (IFRC), NGOs, insurance companies, research institutes and the media, according to a priority list (Emergency Events Database, 2015). ReliefWeb is a specialized digital service of the United Nations Office for the Coordination of Humanitarian Affairs (OCHA). The service provides a collection of timely updates and analysis from more than 4000 global information sources, including country and disaster reports, maps, and info-graphics (ReliefWeb, 2015). The mentioned systems aim at supporting planners and decision makers in humanitarian aid by providing relevant and accurate data. However, in case of emergencies, information still has to be partly collected manually, which makes the implementation of OR methods in concrete applications and real-world contexts a challenging issue.

@&#CONCLUSIONS@&#
The recent rapid growth of the literature on multicriteria optimization in humanitarian aid lets us anticipate that this subarea of operations research will see a vital further development in the near future. It is clear that MCDM methods can only be one component in the toolbox of well-planned humanitarian operations, and, as argued above, a lot of joint effort of several disciplines and intensified collaborations with governments and field organizations will still be necessary to put diverse scientific results into practice. Nevertheless, the papers reviewed in this article show that the MCDM mindset is definitely gaining influence in the methodology of humanitarian logistics. Moreover, the reviewed literature also raises a lot of new research questions that are scientifically challenging enough to stir the interest of academic researchers, and close enough to concrete applications to be valuable for the practice of humanitarian aid.