@&#MAIN-TITLE@&#
Comparison of many-objective evolutionary algorithms using performance metrics ensemble

@&#HIGHLIGHTS@&#
A performance assessment on state-of-the-art many-objective evolutionary algorithms.Proposed performance metrics ensemble exploits a collection of performance metrics.Performance depends on ability to address specific characteristics of the problem.Performance depends on ability to handle high-dimensional objective space.

@&#KEYPHRASES@&#
Performance metrics ensemble,Many-objective optimization problem,Evolutionary algorithms,Double elimination tournament selection,Many-objective evolutionary algorithms,Performance metrics,

@&#ABSTRACT@&#
In this study, we have thoroughly researched on performance of six state-of-the-art Multiobjective Evolutionary Algorithms (MOEAs) under a number of carefully crafted many-objective optimization benchmark problems. Each MOEA apply different method to handle the difficulty of increasing objectives. Performance metrics ensemble exploits a number of performance metrics using double elimination tournament selection and provides a comprehensive measure revealing insights pertaining to specific problem characteristics that each MOEA could perform the best. Experimental results give detailed information for performance of each MOEA to solve many-objective optimization problems. More importantly, it shows that this performance depends on two distinct aspects: the ability of MOEA to address the specific characteristics of the problem and the ability of MOEA to handle high-dimensional objective space.

@&#INTRODUCTION@&#
Evolutionary algorithms (EAs) with meta-heuristic character and population-based property provide powerful search ability to generate both converged and diversified Pareto-optimal fronts in multiobjective optimization problems (MOPs), which generally involve two or three conflicting objectives. On the other hand, there are many real-world problems with multiple conflicting objectives (in most cases, more than five) needed to be optimized simultaneously, which are called many-objective optimization problems (MaOPs). In the literature, Multiobjective Evolutionary Algorithms (MOEAs) have been effectively applied to search for the Pareto-optimal fronts in MOPs, but render much worse performance in MaOPs [1]. This subject has been gaining an increasing interest in recent years. Compared with low-dimensional MOPs, the curse of dimensionality in MaOPs has presented several challenges for MOEAs.First, in MaOP, Pareto optimality loses its selection pressure in the evolution process due to the increasing number of objectives. In MOPs, Pareto optimality based MOEAs, such as NSGA-II [2] and SPEA2 [3], perform very well in that Pareto optimality is effective to select nondominated individual and facilitates the convergence of the population in low-dimensional space. However, in high-dimensional space, the proportion of nondominated individuals rises quickly with the number of objectives [4]. This leads to severely diminishing selection pressure during the evolutionary process no matter how the MOEA is designed, if it is based on Pareto dominance relation.Second, the high-dimensional objective space of MaOP is extremely large. This large search space makes it difficult to determine the population size in the evolution process. If the population size is too small, the evolution process will prematurely approach the local Pareto solutions, making the whole population settle into local fronts. Also, the small population size makes most of solutions apart from each other. It becomes hard to measure the diversity of the whole population. On the other hand, if the population size is too large, the huge computation effort will paralyze the evolution process. Meanwhile, even with the large population size, two distant solutions may still generate offsprings far from them.Besides the deficiency in the definition of Pareto dominance and extremely large objective space stated above, other complications such as visualization of high-dimensional objective spaces [1] and a very high computational cost (due to a large number of individuals needed to obtain a good representation of the Pareto front) [5] have contributed to the challenges in solving MaOPs.From the above discussions, difficulties caused by a large number of objectives have rendered the existing MOEAs ineffective to solve MaOPs. The efforts in addressing this issue have led to the developments of new algorithms, often called Many Objective Evolutionary Algorithms (MaOEAs). In literature, there are mainly four types of MOEAs that have been proposed to solve MaOPs.First, MOEAs are constructed using modified Pareto dominance design. The relaxing form of the Pareto dominance including Pareto α-Dominance [6], Pareto ε-Dominance [6], and Pareto cone ε-Dominance [6] makes one individual dominates others easier in high-dimensional space by the heuristically chosen parameters. Based on this idea, ε-Domination Based Multi-Objective Evolutionary Algorithm (ε-MOEA) [7] is proposed and shows a good performance [8]. On the other hand, fuzzy concept is incorporated into Pareto dominance for new fitness evaluation mechanism to continuously differentiate individuals into different degrees of optimality beyond the classification of the original Pareto dominance. Based on it, a fuzzy Pareto dominance (FD) relation is defined and incorporated into the designs of NSGA-II, so called FD-NSGA-II [4].The second class is based on the idea of performance indicators. For example, Hypervolume Estimation Algorithm for Multiobjective Optimization (HypE) [9], has been shown to be effective in solving MaOPs. Also, there are some other designs in a similar spirit such as Indicator-Based Evolutionary Algorithm (IBEA) [10] and SMS-EMOA [11].The third class is decomposition based designs, such as multiobjective evolutionary algorithm based on decomposition (MOEA/D) [12] and reference-point based many-objective NSGA-II (MO-NSGA-II) [13]. This type of methods decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. In the evolution process, aggregation functions, such as Tchebycheff in [12] and Achievement Scalarizing Function in [13], are applied for fitness assignment and individual selection instead of Pareto-dominance. Nowadays, this method is very popular to solve MaOPs.The last class is the grid-based method. From [14], a grid can reflect the status of both convergence and diversity simultaneously. Grid-Based Evolutionary Algorithm (GrEA) [14] exploits this grid approach to strengthen the selection pressure toward the optimal direction, while maintaining an extensive and uniform distribution among solutions. Territory Defining Multiobjective Evolutionary Algorithm (TDEA) [15] defines a territory around each individual to prevent crowdness in any region.Although numerous MOEAs exist for many-objective optimization problems, there is no comprehensive study conducted to reveal advantages and weaknesses of the underlying MOEAs and at determining the best performance algorithm to specific class of problem characteristics [16]. Recently, multiple comparisons between latest improvements on NSGA-II and MOEA/D for many-objective optimization problems have been made in [17–19]. In those experiments, only single performance metric is used therein. However, every metric can merely provide some specific, but incomplete, quantifications of performance and can only be effective under specified conditions. For a specific test problem, we cannot ascertain which metrics should be applied in order to faithfully quantify the performance of MOEAs. The conclusion, if any is drawn, is often indecisive and reveals no additional insight pertaining to the specific problem characteristics that proposed MOEA would perform the best [20,21].To overcome these deficiencies and arrive at a fair evaluation of MOEAs, performance metrics ensemble with double elimination tournament [22] is used in this research work. The ensemble method uses multiple metrics collectively to obtain a better assessment than what could be obtained from any single performance metric alone. Metrics ensemble not only can give a comprehensive comparison between different algorithms, but avoid the choosing process and can be directly used to assessing MOEAs.In the remaining paper, Section 2 provides the literature review on the MOEAs for comparison. In Section 3, we give detailed information for performance metrics. Section 4 describes the performance metrics ensemble approach in detail, including the double elimination tournament selection operator. In Section 5, we elaborate on the experiment results for selected benchmark problems. Finally, a conclusion is drawn in Section 6 along with pertinent observations.In this study, six state-of-the-art MOEAs are chosen for competition. They are FD-NSGA-II [4], HypE [9], MOEA/D [12], GrEA [14], ε-MOEA [7], and MO-NSGA-II [13]. Here, FD-NSGA-II is of the first type of algorithms modifying Pareto dominance. HypE based on performance indicator comes from the second type. MOEA/D is the decomposition-based method and belongs to the third type. The grid-based method GrEA is from the fourth type. ε-MOEA not only modifies the Pareto dominance, but also uses the grid to improve the diversity, so it is a combination of both the first and the fourth types. MO-NSGA-II is also a hybrid method and contains both decomposition and grid ideas from the third and the fourth types, respectively. A brief overview of each chosen MOEA is given below.FD-NSGA-II is the improved NSGA-II by adopting the fuzzy Pareto dominance relations and the corresponding fuzzy fitness assignment process. In the proposed design, fuzzy Pareto dominance relation is applied to determine the rank value of each individual instead of Pareto dominance in the original NSGA-II. After the rank value is determined, the same crowding-distance is used as the original design of NSGA-II. The fuzzy fitness assignment process ensures one individual is fuzzy nondominated with respect to others in the same rank.HypE is a hypervolume-based evolutionary many objective optimization algorithm. It applies Monte Carlo simulation to approximate the exact hypervolume value, and assigns ranks of solutions induced by the hypervolume indicator. These ranks of solutions can be used in fitness evaluation, mating selection, and environmental selection. Overall, it balances the accuracy of the estimates and the computation cost of the Hypervolume calculation.MOEA/D decomposes a MOP into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem has a different weight vector and a single solution. For each subproblem, a certain number of the nearest subproblems are defined as its neighbors based on the Euclidean distance between their weight vectors. Each subproblem is optimized by only using information from its several neighboring subproblems. For each subproblem, a new solution is generated by current solutions in its neighboring subproblems and is compared with current solutions in the neighboring subproblems.Grid-Based Evolutionary Algorithm (GrEA) exploits the potential of the grid-based approach to strengthen the selection pressure towards the global Pareto front while maintaining an extensive and uniform distribution among solutions. Two concepts, grid dominance and grid difference, were introduced to determine the mutual relationship of individuals in a grid environment. Then, three grid-based criteria, grid ranking, grid crowding distance, and grid coordinate point distance, are incorporated into the fitness of individuals to distinguish them in both the mating and environmental selection processes. GrEA uses the basic framework of NSGA-II while modifying three main steps of evolution process: fitness assignment, mating selection, and environmental selection.ε-MOEA is a steady-state algorithm based on the ε-dominance relation. It divides the objective space into hyperboxes by a size of ε. Each hyperbox is assigned at most a single solution on the basis of ε-dominance. From [7], ε-MOEA provides a tradeoff among convergence, diversity, and computational time. Furthermore, it could be made interactive with a decision-maker which implies ε can be chosen by decision-maker according to user’s preference.MO-NSGA-II is a hybrid NSGA-II with similar framework as the original NSGA-II except a modified selection mechanism is designed for handling many-objective optimization problems. It uses multiple predefined reference points to guide the search in the evolution process. Then, population members are projected on a hyper-plane and a clustering operation is performed on the hyper-plane to select a desired number of clusters (user-defined). Based on the diversity of the population, either a local search operation on a random cluster member is used to move the solution closer to the Pareto-optimal front or a diversity enhancement operator is used to choose population members from all clusters.From literature, each MOEA has some distinct advantages and disadvantages compared with others. FD-NSGA-II can ensure its convergence no matter how large the dimension of objective space but this convergence performance is much influenced by the diversity method. MOEA/D can quickly generate a converged and well-distributed approximation front, but requiring a huge number of target vectors. The grid methods, e.g., ε-MOEA and GrEA, can effectively deal with convergence and diversity simultaneously, but the choice of hyperbox size and grid parameter is made ad hoc. In HypE, Hypervolume indicator is strictly monotonic with Pareto dominance [9] but the approximation of its value is not easy and influenced by the number of sampling points. From above discussions, a comprehensive comparison is necessary to arrive at a fair evaluation among these state-of-the-art MOEAs designed specifically for MaOPs.For performance metrics, Zitzler et al. [23] proposed three optimization goals to be measured: the distance of the resulting nondominated set to the Pareto-optimal front should be minimized; a good (in most cases uniform) distribution of the solutions found in objective space is desirable; and the extent of the obtained nondominated front should be maximized. In literature, there are manyunaryperformance metrics used to compare MOEAs. These metrics can be broadly divided into five categories according to the optimization goals. Each category mainly evaluates the quality of a Pareto-optimal set in one aspect only.Considering the approximation fronts, A1,A2,⋯,Amobtained by different algorithms, this n-ary metric measures the ratio of nondominated solutions that is contributed by a particular solution set A1 to the nondominated solutions provided by all algorithms:(1)NRA1,A2,⋯,Am=A1∩BBwhereB=bi∀bi,¬aj∈A1∪A2∪⋯Am≺bi, and aj≺biimplies that ajdominates bi⋅A1 is the set under evaluation.(2)GD=∑i=1ndi2nwheredi=minjf(xi)-PFtrue(xj)refers to the distance in objective space between individual xiand the nearest member in the true Pareto front, and n is the number of individuals in the approximation front. This metric, assuming PFtrueis readily available, is a measure representing how “far” the approximation front is from the true Pareto front. Lower value of GD represents a better performance.This metric measures both convergence and diversity. Let PFtrueis a set of uniformly distributed solutions in the true Pareto front. X is the set of nondominated solutions in the approximation front PFknown:(3)IGD=∑v∈PFtruedv,XPFtruedv,Xdenotes the minimum Euclidean distance between v and the points in X. To have a low value of IGD, the set X should be close to PFtrueand cannot miss any part of the whole PFtrue.This metric is a value measuring how evenly the nondominated solutions are distributed along the approximation front,(4)S=1n¯∑i=1n¯(di-d¯)2where diis the Euclidean distance in objective space between individual xiand the nearest member in the true Pareto front, andn¯is the number of individuals in the approximation front. This metric requires low computational overhead and can be generalized to more than two dimensions.It addresses the range of objective function values and takes into account the proximity to the true Pareto front, assuming available. This metric is applied to measure how well the PFtrueis covered by the PFknown.(5)MS=1M∑i=1MminPFknown,imax,PFtrue,imax-maxPFknown,imin,PFtrue,iminPFtrue,imax-PFtrue,imin2wherePFknown,imaxandPFknown,iminare the maximum and minimum of the ith objective in PFknown, respectively; andPFtrue,imaxandPFtrue,iminare the maximum and minimum of the ith objective in PFtrue, respectively. M denotes the number of objectives considered. A higher value of MS reflects that a larger area of the PFtrueis covered by the PFknown.It calculates the hypervolume of the multi-dimensional objective space enclosed by approximation front PFknownand a reference point. For example, an individual xiin PFknownfor a two-dimensional MOP defines a rectangle area,axi, bounded by an origin andfxi. The union of such rectangle areas is referred to as Hyperarea of PFknown,(6)HPFknown=⋃iaxi∀xi∈PFknownAs pointed out in [28], this metric requires defining a reference point of the region and could be misleading if PFknownis nonconvex. In [29], suggestion is given as how to properly choose a reference point. Van Veldhuizen [25] also proposed a Hyperarea Ratio metric defined as:(7)HR=HPFknownHPFtrueApparently, PFtrueis given as a reference. In the proposed performance metrics ensemble to be presented in the next section, we adopt the Hyperarea Ratio metric.Fig. 1shows the process of performance metrics ensemble proposed by [22]. The final output from the performance metrics ensemble is a ranking order of all MOEAs considered. A number of MOEAs are presented as input. To arrive at a statistically meaningful conclusion, 50 independent runs are conducted. Given the same initial population, each MOEA chosen for comparison produces an approximate Pareto front. A performance metric, randomly chosen out of metrics ensemble is used to identify the winning approximate front. This process will repeat 50 times to result into 50 approximate fronts. A double elimination tournament selection is then applied to these 50 approximation fronts and one ultimate winning approximation front will be identified. The MOEA which is responsible to this approximation front will be assigned with ranking order one. The approximation fronts which are generated by this winning MOEA will be removed from the 50 approximation fronts. The remaining approximation fronts will then go through another round of double elimination tournament to identify the second winning MOEA with ranking order two. The process will repeat until the complete ranking order of all MOEAs considered is assigned.The process of double elimination tournament down selects the winning front out of all approximation fronts available using a series of binary tournament selections [22]. In each tournament selection, a performance metric from metrics ensemble is randomly chosen for comparison.Fig. 2depicts the first round of double elimination tournament in a general setting. Suppose the tournament has a pool size of N approximation fronts to begin with. The N/2 “qualifier” binary tournaments are held, and the whole pool is divided into two parts: winner bracket contains N/2 winners and loser bracket N/2 losers. Then, in each of the bracket, N/4 binary tournament selections are competed so that each part is further divided again. In both parts, there are N/4 new winners and N/4 new losers. The N/4 losers from loser bracket will lose twice and be eliminated from further consideration. The N/4 winner from winner bracket will be reserved in winner bracket for the next round of competition. Additionally, N/4 losers from winner bracket and N/4 winners from loser bracket will be paired for binary tournaments. Specifically, one approximation front from winner bracket and one from loser bracket will be matched for a binary tournament. Afterward, we obtain N/4 winners which will be placed in the loser bracket for the next round of competition. Those N/4 losers lost twice and will be eliminated from the pool. This process reduces the total number of approximation fronts in the pool from N to N/2 (i.e., N/4 in winner bracket and N/4 in loser bracket). Repeat the same process; the number of candidate approximation fronts will be trimmed down from N/2 to N/4, N/4–N/8, and eventually down to 2. The remaining two will then compete given a randomly chosen performance metric. If the one from winner bracket wins, it will be declared as the final winner. If the one from loser bracket wins, one more round of competition will be held to decide the ultimate winner.The motivation for applying the double elimination tournament is that it gives every individual approximation front at least two chances to take part in the competition. This design would be helpful to preserve good approximation fronts. Because of the stochastic process, one quality approximation front may lose the competition if a biased performance metric is chosen. For example, for a benchmark problem with discontinuous Pareto front, performance metric, uniform distribution [30], will not offer a fair assessment. If this occurs in the single elimination tournament, a quality front could be lost forever. However, in the double elimination tournament, it still has an opportunity to compete and to win it all. Double elimination design allows a characteristically poor performance of a quality MOEA under the special environment still be able to win it all.

@&#CONCLUSIONS@&#
In this study, we have compared six state-of-the-art MOEAs designed specifically for many-objective optimization problems under a number of benchmark problems using the performance metrics ensemble. An ensemble of performance metrics collectively provides a comprehensive and fair comparison among all MOEAs considered.This experiment confirms the conclusion that each MOEA with a specific design can only do well in some of benchmark problems. Specifically, MOEA/D in five-dimension DTLZ1, DTLZ6, DTLZ7, WFG2, WFG3, and WFG4; FD-NSGA-II in ten-dimension DTLZ1, DTLZ2, DTLZ6, WFG2, WFG4, WFG6 and WFG8; MO-NSGA-II in five-dimensional DTLZ2, DTLZ3, WFG5, WFG7, and WFG8; GrEA in five-dimension DTLZ4 and WFG9, ten-dimension DTLZ3, DTLZ4, DTLZ7, WFG3, and WFG6; ε-MOEA in both five- and ten- dimension DTLZ5 and WFG1, and ten-dimension WFG9; HypE in ten-dimension WFG5 and WFG7.The observation of experiment results shows that the performance of MOEA to solve many-objective optimization problem depends on both the ability of MOEA to solve the specific problem characteristics and the ability of MOEA to handle high-dimensional objective space.