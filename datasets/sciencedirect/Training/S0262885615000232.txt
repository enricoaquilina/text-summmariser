@&#MAIN-TITLE@&#
Non-uniform patch based face recognition via 2D-DWT

@&#HIGHLIGHTS@&#
A new strategy of overlapped non-uniform patch is proposed.2D-DWT and integral projection technique are used to obtain the patch strategy.The overlapped patches are elected to keep the patches robust.The proposed face recognition method processes good performance.

@&#KEYPHRASES@&#
Face recognition,Two-dimensional discrete wavelet transform,Integral projection,Non-uniform patch,

@&#ABSTRACT@&#
In this paper, we propose a method for face recognition by using the two-dimensional discrete wavelet transform (2D-DWT) and a new patch strategy. Based on the average image of all training samples, by using integral projection technique for two top-level's high-frequency sub-bands of 2D-DWT, we propose a non-uniform patch strategy for the top-level's low-frequency sub-band. This patch strategy is more suitable to reflect the structure feature of face image; and it is better for retaining the integrity of local information. By applying the obtained patch strategy to all samples, we obtain patches of training samples and testing samples; and then, give the final decision by using the nearest neighbor classifier and the majority voting. Experiments are run on the AR, FERET, Extended Yale B and LFW face databases. The obtained numerical results show that the new face recognition method outperforms the traditional 2D-DWT method and some state-of-the-art patch based methods.

@&#INTRODUCTION@&#
The two-dimensional discrete wavelet transform (2D-DWT) is a popular tool in image processing and computer vision due to its nice features of space–frequency localization and multiresolutions [1–8]. Through 2D-DWT, a face image is transformed into four parts: a low frequency sub-band and three high frequency sub-bands. Generally, the k-level 2D-DWT (k>1) means that the low frequency sub-band obtained in the (k−1)-level 2D-DWT is further decomposed into a low frequency sub-band and three high frequency sub-bands. Since the low frequency sub-band plays a dominant role in four sub-bands for approximation of the original image, it is usually solely used for face recognition [9]. However, as the high frequency sub-bands also contain some important information, the method in [10] introduces a joint of pixel-level and feature-level fusion at the top-level's wavelet sub-bands. In this paper, we try to show another use of the high frequency sub-bands.In recent years, the strategy of patch has been adopted in many face recognition methods. A modular eigenspace description technique is used to incorporate salient features such as the eyes, nose and mouth, in an eigenfeature layer in 1994 [11], which is the first patch based method. In the subsequent earlier methods, the whole image is partitioned into patches for feature extraction [11–15]. These methods show better performance when confronted with some problem such as illumination and the singular in linear discriminant analysis (LDA), to some extent, which draw the attention upon an image from global to local. By combining patch technique with some other methods, many effective face recognition methods have been proposed recently in the literature [16–24]. From the above papers, it is not difficult to find that there are two basic kinds of patches: one is overlapped patches as in [16,17]; and another is non-overlapped patches as in [22,23]. Among these papers, [16] investigates the face recognition problem via the overlapping energy histogram of the DCT coefficients, and it is an earlier paper which adopts overlapped patch technique for face recognition; in [17], the method of collaborative representation based classification with patch, denoted by PCRC, is proposed to classify the query sample; and in [22,23], each face image is divided into smaller regions of the same size and the two-dimensional principal component analysis is used in each region. Generally, the overlapped patches are more robust. In all of these methods, images are partitioned uniformly; and hence, some salient features (like eyes and nose) may be set apart. A natural question is how can face images be partitioned according to its own geometrical structure automatically? We will give part of the answer to this question in this paper.In order to obtain better patches of a face image, we will use integral projection technique. It is known that integral projection is a method for extraction of facial features, which is first proposed by Kanade [25]. It is well known that integral projections are used to detect salient features and locate boundaries of local regions; and they are usually implemented on frontal and standard faces [25–27]. In this paper, we use the idea of integral projection to propose a new patch strategy which is suitable to many different conditions including different illumination, expressions and some small changes in pose.In addition, in patch based methods, an important issue is how can the classification outputs of all patches be combined to classify the query sample. There are many methods to do it, such as majority voting [24,28,29], probabilistic model [30], linear weighted combination [15], and kernel plurality [31]. The method in [24] describes majority voting clearly, where each face image is represented as a spatial arrangement of image patches, and a smooth non-linear mapping for the corresponding patches are sought using Volterra kernels; then each patch casts a vote towards image classification after been classified independently; finally the class with the maximum votes is chosen. Similarly, in this paper, we will use the idea of majority voting.Motivated by the methods mentioned above, we propose a new method for face recognition, which is based on 2D-DWT and a non-uniform patch strategy. We denote it by NUPDWT. In NUPDWT, we first propose a patch strategy, whose process is divided into the following five steps. In Step 1, we give the average image of all training samples. In Step 2, 2D-DWT is performed on the average image to gain the top-level's four sub-bands: LL, LH, HL and HH (Note: for a k-level 2D-DWT, the top-level means the k-th level). In Step 3, the vertical integral projection and the horizontal integral projection are implemented on the sub-bands LH and HL, respectively; and then, from the two resulting projection vectors, we search for all of the extreme points. In Step 4, by using the obtained extreme points, we give non-overlapped patches of the top-level's low-frequency sub-band. In Step 5, based on the obtained non-overlapped patches, we further give overlapped patches of the top-level's low-frequency sub-band. Furthermore, by using the above patch rule to obtain all patches of the top-level's low-frequency sub-band of all samples, we classify all patches of each test sample by the nearest neighbor classifier (NN), and give the final decision according to the majority voting.The rest of this paper is organized as follows. In Section 2, we give a brief introduction of 2D-DWT and the integral projection technique. Then the proposed method is discussed in Section 3. The numerical experimental results on the AR, FERET, Extended Yale B and LFW face image databases are reported in Section 4. Finally, conclusions are given in Section 5.2D-DWT is a very popular and commonly used transform for image processing. It is based on one-dimensional wavelet transform and discrete wavelet transform (DWT) [1]. Firstly, a two-dimensional scaling function, Φ(x,y), and three two-dimensional wavelet functions, ΨH(x,y), ΨV(x,y), and ΨD(x,y), are required [5]. They are usually showed as the products of two one-dimensional functions,Φxy=ϕxϕy,ΨHxy=ψxϕy,ΨVxy=ϕxψy,ΨDxy=ψxψy,where ϕ(⋅) is a one-dimensional scaling function and ψ(⋅) is a one-dimensional wavelet function. These wavelets measure functional variations (intensity variations for images) along different directions [9]: ΨHmeasures variations along columns (for example, horizontal edges), ΨVmeasures variations along rows (like vertical edges), and ΨDmeasures variations along diagonals.The two-dimensional discrete scaled and translated basis functions are defined asΦj,m,nxy=2j/2Φ2jx−m,2jy−n,Ψj,m,nixy=2j/2Ψi2jx−m,2jy−n,i∈HVD,where j is a scale and m, n are the translation quantities. The corresponding transform of image f(x,y) of size M×N is expressed asWΦj0mn=1MN∑x=0M−1∑y=0N−1fxyΦj0,m,nxy,WΨijmn=1MN∑x=0M−1∑y=0N−1fxyΨj,m,nixy,i=HVD,where j0 is an arbitrary starting scale and normally designed as 0. This transformation is the so-called two-dimensional discrete wavelet (2D-DWT).2D-DWT is implemented as a set of filter banks, comprising of a cascaded scheme of high-pass and low-pass filters. The final result obtained is four non-overlapped multi-resolution sub-bands: LL, HL, LH and HH. The HL, LH and HH are all the high frequency components of the image. Further decomposition can be conducted on the LL sub-band, just as Fig. 1shows. Each sub-band can be thought of a smaller version of the image representing different properties. Take a simple image for example, just as Fig. 2shows: The band LL is a coarser approximation to the original image; the bands LH and HL record the changes of the image along horizontal and vertical directions, respectively; and the HH band shows the changes of the image along diagonal direction.Integral projection is a method for extraction of facial features, which was first proposed by Kanade [25]. It is a useful technology for reflecting the changes along one fixed direction by analyzing the accumulative changes. For a given image f(x,y), we use H(y) and V(x) to represent the horizontal and vertical projections, respectively. Then, over the image area Ω=[x1,y1]×[x2,y2], H(y) and V(x) are defined as:Hy=∑x=x1x2fxy,∀y∈y1y2;Vx=∑y=y1y2fxy,∀x∈x1x2.On the one hand, the sub-bands LH and HL after 2D-DWT can exhibit the texture's changes along horizontal and vertical directions, respectively, just as Fig. 2 shows. On the other hand, integral projection is a good technology to make the texture changes statistically significant along horizontal and vertical directions. Thus it is logical to adopt integral projection on LH and HL to analyze the texture's changes. When the corresponding direction's integral projection is respectively applied to the sub-bands LH and HL, the changes will be more intuitive. Then the sub-band LL, which has the same size with LH and HL, can be partitioned based on the intuitive changes. Furthermore, compared with the original image, LL eliminates some noise and reduces the dimension which are both beneficial for recognition. We can illustrate the idea on face image in Fig. 3, where the bottom part is the vertical integral projection of the sub-band LH; and the upper part is the corresponding partition which is performed on LL along horizontal direction. From this figure, we are amazed to find that Region 1 locates the boundary of the nose along horizontal direction, and meanwhile, Regions 2 and 3 locate the boundary of the eyes along horizontal direction.According to the basic idea introduced above, we can find that our patch strategy is able to automatically partition the face images into non-uniform patches, essentially because of the special geometrical structure and physical meaning of the 2D-DWT's sub-bands. Based on this idea, we propose the method — NUPDWT.There are two parts in this section. The first one describes the strategy of non-uniform patch; and in the second one, the part of classification is described and the whole steps of the method are listed.Suppose that a set of training images with size of m′×n′ from C different subjects is given and the i-th subject contains Nitraining samples, i∈{1,2,…,C}. LetXi=X1iX2i…XNii, where the matrixXji∈Rm′×n′represents the j-th training image of the i-th subject, and j∈{1,2,…,Ni}. The average face of training images can be calculated by(1)X¯=1N∑i=1C∑j=1NiXji,where N=∑i=1CNiis the total number of training samples.X¯can give a general view of the current training database, so its patch strategy is suitable to most images. Thus we can directly apply the patch strategy ofX¯to all images.After disposingX¯with the 2D-DWT, we get the top-level's sub-bands LL, HL and LH with the size of m×n. Then take the absolute value of LH and HL because what we need are the absolute variations of LH and HL in fact. We can observe the texture variations along horizontal direction after performing a vertical integral projection upon LH. Suppose the matrix of LH is A=(aij)∈Rm×n, the integral projection can be calculated by(2)vj=∑i=1maij,j∈12…n.Next, we find all of vj's extreme points, that is to say, we can obtain the set of extreme points byIx=j^∈12…n|vj^−1≤vj^&vj^≥vj^+1.These extreme points reflect the saltation of texture along horizontal direction, and the regions between two extremes are relatively stable. So, the extreme points can mark the locally boundaries along horizontal direction just as Fig. 3 shows.Similarly, we get the horizontal integral projection of HL and the set of extreme points, denoted by Iy. Then, we give the partition of LL according to sets Ixand Iyjust as the first graph in Fig. 4. The second graph in Fig. 4 shows the partition of an image according to the method of PCRC [17]. From Fig. 4, it is easy to see that our method shows its advantage on retaining the integrity of local information.The above patch strategy is given based on the average imageX¯. Though different images may have different tiny changes compared with the average image, for convenience, we apply the above strategy to all samples. In addition, in order to enhance stability and retain the integrity of local information further, we consider the overlapped patch. In our method, the overlapped patches combine four small blocks, that is, they contain both two small blocks along two directions, just as shown in the first graph of Fig. 5: Patch A1A3C3C1 is the first overlapped patch, and Patch B1B3D3D1 is the second overlapped patch, where their overlapped part is B1B3C3C1. In the method of PCRC [17], the size of patch was designed as 10×10 (overlap was 5pixels), which is shown in the second graph of Fig. 5.As the information on face is quite maldistribution, some important areas will be divided if the face image is partitioned uniformly. So our patches are reasonable with different sizes and better for retaining the integrity of local information when compared with the traditional partition schemes, e.g., uniformly partition, just as Fig. 4 shows. Furthermore, different from manual partition or partition after finding some fixed points, our strategy is automatical through analyzing the image's geometrical structures, i.e., analyzing the corresponding direction's integral projection upon the sub-bands HL and LH to find the breakpoints and get the smooth regions.As we know, in recognition process, classifier plays a vital role. There are many classifiers such as NN [32], sparse representation-based classification (SRC) [19], support vector machine (SVM) [33] and so on.In this paper, we apply the strategy of patch given in the above subsection to all samples to obtain the non-uniform patches, then classify them with NN and give the final decision according to the majority voting.The whole steps of the method are listed in the following.•Preparatory phase:(a)Get the average image of all training samples as ((1)).Decompose the average image with 2D-DWT to get four top-level's sub-bands: LL, HL, LH and HH. Take the absolute value of HL and LH.Perform a vertical integral projection on LH as ((2)), then find the set Ixof extreme points.Perform a horizontal integral projection on HL to get the set Iyof extreme points.Training phase:(a)Read in all training samples, and decompose them with the same 2D-DWT.Partition LL of every training sample according to sets Ixand Iy. Extract the non-uniform patches from each sample and save them.Test phase:(a)Read in and decompose a query sample with the same 2D-DWT, then partition its LL according to sets Ixand Iy.Extract the non-uniform patches and classify all of them by NN.Give the final decision according to the majority voting.We use the AR, FERET, Extended Yale B and LFW face databases to test the performance of the proposed method.The comparison methods contain four kinds, the first one is some state-of-the-art patch based methods, including patch based NN (PNN) [31], PCRC [17], patch based SRC (PSRC) [19], modular image principal component analysis (MIMPCA) [22,23]; the second is majority voting based method Volterra [24]; the third is 2D-DWT based method TWSBF [10] which is combined with PCA here and the traditional 2D-DWT method (TDWT) [9] whose classifier is SVM with the parameters of C=128 and γ=0.0078425; and the last one, named UPDWT, is designed by ourselves in order to verify the superiority of non-uniform patch strategy used in this paper. In this method, integer projection technique is not used and the patch strategy is designed as follows: after we obtain the top-level's low-frequency sub-bands, an overlapped uniform patch method is used for the top-level's low-frequency sub-bands, where overlapped method is the same as the one of NUPDWT.Our experiments are made on a PC platform with 64-bit win8 operating system, Intel Core i5-3550S CPU, and 8G memory.Different from other patch based methods in which the size of patch are designed artificially and fixed, the size of patch in our method is unfixed. But the two parameters: the level of 2D-DWT and the combined number of patches, together influence the size of patch and eventually influence the number of final votes. Obviously, after partition, the size of the patch will get bigger but the number of final votes will be less as the combined number of patches increases. The level of 2D-DWT is directly related to the whole size of LL and the number of the extreme points, so the choice of the level is very important to the size of patch. Take the practice on the AR database for example. We randomly select 13 images of each person for training, and the remaining images are used for testing. Experiments of the level of 2D-DWT and the combined number of patches (which are marked as l and cp in the following) are shown in Fig. 6, where l changes from 1 to 4, and cp has four choices as 1×1, 2×2, 3×3, and 4×4. The highest recognition rate is obtained when l=1 and cp=2×2, which shows that the patches have suitable sizes and stable property in this case. And these two parameters in other databases are all chosen through this way.According to the original settings in references and the experiments above, some important parameters are exhibited in Table 1, where, l, s, o represent for the level of 2D-DWT, the size of patch and the size of overlap, respectively.Besides, the penalty parameter λ in PCRC is respectively set as 0.001, 0.1, 0.001, and 0.001 in these databases. For MIMPCA, the final dimensions of each patches after PCA are all set as 5, and the final dimension of PCA in TDWT is 20. For Volterra, the Volterra kernel is set as 3 and the approximation order is 2 on the databases except Extended Yale B where it is 1.In our experiments, the chosen 2D-DWT is the 4-th order Daubechies (‘db4’) wavelet. For comparison, the levels of ‘db4’ in methods NUPDWT and UPDWT are designed as the same. However, the methods TDWT and TWSBF are equipped with the levels to gain as good performance as possible in different databases. The experiments are all repeated 20 times.The AR database contains over 4000 color face images of 126 people (70 men and 56 women), including frontal views of faces with different facial expressions, lighting conditions and occlusions. Images are of 768 by 576pixels and of 24bits of depth. The images of most persons were taken in two sessions (separated by two weeks). Each section contains 13 color images and 120 individuals (65 men and 55 women) participated in both sessions. In our experiments, AR database which we use contains 1560 gray level images of 60 individuals (each person has 26 different images) and each image is manually cropped and resized to 50×40pixels. Fig. 7shows 26 sample images of one person in the AR database.We compare NUPDWT with TDWT, TWSBF, PNN, PSRC, PCRC, MIMPCA, Volterra and UPDWT on the AR database.We randomly select 7, 9, 11, 13, and 15 images of each person for training, respectively, and in every case, the remaining images are used for testing. The average recognition rates of TDWT, TWSBF, PNN, PSRC, PCRC, MIMPCA, Volterra and NUPDWT are shown in Table 2.In addition, we extract the faces with scarf and faces with sunglasses as two small sub-databases. In each sub-database, there are 60 individuals with 6 different images each person, and each image is also manually cropped and resized to 50×40pixels. We randomly choose 3 images for training, and the remaining images are used for testing. The average recognition rates are shown in Table 3.From Tables 2 and 3, it can be easily seen that the proposed NUPDWT achieves obviously higher recognition rates on the AR face database in all circumstances, no matter whether there are occluded images in the training and testing set or not, which proves that our method performs well for the images with occlusion.The FERET database is one of the most useful databases for face recognition. The images are taken under different poses and illumination conditions. The FERET database in our experiment contains 1200 face images of 200 people and the sizes of all images are tailored into 80×80. Fig. 8shows 18 sample images of 3 persons in the FERET database.We randomly choose 1, 2, 3, 4, and 5 images of each person for training, respectively, and in every case, the remaining images for testing. The average recognition rates of each method are shown in Table 4, and it can be easily seen that the recognition rates of NUPDWT are higher than the other methods on the database of FERET. In addition, we can see that our method can also be used to solve problem with small changes of pose.The Extended Yale B database contains images of 38 individuals, and each person has 64 different images with the size of 192×168pixels under 9 poses and 64 illumination conditions. In our experiments we choose the former 40 images per person. The examples of this database are shown in Fig. 9.We compare NUPDWT with TDWT, TWSBF, PNN, PSRC, PCRC, MIMPCA, Volterra and UPDWT on the Extended Yale B database.We randomly choose 20 images per person for training, and the remaining samples for testing. The average recognition rates are shown in Table 5. RR in table represents “recognition rate”.From Table 5, it can be easily seen that on the database of Extended Yale B, the average recognition rates of NUPDWT are higher than the other methods and the difference between the MinRR and MaxRR is the smallest in NUPDWT, which indicates that the proposed method is more robust than other methods.What's more, we can confirm from these experimental results that the use of non-uniformly patch strategy alleviates the influence of illumination variations even when such noise is presented in both training and testing samples.The LFW database contains images of 5749 different individuals in unconstrained environment [34]. The database here is a sub-database which gathers the subjects including no less than ten samples. It contains 158 individuals and each person has 10 different images with the size of 64×64pixels. The examples of this database are shown in Fig. 10.We compare NUPDWT with TDWT, TWSBF, PNN, PSRC, PCRC, MIMPCA, Volterra and UPDWT on the LFW database.We randomly choose 1, 3, 5, 7, and 9 images per person for training, respectively, and in every case, the remaining images for testing. The average recognition rates are shown in Table 6.From Table 6, one can see when training number is 1, NUPDWT has the second higher recognition rate only to PCRC. As the training number increases, NUPDWT and UPDWT perform much better than other methods, while the recognition performance is improved by NUPDWT to a larger extent. However, due to the unconstrained environment such as great changes on expression especially on pose, the recognition effectiveness of all the comparative methods on the LFW database is not ideal.It can be seen from the experiments implemented above that the recognition rates of our method are always higher than the methods based on 2D-DWT (such as TDWT and TWSBF) due to the consideration of the sub-bands' properties and the using of the patch strategy; when compared with some patch-based methods, such as PNN, PCRC, PSRC, and MIMPCA, the advantage of the non-uniform patch strategy in our method can be exhibited; though our method and Volterra adopt the same voting strategy, our method outperforms Volterra because the patches in our method are non-uniform so that the integrity of some important local information can be maintained.

@&#CONCLUSIONS@&#
Considering the physics meaning of 2D-DWT's sub-bands, applying the technology of integral projection on the sub-bands, and employing the idea of overlapped patches, we proposed an overlapped non-uniform patch strategy in this paper. By using NN and majority voting, we accomplished the classification. Thus the new method was proposed. It contained the advantages of taking better consideration of the sub-bands' properties and retaining the integrity of local information. We implemented the new method as well as TDWT, TWSBF, PNN, PSRC, PCRC, MIMPCA, Volterra and UPDWT on the AR, FERET, Extended Yale B and LFW face databases, and the numerical results showed that the new face recognition method outperformed other methods, which revealed the superiority of the proposed overlapped non-uniform patch strategy.The strategy of patch in our method was proposed based on the average image of training samples and complemented on the top-level's sub-band LL of all samples. If every sample can be further partitioned according to its own geometry structure, then the obtained patches will be better for retaining the integrity of local information, which may lead to more effective method for face recognition. In addition, the proposed method performed well with frontal or near-frontal facial images, but it can't effectively deal with the images under great changes on pose, as 2D-DWT cannot solve pose problem effectively. Face recognition under complex conditions, especially the different poses is a challenging and valuable issue. These are our study topics in the future.