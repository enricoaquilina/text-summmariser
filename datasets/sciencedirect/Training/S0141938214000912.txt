@&#MAIN-TITLE@&#
Distance estimation with mixed real and virtual targets in stereoscopic displays

@&#HIGHLIGHTS@&#
Accuracy of exocentric distance estimation in augmented reality were studied.Layout, parallax and center-to-center distance influence the accuracy of estimation.Observers generally underestimated center-to-center distance.Accuracy improved as real and virtual targets presented vertical and closer to observer.Underestimation raised a question whether real environment was dominated by virtual.

@&#KEYPHRASES@&#
Augmented reality,Stereoscopic displays,Exocentric distance,Near field,Distance perception,

@&#ABSTRACT@&#
In this paper we investigated the accuracy of center-to-center distance perception in near field augmented reality visual targets viewed by stereoscopic glasses. One real and one virtual targets were presented in four layout or target orientations (two horizontal and two vertical, by altering the relative positions of real and virtual targets) at three different parallax conditions (on screen, 5cm from screen and 10cm from screen) and four levels of scaled between targets’ distance (10–20cm, 20–30cm, 30–40cm and 40–50cm). The result revealed overall underestimation with an accuracy of about 84%. Interestingly, it was noticed that the main effects of layout, parallax and center-to-center distance were significant. Generally, accuracy improves when targets put vertical, close to observers’ position and smaller separation of targets. Significant interactions among the three main factors were also reported. The results are of great importance as it provides guide for the developers to decide where to present targets depending on the need for relative accuracy of judgment. Some engineering implications of the result are also discussed in this paper.

@&#INTRODUCTION@&#
In the spectrum of 3D stereoscopic vision, augmented reality (AR) lies between viewing completely real and completely virtual objects. In completely immersive virtual environment, the real object is completely replaced by the virtual 3D image and observers could not see their physical environment around. Whereas, in augmented reality the virtual 3D image will be integrated into the physical environment so that both can coexist and can be created by combining the virtual and real world environment using either the optical or video approaches [1,2]. Unlike virtual reality, AR aims at supplementing reality instead of completely replacing it [2]. For Nicolau et al., [3] any AR would fall in one of the four systems; video-based, see-through, projection-based or tracking; depending on the display technology employed. In optical systems, synthetic images are overlaid on the real object while in videos approaches the real object’s real-time image is recorded and displayed to the user after mixed with the virtual image. Displays, trackers, and haptic and force feedback are basic hardware components required to realize the augmented environment. Head mounted displays (HMDs) are the oldest and most commonly used display devices. Different types of HMDs are commercially available. Some models provide cameras embed with sensors that continuously track head movement and update scenes accordingly. Other commercially available displays that can also support augmented reality are see-through optical (OST) or video (VST) HMDs [4]. Handheld display devices (HHD) are also used where mobility is required as recent applications sees promises of broad users [5]. Integrating augmented environment on physical elements reportedly improve performance of operators in many of applications such as medical [2,4], manufacturing [2,4], maintenance [2,6], annotation and visualization [2], robot routing [2,4], military [2,4] and entertainments [2,4]. The current advances in mobile devices such as smart phones and tablets gave another dimension to AR applications such as tourism and entertainment [1,5,7]. Together with security and privacy issues as in Google Glass, enhancing felt realism and brain and sensory perceptions remained to be challenges of the current technology in building augmented reality [1]. The aim of this study is to explore the accuracy of exocentric distance perception which is an important component of interaction in near field synthetic environment.Kurkovsky et al., identified three major challenges in recent AR, especially for handheld devices [5]. These are accuracy of navigation and tracking, where the user’s location should continuously be updated where the current handheld devices such as Smartphone use the GPS information with Wifi and limited CPU capability; the content adding and programming that is not easy for ordinary users; and the limited usability of the technology to simple areas. Literature provides some solutions for each problem, however, it is still an active area of research where creative solutions continue to be proposed. So far, the interaction is not yet natural and effective as most of the techniques well established are in the 2D environment [7].The second major problem reported in the literature is fatigue and visual discomfort associated with viewing stereoscopic images. Stereoscopic motion images was found to induce fatigue [8]. Kooi and Toet [9] suggested three binocular asymmetry driven discomforts; optics-related, filters-related and stereoscopic-related. Optics-related problems refer to the shift, rotation or resolutions associated to the displays used. Filters-related asymmetric problems arise from difference in luminance, contrast, color, accommodations, or crosstalk of right and left displays. The third that originates from accommodation–convergence or parallax-convergence mismatches is referred as stereoscopic-related discomfort. In their review, Lambooij et al. [10] found similar problems in stereoscopic vision, discussed as, temporally changing demands of accommodation–convergence linkage, 3D artefacts resulting from insufficient depth information, and unnatural blur. Reichelt et al. [11] focused on distance cue factors that would cause discomfort, and concluded that motion parallax and oculomotor cues of vergence and accommodation contributed the most when not consistently provided.Another limitation reported in a few studies is distance perception. Generally, the distance perception space can be classified as egocentric or exocentric. In egocentric distances, the observer is used as the center of reference and the distance measurement is made between the observer and the target, whereas in exocentric space distances are measured between two targets in the environment other than the observer but the center of reference is still the observer [12]. Compared to real world, egocentric distance estimation is inaccurate in augmented reality [13–17] Corujeira and Oakley [16] compared distance perception of real objects with that viewed in HMDs and 3D stereo displays and found underestimation in all conditions, while the compression is reduced in HMD and 3D stereo when the targets are displayed at lower viewing height. Similarly, Dey et al. [18] conducted four experiments to study effect of AR X-ray and display (size and resolution) on egocentric distances for handheld devices. Their result showed overall distance compression and the error increases with distance. They also reported compression is less in mobile phones compared with tablet, whereas, no difference caused by presence of AR X-ray. Underestimation was also reported in few other studies such as in [19]. Kuparinen et al. [17] replicated the method used by Lappin et al. [20] in real world to evaluate distance perception in tablet-based AR, and revealed mixed results; overestimation and underestimation at 15m and 30m respectively. Interestingly, in Singh et al. [15] AR estimations were observed to be accurate in near field distance when blind reaching was employed. However, in the same study, perceptual matching results in slight overestimation for AR while real world estimates were accurate. In general, in the domain of augmented reality, majority of the literature seemed to report compression of egocentric distance compared to the accurate estimates in real world environment.The aforementioned cases were in the egocentric space. As for exocentric distance perception, a good number of experiments have evaluated the real world environment, however, literature reported only a few experiments in the stereoscopic viewing scenario, and most of them were in completely immersive virtual environments categories [21–25]. Despite the fact that the studies so far were not conclusive, compression looked to dominate the outcomes [22,25]. However, it is not yet known if underestimation holds in augmented reality because there are very few studies published in the domain of AR that conduct experiments to evaluate the accuracy of exocentric distance perceptions. Only recently, the first study reported in this realm was by Dey et al. [18]. Out of several experiments in the study, the fourth experiment evaluated exocentric distance perception in iPhone and iPad displays, and found overall underestimation with less underestimation in iPhone display condition. Despite the fact that a number of egocentric distance results are available, to the best of authors’ knowledge, exocentric distance accuracy in wide screen displays where observers wear stereoscopic glasses, were not reported so far. And yet, in the emerging AR applications, the relationship between objects is an important feature that needs to be addressed, and hence exocentric information should be provided accurately [18]. Therefore, this study aimed to contribute to the knowledge gap in this area.In this experiment, we investigated the effect of layout (targets’ orientation) and parallax (distance between screen and targets) on accuracy of exocentric distance judgment in augmented environment. The experiment also evaluated the effect of between targets’ distance. The experimental tasks and protocols were defined under near field space, because there are no studies so far and it is important in terms of user-display interaction in which one is able to point to or reach for the object of interest. We developed a perceptual matching technique for observers to report perceived distance between two objects (real and virtual), by sketching. Sketching was used by Henry and Furness [22] and disclosed, accurate perceptions of real and compression of virtual distance in extrapersonal space. This result was consistent with Michael Geuss et al. [25] who used blind walking. As mentioned in section 2, only few studies available in exocentric spaces and even fewer in exocentric AR, none of them discussed the effects of orientation of targets or parallax.Perceptual matching by sketching was employed to measure the distance between real and virtual targets. Fig. 1shows the experimental settings for the two layout conditions (horizontal and vertical). Depending on the desired parallax condition, the distance between targets and the fixed screen was adjusted. Participants sat on adjustable chair, with chin fixed at 100cm distance from the screen, such that the center of eyes’ projection is the geometrical center of the two targets. The targets presented in various combinations of layout, parallax and between targets distance. The 3D projector was fixed above and just behind the observer at a distance of 153cm from the screen and at 135cm above the floor where the projector camera was kept at vertical and horizontal angle of projection of 22.52 and 31.97 degrees, respectively, from camera position. The observer’s task was to estimate the exocentric distance between targets by drawing a line, on paper provided by the experimenter, that she/he believed would match the perceived distance.The observers viewed two yellow spheres – one real (tennis balls of 40mm diameter) and the other one its replica (virtual), in four different orientations and presented at three different egocentric distances from observers where the center-to-center distance varied as well in four levels. The virtual ball was drawn using Unity 3D (version 3.5.1) and run on ASUS computer (Pentium® Dual-Core, 3.20GHz), with the yellow color approaching the real ball as close as possible. The simulated targets were displayed on ViewSonic (3D DLP, Model VS14555, 120Hz) projector with interlaced 120×90 resolution of view, and viewed by NVIDIA 3D Vision Wired Glasses. A small 3.6m×3.2m×2.5m space partitioned by black curtain was used to create good stereoscopic vision, which was equipped with a desk, chair and stationary materials. The projection screen of 90cm×75cm was made from black paper with effective projection area of approximately 78.5cm×60cm. Before the experiment started, calibration was done for required virtual target size and center-to-center distance between the real and virtual targets by measuring, when virtual target displayed on the screen. In the process, the 3D projector was always kept fixed. After each experimental scene was displayed and the participant viewed and felt confident to start estimation, he/she turned away to the right side and began to draw a line for the perceived distance.Ten graduate students aged between 23 and 27 (with a mean age of 24.6) were recruited from National Taiwan University of Science and Technology (three females and seven males). Payment, credit or any other compensation was not given for their participation; they only volunteered for experiencing stereoscopic viewing. Each participant took part in all experimental conditions. All participants reported normal or corrected to normal visual acuity. The study was approved by the institutional review board of the university.The first factor was layout which depicted how the targets were arranged. The layout shows the position of one target relative to the other. Four different arrangements were used; two in horizontal (V-R-H and R-V-H) and the other two in virtual orientations (V-R-V and R-V-V). The first letter in the designation represents the target either virtual or real displayed to the left (horizontal orientation) or at the top (vertical orientation). Similarly the second letter represents the right side (horizontal orientation) or the lower (vertical orientation) target. The third letter represents the type of orientation (i.e. H is for horizontal while V is for vertical). For instance, R-V-H describes the setup where targets presented horizontally, the real target placed at the left and the virtual to the right.The second major factor that varies in three levels (on the screen, 5cm in front of the screen, 10cm in front of the screen) is parallax. The parallax defines the position of the targets relative to fixed screen position while observer was seated at a distance of 100cm away from screen. Therefore the targets are displayed on, 5cm, or 10cm distance from the screen (Fig. 1). The experiment considered only zero and negative (virtual object on or in front of the screen) parallax. Positive parallax (virtual object behind the screen) was not considered in this experiment due to technical limitations of displaying the real object behind the opaque screen, which could not be visible to the observer.The last independent variable for this experiment was exocentric distance, which can also be defined as the center-to-center distance between the two targets. Four scaled distances were chosen to be assigned randomly for each trial. The ‘exocentric distance’ in Fig. 1 represented the center-to-center distance between targets, which, participants were asked to estimate. These distances were categorized by four scaled ranges of 10–20cm, 20–30cm, 30–40cm and 40–50cm, where the exact values for each trial in the range was picked randomly. Random variation of the distance within each category is done to avoid possible effect of learning or guessing over a fixed distance.Participants estimated center-to-center distance between the two spheres (real and virtual) by sketching. After estimates were made, distances were measured and tabulated by the experimenter. From the response and corresponding reference distance, two dependent variables, accuracy and signed error (SE), were derived. Accuracy and signed error was previously used by Dey et al. [19] to report egocentric distance perception.The closeness of judgment to the true value, the accuracy, was determined for each trial by equation below which can be defined as fraction of the actual distance:(1)Accuracy=1-Dp-DaDawhere Dpwas the observer’s perceived distance and Dawas the corresponding actual distance.SE was calculated using Eq. (2) as the difference between the ratio of perceived center-to-center distance and actual. The signed error varies between −1 and +1. Positive SE indicates overshoot of exocentric distance, while a negative SE indicates undershoot and zero when exact match.(2)Signed Error(SE)=DpDa-1Despite the fact that time to complete the trials was not measured, participants were instructed that their initial reaction with perceptual matching response was important and encouraged not to take too much time with any one of the trials.Prior to conducting the experiment, we had the following hypotheses:H1Exocentric distance will be underestimated. In virtual environments, Guess et al. [25], and Henry and Furnes [22] reported underestimation. Therefore we expect similar results in the current experiment.Accuracy of distance estimation will be better in vertical orientations compared to vertical. This hypothesis was based on the assumption of the first hypothesis and the theory that people perceive vertical dimensions to be longer than their horizontal matches. This theory is widely discussed especially in physical environments as horizontal-vertical-illusions [26,27].Accuracy will be higher when targets are displayed closer to the observer. This is with the assumption that egocentric and exocentric distance affect each other and in majority of the studies, in physical and virtual reality, accuracy was higher in near field visual space [28].Distance perception will be more accurate in the closer center-to-center distance between the real and virtual targets.

@&#CONCLUSIONS@&#
