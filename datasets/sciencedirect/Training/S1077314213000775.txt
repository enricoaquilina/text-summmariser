@&#MAIN-TITLE@&#
A survey of shaped-based registration and segmentation techniques for cardiac images

@&#HIGHLIGHTS@&#
This article presents a review summary of the shape modeling applications to cardiac image.The covered modalities are MRI, CT, echocardiography, PET and SPECT images.The methods are classified based on their properties.The article covered methods published in journals within the last 10years.

@&#KEYPHRASES@&#
Cardiac CT,Cardiac motion,Cardiac MR,Cardiac segmentation,Cardiac registration,Echocardiography,Review article,

@&#ABSTRACT@&#
Heart disease is the leading cause of death in the modern world. Cardiac imaging is routinely applied for assessment and diagnosis of cardiac diseases. Computerized image analysis methods are now widely applied to cardiac segmentation and registration in order to extract the anatomy and contractile function of the heart. The vast number of recent papers on this topic point to the need for an up to date survey in order to summarize and classify the published literature. This paper presents a survey of shape modeling applications to cardiac image analysis from MRI, CT, echocardiography, PET, and SPECT and aims to (1) introduce new methodologies in this field, (2) classify major contributions in image-based cardiac modeling, (3) provide a tutorial to beginners to initiate their own studies, and (4) introduce the major challenges of registration and segmentation and provide practical examples. The techniques surveyed include statistical models, deformable models/level sets, biophysical models, and non-rigid registration using basis functions. About 130 journal articles are categorized based on methodology, output, imaging system, modality, and validations. The advantages and disadvantages of the registration and validation techniques are discussed as appropriate in each section.

@&#INTRODUCTION@&#
The heart is the most energetic organ in our body. Beating about every second, it continuously supplies the body with vital oxygen-carrying blood. Heart disease is the leading cause of death in modern countries [1–3]. The mortality rate of CVD is estimated to be 17 million in 2005 and thus is ranked as the top killer worldwide [3–5]. According to the AHA update of 2009, CVD is the cause of 10% of days of lost productivity in low- and middle-income countries, and 18% of days of lost productivity in high income countries. CVD morbidity rates are estimated to rise from around 47 million days globally in 1990 to 82 million days in 2020 [4–6].Analysis of the cardiac function using imaging instruments has shown to be effective in reducing the mortality and morbidity of CVD. Myocardial motion analysis is time consuming and suffers from inter and intra-observer variability. Computerized analysis can help clinicians to interpret the medical conditions objectively [1,7–9]. Cardiac image processing techniques, mainly categorized as segmentation and registration, have been used widely to assess the functionality of the heart [10–14]. Cardiac image segmentation provides us with high quality structural information of the heart while registration techniques calculate the local functional analysis helpful in diagnosis and treatment planning of patients. Modeling of the cardiac shape, motion and physical structure have played a major role in the development of the image analysis algorithms. Previously, there have been some review papers in the field of computer analysis of cardiac imaging [15,16]. Some review papers have focused on echocardiography segmentation [17], cine MR segmentation [18] or Tagged MRI [19,20]. Frangi et al. [16] classified cardiac modeling techniques to three classes: surface models, volume models, and deformable models. The review focused on 3D cardiac modeling techniques based on different modalities namely angiography, cardiac US, isotope imaging, cardiac CT, and MRI. With the increasing number of the cardiac modeling techniques, a review article to summarize recent efforts is timely.This survey aims to (1) classify major contributions in the field of cardiac modeling, (2) introduce the methodologies in this field, (3) tutor beginners to initiate their research, and (4) introduce the major challenges of registration and segmentation with examples. The techniques developed in the last 10years are classified as: statistical models, deformable models/level sets, biophysical models, and non-rigid registration methods. The articles are classified in different tables describing the method, database, and output of the technique. The novelties of the methods are described in relevant sections and are compared to alternative algorithms. The advantages and disadvantages of each category are discussed as well and different approaches to validation are classified.The surveyed articles in this review are from major journals such as IEEE Transaction on Medical Imaging, Medical Image Analysis, IEEE Transaction on Image Processing, IEEE Transaction on Information on Biomedicine, Ultrasound in Medicine and Biology, International Journal of Computer Vision, Computer Vision and Image Understanding, IEEE Transaction on Biomedical Engineering, Cardiovascular Magnetic Resonance, and Journal of Magnetic Resonance in Medicine.The heart is composed of a muscular contractile organ (myocardium) surrounded by two layers of connective tissue inside and outside called endocardium and epicardium, respectively. The heart has four chambers and four major valves (Fig. 1). LV, the prominent chamber of the heart, is the major contractile chamber, and maintains the systemic circulation. Myocardial contraction is maintained by a circulatory system of coronary arteries that supplies the muscle with oxygenized hemoglobin and nutrients. Coronary arteries (right and left) are two branches of the aorta and supply the myocardium through smaller branches such as LCX, LAD and diagonal arteries [2].Due to atherosclerosis, the coronary arteries may gradually become occluded and end in CAD (Coronary Artery Disease). Coronary occlusion leads to disturbance in the cardiac contractility and causes global or regional dysfunction in the heart and may be diagnosed using state-of-the-art medical imaging techniques such as echocardiography, MRI, CT, and nuclear medicine [2]. In studying ventricular motion, physicians typically assign a subjective segmental function score to different segments of the ventricles:Normokinesia (0): The myocardial motion and thickening is normal.Hypokinesisa (1): The affected segment moves slower and thickens less than normal.Akinesia (2): The infarcted region has totally lost its ability to contract in the systolic phase and moves passively along with its surrounding myocardial tissue.Dyskinesisa (3): The infarcted region moves paradoxically and bulges out during systole due to the ventricular blood pressure.Aneurysm (4): The infarcted region undergoes remodeling, becomes thin, bulging outwards during the systolic phase like a balloon, leading to rupture and death [9].The cardiac blood circulation is an alternation of two phases: diastole (relaxation phase) and systole (contraction phase). Normally 70% of the whole LV blood in end diastole is ejected out during systole. The Ejection Fraction (EF) ratio is an index of global LV function. EF is calculated as (EDV–ESV)/EDV where EDV is the volume of the LV at end-diastole and ESV is the volume of the LV during end-systole. Ventricular walls thicken during systole – this is typically referred to as wall thickening and has been proven to be a very reliable index of regional myocardial function. Heart failure is characterized by a significant decrease in the EF. An additional index of cardiac performance is myocardial mass which can be determined from myocardial volume, assuming the myocardium to have uniform density [9].There are several cardiac imaging modalities that are in widespread use. These include MRI, CT, echocardiography, and nuclear medicine. Each method has advantages and draw backs that are discussed in this section. MRI, CT, and Echocardiography are amenable to computer analysis and much effort has been devoted to automated processing of images from these modalities. In comparison, nuclear medicine has seen less effort devoted to computerized analysis.Magnetic Resonance Imaging (MRI) uses a magnetic field to align the magnetization of hydrogen nuclei in the body. Subsequently radio frequency pulses change the alignment of this magnetization and produce a rotating magnetic field detectable by an external RF coil. MRI uses non-ionizing radiation and is considered a non-invasive technique. Contrast may be used for further signal enhancement. Contraindications to use of MRI include pacemakers and metal implants. With MRI, different segments of the myocardium are well visualized and can be easily reconstructed in 4D format. An advantage of MRI is that it is possible to acquire images with different orientation with no image processing (no reslicing is necessary). An advantage of MRI in comparison to other imaging methods is that it permits evaluation of perfusion (first past perfusion), function (cine and tagged imaging), scars (Late-Gadolinium Enhancement imaging), as well as epicardial coronaries. However, MRI is more costly than other methods, (particularly echocardiography) and is not available in all cardiac care centers. Cine MR is able to achieve high resolution images with respect to the cardiac border but the contrast is not as helpful inside the cardiac wall. An MR imaging protocol named tagged MRI uses spin tagging prepulses to produce markers inside the myocardium over time, which can be tracked, permitting the possibility to compute dense myocardial motions and the strain. One drawback of this method is the fading of the tag lines over time, which is especially pronounced in diastole, when imaging with no trigger delay. A solution to this is to apply a trigger delay in order to visualize diastolic function of the heart. Cardiac cine-MRI is considered the standard MR technique mainly used for global function measurements and segmentation while tagged MR techniques are used for regional analysis and temporal registration [7]. MR images acquired with orientation perpendicular to the long axis of the heart (the line which connects the apex to the outflow tract) is called Short Axis plane (SAX) (Fig. 2). Imaging of the heart in cine MRI covers about 10–15 slices and 15–30 frames, depending on the size of the heart, prescribed slice thickness, the heart rate, and specific approach to image acquisition. Fig. 3shows SAX images in cine and tagged MR series during different cardiac cycles. Images acquired parallel to the long-axis axis are called Long Axis (LAX) images and are sometimes combined with SAX images for better visualization of the anatomy as well as for computing true 3-D motion (including the through-plane motion). Cardiac images are not specific to the heart and certainly include non-cardiac tissue as well. To decrease the computational time, a region of interest (ROI) can be computed that only includes the heart tissue. On a usual (gradient echo) cine MR image, the blood pools is white and the myocardium is black; however, black blood imaging renders the blood pool dark [7,19,20]. Other submodalities of CMR include Late-Gadolinium-Enhancement (LGE) imaging for visualizing scarred tissue, coronary MRA for visualizing the coronaries, multinuclear spectroscopy for spectroscopic imaging based on Carbon, Sodium, or Flourine, and first-pass perfusion imaging to visualize the ischemic myocardium. Flow imaging (e.g., phase-contrast) MRI can also be used to reveal flow and motion information for blood flow inside vessels which may be located deep within the body or to determine ventricular wall motion [7].Echocardiography utilizes the backscattered ultrasound wave generated by an array of piezoelectric crystals to acquire images of different tissues. It has important advantages including, portability, non-invasiveness, use of non-ionizing radiation, real-time, and low cost. However, echocardiography, in general, suffers from poor contrast, noisy images, sub-optimal visualization of the cardiac segments, air/bone interaction problems causing reverberation artifacts, and reproducibility and operator dependence issues. An additional disadvantage in the overweight patients is the inability to obtain an acoustic window since there is a need to bypass the lungs and the ribcage to image the heart [8,9]. Doppler imaging is possible with US and may be used to compute the velocity of moving particles (and measure blood flow). However, use of Doppler US only permits computation of the tissue/blood motion in the direction of the ultrasound beam (called the angle of insonification) [8,9].3D echocardiography images can be obtained using recent sophisticated 3D ultrasound transducers by using a miniaturized array of piezoelectric crystals. Real time 3D scanners were introduced in the early 1990s but in comparison to 2D echocardiography, initial images suffered from low spatial resolution. New high-tech transducer arrays have significantly improved spatial resolution and image quality – as a result, 3D imaging is enjoying more wide-spread use [8,9].Ultrasound images have a texture pattern usually referred to as speckle. Speckle formation is the result of the diffuse scattering of the ultrasound wave encountering random interference with scatterers which are very tiny particles of size comparable to the wavelength of the ultrasound wave. These scatterer particles do not simply reflect or refract the ultrasound wave but induce a more complex diffuse scattering which is the basic physical concept of speckle formation. Speckle is considered an inherent property of the ultrasound image notorious for having spatial correlated multiplicative noise and making the ultrasound images unreliable. Speckle tracking techniques try to use these same speckle patterns to detect the cardiac motion in echocardiographic frames. Doppler imaging is also utilized for computing the velocity of blood as well as that of the myocardium. When applied to image tissue velocities, the technique is referred to as Tissue Doppler Imaging or TDI for short [8,9].4D cardiac CT allows non-invasive imaging of the detailed cardiac anatomy with high contrast and exquisite resolution; especially useful for the assessment of coronary artery structure. However, it is not as widely available as echocardiography and uses ionizing radiation. Cardiac multi-detector computed tomography (MDCT) is able to acquire moving images of the heart that rivals cine MRI (though with reduced temporal resolution) as a detailed source of information (Fig. 5). Initial generations of CT systems were not able to provide accurate images of the heart due to its fast motion. Now a days, MDCT scanners such as 64 (128, 256, or 320) detector-row CT scanners and dual source CT scanner are available with multiple gantry rotations in one second acquiring several CT slices (64 slice for a 64 row CT scanner). It is foreseeable that CT technology will advance to the point of covering the entire heart in a single rotation and in a single cardiac cycle. Also, use of iterative reconstruction techniques has the potential to permit the use of low dose, high quality scans. CT angiography (CTA) is very sensitive for diagnosis of coronary artery, by-pass graft, and stent abnormalities. It is able to acquire unique visualization of the coronary arteries including narrowing, type and degree of atherosclerosis plaque. Additionally, it can also be used to simultaneously visualize the pulmonary and systemic arteries as well as the thrombosis. Despite the expense, cardiac CT is becoming more widely available in cardiac care centers and may be an alternative to diagnostic catheterization which is invasive and costly. Recent advances in cardiac CT with contrast (late enhancement CT) also permit visualization of scarred myocardium (similar to LGE imaging in MRI) and also the possibility to utilize a range of X-ray energies to perform tissue characterization (this is referred to spectral CT) [7,8,10].Nuclear medicine techniques such as Positron Emission Tomography (PET) and Single Photon Emission Computer Tomography (SPECT) use the gamma-ray or positron emission of injected radiopharmaceuticals in order to image the myocardium. The injected radiotracers are taken up in particular tissues, such as malfunctioning or dead myocardium, and continue to irradiate positrons (which lead to emission of gamma-rays) during decay, permitting visualization of the metabolism and function of the heart. SPECT studies, which make use of Thalium or Technetium, are routinely utilized to image myocardial perfusion. Imaging can be performed at rest or under pharmacologic stress (e.g. adenosine) to measure the perfusion reserve and defects (Fig. 5). The wash-out of the isotope is the long acquisition time which is in the range of 30min to 3h while the patient should stay still. Although radio-tracer studies pose some risk to the patient, they have proven to be extremely powerful with high sensitivity and specificity in the assessment of patients with coronary artery disease and in determining the territory with perfusion defects. Fluroro-Deoxy-Glucose (FDG) is used in the case of PET to image myocardial metabolism. In fact, with FDG PET it is possible to distinguish between necrotic vs. stunned vs. hibernating myocardium. PET is the only modality which can conclusively determine myocardial viability and is typically used as ground-truth in multimodality studies [10–14].Albeit the importance and prevalence of nuclear cardiology in clinical care of patients, nuclear techniques (especially PET) are very expensive and furthermore the resolutions are nowhere near other modalities. Perhaps, this has contributed to decreased enthusiasm of computer vision researcher to develop automatic and quantitative techniques for this modality.Cardiac segmentation consists of the segmentation of the epicardium and the endocardium of LV, RV, LA, and RA. Epicardial segmentation: In general epicardial delineation is more difficult than endocardial delineation due to the similarity and fuzziness of the gray level of the outer tissues and the heart and poor contrast. Endocardial contour has a good contrast due to the large intensity variation of the blood and the myocardium in all the modalities. Endocardial segmentation: Endocardial delineation is not straightforward due to the Papillary Muscles and myocardial trabeculation ridges visible in MR, echo and CT (Figs. 3–5). Local image features such as intensity and gradient do not represent the real contours near the Papillary Muscle. Since clinicians consider the Papillary Muscle as a part of the blood pool, it is usually not segmented in the current algorithms. Some of the challenges are shown in Fig. 6.The shape of the RV is also more variable and concave and thus more challenging than the LV. The RV chamber is present in few slices and the RV wall is thinner with respect to the LV wall and therefore the epicardium and endocardium are close to each other and more difficult to segment. Atria and great vessels are only present in 2–4 slices. They are especially difficult to delineate in echocardiography images but easier to deal with in CT series due to the better spatial resolution and visibility.Additionally apical slices are more difficult to segment in all the modalities due to less information, unpredictable end of the LV and RV cavities, vicinity of diaphragm, more variable shape and motion of the contours and haziness of the tissue. Indeed, even manual segmentation of the tip of the heart (apical slices) is difficult. Basal slices are also more cumbersome to segment due to highly variable shape and motion of the LV and RV walls and cavities in the basal slices as well as the vicinity of the atrial and great vessel lumens.Pixel resolution anisotropy is a common issue in MRI and CT segmentation and registration. The resolution of the pixels in the spatial direction is not the same as the resolution of the pixel in the through plane direction.With respect to motion estimation, out-of-plane error (through-plane error) is a common issue in any 2D technique and therefore 3D motion detection is suggested to cope with the problem. However 3D cardiac imaging usually requires a longer acquisition period, slice misregistrations, ECG gates, and breath-holding [7].Although cine MRI has excellent cardiac contour contrast, it lacks the myocardial contrast inside the cardiac wall and, therefore, it is not suitable for dense motion analysis and strain estimation. Tagged MRI is suitable for this purpose. The tag line markers can be tracked through the cardiac frames but they fade out through the cardiac cycles and are washed out and less useful especially during the diastole.Since echocardiography is performed by hand, several views can be acquired using different transducer orientations. These views are not the same especially in the task of segmentation. Another shortcoming is the fact that in both 2D and 3D echocardiography data, the contour of the epicardium or endocardium may be incomplete simply because it is out of the region of the transducer coverage. The endocardial and epicardial contours have even less contrast in echocardiography due to the noisy structure of the ultrasound images. Different types of ultrasound artifacts contribute to this problem as well, especially “drop out artifact” that happens when the tissue contour is in the direction of the ultrasound beam. Another feature of ultrasound images is the speckle pattern. The shift varying PSF in echocardiography makes decorrelation in the RF signal and the B-mode image which leads to higher error in the registration methods. Artifacts and the presence of air and bone also contribute to less accurate results.Calculation of important cardiac indices such as cardiac volumes and Ejection Fraction are based on accurate segmentation of the heart chambers while computation of the regional displacements and mechanical indices of cardiac function are related to temporal registration of the imaging data. Segmentation and registration can be performed via techniques that will be discussed in this section.Bottom up methods: Such as thresholding, morphological, pixel classification and edge-based techniques were among the first techniques to be used in the field of cardiac image analysis due to their simple and intuitive nature. However cardiac texture has a wide intensity range that is not completely detectable by pixel-driven techniques. Additionally, object boundaries do not necessarily overlay on the edges. This problem can be tackled by using additional assumptions derived from the cardiac structure, statistics and physics.A large number of methods have been developed for cardiac functional and anatomical modeling. In this section, we classify the modeling techniques into four categories described in Tables 1–4. These are (1) statistical models, (2) deformable models/level set, (3) biophysical models, and (4) non-rigid registration using basis functions. However the boundaries of each class are not exact. Several papers have combined two or more different classes in the same algorithm. In this situation, the papers are classified according to the most relevant group. The tables cover about 130 journal article published in the last 10years.Key to the tables: Each table consists of several columns representing authors, modality, dimension of the method, vendor, output of the algorithm, description of the algorithm, types of validation, and type of data. The number of cases in the validation dataset is mentioned in parenthesis as normals (N) or patients (P). Most of the papers use 2D or 3D human data for validation but some papers focus on dogs, or computational/ physical phantom data. The output of the proposed methods can be the contour of the endocardium only (endo), epicardium (+Epi), RV (+RV), atria (+A), great vessels (+V), Tag lines (+tag) or motion vectors (+M). Since any segmentation method delineating the epicardium or the RV also delineates the endocardium, the key (endo) is used for methods that only segment the endocardium. In some cases, parameters such as the number of the data and vendor are missing, are incomplete or unclear and are left blank in the table.Since intensity is not a perfect descriptor of the contours in cardiac images, statistical techniques are finding ever increasing interest in their area. In general, the heart is a convex, and excluding a few conditions such as a cardiac aneurysm, can be modeled as an ellipsoidal object that moves in- and out-wards [1–3]. Therefore use of statistical priors, including shape, motion or texture, can aid in the cardiac segmentation and registration tasks. Statistical methods can be classified based on use of shape prior, Active Shape Model, Active Appearance Model [21,22] and motion model. Each subcategory will be discussed separately in this survey. Table 1 contains the statistical articles [23–34,22,35–70] classified based on the structure, method, vendor, dataset, and output.The LV cavity looks like a truncated ellipsoid while the RV cavity is thinner and crescent shape. The LV wall is three times thicker than the RV wall. Several authors have tried to use the expected shape of the heart as a prior in aiding automated segmentation and registration. The prior is typically incorporated as an additional constraint to overcome the failures of intensity or edge based energy functions to uniquely determine the anatomical boundaries.Since the LV contour resembles an ellipse; a fast approach for building a prior is to use an ellipsoid. Pluempitiwiriyawej et al. [53] utilized an ellipsoid with 5 degrees of freedom as prior. The five parameters defined the location, size and scale of the ellipsoid. The distance of the contour to the ellipsoid was used as the ellipsoid constraint. The authors also added two additional energy terms for the ellipsoid shape prior: 1. stochastic region based term based on modeling the distribution of the pixels inside and outside the contour; 2. an edge based term similar to a snake (latter will be discussed in Section 3.2) energy function to attract the contour toward the edges. The combined energy functional is used in a level set framework (latter to be discussed in Section 3.2) in order to segment 2D short-axis cine MR images. The advantage of this method is using five degrees of freedom, which can decrease the computation.Practically, the shape of contours does not change dramatically, as they move from one cardiac image to the next in the spatial or temporal direction. Therefore, a simple approach to modeling and segmenting the cardiac cavity in 3-D is to use the contour already segmented to locate the contour in the next slice or the next time point. Chenuoune et al. [50] use the previous frame as the prior incorporated in a level set (Section 3.2) technique. In the first step, the endocardial border of SAX cine MR images are segmented based on a level set method. The previous contour is then registered using morphology operators to the next frame as a shape prior. Using the previous contour can decrease the computation but can cause local minima problem as well.Another method uses a learned shape derived from a training step with manually delineated images. Tsai et al. [28] used a shape prior computed by applying Principal Component Analysis (PCA) to a collection of signed distance representations of manually segmented data. Subsequently, the shape prior was incorporated into a level set framework in order to segment cine MR images. Folkesson et al. [51] used the distance to a prior shape in the context of a geometric active contour model (Section 3.2). The prior was computed by training the algorithm using a set of images. Instead of the image pixels, local features derived by Hessian operator were utilized to increase the speed of the algorithm. In [44], the heart model was constructed in the wavelet domain and used as the prior. The wavelet transform was applied to the cardiac surfaces in the spatiotemporal domain to extract the coefficients. A neural network model was generated to combine the local and global information in order to extract the trained shape and segment the cardiac boundaries. The Fourier decomposition approach was shown to be able to represent different shapes by their Fourier descriptors. Coarse shape coefficients were computed by low-order harmonics, while higher order coefficients represented the fine detail.Practically, the endocardial and epicardial contour segmentations may overlap due to variable contrast and haziness of the boundaries. This problem dramatically increases the error and leads to unrealistic rendered 3D heart images. In order to tackle this problem, Dietenbeck et al. [46] used a constraint that poses a forced distance between the endocardial and epicardial contours. The thickness constraint was combined in a level set framework in addition to a regional intensity term and a distance term describing the distance of the contour to a learned shape. This technique was applied to echocardiography images to segment the LV epicardium and endocardium simultaneously.Ben Ayed et al. [47] proposed to compute the endocardial and epicardial contours simultaneously using the first frame. In the first step, three image region classes were proposed: 1. LV cavity containing blood; 2. Myocardium; 3. Background containing adipose tissue, lungs, etc. The algorithm assumes that the overlap between the kernel-based intensity distributions within each region remain the same through the consecutive frames. The Bhattacharyya coefficient was used as the overlap measure. The Bhattacharyya coefficient is a popular measure to determine the overlap between two statistical samples. This coefficient is generally used to calculate the relative closeness of the two distributed classes. In a novel approach, the energy term does not assume that the overlap between the intensity profiles within different regions has to be absolutely minimal. This modification helps to include the Papillary Muscle as well. The authors were able to achieve competitive results without using geometric training or preprocessing which leads to higher flexibility in the real clinical setting.Ben Ayed et al. [48] proposed to use combined energy terms consisting of the distance to a learned shape in addition to an intensity-matching constraint. The first cardiac frame was utilized for training of the model of the histogram. The algorithm was applied to cine cardiac images for segmentation of the epicardial and endocardial boundaries in cine MR SAX images. The prominent advantage of the last two articles is reduction of the training time. Since training is only based on the first frame, the training time is significantly reduced. As a disadvantage, the validation is based on 20 datasets. Increasing the number of the tests set can increase the reliability of the method.Codero-Grande et al. [42] coarsely delineate the myocardium initially. The tissue statistics is modeled using Gaussian Mixture Model (GMM) according to the intensity and gradient of the LV contour and the tissue inside the LV. GMM tries to model the tissue histogram using a weighted summation of Gaussian distributions. Consequently, a center-surround biannular radii is overlaid on the circular myocardium of SAX slices. Thereafter, a 3D polar grid is generated on the images. A Markov Random Field (MRF) system including the prior and the likelihood terms is defined over that grid. A Markov random field is a graphical model of a set of memoryless random variables represented by an undirected graph that works similar to a Bayesian network. The intensity and the gradient likelihood over different image subsets are constructed using the previous grid and finally the parameters of the MRF are recursively estimated and used for segmentation of cine MR images.The intensity, probability, and estimated contours from previous spatial and temporal locations may not represent the cardiac boundaries well; this is especially true in cardiac US images since at times, the contours are not complete and the cavity cannot be fully visualized. The main advantage of the ASM methods is their ability to overcome the noisy structure and drop outs of the cardiac images based on probabilistic knowledge of the object which is independent of the intensity [13,14]. ASM builds a whole shape model using manually segmented data. Subsequently, the model is registered on the images as will be discussed. A shape model is defined as a structure which reflects the typical structure of a special set of anatomical objects of interest; i.e., the shape model is invariant to transformations. There are several ways to represent a shape: 1. cloud point, 2. surface, 3. mesh/triangulation (a set of points with connectivity), 4. skeletonization, 5. parameterization via a set of basis functions such as B-spline or NURBS. In computational cardiac studies, surface and mesh models are utilized more frequently. Since most Active Shape Models have the same general structure, below, the ASM is discussed in general terms and the differences among the methods are described. Basically, there are five steps in use of ASM for segmentation:1.Contour extraction and spatial alignment: A database containing adequate number of examples is manually segmented in the training phase. Several landmarks are selected on the contours of the manually segmented training set. Subsequently, the detected landmarks are aligned to a defined coordinate using rigid registration techniques such as the Procrustes method [71]. One shape is arbitrarily selected as the reference.This step is usually the same in most papers but some variations exist. Lekadir et al. [63] used inter-landmark measure as an invariant shape representation that allows the decomposition of the global prior as well as constraining each individual landmark. The inter-landmark measures rely on barycentric coordinates based on three coefficients to describe the relative position of each landmark with respect to two neighbor triangles of different shapes and poses. The barycentric coordinate system is a homogeneous coordinate system in which the location of each point is represented with respect to the center of mass, or the barycenter. The authors suggested that inter-landmarks carry larger proportion of the shape difference with respect to the other and this leads to inaccurate alignment.2.Temporal alignment: Different datasets have different numbers of frames. In that case, an interpolation (such as spline or bilinear) in time is necessary in order to make the number of frames similar in the temporal direction [57,60]. Here again one dataset is arbitrarily selected as the reference.Construction of the shape model: A set of selected points distributed on the surface known as PDM (point distribution model) can be formulated as:4.Dimensionality reduction: Dimensionality reduction of the training set is usually performed by using Principal Component Analysis (PCA) to find a small set of values that best represent the observed variation. PCA extracts the eigenvalue decomposition of the covariance matrix, providing the principal eigenvectors. Principal eigenvectors show the variability in the data. In practice, the eigenvalues that describe 95–99% of the total variance are kept and the rest are discarded. Subsequently, each shape may be represented as:Instead of the above-mentioned linear equation, Hoogendoorn et al. [41] used a bilinear model to segment the ventricles, atria and great vessels in CT images. In the bilinear mode, an additional parameter (b) was added to provide a better model of the point set. The bilinear model represented an extension of the linear model by using two factors (Aandb) while removing each factor leads to a linear model. The bilinear model is formulated as:(5)x=ATWbwhereXis a scalar observation defined by the point set,Aandbare parameterization vectors, andWis similar to the eigenvalue matrixPCA is based on the assumption that the data are Gaussian distributed which may not be true. To cope with this problem, some authors have used Independent Component Analysis (ICA) [72] which assumes statistical independence [24,43]. ICA is a technique to separate set of data into additive non-Gaussian subcomponents provided that the subcomponents are mutually statistically independent. However, ICA increases the computational burden in comparison to the PCA. Several other variants of PCA have been developed in the literature. In [24], temporal dynamics and inter-subject variation is tackled using Multilinear PCA (MPCA) and Multilinear ICA (MICA). Bosch et al. [62] performed the PCA technique in smaller regions to give more local versatility to the general shape model. Therefore, the local landmarks achieve regional independence with regard to the global shape.5.Shape correspondence: Shape correspondence computes the transformation (T) that relates the object (x′) to the shape model as:Several techniques have been used for the correspondence of the point sets. One of the major techniques is Iterative closest point technique (ICP) [73]. ICP iteratively estimates the global transformation T and then applies that transformation (T) on the current position of the point distribution. The transformation T is updated based on the minimization of a least squares cost function that is the distance between the expected point distribution position and current estimate of image boundary points. In practice, ICP consists of four steps: (1) using the nearest neighbor criteria to map the points of the object to the points of the model, (2) Estimating transformation parameters applied to the point set (pi,t) based on a minimizing the mean square cost function such that:(7)f(T)=∑i=0m-1‖T(pi,t)-pi,t-1‖2(3) Transforming the point set using the estimated parameters, (4) the first three steps iterates recursively until the cost function is less than a small predefined value [73].However ICP is computationally costly and cannot handle different energy functions for correspondence computations. Optimized matching techniques can be utilized instead of brute-force point set matching. Non-rigid registration techniques such as B-spline registration (described in Section 1.3.4) have also been used for shape correspondence since they are inherently smooth and can handle different energy functions. Besl and McKay [73] and Frangi et al. [74] used the landmarks extracted from manually delineated images to build a cardiac model. The landmarks were propagated using volumetric B-spline registration due to several advantages. B-spline non-rigid registration is less restrictive regarding the structure which is due to the faster implementation and inherently smooth nature of the spline basis functions. No search space or point to point mapping is needed either. It is possible to achieve smooth results and handle multiple point set models at the same time. The B-spline registration will be discussed in details later in this survey. In an additional article, Frangi et al. constructed an atlas of binary volumes based on quasi-affine registration using the Normalized Mutual Information (NMI) metric [75].ASM and AAM are mostly used for segmentation purposes. Nevertheless, since the correspondence among the point sets is computed, the motion of the point set can be subsequently analyzed. If the point set is positioned on the contours (endocardium or epicardium), the derived motion will be sparse. However, the point set could be positioned on the heart as a 3D mesh to cover the inside of the myocardium in order to achieve a measure of dense motion.An Atlas can represent one object or a set of normal or abnormal objects. Multi atlas propagation and segmentation (MAPS) techniques have become popular recently in the field of medical image segmentation [76,77]. MAPS combines object intensity and object label (contour) while the intensity is used for registration and the label is used for the propagation of the contours or the prior model. Modified versions of MAPS are also proposed. MUPPS (MUltiple Path Propagation and Segmentation) uses a set of atlases as well as a set of paths of propagation similar to a multiple classifier strategy [78]. The selection of the optimal atlas and path is based on MI as the similarity criterion. In similar work, Isgum et al. [59] argued that a single atlas may not be a good representation of the whole population and proposed a multi-Atlas model that uses decision fusion to select the optimal atlas. In the first step, an affine registration was used to align the global image. Subsequently, nonrigid registration based on B-spline was performed using a gradient descent technique. MI was utilized as a measure of image matching. To cover the whole range of transformation and in order to increase the speed of the algorithm, multi-resolution and multi-grid strategies were adopted. Finally, the atlas that gives the best registration success is given an increased weight. The algorithm outperformed the single best atlas strategy and averaged shape-atlas strategy.Zhuang et al. [79] used LARM (Locally affined Registration Method) to transform each substructure (LA, LV, RA, RV and vessels) of the heart in a separate step. LARM was able to provide an initial registration of the images to align the cardiac subcomponents. In order to refine the registration, FFD registration was used in the next step. The novel aspect proposed by the authors in this step was Adaptive Control Point Status (ACPS) that turns the control point status of the object on or off based on the performance of the registration. The status of the control points was updated adaptively to guarantee that the active control points were not inactivated. The proposed technique was able to overcome the shape complexity of the heart in cardiac MR images by decomposing the problem into several smaller structures and was able to achieve a better computational speed.In order to handle different structures such as ventricles and atria more efficiently, multiple-shape model and piecewise registration methods have been proposed. Instead of a single global shape model, van Rikxoort et al. [34] used multiple shape models that act locally using a method called ALMAS (Adaptive Local Multi Atlas Segmentation). Atlas is a point set model that represents an anatomic structure. ALMAS finds the number of necessary atlases to efficiently reconstruct the cardiac model. It locally and automatically selects the most appropriate atlases ui(Si) to make the final combined atlas (S). In ALMAS, n registrations (Ti) are applied to different atlases such that:(8)S=1n∑i=1Nui(Si)The method was applied to cardiac CT images to segment the ventricles and atria and great vessels in 3D. It was shown that the multiple-shape model provides more local autonomy in the atlas. Ecabert et al. [80] developed a model-based approach for the segmentation of the four chambers and great vessels using 3D CT images. Hough transform was applied first to automatically localize the heart. ASM was utilized to construct the cardiac model from coarse to fine scales using PCA dimensionality reduction. Piecewise affine transformation was used to handle the shape variability and match the model to the objects. The shape model was adjusted by changing the degrees-of-freedom of the allowed deformations. To ensure that the mesh remains continuous in-between the chambers, a weight was assigned to each local model. The user can also manually change the continuity as well.Esther-Leung et al. [31] proposed two different methods (model-driven and edge-driven) for tracking the myocardium in echocardiography images. The approach was motivated by the fact that in echocardiography, visibility of the myocardium depends on the view. The technique relied on a local data-driven tracker using optical flow (a temporal registration technique that for the most part uses the intensity constancy assumption between corresponding pixels in successive frames [81,82]) applied to the visible parts and a global statistical model applied to the invisible parts of the myocardium. It was concluded that the shape model can handle the invisible tissue in ultrasound images as well as the missing boundaries. Another shape based tackling of drop outs in echocardiography images was described in Zhou [36]. The authors use Shape Regression Machine (SRM) as a method to overcome the fuzzy boundaries in 2D echocardiography images without using the initial delineation. The SRM uses statistics of the shape, appearance, and anatomy in the training step to construct a model. Subsequently an automatic initialization was derived using a rigid shape. The initial contour is updated using a nonlinear regressor to directly associate the nonrigid shape with the image appearance.The number of datasets in the training set should be large enough to cover different types of diseases and dysfunctions. Any undertrained shape model can theoretically lead to false results and over-fitting [83]. In the case of 3D and 4D shape modeling; very large datasets are needed, leading to the curse of dimensionality. Therefore, the extracted heart model may be unable to cover different cardiac morphometrics. Zhang et al. [61] used the manual segmentation of the first frame of the test dataset as an adjunct to the shape model to overcome the limited training dataset problem. Koikkalainen et al. [23] described several methods to artificially increase the size of the database using different techniques such as nonrigid movement and combination of Principal Component Analysis (PCA) and Finite Element Model (FEM). In a separate work, Lötjönen et al. [84] proposed several methods to generate synthetic training data to increase the size of the training dataset. Andreopoulos and Tsotsos [52] argued that ASM’s are unable to rely on a small training set to capture the full range of biological shape variability. They handled the problem of training 3D ASM through use of wavelets. Wavelets can decompose the data into several sub-bands having different amount of detail. Intuitively, wavelets can discard unnecessary details of the manually segmented boundary and keep the coarse and stable parts. The technique was performed in four steps: (1) the object was aligned to the shape model; (2) 2D wavelet was performed in two steps on the coarse band and thus leaved seven image bands; (3) the shape model was constructed in the wavelet domain based on the coefficients of the wavelet transform; (4) inverse wavelet transform was used to recover the shape in the space domain.The incorporation of temporal data can be tricky due to the different resolutions of the time dimension, higher variation of the motion, and computational expense. Extension of ASM’s temporal modeling has been performed in [52,62].One of the limitations of most image registration techniques is lack of explicit constraints to ensure that the computed transformation is invertible. Folding of the grid over itself can lead to the corruption of the neighboring structures of the model or triangular flipping [85]. Therefore, diffeomorphic techniques are of interest due to the smooth invertible transformations with smooth inverse solutions. Since diffeomorphism has been almost exclusively used in the context of ASM in the cardiac segmentation and registration field, it is categorized in this section. Diffeomorphic registration algorithms [86–88] guarantee an invertible continuous differentiable mapping between the object features in order to preserve the topology and orientation of the anatomical structures over time. The log transform of the motion field was incorporated in the shape model to conserve homeomorphism in [60] since the logarithmic transform can decrease the value of the motion. In another work, Beg et al. proposed a variational diffeomorphic model based on cardiac fiber elements in DT MRI cardiac images of postmortem biopsies [76].The differences in the anatomic variability of the heart originate from three sources: (1) subject variability due to the heart motion; (2) inter-subject variability due to the shape differences among different humans; (3) pathological variability due to the abnormal cardiac size or function. In order to overcome this problem, some authors have proposed combined inter and intra-subject atlases that considers the huge shape variation of the heart [48].The probabilistic knowledge is usually derived from a training step. This method mandates a comprehensive database, tedious human effort, and high clinical and technical expertise. The adequate size of the training set that includes different pathologies can be a huge problem. This problem can be cumbersome since the cardiac chambers can vary widely in size and motion, especially if uncommon diseases are also considered. The learned template is limited to recognize a specific group of images with similar properties and may miss others. Different training steps should be used for each echocardiography or MR imaging view in 2D techniques. Additionally, the traditional shape model is a global structure while local landmarks do not have self autonomy to fit to the local edges. ASM requires good initialization as well. If the point distribution set is large, the computational time can also be problematic in ASM [55,56].Active Appearance Models use the same platform and steps of ASM’s but include the texture (intensity variations) appearance of the object as well. The object intensity or gradient perpendicular to the boundaries is usually considered as the appearance texture. The shape data (s) and the appearance data (g) are combined to make a joint linear system as:(9)x=x¯+ϕshapeWshapeQshapecg=g¯+ϕAppearQappearcwhere ϕshapeand ϕAppearare independent eigenvectors of shape and appearance, Wshapeis a diagonal weight matrix, Qshapeand QAppearare the eigenvector matrices of the combined shape and appearance and c is the combined shape appearance parameter vector. The object data normal to the boundary contour (also known as profile) are mainly computed by interpolation of the intensity or intensity gradients in the direction of the contour normal [89–92]. It is shown that the normalization of the profile leads to more accurate results. Two methods are linear normalization using an initial offset [89] and non-linear normalization [62] to handle non-Gaussian distributions.Different object profiles can be computed using several other techniques such as Gabor filters [93], gradient strength and direction [80–83], regional features [94], color features [95] and combination of several profiles [96]. In another work, Song et al. [32] used pixel feature vector as a combination of the smoothed intensity values and the second directional derivative to construct the shape model.ASM is faster and achieves more accurate local point location than the AAM, but the AAM also models the texture. Since the internal structure of the heart is taken into account, memory problems can be a big issue especially in 3D and 4D AAM methods. Decomposing the large matrix into a smaller one is a preliminary solution. Decreasing the resolution [55,62] and sparse regional analysis of the profile [94] were proposed as well.The heart has an approximately periodic motion that is congruent in space and time. Each region of the heart moves on a more or less periodic curve called regional motion trajectory [2,3]. Motion trajectories can be used as diagnostic tools in medical imaging. The motion trajectories relevant to a region should be congruent in time and make an almost closed path. There are several strategies to make the motion smooth such as shape-motion models, Kalman filters, and Markovian systems. Motion prior is a model that can simulate the spatial and temporal changes of the displacements by taking the motion pattern of the cardiac cycle into account as an additional constraint. Several papers that have considered motion models are reviewed in this section.Dydenco et al. [66] applied a level set algorithm which made use of shape and motion prior, for both segmentation and tracking of echocardiographic images. The method is based on three steps: (1) the trained shape is aligned to the image using a rigid registration technique; (2) the aligned shape is used as an initial contour for the level set method. The level set uses the data from the learned shape prior and the statistics of the inside and outside of the evolving curve to update the endocardial and epicardial borders; (3) the evolution of the level set is used to train the motion prior.Paragios [65] embedded a motion prior and a shape prior in a level set function. The motion prior minimized the sum of absolute difference of the corresponding images in the time dimension. The prior shape was based on distances of the point set to a model. The distribution of the distances was assumed to be Gaussian. Punithakumar et al. [67] proposed to minimize an energy function consisting of the distance of the transformed shape to a prior shape (a trained shape) as the geometric constraint. A graph cut distribution method was utilized in the minimization of the energy function and delineation of the LV cavity in cardiac MR images. Since a single Markovian cannot handle the complex heart motion, a set of weighted models were combined together to handle the different types of motion of the heart. The multiple model system was able to automatically switch between the models and identify the appropriate multiple model that matches the cardiac motion based on a training process. Finally the technique was applied to the cine MR SAX images for the segmentation of endocardial shapes as well as to define the trajectories in time through different frames. Myronenco and Song [70] developed the Coherent Point Drift (CPD) technique, constraining the motion of the point set in the temporal direction for both rigid and nonrigid point set registration. The point set distribution was modeled with a Gaussian Mixture Model (GMM). The GMM centroids were updated coherently in a global pattern using maximum likelihood to preserve the topological structure of the point sets. The algorithm was used for both rigid and non-rigid applications. In the nonrigid case, the motion coherence constraint was added based on regularization of the displacement fields. The purpose of regularization is to increase the motion smoothness. The motion is defined to be smoother if it oscillates less which means that it has less energy at high frequencies. The method was applied to 3D echo images of the LV in order to compute displacements.Deformable models, or active contours (also known as snakes) technique which was first described by Kass et al. [97], is a popular physically inspired, model-driven technique based on parametric curves, surfaces or volumes, that deform under internal and external forces. The external energy forces the contour to move toward the image data (such as an edge). The internal energy controls the contour based on a regularizing smoothness constraint. Additional energy terms can constrain the deformable model to achieve better results. The general deformable model energy function can be written as:(10)E=Eext+EintExternal energy is usually defined as:(11)Eext=-‖∇|Gσ(x,y)∗I(x,y)|‖2where Gσ(x,y) is a two dimensional Gaussian function with standard deviation σ and I(x,y) is the intensity at point v(s)=[x(s),y(s)]. Internal energy is defined as(12)Eint=12(α(s)‖vs(s)‖2+β(s)‖vss(s)‖2)where α and β are weights, the first order term (membrane term: ‖vs(s)‖2) defines the stretching and the second order term (thin-plate term: ‖vss(s)‖2) defines the curvature.This energy function was minimized within a variational energy minimization. The numerical optimization was improved by Amini et al. [98] who cast the optimization within a dynamic programming framework and introduced the concept of soft and hard constraints. Further improvements to this framework was proposed by Klein et al. who introduced DP B-spline snakes [99].Some studies have incorporated other terms such as shape prior and physical constraints as will be discussed later. Deformable models have been widely used for the segmentation and tracking of cardiac images in both MRI and echocardiographic images.Since the edge map of the image can be misleading due to the noise and missing data, GVF (gradient Vector Flow) was proposed as a new external energy function to handle the edge function smoothly. GVF is derived based on the minimization of the energy function proposed in Eq. (13) where v is the Gradient Vector Flow, μ is the smoothing weight, ∇I is the image gradient, and ‖∇I2‖ penalizes the edge information [100].(13)EGVF=∫∫μ(‖v‖2)+‖∇I2‖·‖v-∇I‖2Level-sets, first introduced by Osher and Sethian [101], represents an implicit function which deforms based on regional intensity or edge-based feature and is able to develop topological changes. The initial contour at time zero (C0) corresponds to the zero level set of the function ϕ:(14)C0=(x,y)|ϕ(x,y,0)=0If we represent a continuous speed function as F then the generalized level set equation dynamics can be parameterized as:(15)ϕt+F|∇φ|=0where F represents the speed function for the curve evolution. The speed function depends on internal properties such as geometry (e.g. curvature) of the interface and external properties such as image gradient. Given an initial contour (or contours), an implicit function is defined and deformed at each pixel where the zero-level set determines the actual position of the curve(s) as a function of time. Level set approaches are stable but are computationally costly. Deformable models are mostly used for segmentation tasks. However, a measure of cardiac motion can be calculated by computing the displacements of the contour or the mesh.Table 2 describes the related articles using this class of techniques [102–123]. Angelini et al. [102] proposed a level set technique to segment Ultrasound echocardiography images. It is beneficial to describe the method utilized in this paper, since it was based on Chan and Vese [103], which is a classical level set algorithm that can be utilized for other purposes as well. The authors minimized an energy function that contained area, length, and intensity variations inside and outside a contour (the image is considered piecewise smooth inside and outside the contour) such that:(16)E=αL(contour)+βV(insideofcontour)+γ∫Ω|I-c0|2H(ϕ)dΩ+ρ∫Ω|I-c1|2(1-H(φ))dΩwhere α,β,γ,ρ are the weighting parameters, I is the intensity, c0 and c1 represent a fixed intensity level that represent the mean distribution of the intensity inside and outside the curve. H(ϕ) is the Heaviside function defined as:(17)H(u)=1u⩾00u<0The length of the contour can be written as:(18)L(contour)=∫Ω|∇H(ϕ)|dΩ=∫Ω|∇(ϕ)|δ(ϕ)dΩwhere δ(ϕ) is the Dirac function and the area inside the contour can be written as:(19)A(insideofcontour)=∫Ω|H(φ)|dΩThe authors extended this method to delineate the endocardium of both LV and RV cavities.Sarti et al. [104] used the Rayleigh distribution of the speckle statistics to segment cardiac US images in a level set framework. The Rayleigh distribution is defined as:(20)p(I)Raileigh=I(x,y)/σ2·exp-I(x,y)2/2σ2where σ is the standard deviation. The authors assumed that the intensity distribution of the tissue inside and outside the endocardial curve is similar through the cardiac frames since they represent the texture of the blood and the myocardium.Barbosa et al. [119] developed a level set technique based on the global intensity inside and outside of the object boundaries and an additional local regional intensity term. The energy functional was handled in spherical coordinates to match the anatomic shape of the LV. The level-set was evolved based on B-spline control points to increase the smoothness of the curve evolution. It was shown that the algorithm is able to effectively segment the endocardium in echocardiography images. Wolf et al. [105] used an energy function consisting of region-based information of several landmarks in a deformable model framework combined with morphology operators. The algorithm was used in order to segment the endocardium in 2D echocardiography images. These aforementioned deformable methods are mostly based on the intensity information that may cause errors. Additional techniques and constraints are considered to resolve this problem. Huang et al. incorporated the shape and interior texture into the variational deformable model framework using a technique named metamorph [122]. The object texture is modeled using a nonparametric kernel-based approximation of the intensity probability density function. The deformations that the model is modeled using cubic B-spline based Free Form Deformations (Section 3.4). The model deforms under the force of boundary and region based functions. It is shown that the proposed metamorph model when applied to cine MRI images can converge to a reasonable solution even when initialized far away from the original object boundaries.Kaus et al. [123] utilized a triangulated surface mesh that deforms in response to different energy forces. The shape model was embedded into the deformable energy function by maximizing the similarity of the distribution of the object mesh vertices. The mesh surface was iteratively scaled and rotated based on a prior as well as internal and external energy terms.Zagrodsky et al. [114] utilized a deformable mesh technique based on internal and external energies in order to segment 3D echocardiography images. Montagnat et al. [115] proposed a 4D deformable mesh driven by Lagrangian dynamics to extract the epicardium and endocardium in Cine MR images. A simple motion prior derived from the averaged contour trajectories was utilized to compute the boundaries more accurately. Lin et al. [110] used feature extraction using Gabor filters. Subsequently, a Robust Point Matching (RPM) method was applied to the grid tag intersections in different image frames to build a one-to-one correspondence and to compute the motion. Rougon et al. [120] utilized “generalized information measure” a parameter derived from NMI to compute the motion in tagged MRI. The authors made use of novel information measures as a superset of both NMI and MI. Kermani et al. [121] used a combination of elasticity and distance to a learned mesh model in the context of Active Mesh Model (AMM) to segment SAX cine MR images.Deformable models can be customized to match particular shapes by changing the parameters of energy functions. There is no need for training the model. They are able to generate smoothed closed parametric or implicit curves or surfaces from the images. Finally, it is possible to integrate physical and shape prior constraints in developed techniques.The disadvantages are inaccuracy in handling noisy images, and inability to cope with specific protrusions/bifurcations. The basic snake energy alone is not able to segment some objects and therefore modifications and extensions to the energy function are crucial to handle the problems. They are also dependent on the parameters as well as contour initialization. The disadvantage of level set techniques is the vital importance of appropriate speed function to advance the level set function.This group of techniques relies on the mechanical, physical, or physiological properties of the heart such as FEM, incompressibility of the myocardium, and physical or elasticity laws as constraints for segmentation and motion estimation of cardiac images (Table 3[124–145]).The cardiac tissue can be divided into small finite elements that move in accordance to the mechanical laws. As a basic model, Hook’s law of spring (F=−k⋅x;where F is the force, x is the displacement, and k is the spring constant) can be extended for elastic materials as:(21)σ=E·εwhere σ is the stress (the force applied to the element), ɛ is strain (the element deformation with respect to the original length, Section 4.1) and E is the elastic or Young’s modulus. For many materials, Young’s modulus is approximately constant over a wide range of strains. These materials are called linear elastic. Heart tissue is non-linear and not linear elastic. This basic model however can be modified using more complex models such as a hyperelastic model that simulates a nonlinear relationship between the stress and strain. Additionally, the stress–strain relationship is not the same in different cardiac directions (anisotropic) due to the fiber orientation of the cardiac tissue [146,147].Isotropic models consider the heart as a homogeneous medium. Fan et al. [133] incorporated the regional force of the myocardium by including Newtonian dynamics as an additional term in the snake framework. The acceleration of each element of the cardiac boundary is simulated by the second derivative of the displacement as:(22)∑Fext(S,t)-Fint(S,t)=md2(S,t)dt2where F represents the snake energies, S is the cardiac boundary element at time t and m represents the element mass. The technique was applied to canine 3D US echocardiography images in order to segment the endocardium. Boundary Element Method (BEM) proposed by Yan et al. [137] was a technique to place the B-spline control points on the boundaries to estimate the dense motion fields using GRPM. GRPM was applied to the LV point set based on feature points extracted based on endocardial surface curvatures. 3D B-spline non rigid registration was used to extract the correspondence. Since the structure of the heart is the same in all modalities, the method was applied to analyze the cardiac function from Ultrasound and cine MRI. Remme et al. [138] utilized a set of fiducial markers selected by the user, in an FEM model distributed over the cardiac geometry to compute the motion of the LV. The motion of the fiducial markers was used in order to prescribe deformations for the model. The method was applied to tagged MR images to segment the epicardium and compute the motion. Additionally, it was hypothesized that the algorithm can be extended to analyze other modalities such as cardiac CT and echocardiography. Shi et al. [139] combined the data from two different sources: cine contour data and mid-wall phase contrast. The combined information was used to extract the displacements based on an FEM framework.The myocardium is believed to be nearly incompressible during systole and diastole due to the high water content. Myocardial volume changes have been quantified during systole and diastole in several studies such as Hamilton and Rompf [148], Bowman et al. [149], and Hoffman et al. [150,151]. It is believed that the myocardial volume (MV) is relatively constant during a cardiac cycle, varying about 3.5–5%. The conservation of volume of the myocardium has been utilized as an additional term in several articles. The small compressibility of the heart is usually attributed to the compressible blood vessel lumens and the difference in the total volume of blood in the myocardium depending on the phase of the cardiac cycle. Bistoquet et al. [124] utilized Normalized Mutual Information (NMI) in addition to the incompressibility of the myocardium using a curvilinear coordinate system which is based on the mid-wall surface of the LV wall. The cardiac contour was manually segmented in the first frame of cine MR images. To achieve the new coordinate system, the authors reparameterized each point inside the myocardium with respect to the mid-wall hyper-plane of the heart by using a sign distance equation normal to the mid-wall surface. Subsequently, NMI was used to update the control points located on the cardiac contour and the incompressibility criterion was incorporated in the contour evolution framework as a prior. In another work, the authors argued that the incompressibility condition has a failure rate of about 5% and proposed “nearly incompressible” model that allows a small change in the myocardial volume by adding a small offset to the above-mentioned framework [125].So far, we have only described contributions were the myocardial incompressibility has been simulated deterministically. Statistical simulation of the incompressibility has also been used. Zhu et al. [127] incorporate the speckle statistics and myocardial volume incompressibility using probability models. The compressibility (ρ) is statistically modeled as a Gaussian (G(V0,σ)) such that:(23)ρ(ϕin,ϕout)=12πσexp-(V-V0)22σ2where the volume of space between the endocardium (ϕin) and epicardium (ϕout) is the myocardial volume andσ0=1120V0. This simulation allowed about 5% variation in the myocardial volume. Speckle statistics can be initially classified as pre-Rayleigh, Rayleigh, and post-Rayleigh, depending on the density and spatial distribution of the scatterers. The most popular model considers a large number of random scatterers which produces Rayleigh distribution leading to full speckle formation. Pre-Rayleigh pattern occurs when the number of scatters is not large enough. Post-Rayleigh pattern occurs when the scatterers are not randomly distributed but have a general periodic pattern due to the tissue structure. Other statistical models that can handle the three different situations have been proposed such as Nakagami and Rician distribution. In the aforementioned article, the tissue statistics are separately modeled using Nakagami distribution in three different media (l=3): 1. Blood pool, 2. Myocardium, 3. Peripheral tissue. The data terms are defined as:(24)logp(I|ϕin,ϕout)=∑l=13log(pl(I))·dxZhu et al. then combine the speckle statistical model and the incompressibility model in a level set framework in order to segment the cardiac endocardium and epicardium in 3D echocardiography images.Myocardial fibers are tangential at the endocardium and epicardium, and at mid-wall follow a right handed helical geometry. The heart contracts in the direction of the cardiac fibers and therefore taking the mechanics of cardiac fibers and fiber directions into account may lead to more accurate results. Diffusion Tensor (DT) MRI is able to define the myocardial fiber directions. Normal canine DTMRI data is available online and may be included as part of the myocardial model (www.ccbm.jhu.edu/research/DTMRIDS.php). However the fiber directions should be registered on the cardiac model. Furthermore, it is known that fiber directions become disorganized and change during disease.Fiber direction models can be simplified or complex. Bachner-Hinenzon et al. [130] divided the myocardial tissue into three inner, mid and outer sections. Wavelet transform was applied to each section separately in order to model the different fiber orientation in the cardiac wall. Papademetris et al. [142,143] modeled the LV myocardium as a linear elastic structure defined by mechanical parameters such as Poisson’s ratio and Young’s modulus. To simulate the anisotropic propagation of force through the myocardial wall, the continuous myocardial fiber twisting and orientation were modeled using FEM. Sermesant et al. [134] used a FEM biomechanical deformable model integrating the internal and external energy as well as the fiber direction for segmentation and motion estimation from cine MR cardiac images. Internal energy was modeled based on the linear elasticity of a Tensor-Mass model. Finite Element Method was handled based on linear tetrahedral elements, mass-lumping model, and Newtonian differential equations using an explicit time integration scheme. Fiber directions were obtained according to the DTI images in order to orient the elemental directions. External energy force directions were computed on the surface nodes of the model as vectors orthogonal to the surface of each element and the external force values were made proportional to distance to the model point. The algorithm was used to segment the LV epicardium and endocardium and RV in SPECT and cine MR images. Additionally, since the correspondence among the cardiac elements is known, a measure of motion may be derived as well. Verres et al. and Phatak et al. [116,117] used hyperelastic warping in addition to the fiber direction information in a deformable framework. The epicardial and endocardial surfaces of the end diastolic MR images were first segmented by a user. The triangulated myocardial surfaces were utilized as the basic structure in a FEM preprocessing software in order to build a hexahedral volume. A transversely isotropic hyperelastic model was utilized to simulate the myocardium. The fiber directions were estimated using three different fiber direction models for different cardiac segments as: (1) Fiber direction varying from −90° at the epicardium to+90° at the endocardium for the basal level, (2) helical pattern for the inner and outer layers: The inner layer varies from +90° to 0° from the basal level to the apical level and the outer layer varied from +90° to 0° from the basal level to the apical level, and (3) fiber directions at the basal septal and apical levels are aligned with the measurements from DTMRI data from dog and human cadaver hearts. Hu et al. [132] proposed a biventricular model for LV and RV that includes the fiber direction of the myocardium as well. Subsequently, the elements of FEM were distributed on the model to simulate the stress–strain relationship. Expectation Maximization was used to solve the model and compute the cardiac contours and motion from tagged MR images.The cardiac periodic motion originates from the electrophysiological activity of the heart. The main trigger of the cardiac electrical activity is located in the sinus node. The sinus node generates the leading depolarization wave that propagates to the atria and ventricles. The electrical wave causes the myocardial fibers to contract and produces the mechanical contraction of the heart. Wong et al. [135] used a combination of electrical wave propagation model and electromechanical coupling model in addition to the biomechanical heart model to extract the boundaries in 3D cine MR images. The authors proposed a mesh-free framework to solve for this integrated model. Every node was given an influence domain and the value of each point of the model was computed by summing the effect of the influence regions. Finally, a least square technique was applied to solve for the integrated model.Biophysical models have been widely used for the registration and motion detection of the cardiac images. The physical priors such as incompressibility or fiber direction can be useful in determining cardiac displacements. Biophysical models have the advantage of providing additional constraints based on the physical properties of the cardiac tissue. Additionally, training is not necessary. However, the physical laws are not completely true; as an instance the cardiac tissue is neither linear elastic nor hyper-elastic.This class of techniques attempts to extract the non-rigid motion of anatomical objects using a set of basis function such as splines that have inherent smoothness properties (Table 4[152–174]). B-spline based representation of the tag planes in 3D were used to track the myocardial motion in Amini et al. [152,153]. Redeva et al. [154] proposed an approach to nonrigid registration of cardiac tagged MRI volumes with volumetric B-splines. The approach was extended to 4D in [155]. The smooth nature of the B-spline basis functions lead to more congruent results. Rueckert et al. [175] and Chandrashekara et al. [159] used a two-step registration technique: 1. Global registration using affine registration, 2. Local registration using a spline based similarity matching. The similarity function can be different measures such as NMI and SSD. The advantage of B-spline based Free Form Deformation is that it offers the capability to be used as a multimodal algorithm to provide dense and pixel-wise results.The basic idea of B-spline FFD is to transform an object by manipulating an underlying spline-based mesh of control points Φ.The resulting transformation defines the shape of the 3D object. The energy term that leads the motion of the control points usually consists of the similarity function and a spatial velocity smoothness constraint but can be extended to any functional.(25)T(x,y,z)=∑l=03∑m=03∑n=03Bl(u)Bm(u)Bn(u)Φi+l,j+m,k+nwhere T is the transformation and(26)i=⌊x/nx⌋-1,j=⌊y/ny⌋-1,k=⌊z/nz⌋-1u=x/nx-⌊x/nx⌋,v=y/ny-⌊y/ny⌋,w=z/nz-⌊z/nz⌋where nx, nxand nxdefine the number of control points in x, y and z directions. Blis the lth basis function for the uniform non-rational case is defined below for order up to cubic:(27)B0(u)=(1-u)3/6,B1(u)=(3u3-6u2+4)/6,B2(u)=(-3u3+3u2+3u+1)/6,B3(u)=u3/6A similar 3D B-spline method was used in Deng and Denney [158]. The authors apply the 3D B-spline basis function in the cylindrical coordinate system. The cylindrical axes are adopted to fit to the LV contour to simulate the anatomy of the heart during motion estimation. The displacement smoothness is applied to the circumferential, radial, and longitudinal directions as an additional energy term. Sundar et al. [161] define a cardiac attribute vector at each voxel as a feature that can be tracked during the cardiac motion. The cardiac attribute reflects the underlying cardiac structure at different scales. Each attribute vector includes the image intensity, image boundary, and geometric moment invariants (GMIs). GMI is computed at different image scales as thirteen rotation invariants that are calculated from the zero-order, second-order, and third-order 3D regular moments. Finally, the attributes are registered using cubic B-spline registration. Tustison and Amini [157] and Lin et al. [160] transform the Cartesian grid of control points in B-spline nonrigid registration to a cylindrical lattice. This can be considered an anatomical modification of the Cartesian grid to achieve better results. Declerck et al. [176] used a mathematical framework for non-rigid registration of SPECT images by fitting planispheric hyper-planes to epicardium and endocardium. The correspondence between the cardiac contours is computed using ICP. The advantage of using non-Cartesian coordinates is the symmetric structure of the cardiac model which resembles the circular or cylindrical shape of the heart as well. The disadvantages of the non-Cartesian system are higher computation and the possibility of additional error during the Cartesian-polar conversion especially near the poles of the model.Metz et al. [169] utilize a 4D (3D+time) free-form B-spline deformation model based on a similarity metric that minimizes the intensity variations over time. A public domain software (elastix) was used for the elastic registration. The proposed method was applied to both heart and lung 3D CT images. De Craene et al. propose Temporal Diffeomorphic Free Form Deformation (TDFFD) by incorporating image similarity according to the sum of squared differences, incompressibility, and a regularization term in a 4D B-spline framework. Thin-plate-spline (TPS) is subsequently used to warp the initial mesh towards the refined control points in the correspondence step. The algorithm is applied to segment the 3D human echocardiography images. In [156,157] a biventricular cardiac model is generated in both cylindrical-Cartesian and cylindrical-polar coordinates to track the heart motion by using tag positions in LAX and SAX MR images. Tag lines are parameterized based on NURBS (Non-Uniform Rational B-Spline) basis functions. Chen and Guan [168] also implemented a NURBS based model in a cylindrical coordinate system to segment the LV contour in cine MR images. A volumetric NURBS object can be formulated as:(28)S(x,y,z)=∑l=03∑m=03∑n=03Bl(u)Bm(u)Bn(u)ψl,m,nΦl,m,n∑l=03∑m=03∑n=03Bl(u)Bm(u)Bn(u)ψl,m,nwhere ψl,m,nis the assigned weight of each control point. NURBS registration is an extension of the B-spline registration using additional weights. NURBS has an extra degree of freedom to adopt the regional weight of the control points. It can handle sharp surfaces by increasing the weight of the attributed control points. Suhling et al. [173] combine rigid registration in the optical flow framework in order to detect the motion of 2D echocardiography images. B-spline moments were applied to echo images to achieve invariance to the translation and rotation. The algorithm is applied to the B-spline moments of the image instead of the image intensity in a coarse to fine strategy. The algorithm was validated using open chested dogs after ligation of a coronary artery. Additional validations are based on simulation and phantom images.Ellen et al. used elastic registration on 3D B-mode echocardiography images to extract the motion and strain values. The method was validated using simulated and real echo images [167]. Peyrat et al. [172] decoupled the image registration in CT images into two components: 4D spatial registration that dealt with the registration of the cardiac physical points; and 4D temporal registration that dealt with the physiologic (systolic/diastolic) alignment of the frames. The second component handled the trajectory modeling in time over the cardiac cycle. The spatial registration was performed initially and thereafter the temporal registration was computed. Diffeomorphic Demons [177] were used as the registration technique. Demon technique uses a diffusion-like model to align two images minimizing the intensity differences between the model elements.The advantages of the basis function based techniques (such as spline) are their inherent smoothness and their ability to reduction of the computation to control points. Additionally no training is needed and the same framework can be extended for other applications. The disadvantages of such a framework are the dependence of the results on the nature of the basis functions, number of control points, as well as their position. The optimization technique may not lead to the best results if the control points do not properly cover the complex portions of the shape, e.g., with intrusions and protrusions. Table 5summarizes the advantages and disadvantages of each technique.Manual tracking: Manual tracking of the markers has been utilized for the validation of motion detection algorithms. However manual validation is trickier in registration with respect to segmentation. Manual landmark detection is cumbersome in 3D and marker displacements do not represent sub-pixel motion. Finally prominent landmarks are not a good sample of the general tissue displacement because they usually represent edges, corners or higher amount of contrast.Simulation and phantoms: Several authors [158,163,167] have tried to model the medical imaging techniques and generate a set of simulated series. The importance of the simulator is to provide a set of images for which the ground truth is known. The drawback of the simulated images is that it is not possible to perfectly model the imaging physics and acquisition. Phantoms [136] can provide realistic images but it is difficult to have a dense ground truth for phantom images.Comparison to the other modalities: Several other validation techniques have been used for cardiac registration such as comparison with Tagged MR [124,125] and TDI [165]. Other modalities provide an independent and objective validation of the algorithms. However, pixel to pixel inter-modality comparison may need registration because the two images will not fully overlap on each other. Comparison of different segments of the heart instead of pixel to pixel comparison can overcome this problem.Implanted markers and sensors: Comparison of the implanted markers is an independent though invasive validation. Several authors have used inserted landmarks so far. Implanting sensors such as sonomicrometry is another approach to validate the cardiac motion. Sonomicrometry is the application of microcrystals (small piezoelectric with the size of a few millimeters) embedded on the myocardial surface. Ultrasound pulse is utilized to measure the distance between the microcrystals based on the speed of sound. An electric pulse sent to each crystal will be transformed into sound wave, which passes through the medium to the other crystal and is converted into an electric signal again. The distance between the crystals can be calculated from this time of flight of the received pulses. SM can provide independent and accurate measurements but it is not possible to use the ultrasonic microcrystals simultaneously with the echocardiography machine due to the interaction of the ultrasonic pulses. Therefore the measurements should be performed separately which may cause unreliability. In general implanted markers and sensors are invasive and the local injury around the implanted sensor can change the natural motion. Sonomicrometry measurements have been used in [128].Validation of the computed EF: Cardiac segmentation has been usually validated using manual delineation of the in vivo images. Since EF is calculated using the segmentation results, comparison of the computed EF with the EF derived using other modalities can be helpful. Ma et al. compared the LV mass extracted based on the echocardiography segmentation with the LV mass derived from cine MRI data [40]. Nuclear medicine techniques can provide very accurate EF measures [2,3]. Sanchez-Ortis et al. have compared the EF extracted by segmentation to the EF derived from SPECT [29].In-vivo validations: The in vivo validations are mostly performed on humans, open chest dogs (before and after synthetic infarction) and mouse. Synthetic infarction is able to evaluate the motion detection techniques in analyzing the abnormal tissue motion before and after the pathology.Some techniques are multi-modal and can be extended to both cine MR and echocardiography modalities [110,137,142,143,138]. Delineation of the endocardium is a common output in all the segmentation articles. Epicardium is also segmented in some papers. As mentioned before, errors are usually larger for the epicardium and RV contours. Some papers have reported segmenting all the ventricles and atria; see for example, Lötjönen et al. [84].Strain is an index of deformation or lengthening or shortening of an object. Strain and strain rate imaging allow the measurement of regional myocardial deformation to assess specific local and global functions. Strain measures deformation while strain rate is the rate of the change of the deformation. Both of these measures have been shown to provide complementary information about the clinical assessment of cardiac function, Strain (s) is defined in one dimension as:(29)S=12ll02-1where l and l0 are secondary and original length of a line element in the material and S is the final measured strain. Strain rate (SR) is defined as the velocity of strain changes such that:(30)SR=Strain(t2)-Strain(t1)(t2-t1)If I is the identity matrix, the Lagrangian strain tensor can be derived as:(31)E=12(FTF-I)where the elements of the deformation gradient tensor, F, are:(32)F=∂x∂X∂x∂Y∂x∂Z∂y∂X∂y∂Y∂y∂Z∂z∂X∂z∂Y∂z∂ZWhile x=X+V(X), X represents the spatial coordinates in the undeformed coordinates, and V(X) is the motion vector at the corresponding spatial location.The Eulerian strain tensor, G, is:(33)G=12I-(FTF)-1Diagonalization of the strain tensors will yield principal strain values and directions that describe the maximum and minimum values and directions for the deformation [157].Regional analysis is usually performed on 17 American Heart Association (AHA) prescribed segments of the heart. Fig. 7shows the different segments. The acronyms stand for antero-septal (AS), anterior (A), lateral (L), posterior (P), inferior (I), and infero-septal (IS). For a review of topics related to determination of strain from cardiac images, the reader is referred to [156,157,178,179].Comparison of the validations of different studies is difficult and intractable due to the different data sets, imaging views, segmental analysis, and evaluation measures. Some papers have provided local segmental analysis of the 17 segments while other results are reported as global functional parameters EF% error or LV mass error. Clinical validations using sensitivity, specificity, and p-value are utilized as well [61]. Occasionally the reports are based on some of the cardiac segments. However, in general, the surface distance errors such as Point to surface distance (p2s) or MAD (Mean Absolute Difference) are mostly utilized. These measures are usually in the range of 1–3mm for 2D/3D CT, MR, and echocardiography images. Zhu et al. [109] have presented MAD errors ranging from 1.11 to 1.33mm for epicardium and 0.47 to 0.82mm for endocardium depending on the cardiac segment. The apical results are usually the worst while the mid LV results are the best as intuitively expected. The error is higher for the RV and epicardium with respect to endocardium [61,109]. Table 6categorizes the articles that utilized the same evaluation metrics. However, the numerical values are dependent on the database and the way the data is used for the validation. Some studies discarded the apical slices during the validation because it is cumbersome to even manually delineate the apical segments.Thanks to the advances in image acquisition hardware and instrumentation, the cardiac imaging field is seeing rapid progress and expansion. 2D cardiac imaging suffers from out-of-plane error and limited reliability in obtaining appropriate cardiac planes in sequential acquisitions. 3D imaging techniques such as 3D echocardiography, MRI, SPECT, and cardiac CT are likely to partly replace the routine use of 2D imaging for accurate measurement of cardiac size, function, perfusion, and metabolism.Increased resolution of the 3D echocardiography images has led to better analysis of the local and global LV function. With developments in the multi-detector row CT technologies (more detector rows, smaller detectors, etc.), have provided the capability for acquisition of high quality 4D cardiac Images, preserving the fine structural details inside the endocardium. The unseen structures, such as trabeculation and cords can be visualized and used by the clinicians [180]. With MRI, better gradient hardware and RF coil technologies have resulted in high quality cardiac imaging with better SNR and resolution, and at a higher speed. Due to larger size of the resulting imaging data, for all modalities, computer aided analysis methods are increasingly mandated.Grand challenges in the field of medical image processing are held as a part of MICCAI (since 2009) and ISBI conferences (since 2012). They are able to produce unbiased validation of different algorithms based on the same data set, thus eliminating the confounding character of patient type, vendor, and validation measures. However, the participant research groups are typically limited to about 10 or less and therefore, most techniques are not tested. Additionally, only a few challenges provide the data for validation and comparison in the future publications. To date, three grand challenges have taken place as a part of MICCAI 2009, 2011 and 2012.1.MICCAI 2009, Cardiac MR Left Ventricle Segmentation Challenge: http://smial.sri.utoronto.ca/LV_Challenge/, This challenge has provided the data for future experiments and maybe downloaded. The top ranked papers in this challenge were Lu et al. [181] and Huang et al. [182]. Both papers include a preprocessing and post processing stages similar to bottom-up techniques. Lu et al.’s technique [155] proposed using an automatic roundness measure that locates the Left Ventricle. Subsequently the epicardial contour was transformed from Cartesian to polar coordinates. The final contour was smoothed using the Fourier transform. This method does not need user interaction and provides the endocardial and epicardial contours as well as the Papillary Muscle and trabeculation contours. Huang et al. [182] utilized various features of cine MR images and combined multiple image processing bottom-up methods such as thresholding, edge detection, and morphology operators in order to automatically segment the LV borders. A deformable model was applied subsequently to the coarsely processes images.MICCAI 2011, The STACOM 2011 – 4D LV Segmentation Challenge: based on 100 cases for training and 100 cases for testing. Data was subsequently removed and is not available for future use. Website: http://www.cardiacatlas.org/web/guest/stacom2011 The MICCAI 2011 challenge was extended to cardiac registration of Cine MR, 3D echocardiography and EP studies and is based on about 16 MR and 16 3D echocardiography data: The STACOM 2011 – 4D LV Segmentation/Registration/EP Simulation Challenge: (http://www.cardiacatlas.org/web/guest/stacom2011). The results of the challenge are not yet compared.STACOM 2012 considered registration and segmentation methods based on simulation, phantom and patient data. The results are not yet available to the public. http://www.miccai.org/news/miccai-2012-workshops-and-challenges-call-papersAnother challenge was devoted to Coronary Artery Stenosis Detection and Quantification Evaluation Framework, Website: http://coronary.bigr.nl/stenoses/1.euHeartDB is a recent consortium of 16 different research institutes from six countries in Europe organized to improve the diagnosis of cardiac diseases. The Euroheart database provides a publicly accessible database to upload and download geometrical models and software.The cardiac Atlas project: http://www.cardiacatlas.org.Available datasets and software:1.York University cine MR dataset including the manual segmentation of the endocardial and epicardial contours: http://www.cse.yorku.ca/∼mridataset/.Stegmann 2D data base: 14 set of annotated 2D Cardiac cine MRI available at http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=500.Yale echocardiography atlas: http://www.yale.edu/imaging.CCBM available models/software/dataset: http://www.ccbm.jhu.edu/software/index.php.Graphical Interface for Medical Image Analysis and Simulation: Available software developed in C for medical image analysis applications, www.gimias.org.SEGMENT: an open source software for the segmentation of MR images: http://medviso.com/products/segment/.RV growth model: An open source diffeomorphic model for RV growth in children based on Matlab+data: http://www-sop.inria.fr/asclepios/projects/Health-e-Child/ShapeAnalysis/index.php.Several heart models such as mean atlas, mean fiber, and tetrahedral mesh: http://team.inria.fr/asclepios/data/.An open source code based on several algorithms such as locally affine registration method (LARM), spatially encoded mutual information (SEMI), as well as other image/vector field processing tools. (http://www.cs.ucl.ac.uk/staff/x.zhuang/zxhproj/index.html).Several open source codes for rigid, affine, and nonlinear registration: http://cmic.cs.ucl.ac.uk/home/software/.ITK-SNAP: an open source extension of ITK for segmentation of medical images, http://www.itksnap.org/pmwiki/pmwiki.php.

@&#CONCLUSIONS@&#
This article presented a review summary of the shape modeling applications to cardiac image analysis in MRI, CT, echocardiography, PET and SPECT. The main classes surveyed were statistical models, deformable models/level set, biophysical models, and non-rigid registration techniques using basis function methods. The article covered image analysis of cardiac images published in journals within the last 10years, classified in a number of tables based on various properties such as method, modality, and validation techniques. Active shape and appearance models are widely used for cardiac segmentation and registration. They are independent of the intensity and can overcome confounding factors such as the Papillary Muscle and contour fuzziness, especially in apical and basal slices as well as echocardiography images. However, they are dependent on an offline and sometimes difficult training stage. Level set and deformable models do not need training and can adjust to fit different shapes. However, dependency on the initial contour and parameters can be considered a drawback. Physical constraints such as incompressibility of the myocardium, Newton law, and FEM have been used as additional terms in this category. Basis functions have been used as a technique to model the volumes for cardiac segmentation and registration as well. Validation of methods have primarily involved manual delineation and comparison with the other modalities.