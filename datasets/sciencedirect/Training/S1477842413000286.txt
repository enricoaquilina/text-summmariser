@&#MAIN-TITLE@&#
Just-in-time value specialization

@&#HIGHLIGHTS@&#
Most of the JavaScript functions are called with same arguments.We specialize code that the JIT produces, given the arguments of functions.We have validated our approach in the industry-quality Firefox browser.We speed up programs by 5%, compared to original Firefox.

@&#KEYPHRASES@&#
Just-in-time compilation,JavaScript,Speculation,

@&#ABSTRACT@&#
JavaScript emerges today as one of the most important programming languages for the development of client-side web applications. Therefore, it is essential that browsers be able to execute JavaScript programs efficiently. However, the dynamic nature of this programming language makes it very challenging to achieve this much needed efficiency. In this paper we propose parameter-based value specialization as a way to improve the quality of the code produced by JIT engines. We have empirically observed that almost 60% of the JavaScript functions found in the world's 100 most popular websites are called only once, or are called with the same parameters. Capitalizing on this observation, we adapt a number of classic compiler optimizations to specialize code based on the runtime values of function's actual parameters. We have implemented the techniques proposed in this paper in IonMonkey, an industrial quality JavaScript JIT compiler developed at the Mozilla Foundation. Our experiments, run across three popular JavaScript benchmarks, SunSpider, V8 and Kraken, show that, in spite of its highly speculative nature, our optimization pays for itself. As an example, we have been able to speed up V8 by 4.83%, and to reduce the size of its generated native code by 18.84%.

@&#INTRODUCTION@&#
JavaScript is presently the most important programming language used in the development of client-side web applications [1]. If in the past only very simple programs would be written in this language, today the reality is different. JavaScript is ubiquitously employed in programs ranging from simple form validation routines to applications as complex as Google's Gmail. Furthermore, JavaScript is also used as the target intermediate representation of frameworks such as the Google Web Toolkit. Thus, it fills the role of an assembly language of the Internet. Given that every browser of notice has a way to run JavaScript programs, it is not surprising that industry and academia put considerable effort in the creation of efficient execution environments for this programming language.However, executing JavaScript programs efficiently is not an easy task. JavaScript is a very dynamic programming language: it is dynamically typed, it provides an eval function that loads and runs strings as code, and its programs tend to use the heap heavily. This dynamic nature makes it very difficult for a static compiler to predict how a JavaScript program will behave at runtime. In addition to these difficulties, JavaScript programs are usually distributed in source code format, to ensure portability across different computer architectures. Thus, compilation time generally has impact on the user experience. Today, the just-in-time compiler seems to be the tool of choice of engineers to face all these challenges.A just-in-time compiler either compiles a JavaScript function immediately before it is invoked, as Google's V8 does, or while it is being interpreted, as Mozilla's TraceMonkey did. The advent of the so-called Browser War between main software companies has boosted significantly the quality of these just-in-time compilers. In recent years we have seen the deployment of very efficient trace compilers [2–4] and type specializers for JavaScript [5]. New optimizations have been proposed to speed up JavaScript programs [6,7], and old techniques [8] have been reused in state-of-the-art browsers such as Google Chrome. Nevertheless, we believe that the landscape of current JIT techniques still offers room for improvement, and our opinion is that much can be done in terms of runtime value specialization.As we show in Section 2, we have observed empirically that almost 60% of all the JavaScript functions in popular websites are either called only once, or are always called with the same parameters. Similar numbers can be extended to typical benchmarks, such as V8, SunSpider and Kraken. Grounded by this observation, in this paper we propose to use the runtime values of the actual parameters of a function to specialize the code that we generate for it.11This paper is an extended version of earlier work, published in the Symposium on Code Generation and Optimization (CGO) 2013 [9].In Section 3 we revisit a small collection of classic compiler optimizations under the light of the proposed approach. As we show in the rest of this paper, some of these optimizations, such as constant propagation and dead-code elimination, perform very well once the values of the parameters are known. This knowledge is an asset that no static compiler can use, and, to the best of our knowledge, no just-in-time compiler currently uses.We have implemented the ideas discussed in this paper in IonMonkey, a JavaScript JIT compiler that runs on top of the SpiderMonkey interpreter used in the Firefox browser. As we explain in Section 4, we have tested our implementation on three popular JavaScript benchmarks: V8, SunSpider and Kraken. We only specialize functions that are called with at most one different parameter set. If a function that we have specialized is invoked more than once with different parameters, then we discard its generated machine code, and fall back into IonMonkey's traditional compilation mode. Even though we might have to recompile a function, our experiments in the SunSpider benchmark suite show that our approach pays for itself. We speed up SunSpider 1.0 by 2.73%. In some cases, as in SunSpider's access-nsieve.js, we have been able to achieve a speedup of 38%. We have improved run times in other benchmarks as well: we have observed a 4.8% speedup in V8 version 6, and 1.25% in Kraken 1.1. We emphasize that we are not comparing our prototype against a straw man: our gains have been obtained on top of Mozilla's industrial quality implementation of IonMonkey.We propose to specialize the code that the JIT compiler produces for a JavaScript function based on the parameters that this function receives. This kind of optimization is only worth doing if functions are not called many times with different parameters. To check the profitability of this optimization, we have instrumented the Mozilla Firefox browser, and we have used it to collect data from the 100 most visited webpages, according to the Alexa index.22Alexa, last visited at http://www.alexa.com, in October 2012.We have tried, as much as possible, to use the same methodology as Richards et al. [10]: for each webpage, our script imitates a typical user session, with interactions that simulate keyboard and mouse events. We simulate this mock user section via a jQuery33jQuery Foundation, last visited at jquery.com/ in October 2012.script. This script collects all links and buttons of a webpage and randomly executes them to simulate mouse events. To simulate keyboard interaction we collect all input fields in the webpage, and then fill them with random strings. We have manually navigated through some of these webpages, to certify that our robot produces results that are similar to those that would be obtained by a human being. For each script, we collect information about all function calls invoked during its execution, logging the following information: length in bytecodes, name (including line number of the function definition), and the value plus type of actual arguments.The histogram in Fig. 1shows how many times each different JavaScript function is called. This histogram clearly delineates a power distribution. In total we have seen 23,002 different JavaScript functions in the 100 visited websites. Functions with the same name, invoked in different websites, are not considered to be the same; i.e., the internet domain of the website is part of the name of its JavaScript functions. In all, 48.88% of all these functions are called only once during the entire browser session. In all, 11.12% of the functions are called twice. The most invoked functions are from the Kissy UI library, located at Taobao content delivery network (http://a.tbcdn.cn), and the Facebook JavaScipt library (http://static.ak.fbcdn.net). The first one is called 1956 times and the second 1813 times. These numbers indicate that specializing functions to the runtime value of their parameters may be an interesting approach in the JavaScript world.If we consider functions that are always called with the same parameters, then the distribution is even more concentrated towards 1. The histogram in Fig. 2shows how often a function is called with different parameters. This experiment shows that 59.91% of all the functions are always called with the same parameters. The descent in this case is impressive, as 8.71% of the functions are called with two different sets of parameters, and 4.60% are called with three. This distribution is more uniform towards the tail than the previous one: the most varied function is called with 1101 different parameters, the second most varied is called with 827, the third most with 736, etc. If it is possible to reuse the same specialized function when its parameters are the same, the histogram in Fig. 2 shows that the speculation that we advocate in this paper succeeds 60% of the time. As we will explain in Section 4, we keep a cache of actual parameter values, so that we can benefit from this regularity. Thus, if the same function is called many times with the same parameters, then we can still run its specialized version.We have built these histograms for popular benchmarks also. The results are given in Fig. 3. The new histograms are more varied than in the previous analysis. We speculate that this greater diversity happens because we are considering a universe with much fewer elements: we have 154 distinct functions in SunSpider, 186 in Kraken, and 320 in Google's V8. Nevertheless, we can still observe a power law, mainly in SunSpider's and Kraken's distribution. In all, 21.43% of SunSpider's functions are called only once. This number is only 4.68% in V8, but is 39.79% in Kraken. The function most often called in SunSpider, md5_ii from the crypto-md5 benchmark, was invoked 2300 times. In V8, we have observed 3209 calls of the method sc_Pair in the earley-boyer benchmark. In Kraken, the most called function is in stanford-crypto-ccm, an anonymous function invoked 648 times.If we consider how often each function is invoked with the same parameters, then we have a more evident power distribution. Fig. 3 (bottom) shows these histograms. We find that 38.96% of the functions are called with the same actual parameters in SunSpider, 40.62% in V8, and 55.91% in Kraken. At least for V8 we have a stark contrast with the number of invocations of the same function: only 4.68% of the functions are called a single time, yet the number of functions invoked with the same arguments is one order of magnitude larger. In the three collections of benchmarks, the most often called functions are also the most varied. In SunSpider, each of the 2300 calls of the md5_ii function receives different values. In V8 and Kraken, the most invoked functions were called with 2641 and 643 different parameter sets, respectively.The types of the parameters: We have performed a comparison between the types of the parameters used by functions called with only one set of arguments in the benchmarks, and in the Alexa top 100 websites. The results of this study are shown in Fig. 4. Firstly, we observe great diversity between the benchmarks and the web, and among the benchmarks themselves. Nevertheless, one fact is evident: the benchmarks use integers much more often than the JavaScript functions that we found in the wild. In all, 37.5%, 48.72% and 33.03% of the parameters used by functions in SunSpider, V8 and Kraken are integers, respectively. On the Internet, only 6.36% of the parameters are integers. In this case, objects and strings are used much more often: 35.57% and 32.95% of the time. Some of the optimizations that we describe in this paper, notably constant propagation, can use integers, doubles and booleans with great benefit: these primitive types allow us to evaluate some arithmetic operations at code-generation time. We can do less with objects, arrays and strings: we can inline some properties from these types, such as the length constant used in strings. We can also evaluate some conditional tests, e.g., ==, ===, etc., and we can evaluate calls to the typeof operator.Our idea is to replace the parameters of a function with the values that they hold when the function is called. Before explaining how we perform this replacement, we will briefly review the life cycle of a program executed through a just-in-time compiler. In this paper, we focus on the native machine code generated by a particular compiler – IonMonkey – yet, the same code layout is used in other JIT engines that combine interpretation with code generation. Furthermore, we consider a mixed-execution mode, in which an interpreter is used in combination with an optimizing compiler. That is the configuration that IonMonkey adopted at the time our experiments were performed. Future versions of this engine are likely to interpose a baseline compiler between the interpreter and the optimizer.Some JavaScript runtime environments, such as Chromium's V8, compile a function the first time that function is called. Other runtime systems compile code while this code is interpreted. The Mozilla Firefox engine follows the second approach. A JavaScript function is first interpreted, and then, if heuristics deem this function worth compiling, it is translated to native machine code. Fig. 5illustrates this interplay between interpreter and just-in-time compiler. Mozilla's SpiderMonkey engine comes with a JavaScript interpreter. There exists a number of JIT compilers that work with this interpreter, e.g., TraceMonkey [3], JägerMonkey [5] and IonMonkey. We will be working with the latter.The journey of a JavaScript function in the Mozilla's Virtual Machine starts in the parser, where the JavaScript code is transformed into bytecodes. These bytecodes belong to a stack-based instruction set, which SpiderMonkey interprets. Some JavaScript functions are either called very often, or contain loops that execute for a long time. We say that these functions are hot. Whenever the execution environment judges a function to be hot, this function is sent to IonMonkey to be translated to native code.The JavaScript function, while traversing IonMonkey's compilation pipeline, is translated into two intermediate representations. The first, the Middle-level Intermediate Representation, or MIR for short, is the baseline format that the compiler optimizes. MIR instructions use three-address code in static single assignment (SSA) form [11]. In this representation we have an infinite supply of virtual registers, also called variables. The main purpose of the MIR format is to provide the compiler with a simple representation that it can optimize. One of the optimizations that IonMonkey performs at this level is global value numbering; a task performed via the algorithm first described by Alpern et al. [12]. It is at this level that we apply the optimizations that we describe in this section.The optimized MIR program is converted into another format, before being translated into native code. This format is called the Low-level Intermediate Representation, or LIR. Contrary to MIR, LIR contains machine-specific information. MIR's virtual registers have been replaced by a finite set of names whose purpose is to help the register allocator find locations to store variables. After IonMonkey is done with register allocation, its code generator produces native machine code. SpiderMonkey then diverts its control-flow to the address of the generated code, shifting the JavaScript engine to native execution mode.This native code will be executed until either it legitimately terminates, or some guard, such as a type guard, evaluates to false. In the latter case, we will have a recompilation. Just-in-time compilers usually speculate on properties of runtime values in order to produce better code. IonMonkey, for instance, uses type specialization. JavaScript represents numbers as double precision floating-point values. However, many of these numbers can be represented as simple integers. If the IonMonkey compiler infers that a numeric variable is an integer, then this type is used to compile that variable, instead of the more expensive floating-point type. On the other hand, the type of this variable, initially an integer, might change during the execution of the JavaScript program. This modification triggers an event that aborts the execution of the native code, and forces IonMonkey to recompile the entire function.Fig. 6shows an example of a control flow graph (CFG) that IonMonkey produces. In the rest of this paper we will be using a simplified notation that represents the MIR instruction set. Contrary to a traditional CFG, the program in Fig. 6 has two entry points. The first, which we have labeled function entry point, is the path taken whenever the program flow enters the binary function from its beginning. This is the path taken whenever a function already compiled is invoked. The second entry point, the on-stack replacement (OSR) block, is the path taken by the program flow if the function is translated into binary during its interpretation. As we have mentioned before, a function might be compiled once some heuristics in the interpreter judge that it will run for a long time. In this case, the interpreter must divert the program flow directly to the point that was being interpreted when the native code became active. The OSR block marks this point, usually the first instruction of a basic block that is part of a loop.The CFG in Fig. 6 contains a number of special instructions called resumepoint. These instructions indicate places where the state of the program must be saved, so that if it returns to interpretation mode, then the interpreter will not be in an inconsistent state. Resume points are necessary after function calls, for instance, because they might have side effects. On the other hand, referentially transparent commands do not require saving the program state back to the interpreter.The core optimization that we propose in this paper is parameter specialization. This optimization consists of replacing the arguments passed to a function with the values associated with these arguments at the time the function is called. Our optimizer performs this replacement while the MIR control flow graph is built; therefore, it imposes zero overhead on the compiler. That is, instead of creating a virtual name for each parameter in the graph, we create a constant with that parameter's runtime value. We have immediate access to the value of each parameter, as it is stored in the interpreter's stack. There are two types of inputs that we specialize: those in the function entry block, and those in the OSR block. Fig. 7(a) shows the effects of this optimization in the program first seen in Fig. 6.Constant propagation is, possibly, the most well-known code optimization, and it is described in virtually every compiler textbook. We have implemented the algorithm present in Aho et al.'s classic book [13, pp. 633–635]. Basically, each program variable is associated with one element in the lattice⊥<c<⊤, where c is any constant. We iterate successive applications of a meet operator until we reach a fixed point. This meet operator is defined as⊥∧c=c,⊥∧⊤=⊤,⊤∧c=⊤,c0∧c1=c0ifc0=c1andc0∧c1=⊤otherwise. We have opted for the simplest possible implementation of constant propagation, to reduce the time overhead that our optimization imposes on the runtime environment. Thus, contrary to Wegman et al.'s seminal algorithm [14], we do not extract information from conditional branches.Fig. 7(b) shows the code that results from the application of constant propagation on the program seen in Fig. 7(a). If all the arguments of an instruction i are constants, then we can evaluate i at compilation time. If i defines a new variable v, then we can replace every use of v by the constant that we have just discovered. The elimination of an instruction that only operates on constants is called folding. We have marked the 14 instructions that we have been able to fold in Fig. 7(b). We can fold a large number of JavaScript's typical operations. Some of these operations apply only on primitive types, such as numbers, e.g., addition, subtraction, etc. Others, such as the many comparison operators, e.g., ==, !=, ===, !== and the typeof operator, apply on aggregates too.JavaScript is a very reflective language, and runtime type inspection is a common operation, not only at the development level, but also at the code generation level. As an example, in Fig. 6 we check if s is an array, before accessing some of its properties. Our constant propagation allows us to fold away many type guards, which are ubiquitous in the code that IonMonkey generates. We have folded the two type guards in block L3. This optimization is safe, as there is no assignment to variable s in the entire function.Loop inversion is a classic compiler optimization that consists in replacing a while loop by a repeat loop. The main benefit of this transformation is the replacement of a conditional and an unconditional jump inside a loop by a single conditional loop at its end. Fig. 7(c) shows the result of performing loop inversion in the program seen in Fig. 7(b). Usually loop inversion inserts a wrapping conditional around the repeat loop, to preserve the semantics of the original program. This conditional, only traversed once by the program flow, ensures that the body of the repeat loop will not be executed if the corresponding while loop iterates zero times. Loop inversion does not directly benefit from the knowledge of runtime values. However, we have observed that a subsequent dead-code elimination phase is able to remove the wrapping conditional. This elimination is possible because our parameter specialization often lets us know that a loop will be executed at least once.Dead-code elimination removes instructions that cannot be reached by the program flow. We run it after constant propagation, in order to give instruction folding the chance to transform conditional branches into simple boolean values. Whenever this extensive folding is possible, the outcome of the conditional branch can be predicted at compile-time; thus, we can safely remove the branch instruction and, possibly, blocks of unreachable code. Fig. 8(a) shows the effects of dead-code elimination on the program in Fig. 7(c). We have removed block L2, because the result of the comparison inside this block is known at code generation time. Notice that we keep the function entry block. We only keep this block because we can cache the generated machine code, in case a function is called with the same parameters again. If a function compiled to native code is called again, then execution must start at the function entry point.JavaScript is a type safe language, which means that any value can only be used according to the contract specified by its runtime type. As a consequence of this type safety, array accesses in JavaScript are bound checked. Accesses outside the bounds of the array return the undefined constant, which is the only element in the Undefined data type. Bound checking an index i is a relatively expensive operation, because, at the native code level it requires loading the array length property l, and demands two conditional tests:i≥0andi<l. The knowledge of function inputs allows us to eliminate some simple bound checks.To perform this optimization, we need to identify integer variables that control loops. If these induction variables are bounded by a known value, then we can perform a trivial kind of range analysis to estimate the minimum and maximum values that array indices might receive. In order to keep our optimizer simple and efficient, we only recognize variables defined by the patterni0=exp;i1=ϕ(i0,i2);i2=i1+c2. Variables i3 and i4, plus the constant 2, in Fig. 8(a) follow this pattern. Variable i2 is initially assigned the constant 2, andi2<100inside the loop; hence, its range is[2,99]. Moreover,i4=ϕ(2,i2); thus, its range is also[2,99]. Therefore, any access of array s2, e.g., reference 0xFF3D8800 in the figure, indexed by i4 is safe, as s2's length is 100. Fig. 8(b) shows the result of eliminating the bounds checks from the program in Fig. 8(b).JavaScript supports higher-order functions; therefore, it is possible to pass a function as an argument to another one. We inline functions passed as arguments, whenever possible. Fig. 8(c) shows the result of replacing the call to function inc, seen in Fig. 8(b), with its body. IonMonkey already performs function inlining; however, it requires 40,000 calls, much later than we do. IonMonkey's inliner is profile guided. Once a function is called a large number of times, it decides to inline it. Closures are not immediately inlined, as they are passed as formal parameters to a function that can be called with many different actual parameters. Furthermore, inlining closures requires guards: if the host function is called again, this time with a different closure, recompilation must take place. Our aggressive approach to inlining avoids all this burden. We inline a closure as soon as we compile the host function, and we do not use guards. In case the function is called again, our entire code will be discarded; hence, these guards would not be necessary.There are many classic compiler optimizations that we have not considered in this work, either due to the lack of time, or due to technological limitations in the current implementation of IonMonkey. Two of these optimizations that we plan to investigate in the future are loop unrolling and integer overflow check elimination. We speculate that loop unrolling can be very effective in our scenario, as we can use the simple analysis of Section 3.6 to find out how many times most of the loops will iterate.

@&#CONCLUSIONS@&#
