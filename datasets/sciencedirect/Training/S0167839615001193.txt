@&#MAIN-TITLE@&#
Detection of critical points of multivariate piecewise polynomial systems

@&#HIGHLIGHTS@&#
A method for detecting critical points of nonlinear algebraic systems.Detecting isolated critical points.Point cloud approximation for critical varieties of dimension greater than zero.

@&#KEYPHRASES@&#
Critical points,Subdivision solvers,B-spline basis functions,Singular points,

@&#ABSTRACT@&#
We propose a general scheme for detecting critical locations (of dimension zero) of piecewise polynomial multivariate equation systems. Our approach generalizes previously known methods for locating tangency events or self-intersections, in contexts such as surface–surface intersection (SSI) problems and the problem of tracing implicit plane curves. Given the algebraic constraints of the original problem, we formulate additional constraints, seeking locations where the differential matrix of the original problem has a non-maximal rank. This makes the method independent of a specific geometric application, as well as of dimensionality. Within the framework of subdivision based solvers, test results are demonstrated for non-linear systems with three and four unknowns.The general problem of finding all solutions of algebraic equation systems in a given domain, arises in various contexts in Computer Aided Design (CAD), engineering, robotics, or whenever the geometry governing the problem can be mapped to (or represented by) a set of algebraic (non-linear in general) equations. The subdivision approach, exploiting properties of the Bernstein/B-spline basis functions, has been extensively investigated for several decades – introducing algorithms for finding roots of a univariate polynomial such as in Lane and Riesenfeld (1981), solutions of fully constrained multivariate systems (Sherbrooke and Patrikalakis, 1993; Elber and Kim, 2001 and more) as well as for under-constrained systems (Hanniel and Elber, 2007; Liang et al., 2008 and more). Typically, the generic methods used in advanced solvers to guarantee the topology of the solution set (number of roots, number of connected components, loops, closed surfaces, etc.) rely on some regularity (or transversality) assumptions which may slightly vary according to the application. However, topological guarantee near singular locations is treated separately, and is usually much more difficult to achieve (if at all).Results and algorithms related to critical points detection are known, in various geometric contexts. In Grandine and Klein IV (1997), Hass et al. (2007), implicit planar curves which may admit self-intersections are traced. The self-intersections are first identified as critical points of the underlying implicit function,f(x,y)=0, namely the solutions of the fully determined system:∇f(x,y)=0¯∈R2. A numerical method with topological guarantee for implicit planar curves is given in Burr et al. (2008), which also detects isolated singularities and computes their degrees, using the number of connected components of certain topological structure in the neighborhood of the singularity.Critical points in the context of curve-surface intersection and surface–surface intersection are identified as tangency events of the two parametric geometries involved. For example, in Hu et al. (1997), tangency events of a parametric curver(t)and a parametric surfaceR(u,v), are found by adding an orthogonality condition:〈r′(t),Ru(u,v)×Rv(u,v)〉=0, to the original intersection requirement:r(t)=R(u,v). In a similar manner, the additional conditions for tangency events of two parametric surfacesR(u,v)andP(s,t), are formulated to require that the two normal vectors at the intersection point are collinear.Further, the dynamic version of the surface–surface intersection problem (Chen, 2008; Chen et al., 2007) is another application where the detection of critical points is essential: as the parametric surfaces evolve continuously with respect to a third parameter (time/control variable), the critical points are the events where intersection curve components may appear/disappear/merge and split. These are the topological events, where the solution curves may undergo topological changes, and they are characterized by tangency events of the evolving surfaces. In Chen (2008), Chen et al. (2007), they are recognized as the locations where a specific projection mapping is degenerate. However, no general method to locate the critical points of a smooth functionF:D⊂Rn→Rk,k≤nis provided.Critical points are also used to determine the topology of an iso-surface of the formf(x,y,z)=const, using established results on the classification of critical points from Morse theory. In Stander and Hart (2005), the critical points are found as the solutions of∇f(x,y,z)=0¯∈R3. Each such point corresponds to a critical value of f. The topological change in the iso-surfaces, as the function values vary through the critical one, is then identified using the Hessian value at the singular location. Consequently, a topologically correct triangular mesh is interactively updated. Such concepts are also used in Ni et al. (2004), where an appropriate Morse function is constructed on a polygonal mesh, such that its critical points can be optimized (their number can be controlled by the user). The critical points of the chosen function are then used to interrogate the topology of the mesh, and to separate it into disc-topology patches.Other applications of critical point analysis arise in the context of bisector curves, offset curves and medial axis computation (Seong et al., 2010; Muthuganapathy et al., 2011; Johnson and Cohen, 2009; Musuvathy, 2011). These methods use critical point analysis of certain distance functions to locate transition events in the required solution manifolds. To the best of our knowledge, there's no (subdivision based) general method for finding the critical points of a smooth functionF:D⊂Rn→Rk,k≤n. Although critical point analysis is widely used, it is usually of a specific function, intimately related to the problem or application domain. Our approach assumes no knowledge of the underlying motivation that gave rise to the equation solving problem or its dimensions. This generality, however, also has its drawbacks, as we discuss in further detail in Section 4.The rest of this paper is organized as follows: In Section 2, the method for detecting critical points is detailed. Section 3 provides test results, for several types of problems and dimensions. Finally, Section 4 concludes and discusses future work.LetF:D⊂Rn→Rk(k≤n), be a (piecewise) polynomial, at leastC1smooth, and given in a tensor product B-spline form. The vector valued function F is defined on the axis parallel, n dimensional compact box:D=[a1,b1]×…×[an,bn],which may formally be considered as a subset of an open setU⊂Rnon which F is defined and smooth. The scalar components of F are denoted by:F=(f1,…,fk). In this section, we describe a method for finding the critical points of:(1)F(x¯)=0¯,using a (subdivision based) multivariate constraint solver. First, recall that the differential of F atp∈D, denoteddFp, is the linear map, matrix representation of which has the partial derivatives of F evaluated at p as its elements:[dFp]ij=∂fi∂xj(p).The critical points of F are generally defined by the following (Do Carmo, 1976):Definition 1Given a differentiable mapF:U⊂Rn→Rk, defined in an open set U ofRn, we say thatp∈Uis a critical point of F if the differentialdFp:Rn→Rkis not a surjective (onto) mapping. The imageF(p)∈Rkof a critical point is called a critical value of F. A point ofRkwhich is not a critical value is called a regular value of F.Remark 2We are not interested, typically, in all the critical points of F, but only in those that are solution points as well. However, as will be evident shortly, the proposed method can be easily adopted to find all the critical points, rather than only those that are solution points (i.e. belonging to the critical value0¯∈Rk).Prior to proceeding to solution details, the following clarification is in order. The singularities (or critical points) we seek are of the solution manifold, implicitly represented by the underlying equations system. This is not to be confused with the input equations, which may admit discontinuities of their own, but are trivial to handle: Since we assume a B-spline represented input (i.e. piecewise polynomials/rationals) – discontinuities of the input representation (if exist) occur only at the B-spline knots. This is commonly handled in subdivision solvers by first subdividing the problem into a small set of smoothly represented problems. It is stressed that each of these, in turn, may admit singular solutions. Both situations will be demonstrated in Section 3.For general positive integersk≤n, saying that ak×nmatrix A is a surjective linear operator can be equivalently stated asrank(A)=k, or simply that A has maximal possible rank. Hence,p∈Dis a critical point of F if and only if:(2)rank(dFp)<k.To formulate the non-maximal rank requirement such that it can be handled by an equation solver, observe thatrank(dFp)=kif and only if there is at least one subset of k linearly independent columns. Denote bySknthe set of all possible k-tuples of multi-indices of the formI=(i1,…,ik), which correspond to all possible selections of k columns out of the n columns ofdFp. Each such a selection determines ak×ksize sub-matrix. For a specific selection I of k columns, the corresponding minor (determinant of the sub-matrix), denotedMI(p), must vanish if p is a critical point of F. Hence, the points we are interested in are exactly allp∈Dwhich simultaneously satisfy:(3)F(p)=0¯∈Rk,MI(p)=0,∀I∈Skn.From now on, the vector valued function defined onD⊂Rnwith values inRk+(nk)which is given by Equation (3), is denoted by G. Hence we seek solutions of:(4)G(x¯)=(F(x¯),M1(x¯),…,M(nk)(x¯))=0¯∈Rk+(nk).Since efficient and robust algorithms for symbolic operations on B-spline functions are known (Elber and Cohen, 1993; Chen et al., 2009 and more), the multivariate determinant functions can be computed, and, conceptually, the systemG(x¯)=0¯in Equation (4) can be sent to an algebraic constraint solver. However, observe that Equation (4) poses two difficulties. First, G inherits the singularity from the original equation solving problem: ifp∈Dis a critical point of the original systemF(x¯)=0¯, then the gradients of F are linearly dependent, when evaluated at p. Since these gradients are a subset of the gradients of G, the linear dependence persists. The second difficulty is that Equation (4) hask+(nk)constraints and n unknowns. This over-constrained (or redundant) structure requires some reformulation prior to passing it to an algebraic equation solver: geometric root isolation techniques such as tangent cones overlapping criteria (Hanniel and Elber, 2007) assume exactly n gradients of functions and n unknowns. Finally, the Newton–Raphson numeric iterative procedure for the solution refinement step, is also designed forn×nsystems. In what follows, we describe our proposed method and how these difficulties are addressed.Remark 3If all critical points of F are needed, rather than only those corresponding to the critical value zero, the proposed method can be modified by ignoring the first k constraints in Equation (4), and solving only for simultaneous zeros of all minors.Recall that subdivision based solvers (such as Sherbrooke and Patrikalakis, 1993; Hanniel and Elber, 2007; Bartoň et al., 2011; Sederberg and Nishita, 1990 and more) essentially consist of two steps. The recursive subdivision and domain exclusion step tests if the currently handled domain can be purged, due to positivity/negativity of all B-spline coefficients of the current representation, in at least one of the constraints (or some other purging criteria using the geometry of the control polygons, etc.). If the domain cannot be purged, a solution may exist, and some root isolation/uniqueness condition is tested. If uniqueness cannot be guaranteed, subdivision proceeds. Otherwise, subdivision is terminated and the second step is executed – iterative numeric improvement in the current domain, for example – via Newton–Raphson iterations – using the center as the initial candidate.Within this framework, our motivation is to find an alternative formulation for Equation (4), that is not over-constrained/redundant (in terms of dimensionality), and, if possible, does not suffer from the same singularity at the locations we seek, as does the original problem. Three reasonable options are the following:1.Formulate the requirement that all minors vanish simultaneously at p using a single scalar constraint, denotedL(p), given by:(5)L(p)=(MI1(p))2+(MI2(p))2+…+(MI(nk)(p))2=0.This formulation is ill-conditioned in many senses, and is hardly useful. Not only does it inherit the singularity of the original problem, it also adds another non-transversal zero requirement, since any zero of the non-negative functionLis a tangential contact. Further, there arek+1constraints in this formulation (k being the number of constraints in the original problem), which is not always equal to n (the dimension of the parameter space). Apart from being useless in the (easier) case ofk=n(the problem is still over-constrained/redundant), in thek≤n−2case it causes a situation where isolated critical points are searched by a solver designed to trace a higher dimensional solution (curves, surfaces, etc.). Due to these drawbacks, and as verified in practice, this approach is highly unlikely to efficiently detect the critical locations.Solve a subsystem of sizen×n, and filter the candidate solutions by evaluating the other constraints: a critical point must be a solution of the chosen subsystem, which is also a zero of all other (unchosen) components of the redundant system Equation (4). The selection method we have experimented with, is using the first k constraints, completing it to a system of n constraints with any choice ofn−kminors. In some cases, we have also tried using only minors exclusively. This approach does prove useful in detecting the critical points, but it is not our chosen method, as it suffers from the following inherent problems: first, a proper choice of a subset of constraints must be made. Such a selection must take place with no knowledge of the regularity of the chosen subsystem, how to recognize better/worse sub-systems, or even the anticipated dimension of the variety of critical points of the original system. In that sense, this is a biased decision – some constraints participate in the solution process, while others participate as post-filters only. The first actual effect of this asymmetry is closely related to scaling and numeric tolerances: experiments show that a solution candidate close to the exact critical point of interest, may satisfy the chosen sub-system (and hence numeric iterations are terminated), while fail the post-filter constraints due to inadequate tolerance adjustments and different constraints scaling. Further, different choices of sub-systems yield different behavior with respect to this technical issue. Another undesired phenomenon due to the asymmetry at present is the following: it can happen that for a problem with isolated critical points only, a very dense set of candidate solutions shall be produced, due to a poor choice of a rank-deficient sub-system. Root isolation techniques are of course useless in such unfortunate case, since the roots of the poorly chosen sub-system are indeed non-isolated. This results in high and unnecessary computational cost – for the equation solver, as well as for the evaluation based post-filter effort.The third option is our choice and is the one used to generate all the examples in this paper. We replace the over-constrained/redundant formulation of Equation (4) with a problem of sizen×nthat always accounts for all minors in the same manner: we view the over-constrained systemG(x¯)=0¯in the minimal norm sense, hence attempt to find minimizers of12‖G(x¯)‖2, that are also zeros of G. This approach is detailed in Section 2.3. A-priori, it need not inherit the singularities from the original problem, unlike the previous two alternatives. One drawback, however, is that this approach produces higher order constraints than the previous alternative, due to the optimization formulation (taking the square of the constraints before differentiation, as will soon be described). Consequently, run times are significantly slower (one or two orders of magnitude), but it is still our preferred method due to its robustness. This framework is also relevant to any over-constrained system (not restricted to the context of finding critical points) and is described next.As in the above notations, let G denote the underlying vector valued function of some over-constrained equation solving problem. In our context, G represents Equation (4), but the question that gave rise to the over-constrained system may be disregarded for most of this section. SinceG(p)=0¯if and only if12‖G(p)‖2=0, and since the Euclidean norm function is non-negative, the required solutions (if exist) ofG(x¯)=0¯, are necessarily minimizers of12‖G(x¯)‖2. This approach is well known, and classically resides in the field of least squares (constrained and unconstrained) optimization, exhibiting established theory and algorithms, such as the powerful Gauss–Newton iterative numeric method (Nocedal and Wright, 2006). The Gauss–Newton method essentially uses the notion of the pseudo-inverse of the Jacobian to take the role of the inverse of the Jacobian in the Newton–Raphson analog.The Gauss–Newton method is a numeric iterative method, applied to over-constrained systems, aiming to converge to a location of minimal norm. Now, remember that numeric iterative methods are local: they cannot guarantee the isolation of all solutions in a domain, and highly depend on the initial candidate. Advanced subdivision solvers are global, and address this issue via root isolation techniques: numeric iterations are applied locally, but in all sub-domains for which solution uniqueness could be verified. Put differently, root isolation enables the termination of the subdivision process, and proceed to numerical improvement. The difficulty we are now facing, however, is that common root isolation techniques (e.g. tangent cone non-overlapping criteria (Hanniel and Elber, 2007)) assume a system of sizen×n, while our system is over-constrained. This technicality prevents us from adopting the optimization approach in a straight forward manner, at the numeric improvement level: we are lacking appropriate subdivision termination criteria!To resolve this issue, we provide the solver with the following alternative problem: the first n constraints have the semantics of the necessary condition for a local minimization of12‖G(x¯)‖2, and are given by the simultaneous zeros of the vector valued functionH:D⊂Rn→Rn, given by:(6)H(x¯)=∇(12‖G(x¯)‖2)=0¯.Since we are not interested in minimizers that are not zeros of G, we passG(x¯)=0¯as additional constraints, but tag them as subdivision step constraints: they are only considered for the domain purging by coefficient signs – not for root isolation or numeric iterative steps. Consequently, the solver shall avoid searching for zeros of H that are not near zeros of G, to the extent of subdivision tolerance. Any local optimizers that are not zeros of G but survive this domain purging filter shall be filtered by evaluation of G in post process – a rare event.Using the above described scheme accounts for all scalar components of G in the same manner, hence no asymmetric selection is done, while the preferred structure of a system of sizen×nexploits the existing machinery of root isolation tests for subdivision termination and Newton–Raphson iterations. The additional constraints (tagged as subdivision step only) act as a filter – also accounting for all components of G equally. Another advantage is that there's no necessary inheritance of degeneracy: as verified by test results – critical points can successfully be detected as isolated roots of the optimization formulation, implying that a problem with singularities may be mapped to an alternative formulation that enjoys regularity. There's no guarantee that this is always the case, but in order for a solutionp∈DofH(x¯)=0¯to be critical point of H as well as of F, it must be a location of linear dependence of the gradients of H and of the gradients of F, which are essentially unrelated events. Examples of such an unfortunate case can obviously be constructed, with a high enough level of degeneracy, and yet – we are in a preferred setting over the previously described guaranteed singularity feature, inherent in the other alternative formulations.Remark 4Observe that although could not be adopted directly, the Gauss–Newton numeric procedure (Nocedal and Wright, 2006) has been used: it is easily verified by differentiation that the Newton–Raphson iterations of the formulationH(x¯)=0¯, coincide with the Gauss–Newton iterations of the over-constrained formulationG(x¯)=0¯. Hence, the numeric iterations that ourn×nformulation yielded are exactly the Gauss–Newton iterations of the over-constrained original problem, with the distinction that now they are applied locally on all sub-domains for which solution uniqueness could be guaranteed. It is the need to test for subdivision termination, that required switching to seeking zeros of H at an earlier stage of the subdivision solver paradigm.This work concerns with detection of critical points of dimension zero, i.e. isolated singularities of the systemF(x¯)=0¯. The singular locations can, clearly, form a manifold of higher dimension or, more generally, a higher dimensional variety (not necessarily a regular manifold). Since the critical points ofF=(f1,…,fk)have been characterized as a subset of yet another equation solving problem, the dimensionality (and regularity) of the critical locations variety of F are now governed by the regularity ofH=(h1,…,hn). Assume a critical pointp∈Dhas been detected, i.e. the set:{∇fi(p)}i=1,…,kis linearly dependent. The linear dependence or not, of the set:{∇hi(p)}i=1,…,nis, as mentioned earlier, conceptually unrelated: it involves the first and second order derivatives of F, and is again, roughly speaking, an event of “zero probability” (a term made precise by Sard's theorem (Lee, 2012), in the sense of the sparsity of the critical values of a smooth function). Hence, it is not surprising that in practice, the alternative formulation chosen can yield solutions (critical points of F) that have been successfully isolated using regularity based methods. When the critical point p of F is also a critical point of H, the question of the dimension of the critical points of F near p arises – p need not be isolated. This is a completely general question, not restricted to the context of critical point detection. To the best of our knowledge, there is no known method to compute the dimension of the variety of real solutions of algebraic equations in the non-regular case. In the case of algebraically closed fields (e.g. the variety of complex solutions), this topic is systematically treated: theory and computational methods are known, relying on algebraic geometry concepts (Gröbner bases and the Hilbert polynomial (Cox et al., 2007)).We summarize what can be concluded regarding the dimensionality of the critical locations near the detected critical point p of F. Denote:rank(dHp)=m.Ifm=nthen p is an isolated critical point of F. This is a sufficient but not necessary condition. Whenm<nthe dimension cannot be concluded since the linear dependence of{∇hi(p)}i=1,…,nmay occur only at p (in which case p may be isolated), or it may hold globally in some neighborhood of p (in which case p is a member of some higher dimensional variety of solutions). In Section 3 we show how the method designed to detect isolated critical points can be used to approximate a one dimensional variety of critical points, using a dense point set.The above described method is summarized in Algorithm 1. Note that the output may be a set of critical points, but it may also be deduced so that the problem is globally degenerate in D: if all the constructed minor functions are identically zero, thenrank(dF)<kindependent ofx¯.We demonstrate the critical point detection method for several equation solving problems with various situations regarding the set of critical points of the solution. The first example is a simple step-by-step presentation of how the algorithm operates, while demonstrating how a critical point of the original problem can be detected via a regular equation system: the suggested formulation yields a regular solution. The entire sequence is depicted in Figs. 1 to 3. Fig. 1 shows the general, original problem of finding the intersection of two planar curves that are singular (i.e. tangent, Fig. 1(a)), given as the zero sets of two scalar bivariate functions in Fig. 1(b).Fig. 2(a) shows the additional constraint, originating from the non-maximal rank differential requirement, yielding a single minor function. At this stage, the problem is formulated as three equations with two unknowns, hence over-constrained, and corresponds toG(x,y)=0¯in our notations. The solution we seek is a minimizer of12‖G(x,y)‖2, represented by the surface in Fig. 2(b).Finally, the minimization problem is approached by searching zeros ofH=∇(12‖G‖2). As shown in Fig. 3, this is realized as a regular (or transversal) zero of a2×2system.In the next example, the situation is of an isolated critical point as the only solution point of an anticipated solution curve inR4. Consider the following system of three equations and four unknowns:(7)y2+z2+w2−0.25=0,y2+z2+(w−1)2−0.25=0,x−0.5=0.When approached manually, it is easily verified that the three dimensional hyper-cylinders of the first two equations are tangent along their common contact line(x,0,0,0.5). The intersection of this straight line with the hyper-planex=0.5in the last equation yields the unique solution point(0.5,0,0,0.5). When sent to the equation solver (Bartoň et al., 2011) which relies on regularity for the topological considerations, the algorithm anticipates a univariate solution curve and fails to detect this isolated (critical) solution point. Using the presented critical point detection method, the point(0.5,0,0,0.5)is detected. This problem does not originate from a parameterized representation of curves/surfaces, and hence the critical point cannot be found using the methods reviewed in Section 1.Next, we show how Algorithm 1 can be applied to detect singular points of surface–surface intersection (SSI) problems, as a special instance of the method. Indeed, this can also be solved by the specific methods using the normal vectors of the parameterized surfaces, as described in Section 1, but this formulation is not used in the examples herein. In the first SSI example, the solution curve is almost entirely regular, except for a unique problematic location. Consider the “monkey saddle” surface (Do Carmo, 1976):S1(u,v)=(u,v,u3−3v2u),which admits a complicated intersection curve with the paraboloid:S2(s,t)=(s,t,s2+t2).The parametrized version of the surface–surface intersection problem can be formulated as follows:(8)u−s=0,v−t=0,u3−3v2u−s2−t2=0.This formulation is of course artificially higher dimensional than required, since by trivial substitution it can be reduced to a single equation in two unknowns. However, for instructive reasons we would like to demonstrate the detection of the critical point at the origin, in this four-variable case (and of course – the subdivision solver does not perform such symbolic substitution/reduction of the problem).Three regular branches of the intersection curve are traced, missing the high order contact at the origin (Fig. 4). The critical point detection method returns the origin as an isolated critical point.Another version of the above example is the zero level contour of the monkey saddle surface, formulated similarly. The critical point at the origin is again missed, but this time it is a complicated self-intersection of the contour curve, leaving it not connected (Fig. 5). Using the presented method, the tangency point at the origin is detected.The last SSI example provided is of two rational B-spline surfaces. Again, the regular SSI solver reports no solution found, and the critical point is detected, as depicted in Fig. 6.Next, an example with non-isolated singular points is given. Consider the implicit equation of the Steiner surface:(9)x2y2+x2z2+y2z2−xyz=0.The Steiner surface admits complicated self-intersections, with a variety of critical points in the form of self-intersecting curves along the coordinate axes. As mentioned in Section 2, in such a case (not known to the user in advance), the critical point detection algorithm returns a large set of points, approximating the higher dimensional, self-intersection variety. Indeed, critical points are detected along the coordinate axes (Fig. 7). As discussed in Section 2.4, the presented method does not provide a way to recognize that the critical points compose a one dimensional variety.We proceed and demonstrate how the presented method can be applied to the problem of detecting topological events in the dynamic intersection of deforming and/or moving geometries. In this context, the term “deforming/displacing” geometry shall refer to any regular manifold, representation of which is, other than its dependence on the parametersx¯∈D⊂Rn, endowed with additional deformation/displacement degrees of freedom via control variablest¯∈T⊂Rm. We assume that the representation depends smoothly onx¯as well as ont¯, and that the manifold remains regular for allt¯∈T. This framework is well defined whether the representation is implicit or parametric, and regardless of dimensionality. Consequently, the intersection of such objects can be written as the solution of an equation of the form:(10)F(x¯,t¯)=0¯∈Rk,where: F is defined onD×T⊂Rn+m, D is the product of the parameter spaces of the involved geometries, and T is the product of their deformation/displacement control spaces. The values of n, k depend on the representation and on the number of geometries in the problem. For eacht¯value, the solution in the parameter space is the result of projecting the solution fromD×Tto D. A detailed treatment of this problem can be found in Chen (2008), Chen et al. (2007). The approach taken in Chen (2008), Chen et al. (2007) is, roughly speaking, propagation in the control space. The intersection of the geometries is advanced, either preserving the topological structure, or (in the case of a singularity in the control/time propagation), undergoing one of several generic transition events. These topological events are classified based on results from Morse theory, and their location is characterized as the critical points of a certain projection mapping of the solution manifold to the control space (although no general method for detecting non-maximal rank is proposed). We now apply a version of Algorithm 1 to the detection of these transition events. Observe that for a fixedt¯∈T, if the parameter space gradients of F (i.e. gradients with respect tox¯∈Donly) are linearly independent, then the resulting manifold is regular in D. A topological event must occur att¯values for which the parameter-space intersection is degenerate. For example, the intersection curve of two deforming surfaces changes its topological structure only when the deforming surfaces are tangent. Hence, adopting the notationdx¯F(x¯,t¯)for the differential of the mapping F with respect tox¯only, we are interested in the(x¯,t¯)∈Rn+mvalues for which thek×nmatrix, entries of which are scalar functions of(n+m)variables, has non-maximal rank. Therefore, we may apply Algorithm 1 with the exception that the matrix providing the minor functions at step 1.4 isdx¯F(x¯,t¯).For example, consider the implicit equation of a torus, obtained by revolving a circle of radius r along a circle of radius R, about the z axis:(x2+y2+z2+R2−r2)2−4R2(x2+y2)=0.Now, fort∈[0,1], the implicit torus can be smoothly displaced along the curve11This space curve is referred to as the “twisted cubic” in literature (Cox et al., 2007).parameterized by:γ(t)=(t,t2,t3), resulting with the following implicit equation:(11)((x−t)2+(y−t2)2+(z−t3)2+R2−r2)2−4R2((x−t)2+(y−t2)2)=0.The intersection of the smoothly displaced torus of Equation (11) with the ellipsoid, implicitly given by:(12)(x−0.5)20.42+(y−0.5)20.32+(x−0.5)20.22−1=0,depends smoothly on t. It is empty fort=0.0,1.0, and changes its topological structure at six different t values. These events correspond to tangency locations in the(x,y,z)space (and need not be tangency critical points in the(x,y,z,t)space). The six events are detected, and are shown according to their t values in Fig. 8.The running times for solving the critical points equation (H(x¯)=0¯, subject toG(x¯)=0¯, not including the minor functions construction) are presented in Table 1, tested on an Intel Core i5-2300 CPU, 2.8 GHz with 4 GB memory. For each example, the maximal orders of the constructed problem is provided, as well as the orders of the input problem. Since (squares of) determinants of function valued matrices are involved, the critical points problem is typically of high order, as can be seen from the third column of Table 1. As mentioned in Section 2.2, solving the problem using the minimal norm form is typically slower than the less robust (and unbalanced) option of selecting ann×nsubsystem from Equation (4). For example, the computation time of the example in Fig. 5, using the faster unbalanced method was 0.09 seconds, while using the balanced, minimal norm approach (shown in Table 1), the time is 0.82 seconds. We suspect that the computation time differences are mostly due to the fact that our balanced approach has to deal with higher order constraints (see also Table 1).In this paper, we have presented a general method for detecting the (zero dimensional set of) critical points in the parameter space of a (nonlinear) algebraic equation systemF(x¯)=0¯, whereF:D⊂Rn→Rk,k≤n. The method assumes no knowledge of the geometry that gave rise to the equation system, and addresses only the geometry of the zero set of F: the intersection of k hyper-surfaces, given in implicit form by each of the scalar components ofF=(f1,…,fk). One potential drawback of the method is that in many applications the parameter space of F is different than the underlying problem's objective (or model) space: for example, the equations represented by F may have a parameter space that consists of parameters of several geometric objects, as well as other auxiliary variables that measure distances/time/control variables, etc. This means that solution points belonging to the zero set of F are mapped (in a post process) by some “application specific” function, to the actual solution points of interest to the user. It is not uncommon that this post process mapping has degeneracies of its own, and the presented method cannot possibly detect them. Nevertheless, the presented method proved useful in detecting points where a generalk×nmatrix with multivariate function elements has non-maximal rank.The proper exploitation of these singularity detections in subdivision solvers are to be investigated. First, consider locating all critical points, as a pre-process step of any general equation solving problem. As a result, it is possible to subdivide the problem in a manner that guarantees two types of sub-domains: sub-domains that contain the critical locations, and a set of sub-problems that are strictly regular: admitting no critical points, not even at domain boundaries, bounded away from the singularity. Next, whenk<n, correct tessellation of the solution manifold (in general dimension), at the above mentioned singular sub-domains, is a very challenging problem, solution of which shall result in topologically correct “stitching” of the regular areas. Such results are known for the cases off(x,y)=0andf(x,y,z)=0, as in Bloomenthal and Ferguson (1995), Burr et al. (2008), Hass et al. (2007), Stander and Hart (2005).Further, the ability to detect non-maximal rank is in fact useful and can be applied whenever linear dependence is to be found. For example, if allk×ksize minors happened to be the identically-zero function, then the problem is degenerate globally in a domain, and the anticipated solution set dimension is found to be wrong by such an observation (which should affect the design of any solver that is meant to support solution sets of several possible dimensions).

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
