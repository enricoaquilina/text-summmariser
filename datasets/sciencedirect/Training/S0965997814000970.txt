@&#MAIN-TITLE@&#
Comparison of nine meta-heuristic algorithms for optimal design of truss structures with frequency constraints

@&#HIGHLIGHTS@&#
Performance comparison is made for nine multi-agent meta-heuristic algorithms.For inspecting the exploration/exploitation characteristics, a diversity index history is defined.Performance of an algorithm is related to the shape of its diversity index history curve.

@&#KEYPHRASES@&#
Structural optimization,Frequency constraints,Exploration/exploitation characteristics,Diversity index,

@&#ABSTRACT@&#
Structural optimization with frequency constraints is a challenging class of optimization problems characterized by highly non-linear and non-convex search spaces. When using a meta-heuristic algorithm to solve a problem of this kind, exploration/exploitation balance is a key feature to control the performance of the algorithm. An excessively exploitative algorithm might focus on certain areas of the search space ignoring the others. On the other hand, an algorithm that is too explorative overlooks high quality solutions as a result of not performing adequate local search.This paper compares nine multi-agent meta-heuristic algorithms for sizing and layout optimization of truss structures with frequency constraints. The variation of the diversity index during the optimization history is analyzed in order to inspect exploration/exploitation properties of each algorithm. It appears that there is a significant relationship between the algorithm efficiency and the evolution of the diversity index.

@&#INTRODUCTION@&#
In low frequency vibration problems, the response of the structure depends in most part on fundamental frequencies and mode shapes [1]. Therefore, the dynamic behavior of a structure can be controlled by constraining these parameters. Minimizing the mass of a structure for which some natural frequencies should be upper and/or lower-bounded corresponds to formulate a structural optimization problem with frequency constraints.Structural optimization with frequency constraints was first introduced by Bellagamba and Yang [2] in 1980s, and since then has received considerable attention by optimization experts that developed several algorithms. Optimization problems including both sizing and layout variables are very demanding especially when frequency constraints are lower-bounded [3]. Solution of frequency-constrained problems including both sizing and layout variables is still an open issue.Sergeyev and Mroz [4] pointed out that natural frequencies of a structure are much more sensitive to layout modifications than to the size modifications. This may be because layout modifications often imply mode switches which in turn result in significant changes in natural frequencies. In addition, sizing and layout variables usually are of different nature and have different orders of magnitude. These facts make the combined sizing-layout optimization of structures with frequency constraints a challenging problem of its kind, including several local optima. Since frequency constraints are highly non-linear, non-convex and implicit functions with respect to design variables, this class of problems is very indicative to evaluate the performance of meta-heuristic algorithms. It is very important to design an optimization engine with a proper balance between diversification (i.e. global exploration of the search space) and intensification (i.e. local exploitation of the best solutions found) [5].A short survey on the literature of optimization with frequency constraints is now provided. Konzelman [6] utilized dual methods and approximation concepts. Grandhi and Venkayya [7] used an optimality criterion based on the uniform Lagrangian density for resizing and scaling to locate boundary constraints. Sedaghati et al. [8] used an integrated finite element force method for frequency determination and mathematical programming to optimize truss and frame structures. Wang et al. [9] formed an optimality criterion via differentiation of the Lagrangian function: 3D truss structures were optimized including simultaneously sizing and layout variables; the initial design was chosen so to have the minimum weight increment. Lingyun et al. [10] hybridized the simplex search method and genetic algorithms to formulate the niche genetic hybrid algorithm (NGHA) that was applied to truss sizing/layout optimization problems. Lin et al. [11] minimized the weight of structures subject to static and dynamic constraints with a bi-factor algorithm based on Kuhn-Tucker conditions.As far as it concerns meta-heuristic algorithms, Gomes [3] used Particle Swarm Optimization (PSO) to solve sizing/layout optimization of trusses under frequency constraints. Kaveh and Zolghadr utilized the Charged System Search (CSS) method and its enhanced form [12], and a hybridized CSS–BB-BC with trap recognition capability [13]. Furthermore, they developed the Democratic Particle Swarm Optimization (DPSO) [14] and the hybridized PSRO [15] algorithms to improve exploration capability of PSO. Improving exploration ability of PSO has been an active research topic in recent years [16–18].This paper will compare the performance of nine meta-heuristic algorithms for weight minimization of truss structures subject to frequency constraints: Particle Swarm Optimization (PSO) introduced by Kennedy and Eberhart [19], Harmony Search (HS) developed by Geem et al. [20], Big Bang–Big Crunch (BB–BC) presented by Erol and Eksin [21], Firefly Algorithm (FA) introduced by Yang [22,23], Charged System Search (CSS) developed by Kaveh and Talatahari [24], Cuckoo Search (CS) formulated by Yang and Deb [25], Enhanced Ray Optimization (ERO) a slightly improved version of Ray Optimization (RO) introduced by Kaveh and Khayatazad [26], Democratic Particle Swarm Optimization (DPSO) [14], and hybridized Particle Swarm Ray Optimization (PSRO) [15] both proposed by Kaveh and Zolghadr. The performance of each algorithm is evaluated on the basis of the convergence behavior observed in the optimization process. For that purpose, a diversity index is defined. Exploration/exploitation behavior is related with algorithm performance by analyzing the trend of the diversity index observed in the optimization process.The article is structured as follows. Section 2 presents the statement of the minimum weight problem for a truss structure subject to frequency constraints. The optimization algorithms compared in this study are concisely reviewed in Section 3. In Section 4, the relative merits of the algorithms are assessed by solving five optimization problems. Some concluding remarks are provided in Section 5.The mixed sizing-layout optimization problem for a truss structure subject to frequency constraints where the objective is to minimize the weight of the structure can be stated as follows:(1)FindX=[x1,x2,x3,…,xn]tominimizeP(X)=f(X)×fpenalty(X)subjecttoωj⩽ωj∗forsomenaturalfrequenciesjωk⩾ωk∗forsomenaturalfrequencieskximin⩽xi⩽ximaxwhere X is the vector of the design variables, including both nodal coordinates and cross-sectional areas; n is the number of optimization variables which depends on element grouping; f(X) is the cost function, which is taken as the weight of the structure in a weight optimization problem; fpenalty(X) is the penalty function, which is used to make the problem unconstrained. When some constraints corresponding to the response of the structure are violated in a particular solution, the penalty function magnifies the weight of the solution by taking values bigger than one; P(X) is the penalized cost function or the objective function to be minimized. ωjis the jth natural frequency of the structure with the corresponding upper boundωj∗, while ωkis the kth natural frequency of the structure with the corresponding lower boundωk∗. ximinand ximaxare the lower and upper bounds for the design variable xi, respectively.The cost function can be expressed as:(2)f(X)=∑i=1nmρiLiAiwhere nm is the number of structural members; ρi, Li, and Aiare the material density, length, and cross-sectional area of ith element.The penalty function is defined as:(3)fpenalty(X)=(1+ε1.v)ε2,v=∑i=1qviwhere q is the number of frequency constraints. The values for vican be considered as:(4)vi=0iftheithconstraintissatisfied1-ωiωi∗elseThe parameters ε1 and ε2 determine the degree to which a violated solution should be penalized. In this study ε1 is taken as unity, and ε2 starts from 1.5 and then linearly increases to 6 for all the considered test problems. Such a scheme penalizes the unfeasible solutions more severely as the optimization process proceeds. As a result, in the early stages the agents are free to explore the search space, but at the end they tend to choose solutions without violation.All the algorithms considered here are multi-agent meta-heuristic methods. These algorithms start with a set of randomly selected candidate solutions of the optimization problem and attempt to improve the quality of the set based on a cost function. According to a series of simple rules, mainly inspired from nature, the existing solutions are perturbed iteratively in order to improve their cost function values. In this section the main rules of the algorithms are briefly summarized.Particle Swarm Optimization (PSO) is a meta-heuristic algorithm which mimics the social behavior of certain species of animals like birds flocking and fishes schooling. This algorithm, for which many modified variants have been proposed, was originally introduced by Kennedy and Eberhart [19]. In canonical PSO the next position of a particle is determined using the particle’s best experience (local best solution) and the whole swarm’s best experience (global best solution). Based on these two sources of information, the velocity vector for the ith particle in iteration k+1 can be formulated as follows:(5)vi,jk+1=χ[ωvi,jk+c1r1(xbesti,jk-xi,jk)+c2r2(xgbestjk-xi,jk)]where,vi,jkis the velocity or the amount of change of the design variable j for the ith particle in kth iteration;xi,jkis the current value of the jth design variable of the ith particle,xbesti,jkis the best value of the design variable j ever found by the ith particle;xgbestjkis the best value of the design variable j experienced by the entire swarm up to kth iteration; r1 and r2 are two random numbers uniformly distributed in the range (0, 1); c1 and c2 are two parameters representing the particle’s confidence in itself and in the swarm, respectively; these parameters, which determine the particle’s inclination toward local and global best solutions, are suggested to be taken as 2 by Kennedy and Eberhart [19];ωis the inertia weight for the previous iteration’s velocity and controls the exploration tendency of the algorithm. In reference [3] which uses this algorithm for the same optimization problems this parameter is defined as:(6)ω=0.4[1+min(cov,0.6)]where cov is the coefficient of variation of the objective functions of swarm particles. The constriction factor parameter χ, which is used to avoid divergence behavior, was originally proposed by Clerc [27] as:(7)χ=22-ϕ-ϕ2-4ϕwhereϕ=c1+c2,ϕ>4In addition to the aforementioned parameters, Eberhart et al. [28] introduced a maximum velocity, Vmax, in order to prevent the particles from leaving the search space. Eberhart and Shi [29] have shown that selecting the value for χ according to Eq. (7) does not eliminate the need for Vmax. Though different values have been suggested for Vmax, suitable values for the parameter seem to be problem dependent. For our problems, we have observed that Vmaxcan be eliminated if the following equation is used for χ:(8)χ=12-ϕ-ϕ2-4ϕwhereϕ=c1+c2,ϕ>4In fact, using Eq. (8) leads to better results than those reported in [3] for the same problems using PSO. After defining the velocity vector, the new positions of the particles are determined as:(9)xi,jk+1=xi,jk+vi,jk+1The general structure of a canonical PSO algorithm is as follows [30]:procedure Particle Swarm OptimizationbeginInitialize parameters;Initialize xi, viand xbestifor each particle i;while (not termination condition) dofor each particle iEvaluate objective function;Update xbestiend iffor each iSet xgbest equal to the best xbestiof the swarm;Use xgbest and xbestito calculate vi;Update xi=xi+vi;Evaluate objective function;Update xbestiend forend whileendMore details on PSO can be found in [19,30].Harmony Search (HS) originally introduced by Geem et al. [20], derives its governing rules form the natural musical performance processes that occur when a musician searches for a better state of harmony. In fact, the process of finding the optimal values of a set of variables in order to optimize an objective function could be considered analogous to a musical improvisation process in which a composer seeks for a pleasing state of harmony by adjusting the pitches of some musical instruments.In HS, every candidate solution is thought of as a state of harmony memorized in a Harmony Memory of size HMS (Harmony Memory Size). When the ith variable of the jth candidate solution is to be determined, there is a HMCR (Harmony Memory Consideration Rate) probability for the variable to be selected from the Harmony Memory. Otherwise the variable will be generated randomly with a probability of (1-HMCR). Moreover, when a variable is chosen from the Harmony Memory, there is a PAR (Pitch Adjustment Rate) probability for it to be adjusted:(10)xi,j=xi,j+bw×uwhere xi,jis the ith variable of the jth solution vector, which is to be adjusted; bw is an arbitrary distance bandwidth for the ith variable; and u is a random number uniformly distributed in the range (−1, 1).Otherwise, the variable will be kept unchanged. The main structure of a HS algorithm is as follows [31]:procedure Harmony SearchbeginInitialize parameters;Initialize Harmony Memory randomly;while (not termination condition) dofor each variable iifrand<HMCRChoose the value for variable i from Harmony Memory;ifrand<PARAdjust the value for variable i;end ifelseChoose the value for variable i randomly;end ifend forAccept the new harmony if better than the worst existing one;Find the current best harmony;end whileendMore details on HS can be found in [20,31].Big Bang–Big Crunch (BB–BC) algorithm, developed by Erol and Eksin [21], is a population-based meta-heuristic optimization algorithm inspired from a theory of the evolution of the universe. Like any other meta-heuristic algorithm randomness and informed use of previously obtained solutions are combined together in order to perform optimization. According to the Big Bang–Big Crunch theory, the universe is formed by particles, randomly distributed in a Big Bang phase, being drawn into order in a Big Crunch phase. Correspondingly, in BB–BC method a Big Bang phase is carried out in order to spread some random candidate solutions in the search space. Then, a Big Crunch phase is performed in which all of the solutions shrink into a single representative point called the center of mass:(11)xc=∑i=1N1fixi∑i=1N1fiwhere xiis a point within the n-dimensional search space; fiis the value of cost function for the ith design included in the population; N is the size of the population generated in the Big Bang phase; xcin the center of mass.When the Big Crunch phase is completed, a Big Bang phase is performed again in order to produce new candidates for the next iteration. These new candidates are generated using a normal distribution around the center of mass of the previous iteration. The standard deviation of this normal distribution decreases as the optimization process proceeds:(12)xjnew=xjc+bw×uwherexjnewis the jth variable of the new solution; bw is an arbitrary distance bandwidth for the jth variable; and u is a random number uniformly distributed in the range (−1, 1). Successive application of Big Bang and Big Crunch phases leads to a gradual convergence. The main structure of BB–BC algorithm is as follows:procedure Big Bang–Big CrunchbeginInitialize parameters;Initialize a population of random particles;while (not termination condition) dofor each particle iEvaluate objective function;end forEvaluate the center of mass;for each particle iGenerate new solutions around center of mass;end forRecord the current best solution;end whileendMore details on BB–BC can be found in [21].Firefly Algorithm (FA), which is based on the flashing patterns and behaviors of fireflies, was introduced by Yang [22,23]. In this algorithm every candidate solution is modeled as a firefly, which gets attracted to brighter ones while at the same time explores the search space randomly. Brightness of a firefly is assumed to be proportional to the quality of the solution it represents. In FA, firefly i will be attracted toward the brighter firefly j according to the following equation:(13)xit+1=xit+β0e-γrij2(xjt-xit)+αεitwhere β0∈[0, 1] is the attractiveness at r=0; rij=∥xi−xj∥2 is the Cartesian distance between the two fireflies; εiis a random vector drawn from a Gaussian distribution; α is the randomization parameter; γ is the light absorption coefficient, which controls the speed of convergence.Naturally, for a given firefly, there could be numerous more attractive fireflies. Then we can either go through all of them via a loop or use the most attractive one [32]. Here, since the optimization problems are quite complex a loop version is used, where moving toward all brighter fireflies is performed. The main structure of a Firefly Algorithm is as follows [33]:procedure FireflybeginObjective function f (xi)Initialize parameters;Initialize a population of random solutions;Define light intensity Iiat xiby f (xi)while (not termination condition) dofor each particle ifor each particle jif (Ii<Ij), Move firefly i towards j;end ifVary attractiveness with distance r via exp[−γ r];Evaluate new solutions and update light intensity;end forend forRank the fireflies and find the current global best;end whileendMore information on FA can be found in [22,23,32,33].Charged System Search (CSS), proposed by Kaveh and Talatahari [24], has its governing rules inspired from electrostatics and Newtonian mechanics. In this algorithm each candidate solution is assumed to be a charged sphere, called Charged Particle (CP). These charged spheres exert electric forces on each other. The force that each particle imposes on the others is determined according to its electric charge:(14)qi=fit(i)-fitworstfitbest-fitworstwhere fit(i) is the objective function value of the ith particle; fitbest and fitworst are the best and worst cost function values among all particles, respectively. In addition to the electric charges, the force that a particle exerts on another one depends on their relative distance, which is defined as a dimensionless quantity:(15)rij=‖Xi-Xj‖‖(Xi+Xj)/2-Xbest‖+εwhere Xiand Xjare the positions of the ith and jth particles; Xbestis the position of the best current CP, and ε is a small positive number to avoid division by zero. It covers the eventuality that the current best record is in the middle point between two charged particles.All better particles attract worse ones, but only some of the worse particles attract better ones. This rule can be mathematically stated as follows:(16)pji=1⇔fit(j)-fitbestfit(i)-fit(j)>rand,or,fit(i)>fit(j)0⇔else.where pjiis the probability of the jth particle being attracted by the ith particle. The resultant electric force Fjon the jth particle can be calculated with the following equation:(17)Fj=qj∑i,i≠jqia3rij·w1+qirij2·w2·pji·(Xi-Xj),w1=1,w2=0⇔rij<aw1=0,w2=1⇔rij⩾aj=1,2,…,Nwhere a is the radius of the charged sphere. It helps the algorithm distinguish global and local search phases as discussed in Ref. [24]. When the resultant forces are determined, the new position for the jth particle can be calculated as follows:(18)Xj,new=randj1·ka·Fjmj·Δt2+randj2·kv·Vj,old·Δt+Xj,old,(19)Vj,new=Xj,new-Xj,oldΔtwhere randj1 and randj2 are two random numbers uniformly distributed in the range (0, 1); mjis the mass of the particle that is taken equal to qj. Δt is the time interval and is taken as unity. kaand kvare two coefficients to control the exploration and exploitation tendencies of the algorithm and are called acceleration coefficient and velocity coefficient, respectively. To maintain more exploration at the early stages of the optimization process and more exploitation at the final stages these two coefficients are defined as follows:(20)ka=c1(1+iter/itermax),kv=c2(1-iter/itermax)where iter is the current iteration number and itermaxis the maximum number of iterations. In [24], c1 and c2 are both suggested to be taken as 0.5. However, different values for these parameters are suggested by Kaveh and Zolghadr [12] for the problems at hand. It should be noted that these parameter values have been determined through trial and error, which could be a time consuming process. The simplified structure of a CSS algorithm is as follows [24]:procedure Charged System SearchbeginInitialize parameters;Initialize a population of random solutions;Evaluate the cost function values and determine the charges of the CPswhile (not termination condition) dofor each particle iDetermine the resultant force acting on the particle;Determine the velocity vector for the particle;Determine the new position for the particle;end forEvaluate the cost function values for the particles in new positions;Record the best particles in Charged Memory;Update the charges of the particles;end whileendCuckoo Search (CS) is a population-based meta-heuristic optimization algorithm developed by Yang and Deb [25,34], which is inspired from parasitic breeding behavior of some cuckoo species that lay their eggs in the nests of host birds of other species. In this algorithm each egg in a nest is considered as an existing candidate solution and a cuckoo egg represents a newly generated one. The algorithm is based on three idealized rules [34]:1.Each Cuckoo lays one egg at a time, and dumps it in a randomly chosen nest;The best nests with high quality of eggs are carried over to the next generations;The number of available host nests is constant, and the egg which is laid by a Cuckoo is discovered by the host bird with a probability of pa in the range of [0, 1].In addition, in CS Lévy flights are used instead of simple random walks i.e. the random numbers used for generation of new solutions are chosen from a Lévy distribution. In each iteration step, every existing solution (nest) is replaced by a new solution (cuckoo egg) produced by Lévy flights from its current positions:(21)nestit+1=nestit+α⊕Lévy(λ)wherenestitis the ith nest’s current position; α is the step size parameter, which should be chosen considering the scale of the problem; the product ⊕ means entry-wise multiplications. Lévy flights essentially provide a random walk while their random steps are drawn from a Lévy distribution for large steps:(22)Lévy∼u=t-λ,(1<λ⩽3)The main structure of a cuckoo search algorithm is as follows [34]:procedure Cuckoo SearchbeginInitialize a population of n host nests;while (not termination condition) doGenerate a cuckoo (say i) randomly by Lévy flights;Evaluate the cost function value for the generated cuckoo (Fi);Choose a nest among n (say j) randomly;if (Fi<Fj) {in a minimization problem}Replace j by the new solution;end ifAbandon a fraction (pa) of worse nests[and build new ones at new locations via Lévy flights];Keep the best solutionsRank the solutions and find the current best;end whileendFor a more detailed description of the CS and a demo implementation of the algorithm with notes on how to generate Lévy flights, see Ref. [34].Ray Optimization (RO) is a meta-heuristic algorithm recently developed by Kaveh and Khyatazad [26]. The algorithm simulates a set of rays of light passing through a boundary between two transparent materials. When a ray enters a darker material, it refracts and its direction becomes closer to the normal of the boundary surface as shown in Fig. 1. In RO, the velocity vectors of the candidate solutions are considered as rays of light. As the optimization process proceeds, these rays of light are gradually refracted towards an origin. The origin is a point defined based on the global and local best solutions for each particle.The first version of the algorithm needs to divide the solution vectors into 2-D and 3-D vectors. Here, a Gram-Schmidt ortho-normalization process is utilized to eliminate this requirement. In Ray Optimization, after initializing the positions of the candidate solutions randomly, the initial velocity vectors are determined using the following equation:(23)Vij′=-1+2randwhereV′ijis the jth component of the movement vector for the ith particle and rand is a random number uniformly selected from the range (0, 1). Then a point named “origin” is defined for each particle toward which the particle itself is supposed to move. This point is defined as:(24)Oik=(itemax+k)GB+(itemax-k)LBi2.itemaxwhereOikis the origin of the ith particle in the kth iteration, itemaxis the maximum number of iterations for the optimization process, andGBandLBiare the global best and local best solutions of the ith particle, respectively.Then the normal vector n is defined using the following equation:(25)nik=Xik-OikXik-Oikwherenik,XikandOikare the unit normal vector, current position and the origin of the ith particle. The incoming vector di(see Fig. 1) for the ith particle is then taken as the movement vector:(26)dik=Vi′kUsing Snell’s refraction law and a series of quite lengthy but not complicated calculations the refracted ray t can now be derived as (for the detailed calculations see [26]):(27)t=-n1-nd2nt2sin2(θ)+ndnt(d-(d.n)n)wherendntis the index of refraction ratio and (.) denotes inner product. Then the velocity vector for the next iteration is taken equal to the refracted vector:(28)Vi′k+1=tikIn order to induce more exploration tendency into the algorithm, each element of the normalized velocity vector can be changed randomly with a probability of stoch (i.e. if an independently generated uniformly distributed random number is smaller than stoch, which is a parameter of the algorithm):(29)Vij′k+1=-1+2randwhere rand is a uniformly distributed random number, which is generated independently for each variable. The direction of the new normalized velocity vector is thus determined. Now, the regular velocity vector can be constructed by multiplication into a coefficient as follows:(30)Vik+1=Vi′k+1norm(Xi-Oi)The new position for the particles is then calculated as:(31)Xik+1=Vik+1+XikIn order to use Eq. (27) in an n-dimensional search space, a Gram-Schmidt ortho-normalization process should be carried out, where vectors n∗ and d∗ are used instead of vectors n and d, respectively:(32)n∗=(1,0)(33)d∗=(d.i∗,d.j∗)where i∗ and j∗ are two perpendicular vectors defined as:(34)i∗=n(35)j∗=d-(d·i∗)i∗d-(d·i∗)i∗The main structure of the Enhanced Ray Optimization algorithm is [26]:procedure Enhanced Ray OptimizationbeginInitialize parameters;Initialize a population of random solutions;Initialize velocity vectors;while (not termination condition) dofor each particle iCalculate the origin (O), the normal vector (n), and the incoming vector (d);Use Gram-Schmidt method and calculate the refracted ray (t);Take the new normalized movement vector (V′) as the refracted ray (t);Change some components of (V′) randomly with a probability of stoch;Convert normalized movement vector to regular movement vector;Add the movement vector to the position of the ith particle;end forEvaluate new objective functions;Update global best and local best solutions if it is necessary;end whileendThis improved PSO algorithm has been proposed by Kaveh and Zolghadr [14] to avoid premature convergence problems occurring in standard PSO. In fact in the standard PSO all of the particles are being attracted towards the best solutions (global best and local best). This means that each particle disregards the experiences of the other ones. This obsession over getting better as fast as possible through the shortest way, which is motivated by selfishness (the particle’s own preference) and tyranny (the global best solution’s dictation), results in some of the better regions of the search space being neglected and leads to premature convergence.In order to address this problem the velocity vector of the democratic PSO is defined as:(36)vi,jk+1=χ[ωvi,jk+c1r1(xlbesti,jk-xi,jk)+c2r2(xgbestjk-xi,jk)+c3r3di,jk]wheredi,jkis the jth variable of vector D for the ith particle. Vector D represents the democratic effect of the other particles of the swarm on the movement of the ith particle. r3 is a random number uniformly distributed in the range (0, 1). Parameter c3 is introduced to control the weight of the democratic vector. Here, vector D for the ith particle is taken as:(37)Di=∑k=1nQik(Xk-Xi)where Qikis the weight of the kth particle in the democratic movement vector of the ith particle and can be defined as:(38)Qik=Eikobjbestobj(k)∑j=1nEijobjbestobj(j)where obj stands for objective function value; objbestis the value of the objective function for the best particle in the current iteration; E is the eligibility parameter and is analogous to parameter P in CSS [24]. In a minimization problem E can be defined as:(39)Eik=1obj(k)-obj(i)objworst-objbest>rand∨obj(k)<obj(i)0elsewhere objworstand objbestare the values of the objective function for the worst and the best particles in the current iteration, respectively. The ∨ symbol stands for union.It can be seen that in Democratic PSO the movement of a particle is decided upon by the majority of the swarm members. According to Eq. (39), all of the better particles and some of the worse particles affect the new position of the particle under consideration. This modification improves the performance of the algorithm in two ways:1.It helps the particles to receive information about good regions of the search space experienced by the other members of the swarm.By letting some low quality particles take part in the movement of the swarm, it enhances the exploration capability of the algorithm.Consequently, premature convergence can be avoided. The pseudo-code for DPSO is as follows:procedure Democratic Particle Swarm OptimizationbeginInitialize parameters;Initialize xi,viand xbestifor each particle i;while (not termination condition) dofor each particle iEvaluate objective function;Update xbestiend iffor each iDetermine eligible particles to take part in democratic vector of ith particle;Use Eq. (36) to calculate vi;Update xi=xi+vi;Evaluate objective function;Update xbestiand xgbestend forend whileendMore details on Democratic PSO are given in Ref. [14].This algorithm, developed by Kaveh and Zolghadr [15], combines some of the features of the PSO and RO to develop a significantly improved meta-heuristic search strategy that allows overcoming premature convergence problems of PSO and RO. Hybridization is hence an attempt to improve exploration capabilities of the parent algorithms. It should be noted that PSRO is substantially different from PSO and RO. In fact, it is much simpler than RO and has fewer parameters to set. The convergence operator is also quite different from that of PSO.Like RO the algorithm starts by initializing some velocity vectors:(40)Vij′=-1+2.randIn Ray Optimization these normalized vectors are then assumed to be rays of light and their refraction as they pass through a boundary between two transparent materials gradually results in convergence. In PSRO, however, there are no rays to be refracted and these vectors simply take care of the random part of the particles’ movements. Moreover, unlike in RO, in PSRO these vectors are produced randomly throughout the optimization process. In this sense these vectors might be better called Random Vectors. In fact this is the source for the explorative nature of the algorithm.The point used as Origin in ERO is used here as the Target Point for each particle:(41)Tik=(itemax+k).GB+(itemax-k).LBi2.itemaxwhereTikis the target point for the ith particle in the kth iteration. As the name suggests, the Target Point is the point toward which the particle is willing to move in absence of randomness. It should be noted that other expressions for the Target Points can be used as well.After the Target Points and the normalized random velocity vectors for all of the particles are determined, the regularized velocity vectors can be obtained as follows:(42)Vi,jk+1=Vi,j′k×Ti,jk-xi,jk×cwhere Vi,j, Ti,jand Xi,jare the jth components of the regularized velocity vector, target point vector, and the current position vector of the ith particle, respectively; ∣.∣ denotes absolute value; c is a scaling factor, which is taken as the square root of the number of optimization variables. Vector V′ is generated randomly in every iteration using Eq. (40). The new position of each particle can be set as:(43)Xi,jk+1=Xi,jk+Vi,jk+1The flowchart of the PSRO algorithm is:procedure Hybridized Particle Swarm Ray OptimizationbeginInitialize parameters;Initialize a population of random solutions;Initialize velocity vectors (random vectors);Evaluate the objective function values for initial solutions;while (not termination condition) dofor each particle iCalculate the target point (T);Generate the random velocity vector (V′);Calculate the regularized velocity vector (V);Update the position of the particle;end forEvaluate the objective function values;Find the current best solution; (Update global best solution);end whileendMore details on the PSRO algorithm are given in Ref. [15].The relative efficiency of the nine meta-heuristic algorithm considered in this study was evaluated by solving five weight minimization problems of truss structures including sizing/layout variables and frequency constraints. For the first four problems, the size of the population was set as 20 particles for all optimizers and the maximum number of iterations was set as 200 and taken as the termination criterion in all cases. For the fifth problem, the population size and the maximum number of iterations were set to 100 and 500, respectively. It should be noted that the total number of analyses is the same for all of the algorithms (population size×maximum number of iterations). For the algorithms which are not formulated originally in terms of iteration concept, iteration is defined as a cycle in which as much analysis as population size is performed. The first three test problems were solved 50 times while the fourth and fifth test problems were solved 25 times in order to evaluate the robustness of the nine algorithms. Different initial populations were used for these independent runs. Table 1reports values of internal parameters set for the different optimization algorithms considered in this study. A diversity index, slightly modified from that used by the present authors in [13], was defined in order to assess the exploration/exploitation behavior exhibited by the each algorithm in the search process:(44)DiversityIndex=1nP∑j=1nP∑i=1nVARGB(i)-Xj(i)Xi,max-Xi,min2where Xj(i) is the value of the ith variable of the jth particle; Xi,minand Xi,maxare the minimum and maximum values of the ith variable, respectively; nVAR is the number of design variables and nP is the number of particles. The mean values for the diversity indices are plotted against iteration numbers for all of the algorithms in different examples. It will be seen that the differences between the algorithms’ performances can be to some extent interpreted by analyzing the differences between their diversity index curves. Optimization runs were carried out in the MATLAB R2009a environment using a 2.80GHz Intel Pentium® 4 processor equipped with 2GB of RAM memory.The first test problem is the planar 10-bar truss structure shown in Fig. 2. This test case was solved by many researchers using a wide variety of optimization methods. The cross-sectional areas of each element were taken as sizing variables and no element grouping was adopted. A non-structural mass of 454.0kg is attached to all free nodes. Table 2summarizes the material properties, variable bounds, and frequency constraints for this example.The optimized designs and the corresponding structural weights found by the different algorithms are compared in Table 3. DPSO converged to the best design in terms of structural weight; FA, BB–BC, PSO, CSS, CS, HS and ERO take the next ranks, respectively. The required number of analyses (iteration number×population size) to obtain the optimal design and the intermediate design less than 0.5 percent heavier than the optimal design are also provided for the nine algorithms in Table 3. A large difference between these two numbers could be a criterion of a desirable performance. It means that the algorithm manages to find a near-optimal solution in the early iterations while it continues searching the search space until the last iterations. It can be seen from Table 3 that PSO, CSS, and PSRO were the fastest optimizers in terms of finding the promising regions of the search space.Fig. 3shows the variation of the diversity index for the best run of each algorithm with respect to the iteration number, while Fig. 4shows the same curves averaged over different optimization runs in order to remove random fluctuations and make them easier to study. The averaged curves can roughly be divided in three groups. For CS and HS the curves maintain a relatively high distance from the horizontal axis at the end of optimization process. This means that the particles are far apart from each other and the algorithms do not perform a proper local search phase. Table 3 shows that the structures found by these algorithms are among the heaviest ones. On the other hand, Fig. 4 shows that PSO and ERO algorithms converge prematurely i.e. these algorithms do not explore the search space adequately and the particles gather in a very small region of the search space hurriedly. In fact, the diversity index curves quickly approached the horizontal axis. Since this test case included a relatively small number of design variables, premature convergence did not affect PSO performance severely. However, ERO performance was significantly affected.Finally, the most desirable trends of variation of the diversity index were obtained for DPSO, FA, PSRO, BB–BC and CSS. High values of diversity are provided in the early stages of the optimization process. As the optimization process continues, the particles focus on more promising regions of the search space in order to perform local search and diversity index values gradually decrease. It should be noted that in these cases a certain amount of diversity is still maintained at the final stages, which shows that the optimization procedure is still in progress.Table 4lists the natural frequencies evaluated for the optimized designs. It can be seen that all algorithms converged to feasible designs. Statistical information on the optimization runs carried out for each algorithm is given in Table 5. In particular, the table reports the number of successful runs (i.e. the independent runs for which the optimized design fully satisfied constraints), the average optimized weight and number of structural analyses and the corresponding standard deviations. It can be seen that DPSO is overall the most efficient algorithm.The second test problem solved in this study was the weight minimization of the planar 37-bar truss structure shown in Fig. 5. This optimization problem included 19 design variables: 14 sizing variables and 5 configuration variables. The lower chord is comprised of bar elements with constant rectangular cross-sectional areas of 4×10−3m2 while all other members are modeled as bar elements grouped in 14 groups to preserve structural symmetry: therefore, there are 14 sizing variables corresponding to the cross-sectional areas of elements included in each group. The y-coordinate of upper-chord nodes must vary symmetrically and are included as configuration variables. A non-structural mass of 10kg is attached to all free nodes of the lower chord. There are three non-linear constraints on the first three natural frequencies. Material properties, frequency constrains and added masses are listed in Table 6.Table 7compares the optimized designs and the corresponding structural weights found by the different algorithms. The lightest weight of 360.56kg was again obtained by the DPSO algorithm which also found the promising region of the search space very quickly. In particular, the intermediate design found by DPSO within only 1380 structural analyses was better than most designs finally optimized by the other algorithms. BB–BC, PSRO, FA and CSS are placed in the next rank with slight differences. Figs. 6 and 7show the best run values and the average values of the diversity indices for different algorithms. According to Fig. 7 the diversity index curves of these algorithms are placed between those of CS and HS from one side and PSO and ERO form the other side. High values of diversity index indicate that the local search phase is not carried out properly in CS and HS. On the other hand, the curves for PSO and ERO show that these algorithms do not perform any search after the 120th iteration i.e. the particles were collected in a very small region of the search space and the algorithms have converged prematurely. Since this test problem is more complicated than the 10-bar truss problem, premature convergence behavior affects the performance of PSO more drastically causing it to place 8th among 9 algorithms.Table 8presents the first five natural frequencies evaluated for the optimized structures. It can be seen that all algorithms converged to a feasible design. Table 9summarizes the statistical information on the total number of successful optimization runs, average optimized weight and number of structural analyses for successful runs and the corresponding standard deviations evaluated for each algorithm. It can be seen that PSRO, DPSO and BB–BC obtained the best average weights that are marginally different. DPSO, BB–BC and CSS were the only algorithms that always satisfied frequency constraints in all optimization runs.The third test problem solved in this study was the weight minimization of the 52-bar dome-like truss shown in Fig. 8. Material properties, frequency constrains and non-structural added masses (i.e. 50kg attached to all free nodes) are listed in Table 10. This optimization problem included 13 design variables: 8 sizing variables and 5 configuration variables. The elements are grouped in the 8 groups listed in Table 11. All nodes can symmetrically move by ±2m from their initial positions. There are two non-linear constraints on the first two natural frequencies.Table 12compares the optimized designs and the corresponding structural weights found by the different algorithms. DPSO again achieved the best compromise between optimized weight and computational cost. Figs. 9 and 10present the trends exhibited by the diversity index of each algorithm with respect to optimization cycles for the best run and the corresponding average values, respectively. It can be seen that the discussion presented in the previous examples hold here as well. The most efficient algorithms in terms of best obtained results, namely DPSO, BB–BC, FA, PSRO, and CSS have their diversity index curves between those of PSO from below and CS, HS, and ERO from above. The change in the nature of ERO’s diversity index curve should be noted. In this example the algorithm joins the group of HS and CS i.e. inadequate local search phase instead of premature convergence. It can also be seen that the curve for PSO does not touch the horizontal axis in this example. This means that the algorithm provides a little amount of diversity, which is seemingly not adequate for performing a suitable local search. These two observations show that the diversity index curves could be problem dependent as well as algorithm dependent.It should be noted that the CSS diversity index curve is not monotonic unlike the curves obtained for DPSO, BB–BC, FA, and PSRO. It also provides less diversity in the last iteration steps compared to the mentioned algorithms. This could be the reason that this algorithm places last between well-performed algorithms. Similar to the previous example the curves for DPSO and BB–BC are very similar.Table 13presents the first five natural frequencies evaluated for the optimized designs. It can be seen that all algorithms converged to a feasible design although Table 14shows that it was relatively difficult in this problem to obtain a feasible solution. DPSO again found the best average weight with the smallest standard deviation. Methods providing more diversity such as HS, CS, ERO, PSRO and FA had more successful runs although the quality of optimized designs was worse than for DPSO. This may be due to the specific search space of this test case and should be the object of an independent study.The fourth test problem considered in this study was to minimize the weight of the spatial 120-bar dome shown in Fig. 11. This problem was solved by Soh and Yang [35] as a combined sizing-layout problem subject to static constraints. Lee and Geem [36] and Kaveh and Talatahari [37] later optimized the dome including only sizing variables. The present authors formulated this problem as a sizing optimization problem with frequency constraints in [12–15]. Non-structural masses are attached to all free nodes as follows: 3000kg at node 1, 500kg at nodes 2 through 13 and 100kg in the remaining nodes. Material properties, frequency constraints and variable bounds are summarized in Table 15.Table 16compares the optimized designs and corresponding structural weights found by the nine algorithms. The best design corresponding to a structural weight of 8886.92kg was obtained by DPSO. Standard PSO converged to a slightly higher weight (i.e. 8891.28kg vs. 8886.92kg) requiring about one third structural analyses (i.e. 1140 vs. 3360). However, DPSO required only 1160 structural analyses to find an intermediate design very close to the optimum. Figs. 12 and 13present the trends exhibited by the diversity index of each algorithm with respect to optimization cycles for the best run and the corresponding average values, respectively. It can be seen that the diversity index curves for all of the algorithms, except for CS, are quite the same. They all provide more amount of diversity at the first stages followed by a gradual decrease, which indicates the local search phase. Also, PSO and ERO algorithms show the same convergence behavior as before. However, since this test problem has only 7 design variables, PSO does not suffer from premature convergence. ERO and CS converged to the heaviest designs. Furthermore, the diversity index curve for the HS algorithm recorded in this test problem is considerably different from the other test cases: in fact, HS converges in the last iteration steps and a suitable local search phase is carried out. This is probably the reason why HS obtained the 4th best result in this example. This observation might indicate that the exploration/exploitation balance of an algorithm is the key factor that determines its performance. A particular algorithm might perform differently on different examples when the forms of the diversity index curves are different.Table 17presents the first five natural frequencies evaluated for the optimized designs: it can be seen that all algorithms converged to feasible designs. Statistical data on optimization runs are given in Table 18.The last test problem considered in this study was to minimize the weight of the spatial 72-bar truss shown in Fig. 14. This problem was solved by Konzelman [6], Sedaghati [38], Gomes [3], and Kaveh and Zolghadr [12,13,39] among others considering an element grouping scheme. In this paper, the element grouping scheme is eliminated in order to study the performance of the algorithms when the number of optimization variables increases. The layout of the structure is kept unchanged during the optimization process. Therefore, this is a sizing optimization problem with 72 design variables. A non-structural mass of 2270kg is attached to each of the uppermost nodes. Material properties, frequency constraints and variable bounds are summarized in Table 19.Table 20compares the optimized designs and corresponding structural weights found by the nine algorithms. It can be seen that the lightest design corresponding to a structural weight of 334.66kg was obtained by BB–BC algorithm. DPSO and PSRO algorithms are placed second and third with structures weighting 338.57kg and 340.13kg, respectively. HS and CSS are the next algorithms with structural weights of 350.55kg and 357.49kg. The structures obtained by PSO, CS, FA, and ERO are considerably heavier. DPSO was considerably faster than BB–BC and PSRO in approaching the optimum design. Figs. 15 and 16present the trends exhibited by the diversity index of each algorithm with respect to optimization cycles for the best run and the corresponding average values for this test problem, respectively. Again, it can be seen that the most efficient algorithms in terms of best obtained results, namely BB–BC, DPSO, PSRO, and HS have their diversity index curves between those of PSO, FA, and ERO from below and CSS and CS from above.This test case is particularly indicative of the effect of internal parameter tuning on the performance of meta-heuristic algorithms and its problem dependency. For example, it has been observed that using the internal parameters of the previous examples (HMCR=0.8 and PAR=0.3) HS does not converge to good results and hence a new set of parameters (HMCR=0.95 and PAR=0.15) was used. The reason could be explained by examining the diversity index curves. Fig. 17shows the variation of the average trend exhibited by the diversity index of HS using different sets of internal parameters. It can be seen that using HMCR=0.8 and PAR=0.3 does not let the algorithm perform an efficient local search (very high values of diversity index at the last stages); HMCR=1 and PAR=0 results in a very premature convergence; the suitable set of parameters, which leads to the algorithm’s best performance (corresponding to a favorable diversity index curve) is somewhere in between. Additionally, it should be noted that the FA algorithm, which tended to obtain relatively good results in the previous test problems, fails to do so in this case. The premature convergence of FA in this problem is reflected in its diversity index curve as shown in Figs. 15 and 16.The above observations suggest that the performance of a meta-heuristic algorithm can be attributed to its exploration/exploitation behavior. Such a behavior is governed not only by the formulation and inherent characteristics of the algorithm, but also by its internal parameters’ values. The optimal values for these parameters seem to be strongly problem-dependent. It can also be seen that the notion of diversity index introduced in this paper could be effectively used for tuning these parameters. A unified approach to parameter tuning of meta-heuristic algorithms using diversity index curves could be the subject of an independent study.While the role of the internal parameters is discussed earlier, the effect of the governing equations might be argued concisely considering four of the algorithms which more or less share a common fundamental structure, namely: PSO, DPSO, ERO, and PSRO.It is well-known that the standard PSO algorithm does not include enough exploration capability and suffers from premature convergence phenomenon. This characteristic could be explained by observing Eq. (5), where each particle merely uses its own experience and that of the best particle to determine its new position. So, metaphorically speaking, it could be said that the decisions made by a particle in a standard PSO are motivated partly by selfishness (effect of the local best solution) and partly by tyranny (effect of the global best solution). This makes the particles ignore more promising regions of the search space and results in a premature convergence. In response to this shortcoming, the authors have developed a democratic PSO (DPSO) in Ref. [14], where Eq. (5) is replaced by Eq. (36) allowing a particle to obtain information from a wider variety of sources. As it can be seen both in Ref. [14] and the present paper, such a democratic way of decision making considerably improves the exploration capabilities of the algorithm. Eq. (36) helps the algorithm maintain a proper balance between exploration and exploitation tendencies and converge to high quality solutions. Comparison of the diversity index curves of the two algorithms verifies the abovementioned discussion.In PSRO algorithm a target point is defined for each particle based on its local best and global best solutions toward which the particle is supposed to move in the absence of randomness. While this strategy is primarily the same as PSO, there is important difference: PSRO enjoys a kind of concealed mutation phase. According to Eq. (42), sinceVi,j′kis a random number in the range (−1, 1), a particle might move in the exact opposite direction of the target point in some dimensions. This means results in involving some unlikely solutions that would not be present in the next generation based on mere objective function consideration. By using this mutation mechanism PSRO considerably improves its exploration capabilities compared to PSO. Moreover, Eq. (41) defines the target point in a way that is exactly consistent with the previously discussed favorable diversity index curve. At the early stages of the optimization process local best solutions are considered to have the same value as the global best solution resulting in an explorative behavior. As the optimization process continues the global best solution gains more and more relative weight and a gradual convergence happens.Although ERO algorithm shares both of the above characteristics with PSRO, there exists an additional convergence operator indicated by Eq. (27). In fact, the velocity vectors utilized in PSRO algorithm are once again inclined toward the origin point increasing the exploitation tendency of the algorithm. This additional exploitation tendency seems to counterbalance the effect of the abovementioned mutation phase leaving the algorithm prone to premature convergence. Increasing the stoch parameter value might be helpful since it increases the chance for the velocity vectors of the particles being mutated using Eq. (29), which means that the additional convergence operator is eliminated. Choosing stoch=1 eliminates the convergence operator completely and thus ERO would perform like PSRO.Table 21presents the first five natural frequencies evaluated for the optimized designs: it can be seen that all algorithms converged to feasible designs. Statistical data on optimization runs are given in Table 22.Nine population-based meta-heuristic algorithms were compared in order to evaluate their suitability for sizing/layout problems of truss structures subject to frequency constraints. A diversity index was introduced in this research to study the positions of the particles during the search process. The average values of these diversity indices were plotted against optimization iterations and the performance of each algorithm was interpreted on the basis of these curves.It appears that the diversity index should be large in the early iterations and decrease gradually as the optimization proceeds. DPSO, PSRO and BB–BC could always satisfy such a requirement thus obtaining high quality results. It is believed that diversity index curves can play a major role in understanding meta-heuristic algorithms. For example, they might be used for assessing the efficiency of an algorithm regardless of its specific formulation, detecting phenomena like premature convergence and instability, and tuning internal parameters of the search engine. The diversity index concept could also lead us to develop new meta-heuristic algorithms or efficient hybrid meta-heuristic algorithms.

@&#CONCLUSIONS@&#
