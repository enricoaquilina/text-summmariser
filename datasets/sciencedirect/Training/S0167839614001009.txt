@&#MAIN-TITLE@&#
Subdivision surface fitting to a dense mesh using ridges and umbilics

@&#HIGHLIGHTS@&#
The natural ridge-joined connectivity of umbilics and ridge-crossings is used as the connectivity of control mesh for subdivision.Preserving and aligning with salient features.Curvature sensitive distance metric for automatic construction of connectivity.

@&#KEYPHRASES@&#
Subdivision surface fitting,Feature alignment,Ridges,Umbilics,Hausdorff distance,Principal curvature vector,

@&#ABSTRACT@&#
Fitting a sparse surface to approximate vast dense data is of interest for many applications: reverse engineering, recognition and compression, etc. The present work provides an approach to fit a Loop subdivision surface to a dense triangular mesh of arbitrary topology, whilst preserving and aligning the original features. The natural ridge-joined connectivity of umbilics and ridge-crossings is used as the connectivity of the control mesh for subdivision, so that the edges follow salient features on the surface. Furthermore, the chosen features and connectivity characterise the overall shape of the original mesh, since ridges capture extreme principal curvatures and ridges start and end at umbilics. A metric of Hausdorff distance including curvature vectors is proposed and implemented in a distance transform algorithm to construct the connectivity. Ridge-colour matching is introduced as a criterion for edge flipping to improve feature alignment. Several examples are provided to demonstrate the feature-preserving capability of the proposed approach.

@&#INTRODUCTION@&#
Fitting a sparse and smooth surface that approximates dense data is a desirable goal in applications such as compression, recognition, and reverse engineering. The simplified surface models or data are obtained for convenient downstream processing, e.g. surface design, animation and manufacturing. Commonly, there are two types of surfaces which are used to fit dense data: NURBS (Non-Uniform Rational B-Spline) and subdivision surfaces. Ma et al. (2004), Lavoué et al. (2007), Panozzo et al. (2011) fit these surfaces to dense meshes. Sometimes one is interested in fitting pure geometric surfaces. For example, the first author's previous work (Ma and Cripps, 2011) fits generalised Cornu spirals to dense surface points to preserve the original shape. Most existing methods fit B-spline surfaces to 3D points with simple topological type. In the case of complex topology, it is an extremely difficult task to handle continuity conditions among neighbouring surfaces. Subdivision surfaces can easily represent arbitrary topology in a compact form and achieve the same accuracy as NURBS.Subdivision surfaces have recently become of great interest due to their high potential in rendering and shape design. A principal achievement in shape design is that subdivision surfaces are now compatible with the industry standard NURBS thanks to the work of Cashman et al. (2009) generalising the schemes of Catmull and Clark (1978) and Doo and Sabin (1978) to general degrees. The scheme of Loop (1987) is a popular subdivision scheme for triangulations. NieBner et al. (2012) achieve unprecedented quality and speed in rendering by fast evaluation of subdivision surfaces on GPUs (Graphical Processing Units). Subdivision surfaces ideally suit the paradigm of hardware tessellation on GPUs. Only the vertices of a coarse model need to be animated; the GPU can amplify the coarse geometry on-the-fly with very little memory bandwidth to produce a dense tessellation of the surface. Panozzo et al. (2011) predict that subdivision-based modelling is expected to replace polygonal modelling even for real time applications.This paper proposes a new approach to fit subdivision surfaces to dense meshes. Most existing algorithms aim at obtaining a mesh with a good quality of accuracy and regularity. However, we focus on preserving the features, since the convergence is improved by the alignment of the connectivity with salient features. The coarse control mesh is constructed from ridges, umbilics, and ridge-crossings of the original dense mesh. Ridges are geometrically and perceptually salient surface features and are used for shape recognition as said in Ohtake et al. (2004). Thirion (1996) states that these features can characterise the overall shape of the original data and are successfully used in image processing for registration. They also constitute a natural connectivity, since ridges start and end at umbilics and cross at ridge-crossings as stated in Porteous (1994). The natural connectivity matches the requirement of connectivity for a control mesh. Hence, we use these features to construct a coarse control mesh of subdivision surfaces to fit the overall shape of the original dense mesh.The flow of the proposed approach is: First, ridges, umbilics, and ridge-crossings are extracted from the input dense mesh. Second, the significant features are filtered. Then, a connectivity of the feature points is constructed and its alignment with ridges is improved. Finally, a coarse control mesh is constructed and a subdivision surface is generated to fit the original dense mesh.The main contributions of the approach are:•The natural ridge-joined connectivity of umbilics and ridge-crossings is used as the connectivity of control mesh for subdivision.A metric of Hausdorff distance including curvature vectors is proposed and implemented in a distance transform algorithm for connectivity construction and feature alignment. An accurate arc-length estimation formula is derived to define the metric.A criterion of ridge-colour matching is introduced for edge flipping to improve feature alignment.The proposed algorithm will work on noisy data as well, thanks to the noise filtering capability of the adopted feature filtering approaches (Ohtake et al., 2004; Cazals and Pouget, 2005), as discussed in Subsection 3.4. Furthermore, since the proposed method aims to preserve the salient features using as few points as possible, detailed features and noisy data will not have much effect on the fitting quality.The paper is structured as follows. In Section 2, previous related work is reviewed. In Section 3, we discuss why we choose ridges and umbilics, and how to extract and filter such features. Construction and optimisation of connectivity are introduced in Section 4. Section 5 derives the metric of Hausdorff distance including curvature vectors. The calculation of control mesh is presented in Section 6. In Section 7, we demonstrate and evaluate the proposed method on several examples. Finally, we give concluding remarks.Subdivision surface fitting has been investigated by many researchers. Most existing methods can be classified as follows: mesh simplification, parametrisation, face clustering, feature extraction and others. Usually, a two-step process is adopted. Firstly, a coarse connectivity is constructed. The second step involves optimising the geometry and regularity of the connectivity. In this review, we will focus on methods that preserve features and alignment.Hoppe et al. (1994) simplify a dense triangle mesh and construct a control mesh for Loop subdivision by optimising vertex positions. Lee et al. (2000) extend this approach using displacement mapping to approximate projectability during simplification. Suzuki et al. (1999) inversely refine an interactively defined initial control mesh. The control mesh is constructed using an iterative local approximation. Kanai (2001) simplifies the dense mesh using a modified QEM method. Ma et al. (2004) distinguish different types of vertices and edges during the simplification process to preserve sharp features. Panozzo et al. (2011) use fitmaps to achieve adaptive mesh simplification. Usually, following simplification, optimisation steps are used to optimise the geometry or connectivity using distance minimisation, collapsing, splitting or swapping edges of the control polyhedron. Approaches based on mesh simplification are easy to implement by using an established mesh simplification algorithm. However, they may need extensive computing time due to the large amount of data and geometric optimisation. It is also not clear how these methods align to salient features.Parametrisation methods fit parameter equations for a selected domain and construct the coarse control mesh from these domains. Ma and Zhao (2002) interactively define a topological model for parametrisation and fit Catmull–Clark surfaces using linear least squares. Boier-Martin et al. (2004) introduce a method for computing parametrisations of triangulated manifolds over quadrilateral domains. The creation of the base domain is performed through a combination of clustering methods which control the shape and flatness of clusters. Lai et al. (2006) use feature sensitive parametrisation to allocate more parameter space to highly curved feature regions, so that more control points will be provided in those regions. Li et al. (2006) consider global parametrisation and quad domain remeshing to fit T-splines. Parametrisation methods can produce quality meshes but may need interactive definition of the topology model. They are suitable for simple topology cases, but can find complex topology objects difficult to handle.Clustering algorithms are proposed by Cohen-Steiner et al. (2004), and driven by alignment of face normals, resulting in coarse but irregular meshes. Marinov and Kobbelt (2005) use a similar face-merge method to compute a coarse polygonal mesh, taking into account normal projectability. They compute a normal displacement map from the resulting control mesh. Such methods consider the geometric properties of surface normals, but without considering curvature which characterises the geometric features. Reverse subdivision is a multiresolution method to generate a sparse surface to fit the original dense mesh. Sadeghi and Samavati (2011) construct smooth reverse of the Loop and Catmull–Clark subdivision surfaces, balancing the two optimisation goals of finding a good approximation of the fine points and producing coarse points with minimum energy.Feature-based methods construct a coarse control mesh by aligning the extracted salient features. Marinov and Kobbelt (2005) integrate curvature lines for meshing of isotropic regions. The QuadCover method proposed by Käberer et al. (2007) uses principal curvature frames to compute global parametrisations. Ling et al. (2008) fit sharp features by iteratively solving a nonlinear least squares problem based on the squared distances from the input mesh vertices to the fitted subdivision surface. Lavoué et al. (2007), Lavoué and Dupont (2009) extract features by segmentation and using semi-sharp subdivision surfaces to fit sharp features. Bommes et al. (2009) introduce cross field symmetry to formulate a mixed-integer problem for quadrangulation. Such methods achieve very good results in terms of regularity of the mesh, but they need interactive definition of feature and topological constraints. These methods have the advantage of feature preservation and potential for complex topology cases. However, how to choose appropriate features and align to the features are important issues.In the above literature, most previous works aim at obtaining meshes with good surface shape and regularity. Few address feature preservation and alignment when constructing a control mesh. The typically used features have limitations in characterising salient edges and constituting topology. Basically, these features are based on surface normals, curvature lines and special subdivision rules. Surface normal based features lack curvature and topological information. Lines of curvature may not align to salient edges, e.g. the curvature lines of a twisted rounded cube do not align with the twelve salient edges of the cube.We consider umbilics and ridges as the salient feature points and lines to characterise the shape of the input mesh. Ridge lines have maximum principal curvature along the corresponding principal directions. Umbilics are points with the same surface normal curvatures in all tangent directions. It is important for the connectivity of a reconstructed mesh to follow the salient features of an object. The main reason is given by D'Azevedo (2000): the convergence is improved by such alignment, for both remeshing and fitting. We discuss ridges and umbilics in detail in the following section.We choose to place the images of control points at umbilics and ridge-crossings, because we want the edges to follow features in the surface. It is highly plausible that ridges of a surface give a good characterisation of the features, and ridges join umbilics. This section discusses why ridges and umbilics are chosen as the features to construct a control mesh. We briefly review the properties of these features; see Hallinan et al. (1999) and Cazals and Pouget (2005a) for details. These properties illustrate that ridges and umbilics can characterise the overall shape and constitute a natural connectivity.Given the principal directions x and y and the normal vector at a non-umbilic point, a surface can locally be represented using the Monge form:z=12(k1x2+k2y2)+16CM(x,y)+124∑i=04cix4−iyi+h.o.t,wherek1andk2are the maximum and minimum principal curvatures, respectively, andCM(x,y)=b0x3+3b1x2y+3b2xy2+b3y3is referred to as the Monge cubic. The Taylor expansions of principal curvatures along their principal directions arek1(x)=k1+b0x+P12(k1−k2)x2+h.o.t,k2(y)=k2+b3y+P22(k2−k1)y2+h.o.t,whereP1=3b12+(k1−k2)(c0−3k13),P2=3b22+(k2−k1)(c4−3k23).The Monge form provides a concise mathematical expression for the definition, properties, and extraction of ridges and umbilics.One reason for choosing ridges to construct the control mesh is that they are geometrically and perceptually salient surface features and are used for shape recognition (Ohtake et al., 2004). Thirion (1996) states that ridges and umbilicus are a decomposition of the curved surfaces as natural as the decomposition of the polyhedral surfaces into faces, edges and vertices. These features have been successfully used in 3D image processing registration. This is due to the fact that ridges are points of extrema of principal curvatures along their curvature lines. A ridge point is defined by:Definition 1A non-umbilical point (k1≠k2) is called a ridge point if the extremality coefficientb0=dk1/dxvanishes orb3=dk2/dyvanishes.Ridges can be classified into several types. To simplify notation, we assign a colour to each type. A ridge is called•maximum elliptic (red) ridge ifb0=0andP1<0;maximum hyperbolic (green) ridge ifb0=0andP1>0;minimum elliptic (blue) ridge ifb3=0andP2<0;minimum hyperbolic (yellow) ridge ifb3=0andP2<0;maximum crest ridge ifb0=0andP1<0and|k1|>|k2|;minimum crest ridge ifb3=0andP2<0and|k2|>|k1|.We remark that the maximum/minimum and colour assignments depend on the orientation of the normal of the surface. However, this ambiguity plays no role in our algorithms.Ridges on a triangular mesh can be extracted using Cazals and Pouget's (2005) marching method due to its robustness. Firstly, the Monge forms of the original vertices are estimated using jet fitting introduced by Cazals (2008), getting the estimated value ofb0andb3for all vertices. For boundary points, their curvatures can be estimated by our circle fitting method presented in Ma and Cripps (2007). Then, a marching method is used to extract the ridges, as shown in Fig. 2. For the two vertices of an edge, if the signs of the twob0are different, the edge is marked as a ridge-passing edge. Ridges can be extracted by connecting the proportional internal points of all the adjacent ridge-passing edges.Note that there are alternative methods to extract ridges on a mesh: Hildebrandt et al. (2005) use discrete differential geometry and externality smoothing method, Kim and Kim (2006) employ modified moving least square method, Clémençon et al. (2008) propose integrating a first-order ordinary differential equation, and Yoshizawa et al. (2008) use focal surface based finite difference scheme. These methods can also be used to extract ridges from meshes. However, the adopted method is accurate due to the high order of jet fitting and robustness of the marching method. It can extract both feature lines and feature points, i.e. ridges and umbilics, and has been implemented into Computational Geometry Algorithms Library (CGAL, 2013) to give convenient application.The definition and examples of ridges demonstrate that ridges are geometrically salient features and natural decomposition of the curved surfaces. These features have been successfully used in shape recognition and registration. Hence, a control mesh based on ridges can align with the salient features and preserve the overall shape of the original dense mesh.Another reason for choosing umbilics and ridges is that their topological relationship provides a natural connectivity for control meshes. Ridges start and end at umbilics, points where the two principal curvatures are equal in value, i.e.k1=k2. Umbilics can be classified in terms of their configuration of ridges, determined by the Monge cubic.Definition 2Generic umbilics are of two types:•Elliptic or 3-ridge umbilic. The Monge cubic has three different real factor lines and three ridge lines meet at the umbilic.Hyperbolic or 1-ridge umbilic. The Monge cubic has only one real factor line and one ridge passes through the umbilic.Additionally, ridges cross transversally at generic umbilics and change from a minimum ofk1to a maximum ofk2.To summarise the topological relationship of ridges and umbilics, they have the following generic properties:•Ridges start and end at umbilics, or form closed loops;A generic umbilic is either a 1-ridge umbilic (hyperbolic) or a 3-ridge umbilic (elliptic);Ridges of the same type (colour) do not cross, they only meet at 3-ridge umbilics. Two ridges of different types (colours) may cross at so-called ridge-crossings;A ridge contains an even number of turning points at which the ridge changes from elliptic to hyperbolic.Umbilics on a triangular mesh can be extracted using the minimum value of|k1−k2|as given in Cazals and Pouget (2005). An example of extracted ridges and umbilics on a Catmull–Clark subdivision surface of a car model is shown in Fig. 3. It illustrates that elliptic ridges are salient features. However, hyperbolic ridges also play an important role. Note that in this paper the features and their connectivity are not obtained by tracing, i.e. the technique studied in Ray and Sokolov (2013). Since we aim to get a regular and feature aligned connectivity for subdivision, a tracing technique is not convenient to achieve that goal. The feature points and lines in Fig. 3 are extracted using a jet fitting and marching method (Cazals and Pouget, 2005; Cazals, 2008), which has already been implemented in CGAL (2013). The feature points will be connected using a modified distance transform algorithm to construct a triangulation connectivity. Then the alignment with salient feature lines will be improved using edge flipping and ridge colour matching. The detailed process will be given in Section 4.We illustrated that ridges, umbilics, and ridges-crossings constitute a natural connectivity which can be used to construct a coarse control mesh for subdivision. Hence, ridges and umbilics are chosen as the features for subdivision surface fitting.For real scanned objects, the configuration of umbilics and ridges may not match that of a smooth generic surface, especially for meshes with sharp features or featuring degenerate regions. For example, for a plane or a cylinder whose principal curvatures are constant, all points are ridge points. In such cases, sharp ridges or prominent ridges should be filtered.We use Ohtake et al.'s (2004) metric of strength to filter the salient ridges. The strength is defined by the integral ofk1along a ridge line or a line connecting two feature points, and use the trapezoid approximation of the integral. Note that strength is a scale-independent threshold specified by the user. Similarly, strength is also used to filter ridge-crossings. Umbilics are filtered by threshold of curvature value.Fig. 4shows the feature filtering for the rocker-arm and Stanford bunny models. Note that the thresholds need to be interactively tuned by the users. Different models will have different thresholds. For the bunny model, the strength threshold is set to 1.0 and the curvature threshold 0.1. For the rock-arm model, the strength threshold is set to 10.0 and curvature threshold to 1.0. It is illustrated that the filtered features characterise the overall shape of the original meshes with noise being filtered out.For moderate noisy input meshes, the noisy features will be removed by the filtering process. The extracted initial features may include small features caused by noise in the mesh. The feature filtering process uses the metric of strength defined by the integral of curvatures along a feature line. Noisy features are often short and have low strength measure, so they will be filtered out.Because we are looking for a triangulation, there is a straightforward solution. We determine the Voronoi tessellation of the feature point set (umbilics and ridge crossings) and then take the dual. A distance transform algorithm starting from the feature points can give the Voronoi regions on the original mesh corresponding to the feature points as stated in Guan and Ma (1998). The dual of this is a candidate connectivity. A distance transform algorithm is driven by a suitable metric. In our approach, we introduce a metric based on Hausdorff distance that also takes into account curvature vectors. Details of how to derive the metric and its properties are given in Section 5. Since the generated connectivity may not always align with the filtered ridges, a colour matching and edge flipping method is introduced to improve ridge alignment.The distance transform maps each point into its shortest distance to points of interest as discussed in Fabbri et al. (2008). In our case, the interested points are the extracted and filtered umbilics and ridge-crossings. It is a useful tool in computational geometry and has many applications in generating Voronoi diagrams. We use the distance transform algorithm, also known as the grass-fire algorithm, to find the nearest feature points for each vertex on the original 3D dense mesh. A priority queue is implemented in the algorithm to achieve linear complexity. It is a very efficient way to find the Voronoi tessellation of the feature points.One way to think about the algorithm is to first imagine that foreground regions on the 3D dense mesh are made of some uniform slow burning inflammable material. Then consider simultaneously starting a fire at all feature points and letting the fire burn its way uniformly around the mesh. Then the source of the fire first reaching a vertex is the nearest feature point of the vertex. If we set fires simultaneously at the feature points on a sphere, these fires will meet each other at some edges which constitute a Voronoi diagram on a 3D surface. All the vertices in a Voronoi cell have nearest distances to the feature point in the cell. Algorithm 1gives the implementation of distance transform to construct the triangulation connectivity of feature points on a dense mesh.The dual of a Voronoi tessellation is normally a triangulation. The only case where it does not occur is when four or more regions meet in a single place. However, this is neatly resolved by the fact that each triangle can only have three source seeds. Thus a place where four (or more) regions meet is represented by two (or more) triangles. Thanks to geodesic distance metric implemented in the distance transform algorithm, the 3D Voronoi tessellation can be mapped to a 2D Voronoi tessellation. There will be no nested case, e.g. region A is enclosed by two regions B and C.What we have to do is to create an output triangle wherever there is an original facet whose three vertices are labelled with three different feature points as sources. This is created by looping over all the facets of the input mesh. The output triangles make up an initial connectivity of all the feature points. This connectivity is further improved to align better with features.An initial connectivity has been constructed using a modified distance transform algorithm to connect the feature points. In order to improve the alignment of the connectivity with significant ridges, edge flipping based on ridge colour matching is introduced.Each feature point has one or more ridges passing through. These ridges may have different types represented by different colours. Each feature point is associated with colours of the ridges passing through it. For example, if two neighbouring feature points have one colour matching there may be a ridge connecting them; if they don't have any matching colours there should be no ridge connecting them; see Fig. 5.In the initial connectivity, we consider one edgep1p2shared by two triangles, as show in Fig. 6. If the two verticesp1,p2of the edge have no colour matching and the other two verticesp3,p4have matching colours, then we swap the edgep1p2top3p4.There is also a priority of the coloursred>blue>yellow>green, which can be used to choose the priority when two connections intersect each other as it respects the expected saliency of a ridge. This situation can occur in estimated features from noisy data.A colour coding method is introduced to represent the priority of colour. A four-bit binary number is used to represent the four ridge colours. Red, blue, yellow and green are represented by1000,0100,0010and 0001 respectively. The code of a feature point is represented by the sum of codes of the ridges passing through the point. For example, the ridge colours at point p of Fig. 5 left are red and blue, so the colour code of p is1000+0100=1100.The colour matching of a pair of feature points is measured by the value of ‘logic and’ of the colour codes of the two points. The value is named ‘The matching value’. Zero means no colour matching. Positive means some colours match. The higher the matching value, the higher probability the two points should be connected. For example, in the left of Fig. 5, the matching value of points p and q is ‘1100 logic and0011=0000’. There is no colour match, so the two points should not be connected. In the right of Fig. 5, the matching value of points p and q is ‘1100 logic and1001=1000’. The matching colour is red, so the two point should be connected.Matching value is used as the criterion in edge flipping to improve the alignment with salient ridges. Algorithm 2gives the implementation of edge flipping and ridge colour matching for the initial connectivity to improve feature alignment.We remark that there are alternative curvature-driven criteria for edge flipping. Li et al. (2006), Lai et al. (2010) align with another criterion, curvature directions, for connectivity optimisation. Here, we are interested in alignment with ridges as discussed above.Several metrics can be used in the grass-fire algorithm to construct the connectivity, e.g. mesh distance, unwrapped Euclidean distance, and geodesic distance on the mesh. Since the vertices of the mesh lie on some smooth surface, these distances are not accurate to approximate the surface geodesic distance and may bring self-intersections to the connectivity. An accurate estimation of geodesic distance is needed for the grass-fire algorithm.We introduce a modified Hausdorff distance including curvature vectors to estimate the geodesic distance between two vertices. The introduced metric works not only on meshes but also on point clouds, since it is independent of connectivity. The geodesic distance can be directly calculated from the estimated principal curvature vectors at the vertices. In the present work, the differential geometric properties have already been estimated during the stage of feature extraction.We note that there are alternative approaches to geodesic distance estimation on meshes (Surazhsky et al., 2005; Bose et al., 2011; Aleksandrov et al., 2010). They can give bounded approximation of geodesic distance in some order of efficiency, but they are graph-based and only apply on polyhedral surfaces. The introduced geodesic distance estimation is suitable for both polyhedral surfaces and point clouds.In our estimation, it is assumed that the two vertices in question lie on an unknown smooth surface and are close enough so that they can be expressed by each other using a single Taylor series. For example, two adjacent feature points match this assumption. We start by estimating the arc-length between two points on an unknown smooth planar curve.As shown in Fig. 7, given two close points p and q and their estimated curvature vectorskpandkqon a smooth planar curve, we derive a formula to estimate the arc-length between the two points. It is assumed that p and q are close enough so that they can be expressed using Taylor series(1)q=p+stp+s22kp+O(s3),(2)p=q−stq+s22kq+O(s3),from which it follows that(3)2(q−p)=s(tp+tq)+s22(kp−kq)+O(s3).Approximating the squared arc-lengths2by the squared chord lengthl2gives2(q−p)≈s(tp+tq)+l22(kp−kq)+O(s3)and thuss(tp+tq)≈2(q−p)−l22(kp−kq)+O(s3).Taking norms on both sides yields(4)‖s(tp+tq)‖≈‖2(q−p)−l22(kp−kq)+O(s3)‖.Let θ be the angle between unit tangent vectorstpandtq. Then‖tp+tq‖=2cos⁡θ2and substituting into (4) gives(5)s≈1cos⁡θ2‖(q+l24kq)−(p+l24kp)‖.This formula gives second geometric order estimation of arc-length between two adjacent points, given their estimated curvature vectors. It implies that the arc-length can be approximated as: firstly, the two points are transferred along their curvature vector with a displacement ofl24‖k‖, which is related to their second order properties (curvature vector); then the distance between their new positions is scaled by1/cos⁡θ2, which is related to their first order properties (tangent vector). The resulting distance is the approximated arc-length between the two points.In a similar way, we can estimate the shortest arc-length between two adjacent points on a surface mesh. Theoretically, normal curvature vectors corresponding to the tangent direction along the two points are used to estimate geodesic distance. However, estimation of normal curvature vectors requires estimation of principal directions which are unstable near umbilics. We derive a simple formula to estimate geodesic distance directly using principal curvature vectors, following (5).Note that principal curvature vectors are different from principal directions. Principal directions lie in tangent plane while principal curvature vectors are along the surface normal, although both of them can use the magnitude of principal curvatures. Following formula (5), we use principal curvature vectors to estimate the geodesic distance between two adjacent points on a surface mesh.At a point on a surface, there are two principal curvature vectors which can be treated as a set of two elements. Hausdorff distance is the appropriate tool to measure the distance between two sets. The symmetric Hausdorff distance,DH(A,B), between two sets A and B is defined by:DH(A,B)=max⁡(dH(A,B),dH(B,A)),wheredH(A,B)=maxa∈A⁡minb∈B⁡d(a,b)andd(,)represents a more familiar metric, e.g. the rectilinear distanceL1, the Euclidean distanceL2, or the maximumL∞metric. The Hausdorff distance measures the discrepancy between any element in one set and all elements in the other set. This is used to measure the distance between pairs of principal curvature vectors.Inspired by formula (5), settingλ=l24cos⁡θ2and using the notation of Fig. 8, we introduce the modified Hausdorff distance(6)DH=1cos⁡θ2max⁡{max⁡(min⁡(d1,d2),min⁡(d3,d4)),max⁡(min⁡(d1,d3),min⁡(d2,d4))}.Substitutingdiby formula (5), the geodesic distance between two points on a surface mesh can be estimated by(7)s≈1cos⁡θ2max⁡{maxi=1,2⁡minj=1,2⁡‖(q+l24kqi)−(p+l24kpj)‖,maxj=1,2⁡mini=1,2⁡‖(q+l24kqi)−(p+l24kpj)‖}.This estimation can achieve second order geometric accuracy. It directly uses principal curvature vectors to weave a complex estimation of normal curvature vectors near umbilics. The implementation of Hausdorff distance can solve the problem of which curvature vector at the second point corresponds to which at the first. This metric is used in the grass-fire algorithm.The introduced metric has the potential to improve the alignment of the connectivity with ridge features, since it takes into account curvature information. Note that geodesic distance can be calculated by some practical anisotropic geodesy, e.g. (Campen et al., 2013) using short-term vector Dijkstra algorithm. Similar results can be achieved using isotropic remeshing (Lai et al., 2007), which re-samples the points by minimising an energy function of geodesic distance and connects these points using feature-sensitive local parametrisation. However, our approach directly adopts umbilics and ridge-crossings as the re-sampled feature points. We reconstruct the connectivity using distance transform based on the proposed Hausdorff distance metric to achieve feature alignment.With△kpq=kq−kp, Eq. (5) can be rewritten ass≈1cos⁡θ2‖q−p+l24△kpq‖.We can observe that the arc-length is determined by the term△kpqfor a given chord lengthl=‖q−p‖, since θ can be calculated from curvature vectors. It means that, for two given points, the estimated arc-length is determined by the variation of curvature vectors not only by curvature values.Consequently, two points on a ridge are more likely to be connected than two points on either side of the ridge if they have approximately the same chord length. The reason is that points on a ridge have lower variation of principal curvatures, hence smaller estimated geodesic distance.As shown in Fig. 9, verticesB,Dlie on a ridge andA,Clie on either side of the ridge with the same chord length‖BD‖=‖AC‖. Whether the connection should be BD or AC is determined by the variation of curvature vectors△ki,BD,△ki,AC,i=1,2. SinceB,Dare ridge points with zero variation of principal curvature, it is more likely that△ki,BD<△ki,ACandsBD<sAC. Thus,B,Dare more likely to be connected thanA,Cand the connection is aligned with the ridge.We note that the alignment with ridge happens when the geometric properties of BD and AC are similar. If there is a big difference‖BD‖≫‖AC‖, the connection will cross the ridges.In order to illustrate the proposed Hausdorff distance, we apply it as the metric for the grassfire algorithm introduced in Section 4.1 and produce the distance field. Then, we compare the distance field with that produced by the metric of unwrapped Euclidean distance.As shown in Fig. 10, (a) and (b) are the distance fields generated by the unwrapped Euclidean distance and the proposed Hausdorff distance respectively on the Stanford bunny model. The centers of green regions have zero distance values and they are fire sources. The fire sources are extracted feature points, i.e. umbilics and ridge-crossings. The purple regions construct the Voronoi diagram of the feature points. The green regions in Fig. 10(b) are ‘fatter’ than those in Fig. 10(a) along the valley between the top leg and the body. Similarly, on the face, the green regions in Fig. 10(b) are ‘fatter’ than those in Fig. 10(a) along the valley of neck. These illustrate that 10(b) may have better feature alignment capability than 10(a), since the proposed Hausdorff distance metric takes into account curvature information.The proposed metric has the potential to improve alignment with salient features. Fig. 11(a) and (b) illustrate the connectivities produced by the unwrapped Euclidean distance metric and the proposed Hausdorff distance metric respectively. Note the ridge areas at the top of the ear, along the connection between the leg and the main body, the connection between the leg and the feet, and the connection between the tail and the main body. The green edges in Fig. 11(a) show that the connections produced by Euclidean distance cross the ridges in those areas. The red edges in Fig. 11(b) show that the connections produced by the proposed distance align with the ridges in those areas.For the sake of completeness, we briefly review the Loop subdivision scheme developed in Loop (1987). In particular, we focus on limit point stencils as they are used in our algorithm to map feature points on the input surface to the vertices in the control mesh. Connectivity remains unchanged.Given a triangular mesh, the subdivision process successively refines this mesh, resulting in a smooth limit surface. A vertex on the control mesh converges to a pointv∞on the limit surface. Using eigenvalue analysis, one can show that this limit point is given byv∞=(1−nβ)v+β∑j=1nvj,where thevjare the neighbours of v in the control mesh, andβ=8α3+8nαwithα=1n(58−(38+14cos⁡2πn)2)forn>3andα=316ifn=3.Calculating control vertices from limit points is a reverse process of calculating limit points. Treating the filtered feature points, umbilics and ridge-crossings, as the limit pointsv∞of a subdivision surface, the control vertices v of the subdivision surface can be found by solving the linear system(1−n1β)v1+⋯+βvp+⋯=v1∞,⋯+(1−n2β)v2+⋯+βvq+⋯=v2∞,⋯+(1−n2β)v2+⋯+βvq+⋯⋮⋯+βvr+⋯+(1−nmβ)vm=vm∞,where m is the total number of feature points. On the left hand side of each equation, the points areviand theirnineighbours. All the control pointsvican be calculated by solving the linear system. The connectivity of the control mesh is kept exactly the same as the connectivity of feature points. Then the fitted subdivision surface can be generated using the standard Loop subdivision scheme.The final Loop subdivision surface exactly goes through the filtered feature points. The final fitted surface only uses a subset of the original vertices in the fitting process, though they are all used in other stages for feature extraction and topological modelling.To fit highly curved features, e.g. on the Rocker arm model, we use a refinement of the connectivity without changing the standard subdivision rules. A fine connectivity is produced by first subdividing the coarse connectivity using a mid-point interpolatory scheme, and further replacing each of the newly inserted vertices by the nearest vertex found in the original dense mesh. Then the refined connectivity is used to calculate the control mesh for the model with highly curved features.To fit extreme explicit sharp features, some special subdivision rules would need to be used, e.g. semi-sharp subdivision surface fitting of Lavoué and Dupont (2009) or modified Loop subdivision rules to fit sharp features as in Ling et al. (2008). While these special rules could be incorporated, our implementation does not support them.Note that some error control strategies could be adopted to improve the accuracy of the control mesh, such as using Panozzo et al.'s (2011) fitmaps to calculate adaptive control meshes, or using Ma et al.'s (2004) mid-point interpolatory and least squares to calculate the control mesh.This section presents several examples to demonstrate the proposed approach. Different types of models are tested for evaluation: the rocker arm model, the Stanford bunny model, the Igea model and the Fertility model. The bunny model has ears, legs, and tail features. The Igea model has eyes, nose, and mouth features. The Fertility model has many geometrical features with complex topology and high resolution. These critical features test the performance of the proposed approach.Fig. 12shows the example of the rocker arm, a triangular mesh with 10 044 vertices. The model is fitted by a single subdivision surface. The constructed connectivity has 239 vertices. Comparing Fig. 12(a) to (d) illustrates that the overall shape is preserved during the fitting procedure. Comparing (b) to (c) shows that the connectivity is aligned with significant ridges along the inner and outer circles at the top and bottom of the model, and the intersection of the cylinder and the base.Fig. 13shows the Stanford bunny model. The original bunny mesh has 35 947 vertices whilst the constructed connectivity has only 381 vertices. Comparing the fitted subdivision surface to the original mesh shows that the overall shape including ears, mouth, legs, and tail is preserved in the fitting procedure. From Fig. 13(b) and (c), we can see that the connectivity is aligned with valleys (concave ridges) in the areas of the neck, the bottom of the ears, the intersection between legs and the main body, and the intersection between the tail and the main body of the bunny.Fig. 14shows the Igea model. It is reduced from 8268 vertices to 383 vertices. The overall shape of the Igea model is also preserved. Note the feature alignment in the areas of the neck, the top and the bottom of the nose, and the intersection of the hair and the face of the model.Fig. 15shows the results of the fitting processes for the Fertility model. The original dense Fertility mesh has 241 607 vertices. Since it is very expensive to estimate differential geometrical properties on such a dense mesh, the number of vertices is firstly reduced to 40 000 using Garland and Heckbert's (1997) QEM-based mesh simplification. The number 40 000 is chosen as just over the maximum number of vertices of the other three popular models on which the proposed fitting approach works well. The salient features on the simplified Fertility model are shown in Fig. 15(b). The constructed connectivity has only 254 vertices as shown Fig. 15(c). The final fitted subdivision surface in Fig. 15(d) shows that the complex topology and overall shape including heads, arms, bodies, legs and the base are preserved for both the mother and the baby. Comparing Fig. 15(b) with (c), it is illustrated that the connectivity is aligned with valleys along the necks, the connection between the mother and the baby, and the connection between the mother and the base. The connectivity is also aligned with ridges along the profiles of the heads, arms, bodies, legs and the base.The above examples illustrate the overall shape preserving quality and salient feature alignment of the proposed subdivision surface fitting approach. The feature alignment is improved using colour matching and a modified Hausdorff distance that includes curvature vectors. The results match the aim of the approach to fit the overall shape characterised by salient features using a relatively small number of control vertices.Table 1gives the quantitative comparison between the original surfaces and the surfaces fitted by the proposed method and the competing methods. Both error criteria of Hausdorff distance and average Euclidean distance are used for the comparison. The comparison focuses on the final errors instead of the processes. The processes are treated as black boxes. The comparison concerns the errors between the output (the fitted meshes) and the input (the original meshes) of the black boxes (the processes of the proposed method and the competing methods). These errors are computed between the final fitted subdivision surface and the original mesh. The distances are evaluated from vertices on one mesh to the faces of the other mesh. Table 1 illustrates that the proposed method has smaller geometric approximation errors than the competing methods of Lee et al. (2000) and Kanai (2001) in both error criteria of Hausdorff distance and average Euclidean distance.For feature preserving, the proposed method performs better than the other fitting approaches. Fig. 16shows the features on the original bunny model and the fitted subdivision surfaces generated by the proposed method, Ma et al.'s (2004) simplification-based method and Kanai's (2001) method respectively, using the same number of control points, 381. On the bunny head, the proposed method preserves features better than the others. For example, the three valleys and the three ridges of the mouth are well preserved by the proposed method, while they are changed or removed by other two methods. The four valleys on the face are also well preserved by the proposed method, while they degenerate to one or disappear in the other two methods. For the features on other parts of the bunny, there is no significant difference among all the methods. Fig. 17illustrates the comparison on the Igea model. On the eyes, the proposed method preserves features better than others. For example, the creases at the top right eyes are missed in the simplification-based and Kanai's methods. The ridge on the left eyebrow is discarded in Kanai method. These features are preserved in the proposed method. For the other parts, there is no big difference between all the methods. Fig. 18shows the comparison on the Fertility model. The valleys on the baby's face is removed by the simplification-based method. One valley on the mother's face is discarded by Kanai's method. Both competing methods missed the valley along the connection of the mother's head and her neck, and also missed some valleys on the mother's leg. The proposed method preserves all these features. The results are not surprising, since the connectivity of the proposed methods intends to follow the significant ridges and thus preserves features well.The total computational time is few minutes running on an Intel i7 CPU 2.2G under a Windows 7 operating system. As shown in Table 2, the total running times are around1.5,4,1, and 4 min for the models of Rocker arm, Stanford bunny, Igea, and Fertility, respectively. Note that the dense mesh of the Fertility model is pre-simplified to 40000 vertices, so that it has a similar number of vertices to the other models. It is illustrated that about80%of the running time is spent on feature extraction including estimation of differential geometry properties by jet fitting, extraction of ridges by a marching method, and extraction of umbilics by local minimisation. These processes are relatively efficient, since they are well established and have already been integrated into CGAL. In the fitting process, these functions are called from CGAL. The construction of connectivity spends about20%time, since the distance transform algorithm is linear, looping once over each original vertex by using a priority queue. The calculation of control points is within 1 s. Although the calculation by the linear solver is not linear, this will not be dominant because the number of filtered significant feature points is usually much smaller than that of the original vertices; the matrix of the system is very sparse. The final Loop subdivision is very efficient, spending less than 1 s. Table 3compares the running times between different methods. The proposed method is slower than the competing methods, since it spends most of the time on feature extraction. Although the proposed method sacrifices some efficiency to preserve the accuracy and features, it is still reasonably efficient with total computation times of few minutes.

@&#CONCLUSIONS@&#
