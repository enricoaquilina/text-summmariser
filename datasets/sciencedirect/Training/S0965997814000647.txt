@&#MAIN-TITLE@&#
Asynchronous Schwarz methods applied to constrained mechanical structures in grid environment

@&#HIGHLIGHTS@&#
We characterize the solution of the obstacle problem by various ways.We consider discretization schemes arising convergence of iterative algorithms.We consider parallel solution of discrete problem by asynchronous Schwarz method.Parallel experiments show the interest of asynchronous algorithms.Tests are performed on grid architecture on distant and heterogeneous machines.

@&#KEYPHRASES@&#
Obstacle problem,Parallel algorithm,Synchronous method,Asynchronous method,Complementary problem,Schwarz alternating method,Constrained mechanical structures,

@&#ABSTRACT@&#
This paper deals with the parallel solution of the stationary obstacle problem with convection–diffusion operator. The obstacle problem can be formulated by various ways and in the present study it is formulated like a multivalued problem. Another formulation by complementary problem is also considered. Appropriate discretization schemes are considered for the numerical solution on decentralised memory machines by using parallel synchronous and asynchronous Schwarz alternating algorithms. The considered discretization schemes ensure the convergence of the parallel synchronous or asynchronous Schwarz alternating methods on one hand for the solution of the multivalued problem and on the other hand for the solution of the complementary problem. Finally the implementation of the algorithms is described and the results of parallel simulations are presented.

@&#INTRODUCTION@&#
The behavior of mechanical structures is classically modelled by the equations governing the elasticity field [1,2]. The problem consists in studying the displacement of mechanical structure submitted to external forces. For physical reasons, the displacement of the structures may be submitted to some constraints, for example the displacement u cannot be less than a given thresholdϕ. The modelling of such constrained problem is very complex and leads to the solution of nonlinear boundary value problem, called in applied mathematics the obstacle problem. In fact this previous problem leads to the solution of a variational inequality. Variational inequalities arise from many physical and economical applications such as fluid flow in porous media, the behavior of elasto-plastic materials and lubrification phenomena in mechanics like free boundary problems and valuation of American options pricing in modern finance.The obstacle problem has been studied in many contributions and by many authors. For example in [3] sequential methods are considered for the Hamilton–Jacobi–Bellman problem; in [4] a study concerning the rate of convergence when multilevel domain decomposition and multigrid methods are considered for sequential solution of the obstacle problem. In [5] the linear convergence is proved for sequential multiplicative Schwarz method applied to the solution of variational inequalities and in [6] a geometric convergence rate is established for sequential additive Schwarz method for the same problem; in [7] the convergence rate analysis of domain decomposition methods is also studied in the case of obstacle problem solution. In [8] the block relaxation methods for algebraic obstacle problems with M-matrices are considered while in [9] multiplicative and additive Schwarz methods for obstacle problems with convection–diffusion operators, when two (possibly overlapping) subdomains are considered, one, where the solution is equal to a given obstacle function, and the other, where the solution satisfies a linear equation. In [10] the sequential convergence analysis of the generalized Schwarz method for solving the obstacle problems with T-monotone operator is studied. In the previous contributions, note that, mainly, the study of numerical solutions is considered by using sequential subdomain methods; moreover when the parallel solution is considered for the solution of the obstacle problem, it can be noticed that only parallel synchronous subdomain methods are studied. In [11] the rate of convergence of parallel asynchronous method is studied in the context of convex optimization; the considered work includes as particular cases parallel domain decomposition and multigrid methods for solving elliptic partial differential equations and is closely related to relaxation methods for nonlinear network flow.In the present study we will solve the model problem by the Schwarz alternating method. Thus, it is necessary to take into account the constraints and so to project the relaxed updates computed by the previous iterative algorithm on a convex set which defines such constraints. Thus, this projection has been achieved by various ways and in the proposed study we will consider two distinct ways allowing to project the relaxed updates. On other side, it can be noted that the discretization of boundary value problems arising from the formulation of the obstacle problem, leads to the solution of large scale algebraic systems. In order to compute efficiently the solution of such large algebraic systems, supercomputers can be used. The present study is devoted to the parallel solution by synchronous or asynchronous relaxation algorithms implemented on distributed architectures, mainly in Grid computing environment [12]. Recall that the asynchronous relaxation method corresponds to a general scheme of computation where the computations are performed in parallel without order nor synchronization among the processors [13]. Then idle times due to the synchronizations among the processors are suppressed; consequently, since the synchronizations are time consuming, the elapsed time of computation decreases when parallel asynchronous relaxation algorithms are performed.In our previous works, the solution of the obstacle problem has been computed by various parallel synchronous or asynchronous algorithms implemented on various architectures. In [14–17] the parallel synchronous and asynchronous projected Richardson’s method has been studied and implemented; since the projection operator is contracting, if appropriate additional assumptions hold, the convergence of the projected Richardson’s method is ensured. Nevertheless, in the general model of the obstacle problem, when the gradient of the displacement u occurs, i.e. when a convection–diffusion operator models the studied problem, this previous algorithm cannot be applied directly in the context of the projected Richardson’s method. Indeed the use of the Richardson’s method needs a formulation of the obstacle problem as a constrained optimization problem on a convex set and is not directly suitable, since in such formulation the cost function must be defined thanks to a symmetric stationary operator. Moreover, the projected Richardson’s method is not very efficient.Besides domain decomposition methods are well suited to the parallel solution of boundary values problems. In [16,17], we have considered for the solution of the obstacle problem an iterative parallel asynchronous projected subdomain method without overlapping among the subdomains; the subdomains are here defined by gathering several adjacent blocks of the discretization matrix.For both previous mathematical formulations, the convergence of parallel synchronous and asynchronous algorithms applied to the solution of the discretized problem, can be proved, either for every splitting of the problem to solve, by contracting techniques [18,19] or by partial ordering techniques [20,21]. The reader is referred to the previous works for more details.The present study is based on various different formulations of the model problem taking into account the constraints on the expected solution. Indeed, we concentrate on the obstacle problem modelled with convection–diffusion operator. In a distinct mathematical context we consider in the present paper the use of parallel synchronous or asynchronous Schwarz alternating method for the solution of the obstacle problem. Recall that, in the considered Schwarz method the domain is decomposed into subdomains which overlap each other. So the present work is distinct from previous studies concerning the solution of the obstacle problem. A general approach is considered, linked to the numerical parallel solution of the obstacle problem, well adapted and very different than the ones considered from [3–11]. By using the asynchronous Schwarz alternating method we hope to obtain the more multiplicative possible behavior of the domain decomposition method; recall that the additive and the multiplicative Schwarz alternating methods may be viewed respectively as Jacobi and Gauss–Seidel type methods applied to partial differential equations.A main property ensuring the convergence of parallel asynchronous iterative method is related to the fact that after appropriate discretization, the spatial part of the operator leads to a discretization matrix which is an M-matrix [22]. On the other hand, the projection on a convex set can be also formulated by the perturbation of the continuous convection–diffusion operator by a multivalued increasing diagonal operator [23]; so, the convergence of the considered method can also be analyzed by combining the monotony of the diagonal operator with the main property of the discretization matrix (see [19]). Another distinct theoretical approach consists in considering the obstacle problem written by a complementary formulation of this problem (which in fact corresponds to the projection of the intermediate values on the convex set which defines the constraints) and in solving the linearized algebraic system obtained by the Howard process, by the parallel asynchronous Schwarz alternating method. Note also that the present study is distinct to the one considered in [24], since in this previous work we have considered the parallel asynchronous Schwarz alternating method with flexible communications analyzed by partial ordering techniques, this last kind of communication mode among the processors which, possibly, consumes time when the rate of convergence is low; here, the convergence of the parallel asynchronous method follows from the fact that the matrix of the discretized and linearized problem is an M-matrix. Moreover, in order to obtain good efficiencies, in the presented work we consider only parallel experiments with the classical asynchronous schemes. Then we have to solve either a multivalued problem either a linearized problem by using the Howard process. So we obtain very interesting properties of discretized problems which ensure easily the convergence of parallel synchronous or asynchronous Schwarz alternating algorithms (see [18,20,21,25]).Implementation of the considered algorithms is carried out on Grid’5000, the French national grid (see [12]). This architecture allows us to study the behavior of parallel algorithms on distant and heterogeneous clusters. Communications are managed with MPI facilities. Asynchronous and synchronous efficiencies of the studied parallel algorithms are compared. Nevertheless, in such experimental context of distant and heterogeneous clusters, the classical notions of speed-up and efficiency are not relevant. Thus, we define a new parameter which permit us to measure the real efficiency of the studied asynchronous parallel algorithms. Moreover, in the parallel experiments, we have also considered the impact of the communications on the elapsed time of the iterative parallel algorithms for both synchronous and asynchronous mode.The present study is organized as follows. In Section ‘The obstacle problem’ several useful formulations of the obstacle problem are presented. In Section ‘Numerical solution of the model problem’ appropriate discretization schemes ensuring the convergence of the parallel synchronous or asynchronous Schwarz alternating method are considered for both formulations of the model problem. In Section ‘Parallel simulation’ the implementation of the algorithms and the results of the parallel experiments are presented. Finally some concluding remarks are given.The classical obstacle problem [1–11] occurs in many applications such as mechanics, free boundary problems and financial derivatives. In the present study we concentrate mainly on the obstacle problem occurring in civil engineering. The obstacle problem consists in computing a function u, whose characterization is given by the following time dependent nonlinear problem(1)∂u∂t-b·Δu+c.u-f⩾0,u⩾ϕ,everywherein[0,T]×Ω,b>0,c⩾0,∂u∂t-b·Δu+c·u-f(u-ϕ)=0,everywherein[0,T]×Ω,u(0,x,y,z)=u0(x,y,z),B.C.foru(t,x,y,z)definedon∂Ω,whereu0is the initial condition, b is a physical parameter, T is the final time,u=u(t,x,y,z)is the displacement of the constrained mechanical structure submitted to external strains, f is the external force imposed to the structure, B.C. describes the boundary conditions on the boundary∂Ωof the domainΩandϕmodels a constraint imposed to u. Practically, the Dirichlet condition (where u is fixed on∂Ω) or the Neumann condition (where the normal derivative of u is fixed on∂Ω) are classically considered.Remark 1When the materials constituting the structure are not homogeneous, then the coefficients arising in the mathematical model are not constant. Consequently, we can also consider the general formulation of the obstacle problem in which, after appropriate derivation with respect to the spatial variables, some terms of convection may appears. Then, we consider hereafter a simplified formulation of the obstacle problem, using a convection–diffusion operator.(2)∂u∂t+at·∇u-b·Δu+c·u-f⩾0,u⩾ϕ,everywherein[0,T]×Ω,b>0,c⩾0,∂u∂t+at·∇u-b·Δu+c·u-f(u-ϕ)=0,everywherein[0,T]×Ω,u(0,x,y,z)=u0(x,y,z),B.C.foru(t,x,y,z)definedon∂Ω,where a is a vector describing physical parameters. Consequently, we consider two situations in which on one hand the diffusion operator appears like that in (1) and, on the other hand, the convection–diffusion operator is considered in the formulation of the problem. This last situation is more general and our study can take into account the two situations.For the sake of generality, we consider, in what follows the more general formulation of the obstacle problem, expressed with the convection term. The previous time dependent problem is solved numerically by considering an implicit or semi-implicit time marching scheme, where at each time step the following stationary nonlinear problem is solved.(3)at·∇u-b·Δu+(c+δ)·u-g⩾0,u⩾ϕ,everywherein[0,T]×Ω,b>0,(at·∇u-b·Δu+(c+δ)·u-g)(u-ϕ)=0,everywherein[0,T]×Ω,B.C.foru(t,x,y,z)definedon∂Ω,whereδis the inverse of the time step andg=f+δuprec, whereuprecis the solution obtained at the previous time step.Remark 2In Fig. 1we can see a mechanical interpretation of the obstacle problem. Indeed, in Fig. 1(a), a thread is fixed at its own extremities and is subjected to an external force; due to their effect, the thread has a displacement submitted to some constraints. So we can see that there exists a contact areaOin which the value of the displacement u is identical to the value of the constraintϕwhereas the displacement is free outside of this contact area. Indeed, classically, ifat·∇u-b·Δu+(c+δ)·u-g<0, thenu=ϕ; on the contrary ifat·∇u-b·Δu+(c+δ)·u-g⩾0, then the constraints are not saturated and the solution of (3) is free. So, classically, due to the lack of constraints, in this last case whereu>ϕand the operatorat·∇u-b·Δu+(c+δ)·u-gis null; thus the physical problem is well described. From an industrial point of view, the Fig. 1(b) shows an example of application concerning the study of crash test arising in the self-propelling construction.For each stationary problem many equivalent formulations of the obstacle problem exist. In the present study, we concentrate on the variational formulation associated with problem (3); classically the corresponding variational formulation is given as follows(4)Findu∈Ksuchthata(u,w-u)⩾L(w-u),∀w∈K,wherea(u,w)=∫Ω(b·∇u·∇w+at·∇u·w+(c+δ)·u·w)dxdydz,L(w)=(f,w)=∫Ωf·wdxdydz,andK=w|wgiveninΩ,suchthatw(x,y,z)⩾ϕ(x,y,z)everywhereonΩ.Let us consider the stationary variational inequality (4). Then, since classically1.the spaceH1(Ω)normed by‖w‖1,Ω2=∫Ω(∇w·∇w+w·w)dxdydz, is an Hilbert space and K is a closed convex set,the mapping(u,w)→a(u,w)is obviously a bilinear, continuous and elliptic form,the mappingw→L(w)is obviously a linear continuous form,then, by applying the Stampacchia theorem, the variational inequality (4) has a unique solution.In the case of the evolution problem (1) or (2), the reader is referred to [26] for a result of existence and uniqueness of the solution.We can also apply the Riesz representative theorem. Let us denote byE=H1(Ω)the real vector space and byE′its dual space; in our caseE′is identified with E, sinceH1(Ω)is an Hilbert space. Then, there exists a unique element denoted byA‾u∈E′, whereA‾is a continuous linear mapping fromE→E′, such thata(u,w)=〈w,A‾u〉E×E′,∀w∈H1(Ω);similarly, there exists also a unique element, denoted byg¯∈E′such thatL(w)=〈w,g¯〉E×E′,∀w∈H1(Ω);then the stationary variational inequality (4) can be written as follows(5)Findu∈Ksuchthat〈w-u,A‾u-g¯〉E×E′⩾0,∀w∈K.Remark 3From a practical point of view, note that for the studied stationary problem (4)A‾u(x,y,z)=-b·Δu(x,y,z)+at·∇u+(c+δ)·u(x,y,z)andg¯=g(x,y,z).The notion of sub-differential mapping will play a major role in the following study. So we recall hereafter this notion and the main properties associated (see [1,23]).Definition 1Let beχa given convex function on E and a pointu∈E; we denote by∂χ(u)the set of allu′∈E′such that(6)χ(v)⩾χ(u)+〈v-u,u′〉E×E′,foreveryv∈E,where〈,〉E×E′denotes the pairing between E andE′. Such elementu′is called sub-gradient ofχat u, and∂χ(u)is called the sub-differential ofχat u.Recall that the pairing between E andE′is a bilinear form, fromE×E′ontoR(or possiblyC). If E is an Hilbert space, then the pairing is the inner product of E.Letχbe a Gateaux differentiable (or Frechet differentiable) convex mapping at u. Then∂χ(u)consists of a single element, namely the Gateaux (or Frechet) differential ofχat u (see [23]). From (6), it is obvious that∂χ(u)is a closed convex set (possibly empty, see [23]).In the sequel, we will use a multivalued formulation of the model problem (4) which playes a major role for the studied nonlinear obstacle problem.Lemma 1Letu∈Ebe such thatχ(u)=minv∈E(χ(v)); then u is a minimum if and only if0∈∂χ(u).Indeed, letu∈Esuch thatχ(u)⩽χ(v),∀v∈E; then we haveχ(v)⩾χ(u)+〈v-u,0〉E×E′,and then0∈∂χ(u). □The sub-differential∂χ(u)is a monotone operator (in general multivalued) from E toE′.Letw′∈∂χ(w); thenχ(v)⩾χ(w)+〈v-w,w′〉E×E′,∀v∈E. Let alsou′∈∂χ(u); thenχ(v)⩾χ(u)+〈v-u,u′〉E×E′,∀v∈E. Let us consider the first inequality forv=uand the second forv=w; then by adding, we obtain〈w-u,w′-u′〉E×E′⩾0, and the proof is achieved. □The indicator function of the convex subset K will also play an important role in the sequel and is defined as follows.Definition 2Let K be a closed convex subset of E. The indicator function of the convex subset K denotedψKis then defined byψK(v)=0ifv∈K+∞otherwise.Clearly,ψK(v)is convex. By definition of the sub-differential we have (see [23])∂ψK(v)={v′∈E′|〈v-w,v′〉E×E′⩾0,foreveryw∈K}.This shows that the domain of the subdifferential isD(∂ψK)=D(ψK)=Kand∂ψK(v)={o}for eachv∈int(K). Moreover, if v lies on the boundary of K, then∂ψK(v)coincides with the cone of normal toKat point v. So we can summarize by giving bellow the expression of the sub-differential indicator function of the convex subset K∂ψK(v)=∅ifv<ϕ,]-∞,0]ifv=ϕ,0ifv∈K,and the corresponding graph presented on the following Fig. 2.Then, thanks to the notions presented in the previous subsection, the formulation (5) of the continuous stationary variational inequality (4) is equivalent to the following multivalued problem(7)Findu∈EsuchthatA‾u-g¯+∂ψK(u)∋0,where∂ψK(u)is the sub-differential of the indicator function of the convex subset K. Note that, in (7), the projection on the convex set K can be also formulated by the perturbation of the continuous convection–diffusion operator by a multivalued increasing diagonal operator. Indeed, the definition of the sub-differential of the indicator function implies∂ψK(u)={ω′∈E′|ψK(w)-ψK(u)⩾〈w-u,ω′〉E×E′,∀w∈K}.Let us assume that (5) holds and let us verify that the following inequality is true(8)ψK(w)-ψK(u)⩾〈w-u,g¯-A‾u〉E×E′,∀w∈K.Ifw∈K, thenψK(w)=0and sinceψK(u)=0, then we obtain0⩾〈w-u,g¯-A‾u〉E×E′,which is valid by considering (5).Ifw∉K, thenψK(w)=+∞; since,ψK(u)=0, then we obtain+∞-0⩾〈w-u,g¯-A‾u〉E×E′,and the obtained inequality is always true.Conversely, consider two distinct situations:1.if there existsu∈Esuch thatg¯-A‾u∈∂ψK(u)then we have to verify that there existsu∈Esuch that (8) holds for allw∈K. Ifu∈KthenψK(u)=0and (8) can be written as followsψK(w)⩾〈w-u,g¯-A‾u〉E×E′,∀w∈K.Sincew∈KthenψK(w)=0and (8) can be written as follows0⩾〈w-u,g¯-A‾u〉E×E′,∀w∈K,inequality well verified by (5);besides, let us show that the assertionu∉Kis impossible. Indeed, in this caseψK(u)=+∞, so thatψK(w)-∞⩾〈w-u,g¯-A‾u〉E×E′,∀w∈K,which involves, sinceψK(w)=0, that-∞⩾〈w-u,g¯-A‾u〉E×E′,∀w∈K,inequality never verified.In conclusion, the problems (7) and (8) are equivalent. So the numerical solution of the obstacle problem leads to the solution of the multivalued problem (7).Let us consider the classical stationary linear convection–diffusion operator similar to the one arising in (2) and defined in a bounded domainΩincluded in the 3D space. For the sake of simplicity, let us assume that the discretization grid of the domainΩis uniform. In the sequel h will denote the discretization step-size. The discretization of the operators is made according to the following rules: the Laplacian is discretized with the classical seven points scheme; the first derivatives, for example the derivative with respect to x, is discretized as follows according to the sign of the componenta1of the vector a(9)∂u∂x=u(x,y,z)-u(x-h,y,z)h+O(h),ifthecoefficienta1isstrictlypositive,u(x+h,y,z)-u(x,y,z)h+O(h),ifthecoefficienta1isstrictlynegative,and accordingly for the other first derivatives.Let A denote the discretization matrix of the considered convection–diffusion operator; let us also denote byG‾the corresponding right hand side of the discretized system. Sincec+δis strictly positive, then regardless the sign of the components of the vector a, it follows from (9) that the off-diagonal entries of the matrix A are nonpositive and the diagonal entries of the matrix A are positive. Thus, the matrix A is strictly (and irreducibly by using the characterization of irreducible matrices (see [22])) diagonally dominant; thus, A is a nonsingular M-matrix andA-1⩾0i.e. all the entries of the inverse of the matrix A are nonnegative (see [22]).Let us now consider the discretization of the global problem (7); taking into account the nonlinear part of the problem due to the perturbation of the linear algebraic system by the multivalued sub-differential operator∂ΨKof the indicator functionΨK, then the discretized problem can be written as follows(10)AU-G+∂ΨK(U)∋0,where∂ΨK(U)is the discretized sub-differential operator of the indicator function.Remark 6Since the sub-differential is a diagonal operator, the components of∂ΨK(U)are constituted by all the discretized sub-gradients belonging to the sub-differential of the indicator function.The use of a purely implicit time marching scheme and the considered discretization of the spatial part of the operators lead, at each time step, to the numerical solution of very large algebraic systems. Owing to the great size and also of the sparsity of such a system, iterative algorithm may be used in order to reduce the computation time at each time step. Moreover the parallelization of such iterative algorithm can reduce again the elapsed time of computation.In the present study, we concentrate on the implementation of the iterative Schwarz alternating algorithm for the solution of the stationary obstacle problem. In such method, at each time step, we consider the classical projected Schwarz alternating method applied to the solution of each stationary variational inequality. Note that the Schwarz alternating algorithm with overlapping is well suited for efficient parallel computation (see [27]). Note also that we can consider parallel synchronous and asynchronous Schwarz alternating algorithms. The interest of asynchronous algorithm, compared to the synchronous one, is the reduction of idle times due to synchronizations among the processors.In this kind of method, in order to parallelize the computation, the domainΩ, is split into parallelepiped subdomains which overlap each other. Thus, for the computation of the solution of the global problem, smaller subproblems are solved on each processor of a parallel computer and then more accuracy can be obtained since the problem to be solved is ill-conditioned. For a considered subdomain, the restriction of the available values of the computed solution obtained on the neighboring subdomains are taken as Dirichlet boundary conditions. The synchronous algorithm consists in performing a block Jacobi like method. Besides, in the classical asynchronous algorithm, the components computed by the other processors may be delayed (see [18,20,25]) and the available values are used at the end of each relaxation.More precisely, let us consider the system of algebraic Eq. (10). The numerical solution of (10) by the Schwarz alternating method leads to the solution of the following multivalued problem(11)A·U-G+∂Ψ‾K(U)∋0,whereA,V,GandΨ‾Kare derived from the augmentation process associated with the Schwarz alternating method [28]. This process is a theoretical model that represents the solution of the algebraic system (10) by a Schwarz domain decomposition method. In the implementation of the algorithmsA,GandΨ‾Kare not explicitly computed. According to a result of Evans and Deren [28], the matrixAis also an M-matrix. So, the system (11) derived from the augmentation process, has the same property as the initial algebraic system (10), i.e.Ais an M-matrix and∂Ψ‾K(U)is a monotone operator.Let us consider the system of algebraic Eq. (10) to solve. Letα∈Nbe a positive integer and consider now the following block decomposition of problem (11) intoαsubproblems associated to the subdomain decomposition(12)∑j=1αAij·Uj+∂Ψ‾Ki(Ui)-Gi∋0,∀i∈{1,…,α}whereUi∈Rni,Gi∈Rniand∂Ψ‾Ki(Ui)is the i-th block of the sub-differential mapping, wherenidenotes the size of the i-th block of the previous vectors andA=(Aij)1⩽i,j,⩽α, is defined according to the associated block decomposition.Let us now consider the solution of subproblems (12) by the classical asynchronous parallel iteration which can be written as follows(13)Aii·Uir+1+∂Ψ‾KiUir+1∋Gi-∑j≠iAij·Wj,ifi∈s(r),Uir+1=Uir,ifi∉s(r),where{W1,W2,…,Wα}are the available values of the components(Uj)j≠i, computed by the other processors and corresponding to an iterative method where the updates are performed at the end of any block relaxation by an asynchronous way, each component being defined byWj=Ujρj(r)andS={s(r)}r∈Nis a sequence of nonempty subsets of{1,2,…,α}. In other words,s(r)is the subset of the subscripts of the components updated at ther-th relaxation. In the sequel, we have also to consider the vectorR={ρ1(r),…,ρα(r)}r∈N,which denotes a sequence of integer vectors fromNα. In order to take into account the asynchronism among the processors,Rmodels the delays between the parallel updates of each component, at ther-th relaxation. FurthermoreSandRsatisfy the following assumptions∀i∈{1,2,…,α},theset{r∈N|i∈s(r)}isunbounded,∀i∈{1,2,…,α},∀r∈N,0⩽ρi(r)⩽r,∀i∈{1,2,…,α},limr→∞ρi(r)=+∞.Remark 7Classically, whenρi(r)=rfor alli∈{1,…,α}and for allr∈N, then (13) models a synchronous Schwarz alternating method.This formulation (10)–(12) by a multivalued sub-problem (12) takes some interest only from a theoritical point of view. Indeed, since the sub-differential of the indicator function is monotone and diagonal, the previous formulation allows to prove the convergence of the parallel synchronous and asynchrounous iterations [18–21].Recall that the matrix arising in the algebraic linear system, is an M-matrix; the corresponding algebraic linear system is perturbed by a monotone diagonal operator. Then, for any subdomain decomposition, according to theoretical results obtained in [18,19,25], since it can be proved that the uniform weighted norm of the error at the step r is decreasing, the numerical solution of problem (10) by the classical parallel asynchronous Schwarz alternating method associated with (13) and starting from any initial guessU0, converges to the solution of the obstacle problem. Reference is made to these three last papers for more details concerning these results. Note also that the same result can also be obtained by partial ordering analysis (see [20,21]), since the mappingAU-G+∂ΨK(U)is obtained by the perturbation of a linear system with an M-matrix by a monotone diagonal operator, and then is an M-function, i.e. a mapping off-diagonally antitone and inverse isotone (see [22]).Sometimes, the implementation of parallel algorithms requires the use of lexicographical ordering or red–black ordering of the columns of the mesh. The previous convergence results still hold, in both cases of natural and red–black ordering of the subdomains. Let us denote by A andA‾the corresponding matrices associated with the two considered orderings. Let us assume that if A is an M-matrix, thenA‾is also an M-matrix sinceA‾is obtained from A by a permutation matrix P which preserves the sign of the entries and particularly the sign of the diagonal entries. Furthermore we haveA‾=P·A·Pt; thus we haveA‾-1=P·A-1·Pt. The matrix A being an M-matrix, it follows thatA-1is a nonnegative matrix [22], i.e. the entries ofA-1are nonnegative. ThusA‾-1is also a nonnegative matrix obtained fromA-1by the same permutation as the one considered for A. ThenA‾is an M-matrix. Moreover when a red–black ordering of the blocks is considered, since the sub-differential mapping is a diagonal operator, this is again a monotone mapping. This remark proves that the asynchronous parallel methods converge also in the context of the red–black ordering of the subdomains.Remark 8For the solution of system (10), we can consider instead of the classical parallel asynchronous Schwarz alternating method, the parallel asynchronous Schwarz alternating method with flexible communications which corresponds to a more general model of parallel asynchronous iterations. This kind of method consists in using partial ordering techniques linked with the discrete maximum principle [21]. In the present context, the values of the components of the iterate vector generated by the other process, can be accessed while the computations are still in progress. In such method the current value of any component of the iterate vector is not necessarily labelled by an outer iteration number as communication may occur at any time. Then, in this class of methods, partial updates can be used at any time in the computation. Thus, flexible data exchanges among processors are allowed; as a consequence, the coupling between communications and computations can be improved. This method consists in starting the iteration (13) with an initial guessU0such that(14)A·U0+Λ(U0)-G⩾0,Λ(U0)∈∂Ψ‾K(U0).In practiceU0is chosen such thatU0=Φ. In this case, forr⩾1, the vectorW={W1,W2,…,Wα}belongs to the order interval〈Ur,min(Uρ(r),Uq)〉, whereUρ(r)denotes the vector with block componentsUjρj(r),j∈{1,2,…,α}andq=maxk∈Ks(r)r(k), where the setKircontains all the iteration numbers lower than r associated with the computation of theithblock component (see [21]). Note that the values of the componentsWjare also the available values of the iterate vector. In this case, if (14) is satisfied, it can be proved (see [21]) that the sequence of iterate vectors satisfies the maximum discrete principle; indeed(Ur)r⩾0satisfies the following inequalitiesU⩽…⩽Ur⩽…⩽U0(see also [29] for an analysis by using contraction technics).In conclusion for the first way of projection, since the discretization scheme applied to the numerical approximation of the boundary value problem modelling the obstacle problem, leads to the solution of an algebraic system constituted by an M-matrix perturbed by a monotone diagonal operator, then, the parallel synchronous and asynchronous alternating methods with or without flexible communications converge to the solution of the considered discretized boundary value problem for any initial guessU0and for any ordering of the subdomains. From a practical point of view, concerning the implementation associated to the model problem, we have:1.first to compute an intermediate value of a component of the iterate vector by solving for example, one equation of the algebraic linear system,and then to project this intermediate value of the component on the convex set; more precisely, if the constraint is satisfied, the intermediate value of the component is not changed and if the constraint is saturated, for example, if the component of U is less than the component ofΦ(U<Φ), then the intermediate value of the component is equal toΦ.Note also that the projection on the discretized convex set can be performed by using the Howard method; such mathematical approach avoids using the notion of sub-differential mapping. In fact this second method is a Newton like method allowing the linearization of the stationary problem associated with (3). Indeed, after appropriate discretization we have to solve at each time stepmax(AV-G,V-Φ)=0and we associate it with the linearized system(15)B(V)·V=C(V),constructed as follows:1.if the i-th component of(AV-G)is greater than the i-th component of(V-Φ), then the i-th line ofB(V)is the i-th line of A and the i-th component ofC(V)is the i-th component of G,else all the entries of the i-th line ofB(V)are null except the diagonal entry equal to one, and the i-th component ofC(V)is the i-th component ofΦ.Since the discretization matrix A is strictly (and irreducibly) diagonally dominant and regardless the sign of the entries of the matrix A, obviously the matrixB(V)is strictly diagonally dominant. Note that, the matrixB(V)is not necessarily irreducible, since in the linearization process some entries equal to zero can appear in all the off-diagonal entries of a same line; this happens when the previous case 2) occurs during the building of the linearized system. Nevertheless, at each step of the linearization process, the global matrixB(V)has strictly positive diagonal entries and nonpositive off-diagonal entries; furthermoreB(V)is strictly diagonally dominant. Consequently,B(V)is an M-matrix and at each step of the Howard method we have to solve a linear algebraic system where the matrix to be inverted is an M-matrix. So, for solving such linear system, we can use the parallel synchronous or asynchronous Schwarz alternating method described in subSection ‘The Schwarz alternating method’, and, due to the property ofB(V), this last algorithm converges for each step of the linearization process. We refer to [24] for a direct convergence analysis of the parallel asynchronous Howard algorithm by partial ordering analysis, including parallel asynchronous method with flexible communications.Remark 9It can be noted that the Howard method can be used for a more general class of complementary problems. Indeed consider the Hamilton–Jacobi–Bellman equation arising for example in image processing. Such stationary problem can be formulated as follows(16)Findv∈Esuchthatsup(A‾1v-f1,A‾2v-f2)=0,everywhereinΩ,v=0,everywhereon∂Ω,whereA‾i,i=1,2are two elliptic operators; after appropriate discretization we have to solve the discrete complementary problem(17)max(A1V-F1,A2V-F2)=0,whereAi,i=1,2are the discretization matrices. Then, for the previous problem, we can consider an associated linearized problem obtained by the Howard method. The linearization is the same as the one considered in (15), except the identity matrix is replaced by the matrixA2andΦis replaced byF2in the second argument. Now, ifAi,i=1,2are two M-matrices, the matrixB(V)arising in the linearized system is also an M-matrix and consequently, the parallel synchronous or asynchronous Schwarz alternating methods converge.In conclusion, in the proposed study, we present two distincts ways for achieving the projection on the convex set. The first way consists classically to perturbe the linear algebraic systems by adding the sub-differential of the indicator function. Then we obtain a multivalued formulation of the problem to solve. This way corresponds to a theoretical way and allows to analyze the convergence of the parallel synchronous and asynchronous subdomain methods. In the implementation of the algorithm, we have to project the intermediate value of the iterate vector on the convex set as explained below.The second way is distinct to the first one and is more global. Indeed we have to linearize the problem by the Howard process. Then we obtain a linearized system (15), and the convergence of the parallel synchronous and asynchronous subdomain methods follows from the fact that the matrixB(V)issued from the Howard process is an M-matrix. Then, the proposed paper presents two methods for the solution of the obstacle problem.This section is devoted to the presentation of the parallel algorithms implementation and the results of parallel experiments.The simulation algorithm is based on master/slave paradigm which is a commonly used approach for parallel and distributed applications. In our case, a master process controls the distribution of work to a set of slave processes.Algorithm 1General algorithmAlgorithmif (master)compute discretization matrix and right hand sidesend input data to slavescompute SPMD parallel algorithm to solve the algebraic systemreceive output data from slaveselsereceive input data from mastercompute SPMD parallel algorithm to solve the algebraic systemsend output data to masterend ifThis process is used for the solution of the system that arises in the numerical simulation of the obstacle problem. Matrix and right hand side creation have been implemented sequentially since this part of computation is not very intensive. In this way, the master process can be seen as a matrix and vector filler that feeds a parallel solver. In other words, only intensive computations have been parallelized with MPI facilities.1Message Passing Interface.1Note that only the parallel synchronous and classical asynchronous Schwarz alternating methods have been implemented; the asynchronous Schwarz alternating method with flexible communications has not been considered in the present study. In addition, the principle of parallel asynchronous iterative subdomain algorithms implementation for on one hand the Schwarz method for the multivalued problem and on the other hand for the Schwarz method with Howard linearization can be summarized as follows:Algorithm 2Schwarz for multivalued problemdo until global convergencefor each subdomain assigned to the processor doif local convergence is not reached thenreceive the latest boundary valuessolve with projection the subsystemssend the boundary values to the neighborsend ifend forend doSchwarz with Howard linearizationdo until global convergencefor each subdomain assigned to the processor doif local convergence is not reached thenreceive the latest boundary valuessolve the subsystems:– compute matrix and right hand side according to Section ‘Linearization of the problem by the Howard method’– solve the linearized subsystemsend the boundary values to the neighborsend ifend forend doSubdomains are assigned to each processor following a red–black ordering. For the solution of the obstacle problem, note that in each subdomain we have considered either the implementation of the block Gauss–Seidel method with projection of the iterate vector on the convex set or the block Gauss–Seidel method applied to the solution of the linearized problem by the Howard process. For the first considered method, this kind of algorithm is faster than a point relaxation method with projection.Parallel simulations for the solution of the obstacle problem have been performed on various distant clusters of the Grid’5000 platform. This French grid platform was composed of 2970 processors with a total 6906 cores distributed over 9 sites in France. In this network every site hosts clusters and all sites are connected by highspeed communication; nowadays the communication network is Gigabit Ethernet for local machines. Bandwidth among the different sites is about 10Gbps. Most of Grid’5000 sites are composed of several clusters with different computing architectures and performances. Fig. 3illustrates the sites of the Grid’5000 architecture.The parallel experiments have been performed using an heterogeneous and dedicated machines running Linux 64 bits. The machines of the Grid’5000 platform used are located in Sophia-Antipolis, Rennes, Nancy and Toulouse sites. The characteristics of these machines are summarized in Table 1.In the parallel experiments we have only considered the performances obtained by computing on one time step which in fact corresponds to the solution of a stationary obstacle problem. Indeed in a previous study [16,17] where a time-dependent obstacle problem has been solved by using projected Richardson method and subdomain without overlapping algorithm, we have shown that all time steps require similar execution time for the solution of each stationary problem. Thus, experiments with Schwarz alternating methods allow us to estimate the performances of the considered parallel algorithm for the solution of time dependent problem.In the parallel experiments, we consider a benchmark where a regular mesh is defined onΩ=[0,1]×[0,1]×[0,1]; in numerical simulations, we have considered two meshes constituted on one hand of 64,000,000 mesh points2400×400×400=64,000,000points.2and on other hand of 32,768,000 mesh points3320×320×320=32,768,000points.3; due to utilization constraints of the grid platform in dedicated exploitation, the number of mesh points is limited to the previous values; for the same reason the number of cores is also limited. The diffusion coefficient is set tob=0.2and the components of the convection vector are equal to-0.9; furthermorec=0andϕ=0. The domain is decomposed into 256 overlapping subdomains numbered using a red–black ordering, well adapted to parallel computation. In the implementation of the Schwarz alternating methods, two or more subdomains are assigned to each processor; thus, on each processor, this assignation allows a behavior of the parallel algorithm as close as possible of a multiplicative Schwarz alternating method. From a practical point of view, parallel synchronous and asynchronous algorithms are more efficient on such subdomain distribution.The numerical algorithms have been implemented using Fortran 90, BLAS subroutines, no other external libraries have been used; the remainder of the implementation is coded by ourself. In particular, a block relaxation method has been implemented for the solution of the obstacle problem. The parallelization is achieved using MPI facilities. Message passing are implemented with MPI persistant communication requests, in both synchronous and asynchronous cases. Thus, the proposed MPI implementation of the Schwarz alternating method in decentralized memory multiprocessor is more efficient. The implementations of message passing are described in Algorithms 4 and 5.Algorithm 4Implementation of synchronous message passing using MPI facilities.Synchronous message passing:!!!!!!!!!!!!!!!!!! SEND REQUESTS!!!!!!!!!!!!!!!!!!! Wait for the completion of the former send requestscall MPI_WAITALL (mlpt%NSEND,sndt,starray,ierr)! Pack the current messagesdo i=1, mlptbadr=mlpt%SND_BT (i)call MSGPK (PK_P,mlpt%SND_HD (i), handl%LOCFV,X,buf (badr))end do! Start sending messagescall MPI_WAITALL (mlpt%NRECV,rcvt,starray,ierr)!!!!!!!!!!!!!!!!!!!!! RECEIVE REQUESTS!!!!!!!!!!!!!!!!!!!!!! Wait for the completion of the former receive requestscall MPI_WAITALL (mlpt%NRECV,rcvt,starray,ierr)! Unpack the current messagesdo i=1, mlpt%NRECVbadr=mlpt%RCV_BT (i)call MSGPK (PK_U,mlpt%RCV_HD (i),handl%LOCFV,X,buf (badr))end do! Start receiving messagescall MPI_STARTALL (mlpt%NRECV,rcvt,ierr)Implementation of asynchronous message passing using MPI facilities.Asynchronous message passing:!!!!!!!!!!!!!!!!!! SEND REQUESTS!!!!!!!!!!!!!!!!!!! Nonblocking check for the completion! of the former send requestscall MPI_TESTSOME (mlpt%NSEND,sndt,nout,outarray,starray,ierr)do i=1, nout! Pack the current messages for completed requests onlympos=outarray (i)badr=mlpt%SND_BT (mpos)call MSGPK (PK_P,mlpt%SND_HD (mpos),handl%LOCFV,X,buf (badr))! Start sending messagescall MPI_START (sndt (mpos),ierr)end do!!!!!!!!!!!!!!!!!!!!! RECEIVE REQUESTS!!!!!!!!!!!!!!!!!!!!!! Nonblocking check for the completion! of the former receive requestscall MPI_TESTSOME (mlpt%NRECV,rcvt,nout,outarray,starray,ierr)do i=1, nout! Unpack the current messages for completed requests onlympos=outarray (i)badr=mlpt%RCV_BT (mpos)call MSGPK (PK_U,mlpt%RCV_HD (mpos),handl%LOCFV,X,buf (badr))! Start receiving messagescall MPI_START (rcvt (mpos),ierr)end doFor all considered decomposition of the problem to solve, convergence of the proposed sequential and parallel algorithms is ensured. Concerning the rate of convergence, when the convergence analysis is done by contraction technics, an estimate of the rate of convergence is obtained by considering on one hand the spectral radius of the Jacobi matrix associated with the discretization matrix A and on the other hand, the associated subdomain decomposition (see [19]).Many experiments have been performed to exhibit elapsed times of parallel Schwarz alternating method in both synchronous and asynchronous iterative schemes and using two or three distant sites. The latter case corresponds to an heterogeneous architecture since computing processors are different; indeed the machines located in Sophia-Antipolis and Nancy used Intel processors and the machines located in Toulouse used AMD processors.In the parallel simulations only one core of each machine could be used. Indeed the amount of data to be stored in each RAM memory, for each MPI process, is very large; consequently very large memory size is needed, in fact greater than 4GB. On other hand, the advantage of using 64 bits machines and compilers is the capability to use RAM with size greater than 4GB. Thus, in the case where many cores per machine are used, due to memory swapping, the performances of parallel algorithms will decrease. Note that, due to the size of the algebraic systems to solve, only machines having large memory could be used.The results of the experiments are summarized in Tables 2–7and Figs. 4–9, for the obstacle problem formulated by a multivalued algebraic system [30] and for the linearized and discretized obstacle problem, called in the sequel Schwarz–Howard method. In the following tables, P denotes the number of processors.In fact, the two considered formulations of the discretized obstacle problem lead to similar performances of the associated parallel computational methods. Nevertheless, considering the more general Hamilton–Jacobi–Bellman problem (17), the multivalued formulation is not relevant, while the linearized formulation by the Howard method is interesting.Tables 2 and 3 display the sequential elapsed times obtained on each cluster. The number of machines used has been limited up to 64 or 128 according to the duration of the exploitation of the computational codes. Moreover, for the considered size of the model problem, since the overhead damages the performances of the parallel algorithms, additional machines are not necessary particularly when synchronous scheme are tested; indeed more processors are not really interesting and the performances will not be improved.In these tables and figures, comparison of elapsed time for parallel synchronous and asynchronous methods are presented; since the notion of speed-up and efficiency are not relevant when distant and heterogeneous clusters are used, the parameterτmeasures the ratio of elapsed time between synchronous and asynchronous methods; this parameter is more appropriate for the comparison between the previous two kinds of parallel methods.Figs. 4 and 5 (Figs. 6 and 7, respectively) present the elapsed time obtained when the mesh is constituted by 64,000,000 (32,768,000, respectively) mesh points and when 2 (3, respectively) sites are used. Figs. 8 and 9 show the evolution of the parameterτwhen the number of processors increases and when 2 or 3 sites are used.Tables 4–7, Figs. 4–7 show clearly the benefit of using parallel algorithms. Note that the asynchronous parallel iterative algorithms are more efficient than the synchronous ones; so the advantage of the first method compared to the second one is clearly showed.In Tables 4–7, it can be noted, that in asynchronous parallel experiments, the number of relaxations necessary to reach convergence is greater when few processors are used than the one necessary when parallel synchronous schemes are used. Furthermore, despite higher number of relaxations, elapsed time of asynchronous scheme is less than the one obtained when synchronous scheme is used. This asynchronism is an efficient way to deal with communication overhead and load unbalance. It turns out that the overhead generated by additional relaxations in the case of asynchronous algorithms is smaller than the synchronization overhead combined with processor idle time of parallel synchronous schemes of computation. Nevertheless these additional relaxations improve the solution’s accuracy and the numerical quality of the computations. Moreover, the efficiency of the synchronous algorithm decreases faster than the efficiency of asynchronous algorithm when the number of processors increases. The lack of synchronization points and the use of current values of the components of the iterate vector induce better performances for the asynchronous Schwarz alternating methods when several processors are used.We focus now on experiments performed for the same problem with the same parameters on two and three distant sites.Results are summarized in Tables 4–7. Many interesting issues can be pointed out from these tables:1.it can be noticed that with both Schwarz alternating methods, we obtain good results; indeed this is due to the fact that the discretization matrix is nonsymmetric and it is well known that the block relaxation method is well adapted to this case,the results on two or three distant sites show that the synchronous version of both Schwarz alternating methods is slower than the asynchronous one. The ratioτobviously highlights the power of the asynchronous version compared to the synchronous one.In Tables 4–7, note that another feature of the parallel experiments consists in the fact that the parameterτis increasing with the increasing number of machines used (see Figs. 8 and 9). This means again that the efficiency of asynchronous schemes is clearly better than the efficiency of the synchronous one. Then clearly, asynchronous algorithms are well-adapted to the use of distant and heterogeneous machines.Finally, note that the use of asynchronous parallel schemes is very interesting, since the weight of synchronizations is low and, as a consequence, the obtained elapsed times are shorter. Indeed, since non-blocking MPI communication subroutines are used in asynchronous algorithm, the low values of communication ratio in this case can only illustrate the absence of idle time. On the other hand, a blocking communication subroutine is used in the synchronous algorithm; so, the communication time measurements represent the idle times due to synchronizations and the amount of CPU operation dedicated to communications. Moreover Tables 4–7 and Figs. 4–7 show clearly the impact of the communications on the behavior of the iterative parallel algorithm and the fact that such communications degrade the performances of the synchronous methods. Due to the weight of synchronizations, parallel asynchronous experiments on the grid platform show clearly the interest of such methods on distant clusters. So parallel asynchronous iterative algorithms, more particularly on grid platform, are appropriate ways to solve complex problems.

@&#CONCLUSIONS@&#
