@&#MAIN-TITLE@&#
New features for speech enhancement using bivariate shrinkage based on redundant wavelet filter-banks

@&#HIGHLIGHTS@&#
There are some dependencies among wavelet coefficients.Bivariate shrinkage was proposed based on parent–child coefficients dependencies.Two-channel critically sampled filter-bank is not suitable for bivariate shrinkage.Multi-channel redundant wavelet filter-banks lead to better results.

@&#KEYPHRASES@&#
Wavelet transform,Speech enhancement,Redundant filter-banks,Four channel double density discrete wavelet,Three-channel higher density discrete wavelet,Bivariate wavelet shrinkage,Zero moments,

@&#ABSTRACT@&#
In most of the wavelet based speech enhancement methods, it is assumed that the wavelet coefficients are independent of each other. However, investigating the joint histogram of the wavelet coefficients reveals some dependencies among them. In this regard, Sendur proposed a probability density function (pdf) that models the relation between a wavelet coefficient of image signal and its parent. Then, this pdf is utilized to propose a bivariate shrinkage function which uses the dependencies between the child–parent wavelet coefficients of Image signals to enhance the noisy images. In this paper, we intend to find wavelet structures which are more suitable for speech enhancement based on bivariate shrinkage. We show that the dependencies between the child–parent wavelet coefficients can only be modeled rather easily up to two stages of two-channel discrete wavelet transform using the Sendur's pdf. However, the bivariate shrinkage function works better in three-channel redundant wavelet filter-bank with dilation 2, since it has a joint distribution which is similar to the Sendur's pdf up to the fourth stage of decomposition for speech signals. Furthermore, we show that three-channel higher density wavelet obtained by eliminating the downsampling part of the third channel is more suitable for the bivariate shrinkage function when it is utilized for speech enhancement. Then, appropriate filter values for three-channel higher density wavelet filter-bank are found. Moreover, we propose four-channel double density discrete wavelet filter-bank which leads to some improvement in speech enhancement results. Since the probability of speech presence is higher in lower frequencies, we suggest level-dependent bivariate shrinkage. Finally, Sendur bivariate shrinkage is optimized for speech enhancement and new methods are proposed by combining former successful methods with the bivariate shrinkage function.

@&#INTRODUCTION@&#
The applications of speech signal processing such as speech recognition, speech enhancement and speech coding have been increased recently. In traditional methods, features are obtained by Fourier transform. However, these methods have shortcomings in analyzing non-stationary signals (Wu and Lin, 2009). Short Time Fourier Transform has uniform time and frequency resolutions (de Andrade Bresolin et al., 2008). Hence, it is difficult to detect sudden changes and transient parts of the signals (de Andrade Bresolin et al., 2008; Farooq and Datta, 2001).In the past two decades, the wavelet transform has become a strong tool in speech processing (Favero, 1994). This transform has the advantage of alterable window length in time domain. The wavelet transform has higher frequency resolution in low-frequency parts of the signal, while it has higher time resolution in high frequency parts of the signal (Xueying and Zhiping, 2004). On the other hand, different basic functions can be used in wavelet transform. These basic functions are called mother wavelets. The mother wavelets give us ability to design wavelets based on our needs. In addition, wavelet transform has multi-resolution property (Tufekci et al., 2006).One of the major application of the wavelet transform is signal denoising. In 1995, Donoho proposed a method for wavelet denoising based on the thresholding approach (mentioned in Ghanbari and Karami, 2006). Here, a threshold was used to separate components including speech from those including noise only (Jafer and Mahdi, 2003; Sheikhzadeh and Abutalebi, 2001; Wang et al., 2006). In most algorithms based on Donoho's thresholding, the wavelet coefficients were assumed to be independent (Sendur and Selesnick, 2002). In Bahoura and Rouat (2006), researchers proposed time-scale adaption method to improve speech denoising based on Donoho's approach. In their method (Bahoura and Rouat, 2006), wavelet packet transform was utilized to analyze speech signals. In order to improve Donoho's thresholding, a level-dependent threshold was used. Then a new method was proposed to find noise samples in each stage of decomposition (Bahoura and Rouat, 2006). In this method, first, speech samples were categorized into two categories, namely, the speech samples and the noisy samples. Then, appropriate threshold were suggested for speech samples and noisy samples. In this study, lower threshold values were considered for speech samples in comparison with noisy samples (Bahoura and Rouat, 2006).In most wavelet-based speech enhancement methods (i.e. Donoho's thresholding), it is assumed that the wavelet coefficients are independent. Therefore, each of the enhanced coefficients is calculated independently. However, Sendur and Selesnick (2002) have shown that there are significant dependencies among wavelet coefficients of the image signal. In their studies, first the dependencies between a wavelet (child) coefficient and its parent are modeled by a non Gaussian probability distribution function (pdf). By using this pdf, they find a new shrinkage function known as bivariate shrinkage function. This shrinkage function uses the child and parent wavelet coefficients to eliminate the noisy parts of the wavelet coefficient. It is reported that this assumption improves the performance of the wavelet-based methods for image denoising (Sendur and Selesnick, 2002).In order to make appropriate wavelet based denoising methods, in addition to wavelet shrinkage functions, the properties of different wavelet structures are needed to be considered. For instance, down-sampling operator of the discrete wavelet makes this type of wavelet a time variant transform (Farooq and Datta, 2001; Weickert et al., 2008; Abdelnour, 2005; Abdelnour and Selesnick, 2005; Selesnick and Abdelnour, 2004; Selesnick, 2001, 2006; Tohidypour et al., 2010a,b). Most wavelet transforms, which have been used for speech processing in the past, are based on the critically sampled filter-banks (Tohidypour et al., 2012; Lebrun and Selesnick, 2004). In these filter-banks, the number of input samples remains the same in transform domain. Therefore, there is no redundancy in these systems. But these filters are not time-invariant (Tohidypour et al., 2010a,b), because of the down-sampling factors. This means that, for example, if a signal is down-sampled by 2, a sample of signal among two samples is chosen. Therefore, with a small signal displacement, the wavelet coefficients may be changed. This time-variant property decreases the ability of noise estimation. Previous studies have shown that the shift-variant property of critically sampled wavelet filter-banks has some disadvantages in the case of noisy speech with periodic noise (Weickert et al., 2008). Therefore, nearly-shift-invariant wavelet structures are considered for denoising based on wavelet transform. New wavelet transform based on M-channel filter-banks gives us more degrees of freedom in designing nearly-shift-invariant wavelet structures. In this regard, Selesnick and Abdelnour suggest appropriate filters for some redundant M-channel wavelet filter-banks, which are nearly-shift-invariant (Abdelnour, 2005; Abdelnour and Selesnick, 2005; Selesnick and Abdelnour, 2004; Selesnick, 2001, 2006). Moreover, two types of the four channel redundant wavelet filter-banks are proposed by Selesnick and Tohidypour (Abdelnour and Selesnick, 2005; Tohidypour et al., 2012). The last one was called four-channel higher density wavelet filter-bank (Tohidypour et al., 2012). Note, the redundant transform is a transform that expands C point input signal to D point output, while D>C (Selesnick, 2006).Review of the previous works reveal that in most wavelet based speech enhancement methods, critically sampled discrete wavelet transforms or critically sampled wavelet packets were used. Also, in most of the previous studies, Donoho's threshold was used for noise estimation (Ghanbari and Karami, 2006; Jafer and Mahdi, 2003; Sheikhzadeh and Abutalebi, 2001; Wang et al., 2006; Bahoura and Rouat, 2006).In this study our objective is to find wavelet features which are more suitable for speech enhancement based on bivariate shrinkage function. More precisely, we want to find wavelet structures that have joint parent–child histograms which are more similar to the Sendur's pdf. To this end, first we compare the joint parent–child histogram of wavelet coefficients of two-channel critically sampled filter-bank with the Sendur's pdf. We will show that only up to the second level of decomposition in two-channel discrete wavelet coefficients leads to distributions similar to the Sendur's pdf. Then, for three-channel redundant filter-banks, the joint parent–child histogram is illustrated and it is compared with Sendur distribution. We show that for the three-channel redundant wavelet filter-banks, Sendur's pdf can be seen up to the fourth stage of decomposition. Therefore, the Sendur's bivariate shrinkage function can work better in three-channel redundant wavelet filter-banks. In addition, we introduce a new four-channel redundant wavelet structure. We will show that the joint distribution of the wavelet coefficients are the same as the Sendur's pdf up to fifth stage of decomposition. Moreover, we will find appropriate values for this four-channel redundant wavelet filter-bank. We will call this structure four-channel double density discrete wavelet filter-bank. In order to improve the performance of our proposed methods, we use a voiced/unvoiced classifier and propose a level dependent threshold for bivariate shrinkage function.The rest of this paper is organized as follows: Section 2 includes an overview of the wavelet-based denoising methods, which are used in this paper. In Section 3, four types of discrete wavelets including two-channel, three-channel double density wavelet with dilation 2, three-channel higher density discrete wavelet, and four-channel double density discrete wavelet filter-banks are introduced. Section 4 presents the speech enhancement method proposed in this paper. Database and the performance evaluation methods for speech signals are discussed in Section 5. Section 6 presents the experimental results and Section 7 concludes the paper.One of the major issues in speech enhancement is noise estimation. In this regard, we present two different thresholding algorithms (Donoho Thresholding and Bivariate wavelet shrinkage) in this section. Here we assume a clean signal s(t) corrupted by a white Gaussian noise n(t),(1)y(t)=s(t)+n(t),where y(t) is the noisy signal in time domain. By applying wavelet transform, (1) can be written as(2)Yc(m)=Sc(m)+Nc(m),where Yc(m), Sc(m), and Nc(m) denote wavelet coefficients obtained from y(t), s(t), and n(t) respectively.Noise reduction in wavelet domain is based on the principle that only a small number of wavelet coefficients in low frequency band can be used to estimate the main features of a clean signal. Hence, setting small coefficients to zero can be a good approximation to reduce noise without losing information from the original signal. Therefore, the issue here is to determine the proper threshold (Ghanbari and Karami, 2006). One popular method to estimate the threshold (T) has been presented by Donoho (Bahoura and Rouat, 2006). This threshold is named universal threshold, and is given by(3)T=σˆN2log(L),where L represents the number of wavelet coefficients. In order to simplify the noise estimation problem, it is assumed that n is white Gaussian noise (WGN) with zero mean and a standard deviation ofσˆN, which is computed as (Ghanbari and Karami, 2006)(4)σˆN=median(|Wc|)0.6745,where Wcdenotes the wavelet coefficient of the cth stage decomposition. Johnson presented a level-dependent threshold for the correlated noise. Johnson's threshold is as follows (Ghanbari and Karami, 2006)(5)Tj=σˆj2log(Lj).In our work, we have decided to use Zhang's thresholding method. This method was developed by improving the soft thresholding method. In original soft thresholding, the threshold is subtracted from any coefficient greater than it. The main difference between soft and Zhang thresholding functions is that the latter has a derivative of order p (Zhang and Desai, 1998)(6)Wc,p(wc,T)=wc+T−T2p+1,wc<−T1(2p+1)T2p⋅wc2p+1,|wc|≤Twc−T+T2p+1,wc>TWc,p(wc,T)denotes enhanced wavelet coefficients at cth stage of decomposition. On the other hand wcdenotes the noisy wavelet coefficients at cth stage of decomposition.Donoho's thresholding is proposed by assuming that the wavelet coefficients are independent. However, there are significant dependencies among the wavelet coefficients. As a result, using the statistical dependencies which exist among wavelet coefficients can improve the wavelet based denoising algorithms. In this regard, Sendur investigated the dependencies among the wavelet coefficients and their parents (Sendur and Selesnick, 2002). He assumed all quantities had zero means. According to his work, we can also modify Eq. (2) for parent's wavelet coefficients, so the following equation is obtained(7)Yc−1(m)=Sc−1(m)+Nc−1(m).In order to model the dependency between a wavelet coefficient and its parent, a bivariate probability density function (pdf) is proposed by Sendur and Selesnick (2002):(8)P(S(m))=32πσ2⋅exp−3σ⋅Sc−12(m)+Sc2(m).Note, P(S) is a non-Gaussian pdf for wavelet coefficients. The Sendur's bivariate pdf is illustrated in Fig. 1. It is assumed that the pdf between a wavelet coefficient and its parent is similar to P(S). Then, by using the maximum a posteriori (MAP) estimator, we estimate s from y. The MAP estimator for (2) and (8) is as follows(9)Sˆ(Y(m))=argmaxS(m)p(S(m)|Y(m)).By using the Sendur's pdf (8) and the MAP estimator (9), a new shrinkage function known as bivariate shrinkage function is obtained (Sendur and Selesnick, 2002)(10)Sˆc−1(m)=((Yc−1(m))2+(Y(m)c)2−((3σN2)/σS))(Yc−1(m))2+(Yc(m))2⋅Yc−1(m),where σNis the standard deviation of zero mean noise estimated by Eq. (4) (Sendur and Selesnick, 2002).Sˆc−1(m)denotes the denoised wavelet coefficient. In order to avoid negative values under the square roots, the standard deviation of the clean signal was computed byσS=max(Mean[Yc2]−σN2,Epsilon). Epsilon is an extremely small positive number (we use the smallest positive value which is defined in Matlab software). Unlike the ordinary shrinkage functions (i.e. Donoho's thresholding function), the bivariate shrinkage function uses two items (the wavelet coefficient and its parent) for wavelet denoising. Therefore, Sendur called this method as the bivariate shrinkage function.The focus of our study is to improve speech enhancement based on bivariate shrinkage by finding wavelet decomposition methods that have joint parent–child distribution similar to the Sendur's distribution. It is important, because bivariate shrinkage is proposed based on the assumption that the joint pdf between a wavelet coefficient and its parent is similar to Sendur pdf. Therefore, in the case that this similarity is high, we expect that the Sendur's bivariate shrinkage function works better. In the following subsections, we propose several wavelet structures and investigate the joint distributions of the wavelet coefficients. Then to find the best wavelet structure for the bivariate shrinkage, we compare those distributions with the Sendur's pdf. The following subsections elaborate on the wavelet structures which are used in this study.In this section, we propose features obtained by two-channel critically sampled filter-bank to implement bivariate shrinkage. Here, Daubechies are used as mother wavelet functions. From Daubechies wavelet family, db6 is chosen as the mother wavelet.In order to find the appropriate wavelet features for speech enhancement it is required to consider time domain characteristics and frequency responses of the wavelet functions. The wavelet coefficients should be appropriately chosen to represent the signal features. In order to obtain the wavelet features, we continue the analysis of signal up to level 6. Therefore, 7 vectors are obtained.Here, we review the appropriateness of the Sendur's bivariate shrinkage for the two-channel DWT. In this regard, the joint parent–child histogram of each stage of decomposition is computed using TIMIT11See Section 5.1.speech signals. The joint histograms are illustrated in Fig. 2. Each histogram is obtained by computing the average values of the several histograms which are plotted for several frames of the TIMIT signals. In our study, we choose db6 as the mother wavelet, because using this mother wavelet leads to joint parent–child histograms that are more similar to the Sendur's pdf compared with other Daubechies mother wavelets.Review of Fig. 2 indicates that the joint distribution of the first and the second stages of decomposition is the same as the Sendur's joint pdf. Similarly, Fig. 2 shows that the joint histogram for the second and the third stages of decomposition are the same as Fig. 1. However, for the next stages of decomposition, this assumption is not valid and the distributions are very different from the desired one. As explained in Section 2.2, Sendur's bivariate shrinkage function is proposed by assuming that the joint distribution between a wavelet coefficient and its parent is the same as Sendur pdf. Therefore, we expect the Sendur's bivariate shrinkage function to lose its effectiveness. Hence, if one would like to use bivariate shrinkage method for speech enhancement, other thresholding methods should be used for stages after the third stage.In order to express this quantitatively, we use Kullback–Leibler Divergence (KLD) (Bishop, 2006) to show statistical differences among those joint histograms. The KLD results are summarized in Table 1.Table 1 confirms that the joint distributions of the first and second stages’ coefficients and the second and third stages’ coefficients are very close to Sendur joint pdf. However, after the third stage we observe strong increases in the KLD values (see Table 1). It means that these histograms are far from the desired distribution.In original DWT the quality factors of the filters remain constant. In auditory system, however, the quality factors of natural filters vary in a small range (Yao and Zhang, 2001). In order to obtain more precise analysis of signals in time and frequency domains, we suggest using an M-channel filter-bank in wavelet framework (M>2) (Tohidypour et al., 2012). Using these types of structures give us more degrees of freedom in designing wavelet functions. Here we use three channel wavelet filter-bank with dilation 2. In this structure, there are a scaling function and two wavelet functions. Therefore, this structure makes more frequency divisions than the structure presented in Section 3.1. In fact, speech signal is built by these functions and their dilation. We use the three-channel filter-bank illustrated in Fig. 3. This structure was named three-channel double density DWT (TCDD-DWT) by Selesnick (Selesnick, 2001). In TCDD-DWT, in addition to the low-pass and high-pass filters, a band-pass filter is added between the low-pass and high-pass filters. Thus in this structure, there exist more accurate frequency divisions compared to the two-channel critically sampled filter-bank (Tohidypour et al., 2012).As can be seen in Fig. 3, this three-channel filter-bank is redundant. Meanwhile, it has better shift-invariant properties than critically sampled filter-banks. Shift-variant property causes problem in noise estimation, especially when the clean signal is degraded by a periodic noise. In this case, even a small shift in time domain may cause error in noise estimation (see Appendix A.1). Therefore, we suggest this structure for speech enhancement. In order to find the wavelet features, we continue the analysis of the signal up to level 6 using analysis filters depicted on the left side of Fig. 6. Then, 13 vectors are obtained. After removing the estimated noise, the enhanced signal is reconstructed by using the synthesis part of the filter-bank.In 2004, Selesnick and Abdelnour suggested appropriate filters for this structure (Selesnick and Abdelnour, 2004). From their suggested filters, we have chosen symmetric scaling filter with two wavelet filters. These wavelets are symmetric and anti-symmetric, respectively (Selesnick and Abdelnour, 2004). The filters values are presented in (Selesnick and Abdelnour, 2004; Tohidypour et al., 2012).Here we want to know if the Sendur's joint distribution is appropriate for the TCDD-DWT. The joint parent–child histograms of each stage of decomposition are computed using TIMIT speech database. Then, statistical differences among parent–child histograms of each stage of decomposition and the Sendur distribution are measured using KLD (see Table 2).As can be seen in Table 2, the KLD values are less than 0.5 up to stage four of decomposition. It shows that joint parent child histograms of the TCDD-DWT are similar to Sendur joint histogram upto stage four. Therefore, we expect the features which are obtained by TCDD-DWT to work better in speech enhancement method using bivariate shrinkage compared to the DWT's features. However for the fifth and the sixth stages the KLD values are equal or greater than 1.9. Hence we can remove noise by ignoring the joint distributions of the coefficients of the fifth and the sixth stages, using Sendur's bivariate shrinkage function. Therefore, it would be better to use another shrinkage function for the fifth and the sixth stage of decomposition.In order to improve speech enhancement based on bivariate shrinkage we suggest a new structure. In this structure, redundancy is more than those structures presented in Sections 3.1 and 3.2. Therefore, this structure is more time-invariant than the former ones, leading to better noise estimation compared to the previous presented structures. We use three-channel redundant filter-bank illustrated in Fig. 4. This structure was named Higher Density Discrete Wavelet (HDDWT) by Selesnick (2006).Note, there is a small difference between this structure and the previous structure (TCDD-DWT). As can be seen in Fig. 4, in the third band of this filter-bank no decimation is carried out. Selesnick (2006) offered a solution for this structure. In the solution, three zero moments are used for the scaling and wavelet functions (namely, K0, K1 and K2) (Selesnick, 2006). Here, we consider different values of K0, K1 and K2 and tried to find the most appropriate ones for the Sendur's pdf. Experimental results showed that if we choose K1=1, K2=10 and K0=K1+K2=11, we get better results for TIMIT database. Choosing other values causes undesirable joint histograms. The filter coefficients were presented in our previous work (Tohidypour et al., 2012). Note: we use wavelet functions that have ten vanishing moments.Here we would like to know if the Sendur's joint distribution is appropriate for the HDDWT. The joint parent–child histograms of each stage of decomposition are computed using TIMIT speech database. These parent–child histograms are obtained by computing the average values of the histograms. The KLD results (see Table 3) indicate that the joint parent–child distributions of all stages of decomposition are almost the same as the Sendur's joint pdf. Therefore, we conclude that HDDWT with (K0,K1,K2)=(11,1,10) (Tohidypour et al., 2012) is more suitable for the Sendur's shrinkage function compared to the previous structures.In order to extract wavelet features using this wavelet filter-bank, we continue the analysis of the signal up to level 6 using analysis filters depicted on the left side of Fig. 4. This wavelet decomposition results in 13 vectors. After removing the estimated noise, the enhanced signal is reconstructed using the synthesis part of the filter-bank depicted on the right side of Fig. 4.Finally, we propose a new wavelet structure based on four channel redundant wavelet transform. In this structure, redundancy is more than those discussed in Sections 3.1–3.3. However, this structure is less shift-variant than the former ones, this brings us the ability to estimate noise more accurately in comparison to all the previous structures. We call this structure Four-channel double density discrete wavelet transform (FCDDDWT). This four-channel filter-bank is illustrated in Fig. 5. Two types of four channel redundant wavelet filter-banks were proposed in previous works (Tohidypour et al., 2010a). FCDDDWT filter-bank is even more redundant compared to four-channel discrete wavelet filter-banks which were proposed in previous works (Tohidypour et al., 2012).Here, we want to find appropriate filter values for FCDDDWT. Suppose x(n) and y(n) are the input and the output signals of the filter-bank showed in Fig. 5, respectively. Then, by using Z-transform Y(z) is obtained:(11)Y(z)=0.5[H0(z)X(z)+H0(−z)X(−z)]H01z+0.5[H1(z)X(z)+H1(−z)X(−z)]H11z+H2(z)X(z)H21z+H3(z)H31zX(z).After rearranging, we obtain the perfect reconstruction conditions:(12)H0(z)H01z+H1(z)H11z+2H2(z)H21z+2H3(z)H31z=2and(13)H0(−z)H0(z−1)+H1(−z)H1(z−1)=0In order to find appropriate values for these equations, let us factor H0(z) as(14)H0(z)=1+z−12K01+z−12K1A(z)The degree of A(z) will be denoted by L. Define(15)H1(z)=z−α1+z−12K01−z−12K1A(−1/z)(−z)−Mwhere A(z) will be computed in a way to satisfy Eq. (13). And(16)α=0,ifLisodd1,ifLiseven.Then α+L will be an odd value. In addition, M=L−K1. We factor H3(z) and H2(z) as(17)H3(z)=1−z−12K01−z−12K3A(−z)H2(z)=1−z−12K2Q(z),where Q(z) is computed based on the perfect reconstruction equation (12). It means that first H0(z), H1(z), and H3(z) are computed. Then, Q(z) is computed using (12). For (K0, K1, K2, K3)=(10, 6, 4, 5), the resulting filters obtained are listed in Table A.2.1 in Appendix A.2. We choose these values, because they lead to filters which are appropriate for the Sendur's bivariate shrinkage. The normalized scaling and wavelet filters are illustrated in Fig. 6. In addition, the scaling function and the wavelet functions of FCDDDWT are also depicted in Fig. 6.The frequency response of FCHDDWT filters and frequency response of four-stage decomposition using FCDDDWT are illustrated in Fig. 7. In order to provide the wavelet features, the analysis of signal is continued up to level 6 using the analysis filters. Therefore, 19 vector parameters are obtained.Here we would like to know if FCDDDWT's coefficients have the joint distributions similar to the Sendur's joint distribution. The joint parent–child histograms of each stage of decomposition are computed using TIMIT speech signals. These histograms are found for the second, the third, and the fourth channels of the filter-bank. In order to verify the legitimacy of using bivariate shrinkage function for the wavelet coefficients obtained from FCDDDWT, KLD values among the joint parent–child histograms and the Sendur's pdf are computed and reported in Table 4. Quantitative analysis using KLD shows that the joint distributions are almost the same as the Sendur's pdf.Finally, the average is taken separately for each stage of decomposition over the histograms of the three channels (second, third, and fourth channels). The average joint parent–child histograms of each stage of decomposition are shown in Fig. 8. Fig. 8 confirms that the joint distributions of all stages of decomposition are almost the same as the Sendur's joint pdf. Since the bivariate shrinkage function is obtained by assuming that the parent–child joint histograms are the same as the Sendur's pdf, we conclude that FCDDDWT with (K0, K1, K2, K3)=(10, 6, 4, 10) is appropriate for the Sendur's shrinkage function.In order to enhance speech using this wavelet filter-bank, we continue the analysis of the signal up to level 6 using analysis filters depicted on the left side of Fig. 5. The wavelet decomposition results in 19 vectors. After removing the noisy components of the wavelet coefficients, the enhanced signal is reconstructed using the synthesis part of the filter-bank depicted on the right side of Fig. 5.In this section we discuss the implementation of the above mentioned methods for speech enhancement. As a first step, speech signals are divided into frames of 512 samples. Then wavelet transform is applied to the frames. Decomposition continues up to the sixth stage of decomposition. Each frame is classified as either voiced or unvoiced frame. Then the speech enhancement method is applied to each frame. Finally, the enhanced signal is reconstructed using inverse DWT. In the following subsections first we introduce the Voiced/Unvoiced method, which is used in this study. Then, the speech enhancement methods, which are used in our work, will be explained.In order to improve the performance of the speech enhancement methods, it is crucial to categorize the noisy speech signal into voiced and unvoiced regions. In this regard, we know that the energies of the unvoiced frames are comparable to those of the noise. However, voiced phonemes are created by the vibration of vocal cords (Sheikhzadeh and Abutalebi, 2001; Wang et al., 2006). Hence, certain features are needed to classify these phonemes (V/UV classifier). Jafer and Mahdi (2003) suggested two approaches for V/UV classification:(1)Comparing the energies of wavelet bands below 2kHz and above 2kHzComparing zero crossing ratesThen, Jafer used the combination of these two approaches to categorize a frame into voiced and unvoiced frame (Jafer and Mahdi, 2003). In this work, the method proposed by Jafer is used with some modifications.It is known that most of the energies of the unvoiced phonemes are concentrated in higher frequency bands of speech signals. On the other hand, for the voiced phonemes, energies are concentrated in lower bands. According to Jafer's report, when the energies of the bands below 2kHz are smaller than those of the bands above 2kHz, the frame should be classified as an unvoiced frame. If this condition is not met, the frame is classified as a voiced frame (Jafer and Mahdi, 2003).In order to perform V/UV classification for two-channel DWT, the ratio (Rk) between the energy of the frequency bands below 2kHz to that of the frequency band above 2kHz is computed as follows (Jafer and Mahdi, 2003)(18)Rk=∑i=26EiE1,where k is the frame number, E1 is the energy of the first stage's coefficients (energy of the bands above 2kHz) and Eiis the energy of the ith stage of decomposition. If Rk<0.95, the frame is classified as unvoiced (Jafer and Mahdi, 2003).Based on the above discussion, we modify Rkinto the following form for three-channel DWT-based V/UV classification(19)Rk=∑i=26∑j=23Ei,jE1,where E1=E1,2+E1,3 is the energy of the first stage's coefficients (energy of the bands above 2kHz) obtained from the second and third channels of the three-channel filter-bank. Ei,jis the energy of the jth channel at ith stage of decomposition. If Rk<1, the frame is classified as unvoiced. For four-channel DWT, Rkis modified by substituting j=2,3,4 and E1=E1,2+E1,3+E1,4 in (19).In Jafer and Mahdi (2003), it is reported that when the zero crossing rate of a frame (ZCRk) is higher than the median of ZCRs of all frames, the frame is classified as an unvoiced frame. In Jafar's study, ZCRkis computed as follows (Jafer and Mahdi, 2003)(20)ZCRk=∑n=0L−1|sign[xk(n)]−sign[xk(n−1)]|,where xkrepresents a speech frame. In our study based on Jafer's suggestion, V/UV classification is carried out using the above two algorithms (Jafer and Mahdi, 2003). Then, level-dependent threshold is computed for the voiced frames as follows (Wang et al., 2006)(21)σN,k=σN2ln(L)ln(i+1),where i shows the stage of decomposition and L denotes the number of coefficients of the ith stage of decomposition. For unvoiced frames the level-dependent threshold is computed as follows (Wang et al., 2006)(22)σN,k=σN2ln(L)ln(i2+1).Here, σNis obtained using (4). According to (21) and (22), in level-dependent threshold setting, the denominator is increased from each stage to the next stage of decomposition. This is based on the fact that most speech information is concentrated in lower frequencies. We use (21) and (22) just for Zhang thresholding.As explained before the joint parent–child histograms of the two channel DWT are similar to the Sendur's pdf up to the second stage of decomposition. As a result, we implement speech enhancement based on two channel DWT in two different ways. We call the first method as Bivariate Two-channel DWT (M-1) and the second one as Proposed Bivariate Two-channel DWT (Pro M-1). In our implantation, for both M-1 and Pro M-1, two-channel DWT is first applied to each frame, leading to 7 vectors per frame. The standard deviation of noise is estimated using (4). The coefficients of the detail part of the first stage of decomposition are used in that equation. Then in the M-1 method, the bivariate shrinkage function is applied to all coefficients in different stages of DWT. Unlike M-1, for Pro M-1 method, we use the V/UV classifier and level-dependent σN. In this regard, we suggest σN,kfor the voiced frames as follows(23)σN,k=σNln(i+1).σN,kis substituted with σNin the Sendur's bivariate shrinkage function. On the other hand, for the unvoiced frames σN,kis given by(24)σN,k=σNln(i2+1).Since the joint histogram of the two-channel DWT coefficients are similar to the Sendur's distribution only up to the second stage of decomposition, in the Pro M-1 method, the bivariate shrinkage is only used for the first and second stages. Here, we use level-dependent bivariate shrinkage using (23) and (24) which are applied to (10). For higher stages of decomposition, we use Zhang thresholding (6). Our experimental investigations show that if we use (21) and (22) instead of (23) and (24), the quality of enhanced speech signal decreases dramatically. Therefore, we use (23) and (24) to compute σN,k.For the Bivariate TCDD-DWT (M-2) and Proposed Bivariate TCDD-DWT (Pro M-2), three-channel double density DWT (TCDD-DWT) is applied to each frame. The decomposition is continued up to the 6th level. Thus, 13 feature parameters are obtained. Similar to M-1, in the M-2 method, we apply bivariate shrinkage to all the detail vectors. Here, V/UV classifier and level dependent σNare not used.Similar to Pro M-1, in the Pro M-2 method, V/UV classifier and level-dependent σNare used. Here, TCDD-DWT is applied to each frame. From Section 3.2, we understand that the joint histograms of the TCDD-DWT coefficients are similar to the Sendur's pdf exactly up to the stage four of decomposition. Therefore, in the Pro M-2, bivariate shrinkage (10) is used for the stages 1–4. Unlike M-2 method, we apply level-dependent bivariate shrinkage using (23) and (24) in (10) for the voiced and the unvoiced frames, respectively. For the decomposition stages higher than four, we use Zhang thresholding (6). The value of T is computed similar to the level-dependent threshold proposed in Section 4.1.2. As mentioned before, (23) and (24) are used for the voiced and the unvoiced frames respectively in order to determine T in Zhang thresholding (6).For the Proposed Bivariate HDDWT (M-3) method, three-channel HDDWT is applied to each frame and decomposition is continued up to the 6th level. Thus, 13 vector parameters are obtained. Bivariate shrinkage is then applied to all the detail vectors (from the first stage to the fifth). For the sixth stage of the decomposition, Zhang thresholding is applied to the detail and scale coefficients. Also, V/UV classifier is added and level dependent threshold is used for both bivariate shrinkage and Zhang thresholding. As mentioned before, equations (23) and (24) are used to make a level-dependent bivariate shrinkage (10). We want to indicate that because the joint-histogram of the parent–child wavelet coefficients of all the stages are the same as the Sendur's joint pdf, we do not implement two different methods for HDDWT. In the three-channel wavelet filter-banks, in order to apply bivariate shrinkage function to each stage of decomposition, both second channel and third channel coefficients of each stage and those of the next stage are considered as parent and child coefficients, respectively.For the Proposed Bivariate FCDDDWT (M-4) method, Four-channel double density discrete wavelet is applied to each frame and decomposition is continued up to the 6th level. Thus, 19 feature parameters are obtained. Adaptive bivariate shrinkage is then applied to all the detail vectors (from the first stage to the fifth stage). For the stage six of decomposition, Zhang thresholding function is applied to the detail and scale coefficients. Also, V/UV classifier is added and level dependent threshold are used for both bivariate shrinkage and Zhang thresholding. As mentioned before, Eqs. (23) and (24) are used to make the level-dependent bivariate shrinkage (Eq. (10)). In the four-channel wavelet filter-banks, in order to apply the bivariate shrinkage function to each stage of decomposition, the coefficients of the second channel, the third channel and the fourth channel of each stage and those of the next stage are considered as parent and child coefficients, respectively.We expect Pro M-1, Pro M-2, M-3 and M-4 methods to lead to the significant improvement in terms of speech quality in comparison to the M-1 and M-2 approaches, respectively. Here, the proposed approach is summarized in the following flowchart which is illustrated in Fig. 9.The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences (TIMIT Acoustic-Phonetic Continuous Speech Corpus). The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance. Corpus design was a joint effort among the Massachusetts Institute of Technology (MIT), SRI International (SRI) and Texas Instruments, Inc. (TI) (TIMIT Acoustic-Phonetic Continuous Speech Corpus).In order to contaminate the clean speech with noise, NATO RSG-10 noise data is used. This includes machinery, factory, aircraft, F16 cockpit, babble, tank, machine gun and other noises (NATO RSG-10 noise data). We use some of these noises in this study.While subjective quality measures could also be used for speech quality evaluation, in this paper, first we have based our judgments on objective quality measures. Among different available objective measures, Segmental SNR (segSNR) and Perceptual Evaluation of Speech Quality (PESQ) are the measures which are utilized to compare methods due to their popularity in area of speech enhancement (Hu and Loizou, 2008). PESQ is a method based on auditory perception and takes clean and enhanced signals as its inputs, and as a measure of the enhanced speech quality outputs a number between zero and 4.5. The higher this number, the better the quality of the enhanced signal (Hu and Loizou, 2008). Finally, we conduct two subjective tests using several human listeners.In this part, the results obtained using our database (TIMIT) data are presented. Figs. 10 and 11show the results obtained by applying the Sendur's bivariate shrinkage to two-channel DWT in time and frequency domains. It is clear that this approach destroys some important parts of signal in both time and frequency domains. However, according to Figs. 10 and 11, the proposed bivariate shrinkage in four channel double density DWT leads to better results and does not eliminate important parts of the signal compared to two-channel DWT.In order to examine the proposed methods, 30 utterances from the TIMIT database have been chosen and used for both objective and subjective studies. The performances of the methods are evaluated under four different noise conditions by computing corresponding segmental SNRs and PESQ. The TIMIT speech signals are down-sampled to 8kHz and degraded by various types of noise. The noises include White Gaussian Noise (WGN), Factory Noise (FN), F16 Cockpit Noise (F16CN), and Babble Noise (BN) taken from NATO RSG-10 noise database (Hu and Loizou, 2008). The proposed enhancement methods are applied to the noisy speech signals. In the following tables, we use abbreviations to represent methods: bivariate two-channel DWT (referred to as M-1), the proposed bivariate two-channel DWT (Pro M-1); bivariate TCDD-DWT (M-2), the proposed bivariate TCDD-DWT (Pro M-2), the proposed bivariate HDDWT (M-3), and the proposed bivariate FCHDDDWT (M-4). In addition, our proposed methods are compared with three well-known speech enhancement techniques, including Ephraim Malah filtering (referred to as M-5) (Ephraim and Malah, 1984), Wiener filtering (referred to as M-6) (Scalart and Filho, 1996), and spectral subtraction (referred to as M-7) (Boll, 1979). In order to evaluate the performance of each method, we make noisy speech signals with input SNRs of −10, −5, 0, 5, 10 and 15dB.In all of wavelet based methods, the highest frequency band of the wavelet decomposition is used to estimate noise standard deviation. The output segmental SNR of the six proposed methods and the three state-of-the-art methods are presented in Table 5. Results reveal that the proposed methods consistently outperform the original method (M-1). As it is observed from Table 5, for wavelet based methods the improvement is in the range [0.01, 3.35] dB in segmental SNR. Also, M-4 works better than the other wavelet based methods in all noise levels and all noise types. The next best method is Pro M-3 in all noise types. For the WGN, M-4 works better than all of the methods when input SNR is larger than −5dB. For the FN, M-6 outperforms other methods in most of the cases.The PESQ results for the outputs of the six wavelet based methods and three state-of-the-art methods are presented in Table 6. Almost the same performances are once again observed here. As it is observed from Table 6, the improvement is in the range [0.28, 0.84] in PESQ for wavelet based methods. Once again M-4 outperforms other wavelet based methods in all noisy conditions. For the WGN, M-4 outperforms other eight methods (wavelet based and Fourier based methods) except when input SNR is equal to −5dB. For FN, M-5 is the best method in terms of PESQ performance. For the BN, M-4 works better than all of the methods when SNR is equal to or greater than −5dB. Altogether, according to the tables discussed, all the wavelet based methods have better performances than those of M-1. Especially, M-4, M-3, and Pro M-2 work better than the other wavelet based methods. This success is achieved because in those methods, multi channel redundant wavelet filter-banks are used. These structures are less shift sensitive than critically sampled two-channel wavelet filter-banks. Therefore, we can better estimate amount of noises. This is based on the fact that the amount of noise is estimated using wavelet coefficients. Therefore, using shift-sensitive transform can lead to wrong results.Another important point is that empirical joint histograms of parent–child coefficients of both FCHDDWT and HDDWT are similar to the Sendur's histogram up to the fifth stage of decomposition. Therefore, they work better than the other wavelet based methods. Finally, Using V/UV detector and level dependent bivariate shrinkage have led to improved results. As explained, M-4 works better than all the proposed wavelet based methods. It is because M-4 method uses a less shift sensitive wavelet transform.One interesting observation is that M-4 works better than all the presented wavelet based methods and Fourier based methods for WGN in most of the SNR cases. It is because M-4 method uses a less shift sensitive wavelet transform and the bivariate shrinkage function which was proposed for the case that the noise type is white Gaussian noise.The objective measures used in the previous section need the clean signal and the noisy signal to evaluate the performance of the different methods. However, in most speech enhancement tasks the clean speech signal is not accessible. Therefore, another measures are needed to evaluate the performance of the proposed methods. To this end, we perform subjective quality tests. Several listeners are asked to participate in two subjective tests, namely, the mean opinion score (MOS) test and diagnostic rhyme test (DRT). The following subsections elaborate on the subjective quality measures and their results.In this subsection subjective quality results using MOS are presented. Ten subjects are asked to rate the enhanced signals in terms of quality. Here, standard MOS scale is used, where 5 shows the excellent quality, 4 indicates good quality, 3 shows fair quality (Slightly annoying), 2 shows bad quality, and 1 indicates annoying distortion. Average MOS of all of the methods for different types of noises are presented in Table 7.Table 7 shows that, the maximum average MOS belongs to M-5. The next one is M-4, followed by M-6, M-7, M-3, Pro M-2, Pro M-1, M-2, and M-1. Altogether, MOS results confirm objective results and show that our proposed methods improve speech quality significantly compared to M-1 method.One of the most common tests among the intelligibility tests is the DRT test. In this test, 75 one-syllable rhyming word pairs (word sets), which were suggested by Lim (2010), are used in our studies. The audio files of these word sets are available at http://www.isle.illinois.edu/sst/data/wTIMIT/. The rhyming words differ by only one initial consonant. Here, twenty subjects were asked to recognize words which are randomly selected from the list of rhyming word pairs. For example, when the word cold is the correct answer, the listeners see cold and fold as the choices on their answer sheets. The percentage of the correct responses (PCR) are reported in Table 8.As it is observed the performance of different methods in terms of DRT follows almost similar pattern as the case where PESQ is utilized for performance evaluation. Table 8 shows that the maximum DRT mostly belongs to M-4. For the WGN, the second method in terms of DRT performance is M-3 followed by M-5. For the FN and F16CN, M-5 is the second best method when input SNR is larger than −5dB. Similar to the Segmental SNR, PSNR and MOS results, the DRT results show that our proposed methods improve the speech quality significantly compare to M-1 method.In the previous sub-sections the subjective and objective results were presented. In this section, the average execution times of all the methods for different types of noises are compared in Table 9. Note that the execution times depend on the implementation of the methods as well as the processing power of the computer used in the experiment. In our study, the test platform is Intel Core i7-2.0GHz central processing unit, 8GB random access memory with Windows 7 operating system. Note, all the methods are implemented in Matlab software.As can be seen in Table 9, the fastest method is M-7. M-2 is the second to spectral subtraction, followed by Pro M-2, M-3, M-1, Pro M-1, M-6 and M-5.

@&#CONCLUSIONS@&#
