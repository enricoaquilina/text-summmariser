@&#MAIN-TITLE@&#
Bounded cepstral marginalization of missing data for robust speech recognition

@&#HIGHLIGHTS@&#
Robust recognition of noisy speech achieved via a novel missing data technique.Proposed modified bounded marginalization compatible with MFCC trained models.The second proposed technique is more accurate, but still fast and simple.The third method competes with imputation techniques considering accuracy.Proposed techniques are all simpler and faster than imputation techniques.

@&#KEYPHRASES@&#
Automatic speech recognition,Missing data theory,Noise robustness,Cepstral analysis,

@&#ABSTRACT@&#
Spectral imputation and classifier modification can be counted as the two main missing data approaches for robust automatic speech recognition (ASR). Despite their potentials, little attention has been paid to the classifier modification techniques. In this paper, we show that transferring bounded marginalization, which is a classifier modification method, from spectral to cepstral domain would be beneficial for robust ASR. We also propose improved solutions on this transfer toward a better performance. Two such techniques are presented. The first approach still does not need training of any extra model. It benefits from an observed characteristic of cepstral features and raises accuracy of previously proposed method to a comparable level with that of a classic imputation method. The second technique combines our originally proposed method with an imputation technique but replaces spectral reconstruction with a simpler and faster possible range estimation of missing components. We show that the resulting method improves the accuracies of either of the two combined methods. The proposed techniques also show good robustness when implemented with an inaccurate spectrographic mask.

@&#INTRODUCTION@&#
Achieving practical ways to Human-Machine spoken communication has been an ultimate goal in the past few decades. One of the most challenging parts of this task is Automatic Speech Recognition (ASR) (Jokinen and McTear, 2010). Currently, systems that exploit statistical modeling of speech – especially Hidden Markov Modeling (HMM) – are almost dominating the ASR field, because they have gained excellent recognition accuracies under unpolluted acoustic conditions (Benesty et al., 2008). However, their performances fall drastically when acoustic conditions in which they are tested differ from which they were trained. Additive environmental acoustic noise – which is common in practice – is one of the main contributors to the training-testing mismatch. It is customary to either train recognizer merely by information derived under clean conditions, which is known as clean training, or train it by information derived under various additively polluted conditions, which is known as multi-condition training. Extensive efforts have been carried out to make the recognizer more robust against additive environmental acoustic noise (Virtanen et al., 2012).Methods employed for robust ASR can be divided into two general categories of model compensation and feature compensation (Virtanen et al., 2012). In model compensation, the ultimate goal is to shift clean-trained statistical model parameters in such a way as if they were trained under present noisy condition. Parallel Model Combination (PMC) (Gales, 1993) and vector Taylor series (VTS) noise adaptation (Moreno et al., 1996) are among the most successful methods in this category. In contrast, in signal/feature compensation methods, models trained under the clean condition remain intact, while the efforts are concentrated on either extracting speech features that contain more information from speech than from noise, or remove the noise impairments from them. Cepstral mean and variance normalization (CMVN) (Furui, 1981), RASTA filtering (Hermansky and Morgan, 1994), histogram equalization (De la Torre et al., 2005), autocorrelation based feature extraction (Farahani et al., 2007) and missing data approaches (Cooke et al., 2001; Raj and Stern, 2005) are good examples in this category. Our proposed methods belong to the latter category.Recently, missing data robustness approach, which is a feature compensation approach based on the missing data theory, has shown promising results toward robust ASR. The fact that even in severe noisy conditions some regions of the log-spectrogram representation of speech remain almost intact is the main initiative in this approach. Hence, if one could detect these regions and somehow perform decoding only using them, destructive effects of noise could be mostly removed. First step to reach this goal is to identify these useful regions from the missing ones, which is known as mask estimation. Rich literature on mask estimation is now available (Virtanen et al., 2012), most of them like SNR estimation approaches, Bayesian classifiers (Seltzer et al., 2004) and perceptual (like Zhao et al., 2012) and binaural approaches (Harding et al., 2006) perform estimation as a preliminary phase to decoding. However, recently, there has been a trend to perform mask estimation and decoding simultaneously (Barker et al., 2010; Ma et al., 2012; Narayanan and Wang, 2013). After mask estimation, decoding should be carried out using incomplete log-spectrogram. The approaches proposed to achieve this goal can generally be divided into two groups, Classifier Modification (CM) and Spectral Imputation (SI) (Raj and Stern, 2005). In CM, the classifier is modified in a way to make it capable of classifying incomplete features. In other words, decoding is made merely using the reliable data. In SI approaches, the missing components are estimated and restored based on a trained prior knowledge. Decoding is then performed in a conventional complete-feature manner. While covariance-based (Raj et al., 2004), cluster-based (Raj et al., 2004) and sparse (Gemmeke et al., 2010; Gemmeke et al., 2011; Ahmadi et al., 2014; Yilmaz et al., 2014) imputation are among the most successful approaches in this category, the most important CM approach is bounded marginalization (Cooke et al., 1999). Furthermore, class-conditional imputation (Josifovski et al., 1999) is a combined technique of SI and CM. Uncertainty decoding (Droppo et al., 2003) also modifies the classifier in order to incorporate the uncertainty of features in decoding process. Since complete spectrogram reconstruction allows for the straightforward employment of common robustness procedures, such as cepstral analysis or feature normalization, SI approaches could be easily merged with these kinds of methods and consequently, majority of research in the field of missing data ASR have been carried out in the SI category (González et al., 2013; Wang et al., 2013; Remes et al., 2011; Goodarzi et al., 2010; Borgström and Alwan, 2010; Keronen et al., 2013; Badiezadegan and Rose, 2015). However, they also suffer certain drawbacks. Regardless of any imputation method employed, either a distinct statistical spectral estimation model or an ensemble dictionary should be trained and missing components of the log-spectrogram should be estimated at the decoding phase as well. These two processes are often computationally expensive, and if higher estimation accuracies were needed, algorithms became more complex and even more computationally demanding. Furthermore, even the best estimation algorithm is not perfect and adds an additional noise to the features (Virtanen et al., 2012; Raj and Stern, 2005; Hartmann et al., 2013).On the other hand, CM approaches need neither separate model training nor an estimation procedure, as they only use the reliable parts of data without any estimation (Virtanen et al., 2012; Raj and Stern, 2005). Nevertheless, due to certain obstacles, minor attention has been paid to them compared to SI approaches (Virtanen et al., 2012; Wang et al., 2013). Since modification of the classifier by marginalization of missing components is more straightforward in spectral domain, CM approaches have been usually carried out in this domain (Raj and Stern, 2005; May et al., 2012). This means that the structure of ASR classifier, learning process, and feature extraction should be modified to adapt to the spectral domain. According to a pervasive belief, efficiency of cepstral features is higher than the spectral ones, as their lower statistically correlated elements allow for a better acoustic modeling with diagonal covariance matrices. Furthermore, cepstral features have shown more robustness to the additive noise, while their normalization has led to a more effective compensation against channel distortion (Virtanen et al., 2012).In order to employ the beneficial properties of cepstral along missing data techniques, which would allow for modeling with diagonal covariance matrices, some methods have been proposed. In one kind of such approaches, the model parameters are retransformed to the log-spectral domain to perform marginalization (Hakkinen and Haverinen, 2001; Cerisara, 2003; Kim et al., 2010). In another kind, the missing data estimation process is modified in a way to use the reliable spectra as well as the predicted bounds of missed spectra (Van Hamme, 2003; Faubel et al., 2009; González et al., 2012; Wang and Van Hamme, 2012). These approaches are known as bounded imputation. Another approach is employing models with non-diagonal covariance matrices to effectively marginalize the missing features in the spectral domain (Kühne et al., 2008). As the computational load of this approach is relatively high, a set of new features, named PROSPECT, is introduced to alleviate the problem (Van Hamme, 2004).In this paper,11Part of this work has been previously presented as a conference paper (Ebrahim Kafoori and Ahadi, 2014).unlike classic bounded marginalization which uses reliable values and possible ranges in the spectral domain, we transfer them to the cepstral domain to construct cepstral possible ranges, and then marginalize them by modifying the decoder. Our motivation for establishing the technique is finding a way for better exploitation of potentials of CM approaches and making their accuracy levels competitive with SI approaches’. We show that this method not only outperforms bounded marginalization, but could also be a possible solution to the mentioned impediments on the way of CM approaches.Despite having a relatively simple computational structure and the ability to easily adapt to a conventional decoder, accuracy level of the technique is very lower than a classic SI method. Therefore, we propose two novel techniques based on our original method in order to improve the performance. The first technique modifies the possible ranges based on an observed property of cepstral features. Our experiments show a significant improvement of accuracy compared with the original method and also a comparable result with the classic SI technique. As a consequence of being a CM method, this technique neither needs to learn a separate model nor performs a spectral reconstruction procedure. The second improving technique employs a similar trained model of a SI technique to modify possible ranges more meaningfully. We examine this technique on the same framework and show that it gains a significant improvement over the first method and the SI technique. Despite having fairly lower complexity and computational cost than common SI methods, the two techniques manage to gain comparable and even better performances.The rest of the paper is organized as follows. Section 2 presents the CM approaches for handling missing data for ASR. In Section 3 we describe our proposed method to marginalize the missing data in cepstral domain. The proposed performance improving techniques are presented in Section 4. We perform some comparative practical experiments and discussions in Section 5 and finally conclude the paper in Section 6.In order to handle the non-stationary properties of speech, features are usually extracted from time-overlapped frames of speech and Fourier analysis is applied to each frame which results in the short-time Fourier transform (STFT). It is common to retain the absolute magnitude of STFT and discard the phase in such cases. We will call itXSm,kwhere m is the frame number (or time index) and k is the frequency index. Also a compressing function (usually the logarithm function) is often applied to the Absolute magnitude of STFT which results in log-spectrogram which we will refer to asXm,k. Furthermore, the frequency axis is often transformed to a new scale like mel or bark, which mimics the human ear frequency sensitivity. In this work we will consider this scale transformation when using the frequency index (k). Additive noise affects the absolute magnitude of STFT approximately in an additive manner. So the effect can be written as(1)Ysm,k=Xsm,k+Nsm,k,whereNsm,kandYsm,kare the spectrograms of noise and noisy speech respectively. Applying the logarithm function as the compressing function results in(2)Ym,k=log(XSm,k+Nsm,k).If, in a particularm,kpair,XSm,kgets far greater thanNsm,k, thenYm,kcould be a good approximation ofXm,k. If this is not the case, it is not possible to estimate an approximation forXm,k, but one can use the available information to estimate a possible range forXm,klike(3)−∞<Xm,k<Ym,kwhich expresses the range of possible amounts for theXm,kbased on the noisy observation. The lower bound of minus infinity in (3) can be effectively replaced by zero, since even a single weakest non-zero value in a frame could produce a larger than one value forXsm,kand consequently a positive value forXm,k(Cooke et al., 2001; Hartmann et al., 2013).If there is a prior knowledge of the values ofXsm,kandNsm,k, the time-frequency components can be classified into two groups of reliable and missing components by comparing these two values (Raj and Stern, 2005). The mentioned method results in a mask that is known as oracle mask (or ideal binary mask (IBM)). In practice, missing and reliable components are not known. Hence, it is impossible to obtain oracle mask in real conditions. However, this type of mask has certain usage in evaluating missing data handling approaches in artificially polluted conditions (Raj and Stern, 2005). Diverse methods for practical mask estimation have also been proposed (Kim and Hansen, 2011; Keronen et al., 2013; Cerisara et al., 2007; Demange et al., 2009).Acoustic models are usually trained with complete feature vectors. Hence, after mask estimation, the incomplete features should be made compatible with the acoustic models. Two different kinds of approaches have been proposed to tackle this problem. In Spectral Imputation (SI), original values of the missing components are estimated and restored to get a complete spectrogram, Simplified block diagrams of this approach is illustrated in Fig. 1(b). In the other approach, namely Classifier Modification (CM), which is depicted in Fig. 1(c), classifier is modified in a way to adapt acoustic models to incomplete features. It only employs the reliable information, without any estimation (Virtanen et al., 2012; Raj and Stern, 2005; Wang et al., 2013). Our proposed methods use the latter approach. In the remainder of this section we briefly discuss the most basic CM method, namely bounded marginalization (Cooke et al., 1999), as well as uncertainty decoding (Droppo et al., 2003), which modifies the classifier to handle uncertain features as well.The main goal in speech recognition is to find the best word sequencewˆdefined as(4)wˆ=argmaxw{Pw|O}=argmaxwP(O|w)Pwwhere O is the sequence of observed speech feature vectors and P(w) is the likelihood of the word sequence w which is calculated separately using the language model.In HMM-based classifiers, the fundamental contributing part ofP(O|w)calculation is the term P(Xc|s) which is the probability of a particular observation Xcin the sequence O given a particular state s. Subscript c in Xcmeans the observation vector consists of cepstral domain features like MFCCs. Usually, acoustic models are also trained using cepstral features and composed of mixtures of multivariate Gaussian distributions. This means that calculation ofPXc|sleads to(5)PXc|s=∑m=1MsCmPmXc|swhere Cmis the mixture weight coefficient, andPmXc|s, which is the probability of observation Xcin the mth mixture component of state s. In the case where mixture components are assumed to have diagonal covariance matrices, it is found as(6)PmXc|s=∏i=1d12πσcie−Xci−μci22σci,whereXci,μci, andσciare the ith elements of Xc, μc, and the main diagonal of Σcrespectively and d is the dimension of the feature vectors.In bounded marginalization (Cooke et al., 1999), feature vectors are incomplete and (6) is modified as(7)PmX|s=∏i∈R12πσie−Xi−μi22σi×∏i∈U∫LiHi12πσie−x−μi22σidx,where R and U are subsets of spectral components set, which include indexes of reliable and unreliable feature vector elements respectively, and H(i) and L(i) are the limits of the possible ranges for the missing components which are found by (3). Eq. (7) marginalizes unreliable features and at the same time utilizes all available information. As using X instead of Xcin (7) suggests, this approach employs log-spectral features. This is because of the use of mask estimation which is only applicable in this domain. Despite using only the reliable data in this approach, employing spectral features degrades the performance and also increases the computational cost.Uncertainty decoding which employs a different idea compared to the missing data techniques also deals with the problem of uncertain features. It assumes that the front end could output the uncertainty level for each feature element. Instead of modifying the integral range, the technique marginalizes over all possible unseen clean speech. Therefore, the output uncertainty changes the Gaussian mixture variances at the decoding phase. For a more uncertain feature component, more increase is applied to the variance. Generally speaking, it assumes that an estimated probabilistic model can link the uncertain features and clean-trained acoustic models. Either an independently trained model or a propagation function (e.g. (Droppo et al., 2001) and (Astudillo and Orglmeister, 2013)) is required to estimate the uncertainty variance in the Cepstrum from observed features.The uncertainty decoding still employs the unreliable feature values for decoding while changing the models by changing variances. On the contrary, bounded marginalization leaves the models unchanged but sets a possible range on the spectral feature values.In order to preserve the mentioned benefits of Bounded Marginalization and use speech modeling in cepstral domain at the same time, and also to avoid the extra computational cost and estimation error imposed by imputation, some techniques have already been proposed. Among the proposed solutions to the mentioned problem are retransferring model parameters from cepstral to spectral domain in order to perform spectral marginalization with cepstral-trained models (Hakkinen and Haverinen, 2001; Cerisara, 2003;Kim et al., 2010); taking the upper bounds of the missing parts into account, as well as the reliable parts, to reconstruct the spectra (Van Hamme, 2003; Faubel et al., 2009; González et al., 2012; Wang and Van Hamme, 2012); transferring masks or uncertainties from spectral to cepstral domain or estimating them in order to estimate the reliability level of available contaminated cepstral features (Srinivasan and Wang, 2007; Yi and Ge, 2010; Astudillo et al., 2010; Droppo et al., 2001; Astudillo and Orglmeister, 2013; Tran et al., 2014); combining decoding results from spectral marginalization and MFCC (Joshi and Guan, 2010); approximating the cepstral decoding integral (Seide and Zhao, 2010); and simply replacing missing spectral values with zeroes (Hartmann et al., 2013).The retransforming techniques perform decoding in the spectral domain, which increases the computational load and reduces the accuracy but they allow the decoder to employ MFCC-trained models. On the contrary, our proposed technique performs decoding in cepstral domain employing the same models. Furthermore, unlike the second mentioned group of approaches above, our technique does not estimate any exact value for the missing components.In our technique, we employ our novel possible range transfer function (Ebrahim Kafoori and Ahadi, 2014) which is applied to MFCC feature extraction process. The technique transfers spectral features to cepstral domain considering the reliable information instead of transferring the mask or uncertainties. It also employs a cepstral marginalization function to calculate observation likelihoods at the decoding phase. A brief overview of the technique follows here. The proposed technique is also depicted in Fig. 1(d).Original MFCC features are derived by applying the Discrete Cosine Transform (DCT) to the mel-scale log spectrum and discarding the higher order coefficients of DCT. The type II DCT, also employed in HTK feature extraction (Young et al., 2002), could be written as(8)Xci=2N∑k=0N−1XkcosπiNk+0.5=2N∑k=0N−1XkCFi,kwhere X(k) is the output log energy of kth mel-scaled filter and N is the number of filters. Also, the cosine term is concisely written asCFi,k.It is assumed that in the noisy conditions some reliable X(k)s are exactly known while the others are not. We form a possible range of values for each k based on the available information, similar to (3), as(9)Xrangek=Xmink,Xmaxk.Obviously, for reliable X(k)s,XminkandXmaxkwill have equal values. Then (8) can be written as(10)Xci=2N∑k∈RXkCFi,k+2N∑k∈UXkCFi,kwhere R and U are subsets of spectral parameters that contain the indexes of reliable and unreliable X(k)s respectively. The first term in (10) is a known constant which we refer to as C(i). In order to find the possible ranges for Xc(i)s, the second term should be considered. Because of the linear characteristics of the equation these ranges can be written as(11)XCmaxi=Ci+2N∑k∈POSiXmaxkCFi,k+2N∑k∈NEGiXminkCFi,k,(12)XCmini=Ci+2N∑k∈POSiXminkCFi,k+2N∑k∈NEGiXmaxkCFi,kwherePOSiandNEGiare two subsets of set U which are separately defined for each i as(13)POSi=k|k∈U,CFi,k>0NEGi=k|k∈U,CFi,k<0.The whole process transforms all available information in the form of {Xrange} to a new form ofXCrange. This new set consists of possible ranges for cepstral values in the form of(14)XCrangek=XCmink,XCmaxk.This leads to two upper and lower limits for the MFCC features. Fig. 2(a) illustrates log-spectrum of a noisy speech frame and the same clean speech frame. The missing points are also shown in the figure. Fig. 2(b) shows the MFCC values for the clean speech frame and also possible limits for the MFCC features of the same but noisy frame which are derived by (11) and (12). Apart from negligible approximations in (1) and (3), there were no approximations along deriving (11) and (12). Therefore, it is expected that the original clean cepstral features of a noisy frame fall inside the possible cepstral range. For examining this, we arranged some experiments in which we derived the clean MFCC features for some utterances as well as the ranges of (14) for artificially polluted version of the same utterances. Utterances were selected from the TIMIT continuous speech corpus (Garofolo et al., 1993), while noises were selected randomly from the NOISEX data (Varga and Steeneken, 1993) and added at different SNR levels. We observed that, in general, clean MFCC features almost always had values inside the ranges. Therefore, the range in (14) could be practically counted as an estimate for possible range of cepstral features.In order to find out how much information is lost during application of the proposed transfer function of (11) and (12), we first rewrite them asXCrange=T×{Xrange}, where T is a square linear transfer matrix. We observed that T is not a full rank matrix and it is not invertible. Consequently, some information is lost during the transfer if XCrange is employed as the feature vector. However, it is customary to omit the higher order coefficients of DCT, (8), which are believed to have minimal information of vocal tract characteristics as well as the recognition ability. We applied the same truncation to our feature vector. The employed feature vector can be written asXCrangetuncated=T′×{Xrange}, where T′ is a rectangular linear transfer matrix. We observed that, in the case of a size reduction of 23 to 13, T′ is a full rank row matrix. Therefore, the loss of information is not higher than the truncation ratio, 13/23, and not higher than the customary MFCC truncation.As (11) and (12) are derived from DCT, it is expected that characteristics of higher and lower order cepstral coefficients are still applicable to the new higher and lower order cepstral ranges. In some experiments, we observed that these characteristics are still present, and the application of the same MFCC truncation is a reasonable act.In bounded marginalization, Eq. (7) employs all available spectral information to calculate observation probability of each state. Considering that we have already transformed all spectral information in the form of (8) into the cepstral form of (14), calculation of this probability and consequently decoding could be carried out in cepstral domain. Knowing the possible cepstral ranges, in a manner similar to the derivation of (7), Eq. (6) could be transformed into(15)PmXC|s=∏k∈RC12πσcke−Xck−μck22σck×∏k∈UC∫XCminkXCmaxk12πσcke−x−μck22σckdx,where RCand UCsubsets are defined as(16)RC={k|XCmink=XCmaxk}UC={k|XCmink≠XCmaxk}.Eq. (15) is written with the diagonal covariance matrix assumption for Gaussian densities of HMM states. Also, the C subscript suggests that the acoustic model is trained with cepstral features. Hence, the proposed decoder of (15) can employ conventional MFCC-trained models. Consequently, unlike bounded marginalization, there is no need to switch to a new spectral feature-based acoustic model, which includes unusual and computationally expensive processes of spectral feature extraction and spectral model training. Furthermore, due to lower correlations between the elements of cepstral feature vectors, the widely used diagonal covariance matrix will be a more realistic assumption. Finally, more sparse nature and smaller feature vector dimensions in cepstral domain reduce the computational cost. One possible drawback for the proposed method could be the uncertainty spreading property of the DCT function, i.e. in a particular frame, unless the cepstral values found for lower and higher bounds match exactly, the integral in (15) should be calculated and therefore leads to more computational demands. However, knowing some points alleviates this problem. First, as mentioned before, is the intrinsic smaller dimension of cepstral features compared with spectral ones and the second is the availability of efficient numerical methods, which are specifically prepared for the calculation of this type of integral and known as Gaussian error function (Press et al., 1992). Such methods that calculate the integral with an acceptable approximation can help in narrowing the gap between the computational times of the first and the second terms of (15). We will show in Section 5 that despite using smaller feature vectors and consequently smaller models and with almost the same computational time, our proposed method outperforms bounded marginalization.Dynamic features are among very popular extensions to the standard static features to increase robustness in ASR systems. However, employing dynamic features have often been a source of problem in missing data methods. In SI methods complete spectral and cepstral features are available and dynamic feature calculation is possible. However, during dynamic feature calculation, probable incorrect estimations of missing components are further spread to the adjacent frames. In CM methods, because of the incomplete feature vectors, even more problems exist. In this paper, our focus is not on the dynamic features issue. Hence, to preserve fairness of our comparisons, in any CM method addressed here, we employ the intact set of dynamic features. In other words we calculate dynamic features from the raw noise-contaminated static features and count them as reliable features. For the case of SI methods, dynamic features are extracted from reconstructed features, as it is common for this kind of approaches.Our proposed bounded “cepstral” marginalization shows better performance than the classic spectral one, but still falls short of the classic and state of the art SI methods. One of the obvious reasons, for this upper hand of SI approaches, is that all SI approaches employ a separate model or dictionary to reconstruct the spectrum, while our proposed method only relies on the acoustic models.In this section, we introduce two performance improving approaches for the proposed method of Section 3. First, we benefit from an observed property of cepstral features to compress the possible ranges of (15). This approach still does not employ any model other than the acoustic model, but it shows fairly good improvement in the recognition accuracy compared with our original bounded cepstral marginalization. In the second approach, we attempt to estimate better and narrower possible ranges in spectral domain than that of (3). This will compress the ranges in the set{XCrangek}more meaningfully compared to the first proposed approach. This approach employs part of a classic SI method and a small separate model to estimate the spectral possible ranges. It can be considered as a kind of SI and CM combination.The differences between elements of pairs in the set{XCrangek}indicate the amount of unreliability in available information. If the average of these differences gets close to zero, then almost all available features are reliable and if it tends toward infinity, then all of the information is lost. As we mentioned earlier, the real unknown “clean” cepstral coefficient,XCcleank, lies inside the predicted possible range as(17)XCmink≤XCcleank≤XCmaxk.In order to increase the reliability of ranges of (14), which serve our technique as feature vectors, the predicted possible ranges must somehow be decreased. Hence the upper and lower limits of (17) should be modified. Modification of the limits means that (17) will not always be true and clean value may lie outside this range. The ultimate goal in this modification is to compress the range in a way that maintains the clean value inside the limits. In more precise words, range compression should be carried out in such a way that the probability of violating (17) will be minimal or relatively small.In order to find the best range compression method, first we introduce a parameter, namely Placement Ratio (PR), which is defined as(18)PRk=XCcleank−XCminkXCmaxk−XCmink.For the non-modified limits of (14), the value of PR is between zero and one. We omit the index k for the sake of simplicity in our future references. The value of PR states the placement point of clean value inside the predicted limits. A close to one PR states that the clean value is close to the upper limit, and for zero it is close to the lower limit. If for a given range of (14) and for each k, we could find the probability density function (PDF) of PR, fPR(·), which is defined as(19)Pa<PR<b=∫abfPRxdx,then we could find the best range compression method for (14). If the PDF has centralized figures over some regions, it means that, more probably, the unknown clean value lies in those regions. We can compress the ranges in such a way which preserves these probable regions inside the modified range.Since it is difficult to find this PDF theoretically, we arranged some experiments to get a glimpse of it practically. We artificially added various types of noise at different SNRs to some utterances. Noises were selected from the NOISEX data and utterances were selected from TIMIT speech corpus. Note that both of these corpora are different from our main evaluation dataset which is the AURORA 2.0 (Hirsch and Pearce, 2000). This preserves the independence between train and test conditions. Fig. 3illustrates histograms of the PR value for four different kinds of noises, namely white, pink, factory and car, as well as for different SNRs and ks.The interesting point in the diagrams is that PR tends toward values around 0.5, almost regardless of Noise type, SNR, and value of k (there is an exception when k is equal to zero). It should be noted that this is true for the cepstral features. In similar experiments in the spectral domain such centralization was not observed.This mediocre knowledge about the PDF function allowed us to choose a simple range modification method. As the probabilities of having PR values near zero or one are predicted to be relatively small, we move the upper and lower limits of (14) toward the center concurrently as(20)XMCmink=XCmink+1−a2XCmaxk−XCminkXMCmaxk=XCmaxk−1−a2XCmaxk−XCmink,where a is the coefficient of compression which has a range of values between 0 and 1. When a is equal to one there is no modification and when a equals zero the limits meet in the midpoint.Different observed histogram for k=0, which is centralized around 0.8, requires a different modification method to the limits of 0th coefficientas(21)XMCmin0=XCmin0+1−bXCmax0−XCmin0XMCmax0=XCmax0.The ranges of (14) will be replaced by (20) and (21)22If log energy coefficient is employed instead of 0th cepstral coefficient, a similar function is believed to be applicable to as well.and our proposed bounded cepstral marginalization of (15) will be used along the resulting ranges for decoding. In order to find the best values for the compression coefficients, a and b, we present an analytical optimization, as well as a practical experiment for optimization. We express the practical optimization in Section 5.2. Analytical optimization is presented in Appendix A.The first improving technique relies solely on the acoustic features. In order to further improve the results, in our second improving technique we employ a reconstruction model of a classic SI technique. We avoid performing the computationally demanding reconstruction process but employ the model to estimate spectral possible ranges for the missing components more meaningfully than what is done in (3).In this approach, which we call spectral variance learning (SVL), first we employ the extra model, to estimate spectral possible ranges instead of exact spectral reconstruction. In the second phase, we transform these ranges to the cepstral domain using our originally proposed transfer function of (14) and also apply our proposed bounded cepstral marginalization of (15).Covariance-based spectral reconstruction is one of the classic SI approaches, where log-spectral vectors are assumed to be samples of a stationary process (Raj et al., 2004). Statistical parameters of this process, namely mean, covariance, and normalized covariance, are defined by(22)μk=EXm,kcξ,k1,k2=EXm,k1−μk1Xm+ξ,k2−μk2rξ,k1,k2=cξ,k1,k2cξ,k1,k1cξ,k2,k2where E[·] stands for the expected value and ξ states the frame number difference, which is the same as the time difference. These parameters can be estimated using the clean training corpus. In the reconstruction phase, these parameters are employed to estimate the missing components of log-spectrum.We propose utilizing these parameters to estimate a predicted possible range for the missing components instead of exact value estimation. This could alleviate the effect of incorrect reconstruction because there is a good probability that a well estimated range contains the “clean” original value.In covariance-based imputation, reliable and highly correlated spectral components to each missing component are being found and employed, in order to estimate that missing component. Spectral components which have higher r values than a threshold are counted as highly correlated.We introduce a criterion to measure how reconstructable each missing spectral component is as(23)Rm,k=1N∑m′,k′∈Cm,krm−m′,k,k′,whileCm,kis defined asCm,k={m′,k′|rm−m′,k,k′is among the N biggest absolute values of reliable r(m,k)s}.Rm,kroughly states that how much reliable data is available to restore the missing component. Also, N could be selected empirically (we have selected N equal to 16 but other values are also applicable). A close to one value forRm,kmeans the availability of highly correlated information and a close to zero value means lack of information for estimation of missing components.Our experiments showed that there is a statistical dependency between the value ofRm,kand the normalized difference between the real “clean” value and the observed value of the missing component. We introduce this normalized difference as(24)Dm,k=Xm,k−Ym,kc0,k,kwherec0,k,kis taken from the estimated values of (22).In these experiments, we contaminated some utterances with different types of noises at different SNRs and found the missing components. We artificially contaminated 400 randomly selected utterances from the training section of Aurora 2.0 data with four types of randomly-chosen noises which were identical to the noises of its test set B, at randomly selected levels of SNR between −5dB to 20dB. Doing this left test sets A and C completely independent from the training information. For each missing spectral component we found the pair (Rm,k,Dm,k) and drew a scatter plot in which every pair is shown with a small circle at horizontal and vertical coordinates according to the values ofRm,kandDm,k. Fig. 4illustrates the scatter plot for a particular value of k. This figure suggests that there is a statistical dependency betweenRm,kandDm,k. Therefore, this dependency could help us find a possible range forDm,kwhile knowingRm,k. A similar dependency was also observed for other values of k. Fig. 4 also illustrates the means and variances ofDm,kfor missing components with certain values ofRm,k. Means and variances are calculated for ten groups ofRm,kvalues. ForRm,ksvalues close to one, statistical mean of D gets close to zero and its variance decreases, which suggests that for the highly reconstructable spectral components, the “clean” value is relatively close to the observed value and the possible range for clean value is relatively small.This experiment suggests that the possible range for missing components of the log-spectrum could be estimated using the value ofRm,k. In order to perform this range estimation, we created a small distinct model based on the results of the experiment as(25)MDRi,k=1N∑m,k∈SRi,kDm,kSDDRi,k=1N−1∑m,k∈SRi,kDm,k−MDRi,k2whereMDRi,kandSDDRi,kare estimators of mean and standard deviation respectively in uniformly divided sections in the range of R.SRi,kand Riare defined as(26)SRi,k={m,k|(Ri−1)/RN<Rm,k≤Ri/RN}Ri=1,2,…,RNRNis number of selected sections and can be selected empirically. We have set it to 10 as it is clear from Fig. 4. We will call the trained model of (25) as the spectral possibility model (SPM).In order to employ this model, we first findRm,kfor each missing spectral component. Then instead of using (3), we employ the trained parameters of (25) to estimate a possible range for the missing value as(27)Xˆminm,k<Xm,k<Xˆmaxm,kXˆminm,k=maxYm,k+MDRm,k×RN,k−A×SDDRm,k×RN,k,0Xˆmaxm,k=minYm,k+MDRm,k×RN,k+A×SDDRm,k×RN,k,Ym,kwhere⋅stands for the integer ceiling function. Range expanding parameter A should be adjusted for the best performance and we arranged an experiment to find useful values for this parameter which will be discussed in the Section 5.2. We then transfer the ranges found in (27) to the cepstral domain, using the method proposed in the third section, and apply bounded cepstral marginalization in the decoding phase.We evaluated our proposed methods on Aurora 2.0 data (Hirsch and Pearce, 2000). Aurora 2.0 is an ASR task which consists of utterances of English connected digits and contaminated by artificially adding noise. The training dataset includes 8440 utterances from 55 male and 55 female speakers. It consists of two clean and multi-condition sections. The multi-condition section is comprised of both contaminated utterances and clean ones. In our experiments, all of the discussed techniques are tested using the clean-conditioned training. For comparison purposes, we have also reported the results of multi-condition training for MFCC features as well as the results of ETSI Extended Advanced Front-End (ETSI-XAFE) (ETSI Standard, 2003) with clean training. The ETSI-XAFE is employed with the zeroth coefficient and it is appended with delta and delta-delta dynamic features. Test sets are comprised of 4004 utterances from 52 male and 52 female speakers. Test set speakers are different from the training set speakers. Test data is divided into three sections which are named A, B and C. Sets A and B are each contaminated with four different additive noises at six different SNR levels (20, 15, 10, 5, 0, and −5dB) while set C is just contaminated with two noises at the same SNR levels. Clean utterances are also included in all test sets. In order to evaluate the communication channel effects, a different channel effect is applied to set C compared with the two other sets.In Aurora 2.0, HMM modeling is performed using the HTK (Hidden Markov model toolkit) (Young et al., 2002). A model with 16 hidden states is defined for each single digit as well as for the word “oh” as a variant reading for digit “zero”. Also, two shorter models are dedicated to “silence” and “short-pause” parts of the utterances. Topologies of the main models are left-right without skip transitions. Observation probabilities of each state are modeled with three multivariate Gaussian mixtures with diagonal covariance matrices. The baseline feature set employed in the experiments consists of 39-element feature vectors comprising the standard 13-element MFCC feature vector (including the 0th coefficient) appended with the 26-element delta and delta-delta components. Also, a 24-element log-spectral mel-scaled feature vector appended with the delta and delta-delta components, resulting in a 72-element feature vector is used, when spectral features are addressed.Features are extracted from frames with lengths of 25 milliseconds and 15ms of overlap with the adjacent frames. Conventional preprocessing procedures such as pre-emphasis, Hamming windowing, 256-point FFT, triangular mel-scaled filter bank with 24 filters, and compressing the output energy of filters using the logarithm function are applied to obtain the log-spectrogram.Aurora 2.0 task has three phases of feature extraction, model training, and testing. We preserved model training in its original HTK developed framework for either cepstral or spectral features. In order to apply the classifier modification either in the bounded marginalization or in our proposed techniques, we developed a code to replace the HVite.c function in the HTK. The code was developed to implement the Viterbi beam search algorithm similar to the one implemented in HTK, but with the ability to apply either (7) or (15) in the decoding procedure. In our proposed techniques, feature extraction has to be modified. Therefore, a new feature extraction framework has been developed. For the sake of fair comparison and correct model training, we do not employ the HTK feature extraction procedure for any of the techniques tested in this paper, but feature vectors of baseline techniques are extracted using parts of the same developed framework for our proposed techniques. An oracle mask is derived based on previous knowledge about local SNR values, in each set of experiments. In order to evaluate the robustness of the discussed techniques against real masks, a simple estimated mask is also employed for all techniques. Mask estimation is carried out by estimating SNR values using a simple spectral subtraction technique, which estimates the noise and speech spectrum at each frame. The first and last few frames of each utterance are considered as environmental noise and the noise spectra of the middle frames are estimated using linear interpolation. The mask is estimated by applying a zero threshold on the resulting SNR value. This mask estimation technique is chosen because of its simple structure. Since different mask estimation techniques could work well along different missing data techniques, the obtained results of techniques employing our estimated mask could be an indication of robustness against an inaccurate mask, but definitely not a proof.We have based our proposed techniques on bounded marginalization in which the model variances remain unchanged but integral boundaries in feature domain are modified. Consequently, the experiments are carried out comparing with the similar baseline technique.In order to get a performance comparison between our techniques and a classic spectral imputation method, we implement the covariance-based imputation (CI) technique (Raj et al., 2004) in a similar framework for the sake of comparison fairness. We use the same 39-element MFCC feature vector and train the acoustic models using the HTK. In fact the acoustic models employed in CI implementation and our techniques are the same. We also train the parameters of (22) using 8440 utterances in the clean training section of Aurora 2.0 and common statistical estimators. We estimate the parameters of (22) for the ξ values ranging from −50 to 50. This is selected practically, as we observed that a missing component has highly correlated components usually only within a 25 frame range and we foresightedly set the radius to 50. We implement the spectral reconstruction according to the maximum a posteriori (MAP) technique of (Raj et al., 2004) and the decoding phase based on (6). In the CI technique, for each frame with at least one missing component, highly correlated reliable components are found by applying a 0.5 threshold on the r value in (22). We also apply the same threshold.In order to estimate the optimum values for the adjustable parameters of the proposed cepstral possible range compression and spectral variance learning techniques, we use a development test set. This set was selected from 400 utterances of test set A with equal distribution between the speakers. Contaminating noise types and their SNR values were also equally selected from all available types and values.In Section 4 we proposed cepstral possible range compression (CRC) as an extension to bounded cepstral marginalization. As (20) and (21) suggest, two values, namely a and b, should be determined. We perform this optimization both analytically and practically. The analytical optimization is presented in Appendix A. Here, we explain the practical optimization procedure. We arranged some development tests to find appropriate ranges for the optimum values of these two parameters. The mentioned development test set was selected for the experiments. As two adjustable parameters exist, performance had to be optimized on a 2-dimensional plot. Both a and b may have values between 0 and 1, so the optimum region could be found on a unit square like in Fig. 5(a). According to the motive of proposing CRC, compressing the possible range should lead to a better performance. However, excessive compression may result in focusing on a wrong point, loss of information, and missing the real value out of the compressed range. This heuristically tells us to expect an optimum region for both a and b somewhere between zero and one. We first set the steps of change for a and b to 0.1 and 0.05. Knowing that optimization should be performed on a unit square, this led to 200 evaluation points. As it was time consuming to evaluate all points, we first evaluated performance on the two introduced “clue” lines in the optimization plot, as illustrated in Fig. 5(a). Results of the development test set on the two clue lines are illustrated in Fig. 5(b). The results suggest that 0.3<a<0.5 alongside 0.5<b<0.7 create a region with nearly optimum performance.Results from the analytical optimization of the parameters almost confirm the validity of the above ranges. We note that in different conditions, such as different speakers, noise conditions, etc., the best parameter values could be slightly different. However, as we used different conditions in practical optimization, the a and b values found above can be counted as the average of optimum values. As Fig. 2(b) shows, a slightly sub-optimal value does not weaken the performance very much. Therefore, readjustment for new situation is not necessary.In order to evaluate the performance of our second extension to the proposed BCM in Section 4, the value of A in (27) should be determined too. Once again, we first arranged a development test to find an optimum range for the value of A. Table 1shows the results of this development test. We changed the value of A from 0 to 0.4 with steps of 0.05. Theoretically, parameter A could have values between zero and positive infinity, but we stopped at 0.4 as the ASR accuracy was in a descending trend.In order to train the parameters of SPM (parameters of (25)) two different datasets were selected and two different development tests were performed using those two. To form the first dataset, 400 noisy utterances were selected randomly from test set B and from all SNR levels. After oracle mask calculation for each utterance, values of (23) and (24) were calculated for the missing components using the previously trained model of (22). Then, the parameters of SPM were trained using definitions of (25) and by setting the value of RNto 10. The second SPM training dataset was formed with a similar procedure, except that the 400 utterances were selected from 8440 clean training dataset and artificially contaminated with four types of noise including restaurant, airport, street, and train (the same contaminating noises in test set B of Aurora 2.0) with randomly selected values of SNR from −5 to 20.The selected datasets for SPM training had certain properties. Both datasets were contaminated with the same kinds of noise in set B, which allow the development and evaluation experiments to be carried out in a different training noise condition when test set A is used for evaluation and in a similar training noise condition when set B is used. Also, our development test results of Table 1 are reported for set A. Thus the SPM model is trained in a completely different noise condition than the development test. The first SPM training dataset employs a selection of utterances of set B which share the same utterances with set A, while the second dataset employs utterances from the clean training dataset which are completely different from the ones in set A. This difference lets us evaluate the effect of similarity or dissimilarity between SPM training datasets and the test sets.The second SPM training dataset is more realistic and a better match for the practical conditions. It uses the same utterances which are used in acoustic model training and different types of noises than the test experiments. Hence, in a practical condition, it can be trained alongside acoustic models without having a clue of test conditions.Table 1 suggests an optimum range for A as 0.15<A<0.3. However, our experiments showed that as long as a nonzero and less than one value is selected for A, word accuracy will not fall very drastically.Another point worth mentioning in Table 1 is that the differences between performances of the first and second rows are minor (only 0.41 percent in average). This means that employing a different data set from test data to train SPM will not decrease the ASR performance very much.

@&#CONCLUSIONS@&#
In this paper, we first briefly described bounded cepstral marginalization (BCM), which is a range transfer function designed to practically move feature domain of the classic Bounded Marginalization from the spectrum to the cepstrum. The motivation of proposing the technique is combining the benefits of classifier modification approaches and cepstral features for noise robust ASR. Classifier modification approaches use only reliable information without reconstructing missing components of spectrogram. Therefore, there is no need to either train an extra reconstruction model or perform a reconstruction procedure. They also do not introduce any extra noise to the features due to incorrect reconstruction, which is inevitable in the SI approaches. However, most of them employ spectral features which weaken the performance. They also often have incompatibility with the customary cepstral-trained acoustic models. These drawbacks keep them from competing with the SI approaches.Bounded cepstral marginalization (BCM) not only transforms the marginalization from spectral to cepstral domain, but also is compatible with cepstral-trained acoustic models. It only needs minor adjustments to the Viterbi-based classifier. Furthermore, our experiments indicate fair improvements to the spectral bounded marginalization despite using a smaller feature vector and consequently less computational overhead.The BCM opened doors to further performance improvement of CM techniques. We proposed two techniques in this paper to improve the performance of BCM by employing an observed characteristic of cepstral features and by introducing a spectral possible range prediction technique instead of an exact spectral reconstruction. The proposed techniques also show solid robustness in the case of replacing oracle mask with an inaccurate mask estimation method.Our experiments showed that the cepstral features tend to have centralized values on the estimated possible range of the BCM. Employing this trend and compressing the predicted possible range for marginalization, the proposed approach, which we named it as cepstral possible range compression (CRC), improved the performance of BCM without any need to train an extra model. Performance of CRC is relatively good considering its simple algorithm with no spectral reconstruction process and consequently lower amount of decoding time. Although the performance of CRC is comparable with a classic SI technique, it lags the state of the art SI techniques in missing data approaches.In a second extension to BCM, we employed one of the classic SI methods not for spectral reconstruction, but for possible range estimation of the missing components. Utilizing this technique, which we named as spectral variance learning (SVL), alongside BCM, resulted in a good performance which is comparable with that of the complex SI approaches. Estimating a range, instead of an exact value, for the missing component, is more error tolerable and can be performed more easily.The proposed technique could be further developed in many ways. We point out some of the potential fields for further improvements here. One improvement possibility is via manipulating dynamic features, which are remained intact in this paper. In the CRC approach, benefits of the observed characteristic of cepstral feature have been employed very simply. Another possibility for improvement is through making better use of it. For example, compression ratios or styles could be adapted differently either depending on the amount of estimated local noise or for different cepstral coefficient orders. Finally, more powerful methods of SI can be employed within the SVL framework to achieve better possible range estimation and consequently gain higher recognition accuracies.In Section 5.2 we have shown that there are optimal values for compression coefficients of (20). In this appendix we present an analytical way, which is based on minimum mean square error (MMSE), to find the optimum values.The main difference between a common HMM decoder and our bounded cepstral marginalization is on the second term of (15), which replaces the Gaussian probability of a missing feature with the integration over the possible ranges of that feature. The resulting error of this replacement could be written as(A.1)e=gxr;M,σ−1h−l∫lhgx;M,σdx,whereg⋅and xrstand for the Gaussian PDF and the unknown reliable value respectively. l and h are the bounds of the predicted possible range for the unknown xrand assumed to be known. According to the results of our experiment in Fig. 3, the unknown xrshows a centralized statistical behavior on the possible range. Therefore, xrcould be counted as a random variable which will be declared as Xrand will be modeled with a distribution. The parameters of this distribution can be estimated from the possible range as well as the results of the mentioned experiment. We approximated the distribution with a double Gaussian mixture in accordance with Fig. 3 with the means33A single Gaussian distribution with a mean of (3h+l)/4 is selected for the 0th cepstral coefficient according to the results of Fig. 3(a).ofh+l/2and3h+l/4and standard deviations44K1 and K2 are set to 0.172 and 0.126 according to the complete data used on the experiment of section 4.1. K1 is set to 0.126 for the 0th cepstral coefficient.ofK1h−landK2h−lrespectively. The first Gaussian is weighted ten times heavier than the second. The error, which is a random variable now, can be rewritten as(A.2)e=gXrh+l2,h−l;M,σ−1h−l∫lhgx;M,σdx,where Xris a generally written function ofh+l/2and h−l. And without the loss of generality it can be rewritten as(A.3)e=gXrh+l/2−Mσ,h−lσ;0,1−σh−l∫l−M/σh−M/σgx;0,1dx.We have compressed the possible range toward the center by applying (20), which we rewrite it as(A.4)lc=l+1−a2h−l=h+l2−ah−l2=C−aRhc=h−1−a2h−l=h+l2+ah−l2=C+aR,where a is the compression coefficient and C and R are center and half length of the range respectively. As h and l are assumed to be known, C and R are known values as well. Therefore, by replacing l and h with new values of (A.4) the error becomes(A.5)e=gXrC−Mσ,2Rσ;0,1−σ2aR∫C−M−aR/σC−M+aR/σgx;0,1dx.For a known range, e is only a function of three parameters ofD=C−M/σ, Σ=R/σ, and a. Optimum compression could take place where the mean square of error has a minimum value. Hence, the equation of(A.6)∂Ee2D,Σ,a∂a=0should be solved to find a, where E(·) stands for the expected value. The optimal value of a will be a function of D and Σ.We have solved this equation numerically using different values for D and Σ. For a given D and Σ, a Gaussian random number generator is employed to mimic the random variable of Xrand enough numbers were generated to find a stabilized value for each value of e2. This is repeated for different values of a. Fig. A.1illustrates the results of two particular pairs of D and Σ. The figures indicates that there is an optimal value for a. These optimal values are found for different values of D and Σ and illustrated on Fig. A.2. Ranges of D and Σ in the figure are set to 0–3 and 0–1.6 respectively. These ranges are selected due to results of experiments of a real missing data ASR decoder which have shown that on more than 85 percent of occasions when (15) is calculated, D and Σ lied on this range. The experiments are carried out with utterances of different speakers with different levels of SNR derived from Aurora 2.0 training section.Fig. A.2 shows that with different values of D and Σ, different optimal values exist for a. A constant a could be chosen by averaging these optimal values. We applied a weighted average based on calculation frequency of the mentioned experiments. The optimal value of a is found at 0.443. This value is in accordance with the optimal value which is found practically in Section 5.2. A similar procedure is performed to find optimal value of b in (21) which is related to 0th cepstral coefficient. The only differences were in approximation of The Random variable Xrand integral ranges of (A.2) which are selected in accordance to Fig. 3(a) and (21) respectively. The optimal value of b is found at 0.732 which relatively confirms the practically found optimal value of Section 5.2.