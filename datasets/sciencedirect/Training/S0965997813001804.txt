@&#MAIN-TITLE@&#
On the numerical modeling of convection-diffusion problems by finite element multigrid preconditioning methods

@&#HIGHLIGHTS@&#
Geometric finite element multigrid preconditioning schemes for convection diffusion problems.New proposed multigrid FE preconditioning methods based on approximate inverses.Finite element multigrid preconditioning schemes in conjunction with PR2 refinement.Multigrid preconditioning of Krylov subspace methods with approximate inverses.Comparative results are presented against classic smoothers.

@&#KEYPHRASES@&#
Sparse linear systems,Finite element method,Multigrid methods,Approximate inverse smoothing,DOUR algorithm,PR2 refinement,Multigrid preconditioning,

@&#ABSTRACT@&#
During the last decades, multigrid methods have been extensively used in order to solve large scale linear systems derived from the discretization of partial differential equations using the finite difference method. The effectiveness of the multigrid method can be also exploited by using the finite element method. Finite Element Approximate Inverses in conjunction with Richardon’s iterative method could be used as smoothers in the multigrid method. Thus, a new class of smoothers based on approximate inverses can be derived. Effectiveness of explicit approximate inverses relies in the fact that they are close approximants to the inverse of the coefficient matrix and are fast to compute in parallel. Furthermore, the proposed class of finite element approximate inverses in conjunction with the explicit preconditioned Richardson method yield improved results against the classic smoothers such as Jacobi method. Moreover, a dynamic relaxation scheme is proposed based on the Dynamic Over/Under Relaxation (DOUR) algorithm. Furthermore, results for multigrid preconditioned Krylov subspace methods, such as GMRES(res), IDR(s) and BiCGSTAB based on approximate inverse smoothing and a dynamic relaxation technique are presented for the steady-state convection-diffusion equation.

@&#INTRODUCTION@&#
Let us consider a class of problems defined by the following Partial Differential Equation (P.D.E.):(1)-ε(Δu)+α∂u∂x=f(x,y),(x,y)∈Ω,where ε is the diffusion coefficient, α is the convection coefficient and f is the force function, cf. [15,18], subject to generalized boundary conditions:(1.a)η(c1∇u)+c2u=c3,(x,y)∈∂Ω,where Ω is a closed bounded domain, ∂Ω denotes the boundary of Ω andη→is the outward unit length normal. The c1, c2 and c3 are sufficiently smooth functions in two space variables. Assuming that the associated bilinear form B(u,v) is continuous and coercive on Hp(Ω) then there exists a solution uhassociated with the solution u of the original problem (1):(2)B(uh,vh)=〈f,vh〉,∀vh∈Sh⊂Hp(Ω),where Shis a space, p is the order of the Sobolev space and the finite element approximation uhto u can be derived. The region Ω is then divided into a non-overlapping triangular finite elements of mesh size h with k nodes for each element. Let us consider n nodes in Ω∪∂Ω not containing points on which the boundary conditions are imposed. The finite element solution over the total elements of the region in a column-wise ordering, is(3)uh(x,y)=∑i=1nuiΦi(x,y),where Φi(x,y) are trial functions. It is well known, that the solution to the bilinear form, viz.,(4)∑i=1nuiB(Φi,Φj)=〈f,Φj〉,j=1,…,nresults in the following sparse linear system, i.e.(5)Au=fwhere the coefficient matrix A is a nonsingular large, sparse, unsymmetric, positive definite matrix of certain structure with semi-bandwidth m, while u is the FE solution at the nodal points and f is a vector, with components resulting from the combination of source terms and imposed boundary conditions, cf. [10,16,17]. The ordering of the grid points is lexicographical. In the case of triangular elements the width of the bands at semi-bandwidth m is two, while in the case of rectangular elements the width of the bands at semi-bandwidth m is three.Explicit preconditioned methods have been extensively used for solving sparse linear systems on multiprocessor systems, and the preconditioned form of the sparse linear system (5) is(6)MAu=Mfwhere M is a suitable preconditioner. The preconditioner M has to satisfy the following conditions: (i) MA should have a clustered spectrum, (ii) M can be efficiently computed in parallel, (iii) “M×vector” should be fast to compute in parallel. The effectiveness of explicit approximate inverse preconditioning relies on the use of suitable preconditioners that are close approximants to the inverse of the coefficient matrix and are fast to compute in parallel, cf. [9]. In this article we present a parameterized “smoother” based on the explicit approximate inverse matrix and the explicit preconditioned Richardson iterative method.During the last decade, multigrid methods, have been extensively used, cf. [1,3,5,12,13,18], for solving large sparse linear systems, and gained substantial interest among the scientific community for both their efficiency and convergence behavior.Multigrid methods are based on the observation that the high frequency components of the error are damped effectively by a stationary iterative method (such as Jacobi or Gauss–Seidel), however the low-frequency components are not damped effectively. In order for low frequency components of the error to be handled, a series of coarser grids with higher mesh size, using triangular and rectangular elements, are used as shown in Fig. 1. In this series of coarser grids the low-frequency modes of the error are more oscillatory and can be damped efficiently by a stationary iterative method, cf. [1,3,13,14,18]. Multigrid methods are composed by four discrete elements: stationary iterative method, restriction operator, prolongation operator and cycle strategy. The stationary iterative methods are first order iterative methods such as Richardson, Jacobi and Gauss–Seidel method. Restriction and prolongation are transfer operators from finer to coarser grids and from coarser to finer grids respectively. The cycle strategy refers to the sequence in which the grids are visited until a solution with the prescribed tolerance is obtained.Let us consider the linear systems derived from the discretization of a PDE at different levels, required by the multigrid method, on a unit square domain with different mesh size h:(7)Ahuh=fh,The linear system (7) can be solved iteratively with a multigrid method. A multigrid method can be formulated by the recursive call of the two-grid method, with ν1 pre-smoothing steps and ν2 post-smoothing steps as well as a correction on the coarser grid, cf. [3,13,18].An important component in multigrid methodology is a stationary iterative solver, namely “smoother”, expressed by the following relation:(8)uℓ(k+1)=uℓk+Mℓrℓ,rℓ=fℓ-Aℓuℓ(k),where ℓ is the level of discretization and fℓ,Aℓare the right hand side and the coefficient matrix anduℓ(k)is the solution vector at the kth iterative step. Further discussions and proofs about classical smoothers can be found in [3,13,14,18]Approximate inverses in conjunction with the general iterative method (8) can be used as smoothers for multigrid schemes, by consideringMℓ=(Mℓ)rδl, where(Mℓ)rδlis a class of finite element approximate inverses of the coefficient matrix of the linear system corresponding to each level of the multigrid method. The finite element approximate inverse matrix(Mℓ)rδl, where δl is the “retention” parameter, with δl=ρm, ρ=1,2,…,m−1, can be computed by Optimized Banded Generalized Approximate Inverse Finite Element Matrix (OBGAIFEM) algorithm, cf. [17], based on Finite Element Approximate LrUrFactorization (FEALUFA) algorithm, where r is the “fill-in” parameter, i.e. the number of outermost off-diagonal entries retained at semi-bandwidth m in the upper and lower decomposition factors, cf. [16]. The “retention” parameter δl denotes the number of elements retained next to the main diagonal elements of the approximate inverse. The new class of smoothing schemes can be described as follows:(9)uℓ(k+1)=uℓ(k)+ω(Mℓ)rδlfℓ-Aℓuℓ(k),where ω is the damping parameter with 0<ω⩽1. In order for a stationary method to function as smoother, the smoothing property must be satisfied, cf. [13,14] and has been proven in [6].The choice of the relaxation parameter for the approximate inverse smoothing scheme is non-trivial and the DOUR scheme, cf. [12], is used to compute the optimal value of ω. The proposed scheme in conjunction with the DOUR method can be expressed as follows:(10)uℓ(k+1)=uℓ(k)+ωe(Mℓ)rδlfℓ-Aℓuℓ(k),ωe=ω(1+κ),where ωeis the effective relaxation parameter andκ=Δuℓ(k),fℓ-Aℓũℓ(k)Δuℓ(k),AℓΔuℓ(k)withΔuℓ(k)=ũℓ(k)-uℓ(k). It should be stated that ωeis computed using the DOUR scheme provided with the ωecomputed in the previous cycle and now denoted ω. Theũℓ(k)is computed by applying one iteration of the proposed smoother with a starting value of ω, thusũℓ(k)=uℓ(k)+ω(Mℓ)rδl(fℓ-Aℓuℓ(k)). The proposed smoothing scheme is referred to as Approximate Inverse Preconditioner smoothing (AIP).The DOUR method is also used in conjunction with the Damped Jacobi method, because the choice of the relaxation parameter ω is non-trivial. Further information and convergence analysis of the DOUR algorithm are given in [12].Transfer operators are used in the multigrid method in order to project or interpolate vectors through a series of grids. Transfer operators are divided in two categories, the restriction and interpolation operators, cf. [3,5,13,18]. The full-weighting restriction operator and bilinear prolongation operator were used for the proposed multigrid schemes. These operators are related through the Galerkin condition, thus simplifying the mapping on the data, cf. [3].Further information on various restriction operators can be found in [3,13,18].The cycle strategy is an essential component of the multigrid algorithm and refers to the sequence that the computations will occur in order to obtain the required solution vector and coarse grid corrections in each level. The common cycle strategy is the V-Cycle algorithm, cf. [3,13,18]. The V-Cycle strategy with ν1 pre-smoothing steps, during the descending phase, and ν2 post-smoothing steps, during the descending phase, in each level is denoted by V(ν1,ν2). Successive applications of the V(ν1,ν2) strategy lead to obtaining the solution of linear system. The iteration matrixTℓVof the ℓth level of the multigrid V-Cycle in conjunction with approximate inverse matrices with ν1 pre-smoothing and ν2 post-smoothing steps is as follows, cf. [18]:(11)TℓV=Iℓ-ωMrδlℓAℓν2Iℓ-PIℓ-1-Tℓ-1VAℓ-1-1RAℓIℓ-ωMrδlℓAℓν1,T0V=0,ℓ=1,2,3,…where Iℓis the identity matrix,(Mrδl)ℓis the approximate inverse matrix of the coefficient matrix Aℓat the ℓth level with “retention” parameter δl and “fill-in” parameter r,Aℓ-1-1is the inverse of the coefficient matrix at the (ℓ−1)th level, and P, R are the prolongation and restriction operators, respectively.The algorithm for the V-Cycle multigrid method as well as various cycling schemes, are given in [3,13,18].The finer grids in the finite element discretization of a square domain are constructed by dividing each uniform coarse element, denoted as ec, to four uniform fine elements denoted as efas depicted in Fig. 2, for triangular and rectangular elements. By dividing each uniform element in four elements the position of the coarse points is retained in the finer grids, thus creating, recursively, the series of finer grids required for the multigrid method algorithm.The PR2 method introduced in [2] is a quadratic iterative method that can be used to evaluate the inverse of a matrix. The method, when provided with a “close” initial approximation, converges quadratically to the exact inverse of a matrix through Richardson’s method in conjunction with the Iterative Refinement algorithm. The PR2 method can be described as follows:(12)Cn+1=Cn(I+Rn)andRn+1=I-ACn+1,where Cnis the sequence of the inverses of matrix. The sequence converges to solution provided with initial approximation R0 such that ‖R0‖<1. By applying few steps of PR2 method maintaining the pattern of the approximate inverse, for small values of the “retention” parameter δl, i.e., δl=1 and δl=2, the resulting matrix is refined with minimum computational cost and can be expressed by the following scheme:(13)Mrδln+1=Mrδln2I-AMrδln.The increase of the “retention” parameter δl, increases the computational cost of the refined inverse due to the sparse–sparse matrix multiplication. A very sparse approximate inverse as an initial guess requires low computational cost for refinement. When the “retention” parameter is set to δl=1, the approximate inverse smoothing scheme tends to Damped Jacobi scheme. Hence the approximate inverse smoothing scheme, with the “retention” parameter set to δl=2 in conjunction with one or two steps of the PR2 method, is used to improve convergence and effectiveness of the smoothing scheme.Multigrid methods are proved efficient for wide variety of problems, cf. [1,3,5,6,13,18]. However, when the multigrid iteration operator Mhhas large isolated eigenvalues the convergence behavior of the classic multigrid schemes deteriorates significantly. In order to accelerate the convergence, multigrid methods are used as preconditioners to classic Krylov subspace iterative methods such as GMRES(res), IDR(s) and BiCGSTAB.For the convection-diffusion equation, cf. (1)-(1.a), discretized with triangular and rectangular elements, the spectra of the multigrid V(2,1) and V(2,2) method in conjunction with Finite Element Approximate Inverses iteration operator Mhfor mesh size h=1/8 and the retention parameter set to δl=1 and δl=2 are presented in Figs. 3 and 4, respectively. It can be observed that there exist large isolated eigenvalues, which increase the spectral radius, thus significantly affecting convergence for small values of the retention parameter i.e. δl=1 and δl=2. The multigrid method will be used as a preconditioner for the Krylov subspace iterative methods, as mentioned before. The methods that will be used is the Generalized Minimum RESidual restarted method, the Induced Dimension Reduction and the Bi-Conjugate Gradient-Stabilized method. The multigrid preconditioned algorithms for the three iterative schemes are presented below. Let us denote ν1, ν2 and ν3 the pre-smoothing, post-smoothing and preconditioning iterations.The Restarted Generalized Minimal Residual Method is an iterative method for the numerical solution of large unsymmetric linear systems. The GMRES(res) method approximates the solution by finding the vector in the Krylov subspace with minimal residual, through the Arnoldi iteration. The res parameter denotes the successive steps before the method is restarted, cf. [20]. The (MultiGrid V-Cycle preconditioned) MGV(ν1,ν2,ν3)–GMRES(res) algorithm for a linear system Ax=b is as follows:Algorithm 1 – MGV(ν1,ν2,ν3) – GMRES(res) algorithmLetx0be an arbitrary initial approximation and res the dimension of the Krylov subspaces. Then,(H‾res)i,j=0,i=1,…,res+1,j=1,…,resThen, fork=1,…, (until convergence) compute the vectorxkas follows:r0=b−Ax0β=‖r0‖2v1=r0βForj=1,…,reszj=K−1vj(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))w=AzjFori=1,…,jhi,j=(w,vi)w=w−hi,jviEndForhj+1,j=‖w‖2vj+1=whj+1,jEndForVres=[v1,…,vres]t=K−1Vresyres(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))whereyres=argminy‖βe1-H‾resy‖2ande1=[1,0,…,0]T.xres=x0+tx0=xresThe preconditioned GMRES(res) variant used is presented in [20] and is available through MATLAB environment. Moreover, it exploits Householder transformations for the orthogonalization process instead of the Gram–Schmidt method, rendering the algorithm more stable.The Induced Dimension Reduction method is an iterative method for solving large unsymmetric linear systems. The method is based on the principle of choosing the residuals through a series of subspaces of reduced dimension forcing them to zero, rather than the approach of search directions. The IDR(s) method with a shadow space of order s is based on the IDR method and generates residuals that are forced to be in a sequence of nested subspaces, cf. [8]. The algorithm of the MGV(ν1,ν2,ν3)–IDR(s) algorithm for a linear system Ax=b is as follows:Algorithm 2 – MGV(ν1,ν2,ν3)–IDR(s)Letxbe an arbitrary initial approximation to the solution vector, “shadow” spaces, rthe residual vector for the initial approximation and P a full rank (n×s) matrix withSas its left nullspace. Then,r=b–Axgi=ui=0,i=1,…,s and M=I,ω=1Then, forj=1,…,(until convergence) compute the vectorxjand the scalar quantities as follows:f=PHr,(φ1,…,φs)T=fFork=1,…,sSolvecfrom Mc=f,(γ1,…,γs)T=cv=r-∑i=ksγigiv′=K−1v,(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))v=v′uk=ωv+∑i=ksγiuigk=AukFori=1,…,k−1α=piHgkμi,igk=gk−αgiuk=uk−αuiEndForμi,k=piHgk,Mi,k=μi,k,i=k,...,sβ=φkμk,kr=r−βgkx=x+βukIfk+1⩽sthenφi=0,i=1,…,kφi=φi−βμi,k,i=k+1,…,sf=(φ1,…,φs)TEndIfEndForv=K−1r,(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))t=Avω=tHrtHt,ρ=tHr‖t‖‖r‖If |ρ|<κthenω=ωk|ρ|EndIfr=r−ωtx=x+ωvThe algorithm presented above is the bi-orthogonal variant of the IDR(s) method, cf. [8].The BiConjugate Gradient STABilized method is an iterative method for solving large unsymmetric linear systems of equations and is based on BiCG method, cf. [19]. The BiCGSTAB method, cf. [19], offers smoother and faster convergence than BiCG method and variants such as CGS. The MGV(ν1,ν2,ν3)–BiCGSTAB for a linear system Ax=b algorithm is as follows:Algorithm 3 – MGV(ν1,ν2,ν3)–BiCGSTABLetx0be an arbitrary initial approximation to the solution vector x and r0the residual vector for the initial approximation. Then,r0=b−Ax0r0′=r0, ρ0=α=ω0=1 andv0=p0=0Then, fori=1,…,(until convergence) compute the vectorsxi,ri,zi,yi,pi,si,tiand the scalar quantitiesα,β,ωi,ρias follows:ρi=(r0′,ri-1),β=(ρi/ρi-1)(α/ωi-1),pi=ri−1+β(pi−1−ωi−1vi−1),yi=K−1pi,(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))vi=Ayi,α=ρi/(r0′,vi),si=ri−1−αvi,zi=K−1si,(where K−1denotes theν3iterations of V(ν1,ν2) method with multigrid iteration operatorTℓV, cf. (11))ti=Azi,ωi=(ti,si)/(ti,ti),xi=xi−1+αyi+ωizi,ri=si−ωiti.The BiCGSTAB implementation used is available through the MATLAB environment.In this section numerical results will be presented for the proposed multigrid schemes. The model problem to be solved with the proposed schemes is an elliptic convection–diffusion P.D.E. The convection–diffusion equation can be described by the following P.D.E:(14)-ε(Δu)+α∂u∂x=Asin(ℓπy)((-εℓ2π2)x2+(εℓ2π2-2α)x+(α+2ε)),(x,y)∈Ω,(14.a)u(x,y)=0,(x,y)∈∂Ω,where ɛ>0,A∊R,α∊R,ℓ∊Z, Δ is the Laplace operator, Ω is the unit square and ∂Ω denotes the boundary of Ω, cf. [3]. The domain was discretized using triangular or rectangular elements. The values of the parameters for the convection–diffusion P.D.E were set arbitrarily to ɛ=0.1,α=2.5,A=1,ℓ=3. The results were obtained using the MATLAB environment. The convergence factor depends on the required number of iterations for convergence, cf. [3,5,18]. The convergence factor with respect to the 2-norm is defined as:(15)q=‖rm‖2/‖r0‖2m,where rmis the residual vector at the m-th iteration. The termination criterion for the model problem is ‖rm‖2<10−10‖r0‖2 and the numbering of the grid is lexicographical. The prefix MGV(ν1,ν2,ν3) denotes that the proposed Krylov subspace iterative method schemes are MultiGrid V-Cycle preconditioned with ν1 pre-smoothing steps, ν2 post-smoothing steps in each level of the multigrid method and ν3 preconditioning iterations to approximately solve the linear systems in each outer Krylov iteration. The maximum number of iterations was set to 100 iterations. For the GMRES(2) and IDR(2) the outer number of iterations was used for computation of the convergence factor.In Table 1, the convergence factors and convergence behavior of the MGV(2,1,1)–GMRES(2), MGV(2,1,1)–IDR(2) and MGV(2,1,1)–BiCGSTAB with Damped Jacobi and Approximate Inverse smoothing for various values of the “retention” parameter δl and mesh size h=1/128, for triangular elements are presented. In Table 2, the convergence factors and convergence behavior of the MGV(2,2,2)–GMRES(2), MGV(2,2,2)–IDR(2) and MGV(2,2,2)–BiCGSTAB with Damped Jacobi and Approximate Inverse smoothing for various values of the “retention” parameter δl and mesh size h=1/128, for triangular elements are given. In Table 3, the convergence factors and convergence behavior of the MGV(2,1,1)–GMRES(2) and MGV(2,2,2)–GMRES(2) for various values of the mesh size h and the “retention” parameter set to δl=1 and δl=2, for triangular elements are presented. In Table 4, the convergence factors and convergence behavior of the MGV(2,1,1)–IDR(2) and MGV(2,2,2)–IDR(2) for various values of the mesh size h and the “retention” parameter δl set to δl=1 and δl=2, for triangular elements are given. In Table 5, the convergence factors and convergence behavior of the MGV(2,1,1)–BiCGSTAB and MGV(2,2,2)–BiCGSTAB for various values of the mesh size h and the “retention” parameter δl set to δl=1 and δl=2, for triangular elements are presented. In Table 6, the convergence behavior and convergence factors for the PR2 MGV(ν1,ν2,ν3)–GMRES(2), IDR(2) and BiCGSTAB methods with the “retention” parameter δl=2 and 1 and 2 refinement steps, for mesh size h=1/1024, for triangular elements are given.In Fig. 5, the 2-norm of the residual against the required number of iterations for convergence of MGV(ν1,ν2,ν3)–GMRES(2), MGV(ν1,ν2,ν3)–IDR(2) and MGV(ν1,ν2,ν3)–BiCGSTAB for various choices of smoothers and pre-smoothing (ν1) iterations, post-smoothing (ν2) and preconditioning (ν3) iterations for mesh size h=1/128, for triangular elements are depicted. In Fig. 6, the 2-norm of the residual against the required number of iterations for convergence of MGV(ν1,ν2,ν3)–GMRES(2), MGV(ν1,ν2,ν3)–IDR(2) and MGV(ν1,ν2,ν3)–BiCGSTAB for approximate inverse smoothing with “retention” parameter δl=2 and various choices of pre-smoothing (ν1) iterations, post-smoothing (ν2) and preconditioning (ν3) iterations with one and two PR2 refinement steps for mesh size h=1/128 for triangular elements are given.It should be noted that the number of iterations of the Krylov subspace methods without preconditioning is excessive compared to the preconditioned proposed schemes.In Table 7, the convergence factors and convergence behavior of the MGV(2,1,1)–GMRES(2), MGV(2,1,1)–IDR(2) and MGV(2,1,1)–BiCGSTAB with Approximate Inverse smoothing for various values of the “retention” parameter δl and mesh size h=1/128, for rectangular elements are given. In Table 8, the convergence factors and convergence behavior of the MGV(2,2,2)–GMRES(2), MGV(2,2,2)–IDR(2) and MGV(2,2,2)–BiCGSTAB with Approximate Inverse smoothing for various values of the “retention” parameter δl and mesh size h=1/128, for rectangular elements are presented.In Table 9, the convergence factors and convergence behavior of the MGV(2,1,1)–GMRES(2) and MGV(2,2,2)–GMRES(2) for various values of the mesh size h and the “retention” parameter set to δl=1 and δl=2, for rectangular elements are given. In Table 10, the convergence factors and convergence behavior of the MGV(2,1,1)–IDR(2) and MGV(2,2,2)–IDR(2) for various values of the mesh size h and the “retention” parameter δl set to δl=1 and δl=2, for rectangular elements are presented. In Table 11, the convergence factors and convergence behavior of the MGV(2,1,1)–BiCGSTAB and MGV(2,2,2)–BiCGSTAB for various values of the mesh size h and the “retention” parameter δl set to δl=1 and δl=2, for rectangular elements are given. In Table 12, the convergence behavior and convergence factors for the PR2 MGV(ν1,ν2,ν3)–GMRES(2), IDR(2) and BiCGSTAB methods with the “retention” parameter δl=2 and 1 and 2 refinement steps, for mesh size h=1/1024, for rectangular elements are presented.In Fig. 7, the 2-norm of the residual against the required number of iterations for convergence of MGV(ν1,ν2,ν3)–GMRES(2), MGV(ν1,ν2,ν3)–IDR(2) and MGV(ν1,ν2,ν3)–BiCGSTAB for various choices of smoothers and pre-smoothing (ν1) iterations, post-smoothing (ν2) and preconditioning (ν3) iterations for mesh size h=1/128, for rectangular elements are depicted. In Fig. 8, the 2-norm of the residual against the required number of iterations for convergence of MGV(ν1,ν2,ν3)–GMRES(2), MGV(ν1,ν2,ν3)–IDR(2) and MGV(ν1,ν2,ν3)–BiCGSTAB for approximate inverse smoothing with “retention” parameter δl=2 and various choices of pre-smoothing (ν1) iterations, post-smoothing (ν2) and preconditioning (ν3) iterations with one and two PR2 refinement steps for mesh size h=1/128 for rectangular elements are given.It should be noted that the standard FEM is stable for relatively low Péclet number. In that case a new algorithmic procedure, namely, generic approximate inverse, has been developed by using effectively low ratios ε/α, cf. [11]. Péclet number is dimensionless and relevant to the study of transport phenomena in fluid flow problems, cf. [18]. If this is not the case then a lower ration ε/α should be considered by using the new generic sparse approximate inverse, cf. [7], in order to examine the effectiveness.An alternative approach to study the case of lower ratios of ε/α for the model problem is to introduce a new stable finite element formulation scheme, namely Streamline Upwind Petrov–Galerkin (SUPG), cf. [4], to improve the numerical properties and the stability of the numerical solution. In the case where the convective coefficient (α) is much greater than the diffusive coefficient (ε) the Péclet number is Pe=|α|h/2ɛ≫1 and oscillations occur to the numerical solution, rendering the standard Galerkin formulation unstable, cf. [4]. By introducing an artificial viscosity term these oscillations and instabilities of the formulation are handled. Let us consider the stable Galerkin formulation of the model problem, cf. [4,15]:(16)B(Φ,u)+Bsupg(Φ,u)=〈Φ,f〉andBsupg(Φ,uh)=∑eτesupgα∂Φ∂x,-εΔu+α∂u∂x-fewhere e is each respective element of the discretization andτesupg=h2|α|cothPe-1Peis the stabilization parameter, cf. [4,15]. By applying the formulation to the triangular and rectangular elements the numerical stability of the finite element discretization is improved and the Approximate Inverse matrix with δl=2 is chosen as the smoother for the Krylov accelerated multigrid methods.In Table 13, the convergence behavior for various values of ε, various Krylov methods and preconditioning choices with h=1/128 and δl=2, for triangular elements, are presented. In Table 14, the convergence factors for various values of ε, various Krylov methods and preconditioning choices with h=1/128 and δl=2, for triangular elements, are given. In Table 15, the convergence behavior for various values of ε, various Krylov methods and preconditioning choices with h=1/128 and δl=2, for rectangular elements, are presented. In Table 16, the convergence factors for various values of ε, various Krylov methods and preconditioning choices with h=1/128 and δl=2, for rectangular elements, are given.In Table 17, the number of nonzero elements in the approximate inverse preconditioners for various values of δl and h, are presented.It should be noted that in the case of non-structured meshes with local refinement, the sparsity pattern of the coefficient matrix is affected and it is preferable to use the algebraic multigrid method in conjunction with generic approximate sparse inverses, which is the subject to be studied in future work.

@&#CONCLUSIONS@&#
