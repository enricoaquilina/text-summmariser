@&#MAIN-TITLE@&#
Credit risk evaluation using multi-criteria optimization classifier with kernel, fuzzification and penalty factors

@&#HIGHLIGHTS@&#
An improved KFP-MCO classifier based kernel, fuzzification, and penalty factors is proposed and used for credit scoring.A fuzzy contribution of each input point is introduced to MCO classifier for soft separation.The penalty factors are used to trade off overfitting and underfitting.KFP-MCOC gains efficiency without solving the quadratic programming problem.KFP-MCOC obtains better performance of credit risk prediction in flexibility, separation and generalization.

@&#KEYPHRASES@&#
Data mining,Fuzzy set,Kernel function,Multi-criteria optimization,Classification,Credit risk,

@&#ABSTRACT@&#
With the fast development of financial products and services, bank’s credit departments collected large amounts of data, which risk analysts use to build appropriate credit scoring models to evaluate an applicant’s credit risk accurately. One of these models is the Multi-Criteria Optimization Classifier (MCOC). By finding a trade-off between overlapping of different classes and total distance from input points to the decision boundary, MCOC can derive a decision function from distinct classes of training data and subsequently use this function to predict the class label of an unseen sample. In many real world applications, however, owing to noise, outliers, class imbalance, nonlinearly separable problems and other uncertainties in data, classification quality degenerates rapidly when using MCOC. In this paper, we propose a novel multi-criteria optimization classifier based on kernel, fuzzification, and penalty factors (KFP-MCOC): Firstly a kernel function is used to map input points into a high-dimensional feature space, then an appropriate fuzzy membership function is introduced to MCOC and associated with each data point in the feature space, and the unequal penalty factors are added to the input points of imbalanced classes. Thus, the effects of the aforementioned problems are reduced. Our experimental results of credit risk evaluation and their comparison with MCOC, support vector machines (SVM) and fuzzy SVM show that KFP-MCOC can enhance the separation of different applicants, the efficiency of credit risk scoring, and the generalization of predicting the credit rank of a new credit applicant.

@&#INTRODUCTION@&#
Credit risk evaluation is a very challenging and important data mining problem in the domain of financial analysis. Credit scoring models have been extensively used to evaluate the credit risk of consumers or enterprises, and they can classify the applicants as either accepted or rejected according to their demographical and behavioral characteristics. Over the past three decades, a large number of methods have been proposed for credit risk decision (Lando, 2004; Thomas, Crook, & Edelman, 2002). These methods mainly include logistic regression (Bolton, 2009; Wiginton, 1980), probit regression (Grablowsky & Talley, 1981), nearest neighbor analysis (Henley & Hand, 1996), Bayesian network (Baesens, Egmont-Petersen, Castelo, & Vanthienen, 2002; Pavlenko & Chernyak, 2010), artificial neural network (Jensen, 1992; West, 2000), decision tree (Bastos, 2008; Zhang and Zhang, et al., 2010; Zhang and Zhou, et al., 2010; Zhang and Zhu, et al., 2010), genetic algorithm (Abdou, 2009; Ong, Huang, & Tzeng, 2005), multiple criteria decision making (Shi, Peng, Xu, & Tang, 2002; Shi, Wise, Luo, & Lin, 2001), SVM (Bellotti & Crook, 2009; Gestel, Baesens, Garcia, & Dijcke, 2003; Huang, Chen, & Wang, 2007; Martens, Baesens, Van Gestel, & Vanthienen, 2007; Schebesch & Stecking, 2005), and so on. Among these classification methods, logistic regression is considered to be the most popular statistical approach and has been more widely used than the others in practice. Neural network credit scoring models have high accuracy but some modeling skills are required – for instance, to design proper network topologies – and it is difficult to explain the results of credit scoring to users clearly. SVM based models indicated promising results in credit risk evaluation, but the SVM classifier needs to solve a convex quadratic programming problem which is very computationally expensive in real world applications.Recently increasing interests in the synergies of optimization and data mining can be observed (Olafsson, Li, & Wu, 2008; Meisel & Mattfeld, 2010; Corne, Dhaenens, & Jourdan, 2012). As optimization techniques, SVM based on statistic learning theory and optimization recently grew in popularity (Cortes & Vapnik, 1995; Vapnik, 1995, 1998), mainly owing to its higher generalization power than that of some traditional methods. The main idea of the SVM algorithm is to separate instances from different classes by fitting a separating hyperplane that maximizes the margin among the classes and minimizes the misclassification simultaneously. For the linearly separable case, the hyperplane is located in the input space. Besides, for the nonlinearly separable case, kernel techniques are used to map the data from the input space into the feature space, and the hyperplane is positioned in the feature space (Cristianini & Shawe-Taylor, 2000; Hamel, 2009).When SVM is employed to solve classification problems, each input point is treated equally and assigned certainly to one of different classes. However, in many practical applications, SVM is very sensitive to noise, outliers and anomalies in data so that the separating hyperplane severely deviates from the right position and direction. Thus several methods have been proposed to solve the problem by introducing a proper fuzzy membership function to SVM model (Abe, 2004; Abe & Inoue, 2002; Jiang, Yi, & Jian, 2006; Lin & Wang, 2002, 2004; Takuya & Shigeo, 2001; Tovar & Yu, 2008; Tsujinishi & Abe, 2003). Additionally, in real world applications, it is very usual that one class is more important than others, and that class distribution is imbalanced, resulting in a rapidly degenerating classification precision and accuracy. In order to effectively deal with the class imbalance problem, penalty techniques based on cost-sensitive learning are used (Koknar-Tezel & Latecki, 2009, 2010; Tang, Zhang, & Chawla, 2002; Yang, Wang, Yang, & Yu, 2008; Yang, Yang, & Wang, 2009; Zeng & Gao, 2009).Another optimization method mentioned above is MCOC which is used to solve classification problems in data mining and machine learning (Shi et al., 2001). The classifier mainly uses a trade-off between the overlapping degree of different classes and the total distance from input points to the separating hyperplane, with the former to be minimized and the latter to be maximized simultaneously based on the idea of linear programming for classification (Freed & Glover, 1981; Glover, 1990). Then MCOC has been used in various applications within different fields of science, ranging from credit scoring to bioinformatics. Subsequently, a linear MCOC based on a compromise solution was proposed for the behavior analysis of credit cardholders (Shi et al., 2002). A multiple phase fuzzy linear programming approach was provided for solving classification problem in data mining (He, Liu, Shi, Xu, & Yan, 2004). And a penalized MCOC using weight of the target class was proposed for solving the class-imbalanced classification problem in credit cardholder behavior analysis (Li, Shi, & He, 2008). Then a quadratic MCOC was proposed and used for credit data analysis (Peng, Kou, Shi, & Chen, 2008). A rough set-based MCOC was put forward and used for the medical diagnosis and prognosis (Zhang, Shi, and Gao, 2009; Zhang, Shi, and Tian, 2009), and a MCOC with fuzzy parameters was used to improve the generalization power of MCOC, where an appropriate fuzzy membership function is introduced to MCOC, and the objective functions and the constraints were transformed into the fuzzy decision set, then the new MCOC with fuzzy parameters was constructed (Zhang, Shi, and Gao, 2009; Zhang, Shi, and Tian, 2009). A kernel-based MCOC was given just like the use of kernel methods in SVM (Zhang and Zhang, et al., 2010; Zhang and Zhou, et al., 2010; Zhang and Zhu, et al., 2010). Additionally, MCOC was used to analyze the behavior of VIP E-mail users (Zhang and Zhang, et al., 2010; Zhang and Zhou, et al., 2010; Zhang and Zhu, et al., 2010). The above rough set-based MCOC was also used to predict protein interaction hot spots (Chen et al., 2011). In these applications, MCOC outperformed some traditional methods in data mining (Shi, 2010). A number of models and algorithms related to MCOC gradually developed to powerful tools for solving classification, regression and other problems.However, in many real world applications such as bioinformatics, language information processing and credit risk evaluation, quality problems like noise, outliers and anomalies within the data set are very common; additionally the set may be class-imbalanced, nonlinearly separable, and uncertain. Because of these uncertainties, some input points are difficult to correctly classify as one of predefined classes. Consequently, when we train MCOC using these data sets with uncertainties, MCOC will degenerate into an inefficient, instable, and inaccurate classifier. In other words, MCOC lacks the capacity of effectively dealing with noise, outliers, anomalies, class imbalance, nonlinear separable cases and other uncertainties in data.To improve the performance of MCOC, we reformulate the model by introducing a kernel function to constraints, a fuzzy membership degree to each input point and penalty factors to objective functions of imbalanced classes in MCOC. Thus, the proposed new method (KFP-MCOC) can improve performance of the original MCOC approach in stability, efficiency and generalization, which reduces the effects of anomalies, class imbalance and nonlinearly separable problems significantly.The rest of this paper is organized as follows: Section 2 describes basic principles of MCOC. Then the new KFP-MCOC is illustrated in Section 3. The experiment on credit risk evaluation and the results are demonstrated in Section 4. Finally, discussion and conclusions will be given in Sections 5 and 6 respectively.Compared to many traditional methods in data mining, the multi-criteria optimization (MCO) approach based on optimization techniques was only recently introduced to practical applications. This is partly due to SVM being successfully applied to various domains at first, and eventually MCO approaches now are paid more attention. The two methods share common advantages of using flexible objectives and constraints to fit a decision function for separation of different classes.Thus, a general classification problem using MCOC can be described as follows: For a binary classification problem, given the training data T={(x1,y1),… ,(xn,yn)}, each input pointxi∊Rdbelongs to either of the two classes with a label yi∊{−1,1}, i=1,… ,m for yi=−1; i=m+1,… ,n for yi=1, where d is the dimensionality of the input space, and n is the sample size. In order to separate the two classes, e.g. Freed and Glover have chosen the two measures for any input point: The overlapping degree of deviation from the separating hyperplane, and the distance between input points and the separating hyperplane (Freed & Glover, 1981). In the first case an input point located the wrong side of the hyperplane is misclassified, while in the second case an input point positioned in the right side of the hyperplane is correctly classified. Subsequently, Glover took the above two factors into consideration when building the classification models (Glover, 1990).Let αi(αi⩾0) be the distance where an input pointxideviates from the separating hyperplane, and the sum of the distance αiis characterized by the functionf(α)=‖α‖pp(p⩾1) which should be minimized with respect to αi, we have(1)minf(α)=‖α‖ppsubject towTxi-b⩾-yiαi,αi⩾0,∀i.Obviously if αi=0, the input point xiis correctly classified. If αi>0, the input point xiis misclassified. Where the input point xiis given training data, the weight vector w and the offset term b are unrestricted variables, i=1,2,… ,n.Similarly, let βi(βi⩾0) be the distance where an input point xideparts from the separating hyperplane, then the sum of the distance βiis characterized by the functiong(β)=‖β‖qq(q⩾1) which should be maximized with respect to βi, and we get(2)maxg(β)=‖β‖qqsubject towTxi-b⩽yiβi,βi⩾0,∀i.And if βi=0, the input pointxiis misclassified. If βi>0, the input pointxiis correctly classified.If we take the two measures in the above Eqs. (1) and (2) into account simultaneously, MCOC is defined as(3)minf(α)=‖α‖ppandmaxg(β)=‖β‖qqsubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀i.If C is a penalty factor of the objective function f(α), we may rewrite Eq. (3) as a new MCOC with the hybrid objective function h(α,β) with respect to αiand βias follows(4)minh(α,β)=Cf(α)-g(β)=C‖α‖pp-‖β‖qqsubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀iAccording to Eq. (4), we can calculate the term b (b∊R) and the weight vectorw(w∊Rd) of the separating hyperplane which is defined as(5)wTx=b.Thus during testing we may use the decision function to predict the class label of an input pointxas below(6)f(x)=sign(wTx-b).If p=1 and q=1 in Eq. (4), we get a linear MCOC with the linear objective function which can be rewritten as(7)minh(α,β)=C∑i=1nαi-∑i=1nβisubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀i.Similarly, if p=1, p=2 and q=1 in Eq. (4), and the term(1/2)‖w‖22which defines the margin of the support hyperplanes from two classes respectively is also added to the objective function, we get a quadratic MCOC with the quadratic objective function and the linear constraints which can be denoted as(8)minh′(w,α,β)=(1/2)(‖w‖22+‖α‖22)+C∑i=1nαi-∑i=1nβisubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀i.Besides, based on Eq. (7), the compromise solution approach has been used to improve the performance of the linear MCOC in business practices (Shi et al., 2001, 2002).With its obvious advantages in simplicity, high efficiency, and interpretability, MCOC has become more popular than some traditional methods in solving practical problems in recent years. But MCOC has the significant limitations of unstability, poor generalization and insufficient flexibility, especially for data sets that contain anomalies, class imbalance, nonlinear separability, and other uncertainties in data. Therefore, it is necessary that we use a soft method to rebuild MCOC instead of crisp one so as to remarkably increase its robustness, predictive accuracy and efficiency in finding an optimal decision function of classification problem.Finally, for a multi-class classification problem, we may transform Eqs. (7), (8) into multiple one-against-all or paired binary classification problems of MCOC in the real world applications.In this section, similar to the idea of fuzzy SVM approach (Jiang et al., 2006; Yang et al., 2008), we propose a new KFP-MCOC which employs kernel tricks, fuzzification, and class-imbalanced methods, hence the effects of noise, outliers, class imbalance, nonlinear separability and other uncertainties in data on the performance of MCOC are reduced. Then, the corresponding classifier algorithm is demonstrated in the following subsections.We know that for classification the case of nonlinearly separable data is very common in many real world applications. The kernel method is often used to address this problem, and it is implemented by replacing the dot product with an appropriate positive definite function where a nonlinear mapping is implicitly performed from the input data into a high-dimensional feature space. An appropriate basic function ϕ(x) is chosen to transform the input space where the data set is not linearly separable into a higher dimensional feature space where the data set may be linearly separable (Boser, Guyon, & Vapnik, 1992). In order to compute the dot product of basic function (ϕ(x)Tϕ(y)), we may replace it by the kernel function K(x,y)=(ϕ(x)Tϕ(y)) of input points in the original input space without computing basic function directly.In this case, following kernel functions are often chosen: (i) The linear kernel K(x,y)=xTy. (ii) The polynomial kernel K(x,y)=(xTy+c)d(c⩾0, d⩾2). (iii) The radial basis function kernel (RBF)K(x,y)=exp(-‖x-y‖22/2σ2)(σ>0). (iv) The sigmoid kernel K(x,y)=tanh(axTy+r) (a,r∊R). In this paper, we use the above four types of the kernel functions in our experiments.Ideally a decision function of MCOC should correctly classify each input point as one of predefined classes. However, in many practical applications, because of noise, outliers, and anomalies in data, the predictive performance of MCOC will rapidly degenerate. Besides, the contribution of each input point to classification is obviously different from that of other points, and some points are more important than others in solving classification problems. In other words, for the before mentioned constraints, the effects of these input points should be reduced or removed from data when a classifier is constructed.Thus an input point is assigned to one of the classes with uncertainty. That is, an input point belonging to one of the classes may be the three cases: (i) The input point belongs certainly to one class. (ii) The input point does not belong to one class with determination. (iii) The input point belongs to one class with the degree of fuzzy membership si(0<si<1). For the first case, of course, we have si=1, at the same time, and si=0 for the second case. For a predefined threshold τ (τ>0) and the degree of fuzzy membership siof an input pointxi, if si⩽τ, the input pointxiis considered to be unimportant and may be discarded from MCOC; Otherwise, the input pointxiis regarded as important one in modeling the classification problem. In our paper, the fuzzification method is implemented based on the kernel feature space.In data mining and machine learning the class-imbalanced problem is very common, many studies show that in that case a classifier tends to overfit the samples of majority-class, at the same time, and underfit the samples of minority-class (Akbani, Kwek, & Japkowicz, 2004; Yang et al., 2008, 2009; Zeng & Gao, 2009). Generally speaking, there are some proposals to solve the problem, including: (i) Cost-sensitive learning, which adds different penalty factors to different classes of data so as to misclassify minority-class samples is costlier than majority-class samples. (ii) Synthetic minority over-sampling, a method which employs over-sampling of the minority-class to shift the separating hyperplane towards the majority-class. (iii) Margin calibration, a method which uses a margin compensation to refine the biased decision boundary for class-imbalanced learning. In our paper, we use the cost-sensitive learning to build the penalized MCOC.Similar to the limitations of the traditional MCOC approach, many studies have shown that SVM is very sensitive to noise, outliers and anomalies in data, so fuzzy SVM was proposed to reduce the effects of anomalies in data (Abe, 2004; Jiang et al., 2006; Lin & Wang, 2002; Tsujinishi & Abe, 2003). A fuzzy SVM model is implemented by associating the importance or contribution of each input point with a fuzzy membership value si. Then a decision function is constructed based on the fuzzy support vector. Generally the method can enhance the classification performance of SVM considerably.Following this approach, MCOC is very sensitive to noise, outliers, and anomalies in data, so we proposed KFP-MCOC by introducing an appropriate fuzzy membership function to MCOC which is based on the distance between an input point and the representative point of one class in the kernel-induced feature space. Thus noise, outliers, and anomalies in data can be distinguished from other input points.Given a training set T={(x1,y1),… ,(xn,yn)} and the mapping function ϕ(xi) (i=1,… ,n), after mapping the input pointxito the high-dimensional feature space, we can use the linearly separable classification method to compute the separating hyperplane. Hence, for the new training set T′={(ϕ(x1),y1),… ,(ϕ(xn),yn)} in the kernel-induced feature space, we use the class mean as a representative point. For the two-class classification problem based on the new training set T′, we defineϕ¯yias the mean of class yias(9)ϕ¯yi=∑iyiϕ(xi)/∑iyi,yi∈{-1,1}where i=1,… ,m for yi=−1, and i=m+1,… ,n for yi=1.Then the radius of class yiis denoted as(10)ryi=max‖ϕ(xi)-ϕ¯yi‖2.Let the degree of fuzzy membership siof each input point be the linear function of the mean and the radius of one class, we have(11)si=1-d(ϕ(xi),ϕ¯yi)/(ryi+δ)where δ (δ>0) is an adjusted constant and used to avoid the case of si=0. The distanced(ϕ(xi),ϕ¯yi)between the point ϕ(xi) and its class meanϕ¯yiusing the kernel method is written as(12)d(ϕ(xi),ϕ¯yi)=‖ϕ(xi)-ϕ¯yi‖2=ϕ2(xi)-2ϕ(xi)·ϕ¯yi+ϕ¯yi21/2=ϕ(xi)Tϕ(xi)-2∑jyjϕ(xi)Tϕ(xj)∑jyj+∑j∑kyjykϕ(xj)Tϕ(xk)∑jyj∑kyk1/2=K(xi,xi)-2∑jyjK(xi,xj)∑jyj+∑j∑kyjykK(xj,xk)∑jyj∑kyk1/2where j,k=1,… ,m for yi=−1, and j,k=m+1,… ,n for yi=1.Apparently the radius of class yiin the kernel-induced feature space (see Eq. (10)) is calculated by(13)ryi=max‖ϕ(xi)-ϕ¯yi‖2=maxd(ϕ(xi),ϕ¯yi).Therefore, for the linearly separable case, given training setT″={(x1,y1,s1),…,(xn,yn,sn)}with the degree of fuzzy membership si(τ⩽si⩽1), where each input pointxi∊Rd(i=1,… , m,m+1,… ,n) is partitioned by class label yi∊{−1,1}. From Eq. (11) we know that the input pointxiwith the degree of fuzzy membership simay be less important one and considered as noise, outlier and anomaly if si⩽τ, otherwise the input pointxiis regarded as a positive contribution to classification. Besides, the parameter αi(αi⩾0) is a measure of the misclassified input point in Eq. (7), so the term siαiis a new measure of the classification error with different weight. By this way, the effects of noise, outliers and anomalies in data are reduced remarkably. At the same time, the stability of MCOC is improved considerably. Thus in the linearly separable case Eq. (7) is written as(14)minC∑i=1nsiαi-∑i=1nβisubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀iwhere C (C>0)is a penalty constant of the misclassified input points.For the class-imbalanced case, if yi=−1, let C1 (C1>0) be the misclassification cost or penalty factor of the negative class. Similarly if yi=1, let C2 (C2>0) be misclassification cost of the positive class. We can rewrite Eq. (14) as(15)minC1∑i=1msiαi+C2∑i=m+1nsiαi-∑i=1nβisubject towTxi-b=yi(βi-αi),αi⩾0,βi⩾0,∀iWhere the input pointxiis given, the weight vectorwand the offset term b are unrestricted variables, C1>0, C2>0, τ<si⩽1, τ>0, i=1,2,… ,n.For the nonlinearly separable case, we suppose that ϕ(x) is a mapping function from the input data to a higher dimensional feature space. According to the ideas of introducing kernel functions to mathematical programming (Cristianini & Shawe-Taylor, 2000; Smola, Bartlett, Scholkopf, & Schuurmans, 1999; Zhang and Zhang, et al., 2010; Zhang and Zhou, et al., 2010; Zhang and Zhu, et al., 2010), given the new data setT‴={(ϕ(x1),y1,s1),…,(ϕ(xn),yn,sn)}in the kernel-induced feature space, the weight vectorwcan be denoted as the linear combination of the input point ϕ(xj) and the class label yjwith respect to the positive coefficientλj(λj⩾0), that is(16)w=∑j=1nλjyjϕ(xj).Integrating the above weight vectorwinto Eq. (15), we have(17)minC1∑i=1msiαi+C2∑i=m+1nsiαi-∑i=1nβisubject to∑j=1nλjyjϕ(xj)Tϕ(xi)-b=yi(βi-αi),αi⩾0,βi⩾0,∀i,0⩽λj⩽C1,foryj=-1,0⩽λj⩽C2,foryj=1.If now the dot product (ϕ(x)Tϕ(y)) of the basic function is replaced by the kernel function K(x,y), we get the KFP-MCOC(18)minC1∑i=1msiαi+C2∑i=m+1nsiαi-∑i=1nβisubject to∑j=1nλjyjK(xj,xi)-b=yi(βi-αi),αi⩾0,βi⩾0,∀i,0⩽λj⩽C1,foryj=-1,0⩽λj⩽C2,foryj=1.By solving Eq. (18), we can obtain the nonnegative coefficientsλj(j=1,2,… ,n). Plugging the coefficientsλjinto Eq. (16), we can calculate the weight vectorw. For any training pointxi(i=1,2,… ,n′, n′⩽n) which satisfies αi=0 or βi>0, according to the separating hyperplanewTϕ(xi)=b, we have the offset termb=∑j=1nλjyjK(xj,xi), then an average of the term b is taken. The decision function is denoted as(19)f(x)=sign(wTϕ(x)-b)=sign∑j=1nλjyjK(xj,x)-bFollowing the above illustrations, the overall process of the KFP-MCOC algorithm can be summarized into the following four steps:Step 1: Computing the degree of fuzzy membership sifor each input pointxi(i=1,2,… ,n) with training set (see Eq. (11)):si=1-d(ϕ(xi),ϕ¯yi)/(ryi+δ), where the class meanϕ¯yi, the class radiusryiand the distanced(ϕ(xi),ϕ¯yi)between an input point and its class mean as Eqs. (9), (10), and (12) respectively, δ (δ>0) is a sufficiently small constant.Step 2: Solving Eq. (18) and getting the optimal solutionλj(j=1,…,n)of KFP-MCOC based on the training set.Step 3: Constructing a decision function according to the separating hyperplanewTϕ(x)=b with respect toλjwith the training set (see Eq. (19)):w=∑j=1nλjyjϕ(xj)andb=∑j=1nλjyjK(xj,xi), where the input pointxisatisfies αi=0 or βi>0. Thus the decision function is written asf(x)=sign∑j=1nλjyjK(xj,x)-b.Step 4: Testing an unknown samplexby the above decision function: If f(x)⩾0, the pointxis classified as positive class; otherwise, the pointxis predicted as the negative class.We designed a data set which is characterized by anomalies, class imbalance, and nonlinearly separable cases so as to test the new KFP-MCOC. In this paper, since the linear MCOC and quadratic MCOC cannot be directly used with nonlinearly separable cases, we only tested KFP-MCOC, SVM, and fuzzy SVM with the RBF kernel on the data set. The data set is used for binary classification with 102 points of negative class and 38 points of positive class as shown by diamonds and crosses respectively in Fig. 1.Figs. 2 and 3show the boundaries and margins found by SVM with C=1000 and fuzzy SVM with C=100,000 and σ=1 for the RBF kernel respectively. In Fig. 4, KFP-MCOC using the RBF kernel generates a better separating boundary with C1=1000, C2=7000 and σ=0.1, which shows that KFP-MCOC can achieve an excellent accuracy for uncertain data.In this section we use KFP-MCOC and other classifiers for credit risk evaluation, including data sets used, experiment design, performance evaluation, experimental results, comparison analysis, and discussion in the following subsections.In our experiments, three credit data sets are used for credit risk analysis: A Australian credit data set, a German credit data set, and a major USA credit data set. They are presented separately as follows.The Australian credit data set is sourced from the UCI Repository of Machine Learning Databases, an online repository of large data set which encompasses a wide variety of data types (http://archive.ics.uci.edu/ml). The data set consists of 307 instances of creditworthy applicants and 383 instances where applicants are not creditworthy. Each instance contains 6 nominal, 8 numeric attributes, and 1 class attribute (accepted or rejected). This data set is interesting because there is a good mixture of attributes: continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values in this data set. To protect data confidentiality, the attributes names and values have been changed to meaningless symbolic data.The German credit data set which is also sourced from the UCI Repository of Machine Learning Databases is class-imbalanced and composed of 700 instances of creditworthy applicants and 300 instances whose credit should not be extended. For each applicant, 24 input attributes describe the credit history, account balances, loan purpose, loan amount, employment status, personal information, age, housing, and job title. This data set consists entirely of the numeric attributes.The last credit card data set used in our experiments is provided by a major U.S. bank. It contains 6000 records and 66 derived attributes. Among these 6000 records, 960 are bankruptcy accounts and 5040 are “good” status accounts. Obviously this credit data set is also class-imbalanced.Finally, owing to the inevitable errors in collecting and computing the values of above attributes, these data sets may potentially contain noise, outliers and anomalies, at the same time, and they may be nonlinearly separable for different classes. Besides, the Australian credit data set, the German credit data set and the USA credit data set are class-balanced, with the first having the ratio of “good” to “bad” of roughly 4 to 5, the second showing a proportion of 7 to 3, and the third of approximately 5 to 1.In our experiments, for each credit data set, we randomly select 250 samples from each class of the respective data set, and form the training set. The remainder is used for the independent test set. Then the 10-fold cross-validation (CV) method is used to train MCOC, KFP-MCOC, SVM, and fuzzy SVM on the training subset, and the averages of predictive performance with the independent test set are calculated and reported. For the performance comparison among the different categories of classifiers, the average accuracies of those classifiers belonging to the same category are also computed and shown. Besides, missing values are filled with the mean of continuous attribute and mode of discrete attribute. All the attributes are normalized to the range of 0–1.Then, in the process of training the parameters for MCOC, SVM, fuzzy SVM and KFP-MCOC are chosen from the specific discrete set so as to get the best classification accuracy. In order to be able to use the grid search method, the different parametric sets of these classifiers are set to: For the penalty factor C for MCOC, SVM, and fuzzy SVM, the penalty factors C1 and C2 for KFP-MCOC from the set {1, 10, 20, 50, 100, 200, 500, 1000, 5000, 10,000, 100,000}; the offset term c from the set {0, 1} and the power d from the set {2, 3} for the polynomial kernel; the bandwidth σ from the set {0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10,000} for the RBF kernel; the coefficient a from the set {0.0001, 0.001, 0.01, 0.1, 1, 10} and the offset term r from the set {−0.00001, −0.0001, −0.001, −0.01, −0.1, −1} for the sigmoid kernel. For a classifier mentioned above an iterative procedure based on the corresponding parametric set is used to determine the best parameter, and the 10-fold CV approach is applied in each iteration. The best parameter of a classifier for the training subsets is chosen with regard to the best average of performance on the validation subsets, so we have 10 classifiers corresponding 10 training subsets for the 10-fold CV method. Then the same classifiers with the same parameter value is later also used on the independent test set for prediction respectively, thus based on 10 classifiers the average accuracy for the evaluation of the total performance and the statistical comparison of different classifiers can be computed and reported.It is clear that for the purposes of preventing credit fraud and avoiding bad loans, the classification accuracy of “bad” credit applicants must be improved considerably, at the same time, these improvements should not affect the predictive accuracy of “good” credit applicants and total creditors.Thus in our experiments eight accuracy measures are used to evaluate the predictive performance of classifiers. These measures are defined respectively as follows:(i)Total accuracy (the total classification accuracy rate, TA):(ii)Type I accuracy (the identification rate of “bad” creditors, T1A):(iii)Type II accuracy (the identification rate of “good” creditors, T2A):(iv)F1 score (the mixed measure of classification, F1S):(v)Matthew’s Correlation Coefficient (the adjusted impacts of imbalanced data set, MCC):Besides, the Kolmogorov–Smirnov (KS) statistic is one of the most useful and general nonparametric methods for evaluating classifiers, as it is sensitive to differences in both location and shape of the empirical cumulative distribution function of the two classes. The area under curve (AUC) statistic is an empirical measure of classification performance based on the area under an ROC (receiver operating characteristic) curve (Fawcett, 2006), where a classifier is preferred if its ROC curve is closer the upper-left corner, that is, with a large AUC. The value of AUC lies in the interval [0,1], and a larger AUC means a better predictive performance of the classifier. For comparative purposes, H measure (HM) uses different distributions to evaluate different classifiers, that is, it is making fair comparisons (Alpaydin, 2010; Hand, 2009).Finally, all of our experiments are carried out using Matlab 7.10. The linear programming problems of linear MCOC and KFP-MCOC, and the convex quadratic programming problems of quadratic MCOC, SVM and fuzzy SVM, are solved by using Matlab optimal tools.For the Australian credit data set, by using the 10-fold CV method the MCOC, SVM, fuzzy SVM and KFP-MCOC models are trained on training subsets and validated on validation subsets in order, the classifiers are obtained and tested on the independent test set. Hence, the averages of different accuracies of these classifiers and the total averages of predictive performance are calculated and reported in Tables 1–4respectively.As the experimental results show in Tables 1–4, we can observe that the predictive performance of our proposed KFP-MCOC is slightly better than that of others on the average. Generally KFP-MCOC has the highest values of type I accuracy (average 95.44%), type II accuracy (average 83.03%), total accuracy (average 86.79%), F1 score (average 0.81), MCC (average 0.74), KS (average 0.83), AUC (average 0.91) and H measure with an average of 0.62. Then, the predictive accuracy of fuzzy SVM with the sigmoid kernel and KFP-MCOC with the RBF kernel outperform that of linear MCOC, quadratic MCOC, and SVM. Besides, KFP-MCOC with the RBF kernel achieves better accuracy in total compared to SVM and fuzzy SVM with the RBF kernel. Owing to the majority of “good” creditors, SVM with the linear kernel and fuzzy SVM with the polynomial and sigmoid kernel classifiers achieve better performance for the type II accuracy than that of others. However, for KS, AUC, and H measure KFP-MCOC is superior in the predictive performance to other classifiers.Similarly, for the German credit data set, MCOC, SVM, fuzzy SVM and KFP-MCOC are trained and obtained with the 10-fold CV subsets, and then the resulting classifiers are tested on the independent test set. So the average accuracies and the total averages with respect to the predictive performance are shown in Tables 5–8respectively.As the experimental results demonstrate in Tables 5–8, we find that the predictive performance of our proposed KFP-MCOC is slightly better than that of other methods for the averages. Generally KFP-MCOC has the highest values of the total accuracy (average 72.69%), the type I accuracy (average 78.02%), the type II accuracy (average 72.15%), F1 score (average 0.37), MCC (average 0.33), KS (average 0.52), AUC (average 0.76) and H measure (average 0.06). The predictive accuracies of SVM, FSVM, and KFP-MCOC are better than that of linear and quadratic MCOC. Besides, for the type II and the total accuracies, SVM with the linear kernel and fuzzy SVM with the sigmoid kernel outperform MCOC and KFP-MCOC. For KS, AUC, and H measure KFP-MCOC is obviously superior in the predictive performance to MCOC and SVM.For the USA credit data set, MCOC, SVM, fuzzy SVM and KFP-MCOC are trained and obtained with the 10-fold CV subsets, and then these classifiers are tested on the independent test set. Hence, the averages of different accuracies of the classifiers, and the total averages with respect to the predictive performance, are shown in Tables 9–12respectively.As the experimental results demonstrate in Tables 9–12, we can see that KFP-MCOC is slightly better than others in predicting “bad” creditors (average 82.86%), the total accuracy (average 74.68%), F1 score (average 0.46), MCC (average 0.40), KS (average 0.57), AUC (average 0.78), and H measure (average 0.11). For the linear, RBF, and sigmoid kernels, the type I accuracy of KFP-MCOC is remarkably superior to other classifiers, while for the linear and polynomial kernels, the total and type II accuracies of KFP-MCOC are slightly better than that of other classifiers. Besides, because of the majority of “good” creditors in data, SVM with the RBF kernel and fuzzy SVM with the sigmoid kernel have a slightly better type II accuracy, while fuzzy SVM with the polynomial kernel achieves the best type I accuracy. However, for KS, AUC, and H measure KFP-MCOC is superior in the predictive performance to MCOC and SVM averagely.On the independent test sets of the three credit data sets, we select the classifiers with the best predictive performance as obtained by the 10-fold CV method and plot the corresponding receiver operating characteristics (ROC) curves, as illustrated in Figs. 5–7respectively.From Figs. 5–7, we find that FKP-MCOC in total performs better than the linear or quadratic MCOC. Hence, we can say that FKP-MCOC achieves a notable improvement in classification performance compared with MCOC. Besides, on the Australian credit data set, as shown in Fig. 5, FKP-MCOC with the linear and RBF kernels explicitly outperforms the classifiers of SVM and fuzzy SVM with the corresponding kernels for the best predictive performance. On the German credit data set, as seen in Fig. 6, FKP-MCOC with the polynomial, RBF, and sigmoid kernels outperforms SVM with the corresponding kernel functions under different loss conditions. On the USA credit data set, as seen in Fig. 7, for different kernels, FKP-MCOC is slightly better than SVM and fuzzy SVM for predictive accuracies, except for fuzzy SVM with the linear and sigmoid kernels, according to the visual analysis of ROC.For comparison of different classifiers, statistical tests are often used on the same data set (Alpaydin, 2010; Kuncheva, 2004). To this end, here we employ the 10-fold CV Paired t-Test method to compare the classification performance of KFP-MCOC with that of MCOC, SVM, and FSVM. To compare the performance of two classifiers, we use the measures of total accuracy, type I accuracy, type II accuracy, F1 score, MCC, KS, AUC and the H measure. For each measure m, a set of 10 paired differences between the two classifiers is obtained. One assumption that we make is that the set of differences is an independently drawn sample from an approximately normal distribution. In fact, for 10-fold CV method the training sets are overlapping, but the test sets are independent. Hence, under the null hypothesis, this means the mean differenced¯of two classifiers is greater than or equal to zero. Then the following statistic has a t-distribution with 9 degrees of freedom as below(25)t=(d¯∗10)sqrt∑i=110(mi-d¯)2/9.whered¯=(1/10)∑i=110mi. For the level of significance 0.05 in the tabulated value we have t0.025,9=2.26. Thus if t>2.26, we reject the null hypothesis that the first classifier has significantly lower accuracies than the second, otherwise, we accept it.The study (Demsar, 2006) shows non-parametric tests are safer and stronger than parametric tests without the assumption of normal distributions. The Wilcoxon signed-ranks test (WSR-Test), as a non-parametrically statistical test, is often used to rank the differences in performances of two classifiers.For the 10-fold CV method, let dibe the difference between the performance measures of the ith fold of the two classifiers on the independent test set. The differences are ranked according to their absolute values and average ranks are assigned in case of ties. Let R+ be the sum of ranks for the test set on which the first classifier outperformed the second, and let R− be the sum of ranks for the opposite. Rank of di=0 are split averagely among the sums. That is(26)R+=∑di>0rank(di)+(1/2)∑di=0rank(di),R-=∑di<0rank(di)+(1/2)∑di=0rank(di).Let t be the smaller of the sums, that is, t=min(R+,R−). Therefore, the z statistic of the 10-fold CV method is distributed approximately normally, which can be denoted as(27)z=(t-(1/4)K(K+1))/sqrt((1/24)K(K+1)(2K+1)).where K=10. With the level of significance 0.05, the null hypothesis should be rejected if z<−1.96, and then we can draw a conclusion that the difference between the two classifiers is significant statistically.Thus the statistics of the paired t-Test (see Eq. (25)) and WSR-Test (see Eq. (27)) based on the 10-fold CV method are calculated with the three credit data sets and shown in Tables 13–15respectively.For the Australian credit data set results in Tables 13–15, as well as the experimental results of classifier performance in Section 4.3 show that KFP-MCOC totally outperforms linear and quadratic MCOC, and that the type I accuracy of KFP-MCOC is better than that of SVM. For the measures of KS, AUC and HM, according to their values of both t and z statistics, we see that FKP-MCOC is more outstanding than other similar classifiers. However, we find that there is no statistically significant difference between KFP-MCOC and fuzzy SVM except that fuzzy SVM with the linear kernel outperforms that of KFP-MCOC with the linear kernel for the type I accuracy.On the German credit data set, we come to similar conclusions. KFP- MCOC significantly outperforms both linear and quadratic MCOC. Also, KFP-MCOC outperforms SVM except for the case of the linear kernel. For the type I accuracy, the fuzzy SVM with the polynomial kernel is better than KFP-MCOC with the same kernel. However, for the z statistical values of KS and HM measures, we see that KFP-MCOC is obviously better than other classifiers in the predictive performance.On the USA credit data set, we conclude that KFP-MCOC is better than the linear and quadratic MCOC. At the same time, KFP-MCOC is better than SVM with the linear and polynomial kernels except for the type I accuracy, AUC, and H measure. Besides KFP-MCOC with the RBF kernel is better than SVM and fuzzy SVM with the same kernel for measures type I accuracy, F1 score, MCC, KS, and AUC. Finally, for the sigmoid kernel classifier there is no statistically significant difference between KFP-MCOC and fuzzy SVM.Finally, for the comparison of different classifiers we can generally find that the results of the non-parametrically statistical tests (z statistic) are consistent with that of the parametrically statistical tests (t statistic), and the former is not as sharp or sensitive as the latter for the statistical values.

@&#CONCLUSIONS@&#
In this paper, we proposed an improved MCOC method, KFP-MCOC, which is based on kernel, fuzzification, and penalty factors for credit risk evaluation. KFP-MCOC extends the capacities of MCOC and avoids solving the convex quadratic programming problem which is required for SVM and fuzzy SVM. KFP-MCOC is characterized by using a kernel function to transform the original space into a new high-dimensional feature space, introducing a degree of fuzzy membership to each input point in kernel-induced feature space, and using class-imbalanced penalty factors to reach a compromise between overfitting majority-class and underfitting minority-class. The improved classifier can effectively reduce the effects of noise, outliers, and anomalies in data, class imbalance, and nonlinearly separable cases. At the same time, KFP-MCOC was tested with simulation data and three real world data sets. The experimental results and the statistically comparative analysis show that KFP-MCOC is a more effective classifier for credit risk evaluation, and has great potential as a prospective classification approach for other applications. Besides, we plan to improve the interpretability of different variables in KFP-MCOC for credit risk evaluation or other real world applications in the future.