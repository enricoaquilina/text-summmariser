@&#MAIN-TITLE@&#
Transaction-level power analysis of VLSI digital systems

@&#HIGHLIGHTS@&#
The paper deals with power analysis on transaction-level models of complex digital systems.We propose an estimation methodology strictly based on the modeling constructs of SystemC/TLM and of general applicability.We consider the comparison with RTL power estimation techniques on several design aspects: estimation accuracy, simulation time and modeling effort,The experimental results show the design advantages of the proposed methodology with respect to RTL estimation techniques.

@&#KEYPHRASES@&#
Power estimation,SystemC language,Transaction-level modeling,VLSI digital systems,

@&#ABSTRACT@&#
The increasing complexity of VLSI digital systems has dramatically supported system-level representations in modeling and design activities. This evolution makes often necessary a compliant rearrangement of the modalities followed in validation and analysis tasks, as in the case of power performances estimation.Nowadays, transaction-level paradigms are having a wider and wider consideration in the research on electronic system-level design techniques. With regard to the available modeling resources, the most relevant framework is probably the transaction-level extension of the SystemC language (SystemC/TLM), which therefore represents the best platform for defining transaction-level design techniques.In this paper we present a macro-modeling power estimation methodology valid for SystemC/TLM prototypes and of general applicability. The present discussion illustrates the implementation modalities of the proposed approach, verifying its effectiveness through a comparison with RTL estimation techniques.

@&#INTRODUCTION@&#
Over the last decade, several researches have been conducted to develop electronic system level (ESL) approaches in the modeling and analysis of microelectronic digital systems. The main motivations behind these researches come from the need of design techniques at an abstraction level higher than register transfer level (RTL). In fact, RTL techniques are becoming less and less suitable to face the complexity reached by many microelectronic products, as in the case of VLSI devices made up of million of gates. More precisely, the evaluations conducted on RTL prototypes may be onerous in terms of execution times and design efforts, because it is necessary to work with rather detailed descriptions of the system architecture. This can burden the design activities and make it difficult to meet strict time-to-market constraints. On the other hand, ESL design techniques allow to work on system prototypes derived from functional specifications, without having to deal with specific implementation details. In this way, there are more chances to take major decisions in the early design phases and with limited efforts, thus to speed up the flow towards the silicon implementation.Transaction level modeling (TLM) has established itself as an effective ESL paradigm, especially in the description of the communication tasks between interacting modules. More precisely, when describing a complex digital system composed by several interconnected modules, a transaction-level representation allows a good separation between communication and elaboration tasks. The channel access is typically mediated by calls to interface functions capable to transport consistent data amount; each module is independent from the others with regard to interconnectivity [1]. The main benefits due to these features consist in the use of system prototypes that can be defined and simulated in reduced times. Moreover, the high interoperability of transaction-level models facilitates the realization of complex system architectures.Nowadays, power performances are often a crucial constraint in the design of VLSI digital systems, in consequence of the wide diffusion of battery-supplied devices as well as the reliability issues due to high clock frequencies. The estimation of power dissipation is by now a primary design matter, providing useful indications in the analysis of implementation options and low-power solutions. Power estimation on RTL representations has been extensively studied, and a number of effective and well-tested techniques is now available [2–9]. More specifically, we can distinguish between cumulative and cycle-accurate RTL approaches [2]. In the first case, the power estimation is achieved by evaluating a power model at the end of a simulation period, on the basis of average input statistics. On the other hand, a cycle-accurate technique leads to evaluate the power model at every time cycle, requiring as input data cycle-based quantities.In the design of a complex VLSI system, the realistic application of these estimation techniques is usually based on a modular approach. More precisely, the power model definition does not concern the system as a whole, but rather is carried out on basic modules that cover specific tasks. The RTL representation of the whole system is built through an aggregation of the RTL description of these modules; these latter can be realized by the designer or also taken from a third part library. In order to define the power model of a basic module, it is often necessary a characterization procedure which provides precise power consumption data from low-level power simulations [2]. For a specific CMOS technology, such characterization may be carried out once and for all, and the results may be reused for several VLSI systems based on that technology. Finally, once built the power models of the basic modules, we can perform power estimations on the whole system in its RTL representation.RTL techniques are often capable to provide reliable power estimations, which can be used to verify design constraints as well as evaluate different implementation options. However, for the reasons before mentioned, many research interests are becoming more oriented towards analysis techniques at electronic system level. In particular, power estimations on transaction-level representations constitute an attractive investigation field that needs to be explored more deeply. In concrete terms, this means defining general and effective estimation methodologies applicable on transaction-level system descriptions.From a conceptual viewpoint, we could expect a possible penalty in estimation accuracy when moving from RTL to transaction level power estimation techniques. In fact transaction-level techniques are applied on system prototypes at a higher abstraction level and with less implementation details than RTL representations. As a consequence, the run-time information achievable from a transaction-level prototype, and used in power model application, can be less detailed and precise. However, this possible loss of accuracy can be strongly mitigated if we consider a transaction-level estimation technique based on a macro-model approach [2], in which transaction-level metrics are connected to precise power measures coming from a low-level system implementation, such as the logic-level or the gate-level architecture.The starting point for a research on transaction-level power estimation is to fix a reference language suitable for transaction-level modeling. In recent times, SystemC language has provided an extension specifically dedicated to transaction-level descriptions, (SystemC/TLM) [10], which is probably the most relevant contribution in the formalization of a transaction-level modeling standard. As a consequence, SystemC/TLM is the most proper platform to define methodologies and CAD instruments for transaction-level power analysis.SystemC language has already been at the center of some studies on transaction-level power analysis [11–15]. However, some of the resultant techniques [11–13] are referred to the core capabilities of the language, without applying the specific constructs provided by SystemC/TLM. In this way, they are precluded from the design advantages achievable from SystemC/TLM in terms of modeling facilities and simulation speed up. Examples of techniques relying on SystemC/TLM constructs are reported in [14,15]. The first contribution is a methodology based on the classification and power characterization of the functional tasks involved in transaction-level operations. The procedural steps are illustrated through a case study on IBM CoreConnect architectures. The experimental results show a good accuracy if there is a good matching between the considered functional tasks and the transactions generated in the run-time behavior of the system. This technique is applicable for SystemC/TLM prototypes in which the inter-module communications are based on the blocking transport interface [10]. On the other hand, the approach presented in [15] is a power state estimation technique aimed at evaluating the power dissipation in the main operative conditions and in reference to different system architectures. Even though the estimation results are not very accurate, the primary intent is to realize a fast comparison of the possible architecture alternatives. Analogously to [14], the application of this technique is restricted to prototypes based on the blocking transport interface.This paper presents a transaction-level power estimation methodology valid for SystemC/TLM descriptions and of general applicability. In our researches, we have considered how to formalize the mapping of functional tasks onto the basic SystemC/TLM constructs that model transactions, without introducing restrictions related to the applied transport interface. By following an ad-hoc macro modeling technique [2] these SystemC/TLM constructs can be properly associated to energy estimations derived from measures on a low-level system implementation. In this way, we can estimate the energy of the transactions executed during a simulation session. Furthermore, we have studied the possibility to tune the estimation accuracy on the basis of the data transported by transactions.In order to implement and verify the proposed approach, we have also realized a specific CAD tool that extends the SystemC/TLM language and is incorporated within the Power Kernel tool (PKtool) framework [13], [16–20]. PKtool is a simulation environment born from an academic project and dedicated to power analysis on digital systems modeled in SystemC/C++. An open source release of the tool we have realized is available in [16].This paper is structured as follows. In Section 2, a preliminary introduction on SystemC/TLM language is reported. Section 3 describes the details of the proposed methodology in conceptual and operative terms, while Section 4 provides the guidelines for a concrete application on SystemC/TLM prototypes. Section 5 explains how our methodology can be extended to cover power optimization techniques. Finally, some experimental results are illustrated in Section 6, considering also performance comparisons with RTL representations. Our methodology provides estimations in terms of energy; the ratio with simulation times allows to estimate also average power dissipations. To avoid ambiguities, in the remainder of the paper we often use expressions such as ‘power dissipation’ or ‘power estimation’ in conventional way, without an explicit reference to a physical quantity.SystemC/TLM has been developed as an extension of the SystemC core language, with the aim to optimize the semantics and the simulation capabilities for transaction-level representations. Furthermore, the use of SystemC/TLM is regulated by precise guidelines that formalize a transaction-level modeling style with reference to specific detail levels.In a typical RTL representation the inter-module communi-cations are realized through wire-like connections, pin-accurate I/O ports and clock-synchronized data transfers. Such scenario changes dramatically when moving to a SystemC/TLM description, in which the inter-module connections are virtually replaced by transport interfaces and the time references are restricted to the duration of transaction phases. Transaction-level communications are based on specific functions (TLM functions) that define the transport interfaces. More precisely, a transaction is modeled by means of calls to TLM functions that execute consistent data exchange between an initiator and a target module. The function calls may proceed from initiator to target (forward path) or in the reverse way (backward path). The linkage between an initiator and a target may be direct as well as constituted by intermediate modules that receive and forward TLM function calls (Fig. 1). In alternative mode, the modules involved in a TLM function call may be identified as caller and callee. The caller issues the function call, whereas the callee deals with the function execution according to a customized definition. The distinction between caller and callee is independent from the logical roles covered by a module as initiator, target or interconnect unit. In general, within a succession of TLM function calls, a module may be caller or callee in interleaved manner. The data exchanged in a transaction are typically referred to the format of a digital communication protocol. For this purpose, SystemC/TLM makes available a protocol template, called generic payload, suitable for memory-mapped bus (MMB) protocols and conceived to guarantee a high interoperability among models coming from different parts. However, generic payload includes some flexibility elements for a possible adaptation to specific communication protocols.The TLM functions currently present in the SystemC/TLM framework are mentioned inFig. 2, with reference to their prototypes. The first three functions handle transactions in general manner, on the basis of blocking and non-blocking transport modalities [10]. In the former case, a transaction is entirely developed via a single function call on the forward path, having as unique time reference the overall processing latency. Conversely, the non-blocking modality allows a more precise modeling, with the inclusion of intermediate phases and timing points. In this way, the course of a transaction may be broken into more TLM function calls on the forward and backward paths. The functions get_direct_memory and invalidate_memory are dedicated to optimized operations for memory management. Finally, transport_dbg is reserved for debug purposes.An important point is that TLM functions are not merely aimed at the transport of transaction data, but also carry out the elaboration of these data. The results of such elaborations are reported in the return value and/or in the references passed as input parameters. Actually, TLM functions may be regarded as the primary elements to represent the run-time functionality of a module in SystemC/TLM. In modeling terms, this is realized by the mapping onto two main entities: the bodies of TLM functions and the processes that issue TLM function calls (Fig. 3). In practice, the whole dynamic behavior can be reconducted to these two entities, because on them depend the tasks related to I/O evolution. In regard to power estimation, this means that dynamic power dissipation can be evaluated by monitoring TLM function executions and caller processes.To illustrate the proposed methodology, the starting point is to characterize properly the power dissipation of a transaction- level prototype defined in SystemC/TLM. In general, the occurrence of a transaction entails an energy dissipation for all the involved modules (the initiator, the target and possible interconnect units). Consequently, the dynamic energy dissipation of a single module can be achieved considering the energy contributions of the transactions in which it is involved. In this way, the overall energy dissipation can be estimated as the sum of the estimations due to the transactions occurred during a simulation.The realization of this approach requires to sample the calls to the TLM functions constituting a transaction and to estimate an energy dissipation for each module involved in such function calls. For this purpose, each module should be associated to a set of power models, one for each TLM function that may concern the module in the role of caller or callee. In this context, a power model can be regarded as a formal definition of the energy cost of a TLM function, from the caller or the callee side. Every time a TLM function is issued, an energy estimation is computed for the caller and callee modules, by applying the respective power models linked to such function (Fig. 4).An essential aspect is to understand how much this estimation modality fits the effective power dissipation of a module. For this purpose, we can evaluate the coverage level with respect to the module functionality, mapped in this case on the TLM function bodies and the caller processes (Fig. 3). The power dissipation of the TLM function bodies is completely covered by the function calls from the callee side. As concerns the caller processes, the related dissipation can be achieved from TLM function calls through an extended view of their energy costs. More precisely, in the energy cost of a TLM function from the caller side, it is always possible to include the contributions of the elaborations surrounding the function call instruction inside the process. In principle, this energy cost could include the whole execution flow of the caller process. If a process issues distinct TLM function calls in different points of its execution flow, the energy cost of each function could include only the closest elaborations, in an orthogonal manner and up to cover the whole execution flow. From these observations we can conclude that the considered estimation approach is able to cover the whole functionality of a module, and provide non-partial estimations in regard to the dynamic behavior.As concerns the power model extraction (that is how to determine the energy costs of a TLM function with respect to the caller or callee side), we can apply a specific macro-modeling technique [2]. The first step consists in a characterization procedure aimed at determining accurate measures of the energy dissipation of the function. These measures should be achieved from power simulations on a low-level prototype of the examined system, e.g. a gate-level description. More precisely, the low-level prototype should be simulated to reproduce the execution of single function calls on a significant amount of training input stimuli. From each simulation, by evaluating an accurate gate-level power model, we obtain the energy dissipation of the TLM function for the applied input sequences. Finally, by averaging all the obtained measures, we can achieve the energy costs that define the power model associated to the TLM function. There are no specific limitations on the power model that can be used in this procedure. It is possible to use a power model based only on dynamic power and signal activity as well as more accurate power models including also leakage power contributions or any other source of power dissipation.Entering more into details, this characterization procedure requires to map the SystemC/TLM prototype on the low-level prototype, in order to distinguish those circuitry blocks triggered by the TLM function call (Fig. 5). In low-level power simulations the sum of the energy dissipations of these circuitry blocks will provide the energy measures related to the TLM function call.As concerns the input stimuli applied in low-level simulations, it is important to consider the time duration associated to the TLM function call. More precisely, the data exchanged in a transaction could cover several clock cycles in the low-level prototype, spanning a sequence of consecutive input values (and not simply a pair of these latter). For this reason, the training stimuli set should consist in a significant number of input sequences corresponding to typical data exchanged in transactions.In our methodology the power model is referred to a table-based representation [2], in which the energy costs of a TLM function call are stored in a lookup table for the caller and the callee module. In its simplest version, the characterization procedure leads to get two generic energy costs, one for the caller and another for the callee side, used as estimations every time the TLM function is run. In this case, the power model is merely associated to lookup tables with only one element. Nonetheless, more accurate power models may be obtained considering also the I/O information managed by the TLM function, i.e. the input parameters and the return value (TLM data). Such information are strictly related to the current operative conditions, such as the type of operation, the transaction phase, the transaction status. The effective power dissipation may significantly vary for different TLM data entries, because of their influence on the signal dynamics and the elaborations carried out. To clarify this point, we can consider the examples reported inFig. 6, which show two typical SystemC/TLM code fragments representing a caller process and the body of a TLM function. In the first example, a TLM function is called with the subsequent execution flow depending on the value returned by the function; this return value specifies the status of the transaction. Examining the code, it is evident how different return values cause the execution of different elaborations, which in turn may lead to quite different power dissipations. The same conclusions hold also for the other example, in which the power dissipation depends on the operation type associated to the transaction.TLM data can be taken into account to get more precise measures from the characterization procedure, thus improving the accuracy of the energy costs associated to a TLM function. This opportunity is based on the mapping of a transaction-level prototype onto a gate-level architecture. In fact, in such mapping several TLM data may correspond to signals of easy identification in the gate-level description. Focusing on one of the TLM data, for example the transaction status, we can realize distinct characterization procedures for fixed values of the corresponding gate level signals. In this case, we can carry out specific evaluations of the energy dissipated by the caller process, whose execution flow may depend on the transaction status specified by the return value of the TLM function.At the end of the characterization procedure, what we end up with is something more accurate than an overall energy cost, i.e. the average power dissipations related to the possible values returned by the TLM function. Each of these measures can be assumed as the energy cost of the function in the corresponding transaction status. In this way, the TLM function can be associated to several energy costs from the caller side, according to the cardinality of the transaction status. Accordingly, the power model is associated to lookup-tables with as many elements as the possible transaction status. During a simulation on the transaction-level prototype, in each function call, the energy cost of the caller side will be the one associated to the current transaction status, as specified by the return value of the function.To explain better this characterization procedure, we can consider the low-level architecture inFig. 7, which shows a general representation of the caller circuitry involved in a TLM function. In such architecture we can distinguish a combinatorial unit, a flip-flop array holding the internal state, the binary primary inputs (I1, I2,…, In) and the binary state signals (S1, S2, … Sm). At this point we should consider the mapping between TLM data and the binary input/state signals. In particular, the inputs i2−i3 and the state signal s2 could be associated to the transaction status, which can assume three different values, i.e. TLM_ACCEPTED, TLM_UPDATED, TLM_COMPLETED [10]. In this example, we can suppose the following correspondence with the binary values of (i2,i3,s2): (0,1,0). (1,0,0), (0,0,1).During the characterization procedure, if we want to achieve energy measures specialized with respect to the transaction status, we should executed a number of power simulations where i2, i3 and s2 are fixed whereas the other signals are assigned to sequences of variable values. These power simulations should be repeated for the three possible transaction status, maintaining (i2,i3,s2) fixed to the corresponding binary values. By averaging the energy measures resulting from power simulations, we achieve three energy costs (one for each transaction status) which will be the elements of the lookuptable power model. These costs represent the estimations of the energy dissipated by the caller module when the considered TLM function is called. More specifically, in each function call the energy cost selected will be the one associated to the transaction status returned by the function.The specialization process now described can be further refined, considering jointly more TLM data and deriving power models with more numerous and precise energy costs. These latter will be associated to the possible combinations of the TLM data values. Such a refinement may further improve the estimation accuracy at the price of a more articulated characterization procedure. In this way, the resulting power model will be represented by a multi-dimension lookup table, with as many dimensions as the number of considered TLM data.The approach so far discussed is able to estimate properly only the power dissipation related to the dynamic behavior of a module. In fact, TLM functions reproduce only the active phases of the run-time evolution, without including those time periods in which no transaction is handled and the power dissipation is essentially due to leakage effects [21]. In general, the run-time behavior of a module is constituted in its entirety by an alternation between active and idle phases, as illustrated inFig. 8. Especially in VLSI technologies with high integration levels, these idle phases may take a relevant fraction of the total power dissipation such that their effects could not be secondary.To solve this limitation, it is possible to consider the solution proposed in [14], in which a further contribution is computed for including the power dissipation in idle phases. In analytical terms, this leads to the following estimation formula:(1)Emod=∑iNei+P×Tidlewhere N is the number of transactions occurred during a simulation, eithe energy of a single transaction (achieved from lookup-table power model), Tidlethe sum of the idle time intervals and P the idle power dissipation. Eq. (1) represents the energy dissipation of a single module and eiis referred to the call of a TLM function that may concern the module in the role of caller or callee.This subsection briefly illustrates the application of the proposed methodology for including inter-module connections in power estimation. In modern VLSI systems the wire connections between modules can have a relevant impact, especially in FPGA-based implementations [21]. In our methodology it is possible to take into account also the power dissipation of wire connections. For this purpose it is necessary to extend the low-level characterization procedure described in the previously subsection.Considering the wire connections between two interacting modules, we could determine the energy cost due to their power dissipation through the same low-level simulations run to calculate the energy costs of the TLM functions of the two modules. As power model, we could use the following expressions:(2)Ewire=12∑iNSiCavgVDD2where N is the number of wires that connect the two modules, Sithe signal activity of each wire, Cavgthe wire average capacitance and Vddthe applied power supply.In order to apply Eq. (2), it can be important to have an idea of the area occupation of the inter-module connections in the examined VLSI system; in fact this piece of information can be necessary to estimate the average wire capacitance.Also for inter-module connections we could apply a TLM data specialization, i.e. the wire energy cost can be possibly refined in reference to entries of one or more TLM data, by following the same procedure described in the previous subsection. In this way, at the end of the characterization process, we would end up with a further lookuptable energy costs associated to inter-module connections.After this conceptual description, it is important to consider how the proposed methodology can be concretely applied on a SystemC/TLM prototype. In particular, we should consider the application modalities on the single modules constituting the prototype. The best solution is probably to extend the basic implementation of the native SystemC/TLM modules, by adding the functionalities required for power estimation tasks. This approach can be addressed by leveraging on the inner implementation of the SystemC/TLM language, represented by an open-source C++ class hierarchy in which it is possible to modify the native classes used in module description. Given a SystemC/TLM prototype composed by several interconnected modules, without loss of generality, we can focus on two modules that are involved in a transaction execution. In this example, such modules are called module_a and module_b and play respectively the roles of caller and callee.To apply our approach, the first intervention could be done on the TLM function bodies defined inside the module classes. These functions have been listed in Fig. 2 and implement the tasks for handling a transaction that may involve the two modules. Each of these TLM function is derived from an interface class and must be defined by the module that covers the callee role when the corresponding TLM function is called. More precisely, every time the TLM function is called by a process of the caller module, the TLM function body is executed. As a consequence, the energy contributions related to the transaction could be sampled and computed inside the TLM function body. In concrete terms, this means to override the interface function defined inside the calle class, so that such function carries out its basic task and, in addition, computes the energy contributions for the caller and callee module.Coming back to our example, the pseudo-code inFig. 9 shows this enhanced implementation in the case of the TLM function nb_transport_fw defined inside the module_b class. The functions nb_trfw_energy_caller and nb_trfw_energy_calle are aimed to get the energy estimations for the caller and the callee module involved in the transaction, by querying the lookup-table power models. These functions can be defined inside the calle class. The estimated energy contributions are summed up to trans_energy_module_a and trans_energy_module_b, two variables holding the total energy estimated during the simulation for module_a and module_b. Each of these variables could be defined in the class of the corresponding module. For this reason trans_energy_module_a is handled through a pointer referred to the module_a object. The functions nb_trfw_energy_caller and nb_trfw_energy_calle take as input parameter the TLM data related to the transaction, in order to select the correct energy cost from the lookup-table power model. nb_trfw_energy_caller is called after the original instructions and takes as input parameter also the return response of nb_transport_fw. This implementation is necessary because the values of some TLM data are known from the caller side only after the original TLM function is executed, as in the case of transaction status.The lookup-tables with the energy costs of the TLM function may be created and linked to the caller and callee modules at the beginning of the simulation, by defining all the necessary instructions in the constructors of their classes. In particular, the energy costs defining each lookup-table could be explicitly assigned in these constructors or could be read by a text/xml file edited by the user. At software level the two lookup-table of the TLM function can be simply implemented through multi-dimension arrays of floats, where the number of dimensions corresponds to how many TLM data are considered to refine power estimations. In this way, the overall lookuptable size (i.e. the number of energy costs stored in the table) is given by the product of the entries of the considered TLM data. In computational terms, querying a C++ array is a quite-fast operation; as a consequence, during a SystemC/TLM simulation the power model application should not burden the simulation speed in relevant way. Actually, the most expensive operation in power model handling is probably the construction of the lookuptable at the beginning of the simulation. In particular, this means reading the energy costs from a text file and create the array of floats that store the energy costs. Nonetheless, the overhead of such operation can be strongly reduced for simulations conducted on relatively long observation periods.The instructions to display the total estimation results (i.e. the variables trans_energy_module_a and trans_energy_module_b) could be reported in the destructors of the module classes. In compliance with the C++ execution rules, the destructor functions will be called at the end of the SystemC/TLM simulation, when the overall power estimations are available.At this point, in compliance with eq. (1), the last contribution to be estimated is the static energy related to the idle periods. This means to estimate for each module the time period during which it is in an idle state and no transaction is executed. For this purpose, we can introduce a further variable in the classes of module_a and module_b, which is aimed to hold the total active time. During a simulation, likewise the transaction energy estimations, these variables could be updated inside the TLM function bodies, using the time parameter related to the transaction duration. Such parameter is passed as writeable reference to the TLM functions in both blocking and non-blocking transport interface. Accordingly, the pseudo-code shown in Fig. 9 should be revised according to the version inFig. 10. For each module the total idle time could be finally computed in the class destructor, by subtracting the total active from the simulation time. After that, in the destructor we could report the instructions to display also the idle energy estimation.If we want to consider also the power estimation of the inter-module connections, we should simply add a further instruction in the pseudo-code in Figs. 9 and 10, which handles the energy dissipation due to the connection wires during the TLM function call. Analogously to the instructions seen for module_a and module_b, this further instruction should execute a specific function that returns the energy estimation of the connection wires by querying the lookup-table with the associated energy costs. The estimation returned by this function will be summed up to a dedicated variable holding the total energy estimated for the wire connections during the simulation.By following these application guidelines, it possible to define all the functionality necessary to run our methodology on a SystemC/TLM description during an ordinary SystemC/TLM simulation. The implementation proposed in this section is simple, effective and may have a limited impact on the time performance of an ordinary SystemC/TLM simulation. On the basis of these guidelines we have realized a CAD tool for power simulations on SystemC/TLM prototypes, which provides user-friendly constructs to apply the proposed methodology. This tool extends the capabilities of the PKtool simulation environment and is currently available in [16].In modern VLSI systems there are often implemented techniques for optimizing power dissipation, such as dynamic voltage/frequency scaling (DVFS). An effective power estimation methodology should take into consideration such optimization techniques and model the related effects on the system performances.A noteworthy study on DVFS modeling in SystemC/TLM prototypes is illustrated in [22]. In this research is introduced the concept of power state, as entity to distinguish the working periods in which the system frequency/voltage can assume fixed values. In this case the power state characterization is based on a functional-level mapping, in which the power states are associated to the different functional conditions which can occur in the run-time behavior.Also in our methodology it is possible to model the contribution of DVFS techniques in power estimations. This modeling can be realized by connecting power states to TLM functions and determining the current power state when a TLM function is called. In comparison with [22], this approach provides a better formalization with reference to the modeling constructs of SystemC/TLM languages. This, in turn, can make easier and more systematic the description of DVFS tasks in power model application.In concrete terms, the modeling of DVFS techniques can be implemented through an augmented version of the energy-cost lookup-table associated to a TLM function. That is to say, we should define as many lookup-tables as the possible power states in which the system can work. As an example, we can consider a dynamic voltage scaling scenario where the voltage can switch among three different levels, on the basis of the current operative state. In this scenario, for a fixed set of TLM data, the power dissipation of a TLM function can be associated to three different energy costs, one for each voltage level. These costs should be derived from three distinct sessions of low-level power simulations, in which we consider the different voltage levels on the gate-level prototype.In this way, such approach leads to a power model lookup-table with a further input, in addition to the proper TLM data, i.e. the applied voltage. Considering the power model implementation described in Section 4, this implies to increase of one dimension the array storing the energy costs. With regard to power model characterization, a higher simulation effort could be required, because it may be necessary to repeat the low-level power simulation for all the possible voltage levels.To complete the DVFS modeling, it is necessary to realize the state machine that determines the current power state, i.e. the voltage/frequency currently applied. This state machine should be incorporated inside each caller/callee module that relies on a DVFS power optimization. For this purpose, we could define an internal submodule that implements the rules to detect the current power state (Fig. 11). This submodule should have access to all the information required by these rules, in particular the input and internal state signals on which depend the operative conditions. Moreover, this submodule should be able to communicate the current power state to the lookup-table power model, in order to select the correct energy costs. In compliance with the implementation described in Section 4, the current power state can be reported in a variable shared with the two functions that returns the energy estimations of a TLM function call.To evaluate the performances of the proposed methodology, we have conducted specific simulations considering the comparison with RTL estimation techniques. For this purpose, we have used the simulation tool introduced in Section 1 (the PKtool framework) and, as testing platform, we have considered benchmark systems of variable complexity, taken from SystemC/TLM releases and SoCLib research project [23].First of all we have considered three transaction-level prototypes included in SystemC/TLM releases (TLM-2.0.1); they are p2p/hierarchical_socket, at_1_phase and at_4_phase [10]. Such prototypes are fully compliant with the modeling rules specified in SystemC/TLM documentation, and represent demonstration examples given by the aggregation of typical digital components. p2p/hierarchical_socket reproduces a simple peer-to-peer connection between two modules implementing datapath operations. The communication channel is based on the blocking transport interface and each transaction is executed through a single TLM function call. at_1_phase and at_4_phase define more articulated bus-based systems, in which the inter-module communications rely on the non-blocking transport interface and a transaction may be carried out through more TLM function calls.At the beginning of this study, we have realized in SystemC a gate-level description for each of the examined systems, using the fine-grained constructs of the language for bit operations. The resulting architectures are constituted by FSMD blocks and memory units whose implementation is based on elementary logic ports. From these gate level architectures we have firstly computed the energy costs of the TLM functions issued in the transaction-level prototypes. These costs have been determined considering a generic behavior (with execution flows randomly generated) and also considering operative conditions related to specific TLM data, i.e. transaction phase and status. Furthermore, we have used these gate-level prototypes to determine the power dissipation in typical running sessions. The resulting measures have been assumed as reference terms to evaluate the estimation accuracy.Function costs and dissipation measures have been achieved from SPICE-like simulations, in which we have adopted a power model based on the expression for the energy dissipation of a CMOS cell [21]. The gate-level descriptions can cover transient assignments and spurious commutations, thus taking into account also glitch effects. As concerns technology mapping, we have considered the characteristic data of a 90nm process to set the power model parameters. The low-level power simulations have been executed by leveraging on the capabilities of the PKtool framework, which allows a run-time computation of the gate energy dissipation In particular, as concerns the dynamic part of power dissipation, during a simulation PKtool allows to sample the gate commutations by means of dedicated components called augmented signals. The data on commutations represent the fundamental information to evaluate the dynamic energy dissipated by the single gates, by applying the expression for the energy dissipation of a CMOS gate. In this way, by summing up the energy dissipation of all the single gates, we can achieve the energy dissipation of the examined system during a simulation.In order to realize a more comprehensive study, we have described in SystemC also RTL prototypes of the examined systems. The comparison with these RTL counterparts has allowed to extend our analysis to other relevant design metrics, in addition to power dissipation, such as modeling effort and simulation speed. This comparison is validated by the use of the same language to describe and simulate the prototypes in the different abstraction levels. To run the SystemC simulation engine, it is only necessary a C++ compiler environment, e.g. Visual C++ or GNU g++.As alternative solution, these low-level power simulations could be carried out on gate-level prototypes realized in a language more supported by standard CAD tools (e.g. VHDL language). In this case we would have probably achieved more precise energy costs. Nonetheless, the application of our methodology would have led to the same power estimation accuracy, because our methodology is based on transaction-level constructs that are independent from the gate-level implementation and the precision of the low-level energy measures.Tables 1 and 2 show the results of evaluations, in which we have determined the code size of the different prototypes and the CPU times required to simulate them. All the simulations have been executed on a PC unit with a 2500Mhz dual core Intel processor and 4GB of RAM.As confirmed by these data, moving from RTL to transaction level representations entails evident improvements with reference to the considered metrics. The modeling efforts may be reduced in remarkable measure, even by 30–40% for prototypes based on the non-blocking transport interface. With regard to CPU times, the first two rows of Table 2 specify the speedup factors with respect to gate-level simulations. The ratio between these values, reported in the bottommost row, provides the speed up of transaction-level simulations with respect to RTL ones. We can verify how transaction-level simulations are definitely faster, with a time saving that can reach one order of magnitude in the case of non-blocking transport modalities.In the core part of our analysis, we have estimated the power dissipation of the examined systems by applying our technique on the transaction-level prototypes. For this purpose, we have considered three power model variants, i.e. model_0, model_1 and model_2. In model_0 a TLM function is associated to its generic energy cost, which is assumed as estimation in every function call without applying TLM data specialization. model_1 introduces a first-level refinement, comprising energy costs related to the possible entries of one TLM data. We have studied two cases for model_1, considering separately transaction phase and status as TLM data. Finally, in model_2 the energy cost of a TLM function call depends jointly on transaction phase and status. The analysis on p2p/hierarchical_socket has been restricted to model_0, since the blocking transport interface does not handle phase and status information.Table 3 shows the average errors resulting from transaction-level estimations, with respect to the reference measures achieved from the gate-level simulations. In line with the expected trend, in all the examined systems we always have an accuracy improvement when applying more specialized power models. The best performances are provided by model_2, with errors slightly higher than 10% and 5% for at_1_phase and at_4_phase respectively. In any case, all the values reported in Table 3 are in the typical accuracy range of RTL estimation techniques (5%–20%), without evident penalizations.After this study on the examples included in SystemC/TLM releases, we have verified our methodology also on virtual prototypes provided by the SoCLib research project. SoCLib is an open platform for virtual prototyping of multi-processors system on chip described in SystemC language. This platform provides a library of SoC IP components used in concrete applications and modelled at different abstraction levels, such as transaction-level and CABA (cycle accurate – bus accurate). Moreover SoCLib provides several system prototypes built by the aggregation of the library components and executable through the standard SystemC simulation environment. These system prototypes define complex architectures related to real VLSI applications. In the last years SoCLib components have been used as effective benchmarks in several researches to evaluate the performances of digital systems, as in [24,25].In our study we have considered a SoCLib prototype performing fir 128 computations under the control of a processor unit. The corresponding architecture is constituted by four main IP components: a Mips32-based processor, a RAM memory, a computational unit (FIR 128 core) that implements the FIR algorithm and a NoC structure that connects the other components in compliance with the VCI on-chip-bus protocol. We have applied our methodology on this prototype, following the steps illustrated in the study on the SystemC/TLM demonstration examples. First of all, from the IP components provided by SocLib we have derived the descriptions at RTL and gate-level for each of the four components. The realization of such descriptions has required a modeling activity of about three months.Also in this study we have considered three power model variants: a basic transaction-level power model (model_0), without TLM data specialization, and two more refined power models (model_1 and model_2), specialized with reference to one and two TLM data respectively. In this case, the TLM data considered for power model specialization are transaction status and command type (e.g. read/write operation). In the transaction status we have added also the handling of error conditions, in order to have a better matching with the low-level system representations. In the power simulations on the NoC component, it was not possible to apply model_2, because the tasks of such component are affected only by transaction status, without dependencies on the operations that involve the connected components.InTables 4 and 5 there are reported the different code sizes and the estimation errors for each of the four components constituting the examined architecture. From the results in Table 4, moving from RTL to TL descriptions we have a reduction in modeling effort similar to the one observed in SystemC/TLM examples, with the exception of the NoC component. In this case we have a much more relevant benefit, with a code reduction superior to 60%. This result is a plain consequence of the specific capabilities of SystemC/TLM in the modeling of communication tasks, which represent the primary activity in a NoC structure.The simulation times of the whole benchmark have confirmed the speedup factors seen in SystemC/TLM examples. The TL system description can be simulated gaining about one order of magnitude in comparison to the RTL counterpart.As concerns power estimation accuracy, the data in Table 5 show some significant differences with respect to the results achieved from the SystemC/TLM examples. The foremost point is the stronger influence of TLM data in power model performances. As first observation, the estimation error is always excessive and unacceptable when we apply model_0, which does not leverage on TLM data specialization. On the other hand, the simulations with model_1 bring to discordant results. More specifically, this power model provides acceptable errors for the processor, RAM and FIR 128 component when the TLM data specialization concerns the command type. Conversely, the specialization with respect to transaction status leads to rather high errors. In the case of NoC we have an opposite situation, since model_1 provides a good accuracy when the TLM data specialization concerns transaction status.This mutable behavior can be explained through the different influence of the TLM data in the intrinsic functionalities of the components. To be more precise, the command type is the TLM data with the highest impact on the tasks carried out at run-time by processor, RAM and FIR 128. In comparison with transaction status, command type is more strongly related to the active and power-consuming tasks. For this reason, the command specialization of model_1 leads to better estimations for these components. In the case of NoC we have a different situation, because transaction status is the predominant TLM data and model_1 provides a good estimation error when specialized with respect to transaction status. To be more precise, for this component there is no dependence on command type and transaction status is the unique TLM data affecting the NoC tasks. Accordingly, the best power model specialization can be achieved only in reference to this TLM data.As expected, for all the components the best results are obtained when applying the most specialized power model (model_2 for processor, RAM and FIR 128; model_1 for NoC). In this case, we always have quite good power estimations with an estimation error around 10%. Such accuracy is at the same level of the best results observed for the SystemC/TLM demonstration examples.RTL power estimation methodologies provide a variable accuracy, depending on the applied estimation technique. With reference to typical accuracy levels, the average estimation errors may be circumscribed in a percentage range between 5% and 20%. Only advanced cycle-accurate techniques are able to provide errors below 5%. The experimental results show how our methodology, based on a transaction-accurate paradigm, can provide estimation errors in the middle between cumulative and cycle-accurate techniques. However, to address these performances, it is necessary a power model specialization with respect to the TLM data more influent in power dissipation.Finally, inTable 6 we have reported the overhead due to the application of our methodology in terms of both additional code and extra simulation time. This overhead is evaluated with respect to the basic description in which no power estimation tasks is introduced; the code size of such descriptions has been reported in the TL row of Table 4. Going from left to right, the columns 2−5 show the code added to each component to apply our methodology, i.e. the instructions to define the energy lookup-tables and the run-time querying functions. These instructions have been realized following the implementation guidelines illustrated in Section 4. The bottom values represent the percentage increments with respect to the code of basic descriptions.The rightmost column shows instead the extra-time required to simulate the whole system applying the different power model variants on each components. As previously said, the NoC component cannot be run with model1-command and model2 power model. In these cases we have then used model1-status on the NoC component.The data in Table 6 show how the application of our approach requires a limited modeling effort (below 12% in all the considered cases) and entails a very low penalty in simulation time. These results have been achieved considering properly long simulation times, consisting in the execution of more than 100.000 transactions between the components.In summary, we can conclude on the validity of the proposed methodology for transaction-level power analysis. Against accuracy analogous to RTL estimation techniques, the higher simulation speed and the lower modeling efforts denote a clear advantage in the design and analysis of complex VLSI systems.

@&#CONCLUSIONS@&#
This paper has presented a power estimation methodology applicable on transaction-level prototypes of VLSI digital systems. The proposed approach is strictly related to the modeling constructs of the SystemC/TLM language, without being restricted to specific communication modalities. These features allow a general and systematic application, with the possibility to refine the estimation accuracy through a power model specialization based on TLM data.After an introductory overview on the modeling principles of SystemC/TLM, the discussion has dealt with the conceptual aspects of the methodology and the application modalities. Finally, the results coming from an experimental verification have shown the effectiveness of the proposed approach and the design advantages in comparison with RTL estimation techniques. In particular, the power model specialization with respect to TLM data is proved to be a fundamental condition to achieve an acceptable/good estimation accuracy.