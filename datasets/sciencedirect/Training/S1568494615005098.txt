@&#MAIN-TITLE@&#
An evolutionary approach to solve a system of multiple interrelated agent problems

@&#HIGHLIGHTS@&#
We develop an evolutionary approach to solve interrelated optimisation problems.Multiple agents autonomously deal with their own problems and react to the others.Test problems in water pollution and aerospace modelling demonstrate the algorithm.Experiments on scalability and convergence of the algorithm show promising results.

@&#KEYPHRASES@&#
Agent based problems,Complementarity conditions,Evolutionary algorithm,Parallel search,

@&#ABSTRACT@&#
Deterministic approaches to simultaneously solve different interrelated optimisation problems lead to a general class of nonlinear complementarity problem (NCP). Due to differentiability and convexity requirements of the problems, sophisticated algorithms are introduced in literature. This paper develops an evolutionary algorithm to solve the NCPs. The proposed approach is a parallel search in which multiple populations representing different agents evolve simultaneously whilst in contact with each other. In this context, each agent autonomously solves its optimisation programme while sharing its decisions with the neighbouring agents and, hence, it affects their actions. The framework is applied to an environmental and an aerospace application where the obtained results are compared with those found in literature. The convergence and scalability of the approach is tested and its search algorithm performance is analysed. Results encourage the application of such an evolutionary based algorithm for complementarity problems and future work should investigate its development as well as its performance improvements.We study a class of problems in which solutions to n interrelated optimisation problems are simultaneously required. In this context, each agent solves one optimisation problem and seeks its own optimal strategies while interacting with the others. That is, each agent's problem is formed to find the best response to the decision of the interacting agents. More precisely, given a functionF:ℝn→ℝnrepresenting n agents, we findx=(x1,…,xn)∈ℝ+nby simultaneously solving the following n optimisation problems, Pi:(1)maximisexiFi(x)subject tox∈Xi.(Pi)where each agent i controls vectorxi∈ℝvi(∑i=1nvi=n) to optimise the objective function Fisubject to the constraints set Xicontainingx∈ℝ+n. The interrelation is explained as the objective function and the constraints in Pidepend on other agents’ decisions which explains that the solution to one agent's problem affects that of the others.This representation can be used to model each agent's personal interests. Given that aggregated optimisation framework seeks collective optimality, which does not necessarily comply with each agent's interest, it cannot be used to solve the aforementioned problem [1]. Deterministic approaches to simultaneously solve the above n problems lead to a system of nonlinear equations, which are formed by each agent's Karush–Kuhn–Tucker (KKT) formulation [1]. Under known conditions, the KKT satisfies necessary and sufficient condition for optimality of each problem i. However, employing the KKT depends on the properties of the function F, namely a smooth continuous function. If so, deterministic techniques generally exercise pivoting algorithm, interior point based approach, and generalised Newton method to find a feasible solution (e.g. look at [2,3]). Complementarity conditions introduced by using KKT provide insight into modelling techniques leading to a general class of nonlinear complementarity problems (NCP) used in economics [4], traffic modelling [5], robotics [6], fluid dynamics [7], and energy planning [8]. However, the non-differentiability and non-convexity of the function F make the deterministic approaches less efficient. Further, potential multimodality requires a good starting point to ensure convergence. To avoid such issues, application of global gradient-free approaches are encouraged to solve the resulting NCPs. Example of these works are decomposition based method coupled with genetic algorithm [9], orthogonal genetic algorithm within successive reformulated optimisation problem for NCP constraint satisfaction [10], and evolutionary based approach using Nikaido Isoda function mapping [11]. General agent based approaches have also been presented in literature to solve complex interrelated optimisation problems. Ouelhadj and Petrovic [12] report the application of agent based modelling in complex scheduling in dynamic environments. Cowling et al. [13] and Lau et al. [14] simulate the supply chain system with multiple independent and autonomous agents for contractor selection. Sauvageau and Frayret [15] use agent approaches to represent the paper pulp recycling supply chain. Moreover, in transportation, scheduling and planning, agent based approaches are successfully employed for optimisation of train coupling systems [16,17], for routing decision making based on local information in dynamic environment [18], for solving the dynamic scheduling problem of a distributed project with self-interested participants [19], for dealing with energy systems planning and forecasting [20] and for land usage and environmental planning [21]. Combination of operational research and agent modelling has also been implemented for developing a decision support system in supply chain coordination context [22–24].In this paper, we present an alternative approach to solve the above n problems without directly employing the KKT and NCP formulations. We employ an evolutionary algorithm which solves n interrelated optimisation problems in parallel. Section 2 explains the sharing strategies and Section 3 develops the algorithm and gives a demonstration on an illustrative example. Section 4 applies the proposed approach on two problems in environmental water pollution and fluid dynamics and discusses the results. The scalability of the method to higher dimension as well as its search algorithm performance are investigated in Section 5. Section 6 concludes the paper with extra discussion for future work.Multiple agents communicate their decision to the others and hence their problems are interrelated. This is due to the fact that each agent deals with its own problem as well as reacts to the decisions of the others within an environment (each agent finds its best response to the decisions of the others). Given this, we propose to solve such interrelated agent problems using the idea of parallel genetic algorithm (GA) [25]. Parallel GA combines the hardware speed of parallel processors and the software speed of intelligent parallel searching [26]. The idea in parallel GA is to divide the problem's search population over multiple processors, typically for performance reasons which determines multiple sub-populations with information exchange between them [27,28]. This implementation promises a substantial performance achievement and therefore leads to extensive attempts to design and improve competitive distributed hardware for effective population communication and migration as well as fitness evaluations speeding up [29–31]. Most of the algorithms in literature run identical GA in parallel with one run per processor while they differ in the linkage of the populations and the information sharing (e.g. look at [32–34]). In this paper, instead of dividing the population over multiple processors, we borrow this idea and dedicate to each agent a population to solve its problem while interacting with the others.More formally, define an agent problem i with Pi, i=1, …, n, and let Xibe a vector containing the decision variables of agent i used in problem Piand let x−ibe a vector containing the decision variables of all agents involved in problem Piexcluding that of the agent i. Further, define P the problem formed by all Pis. We use parallel GA and the idea of co-evolution [35] to solve P with an extension that each (sub-)problem Pihas its own objective function. Since there is interconnection between agents’ problems, we solve each problem whilst it communicates with the other problems by sharing information. This concept is used in [36] to gain faster convergence to Pareto solution in multiobjective optimisation problem. Formally, the search algorithm is described by n different search trajectories performing in parallel through the following linkage Hi:xit+1=Hi(x¯−it,xit,Pi),where H shows the interconnection between the agents. H acts as a synchronisation linkage for agent i to optimise problem Pigiven the decisions of other interacting agents in its neighbourhood remain fixed shown byx¯−it. H describes that Xivalue is updated by a search on problem Piat generation t linking decisions Xiandx¯−i. In fact, in problem Pi, xiis the reaction of agent i to the other agents’ decisions given byx¯−i. Due to problem Pi, each agent knows its own problem components and hence by communicating with other neighbouring agents through H, it has local activity for exploring the search space. Following Alba and Troya classification [37] and due to linkage H, our approach resembles to a fine grained topology of parallel GAs as each agent communicates with its neighbours while solving its own problem. Next, we give the details of the algorithm to solve the agents problems followed by an illustrative example.Algorithm 1 shows the step by step procedure of the proposed method when each agent involves in maximisation problem. At the beginning, the number of agents n, population size m, maximum number of generation MaxGen and convergence tolerance ϵ are specified.Each agent i has a devoted search trajectory formed by a population of size m (Line 1). popiis a m×neimatrix and is populated randomly. Agent i and its neighbours make a set of neiagents (Line 2). Each individual pkin population of agent i is composed of the decision variables of agent i and the decision variables of its neighbours being fixed, and therefore,pk=(xi,x¯−i)has the size of nei. In other words, neiequals the number of neighbouring agents affecting the decision of agent i plus one. For agents to determine their best response to the decisions of their neighbours, all individuals pkin population i undergoes a reproduction in each generation t of parallel searches (Line 8). popiis sorted in increasing order based on the objective value andpopi*, the best individual in popiis determined (Line 11 and 12). At the end of each generation t, the neighbouring agents (j∈neighboursi) share their best individuals to form the updated population for next generation t+1.popi*migrates to the population of the neighbours and remain fixed for the next generation (Line 13). This makes each agent at the end of each generation to be informed of the decisions of its neighbouring agents involved in its own problem. An example of population sharing scheme is illustrated in Fig. 1with nei=3 and three agents dealing with problem Pioptimising for Xi. Due to n different search trajectories, the algorithm allows each agent to search for its best response to its neighbours’ decisions by relying only on locally available information received from them through H. This procedure leads to the evolution of separate populations over successive generations.Algorithm 1Parallel search algorithm.For stopping criterion, we follow the work of Sinha et al. [38] and the algorithm uses a variance-based convergence indicator defined by,η=∑σVic2σVio2,whereσVic2andσVio2denotes the variances of agents i's variables in the current (c) and original (o) population, respectively. The value of η is restricted between 0 and 1 and upon convergence it is expected that this value converges to zero. Therefore, if η is less than ϵ then the algorithm terminates, otherwise, the algorithm continues until MaxGen is reached. We also take a track of the mean of population of each agent's variables in each generation to further analyse the convergence.The constraint domination technique is adopted for constraint handling [39]. The procedure ranks the feasible individuals based on their objective values while the infeasible individuals are ranked only based on their extent of constraint violation.Each agent determines its best decision as the response to the decisions of its neighbours by applying a search on its population in line 7 and 8. In this paper, differential evolution (DE) [40] is adopted for reproduction as it provides promising results on many numerical test problems [41]. Nevertheless, other search algorithm can be exploited. In DE, corresponding to each pk, three individuals ps1, ps2 and ps3 are randomly chosen from population popiand new vector pcis created by adding the weighted difference of ps2 and ps3 to the ps1 given by,pc=ps1+MR(ps2−ps3),where MR is the mutation rate. pcis accepted as a new vector pbif the following is satisfied(2)pb=pcifrand(0,1)≤CRpko.w.CR is the probability of crossover and rand is pseudo random number between 0 and 1. If vector pcviolates the bound constraints, it gets the value half way between the pkand the bound violated.Before we test the algorithm's application, we explain its implementation via a simple two agents problem as follows.To illustrate the algorithm procedure, consider two agents competing in producing a product. The benefit of each agent is given byf(xi)=(30−x1−x2)xi−cixi,where c1=6 and c2=3 represents the unit production cost incurred to agent i. The benefit of one agent depends on the amount of production of the other. Therefore, there is an interconnection between these two and therefore, ne1=ne2=2. We set n=2, m=10, ϵ=10−5 and MaxGen=100. As can be seen in Fig. 2, after initialising the population for the first generation, the best individual in pop1 represented aspop1*=22.938is fixed in the next pop2 generation andpop2*=50.259is fixed in pop1 (shown by grey and black colours, respectively). The population undergoes reproduction stage using DE and in second generation,pop1*=16.583is fixed in pop2 andpop2*=0is fixed in pop1 for third generation. The algorithm runs and the best of each population is fixed in the others in an iterative basis. This simulates a procedure in which each agent is reacting to the best action of its competitor. The competition through generation designs a learning environment which continues till both agents compromise on a solution. Fig. 2 only shows the first three individuals in each population for simplicity of presentation. The algorithm converges after 23 generations with η=10−6.In the next section, we investigate the algorithm performance for two multidisciplinary problems.We solve two problems related to environmental water pollution and fluid dynamics. The first problem involves three agents competing for water abstraction while the second one approximates the pattern of the velocity profile over an aerofoil. The first problem is taken from [42] where a deterministic algorithm is devised for obtaining the solution. The second problem, employs finite difference method for formulating the agent problems, and, to our best knowledge, has not been solved from multi-agent perspective before in literature.In both problems, the population size for each agent is m=50, the maximum number of generation is MaxGen=100 and following Price et al. [40], MR and CR values used within DE equal 0.7 and 0.5, respectively. The convergence is assumed with tolerance of less than ϵ=10−5.In this problem, three firms i=1, 2, 3, are located along a river, abstracting water to produce paper pulp at a chosen level Xi. Due to paper production, the firms also produce one pollutant, eixi, i=1, 2, 3, with eibeing the emission coefficient of firm i (Table 1). The pollution is expelled into the river and reaches two monitoring stations l located along the river where local authority sets the maximum pollutant concentration levels Kl. The following constraints at each location l is then defined as:ql(x)=∑i=13δileixi≤Kl,l=1,2,where δilis the decay-and-transportation coefficient from firm i to location l (Table 1). Each firm is engaged in net profit maximisation equivalent to the following optimisation problems for firmi, i=1, 2, 3:(3)maxxifi=Ri−Cisubject toql(x)≤Kll=1,2.where the revenue and cost functions for each firm areRi=(d1−d2(x1+x2+x3))xi,Ci=(c1i+c2ixi)xii=1,2,3,respectively, with economic constants d1=3.0 and d2=0.01. The cost function coefficients c1 and c2 are given in Table 1 and Kl=100, l=1, 2 for this study.The objective functions represents the gross benefit of each firm in participating in paper pulp production. The complementarity condition essentially state that at an equilibrium solution, marginal revenue must be equal to marginal cost for each firm abstracting a positive quantity of water, and that marginal revenue should not exceed marginal cost for firms which prefer not to be in business.Due to Rifunction, the decision of each firm depends on the other two and hence, nei=3 for i=1, 2, 3. The pollution constraints qlis handled using domination technique; (a) the feasible solutions are always preferred, (b) between any two feasible solutions, the one with higher gross benefit is preferred, and (c) between any two infeasible solutions, the one which less violates the pollutant constraint is favoured.The parallel search is constructed for three agents and the results of its application is shown in Table 2. The solution is consistent with the one obtained using deterministic approach reported by Krawczyk [42]. To show the convergence rate of the algorithm, we provide the mean of water abstraction for each agent in Fig. 3as well as the η value against the algorithm generation. The figures illustrate the firms competition over water abstractions during the population evolution. At the initial generations, since one firm gain leads to others loss, there is an oscillating behaviour to reach equilibrium further down the generation. The convergence is quite fast and as can be seen in the figure, after only 10 generation the firms compromise on a solution while the algorithm tunes the solution afterwards. The approach can be employed for bigger problems where large number of firms compete for water abstraction with different institutional and quality constraints.To further demonstrate the algorithm, we alter the production cost Cito the non-differentiable and non-convex fixed-cost function,(4)Ci=c1i+c2ixixi>00xi=0.and solve problem 2 with no constraint. The introduction of the above function reduces the applicability of the deterministic approaches with convexity and differentiability assumptions [4]. Employing the proposed method, the algorithm converges to x=(75.7, 71.7, 75.7) after 90 generations.In this problem we study the behaviour of the algorithm when it is applied to a fluid dynamic application. We solve the laminar flow around the leading edge of a symmetrical aerofoil, NACA 0015, with zero angle of attack, chord length c=32cm and tmax/2=2.4cm. The characteristics of this aerofoil are documented by Abbott and Doenhoff [43] and it exhibits well-behaved laminar flow around leading edge at low angles of attack. We consider the flow to be two-dimensional incompressible fluid defining a constant density of the fluid. Near low angle of attack, which results in zero lift, a steady flow past the aerofoil has the same pattern on upper and lower surfaces, except for a narrow boundary layer region close to the surface where the flow is retarded by friction. The resultant simplified Navier-Stokes equations for a steady, two-dimensional and incompressible flow can be found in [44]. In practice, by applying the potential flow theory, we can find the velocity profiles of the outer flow field of an aerofoil [44]. The subject of current study is to, from the multi-agent perspective, approximate the pattern of such velocity profiles passing from the leading edge of the aerofoil ignoring the boundary layer effect. Due to impermeability condition of the plate surface, velocity on the surface is zero and the gradient of velocity equals zero anywhere else in y-direction. These conditions give rise to the following complementarity problem:(5)∇x(x−s)=0,x≥s≥0where x is velocity profile and s is the leading edge of the NACA 0015 aerofoil. To obtain the pattern of the velocity profile x using the proposed parallel search, we approximate x in five different locations (a–e) on the surface s. Employing finite difference method on a mesh with step size H, gradient function approximation, ∇, leads to the following set of equations for each location(6)xi−1−xih(xi−s(yi))=0,∀i=1,…,n−1.where n is the number of nodes used to approximate Xiat coordinates yi. If each node i is considered as an agent communicating its value to its neighbouring node due to xi−1−xi, the problem of velocity profile approximation is a multi-agent system with the following problem for each agent i,(7)minxifi=xi−1−xih(xi−s(yi))subject toxi≥si≥0.If fiapproaches to its minimum value of zero, then the complementarity condition holds as either (xi−1−xi)/h=0 or (xi−s(yi))=0 or both: velocity on the surface is zero and the gradient of velocity equals zero anywhere else in y-direction. To employ the parallel search, since n is the number of nodes used to approximate x, n agent problems are solved in five different locations (a–e) of the leading edge surface s shown in Fig. 4.To solve the problem, we consider n=10 nodes for approximation, and set h=n to account for a regular mesh with nei=3 to show that each node is communicating with other two neighbours. The convergence can be analysed by looking at Fig. 4. Fig. 4(a) shows the pattern of the velocity profiles on the leading edge on five different locations. Since the distance around either side of the aerofoil is the same, the average velocity above the aerofoil is the same as beneath it. So, we expect to see a similar flow profile both sides of the aerofoil. The variance-based metric in Fig. 4(b) and (c) implies a pretty fast convergence after only 25 iterations explaining that each black circle point in location b shown in Fig. 4(a) communicates its position with the neighbours before convergence.As opposed to population based methods, where the number of population grows as the dimension of the problem increases, the ability to scale up the performance is not a challenge for deterministic algorithms where mostly gradient search approaches are employed. Therefore, to test the scalability of the proposed population based algorithm in higher dimension problems, we use the velocity profile approximation problem and solve it for n=5, 10, 20, 30, 40 and n=50 nodes (agents). To account for variability of each run, we solve each problem 30 times and the results presented are averaged over 30 runs. We report the average number of generations to reach the convergence tolerance of less than ϵ=10−5 as well as the average time taken for convergence. The scalability Fig. 5(a) suggests a mild exponential trend in computational burden as the number of nodes (agents) increases. While for n=5, 0.5 seconds takes on average to solve the problem with average number of 17 generations, the average running time for n=50 reaches up to 22 seconds with number of 104 generations. Fig. 5(b) presents the same situation as the one illustrated in Fig. 4(a). Fig. 5(b) indicates that at n=50, the accuracy of the approximation is increased (compared with n=10 in Fig. 4a) which leads to higher computational time for convergence (Fig. 5d).We report the performance of the proposed approach on the above velocity profile approximation problem when the DE search algorithm is replaced by simple genetic algorithm (GA), genetic algorithm with elitism (GA-E) [45] and covariance matrix adaptation evolution strategy (CMA-ES) [46]. In GA and GA-E, we use roulette wheel selection, a mutation rate of 0.2 and population size of 10. In each generation of CMA-ES, new candidate solutions are sampled from the population size of 10 according to a multivariate normal distribution where a weighted combination of the μ=2 best out of λ=4 new candidates is used to update the distribution parameters. The reader is referred to the provided references for details of these algorithms. We note that Simple GA, GA-E, CMA-ES and DE are only the operators each agent use to solve their own problem as a result of communicating with neighbouring agents via linkage H. We let n=10 and run the algorithm for 50 generations. We use η value as the performance metric to study the convergence characteristics. Fig. 6shows the convergence behaviour of these four algorithms. As can be seen, all search operators get close to the solution. While DE and CMA-ES converged within 50 runs, it seems that the GA and GA-E requires more than 50 runs before they converge. DE and CMA-ES have smoother convergence behaviour than GA and GA-E do and the quick drop of the sum of the average of population of each agent's variables in each generation is an indication that the convergence was indeed fast.In this paper, we have developed an evolutionary approach to solve n optimisation problems simultaneously. This type of representation is used to model engineering and economic problems. The problem can be as simple as solving a system of equations or as hard as a nonlinear combinatorial problem depending on the properties of the involved functions. We have built upon parallel genetic algorithm where separate populations for different agents are simultaneously evolved, each dealing with its own optimisation problem. Agents have partial information about the whole model and, in each generation, they synchronise their best fitted individual in the population with their neighbours. This keeps each agent aware of the other agents’ decisions and in contact with the whole system. The procedure guides the search towards a compromised solution. The algorithm is illustrated on a simple two-agent problem and its performance is tested on two multidisciplinary problems, namely on environmental water pollution and fluid dynamics, and the results demonstrate the applicability of the proposed technique to low and high dimension problems. We have investigated the performance of the approach when four different population based methods are used as the sub-problem search algorithm. The study suggests that different algorithms can be exploited for each agent to solve its own problem.In this study agents consider their interest in solving their local problem while interacting with each other. The applicability of the technique should be further elaborated when agents cooperates to solve a global problem. In addition, the parallel nature of the algorithm can motivate further research on designing a distributed architecture for implementation of the algorithm on multiple cores and threads synchronisations.This framework can be extended to consider different problems in water market – where different users are trading water rights [47–49,53] in a resource constrained environment – and in plasma actuator study – where the velocity profiles induced by dielectric barrier discharge plasma actuator are necessary to be represented [50–52,54].

@&#INTRODUCTION@&#


@&#CONCLUSIONS@&#
