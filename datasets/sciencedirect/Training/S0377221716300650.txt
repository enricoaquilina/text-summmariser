@&#MAIN-TITLE@&#
Scheduling under linear constraints

@&#HIGHLIGHTS@&#
We study scheduling problems where the processing times are also decision variables.We consider the case where the processing times must satisfy some linear constraints.We investigate the computational complexity of such problems under various settings.We propose algorithms/approximation algorithms for such problems.This seemingly harder problem could be easier than the NP-Hard scheduling problem.

@&#KEYPHRASES@&#
Parallel machine scheduling,Linear programming,Computational complexity,Approximation algorithm,

@&#ABSTRACT@&#
We introduce a parallel machine scheduling problem in which the processing times of jobs are not given in advance but are determined by a system of linear constraints. The objective is to minimize the makespan, i.e., the maximum job completion time among all feasible choices. This novel problem is motivated by various real-world application scenarios. We discuss the computational complexity and algorithms for various settings of this problem. In particular, we show that if there is only one machine with an arbitrary number of linear constraints, or there is an arbitrary number of machines with no more than two linear constraints, or both the number of machines and the number of linear constraints are fixed constants, then the problem is polynomial-time solvable via solving a series of linear programming problems. If both the number of machines and the number of constraints are inputs of the problem instance, then the problem is NP-Hard. We further propose several approximation algorithms for the latter case.

@&#INTRODUCTION@&#
A scheduling problem aims to allocate resources to jobs, so as to meet a specific objective, e.g., to minimize the makespan or the total completion time. One common assumption in the classical scheduling problem is that the processing times of jobs are deterministic and are given in advance. However, in practice, the processing times are usually uncertain/unknown or could be part of the decisions. A number of works in the literature have proposed various scheduling models in which the processing times are uncertain/unknown, such as the stochastic scheduling problem (Dean, 2005; Möhring, Radermacher, & Weiss, 1984; Möhring, Schulz, & Uetz, 1999) and the robust scheduling problem (Daniels & Kouvelis, 1995; Kasperski, 2005; Kasperski & Zielinski, 2008). In the stochastic scheduling problem, it is assumed that the processing times are random variables and the expected makespan is considered. In the robust scheduling problem, it is assumed that the processing time of each job belongs to a certain set and the objective is to find a robust schedule under some performance criterion (e.g., minimize the maximum absolute deviation of total completion time, or the total lateness). Note that in either the stochastic or the robust scheduling problems, the processing times are still exogenously given.In the presented paper, we introduce a new scheduling model. In our model, the processing times of jobs are not exogenously given, instead they can be chosen as part of the decisions, but they must satisfy a set of linear constraints. We call this problem the “scheduling under linear constraints” (SLC) problem. Note that the SLC problem reduces to the classical parallel machine scheduling problem P||Cmax  when the processing times of jobs are given (or equivalently, when the linear constraints have a unique solution). This problem is related to the scheduling problem with controllable processing times studied in the literature (Nowicki & Zdrzalka, 1988, 1990; Shabtay & Steiner, 2007). In the latter problem, the processing times of jobs are controlled by factors such as the starting times and the sequence of the jobs, while in our problem, the processing times are part of the decision variables.The SLC problem is also related to the lot sizing and scheduling problem in production planning, which decides the type and amount of jobs to process at each time period over a time horizon (Drexl & Haase, 1995; Drexl & Kimms, 1997; Haase, 1994). However, although these two problems may share some similar backgrounds, they are different in many ways: (1) In the SLC problem, each task must be completed in a consecutive time interval and can only be chosen once, while in the lot sizing and scheduling problem, an activity (e.g., the production of certain type of products) can be scheduled in multiple non-consecutive periods; (2) The objective of the lot sizing and scheduling problem is to minimize the total costs, including the setup costs, the inventory holding costs, etc, which is significantly different from the objective of the SLC problem (Kreipl & Pinedo, 2004), which is to minimize the makespan of the schedule; (3) Due to the difference in the objective, the key tradeoff in these two problems are different. In the SLC problem, the main consideration is how to balance the workload of each machine, and assign the jobs evenly across machines. In contrast, the key consideration in the lot sizing and scheduling problem is how to divide the jobs and schedule them (e.g., how many units of products to produce in each use of the machine), which is more similar to that in an EOQ model (see Snyder & Shen, 2011); (4) As we will see later, the mathematical programming formulation for the SLC problem is a mixed integer quadratic program, while the common formulation for the lot sizing and scheduling problem is a mixed integer program (e.g., see Drexl and Haase, 1995, page 75). Therefore, the methodologies and research approaches are also different.In the following, we provide a few examples that motivate the study of the SLC problem.1.Industrial production problem. Perhaps the earliest motivation for the scheduling problem came from manufacturing (e.g., see Pinedo, 2009, 2012). Suppose a manufacturer requires certain amounts of different raw metals, and he needs to extract them from several alloys. There are several machines that can extract the alloys in parallel. We focus on the procedure of extracting the alloys, of which the goal is to finish as early as possible. In this problem, the processing times of extracting each alloy depend on the processing quantities, and traditionally, they are predetermined in advance. However, in practice, those quantities are determined by the demands of the raw metals and can be solved as a feasible solution to a blending problem (Danø, 1960; Eiselt & Sandblom, 2007). Sometimes, each alloy also has its own maximum quantity. An example of such a scenario is given in Table 1.In the example shown in Table 1, the demand of iron is 56, and each unit of alloy 1 contains 24 units of iron, each unit of alloy 2 contains 8 units of iron, etc. Let xibe the quantity of alloy i to be extracted. Then the requirement on the demand of iron can be represented as a linear inequality24x1+8x2+3x3+⋯+2xn≥56. Furthermore, the maximum amount of alloy 1 available is 10, which can be represented as a linear inequality x1 ≤ 10. Similarly, we can write linear constraints for the demand of other metals and the quantity for other alloys. In this problem, the decision maker needs to determine the nonnegative job quantitiesx1,…,xnsatisfying the above linear constraints, and then assign these jobs to the parallel machines such that the last completion time is minimized. This problem can be viewed as a minimum makespan parallel machine scheduling problem, where the processing times of jobs satisfy some linear constraints.Advertising media selection problem. A company has several parallel broadcast platforms which can broadcast advertisements simultaneously, such as multiple screens in a shopping mall or different spots on a website. There is a customer who wants to broadcast his advertisements (ad1,…,n) on these platforms.11This example can be easily extended to cases with multiple customers.It is required that each individual advertisement must be broadcast without interruption and the running time of each advertisement has to satisfy some linear constraints. The company needs to decide the running times xiallocated to each advertisement i, and also which advertisement should be released on which platform as well as the releasing order. The objective is to minimize the completion time. An example of such a problem is given in Table 2.Similar to the first example, the above-described problem can be naturally formulated as a minimum makespan parallel machine scheduling problem in which the parameters (running times of the advertisements) are determined by a system of linear constraints.Transportation problem. Both linear programming and machine scheduling problems have extensive applications in the field of transportation management (Eiselt & Sandblom, 2007; Pinedo, 2009, 2012). The parallel machine scheduling problem has many similarities with the transportation scheduling models. For example, a fleet of tankers or a number of workers can be considered as a parallel machine environment, and transporting or handling cargo is analogous to processing a job (Pinedo, 2009). Meanwhile, the transportation problem can be formulated as a linear program. Let xijbe the capacity of cargo that needs to be transported from origin i to destination j. They often have to satisfy certain supply and demand constraints, which are usually linear constraints.In practice, the decision maker decides how to assign cargo (jobs) to tankers or workers (parallel processors), so as to finish the handling as quickly as possible. This is a parallel machine scheduling problem. And the processing times usually depend on xijs, which have to satisfy some linear constraints as mentioned above. This also leads to a parallel machine scheduling problem with linear constraints.In this paper, we study the SLC problem, discussing the computational complexity and algorithms for this problem under various settings. In particular, we show that if there is only one machine with an arbitrary number of linear constraints, or there is an arbitrary number of machines with no more than two linear constraints, or both the number of machines and the number of linear constraints are fixed constants, then the problem is polynomial-time solvable via solving a series of linear programming problems. If both the number of machines and the number of constraints are inputs of the problem instance, then the problem is NP-Hard. We further propose several approximation algorithms for the latter case. We summarize our results in Table 3. In Table 3, the parameters n, m, k stand for the number of jobs, machines and constraints, respectively. The upper line in each cell indicates the computational complexity of the problem, where P refers to polynomial-time solvable and Unknown refers to complexity unknown; the lower line indicates the running time if the problem is polynomial-time solvable, or the performance ratios of our approximation algorithms if it is NP-Hard. The superscripts indicate the section where the corresponding result appears. The parameter L is the input size of the problem and K is a value depending on k and m whose explicit expression will be given in Section 5.2.One interesting conclusion from our result is that although parallel machine scheduling is in general an intractable problem, a seemingly more complicated problem — parallel machine scheduling with linear constraints — can be simpler and tractable in many cases. This suggests that instead of finding a feasible solution to the linear constraints and then assigning it to the machines, a decision maker should consider them jointly. In other words, it is often beneficial to consider the problem with a big-picture perspective.The remainder of the paper is organized as follows: In Section 2, we formally state the problem studied in this paper and briefly review some existing results. We study the simplest case in which there is only one machine or one constraint in Section 3. In Section 4, we consider the case with at least two but still a fixed number of machines. In Section 5, we investigate the case where the number of machines is an input of the instance. Finally, some concluding remarks are provided in Section 6.The scheduling problem under linear constraints is formally defined as below:Definition 1Given m identical machines and n jobs. The processing times of the jobs are nonnegative and satisfy k linear inequalities. The goal of the scheduling problem under linear constraints (SLC) is to determine the processing times of the jobs such that they satisfy the linear constraints and to assign the jobs to the machines to minimize the makespan.Formally, let xibe the processing time of job i. The processing timesx=(x1,…,xn)should satisfy(1)Ax≥b,x≥0,whereA∈Rk×nandb∈Rk×1.Parallel machine scheduling with the objective of minimizing the makespan is one of the most basic models in various scheduling problems (e.g., see Chen, Potts, & Woeginger, 1998). This problem is NP-Hard even if there are only two machines, and it is strongly NP-Hard when the number of machines is an input of the instance (Gary & Johnson, 1979). On the algorithmic side, Graham (1966) proposed a(2−1m)-approximation algorithm for parallel machine scheduling with m machines. This method, known as the list scheduling (LS) rule, is in fact one of the earliest approximation algorithms. Later, Graham (1969) presented the longest processing time (LPT) rule with an approximation ratio of(43−13m)and a polynomial-time approximation scheme (PTAS) when the number of machines is fixed. For the case of a fixed number of machines, Sahni (1976) further proposed a fully polynomial-time approximation scheme (FPTAS). When the number of machines is an input, Hochbaum and Shmoys (1987) showed that a PTAS exists.At first sight, the SLC problem can be formulated as the following optimization problem:mints.t.∑j=1myij=1∀i=1,…,n∑i=1nxiyij≤t∀j=1,…,mAx≥bx,t≥0yij∈{0,1}∀i,j,whereyij=1indicates that job i is assigned to machine j. This can be viewed as a nonconvex mixed integer (binary) quadratic programming problem (Burer & Letchford, 2012; Köppe, 2011) or a mixed integer (binary) bilinear programming problem (Adams & Sherali, 1993; Gupte, Ahmed, Cheon, & Dey, 2013). In general, such problems are NP-Hard and extremely hard to solve. In fact, it is unknown whether the mixed integer quadratic programming problem lies in NP (Burer & Letchford, 2012; Jeroslow, 1973). However, with the special structure of the problem, we will show that several cases of the SLC problem can be solved in polynomial time or approximated within a constant factor.If there is only one machine, then the classical parallel machine scheduling problem becomes trivial since the makespan is simply the total processing time. For the SLC problem, it is equivalent to solving the following linear program:(LP1)min∑i=1nxis.t.Ax≥bx≥0.Therefore, we have the following conclusion. We refer the readers to Ye (1997) for the complexity of the interior point methods.Theorem 1The SLC problem with a single machine can be solved in polynomial time, in particular, inO((n+k)3L)time by the interior point methods, where L is the size of input length.In this subsection, we study the SLC problem with only one constraint, that is,k=1and A is a 1 × n matrix. In this case, the linear constraints can be written as∑i=1naixi≥b,x≥0.Without loss of generality, we assume that a1 ≥ a2 ≥ ⋅⋅⋅ ≥ anand b ≥ 0. If all aiare nonpositive, then this problem is trivial (allxi=0ifb=0,or infeasible if b > 0). Therefore, we assume that there is at least one ai> 0. We definen′=min{max{i|ai>0},m},where m is the number of machines, andσ=∑i=1n′ai. We have the following result:Theorem 2For the SLC problem with one constraint, the optimal decisions arex1=⋯=xn′=b/σandxi=0otherwise, and the optimal makespan is b/σ.Proof. Consider the following linear program:(LP2)mints.t.∑i=1naixi≥b∑i=1nxi≤mtxi≤t∀i=1,…,nx,t≥0.Note that (LP2) can be viewed as a relaxation of the SLC problem, since any optimal solution to the SLC problem is feasible to (LP2) by choosingxas the processing times and t as its makespan. Suppose we have an optimal solution (x, t) to (LP2). If it is also feasible to the SLC problem, that is, the jobs have processing timesxand can be assigned to the m machines with makespan at most t, then it must also be optimal to the SLC problem.The dual problem of (LP2) is(DP2)maxbus.t.aiu−yi−v≤0∀i=1,…,n∑i=1nyi+mv≤1u,v,y≥0.Letxi=b/σfori=1,…,n′andxi=0otherwise, andt=b/σbe a primal solution. If n′ < m, then letu=1/σ,v=0,yi=ai/σfori=1,…,n′andyi=0otherwise be a dual solution; ifn′=m,letu=1/σ,v=am/σ,yi=(ai−am)/σfori=1,…,mandyi=0otherwise be a dual solution. In either case, we can verify that (x, t) and (u, v,y) are both feasible and have the same objective values. Consequently, (x, t) is an optimal solution to (LP2). Since n′ ≤ m and all the jobs have processing times eithert=b/σor 0, we can see that (x, t) is feasible to the SLC problem, and hence it is optimal.□In this section, we discuss the case where the number of machines m is at least two but is still a fixed constant. We consider two further cases: when the number of constraints is also fixed and when the number of constraints is an input of an instance.We show that when both m and k are at least two but are still fixed constants, the SLC problem is polynomial-time solvable. First, we prove the following property of the SLC problem:Lemma 1The SLC problem has an optimal solution in which at mostm+k−1jobs have nonzero processing times.We prove that given any optimal solution to the SLC problem, we can find an optimal solution that satisfies the desired property. To show this, suppose we have an optimal solution to the SLC problem in which Ilis the set of jobs that are assigned to machine l. We construct the following linear program:(LP3)mints.t.Ax≥b∑i∈Ilxi≤t∀l=1,…,mx,t≥0.It can be seen that any optimal solution to (LP3) is optimal to the SLC problem. Note that there are totallym+klinear constraints (except for the nonnegative constraints) in (LP3), therefore each of its basic feasible solutions has at mostm+knonzero entries. Now consider the variable t in any basic feasible solution. Ift=0,then all the processing times are zero and the lemma holds. Otherwise, there are at mostm+k−1nonzero xis in this basic feasible solution. This implies that there exists an optimal solution which has at mostm+k−1nonzero processing times and thus the lemma holds.□By Lemma 1, there exists an optimal solution that contains a constant number of nonzero processing times. In view of this, we can find the optimal solution by enumeration. Our approach is to first enumerate all the nonzero processing time jobs and fix their assignments. Then we solve (LP3) to find the best processing times. We denote J as the job set and state the details of this procedure in Algorithm 1:Theorem 3Algorithm 1returns an optimal solution to the SLC problem and its computational complexity isO(nm+k−1L).The optimality follows from Lemma 1, and the fact that there must be an assignment in the enumeration which is identical to the assignment in the true optimal solution. Then when one solves (LP3) with that assignment, an optimal solution will be obtained.Now we study the total running time of Algorithm 1. There are at mostO((nm+k−1)(m+k−1)m)=O(nm+k−1)cases in the enumeration algorithm. In each case, we need to solve one linear program (LP3), which hasm+kvariables (m+k−1forxand 1 for t) and the same number of constraints. The running time for solving the linear program isO((m+k)3L). Therefore, in total, Algorithm 1 requiresO(nm+k−1(m+k)3L)=O(nm+k−1L)operations.□We close this subsection by considering the simple cases wherem=1andk=2. In Section 3.1, we show that these cases can be solved in O(n3L) time via solving the linear program (LP1). Notice that using the enumeration algorithm above, the worst-case running time in this case can be improved to O(n2L).Now we consider the case in which the number of constraints k is also an input in the problem. In this case, it is easy to see that the classical parallel machine scheduling problem is a special case of the SLC problem, as we can set A in (1) to be an identity matrix andbto be the predetermined processing times of the jobs. Therefore, the hardness result for the parallel machine scheduling problem also stands for the SLC problem, i.e., the SLC problem is NP-Hard when the number of machines is fixed and is strongly NP-Hard when the number of machines is an input (Gary & Johnson, 1979). In the following, we focus on designing approximation algorithms for this case.We first design a PTAS for the case where the number of machines is fixed and the number of constraints is an input. The result is based on guessing the optimal values of the large jobs and the PTAS for the parallel machine scheduling problem with a fixed number of machines by Graham (1969).Before describing our algorithm, we define P to be the optimal value of the following linear program:min∑i=1nxis.t.Ax≥bx≥0.Apparently, P is an upper bound and P/m is a lower bound of the optimal makespan to the SLC problem. In addition, P is polynomial in the input sizes, n and k. We use ⌈x⌉ to denote the smallest integer that is greater than or equal to x. The PTAS for this case is described in Algorithm 2.Theorem 4Algorithm 2is a PTAS for the SLC problem when the number of constraints k is an input of the instance, and the number of machines m is a fixed constant.First we calculate the computational complexity of Algorithm 2. Fixing ϵ, Step 3 requires(nh)enumerations. Note that(1+ϵ)l−2ϵP/m<P,thusl<logmϵ/log(1+ϵ)+2≤2ϵlogmϵ+2,where the last inequality follows from the fact thatlog(1+ϵ)≥ϵ/2when 0 < ϵ < 1. Therefore, the number of iterations in Step 4 islh≤(2ϵlogmϵ+2)h,which is polynomially bounded by the input size. In each iteration, solving the linear program (LP4) requiresO((n+k)3L)operations. The number of iterations in Step 9 is O(mh) and the list scheduling requires O(nlog m) time. By the fact that m and ϵ are fixed constants, the total running time is polynomial time.Now we prove that the returned schedule has a makespan no larger than1+ϵof the optimal makespan. Letx* andCmax*be the processing times and the makespan of the true optimal solution, respectively. We consider the iteration in Algorithm 2 in which the jobs of Jhare exactly the h largest jobs in the optimal schedule, the valuexi*falls in [Qi, Pi] for each i ∈ Jh, and the assignment of jobs in Jh∖J0 is the same as those of the optimal solution, where J0 are the jobs in Jhwhich have processing times in[T0,T1]=[0,ϵP/m].In this iteration, the linear program must be feasible asx* is a feasible solution to (LP4). Denote the processing times and the makespan returned in this iteration byxand Cmax , respectively. We study the last completed job j of the schedule. First, suppose that j is in Jh∖J0. Consider the schedule in which we keep only the jobs in Jh∖J0, and the jobs are assigned to the same machines as the optimal schedule. We denoteCx*and Cxas the makespans of the above schedule with processing timesx* andxrespectively. Notice thatxi≤(1+ϵ)xi*for all i ∈ Jh∖J0 by the third set of constraints of (LP4), thereforeCx≤(1+ϵ)Cx*. By Step 9 of the algorithm, the last completed job j ∈ Jh∖J0 implies that the machine that job j is assigned to only contains jobs in Jh∖J0. Therefore,Cmax=Cxin this case and it follows thatCmax=Cx≤(1+ϵ)Cx*≤(1+ϵ)Cmax*.Next we consider the case in which the last completed job j is in J0 ∪ Jr. There are two further cases. If j ∈ J0, then we havexj≤ϵP/m≤ϵCmax*≤mϵm−1Cmax*,since P/m is a lower bound of the optimal makespan to the problem. If j ∈ Jr, then since j is not one of the largest h jobs, we must havexj≤1h∑i=1nxi. And sincex* is feasible to (LP4) andxis the optimal solution to (LP4), it follows thatxj≤1h∑i=1nxi≤1h∑i=1nxi*≤mhCmax*≤mϵm−1Cmax*.Therefore,xj≤mϵm−1Cmax*for all job j in J0 ∪ Jr.Then since the jobs in J0 ∪ Jrare scheduled by list scheduling, we haveCmax≤1m∑i=1nxi+(1−1m)xj≤1m∑i=1nxi*+(1−1m)xj≤(1+ϵ)Cmax*where the first inequality is because j is the last job in the schedule and we used the list scheduling rule, the second inequality is because xis are optimal to (LP4) in that iteration, and the last inequality is becausexj≤mϵm−1Cmax*as discussed above.Finally, note that the makespan returned by Algorithm 2 cannot be worse than this schedule, thus Theorem 4 holds.□In this section, we discuss the case where the number of machines is an input. We first consider the case where there are two constraints, and then look at the case with more than two constraints.In this section, we demonstrate that when there are only two constraints, the SLC problem can be solved in polynomial time even if the number of machines is an input of the instance. We start from the following linear program, which is similar to (LP2):(LP5)mints.t.∑i=1na1ixi≥b1∑i=1na2ixi≥b2∑i=1nxi≤mtxi≤t∀i=1,…,nx,t≥0.Next, we show that all basic feasible solutions of (LP5) are feasible to the SLC problem. Then since any optimal solution to the SLC problem is feasible to (LP5) by choosing t as its makespan, we know that the optimal basic feasible solution to (LP5) must also be an optimal solution to the SLC problem. We start from the following lemma:Lemma 2In any basic feasible solution of (LP5), there are at most two variables inxsatisfying 0 < xi< t. And it must be one of the following cases: (a) exactly m variables inxsatisfyingxi=twith all otherxi=0; (b) exactlym−1variables inxsatisfyingxi=t,and at most two variables inxsatisfying 0 < xi< t with sum at most t; or (c) no more thanm−2variables inxsatisfyingxi=t,and at most two variables inxsatisfying 0 < xi< t.Ift=0,then the lemma trivially holds. Otherwise, we count the number of nonzero variables in the basic feasible solution. We add a slack variable zito the constraint xi≤ t so that it is represented asxi+zi=t,∀i=1,…,n. For any fixed i, ifxi=0orxi=t,then the number of nonzeros (among xiand zi) in the equalityxi+zi=tis exactly one, otherwise it is two. However, since there aren+3constraints in total, there are at mostn+3nonzero entries in a basic feasible solution of which at mostn+2are in xiand zi. Therefore, for any basic feasible solution, there can only be at most two indicesi∈{1,…,n}such that 0 < xi< t. The remainder of the lemma follows immediately.□Lemma 2 can be used directly to obtain an algorithm for the SLC problem. We describe it as the LP-based algorithm (Algorithm 3). Notice that in Step 3 of Algorithm 3, Lemma 2 guarantees that the sum of the processing times of the remaining jobs (at most two) is at most t if there is only one idle machine. Therefore, the returned schedule is feasible and the makespan is t, the optimal value of (LP5). Thus, we find an optimal solution to the SLC problem.The main computation in Algorithm 3 is to find an optimal basic feasible solution. In Korte and Vygen (2012) (Theorem 4.16), a technique is introduced to transform a feasible solution in a linear program to a basic feasible solution by eliminating the inequality constraints one by one, and in each round, it solves a linear program, which requires O(n3L) operations. Thus the total running time of Algorithm 3 is O(n4L).Theorem 5The SLC problem with arbitrary machines andk=2constraints can be solved in O(n4L) by the LP-based algorithm.Note that the LP-based algorithm can also be applied if the number of machines is fixed. When the number of machines is large, the performance of the LP-based algorithm is better than the enumeration algorithm we presented in Theorem 3, which requiresO(nm+1L)operations.As mentioned in the previous section, the SLC problem is strongly NP-Hard if the number of constraints is an input of the instance. In this section, we design two approximation algorithms for this case. The first one is derived from the property of parallel machine scheduling problems, and the other one is based on the technique of linear programming. Notice that the approximation algorithms can also be applied to the case where the number of constraints is fixed and greater than two, however, the complexity of that case remains unknown.First, we design a simple approximation algorithm by adapting the well-known list scheduling rule (Graham, 1966). We first decide the processing times by solving a specific linear program, and then schedule the jobs via the list scheduling rule. The details are given in Algorithm 4.We prove that the modified list scheduling algorithm has the same approximation ratio for the SLC problem as for the classical parallel machine scheduling problem.Theorem 6The modified list scheduling algorithm is a (2−1m)-approximation algorithm for the SLC problem.The running time for solving the linear program isO((n+k)3L),and for list scheduling is O(nlog m). Therefore the total running time isO((n+k)3L+nlogm),which is polynomial in the input size.Letx*,xmax*andCmax*be the processing times, the maximum of the processing times and the makespan of an optimal schedule, respectively. Letx, xmax , and Cmax  be those returned by Algorithm 4. Consider the last completed job j. By the list scheduling rule, we haveCmax≤1m∑i=1nxi+(1−1m)xj≤1m∑i=1nxi+(1−1m)xmax≤1m∑i=1nxi*+(1−1m)xmax*≤(2−1m)Cmax*.The second last inequality holds since the linear program (LP6) returns the minimum value of such an objective function. And this bound is tight from the tight example of the list scheduling rule for the classical problem.□The second approximation algorithm is based on the idea presented in Section 5.1. However, it is not clear how to directly extend (LP5) to obtain an optimal solution in polynomial time. To see this, consider a simple example withn=4,m=3,andk=3,and the constraints arex1+x2=x1+x3=x1+x4=5. If we try to generalize (LP5), we will get the following linear program:mints.t.x1+x2=x1+x3=x1+x4=5x1+x2+x3+x4≤3t0≤x1,x2,x3,x4≤t.It can be verified that the unique optimal solution to this linear program is(x1,x2,x3,x4,t)=(3,2,2,2,3). However, the jobs with processing times x2, x3, x4 can not be assigned to the two remaining machines with makespan not exceeding three. Therefore, (LP5) may not give a feasible solution to the SLC problem in this case. In the following, we modify it to derive an approximation algorithm.We consider the following linear program:(LP7)mints.t.Ax≥b∑i=1nxi≤(m−K)txi≤t∀i=1,…,nx≥0,where K is defined as:K={m−kk+1−m,ifk˜>m,max(⌈k˜⌉−kk+1−⌈k˜⌉,⌊k˜⌋−kk+1−⌊k˜⌋),ifk˜≤m,wherek˜=k+1−kand ⌊x⌋ is the largest integer that is less than or equal to x.Notice thatK=0fork=1,2and 0 < K ≤ min {m, k} for k ≥ 3 (see Table 4for various values of K), and K is a rational number since k and m are integers. Whenk=2,(LP7) reduces to (LP5), as considered in Section 5.1. If k ≥ 3, however, the optimal solution to the SLC problem may not be feasible to this linear program. Therefore, the optimal solution to (LP7) may not be an optimal solution to the SLC problem. Nevertheless, we prove that the optimal solution to (LP7) is still feasible and has an objective value no larger than a factor of the optimal makespan.Similar to the case wherek=2,we have the following property:Lemma 3There are at most k variables inxsatisfying 0 < xi< t for any basic feasible solution of the linear program (LP7).We omit the proof which is analogous to that of Lemma 2.Lemma 4For each basic feasible solution of the linear program (LP7) with t > 0, if it has exactly l variable(s) inxsatisfyingxi=t,wherel∈{m−⌈K⌉,m−⌈K⌉−1,…,max{m−k,0}},then it has additionally at most k variables inxwith each processing time 0 < xi< t and their total processing time is at mostkk+1−m+lt.Notice that there are at mostm−⌈K⌉variables inxsatisfyingxi=tby the second set of constraints of (LP7), and at most k variables inxsatisfying 0 < xi< t by Lemma 3. If there are exactly l variable(s) inxsatisfyingxi=t,then the sum of the remaining (at most) k variables inxsatisfying 0 < xi< t is no larger than(m−l−K)t. It remains to show thatm−l−Kis no greater thankk+1−m+l.For this, we define a functionf(x)=x−kk+1−xforx∈{1,…,k}. It is easy to see that f(x) is increasing whenx≤k˜and decreasing whenx≥k˜. Therefore, whenk˜>m,we havem−l−K=m−l−f(m)≤m−l−f(m−l)=kk+1−m+l; whenk˜≤m,we havem−l−K=m−l−maxx∈{1,…,k}f(x)≤m−l−f(m−l)=kk+1−m+l. Therefore, the lemma holds.□Let (x, t) be a basic feasible solution of (LP7), then we can construct a feasible schedule of the SLC problem with a makespan of at most t.If k ≤ m and this basic feasible solution has at mostm−kvariables inxsatisfyingxi=t(those jobs must be assigned solely), then by Lemma 3, there are at most k variables inxsatisfying 0 < xi< t and those corresponding jobs can also be assigned solely and we are done.Next, we consider the case where m < k or m ≥ k but there are more thanm−kvariables inxsuch thatxi=t. Let l denote the number of variables inxsuch thatxi=t. By the case assumption and the constraint in (LP7),l∈{m−⌈K⌉,m−⌈K⌉−1,…,max{m−k,0}}. Without loss of generality, we can assume there are exactly k jobs having processing times xi< t, with some jobs having possibly zero processing times. We now show how to construct a feasible schedule with a makespan at most t. First, we assign the l jobs with processing timesxi=tto l machines solely. Then we find the smallestk+1−m+ljobs with processing times smaller than t. We claim that these jobs have a total processing time of at most t, and hence can be fit into a single machine. If not, it follows that anyk+1−m+lof the k jobs with processing times smaller than t have a total processing time greater than t. Then we have the following k inequalities (mod k for each index):(2)x1+x2+⋯+xk+1−m+l>t,x2+x3+⋯+xk+2−m+l>t,⋮xk−1+xk+⋯+xk−1−m+l>t,xk+x1+⋯+xk−m+l>t.On the one hand, summing up inequalities in (2) we obtain(k+1−m+l)(x1+x2+⋯+xk)>kt,orx1+x2+⋯+xk>kk+1−m+lt. On the other hand, by Lemma 4, the total processing time of the jobs with processing times xi< t is at mostkk+1−m+lt,which leads to a contradiction. Finally, there are at mostk−(k+1−m+l)=m−l−1jobs each with processing time smaller than t, andm−l−1remaining machines. Assigning these jobs solely provides a feasible solution with a makespan of at most t.□Similar to LP-based algorithm fork=2,we can find an optimal basic feasible solution of (LP7) in polynomial time and obtain a feasible approximated schedule for the SLC problem. We also call it LP-based algorithm and summarize it in Algorithm 5. Next we study its approximation ratio.Theorem 7The schedule returned by the LP-based algorithm has a makespan ofCmax=t≤mm−KCmax*,whereCmax*is the optimal makespan of the problem.Letx* be the optimal schedule with makespanCmax*. It suffices to show that(x*,mm−KCmax*)is a feasible solution to (LP7). If that holds, then since Algorithm 5 provides a schedule with makespan t, the optimal value of (LP7), the results hold. To show that, note thatx* satisfies the first set of linear constraints of (LP7).Cmax*is the optimal makespan implies that∑i=1nxi*≤mCmax*=(m−K)mm−KCmax*,andxi*≤Cmax*≤mm−KCmax*for each i. Therefore,(x*,mm−KCmax*)is a feasible solution. Thus the theorem holds.□We show some examples of the ratiosm/(m−K)in Table 4. We can see that the LP-based algorithm performs well when k is relatively small. The performance deteriorates when k becomes large. Furthermore, if k is a fixed constant, the approximate ratio is close to one when m is sufficiently large.Finally, we note that in practice one can apply both approximation Algorithms 4 and 5, and choose the one that gives a better solution. The approximation ratio of the combined algorithm will bemin{mm−K,2−1m}.

@&#CONCLUSIONS@&#
