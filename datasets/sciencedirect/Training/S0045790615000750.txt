@&#MAIN-TITLE@&#
Concurrent hardware architecture for dual-mode audio steganography processor-based FPGA

@&#HIGHLIGHTS@&#
We propose concurrent hardware architecture for real-time audio steganography.We implement and test the proposed hardware on Xilinx XC6SLX16 FPGA board.The implemented hardware requires only 97 slices and consumes less than 148mW.The implemented hardware processes data simultaneously with frequency up to 58.82.Full data retrieval at embedding rate of 25% of the cover audio size.

@&#KEYPHRASES@&#
Audio steganography,Lifting wavelet transform (LWT),Security,Field programmable logic array (FPGA),Hardware description language (HDL),Dual mode processor,

@&#ABSTRACT@&#
Recently, audio steganography has become an important covert communications technology. This technology hides secret data in a cover audio without perceptual modification of the cover audio. Most of the existing audio steganography techniques are unsuitable for real-time communication. Although field programmable logic array (FPGA) technologies offer parallel processing in hardware that can improve the speed of steganographic systems, the research activities in this area are very limited. This paper presents a parallel hardware-architecture for dual-mode audio steganography (DMAS) based FPGA technology. The proposed DMAS reconfigures the same hardware blocks in both hiding and recovery modes to reduce the hardware requirements. It has been successfully implemented on a Xilinx XC6SLX16 FPGA board to occupy only 97 slices. Furthermore, it processes data simultaneously at an operating frequency of up to 58.82MHz and accomplishes full message retrieval at an embedding rate of 25% with an audio quality above 45dB in terms of signal to noise ratio.

@&#INTRODUCTION@&#
Steganography and cryptography have attracted increasing attention as covert communication techniques [1,2]. Cryptography renders messages incomprehensible by encryption, whereas steganography conceals the very existence of secret messages within a cover signal [3]. The transmission of an encrypted message may arouse the suspicion of an eavesdropper, unlike an invisible message in a cover signal (which is named the stego signal after including the hidden message). Nevertheless, both encryption and steganography can be combined for high-level message protection [4].The requirements differ depending on the purpose of the steganography. Typically, to create an effective audio steganography scheme, the following features are required, with different grades according to the goal to be achieved through adoption of the audio steganographic system [1,4]:i.Imperceptibility. The perceptual quality of the cover audio signal should not degrade after the message data are embedded.Embedding rate. A large amount of message data must be inserted into the cover audio without losing imperceptibility.Security. Embedded messages should be secured, and the cover signal should not tolerate any evidence of their existence. A secret key can be used to increase the steganography security level.Robustness. Hidden data should be retrievable from a stego-audio signal even after encountering noise or attacks.Computational complexity. Processing time required to complete message hiding or recovery should not be long and it should be appropriate to the goal of the steganography scheme.Essentially, the above features are contradictory. For example; increasing the embedding rate in a steganographic system leads to degradation of the hidden data robustness and stego signal quality. Covert communication-based audio steganography normally requires a high embedding rate without producing perceptually or statistically detectable distortions. Therefore, least significant bit (LSBs) substitution techniques are usually adopted, either in the time or transform domains, to satisfy both the high embedding rate and imperceptibility. The LSB method introduced in the time domain have low complexity in addition to high embedding rates [5]. However, the direct LSBs methods are sensitive to an additive noise. Thus, the authors of [6] have attempted to increase the robustness of LSB method by altering the depth of the inserted data in a higher bit position of the cover sample. In this technique, the perceptual quality is less than that of the conventional LSB method. Basically, in the LSBs methods that insert secret data in deterministic positions, an attacker can easily detect the message by only extracting the entire LSBs plane of these positions.To increase the embedding rate of LSBs techniques, data are embedded by employing human auditory system (HAS) masking either in the frequency [7,8] or wavelet domains [9–17]. According to the literature [7,18,19], the wavelet domain can provide the highest embedding rate compared to the other domains and can achieve over 20% of the cover audio size without compromising the perceptual quality of the stego audio. This is because the time–frequency characteristics of the wavelet domain are similar to those of human ears [20]. However, the existing wavelet based audio steganography has several critical weaknesses that prevent it from being a reliable covert communication technique. The main weaknesses are listed below:i.Critical security against active attacker: most of the existing techniques, such as in [7,9,11,13], embed secret messages in deterministic positions of the cover audio. Therefore, an attacker who knows these embedding procedures can retrieve the secret messages.Hidden data lost: the existing techniques, such as in [9,14,16], do not satisfy full recovery of the hidden data. In practice, full recovery is required for some types of hidden data, such as text, header files, and secret keys.Dependence on the chosen cover audio: embedding capacity and imperceptibility of some existing techniques, such as in [10,11,13], are dependent on the energy of the chosen cover audio. This leads to an imposition of restrictions on the use of these techniques and on the repeated use of cover audios. Repeated use of cover audio can make stego audio more vulnerable to steganalysis.Intensive computational complexity: the existing techniques that have embedding rates above 20% of the cover audio size, such as in [9,10,12,14,16,17], require intensive processing and long execution times. Therefore, these techniques do not satisfy the timeliness requirements of real-time covert communication.In summary, the current audio steganography techniques that are based on the wavelet domain can satisfy the requirement of a high embedding rate, but they lack important features, such as security against active attackers in [9,11,13], full retrieval for the hidden data in [9,10,14], independence of the chosen cover audio in [10,11,13], and all of these techniques require intensive computation.In our previous work [21], we proposed a simple audio steganography scheme based on an integer to integer lifting wavelet transform to optimize the important covert communication features, such as the computational complexity, embedding rate, imperceptibility, security and robustness. This scheme has fixed embedding rates that include 25% of the cover audio size, full retrieval for the hidden data, output imperceptibility independent of the chosen cover audio, and less complexity than the related methods.This paper presents a hardware design and implementation for the audio steganography scheme in that previous work [21]. The designed hardware is suitable for real time covert communication and has been successfully implemented on a Xilinx XC6SLX16 FPGA board. It operates in hiding and recovery modes by sharing the same hardware blocks. Furthermore, it processes the input data concurrently at operating frequencies of up to 58.82MHz with a power consumption of less than 148mW.The remainder of this paper is organized as follows: Section 2 presents a brief review of audio steganography hardware based on FPGAs. Section 3 describes the audio steganography scheme in [21], which has been selected for design as a hardware processor in this paper. Section 3 presents the hardware blocks of the dual-mode audio steganography (DMAS) processor. Section 4 shows the design architecture of each block individually with its simulation and synthesis results. Section 5 presents the overall hardware of the DMAS processor with simulation, synthesis, and implementation results. Section 6 presents a comparison between the DMAS processor and some related works. Section 7 concludes the paper.The hardware implementation of a steganographic system can offer significant advantages over a software implementation in terms of processing speed. The parallelism capability in some hardware, such as a FPGA, allows the designer to implement multiprocessing for concurrent execution of independent tasks. However, few hardware based audio hiding systems have been reported in literature because work in this area requires knowledge in more than one discipline. In this section, we briefly review some of the works in this area that employ FPGA in the implementation of the audio hiding architectures.In [22], the authors have proposed a micro-architecture for a secret-key steganographic based FPGA. The proposed architecture contains two important parts. One is an address generator, and the other is a control unit. The address generator unit is used to generate random addresses in the stored cover samples for hiding a bit. The address generator consists of a memory of pointers and a shuffler, and a shift register that concatenates units. The control unit consists of a status register, control logic gates, and a decoder. The control unit has been used to monitor and control the data embedding process. The proposed architecture has been implemented on anXC2S100tq144-6 FPGA, and it consumes 1195 slices.In [23], a software/hardware data hiding technique for speech bandwidth implementation is proposed. The proposed system employs linear prediction coding (LPC) and vector quantization (VQ) for embedding data to transmit high frequency speech components to improve the speech quality in transmission systems. To optimize the trade-off between a consumption of logic resources and processing speed, the data embedding technique are mainly implemented in the software based Xilinx micro-blaze soft processor, while a fast Fourier transform (FFT) is implemented in a hardware platform. Due to the use of application software, which operates sequentially, the speed performance is limited.In [24], a hardware architecture based FPGA for an audio hiding system has been reported. The hiding system is based on rational dither modulation (RDM) in the modulated complex lapped transform (MCLT) domain. The proposed hardware architecture consists of an MCLT processor, an inverse MCLT processor, a coordinate rotation digital computer (CORDIC) and an RDM processor. According to the authors, the proposed data hiding system is suitable for real-time watermarking applications.In [25], an FPGA implementation for the audio watermarking-based chirp spread spectrum (CSS) method has been proposed. The proposed CSS audio watermarking is implemented on the Vertex 4-XC4VLX25-10FF668 FPGA device, and it is analyzed using real time cover-audio (.wav).The results of the analysis show that it is robust and consumes little power.Recently, the authors in [26] proposed a new hardware system for speech in speech hiding based on DWT. The proposed system hides a message-speech of 8bits in a cover-speech of 16bits for the same timescale and for a frame of m samples (m in the range of 8–127). Each frame of the cover-speech is decomposed by DWT, and its approximation and detail coefficients are attained, whereas the message-speech is decomposed by DWT and only its approximation coefficients are obtained to compress the message by half. Then, the approximation coefficients of the message are sorted in descending order, and their original positions are used as an adaptive secret key. The key data are hidden in the LSBs of the cover-detail coefficients, whereas the approximation coefficients of the speech-message are embedded in the LSBs of the cover approximation coefficients. The embedded compressed message data comprise 25% of the total cover size. The designed hiding hardware consists of two DWT modules, a delay unit, sorting modules, embedding modules, and inverse DWT modules. The extracting hardware consists of a DWT module, extraction module, reverse module, and inverse DWT module. The embedding and extraction modules are synthesized using a Xilinx xc6slx45 device. The resources of the designated FPGA are as follows: 797 slice registers, 849 slice LUTs and 427 LUT-FF pairs. The embedding module latency is in the range of 23–261 clock cycles, or 2.9–32.6ms, based on the frame length.Although the above works have utilized FPGA to implement data hiding in cover audio, they still use sequential processing for independent tasks in most of their parts, which will increase the system latency significantly. Additionally, most of them, such as those in [23–25], can be used only for watermarking applications and are unsuitable for covert communications because they have low embedding rates. Furthermore, even for architectures such as that in [26], which has a high embedding rate, there are still drawbacks, such as critical embedded keysecurity and loss recovery for the hidden data. Therefore, in this paper, we have attempted to design a dual mode audio steganographic processor that overcomes most of the former drawbacks. The designed processor operates concurrently to meet the requirements of real time communication for any cover audio sampling frequency. Moreover, it is secure, and the hidden data are encrypted by a dynamic scrambler key. Additionally, it satisfies full retrieval of the hidden messages due to the use of integer to integer LWT, as will be described in the next section.In this paper, we select the audio steganography scheme in [21] to be designed and implemented as a hardware based FPGA. This scheme has been selected because it is simple and reduces the hardware requirements. In addition to simplicity, this scheme satisfies full retrieval of the hidden messages at an embedding rate of 25% of the cover audio size.The steps of the designed DMAS in this work are similar to those in [21] except for a minor modification in the selection of the scrambler key bits. The details of the hiding and recovery steps are given in the following subsections.An input cover audio with resolution of a16bits/sample is framed into small frames without overlap, where each cover frame has 4 audio samples. Also, an input secret message with an 8bits/sample resolution is framed into two samples per frame. Fig. 1shows the steps of the hiding algorithm, and the processing of these steps is as follows:i.Decomposing each cover audio frame (four samples) by using two levels of Haar integer to integer (Int2Int) LWT. The decomposition results in three sub-bands. These sub-bands are the first detail sub-band, which has two coefficients; the second detail sub-band, which has one coefficient; and the smooth sub-band, which also has one coefficient. The first and second detail sub-band coefficients are used for message data embedding, whereas the smooth coefficient is used to generate a dynamic scrambler key (SK) that is used to encrypt the secret messages.The dynamic scrambler key, which contains an 8bit unsigned integer, is generated from the smooth coefficients. This is achieved by first generating a start position key (SPK) from an input key (K) entered by the user of the system. The key (K) is an 8bit unsigned integer (uint8), where the first two LSBs represent the SPK. Subsequently, The SK is chosen from the smooth coefficient bits based on the SPK. The 8bits of the SK are selected from the 16bits of S2 according to the following equation:(1)SK(0to7)=S2(spk to spk+7)Subsequently, the two messages are converted to 8 binary bits. Then, exclusive or (XOR) operation is performed between the binary data of the SK and each message.In the embedding process, the first 6bits of the first and second encrypted messages are inserted into the first six LSBs of the first and second coefficients of the first detail sub-band, respectively. The remaining 2bits of the first and second encrypted messages are inserted into the first four LSBs of the second detail sub-band coefficient.Then, the output stego-audio frame is constructed by performing the inverse of two levels of Haar Int2Int LWT after converting all of the sub-bands to decimal.The above procedure is repeated for all of the cover and message frames. Finally, the stego frames are merged together to obtain the output stego audio.The steps of the message recovery are similar almost to the hiding steps, as shown in Fig. 2. In the first step, an input stegoaudio is framed into 4 samples per frame. Then, each frame is decomposed by two levels of Haar LWT. Subsequently, from the two coefficients of the first detail sub-band, the first 6bits of each encrypted message are extracted, and from the second detail sub-band coefficient the remaining 2bits of each encrypted message are extracted. Next, the same SK generating procedure used in the hiding steps is followed, and then an XOR operation is performed on each extracted encrypted message sample and the produced SK. The results of the former steps are the two decrypted messages, which are converted to decimal to obtain one secret message frame. The above procedure is repeated for all of the stego audio frames to extract all of the message frames. Finally, all of the extracted message frames are merged into a single array to be converted to the required message type.To reduce the hardware area of the DMAS processor, the same hardware blocks are used to alternately hide or recover messages. This is possible due to the symmetry between most steps of the hiding and recovery operations, as presented in the previous section. The realized DMAS processor has eight inputs and six outputs, as shown in Fig. 3a. The inputs involve seven data buses and one control signal. The data buses include four buses of audio samples (X1, X2, X3, and X4), each with 16bits; two buses of message samples (M1, and M2), each with 8bits; and one bus for the key (K), which has 8bits. The control signal or operation mode signal (OMS) specifies the operation mode. If it is low (logic 0), then the processor operates in the hiding mode; otherwise, the processor operates in the recovery mode. The output involves 6 data buses: four 16bit buses for the stego audio (Xm1, Xm2, Xm3, and Xm4), and two 8bit buses for the recovered message samples.Based on the mode type, an operation mode controller (OMC) and coefficient flow controller (CFC) reconfigure the connections of the internal buses. Accordingly, in the hiding mode, the input data are the seven data buses and the outputs are the four stego audio samples, whereas the recovered message buses are reset to zeros. In the recovery mode, the data inputs are the four stegoaudio samples, and the outputs are the two recovered message samples, whereas the stego audio buses are reset to zeros.The internal hardware blocks of the DMAS processor are shown in Fig. 3b. There are seven blocks: two levels of an integer Haar lifting wavelet transform (2-level IHLWT) processor that operates in the decomposition mode, a start position key (SPK) generator, a scrambler, an operation mode controller (OMC), a hiding and recovery (HIDREC) processor, a coefficient flow controller (CFC) and a 2-level IHLWT processor that operates in reconstruction mode. The details of each block are presented in the following subsections.This section presents the hardware architecture of the designed 2-level Integer Haar LWT (IHLWT). We extend our design of the 1-level Integer Haar Computing Unit (IHCU) presented in [27] to construct the 2-level IHLWT hardware that is used within the DMAS processor. We have chosen our IHCU in this design because it is flexible and can process any arbitrary signal length. Additionally, it can execute either decomposition or reconstruction of the wavelet modes by sharing the same hardware resources based on a control signal. If the input mode signal is low (decomposition mode), then the IHCU performs predict and update operations (LWT operations in decomposition [27]) in parallel. Otherwise, if the mode signal is high (reconstruction mode), the IHCU performs the inverse of predict and update operations in parallel. The IHCU transforms a pair of input samples in each clock cycle to find the LWT decomposition or reconstruction coefficients. For the decomposition mode, the IHCU reconfigures its architecture as shown in Fig. 4a to compute the details and smooth coefficients. Alternately, for the reconstruction mode, the IHCU reconfigures its architecture as shown in Fig. 4b to compute the signal samples. Two multiplexers are used in the IHCU to control the configuration mode (decomposition or reconstruction), as shown in Fig. 5. The overall IHCU architecture shown in Fig. 5 involves an adder, subtractor, two multiplexers, and two shifters. The design of the IHCU is very simple and reliable, and it has low hardware requirements. Both IHCU modes share the same adder and subtractor.The proposed architecture for the 2-level dual mode IHLWT is designed to process four 16bit input samples in parallel to perform a forward or inverse IHLWT in a single clock cycle. Fig. 6a shows the inputs and outputs of the 2-level IHLWT processor. Fig. 6b shows the internal architecture of the processor. The processor uses three IHCU units and eight multiplexers. The eight multiplexers control the data flow of the inputs and outputs based on the mode signal. The inputs and outputs of the circuit blocks, which are shown in Fig. 6b, are reconfigured to form the circuit as depicted in Fig. 7a in the case of low mode signal (decomposition mode), or the circuit shown in Fig. 7b when mode signal is high (reconstruction mode).The proposed architecture has been developed using VHDL codes. A Xilinx ISE has been used to simulate and synthesize the proposed hardware architecture using a Xilinx XC6SLX16 evaluation board. Fig. 8shows a sample of the simulation tests for 12 input samples, where each frame of 4-samples is processed concurrently in one clock cycle. During the first half of the clock cycles, the mode signal is low; therefore, the IHLWT processor decomposes the input samples. At the output, the decomposition coefficients (d1_1, d1_2, d2_1 and S2) are obtained on the Y1, Y2, Y3 and Y4 buses. During the second half of the clock cycles, the mode signal is high, and the input coefficients at the X buses are reconstructed to their original samples by the processor to obtain the reconstructed frames on the Y buses.The synthesis results of the designed 2-level IHLWT hardware show that it requires only 72 slices. A summary of the synthesis results is presented in Table 1.This section presents the design of the ciphering parts of the DMAS processor. The ciphering process starts by producing a scrambler key (SK) from the smooth coefficient based on the start position key (SPK).The SPK is generated from an input key (K) that is entered by the user of the system. Where K can be any array of 8bit unsigned integers (uint8), such as image pixels arranged in a 1D array or characters. In alternate clock cycles, one element of the K array is used to produce one SPK, where SPK is the first three LSBs of K.The block diagram of the scrambler is shown in Fig. 9a. It has four data inputs and two data outputs. The input data includes two 8-bit inputs for messages (m1 and m2), 3bits for the SPK and 16bits for the smooth coefficient (S2). The output data are two encrypted messages (em1 and em2). The proposed scrambler operates in the two modes of the DMAS processor by realizing the same function to both cipher the two messages (m1 and m2) and decipher the encrypted messages (em1 and em2). This is achieved by an exclusive or (XOR) operation between the messages and a scrambler key, as shown in Fig. 9b. The 8bits of SK are selected from the 16bits of the S2 according to Eq. (1). Subsequently, the encrypted or decrypted message data can be obtained using the following equations:(2)em1=m1XOR SK(3)em2=m2XOR SK(4)m1=em1XOR SK(5)m2=em2XOR SKThe proposed scrambler has been developed using IEEE standard VHDL. Xilinx ISE tools have been used to simulate and synthesize the proposed scrambler. Fig. 10shows samples of the simulation results. In Fig. 10a, each frame of two input messages (m1 and m2) is ciphered in a single clock cycle to concurrently obtain the output of the encrypted frame on the em1 and em2 buses. In Fig. 10b, the inputs are encrypted messages on the m1 and m2 buses, which are obtained from the outputs of Fig. 10a and are deciphered in a single clock cycle to concurrently obtain the deciphered messages as the outputs on the em1 and em2 buses. The scrambler has been successfully synthesized using a Xilinx XC6SLX16 board. The summary of the synthesis is presented in Table 2. The implemented scrambler occupies only 16 slices.The operation mode controller (OMC) is used to specify the message’s flow based on the DMAS processor mode. This controller reconfigures the input message buses of the scrambler and HIDREC processor according to the OMS to identify the DMAS internal buses either for the hiding or recovery mode.Fig. 11shows the block diagram and the internal architecture of the OMC. The OMC consists of six 8-bit multiplexers to control the message data flow according to the operating mode signal (OMS). If the OMS is low (hiding mode), then the OMC configures the buses as follows:i.The input messages (M1 and M2) are passed into the scrambler through the internal buses min1 and min2.The encrypted messages (em1 and em2) produced by the scrambler are passed into the HIDREC processor through the internal buses M1_in and M2_in.The recovered message buses R_M1 and R_M2 are reset by connecting them to the ground.Otherwise, if OMS is high (recovery mode), then the OMC configures the buses as follows:i.The input messages of the HIDREC processor (M1_in and M2_in) are reset by connecting them to the ground.The encrypted messages rm1 and rm2 (that have been retrieved by the HIDREC processor) are passed through the internal buses (min1 and min2) into the scrambler for decryption.The deciphered messages from the scrambler (em1 and em2) are passed into the recovered message buses (R_M1 and R_M2).The OMC has been developed using IEEE standard VHDL code, and the designed code has been successfully synthesized on a Xilinx XC6SLX16 board with a Xilinx ISE tool. The summary of the synthesis results are presented in Table 3. The synthesis shows that the designed OMC occupies only 10 slices.The hiding-recovery (HIDREC) processor is designed to achieve the LSBs embedding and recovery processes according to the algorithm presented in Section 3. The HIDREC processor operates in either the hiding or recovery mode based on a low or high OMS, respectively. In the hiding mode, two 8bit of encrypted messages are inserted into the LSBs of the three detail sub-band coefficients of the cover audio. The first 6bits of the first and second messages (M1_in and M2_in) are inserted into the first six LSBs of the first sub-band coefficients, d1_1 and d1_2, respectively. Concurrently, the last two bits of M1_in and M2_in are inserted in the first and second two LSBs of the second detail sub-band coefficient (d2-1). In recovery mode, the first six LSBs of d1_1 and the first two LSBs of d2-1 are extracted and combined on an 8bit bus to obtain the first encrypted message on the M1 bus. Concurrently, the first six LSBs of d1_2 and the second two LSBs of d2-1 are extracted and combined on an 8bit bus to obtain the second encrypted message on the M2 bus.Fig. 12demonstrates the block architecture of the HIDREC processor. The architecture of the HIDREC processor involves a set of combination blocks (Comb.) and multiplexers, as shown in Fig. 12b. The “Comb.” block combines its input buses into one multi-bit bus. It is represented in hardware by a wiring circuit with its output bits arranged depending on the order of the input buses. In the hiding mode, the first three multiplexers of the HIDREC processor pass the three detail coefficients after message insertion to the output buses dm1_1, dm1_2 and dm2_1. Also, the last two multiplexers of the HIDREC processor reset their output buses (M1_out and M2_out) by connecting them to ground. In the recovery mode, the first three multiplexers reset the dm1_1, dm1_2 and dm2_1 buses by connecting them to ground, and the last two multiplexers pass the extracted messages, M1 and M2, to the message output buses, M1_out and M2_out, respectively.The HIDREC architecture has been developed by VHDL and it has been successfully synthesized on a Xilinx XC6SLX16 evaluation board with Xilinx ISE tools. The summary of the synthesis results are presented in Table 4. The designed HIDREC processor requires a low hardware area consisting of only 16 occupied slices. The processor has been simulated using an Isim test bench of the ISE tool. Fig. 13a shows a sample of the simulation results of the HIDREC in the hiding mode. The outputs at the dm1_1, dm1_2 and dm2_1 buses in Fig. 13a are entered as inputs to the HIDREC in recovery mode, as shown in Fig. 13b. The recovered messages are given on the M1_out and M2_out buses in Fig. 13b.The coefficient flow controller (CFC) switches the input data buses of the 2-level IHLWT processor when operating in the reconstruction mode either to the outputs of the HIDREC and smooth coefficient in the hiding mode or to ground in the recovery mode. This process decreases the power consumption required in the recovery mode because the 2-level IHLWT processor in the reconstruction mode will be idle and does not need to be operated.Fig. 14shows the block diagram and internal architecture of the CFC. The architecture of the CFC involves four 2-input multiplexers with the OMS as a selection signal; and each input has a 16bit bus. In hiding mode, the multiplexers pass the outputs of the HIDREC (on the internal buses Z1, Z2, and Z3) and the smooth coefficient (on the internal bus Z4) into the inputs of the 2-level IHLWT processors (on internal buses ZZ1, ZZ2, ZZ3, and ZZ4), respectively. Otherwise, the multiplexers connect the input data of the 2-level IHLWT processors (on internal buses ZZ1, ZZ2, ZZ3, and ZZ4) to ground.The CFC has been developed using IEEE standard VHDL code, and it has been successfully synthesized on a Xilinx XC6SLX16 evaluation board using the Xilinx ISE tool. The summary of the synthesis results is presented in Table 5. The synthesis shows that the designed CFC occupies only 15 slices.All of the above hardware components of the DMAS have been designed to process input data concurrently in alternate clock cycles to obtain fast data processing and avoid synchronization problems in the overall design. Therefore, the overall DMAS hardware also processes its data concurrently. In each clock cycle, it ciphers two 8bits of the messages and then hides them in four 16bit cover samples during the hiding mode or retrieves two 8-bits of message data from four 16bit cover samples and then deciphers them during the recovery mode.The OMC and CFC configure the DMAS internal connections based on the OMS to execute the hiding or recovery modes. Fig. 15shows the DMAS after configuration in either the hiding or recovery mode. The overall design of the DMAS has been developed using IEEE standard VHDL code. The simulation, synthesis and implementation of the overall design are presented in the following subsections.The Xilinx ISE simulator has been used to simulate the overall design of the DMAS. Fig. 16shows a sample of the simulation results of the hiding and recovery modes. The DMAS hides or retrieves data concurrently without any clock cycle latency. In the hiding mode, there are four 16bit signals of input cover data on the X1, X2, X3, and X4 buses and two 8bit signals of message data on the M1 and M2 buses. The outputs are four 16bit signals of stego data on the Xm1, Xm2, X3, and Xm4 buses. In the recovery mode, the outputs of the hiding mode are the inputs to the DMAS processor on the X1, X2, X3, and X4 buses. The outputs are two 8bit recovered messages on the R_M1 and R_M2 buses. The same key (K) must be used in both modes of DMAS to detect the correct messages.The Xilinx synthesis tool (XST) has been used to synthesize the overall design of the DMAS processor for two cases. In the first case, the DMAS processor operates without an interface, and in the second case, the DMAS processor is connected to an Ethernet interface using the FIL tool. In both cases, a Xilinx XC6SLX16 evaluation board has been used in the synthesis.The synthesis results of the DMAS processor alone show that it requires a low hardware area and an acceptable delay path. The overall hardware area is less than the summation of the former individual hardware blocks. The summary of the hardware area synthesis is presented in Table 6. Only 97 CLBs of occupied slices are required for the overall design of the DMAS without the interface hardware. The longest path delay of the DMAS alone is 16.96ns, and the maximum operating frequency is 58.82MHz.The implementation tests have been conducted by employing FPGA-In-Loop (FIL), which is a new MATLAB tool designed to provide the ability to interconnect Simulink software to on-chip hardware. This tool is used to provide an interface between the PC and the DMAS on-chip processor through an Ethernet cable. The FIL tool automatically adds an Ethernet MAC core to the design to provide communication between the DMAS processor and the Ethernet on the FPGA board, as shown in Fig. 17. The synthesis result of the DMAS hardware area, after adding the communication layers, is presented in Table 7. A total of 1070 occupied slices are required for the overall hardware with the interface. Most of these slices are used to implement the communication layers because the DMAS processor alone requires only 97 slices. The longest path delay of the DMAS with the interface is 19.334ns, and the maximum operating frequency is 51.722MHz.The Xilinx power analyser tool has been used to estimate the power consumption of the DMAS with the FIL interfacing. Table 8shows the power consumption of the design using a Xilinx XC6SLX16 evaluation board. The quiescent power for each FPGA device represents the dominant part of the total consumed power, and it includes power for the whole device including idle FPGA resources. Consequently, the total power consumed by the DMAS processor alone (without the FIL interfacing) is lower than those stated in Table 8. Because the total power consumption is low, the proposed design is suitable for low power applications, such as secure mobile telephony.The designed DMAS processor has been implemented and tested successfully on a Xilinx XC6SLX16FPGA board (xc6slx16-2csg324). Testing of the implemented hardware employed the FIL tool that enables a real time test of the on-chip device over Ethernet. The on chip device can be hosted by a PC through a MATLAB simulation model to read and write from and to the device. Fig. 18shows the FIL model of the DMAS processor. An input cover or stego audio signal (C) is entered from the MATLAB workspace as a frame at each sample interval. Each frame contains four 16bit audio samples entered in parallel into the FIL model by the row selector block. Similarly, a message signal (M) is entered from the workspace as frames. Each frame involves two 8bit message samples, which are entered in parallel to the FIL model by the row selector block. Additionally, a secret key (K) is entered from the workspace as one 8-bit sample at each sample time. The manual switch shown in Fig. 18 is used to specify the operating mode of the DMAS processor, either the hiding mode if it is connected to 0 or the recovering mode if it is connected to 1. The stego samples in the case of the hiding mode or the recovered messages in the case of the recovery mode are saved in the workspace signals Yout1, Yout2, Yout3 and Yout4, or R_M1 and R_M2, respectively.Several tests for the DMAS on the FPGA chip have been completed. Three types of messages are used: images (gray and color), speech signals and texts. For the image messages, the pixels of the image are arranged in a 1D array before they are entered into the FIL system of the DMAS. For the text messages, the characters of the text are converted into their ASCII codes as 8-bit unsigned integers and are arranged in a 1D array before they are entered into the DMAS hardware. For the speech messages, each16-bit sample is separated into a pair of 8bit samples and arranged in a 1D array.Table 9demonstrates the test results for various cover audio signals with different messages. The embedding data rate is constant for all of the tests at 25% of the cover audio size. In all of the tests, the output stego signals have an excellent perceptual quality (above 45dB) in terms of the segmental signal to noise ratio (SSNR), which is calculated according to Eq. (6). Furthermore, in the recovery mode, all of the messages have been fully detected with no errors.(6)SSNR=∑j=1N110log10∑i=1N2C2(i)∑i=1N2[C(i)-C′(i)]2where C and C′ are the cover and stego audio segments, respectively, N1 represents the number of samples in each segment, and N2 is the total number of segments.This section presents two groups of comparison tests between the proposed DMAS hardware and some related schemes. In the first group of the comparison tests, the audio steganography performance of the DMAS hardware is compared with the related schemes in terms of the stego audio quality, embedding throughput and errors in the retrieved hidden message. For this comparison, we select the audio steganography methods that are based on the wavelet transform and have maximum embedding rates near or above 20% of the cover audio size, as in [10,13,14,21]. In [10], the secret data are embedded based on a hearing threshold with an integer wavelet coefficient after a coefficient scaling process. This scheme achieves a maximum embedding rate of approximately 4–5bits per sample, or approximately 25–30% of the cover audio size. In [13], the authors employ an integer lifting wavelet transform to embed secret data in the wavelet coefficients based on the coefficients’ strengths. This scheme can embed data up to 20% of the cover audio size. The authors in [14] have proposed efficient wavelet masking (EWM) and indirect speech message embedding. This scheme embeds a maximum of 5bits per coefficient to reach embedding rates of approximately 31% of the cover audio size. In [21], we employ an integer to integer lifting wavelet transform and embed the encrypted data in imperceptible positions of the detail sub-band. This scheme has a fixed embedding rate of 25% of the cover audio size.To evaluate the quality of the stego audio and retrieved hidden messages as well as the embedding throughput and hiding processing time, all of the related algorithms in [10,13,14,21] have been implemented in Matlab. Table 10shows the results of comparison of the DMAS hardware to the other related schemes implemented in Matlab software. These tests used a 10s cover speech sample at a 44,100Hz sampling frequency and message speech samples of varying lengths according to the embedding rate of each scheme. In Table 10, we have calculated the stego audio quality in terms of the SSNR according to Eq. (6) and the retrieved hidden message quality in terms of both the normalized correlation (NC) according to Eq. (7) and the bit error rate (BER) according to Eq. (8) at the maximum embedding rate for each scheme. In the table, a higher SSNR indicates better stego audio quality or higher imperceptibility, and NC=1 or BER=0 refers to full retrieval of the hidden message. The NC and BER formulas are as follows [28]:(7)NC(M,M′)=∑k=1NM(k)M′(k)∑k=1NM(k)2∑k=1NM′(k)2M and M′ represent the original and retrieved secret messages, respectively. N indicates the number of samples in each message.(8)BER=NumberofincorrectretrievedbitsTotalnumberofbitsforentireretrievedmessage×100Furthermore, Table 10 also lists approximations of both the hiding processing time and the embedding throughput for each related scheme at the maximum embedding rate computed using the same computer and Matlab version. The embedding throughput of each scheme has been calculated by dividing the number of bits embedded within10s of cover speech by the required hiding processing time to find the number of bits per second for the embedding data. Table 10 clearly shows the superiority in embedding throughput of the DMAS processor over all other related schemes, with a perceptual quality above 48dB in terms of the SSNR and full retrieval for the hidden message.The second group of the comparison tests has been completed to evaluate the hardware performance of the proposed DMAS and related work. In this comparison, we have chosen the work in [26] that hides speech message audio in speech cover audio at an embedding rate of 25% of the cover audio size. The algorithm in this work is lossy and suitable only for hiding speech messages in speech covers, and cannot be considered as a generic audio steganographic system.To compare the DMAS with the scheme of [26], the same FPGA board (Spartan-6 xc6slx45) used to synthesize the scheme in [26] has been used to synthesize the DMAS. Table 11gives the resources utilization and the longest path delay of the two schemes. The table shows that the DMAS requires lower resources than the other scheme. Additionally, in terms of latency, the DMAS concurrently processes its input data, while the other one requires a relatively long latency. The longest delay path for the DMAS is 14.064ns, whereas for the scheme in [26], it is 7.28ns.In terms of steganography performance, the DMAS hardware has a better performance than the scheme in [26]. While the DMAS scheme has an excellent stego audio quality of approximately 48dB, the scheme in [26] has a stego audio quality near 33dB. Moreover, the DMAS scheme achieves full retrieval of the hidden messages. In contrast, the scheme in [26] has lost data in the retrieved speech messages. Additionally, the proposed DMAS is suitable for hiding any type of binary data in any audio signal (music and speech), whereas the other scheme is specified to hide message speech with 8bits/sample resolution in a cover speech with 16bits/sample resolution.

@&#CONCLUSIONS@&#
This paper has presented an efficient FPGA based hardware architecture for the proposed DMAS processor. The synthesized DMAS processor requires low little hardware due to sharing of the hardware resources for both the hiding and recovery modes. Furthermore, the processor consumes little power and processes input data concurrently in a single clock cycle. The designed DMAS has been successfully implemented and tested on a Xilinx XC6SLX16 evaluation board. The test results of the implemented hardware are correlated 100% with the software results. The comparison of the implemented DMAS to related work shows the superiority of the DMAS over the others in terms of reduced hardware area, concurrent data processing resulting in the absence of clock latency, a high stego audio perceptual quality of approximately 48dB in terms of the SNR and full hidden data retrieval. In addition to the above features, it is a generic audio steganography processor, where the hidden data can be any data type, such as a compressed image, compressed audio and ASCII codes. Additionally, it can be used for secure real time conversation between two parties by hiding speech messages with half the resolution and sampling frequency or the same resolution and a quarter of the sampling frequency of the cover audio, where the cover audio can be a music or speech signal at any standard sampling frequency.