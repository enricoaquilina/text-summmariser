@&#MAIN-TITLE@&#
Behavior-aware user response modeling in social media: Learning from diverse heterogeneous data

@&#HIGHLIGHTS@&#
A hierarchical ensemble learning framework is proposed for behavior-aware user response modeling using diverse heterogeneous data.A data transformation and feature extraction strategy is developed to transform the large-scale and multi-relational data into customer-centered high-order tensors.An improved H-MK-SVM is developed to integrate the external, tag and keyword, individual behavioral and engagement behavioral data for feature selection from multiple correlated attributes and ensemble learning.

@&#KEYPHRASES@&#
Data mining,Direct marketing,Response modeling,Social media,Engagement behavior,

@&#ABSTRACT@&#
With the rapid development of Web 2.0 applications, social media have increasingly become a major factor influencing the purchase decisions of customers. Longitudinal individual and engagement behavioral data generated on social media sites post challenges to integrate diverse heterogeneous data to improve prediction performance in customer response modeling. In this study, a hierarchical ensemble learning framework is proposed for behavior-aware user response modeling using diverse heterogeneous data. In the framework, a general-purpose data transformation and feature extraction strategy is developed to transform the heterogeneous high-dimensional multi-relational datasets into customer-centered high-order tensors and to extract attributes. An improved hierarchical multiple kernel support vector machine (H-MK-SVM) is developed to integrate the external, tag and keyword, individual behavioral and engagement behavioral data for feature selection from multiple correlated attributes and for ensemble learning in user response modeling. The subagging strategy is adopted to deal with large-scale imbalanced datasets. Computational experiments using a real-world microblog database were conducted to investigate the benefits of integrating diverse heterogeneous data. Computational results show that the improved H-MK-SVM using longitudinal individual behavioral data exhibits superior performance over some commonly used methods using aggregated behavioral data and the improved H-MK-SVM using engagement behavioral data performs better than using only the external and individual behavioral data.

@&#INTRODUCTION@&#
Mass marketing and direct marketing are two commonly used approaches for product (service) advertising and promotional activities (Bose &#38; Chen, 2009). For direct marketing, a marketing message is delivered to target customers without an intermediary person or indirect media involved (Bose &#38; Chen, 2009). Customer response modeling aims at identifying the target customers who will respond to a specific marketing campaign from the existing customer base (Cui, Wong, &#38; Zhang, 2010; Kang, Cho, &#38; MacLachlan, 2012). With more and more companies adopting direct marketing, customer response modeling has become one of the most effective direct marketing strategies to increase total revenue and decrease marketing cost (Cui, Wong, &#38; Lui, 2006; Kang et al., 2012; Lee, Shin, Hwang, Cho, &#38; MacLachlan, 2010). Because the purpose is to identify customers as possible respondents and non-respondents to a specific marketing campaign (Bose &#38; Chen, 2009; Lee et al., 2010), customer response modeling is a binary classification problem.For customer response modeling, external and behavioral data are usually used (Bose &#38; Chen, 2009). Customer demographic, geographic and lifestyle data are often obtained from external data vendors (Baecke &#38; Van den Poel, 2011), and thus are called external data. Customer behavioral data including transaction records, feedbacks to marketers, customer reviews and Web browsing records are considered to be the most important data in customer response modeling (Bose &#38; Chen, 2009). Many supervised and semi-supervised machine learning techniques have been proposed for the customer response modeling problem (Lessmann &#38; Voß, 2008). These techniques include artificial neural networks (ANN) (Crone, Lessmann, &#38; Stahlbock, 2006; Kim, Street, Russell, &#38; Menczer, 2005), decision trees (Crone et al., 2006), Bayesian networks (Baesens, Viaene, Van den Poel, Vanthienen, &#38; Dedene, 2002; Cui et al., 2006), logistic regression (Kang et al., 2012), bagging (Ha, Cho, &#38; MacLachlan, 2005), support vector machines (SVM) (Crone et al., 2006; Kang et al., 2012; Lessmann &#38; Voß, 2009) and transductive SVMs (Lee et al., 2010). Moreover, some other techniques including clustering (Kang et al., 2012), sampling (Crone et al., 2006; Kang et al., 2012), sequential pattern discovery (Chen, Hsu, &#38; Hsu, 2011), feature selection (Cui et al., 2010) and other preprocessing methods (Crone et al., 2006) have been combined with classification techniques to refine the customer base and improve prediction performance.In the age of Web 2.0, social media sites develop rapidly. Social media refers to a group of online applications allowing the creation and exchange of user-generated contents (Kaplan &#38; Haenlein, 2010). The most popular types of social media include wikis, blogs, microblogs, social networks, video and photo sharing and online communities. They become popular communication tools due in part to the open access of the Internet, the popularity of mobile devices, the availability of the tools and the fast social interactions among users. Social media have increasingly become a major factor influencing the opinions, attitudes and the purchase behavior of customers (Mangold &#38; Faulds, 2009).User behavioral data generated and collected on social media sites include two categories, i.e., individual behavioral data and engagement behavioral data. Moreover, according to the ways of using the behavioral data in the customer response models, user behavioral data can be classified as longitudinal behavioral data and aggregated behavioral data. Fig. 1illustrates the different types of behavioral data. For traditional customer response modeling, the longitudinal individual behavioral variables derived from the transactional databases are usually transformed into the aggregated variables such as recency, frequency and monetary (RFM) variables which have been included in most direct marketing datasets and adopted in most response models (Baesens et al., 2002; Crone et al., 2006; Cui et al., 2010).In comparison with individual behavior, customer engagement behavior, as an emerging concept, focuses on the customers’ behavioral manifestation beyond purchase such as electronic word-of-mouth, customer–customer interaction, recommendations, blogging and online reviews (van Doorn et al., 2010). In social media, customer engagement behavior has great effect on the individual purchase decisions (Cheung &#38; Thadani, 2012; Dellarocas, 2003; van Doorn et al., 2010). For example, Dell gained high income by posting offers to its followers on Twitter (Li &#38; Li, 2013). A survey showed that 91 percent of respondents said that they consulted online reviews before purchasing, and 46 percent of respondents believed that the online reviews influenced their purchase decisions (Cheung &#38; Thadani, 2012). Therefore, incorporating engagement behavioral data into customer analytical models is increasingly recognized as a new direction of customer relationship management and direct marketing (Bijmolt et al., 2010).The aggregated individual behavioral attributes are usually used as predictors in most customer response models. Few existing studies of customer response modeling pay attention to the longitudinal individual and engagement behavioral data which are widely available in the social media databases. In recent years, the analysis of engagement behavior has been used widely in the areas of recommendation and customer churn prediction. Some researchers combined the extended factorization model with other methods such as additive forest, logistic regression and scorecard model to predict the top-N items the customer was most likely to follow using the aggregated customer–customer interaction data (Chen, Liu, et al., 2012; Chen, Tang, et al., 2012; Zhao, 2012). The information of individual customers and a group of customers which have similar characteristics was used in a novel customer profile model for product recommendation (Park &#38; Chang, 2009). For customer relationship management of the telecommunication industry, the customer–customer interaction data have been recognized as important complements to traditional behavioral data. The aggregated engagement behavioral attributes were combined with traditional attributes to predict customer churn (Zhang, Zhu, Xu, &#38; Wan, 2012).Some researchers recognized that customer purchase behavior varies over time and the use of the longitudinal individual behavioral data can improve prediction performance (Chen, Fan, &#38; Sun, 2012; Liu, Lai, &#38; Lee, 2009). Sequential pattern analysis was combined with collaborative filtering for temporal purchase behavioral data to improve recommendation performance (Cho, Cho, &#38; Kim, 2005; Choi, Yoo, Kim, &#38; Suh, 2012; Huang &#38; Huang, 2009; Liu et al., 2009; Min &#38; Han, 2005). Prinzie and Van den Poel (2006, 2007, 2011) incorporated customer purchase sequence into dynamic Bayesian networks and Markov models to predict the next product for a customer to buy. Ballings and Van den Poel (2012) studied the problem of how long the customer historical data should be for customer churn prediction. They suggested that selecting a good length of historical data can decrease computational burden.For social media, the term Item may represent a specific user, organization, product (service) or event. Examples of events include the appearance of a new term or keyword, the announcement of a new product (service) or activity, or a new price of an existing product (service). The rich behavioral data generated on social media sites can be used for managers to predict user responses to an Item, make marketing policies and allocate marketing resources to influence customer behavior (Power &#38; Phillips-Wren, 2011). For social media, customer response modeling is also called user response modeling, and the two terms are used interchangeably. In this study, customer response modeling taking into consideration of user behavioral, e.g., longitudinal individual and engagement behavioral, data is called behavior-aware user response modeling. However, the large, diverse and heterogeneous data generated on social media sites bring great challenges on behavior-aware user response modeling (Bijmolt et al., 2010; Cao, Ou, &#38; Yu, 2012; Chau &#38; Xu, 2012).How to deal with diverse heterogeneous data is a challenge. A variety of methods can be used for customer response modeling using external and aggregated individual behavioral data. However, to the best of our knowledge, this study is the first attempt of combining the individual behavioral and the engagement behavioral data, as well as the longitudinal and the external data for user response modeling in social media.How to deal with large amount of data is another challenge. Social media sites produce large amount of user data. For example, the daily volume of posts mentioning some well-known brands or products such as Google, Microsoft, Sony, iPhone and iPad in Twitter is in the millions (Li &#38; Li, 2013). It is necessary to use marketing intelligence methods to automatically analyze the massive amount of data. The analysis of the massive amount of data requires efficient preprocessing of the data and excellent scalability of the customer response models.In this study, a hierarchical ensemble learning framework is developed for behavior-aware user response modeling in social media. In the framework, a general-purpose data preprocessing strategy is proposed to transform the large-scale and multi-relational user datasets derived from social media sites into high-order tensors and to extract attributes as input of the models. An improved hierarchical multiple kernel SVM (H-MK-SVM), as an extension of the SVM and the multiple kernel SVM (MK-SVM), is developed to model diverse heterogeneous data including external, tag and keyword, individual behavioral and engagement behavioral data. Because of the multi-relations of the individual behavioral and engagement behavioral data, one advantage of the improved H-MK-SVM is its ability in adaptively selecting associated attributes. Another advantage of this method is its ability in integrating the diverse heterogeneous social media data into a unified ensemble classifier to improve the prediction performance. Furthermore, the subagging strategy (Paleologo, Elisseeff, &#38; Antonini, 2010) is adopted to deal with large imbalanced datasets and ensemble methods are used to combine the results of subagging.This paper is organized as follows. The next section presents the hierarchical ensemble learning framework for behavior-aware user response modeling in social media. Section 3 describes the database used in the study and presents the data preprocessing strategy. The model formulation of the improved H-MK-SVM is presented in Section 4. The computational results are reported in Section 5. Conclusions and directions for future research are given in Section 6.In this section, diverse heterogeneous data used for user response modeling in social media are discussed. A hierarchical ensemble learning framework is then proposed for user response modeling in social media using the diverse heterogeneous data.User response modeling in social media involves diverse heterogeneous data. In general, two categories of data, i.e., external data and behavioral data (Bose &#38; Chen, 2009), are used for customer response modeling. The external data include the demographic, lifestyle and geographic data of the customers (Bose &#38; Chen, 2009). For social media, tags and keywords make up another type of external data. A tag is a word, sign or image selected by a user as his/her descriptions and a keyword is a word with special meaning extracted from the contents of a media site such as a tweet, a retweet and comments generated by users. Tags and keywords are usually used for the descriptions of users’ interests (Chen, Liu, et al., 2012). In comparison with the external data, the behavioral data are more diverse and informative. As shown in Fig. 1, the behavioral data can be grouped into individual behavioral data and engagement behavioral data, and can also be grouped into aggregated behavioral data and longitudinal behavioral data. The aggregated individual behavioral data are usually used in more traditional user response models. The RFM and historical records of user responses are the commonly used behavioral attributes. With the rapid development of social media, firms can easily collect large amount of longitudinal engagement behavioral data. These informative and valuable data have the potential to significantly improve the prediction performance of response models.For the external data and the behavioral data, each customer is treated as an observation and n is used to represent the number of observations in the dataset. A customer is a respondent if the customer responds to an Item or takes action after an event, such as a specific marketing campaign, or a non-respondent otherwise. In the binary classification problem of customer response modeling, customer i is assigned the class label yi= 1 if the customer is a respondent or yi= −1 if the customer is a non-respondent. The value of yiis the desired output of the models for observation i.External data can be represented by a matrix S in which each row represents an observation and each column represents a static variable. In a dataset with m1 variables, the attributes of a customer i is usually represented by a vector si= {sij|j = 1, …, m1}. Different from numerical data, tags and keywords are usually described as textual or symbolic data and represented by a matrixS^. A vectors^i={s^ij^|j^=1,…,m2}is used to represent the tags and keywords of a customer i where m2 is the number of tags and keywords.All standard data mining tasks, including classification, regression and clustering, and the corresponding data mining methods require the input data to be organized as a rectangular matrix. However, the longitudinal individual behavioral data are described as customer-centered multivariate time series of fixed length (Chen, Fan, et al., 2012). A tensor is a multi-dimensional array which can be considered as the generalization of vectors and matrices. A first-order tensor is a vector, a second-order tensor is a matrix, and a tensor with three or higher orders is called a high-order tensor (Kolda &#38; Bader, 2009). Therefore, the longitudinal individual behavioral data can be represented by a third-order tensorB={Bi|i=1,…,n}. The input of each customer i is represented by a rectangular matrixBi={bij˜t|j˜=1,…,m3;t=1,…,T}where m3 represents the number of longitudinal individual behavioral attributes and T represents the number of time points in each longitudinal behavioral variable.In social media, social links among users carry informative information for user response modeling. For example, because of the social links between users A and B, incorporating the behavioral data of user B into the response models may improve the prediction performance of user A. In this study, the engagement behavioral data are defined as the customer-centered behavioral data of a fixed number of followees of a customer. As shown in Fig. 1, the engagement behavioral data can be longitudinal or aggregated. In this study, only the longitudinal engagement behavioral data are used. The longitudinal engagement behavioral data can be represented by a fourth-order tensorB^={B^i|i=1,…,n}. The input of each customer i is represented by a third-order tensorB^i={b^ij′t^f|j′=1,…,m4;t^=1,…,T^;f=1,…,N}where m4 represents the number of longitudinal individual behavior attributes of each followee f,T^represents the number of time points in each longitudinal engagement behavioral variable and N represents the number of followees. Each input of a followee f, as longitudinal individual behavioral data, can be represented by a third-order tensorB^f={b^ij′t^f|i=1,…,n;j′=1,…,m4;t^=1,…,T^}.These four types of data are illustrated in Fig. 2. Dealing with the heterogeneous and high-order tensor data is an essential problem in user response modeling and is discussed in the next sub-section.Targeting potential customers using large, diverse and heterogeneous data generated on social media sites is a difficult task. Three difficult issues need be addressed: (1) identifying the most useful data and generating the customer-centered individual and engagement behavioral datasets; (2) selecting associated attributes from coupled individual and engagement behavioral data; (3) integrating the diverse heterogeneous social media data into a classification model to predict user responses.A hierarchical ensemble learning framework, as illustrated in Fig. 3, is proposed for user response modeling using external, tag and keyword, longitudinal individual behavioral and longitudinal engagement behavioral data. The framework can be organized into three layers. In Layer 1, the original datasets are transformed into customer-centered external, tag and keyword, longitudinal individual and longitudinal engagement behavioral datasets, and the subagging method is used to divide the large training sets into multiple small subsets. In Layer 2, features are selected from the longitudinal individual and engagement behavioral data. In Layer 3, multiple ensemble classifiers are trained on training subsets using the four types of data and the results of these ensemble classifiers are combined. The major tasks of the hierarchical ensemble learning framework are described in the following.In Layer 1 of the proposed hierarchical ensemble learning framework, the original large-scale and multi-relational datasets are preprocessed to generate relatively small-size datasets and are transformed into customer-centered datasets including external data S andS^, longitudinal individual behavioral dataBand customer-centered social network data. Longitudinal individual behavioral dataBand social network data are simultaneously used for feature extraction to obtain longitudinal engagement behavioral dataB^. The subagging method is then used to generate small-size balanced training datasets. The details of data transformation, feature extraction and subagging are discussed using a real database in Section 3.The customer–customer interactions make the individual and engagement behavioral data coupled with each other (Cao et al., 2012). It is difficult to analyze and model the coupled behavioral data partially because of the multi-correlation among the large amount of longitudinal behavioral attributes. Associated attribute selection, as an important task in Layer 2 of the proposed hierarchical ensemble learning framework, is an effective method to reduce the redundant attributes to improve prediction performance (Buckinx, Moons, Van den Poel, &#38; Wets, 2004; Crone et al., 2006). For this task, a sparse modeling method is adopted to learn the weights of the longitudinal behavioral attributes, and the attributes with non-zero weights are kept as associated attributes.In Layer 3 of thehierarchical ensemble learning framework, different types of kernels are adopted to model the external, tag and keyword, longitudinal individual behavioral and longitudinal engagement behavioral data. An ensemble classifier is developed to combine these types of data using the weights of the longitudinal behavioral attributes obtained by associated attribute selection. Furthermore, the results of these ensemble classifiers on local training subsets are combined to achieve better performance.Most existing classifiers cannot combine the above mentioned four types of data to model customer responses. Therefore, a hierarchical ensemble learning method, the improved H-MK-SVM based on the work of Chen, Fan, et al. (2012), is developed for associated attribute selection and ensemble learning.In this section, the database used for the computational experiments is introduced first. The data transformation and feature extraction strategies for heterogeneous high-dimensional and multi-relational datasets are then described in detail using this database. The subagging strategy is then discussed.A real-world database provided by Tencent Weibo11http://kddcup2012.org/c/kddcup2012-track1/data.is used in the computational experiments. Microblogs, as mainstream social media, become a new marketing platform of electronic word-of-mouth (Li &#38; Li, 2013). Tencent Weibo is one of the largest microblog websites in China. In the database, four datasets including Rec-log-training, User Profile, Item and User SNS were used in the following experiments. The characteristics of the database are given in Table 1.The Rec-log-training dataset contains 73,209,277 historical records about users’ responses to different Items over a span of 31 days. Each observation in the Rec-log-training dataset records the response of a user to an Item at a time. The time period of the dataset is from October 13 to November 12, 2011. The User Profile dataset is the only customer-centered dataset in the database. This dataset records the Year of Birth, the Gender and the Number of Tweets of each of the 2,320,895 users with numerical values. It also records the tags of the users with strings. There are 6095 Items in 377 categories in the Item dataset. Each single Item belongs to a hierarchical category, e.g., Category 1.1.1.1. The Category and Keywords of each Item are recorded in the Item dataset with strings. The User SNS dataset contains the follow history of each user. There are 50,655,143 records in the User SNS dataset. The relationships of the customer–customer interactions are derived from the follow history.In the four datasets mentioned above, the User Profile dataset is an example of external and tag data, the Rec-log-training dataset is the basis of longitudinal individual behavioral data, the User SNS and Rec-log-training datasets are the bases of longitudinal engagement behavioral data. How to transform the Rec-log-training and User SNS datasets into longitudinal individual and engagement behavioral data is an important issue and will be discussed in the next subsection.Data preprocessing is a prerequisite phase of a data mining system and has a significant impact on the performance of the data mining methods (Crone et al., 2006). With huge volume and large variety of data in the big data age, data preprocessing and scalability of the algorithms are two key ways to make standard data mining methods suitable for knowledge discovery from big data. For heterogeneous high-dimensional and multi-relational data in social media, data preprocessing include two distinct steps, i.e., data transformation and feature extraction.Data transformation and feature extraction from unstructured text and Web log data, as data preprocessing techniques, have been well studied in the last two decades (Sarawagi, 2007). However, relatively few studies focus on data transformation and feature extraction from heterogeneous high-dimensional and multi-relational data (Lahbib, Boulle, &#38; Laurent, 2014). This is partly due to the fact that most multi-relational classification methods such as link-based classification only use local (non-network) attributes and univariate class labels of network neighbors (Macskassy &#38; Provost, 2007). A few multi-relational classification methods use multivariate network attributes derived from graph theory and social network analysis (Hill, Provost, &#38; Volinsky, 2006; Zhang et al., 2012). In this study, novel data transformation and feature extraction methods are presented to transform heterogeneous high-dimensional and multi-relational data into multiple customer-centered high-order tensors which contain both the relationship and transactional information. Thus, these data can be used by the hierarchical ensemble learning methods.In the computational experiments, Microsoft Access 2010 was used to store the original database and Microsoft Excel 2010 was used to transform the original large-scale and multi-relational datasets into customer-centered datasets. Each single Item has a small number of labeled samples. Therefore, data on the responses to Items belonging to specific categories, rather than to a single Item, are analyzed. Data on responses to Items belonging to 10 categories randomly selected from the 377 categories are analyzed and used in the computational experiments. The historical records in the period from October 13 to November 9, October 14 to November 10 and October 15 to November 11 (T = 28) were used to train, validate and test the improved H-MK-SVM models, respectively. The records on November 10, 11 and 12 were used to label customers as respondents or non-respondents in the training, validation and testing sets, respectively. Thus, the observations (users) having responses, i.e., accepted or not, to a specific category on November 10, 11 or 12 were kept in, and those not having responses were deleted from, the training, validation or testing dataset, respectively.Computationalexperiments were conducted first without using the engagement behavioral data. Microsoft query in Microsoft Excel 2010 was used in selecting the observations with the Items in each selected category into the Training dataset. Pivot Table in Microsoft Excel 2010 was used to transform the data of the selected observations into customer-centered longitudinal individual behavioral data represented by third-order tensors. As shown in Fig. 2, in the transformed datasets, each row represents the historical record of a user, each column represents the historical records of all users in a day and each dataset represents a longitudinal attribute with time length T = 28. Pivot Table in Microsoft Excel 2010 was then used to transform the User Profile dataset into the external dataset to obtain the same observations (users) as those in the longitudinal individual behavioral dataset. Observations with missing values in the external dataset were deleted. The empty values in the tag dataset were all set to zero.The characteristics of the external data with numerical values, the tag data and the longitudinal individual behavioral data are presented in the first three rows in Table 2. The external dataset has m1 = 2 variables, i.e., gender and the number of tweets, and the tag dataset has m2 = 10 tags. The longitudinal individual behavioral dataset has m3 = 2 variables including the number of responses per day in the corresponding period mentioned above (Quantity) and whether or not the user accepted the recommendation of the Items in the category in the corresponding period (Acceptance). Instead of statically derived behavioral attributes used in most response models (Kang et al., 2012), longitudinal behavioral attributes with fixed time interval, i.e., Quantity and Acceptance, are directly extracted from the original transactional records to keep original information and make the feature extraction method suitable for general response modeling problems. The response variable yifor a customer i indicates whether or not the user accepted the recommendation of the Items in the category on November 10, 11 or 12 for the training, validation or testing set, respectively.Computational experiments were then conducted by incorporating the engagement behavioral data into user response modeling. Pivot Table of Microsoft Excel 2010 was used to transform the User SNS dataset into the customer-centered social network dataset. Pivot Table of Microsoft Excel 2010 was then used to transform two relational datasets, i.e., the customer-centered social network and the longitudinal individual behavioral datasets, into customer-centered longitudinal engagement behavioral dataset. Because the engagement behavioral data are the customer-centered behavioral data of followees of the customers, the same m4 = 2 variables, i.e., Quantity and Acceptance, as those in the longitudinal individual behavioral dataset are in this dataset. The values of Quantity and Acceptance for the observations without followees were all set to zero. Hence, the longitudinal engagement behavioral dataset has the same observations as those in the longitudinal individual behavioral dataset. As shown in Fig. 2, the longitudinal engagement behavioral data is represented by a fourth-order tensor. A weighted average strategy can be used to aggregate the fourth-order tensor into a third-order tensor along the followee dimensionB^={b^ij′t|i=1,…,n;j′=1,…,m4;t=1,…,T}, and thus decrease the layers of the hierarchical ensemble methods. For example, the tie strength derived from social network analysis can be used as the weights of different followees. In this study, a simple average is used due to the lack of tie strength information. The characteristics of the longitudinal engagement behavioral data are presented in the last row in Table 2.A common normalization method was applied to the external, longitudinal individual behavioral and longitudinal engagement behavioral data to rescale the values of each variable to the range between 0 and 1. A holdout validation approach was used. Each dataset is partitioned into three roughly equal sets, i.e., a training set, a validation set and a testing set. For customer response modeling, the number of respondents is usually much smaller than the number of non-respondents (Cui et al., 2006; Lee et al., 2010). For example, the response rate is 8.78 percent with 1979 respondents and 20,569 non-respondents for Items belonging to Category 1.1.1.1 in the original database.Sampling methods including undersampling and oversampling are the most commonly used techniques for dealing with highly imbalanced data (Burez &#38; Van den Poel, 2009; Chen, Fan, et al., 2012; Kang et al., 2012; Verbeke, Dejaeger, Martens, Hur, &#38; Baesens, 2012). Undersampling is more suitable for large-scale datasets than oversampling by sampling only the larger class. However, undersampling ignores large amount of data resulting in small samples (Verbeke et al., 2012). The sampling ratio θ is defined to be the number of non-respondents over the number of respondents in the sample. Bagging is a state-of-the-art ensemble learning method. In comparison with boosting, bagging has the advantage of better scalability. For bagging, the training of the model using different training sets can be conducted in parallel and the results of different training sets can be combined by diverse ensemble methods such as majority voting (MV) and averaging (AV) (Polikar, 2006). The subagging method (Paleologo et al., 2010) can deal with the small sample problem and improve the scalability of the proposed hierarchical ensemble learning framework. Therefore, the subagging method (Paleologo et al., 2010) is used to divide imbalanced training sets into v non-overlapping balanced subsets22The number of non-overlapping subsets v roughly equals the number of observations in the training set divided by the number of observations in a training subset. With the subagging strategy given a sampling ratio θ = 1, the number of observations in a training subset is two times of the number of respondents in the training subset.each with equal number of respondents and non-respondents, i.e., with a sampling ratio θ = 1. Classification models usually perform better using roughly balanced training sets than using highly imbalanced training sets. This is especially true for the true positive rate.An improved H-MK-SVM, based on the work of Chen, Fan, et al. (2012), is developed in the hierarchical ensemble learning framework. The H-MK-SVM is an extension of the SVM and the MK-SVM. The SVM is one of the most popular and effective machine learning techniques and usually has excellent classification performance in practical applications (Vapnik, 1998). The MK-SVM, as an important extension of the SVM, can integrate heterogeneous data and adaptively select the best combinations of multiple basic kernels in the learning process. The H-MK-SVM was developed to model longitudinal individual behavioral data for the application of customer churn prediction (Chen, Fan, et al., 2012). A three phase training algorithm for the H-MK-SVM is developed to sequentially learn the Lagrange multipliers, the weight of each longitudinal behavioral attribute and the weight of each single feature basic kernel. Chen, Fan, et al. (2012) provided more details about the MK-SVM and the H-MK-SVM.The improved H-MK-SVM includes two sequential tasks, i.e., the associated attribute selection and ensemble learning. Each task adopts a two phase training algorithm to sequentially learn the Lagrange multipliers and the weight of each basic kernel. The associated attribute selection is adopted to deal with multi-relations of the individual and engagement behavioral data. Different types of kernels used to model the four types of data are then combined to obtain the final model by ensemble learning. As shown in the hierarchical ensemble learning framework, the associated attribute selection by the improved H-MK-SVM in Layer 2 is discussed first and the ensemble learning by the improved H-MK-SVM in Layer 3 is discussed next. Finally, kernels used for the four types of data and the method of parameter tuning are described.In Layer 2 of the hierarchical ensemble learning framework, the training dataset of the improved H-MK-SVM isG={(B1,B^1,y1),…,(Bn,B^n,yn)}with the longitudinal individual and engagement behavioral data. The desired output of the model for each observation yiis the class membership of the customer, i.e., a respondent or a non-respondent. The improved H-MK-SVM in Layer 2 of the hierarchical ensemble learning framework constructs a hyperplane in a high dimensional feature space(1)f(Bi,B^i)=∑j˜=1m3∑t=1Twj˜tT·ϕj˜t(bij˜t)+∑j′=1m4∑t′=1T^w˜j′t′T·ϕ˜j′t′(b^ij′t′)+b′,whereϕj˜t(bij˜t)andϕ˜j′t′(b^ij′t′)are the nonlinear maps,wj˜tTandw˜j′t′Tare the vectors of weights and b' is the bias.For the longitudinal individual behavioral data, the multiple kernel (2) in the following is used to map the elements of the input matrices Biinto high-dimensional feature spaces via the nonlinear mapsϕj˜t(bij˜t)(2)K3(Bi,Bı˜)=∑j˜=1m3∑t=1Tγj˜tkj˜t(bij˜t,bı˜j˜t),wherekj˜t(bij˜t,bı˜j˜t)=ϕj˜t(bij˜t)·ϕj˜t(bı˜j˜t)is the basic kernel andγj˜tis the weight ofkj˜t(bij˜t,bı˜j˜t). For the longitudinal engagement behavioral data, a similar multiple kernel (3) in the following is used to map the elements of the input matricesB^iinto feature spaces via the nonlinear mapsϕ˜j′t′(b^ij′t′)(3)K4(B^i,B^ı˜)=∑j′=1m4∑t′=1T^γ^j′t′kj′t′(b^ij′t′,b^ı˜j′t′),wherekj′t′(b^ij˜t′,b^ı˜j˜t′)=ϕ˜j′t′(b^ij′t′)·ϕ˜j′t′(b^ı˜j′t′)is the basic kernel andγ^j′t′is the weight ofkj′t′(b^ij′t′,b^ı˜j′t′). When convenient,γandγ^are used to denote the vectors of all the weights of the basic kernels in (2) and (3), respectively, andγ′=(γ,γ^)is used to denote the composite vector consisting of the elements ofγandγ^. The values of the elements ofγ'are determined in the attribute selection process.When the multiple kernels in (2) and (3) are used, the improved H-MK-SVM in Layer 2 of the ensemble learning framework is formulated as the following quadratic program(4)minγ′minw,w˜,ξ,b′12{∑j˜=1m3∑t=1T∥wj˜t∥2γj˜t+∑j′=1m4∑t′=1T^∥w˜j′t′∥2γ^j′t′}+C∑i=1nξi(5)s.t.yi(∑j˜=1m3∑t=1Twj˜tT·ϕj˜t(bij˜t)+∑j′=1m4∑t′=1T^w˜j′t′T·ϕ˜j′t′(b^ij′t′)+b′)≥1−ξi,fori=1,…,n(6)ξi≥0,fori=1,…,n(7)γj˜t≥0,forj˜=1,…,m3,t=1,…,T(8)γ^j′t′≥0,forj′=1,…,m4,t′=1,…,T^,where C is the regularization parameter, ξiis the relaxation or the error term of observation i,ξis a vector with ξias its elements, w is a composite vector of allwj˜tandw˜is a composite vector of allw˜j′t′.A two-phase iterative procedure (Chen, Fan, et al., 2012) is used to decompose the problem in (4)–(8) into two sub-problems and to solve them iteratively. In phase 1, the values of the elements ofγ'are fixed and the dual of (4)–(8) is solved. The dual is stated as the quadratic program in (9)–(11) in the following(9)maxα∑i=1nαi−12∑i=1n∑ı˜=1nαiαı˜yiyı˜(K3(Bi,Bı˜)+K4(B^i,B^ı˜))(10)s.t.∑i=1nyiαi=0(11)0≤αi≤C,fori=1,…,nwhere αiis the Lagrange multiplier or the dual variable of observation i andαis a vector with αias its elements. The values of the dual variables are determined after the dual in (9)–(11) is solved. Using the values of the dual variables obtained in phase 1, the primal variableswj˜tTandw˜j′t′Tcan be written as (12) and (13), respectively, in the following(12)wj˜t=γj˜t∑i=1nyiαiϕj˜t(bij˜t),forj˜=1,…,m3,t=1,…,T(13)w˜j′t′=γ^j′t′∑i=1nyiαiϕ˜j′t′(b^ij′t′),forj′=1,…,m4,t′=1,…,T^In phase 2, the values of b' and the components ofwj˜tTandw˜j′t′Tare fixed. Using the primal variableswj˜tTandw˜j′t′Tin (12) and (13), the original problem in (4)–(8) can be rewritten as(14)minγ′,ξ12∑i=1n∑ı˜=1nαiαı˜yiyı˜(∑j˜=1m3∑t=1Tγj˜tk(bij˜t,bı˜j˜t)+∑j′=1m4∑t′=1T^γ^j′t′k(b^ij′t′,b^ı˜j′t′))+λ∑i=1nξi(15)s.t.yi{∑ı˜=1nαı˜yı˜(∑j˜=1m3∑t=1Tγj˜tk(bij˜t,bı˜j˜t)+∑j′=1m4∑t′=1T^γ^j′t′k(b^ij′t′,b^ı˜j′t′))+b˜}≥1−ξi,fori=1,…,n(16)ξi≥0,fori=1,…,n(17)γj˜t≥0,forj˜=1,…,m3,t=1,…,T(18)γ^j′t′≥0,forj′=1,…,m4,t′=1,…,T^,where λ is the regularization parameter and αiis the Lagrange multiplier of observation i obtained in phase 1. Because minimizing the L1-norm based regularization function (14) leads to sparse solutions for the elements ofγ', the solution process of the problem (14)–(18) is also a feature selection process. The solution of this problem can be obtained by solving its dual. The dual is stated in (19)–(23) in the following(19)maxu∑i=1nui(20)s.t.∑i=1nuiyi∑ı˜=1nαı˜yı˜k(bij˜t,bı˜j˜t)≤12∑i=1n∑ı˜=1nαiαı˜yiyı˜k(bij˜t,bı˜j˜t),forj˜=1,…,m3,t=1,…,T(21)∑i=1nuiyi∑ı˜=1nαı˜yı˜k(b^ij′t′,b^ı˜j′t′)≤12∑i=1n∑ı˜=1nαiαı˜yiyı˜k(b^ij′t′,b^ı˜j′t′),forj′=1,…,m4,t′=1,…,T^(22)∑i=1nuiyi=0(23)0≤ui≤λ,fori=1,…,n,where uiis the dual variable of observation i and u is a vector with uias its elements. Sometimes, the weights attached to the elements ofγ'in the objective function (14) can be set to constants to make the linear program in (14)–(18) easier to solve. For example, (24) and (25) in the following can be used in (14)(24)12∑i=1n∑ı˜=1nαiαı˜yiyı˜k(bij˜t,bı˜j˜t)=1(25)12∑i=1n∑ı˜=1nαiαı˜yiyı˜k(b^ij′t′,b^ı˜j′t′)=1.When the variableswj˜tTandw˜j′t′Tin (12) and (13) and the kernels in (2) and (3) are used in (1), the classification function constructed by the improved H-MK-SVM in Layer 2 of the hierarchical ensemble learning framework is(26)Y(Bı˜,B^ı˜)=sgn{∑i=1nαiyi(K3(Bi,Bı˜)+K4(B^i,B^ı˜))+b′}The bias b' in (26) is computed using (27) in the following(27)b′=yı˜−∑i=1nαiyi(K3(Bi,Bı˜)+K4(B^i,B^ı˜)),forαı˜∈(0,C).In Layer 3 of the hierarchical ensemble learning framework, the input dataset of the improved H-MK-SVM isG˜={(s1,s^1,B1,B^1,y1),…,(sn,s^n,Bn,B^n,yn)}with external and behavioral data. The improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework constructs a hyperplane in a high dimensional feature space(28)f˜(si,s^i,Bi,B^i)=β1w^T·ϕ^(si)+β2w′T·ϕ′(s^i)+β3∑j˜=1m3∑t=1Tw¯j˜tT·ϕj˜t(bij˜t)+β4∑j′=1m4∑t′=1T^w⌢j′t′T·ϕ˜j′t′(b^ij′t′)+b˜,whereϕ^(si),ϕ′(s^i),ϕj˜t(bij˜t)andϕ˜j′t′(b^ij′t′)are the nonlinear maps,w^, w',w¯j˜tandw⌢j′t′are the vectors of weights,βm^is the weight of data typem^, andb˜is the bias. In the followingβrepresents a vector withβm^, form^=1,…,4, as its elements.Different kernels are used for different types of data. For the external data with numerical values, the standard single Gaussian kernel, also known as the radial basis function (RBF) kernel, is used(29)K1(si,sı˜)=exp(−1σ12∥si−sı˜∥2),whereσ12is the kernel parameter. For the external data with strings, the string kernel in (30) in the following is used(30)K2(s^i,s^ı˜)=∑j^=1m2I(s^ij^,s^ı˜j^).The following multiple kernel (31) similar to (2) is used for the longitudinal individual behavioral data(31)K˜3(Bi,Bı˜)=∑j˜=1m3∑t=1Tγj˜tkj˜t(bij˜t,bı˜j˜t),wherekj˜t(bij˜t,bı˜j˜t)is the basic kernel andγj˜tis the known weight obtained in Layer 2 of the hierarchical ensemble learning framework. The difference betweenK3(Bi,Bı˜)in (2) andK˜3(Bi,Bı˜)in (31) is thatγj˜tis variable in (2) but known in (31). The following multiple kernel (32) similar to (3) is used for the longitudinal engagement behavioral data(32)K˜4(B^i,B^ı˜)=∑j′=1m4∑t′=1T^γ^j′t′kj′t′(b^ij′t′,b^ı˜j′t′),wherekj′t′(b^ij˜t′,b^ı˜j˜t′)is the basic kernel andγ^j′t′is the known weight obtained in Layer 2 of the hierarchical ensemble learning framework. The difference betweenK4(B^i,B^ı˜)in (3) andK˜4(B^i,B^ı˜)in (32) is thatγ^j′t′in (3) is variable but known in (32).When the kernels in (29), (30), (31) and (32) above are used, the model of the improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework is formulated as(33)minβminw^,w′,w¯,w⌢,ξ˜,b˜12(β1∥w^∥2+β2∥w′∥2+β3∑j˜=1m3∑t=1T∥w¯j˜t∥2γj˜t+β4∑j′=1m4∑t′=1T^∥w⌢j′t′∥2γ^j′t′)+C˜∑i=1nξ˜i(34)s.t.yi(β1w^T·ϕ^(si)+β2w′T·ϕ′(s^i)+β3∑j˜=1m3∑t=1Tw¯j˜tT·ϕj˜t(bij˜t)+β4∑j′=1m4∑t′=1T^w⌢j′t′T·ϕ˜j′t′(b^ij′t′)+b˜)≥1−ξ˜i,fori=1,…,n(35)ξ˜i≥0,fori=1,…,n(36)βm^≥0,form^=1,…,4,whereC˜is the regularization parameter,ξ˜iis the relaxation or error term for observation i,ξ˜is a vector withξ˜ias its elements,w¯is a composite vector ofw¯j˜tandw⌢is a composite vector ofw⌢j′t′.A two-phase procedure is used to solve the problem in (33)–(36). In phase 1, the values of the elements ofβare fixed and the dual of (33)–(36) is solved. The dual is written as(37)maxα˜∑i=1nα˜i−12∑i=1n∑ı˜=1nα˜iα˜ı˜yiyı˜(β1K1(si,sı˜)+β2K2(s^i,s^ı˜)+β3K˜3(Bi,Bı˜)+β4K˜4(B^i,B^ı˜))(38)s.t.∑i=1nyiα˜i=0(39)0≤α˜i≤C˜,fori=1,…,nwhereα˜iis the Lagrange multiplier or the dual variable of observation i andα˜is a vector withα˜ias its elements. The values of the dual variables are determined after the dual is solved. The primal variablesw^and w' are represented by the dual variables in the same way as in the standard SVMs (Chen, Fan, et al., 2012) andw¯j˜tandw⌢j′t′are expressed in similar ways towj˜tandw˜j′t′in (12) and (13).In phase 2, the values ofb˜and the elements ofw^, w',w¯j˜tandw⌢j′t′are fixed. Using the primal variablesw^, w',w¯j˜tandw⌢j′t′, the original problem in (33)–(36) can be rewritten as the linear program in (40)–(43) in the following(40)minβ,ξ˜12∑i=1n∑ı˜=1nα˜iα˜ı˜yiyı˜(β1K1(si,sı˜)+β2K2(s^i,s^ı˜)+β3K˜3(Bi,Bı˜)+β4K˜4(B^i,B^ı˜))+λ˜∑i=1nξ˜i(41)s.t.yi{∑ı˜=1nα˜ı˜yı˜(β1K1(si,sı˜)+β2K2(s^i,s^ı˜)+β3K˜3(Bi,Bı˜)+β4K˜4(B^i,B^ı˜))+b˜}≥1−ξ˜i,fori=1,…,n(42)ξ˜i≥0,fori=1,…,n(43)βm^≥0,form^=1,…,4,whereλ˜is the regularization parameter. The weightsβare obtained after this linear program is solved.When the variablesw^, w',w¯j˜tandw⌢j′t′and the kernels for the four types of data are used in (28), the classification function constructed by the improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework is(44)Y˜(sı˜,s^ı˜,Bı˜,B^ı˜)=sgn{∑i=1nα˜iyi(β1K1(si,sı˜)+β2K2(s^i,s^ı˜)+β3K˜3(Bi,Bı˜)+β4K˜4(B^i,B^ı˜))+b˜}.The biasb˜in (44) is computed using (45) in the following(45)b˜=yı˜−∑i=1nα˜iyi(β1K1(si,sı˜)+β2K2(s^i,s^ı˜)+β3K˜3(Bi,Bı˜)+β4K˜4(B^i,B^ı˜)),forα˜ı˜∈(0,C˜).It should be noted that the improved H-MK-SVM in Layers 2 and 3 of the hierarchical ensemble learning framework play different roles. The one in Layer 2 using two types of behavioral data is for associated attribute selection and the one in Layer 3 obtains the final classification function (44). After associated attribute selection, the H-MK-SVM in Layer 2 can also construct a classification function using just the two types of behavioral data. The hierarchical ensemble learning using the improved H-MK-SVM combines the advantages of sparse modeling with reduced feature sets and the ensemble learning with diverse heterogeneous data and improves the performance of the user response models.In the improved H-MK-SVM, the Gaussian kernel is used for the external data with numerical values in (29) and used as the basic kernels for the longitudinal behavioral data in (2), (3), (31) and (32). For the external data with strings,I(s^ij^,s^ı˜j^)in (30) is given in (46) in the following(46)I(s^ij^,s^ı˜j^)={1,if(s^ij^=s^ı˜j^)0,if(s^ij^≠s^ı˜j^).For the longitudinal individual behavioral attribute Quantity, the following Gaussian kernel in (47) is used as the basic kernel of the multiple kernels (2)(47)kj˜t(bij˜t,bı˜j˜t)=exp(−1σ32∥bij˜t−bı˜j˜t∥2),forj˜=1,whereσ32is the kernel parameter. In the improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework, the same Gaussian kernel (47) is used as the basic kernel of the multiple kernels (31) for the attribute Quantity with a different kernel parameterσ˜32. For the longitudinal individual behavioral attribute Acceptance, i.e.,bij˜twithj˜=2, the same Gaussian kernels (47) with parametersσ42andσ˜42are used as the basic kernels of the multiple kernels in the improved H-MK-SVM in Layers 2 and 3, respectively, of the hierarchical ensemble learning framework.For the longitudinal engagement behavioral attribute Quantity, the Gaussian kernel (48) in the following is used as the basic kernel of the multiple kernels (3)(48)kj′t′(b^ij′t′,b^ı˜j′t′)=exp(−1σ52∥b^ij′t′−b^ı˜j′t′∥2),forj′=1,whereσ52is the kernel parameter. In the improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework, the same Gaussian kernel (48) with parameterσ˜52is used as the basic kernel in the multiple kernels (32) for the attribute Quantity. For the longitudinal engagement behavioral attribute Acceptance, i.e.,b^ij′t′with j' = 2, the same Gaussian kernels (48) and parametersσ62andσ˜62are used in the improved H-MK-SVM in Layers 2 and 3, respectively, of the hierarchical ensemble learning framework.The grid search method (Chen, Fan, et al., 2012) was used to tune the parameters in the improved H-MK-SVM. For the improved H-MK-SVM in Layer 2 of the hierarchical ensemble learning framework, exponentially growing values for λ, C,1/σ32,1/σ42,1/σ52and1/σ62from 10−2 to 102 were tried in turn. For the improved H-MK-SVM in Layer 3 of the hierarchical ensemble learning framework, a nested grid search strategy was used. Exponentially growing values forλ˜,C˜,1/σ˜12,1/σ˜32,1/σ˜42,1/σ˜52and1/σ˜62from 10−2 to 102 were tried first in turn. These parameters were then finely tuned. Additively growing values in the best intervals obtained earlier forC˜,1/σ˜12,1/σ˜32,1/σ˜42,1/σ52and1/σ62were tried in turn. The values of these parameters with the best performance on the validation sets were used to test the performance of the models.Computational resultsare reported in this section. Matlab 7.4 was used to conduct the computational experiments. The desktop computer used for the computation has an Intel Core i7 processor with a 3.40 gigahertz clock speed and has 16 gigabytes of RAM. Eight competitive methods including the SVM, feed-forward ANN (FFANN), radial basis function neural network (RBFNN), decision tree (DT), random forest (RF), Adaboost and the two ensemble methods, i.e., MV and AV, were also used in the experiments to compare their performances with that of the improved H-MK-SVM. The Neural Network and the Statistics toolboxes in Matlab 7.4 were used to implement the FFANN, RBFNN and DT.Three criteria including the maximum profit (MP) (Verbeke et al., 2012), the area under the receiver operating characteristic curve (AUC) and the overall hit rate (PCC) are used to measure performances. The MP is a very suitable measure for customer response modeling due to its consideration of both the class distribution and misclassification costs (Verbeke et al., 2012). The MP criteria proposed for churn prediction by Verbeke et al. (2012) can be naturally extended to response modeling by giving different meanings to the parameters.33For response modeling, the parameter α is set to α = 10 percent; the parameter β represents the fraction of true respondents included in the marketing campaign; γ represents the conversion ratio and CLV represents the average customer value in the marketing campaign. When the purchase (click) data are used, the conversion ratio is set to γ = 1(0 ≤ γ ≤ 1). As a special note, α, β and γ mentioned in this footnote are for the computation of the MP only but are not related to the notations in the models.The AUC is a robust estimator of prediction performance (Lee et al., 2010). The LSSVMlab v1.8 toolbox44http://www.esat.kuleuven.be/sita/lssvmlab/.was used for the computation of the AUC. However, it is known that the PCC is often not an appropriate measure for the imbalanced and cost-sensitive classification problems (Verbeke et al., 2012). As shown in the following, a model performing well in terms of MP and AUC may perform poorly in terms of the PCC. The computational results reported in the following are obtained on the testing sets. The mean (Mean) and standard derivation (STD) of each criterion are reported in the following tables.Statistical tests, i.e., ANOVA (analysis of variance) for the differences in means and Fisher’ LSD (least significant difference)-t test for multiple comparisons were conducted. In Tables 3–6, the best result for each measure is highlighted, the results not significantly different from the best result are in italics and those significantly different from the best result are in regular fonts both at the 0.05 significance level. More details of the statistical tests are reported in the Appendix.In the following,user response modeling performances with and without hierarchical ensemble learning are compared. To measure the benefits of using the hierarchical ensemble learning framework, the following five experiments are conducted: (S1) user response modeling based on the hierarchical ensemble learning framework using the external, tag and keyword, and longitudinal individual behavioral data; (S2) user response modeling by the improved H-MK-SVM in Layer 2 using only the longitudinal individual behavioral variable Quantity; (S3) user response modeling by the improved H-MK-SVM in Layer 2 using only the longitudinal individual behavioral variable Acceptance; (S4) user response modeling by the improved H-MK-SVM in Layer 3 using the same data as those under S1; and (S5) user response modeling based on the hierarchical ensemble learning framework without learning the weights of the three types of data in S1, i.e.,βm^=1.For these five experiments, the results of the sub-classifiers used in subagging and of the ensemble of the sub-classifiers using the AV method are reported in Table 3. The measures of the ensemble are computed based on the average of the outputs of the improved H-MK-SVMs on the balanced subsets. As shown in Table 3, the individual H-MK-SVMs under S1 obtained the highest average MP (2.97) and AUC (66.09 percent), and the ensemble of the H-MK-SVMs under S1 obtained the highest MP (2.91) and the second highest AUC (68.62 percent), while that under S5 obtained the best AUC (69.05 percent). Results in Table 3 show that the average MP and AUC of the individual H-MK-SVMs and of the ensemble of the H-MK-SVMs with hierarchical ensemble learning, i.e., S1 and S5, are considerably higher than those of the H-MK-SVMs without hierarchical ensemble learning, i.e., S2, S3 and S4.In the following, the effects of varying time lengths and aggregation scales of the longitudinal individual behavioral data on prediction performance are examined. The results of the ensemble of the improved H-MK-SVMs using the longitudinal individual behavioral data with different time lengths are shown in Table 4. Results in Table 4 show that the improved H-MK-SVM using the behavioral data with T = 28obtained the highest average MP, AUC and PCC. Specially, the MP, AUC and PCC of the improved H-MK-SVM using T = 28are much higher than those using a smaller T. These results show that long enough behavioral data need to be stored in the data warehouse and used in user behavioral analysis.The longitudinal individual behavioral data are aggregated at different scales to examine the effects of these scales on performance. Specifically, the behavioral data are aggregated per day (Scale = 1), i.e., no aggregation, per 2 days (Scale = 2), per 7 days (Scale = 7) and per 28 days (Scale = 28), respectively. The results of the improved H-MK-SVM using longitudinal individual behavioral data with different aggregation scales are also shown in Table 4. As shown in Table 4, the improved H-MK-SVM obtained higher MP, AUC and PCC with Scale = 1 than with all other aggregation scales. Therefore, it is helpful to select a suitable aggregation scale of the longitudinal data.In the following, the performances of the eight competitive methods are compared with that of the improved H-MK-SVM. Because the SVM, FFANN, RBFNN, DT, RF and Adaboost cannot be directly used to model heterogeneous and tensor data, the longitudinal individual behavioral attributes represented by a third-order tensor were aggregated as a matrixO={oij˜|i=1,…,n;j˜=1,…,m3}. Both the external attributes and the aggregated behavioral attributes, i.e., the composite vector xi= [si, oi], were used as inputs in these six methods. For the ensemble methods, one SVM is used to model the external and tag attributes and two SVMs are used to model the longitudinal individual behavioral variables Quantity and Acceptance. The two ensemble methods, i.e., MV and AV, are then used to combine the results of the SVMs. Unlike the RF and Adaboost, the MV and AV can be used to combine different feature sets from heterogeneous data.The results of the improved H-MK-SVM and of the other eight methods on the ten randomly selected categories are presented in Table 5. The improved H-MK-SVM obtained the highest MP, AUC and PCC. As shown in Table 5, the improved H-MK-SVM demonstrated from 0.76 (1.58 percent) to 1.61 (11.87 percent) improvements in the MP (AUC) over the other eight methods. These results show that the improved H-MK-SVM using longitudinal individual behavioral data outperforms the more traditional methods using aggregated individual behavioral data. Therefore, using the longitudinal individual behavioral data in the hierarchical ensemble learning framework improves the performance of user response modeling.In the following, the effects of using the engagement behavioral data on prediction performance are examined. The external, the tag and keyword, the longitudinal individual behavioral and longitudinal engagement behavioral data are input into the improved H-MK-SVM to obtain the classification results. The performances of the improved H-MK-SVM, as well as the other eight competitive methods, incorporating the engagement behavioral data are reported in Table 6. For the SVM, FFANN, RBFNN, DT, RF and Adaboost, both the longitudinal individual and the engagement behavioral attributes were aggregated as O' = {o'ij|i = 1, …, n; j = 1, …, m3 + m4}, and the external attributes and the aggregated behavioral attributes, i.e., the composite vector xi= (si, o'i), were used as input. For the ensemble methods, one SVM is used to model the external and tag attributes, two SVMs are used to model the longitudinal individual variables Quantity and Acceptance, and two SVMs are used to model the engagement behavioral variables Quantity and Acceptance. The MV and AV are then used to combine the results of the SVMs. For the results reported in Table 6, only users with followees are selected into the datasets to investigate the effect of incorporating the engagement behavioral data on the classification performance.As shown in Table 6, the improved H-MK-SVM using the longitudinal engagement behavioral data obtained the highest MP and AUC. The improved H-MK-SVM using the engagement behavioral data demonstrated 0.32 and 1.61 percent improvements in the MP and the AUC, respectively, over the improved H-MK-SVM using only the external and individual behavioral data. These results show that the use of the engagement behavioral data in the improved H-MK-SVM can improve the user response modeling performance. Table 6 also shows that the improved H-MK-SVM using the engagement behavioral data demonstrated from 1.81 (1.85 percent) to 2.46 (15.44 percent) improvements in the MP (AUC) over the other eight methods. Therefore, the performance of the improved H-MK-SVM is obviously superior to those of the other methods using the aggregated behavioral data and of the other ensemble methods.

@&#CONCLUSIONS@&#
In this study, a hierarchical ensemble learning framework is developed for behavior-aware user response modeling in social media using diverse heterogeneous data. In the framework, a general-purpose data transformation and feature extraction strategy is proposed and an improved H-MK-SVM is developed. In comparison with the work of Chen, Fan, et al. (2012) on customer churn prediction, the major contributions of this study are (1) for the original data from social media, a data transformation and feature extraction strategy is proposed to transform heterogeneous high-dimensional multi-relational data into customer-centered high-order tensors and to extract prediction attributes; (2) four types of data, i.e., external, tag and keyword, longitudinal individual behavioral and longitudinal engagement behavioral data, are simultaneously used for the first time as input of response models to improve prediction performance; (3) for classification using heterogeneous data, an improved H-MK-SVM is developed to hierarchically integrate feature selection from multiple correlated attributes and ensemble learning for user response modeling; (4) for large imbalanced datasets, the subagging strategy is adopted to integrate the local results of the improved H-MK-SVMs on multiple sample subsets to obtain better performance.Computational experiments are conducted using a real-world microblog database. The experimental results show that (1) the improved H-MK-SVM with hierarchical ensemble learning exhibits superior performance over that without hierarchical ensemble learning; (2) the improved H-MK-SVM using the longitudinal individual behavioral data demonstrates considerable improvements over the other eight competitive methods; (3) the improved H-MK-SVM using the longitudinal engagement behavioral data demonstrates substantial improvements over the improved H-MK-SVM using only the external and individual behavioral data; and (4) the improved H-MK-SVM using the longitudinal engagement behavioral data demonstrates considerable improvements over the other competitive methods using the aggregated engagement behavioral data. Furthermore, this study investigates the usefulness of selecting a suitable time length and aggregation scale of the longitudinal behavioral data for user response modeling.The hierarchical ensemble learning framework provides valuable implications about how to integrate diverse heterogeneous user data available in the databases of electronic commerce and social media. Integrating multi-channel, multi-network, multi-media (text, video and audio) and unlabeled data into customer relationship management and direct marketing models to improve the prediction performance so as to effectively allocate the marketing resources will be a direction for future research. Selecting the best combination of local classifiers and assigning the best weights to them to improve the performance and stability of the ensemble of the individual H-MK-SVMs deserve further study. Multi-task and multi-class multi-label multiple kernel learning methods may also be investigated as future work to simultaneously obtain the results of multiple categories. Furthermore, investigating the effectiveness of the models by focusing on specific, such as age, gender and RFM, user groups may deserve further study.