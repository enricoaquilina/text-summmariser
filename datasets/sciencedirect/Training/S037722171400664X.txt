@&#MAIN-TITLE@&#
Operational research from Taylorism to Terabytes: A research agenda for the analytics age

@&#HIGHLIGHTS@&#
Identifies a significant lack of research into analytics in operational research orientated publications.Charts the histories of operational research, analytics and a range of related disciplines.Discussed the relationship between these disciplines and how they are perceived by the wider business community.Provides suggested routes for future research that can combine key themes in analytics and operational research.

@&#KEYPHRASES@&#
Analytics,Big data,Data visualisation,History of OR,History of computing,

@&#ABSTRACT@&#
The growing attention and prominence afforded to analytics presents a genuine challenge for the operational research community. Many in the community have recognised this growth and sought to align themselves with analytics. For instance, the US operational research society INFORMS now offers analytics related conferences, certification and a magazine. However, as shown in this research, the volume of analytics-orientated studies in journals associated with operational research is comparatively low. This paper seeks to address this paradox by seeking to better understand what analytics is, and how operational research is related to it. To do so literature from a range of academic disciplines is analysed, in what is conceived as concurrent histories in the shared tradition of a management paradigm spread over the last 100 years. The findings of this analysis reveal new insights as to how operational research exists within an ecosystem shared with several other disciplines, and how interactions and ripple effects diffuse knowledge and ideas between each. Whilst this ecosystem is developed and evolved through interdisciplinary collaborations, individual disciplines are cast into competition for the attention of the same business users. These findings are further explored by discussing the implication this has for operational research, as well as considering what directions future research may take to maximise the potential value of these relationships.

@&#INTRODUCTION@&#
Over its 75 years of existence, operational research/management science (OR/MS) has clearly become a well-established field of study and practice. Despite assertions some thirty-five years ago that “the future of operational research is past” (Ackoff, 1979), the techniques and methodologies are still taught in universities across the globe and regularly used in business decision-making, in both the public and private sectors. However, this is not to say that OR/MS does not face genuine challenges and difficult decisions. One such issue is the relationship the discipline has with the growing field of analytics.Many in the OR/MS community have cited the prominence of analytics as an opportunity that could “promote the […] profession and expand its reach” (Liberatore &#38; Luo, 2010, p. 313). A recent survey of the membership of INFORMS, the US OR/MS society, found 79 percent supported expanding the society’s focus to include analytics (Liberatore &#38; Luo, 2011) and the organisation now offers analytics certification, a magazine on the subject, and an annual conference. Meanwhile, the OR Society in the UK releases a quarterly publication, hosts an analytics network and an annual analytics event, and produces additional online resources. Similarly many practitioners have sought to engage with analytics, or at least adopt the moniker of analytics. Many organisations have changed the name of their departments to include analytics; such as IBM’s Business Analytics and Mathematical Sciences (Sutor, 2013) and Proctor and Gamble’s Global Analytics (Ericson, 2006) teams. However, despite this interest, and the efforts of these organisations, the amount of academic research into analytics published in journals associated with the OR/MS discipline will be shown to be surprisingly low.The purpose of this paper is to review the growing field of analytics and its relationship with OR/MS. The lack of literature, however, makes such a review using a standard approach problematic. Furthermore, it calls into question the actual relationship between OR/MS and analytics. As a result, this paper will consider not just the limited literature relating to OR/MS and analytics, but the key works, developments, and research over the course of the last century that has led to modern-day analytics. Specific emphasis will be placed on how developments in related fields and disciplines interact, how technological innovations and new methodologies impact upon each, and also how their shared histories have created ripple effects through the whole business community. It is through this historical perspective that, we argue, it is possible to understand the current relationship between OR/MS and analytics.This paper will seek to answer three specific research questions:1.What is the relationship between OR/MS and analytics?How could, or should, the OR/MS community react to growing interest in analytics?If the community should seek to increase research into analytics then what specific directions might such research take?The second section of this paper will discuss the current research into analytics within journals traditionally associated with OR/MS, as well as definitions offered across both academic and practitioner literature. The third will consider how we might frame the shared history, conceived as “periods” in the history of a business paradigm, and the fourth will present a historical analysis of this paradigm, including detailed discussions of each period in this history. Finally, the concluding sections summarise the key findings and proposes a new research agenda for OR/MS and analytics in light of this historical analysis.As discussed in the introduction to this paper, “business analytics” as term, concept and practice has seen significant growth in the last decade. Chen, Chiang, and Storey (2012) report the publication of 126 academic articles in business journals in 2011 containing the phrase “business analytics” in the title or abstract, equal to the total published in such journals in the ten years prior (252 articles in total between 2000 and 2011). Similarly, research from various practitioner sources forecasts growing importance of utilising new sources of data and substantial growth in demand for staff with analytical skills (e.g. Manyika et al., 2011).However, despite the connection between OR/MS and analytics suggested above, the amount of research into analytics published in journals associated with the discipline is surprisingly limited. For this study we searched the International Abstracts in Operations Research database for articles that had the term “analytics” in either abstract or title. A summary of this work is shown in the supplementary materials. Of the 23 found in total, 8 were in the INFORMS’ practice-focused journal Interfaces, whilst two more interdisciplinary journals [Decision Support Systems and the Journal of Revenue and Pricing Management] published 4 and 7 respectively. Until the end of 2013 only one paper had been published in this journal, which was primarily focused on a very specific application of financial modelling (Gosh &#38; Troutt, 2012). Compared to the 252 found by Chen et al. (2012) across all business journals, in the OR/MS literature only 13 were found across the same time period (the years up to and including 2011). We are not able to determine whether these 13 articles are also reported in the study by Chen et al. (2012); we suspect that at least some are.There are of course many limitations in this approach. Firstly it is entirely possible that other articles have been published in OR/MS journals that have analytics-related content, however do not use this term in their abstract or title. Secondly there is the potential that academics in the OR/MS community would publish analytics-orientated research in journals not directly associated with OR/MS (e.g. Coghlan et al. (2010)). Whilst these results cannot be considered indubitable, they still act as a strong indicator that there is a considerable disparity between the perceived value of OR/MS research into analytics and the volume of such research currently being produced. This is somewhat tempered by the increased output observed since 2011, and the recent release of Decision Analytics in 2014, a journal that features both analytics and OR/MS content. However, considering that the first academic articles discussing analytics were published in the early 2000s (e.g. Kohavi, Rothleder, &#38; Simoudis (2002)), the tardiness of the OR/MS academic community’s response is surprising enough to warrant further exploration of the underlying causes.One possible reason for the discrepancy between the perceived opportunity analytics may offer to the OR/MS community and the amount of research in the area, as alluded to in above, may be the lack of any clear consensus about analytics’ precise definition, and how it differs from related concepts. Perhaps the most cited definition of analytics is that provided by Davenport and Harris (2007, p. 7):“[T]he extensive use of data, statistical and quantitative analysis, explanatory and predictive models, and fact-based management to drive decisions and actions. The analytics may be input for human decisions or may drive fully automated decisions. Analytics are a sub-set of […] business intelligence.”The claim that analytics is a subset of business intelligence (BI) is a view supported by others such as Bartlett (2013, p. 4) who argues “Business Intelligence=Business Analytics+Information Technology”. However, this is contradicted in other research: Vesset, McDonough, Morris, and Woodward (2009) and SAP (2012) state the opposite view, describing BI as the subset of analytics. The work of Chen et al. (2012), Chiang, Goes, and Stohr (2012) and Lim, Chen, and Chen (2012) sidesteps this by considering the two as a composite, using the acronym “BI&#38;A”. The inference in their work is that the first part of the acronym refers to the technologies that process and manipulate data, and the latter its analysis. A more cynical perspective is that the distinction is essentially superfluous, and that discussion of “analytics” is effectively an attempt to reinvigorate interest in the existing field of BI (Eckerson, 2011; Elliot, 2011).This ambiguity is not confined to the differences between analytics and BI; there are other examples where definitions of analytics can be seen to be very similar to other supposedly separate fields. For example, Laursen and Thorlund (2010, p. XII) define analytics as “delivering the right decision support to the right people at the right time”. This definition is very similar to that given by Shim et al. (2002) to the field of decision support systems (DSS): “technology solutions that can be used to support complex decision making”. Another example is INFORMS’ definitions of analytics as “the scientific process of transforming data into insight for making better decisions” (Liberatore &#38; Luo, 2011, p. 582); which bears close relation to their definition of OR/MS as “the application of advanced analytical methods to make better decisions” (INFORMS, 2013). A clear argument can be made that the definitions are somewhat interchangeable, ergo that partitions between each are ill-defined.An alternative approach, popular in practitioner literature, is to define analytics not as a concept but as a practice. The most prevalent of such definitions is proposed in Lustig, Dietrich, Johnson, and Dziekan (2010), who argue that analytics comprises of three distinct aspects:Descriptive analytics: statistical methods designed to explore “what happened?”Predictive analytics: machine learning methods designed to predict “what will happen next?”Prescriptive analytics: OR/MS methods designed to answer “what should the business do next?”Whilst this description has been widely cited online (e.g. Basu, 2013; Johnson, 2012; Walker, 2012), there is no clear division between these practices and those that would be considered part of many of the related fields discussed. Descriptive (which can be read as the combination of information systems and basic statistics) and prescriptive analytics (OR/MS) are clearly well-established disciplines (albeit renamed) that have long been used in business decision making. Predictive analytics, whilst regarded by many to be an evolution of the approaches of data mining and machine learning (Agosta, 2004; Shmueli &#38; Koppius, 2011), still has sufficient commonality with these disciplines so as to make a complete distinction problematic.Other discussions of analytics suggests alternate disciplines as providing the source material for analytics. Chiang et al. (2012, pp. 3–4) suggest the key areas are “data management, database systems, data warehousing, data mining, natural language processing, […] network analysis/social networking, optimization, and statistical analysis” and that practitioners are “able to understand business needs, interpret the analyses performed on big data and provide leadership for data-informed decision making”. Varshney and Mojsilovic (2011, p. 84), however, propose “applied mathematics, applied probability, applied statistics, computer science, and signal processing” whereas Evans (2012) argues for BI/information systems, statistics and OR/MS.However, if analytics is merely a collection of existing disciplines then what is essentially new about it other than the name? If OR/MS in its existing form is already an integral part of analytics then effectively there is no need for OR/MS to alter its research agenda. However, taking such an approach may have negative consequences for OR/MS as a distinct and widespread practice. Not only would this suggest that the perceived opportunities analytics may offer could be missed, but also there is some evidence that OR/MS may have a diminishing influence in interdisciplinary and popular literature concerning business decision making.In Decision Support Systems, arguably the area’s most influential book of its era, Keen and Scott Morton (1978, pp. 33–34) propose that four disciplines are integral: “computer science, information economics, management science and behavioral science”. However, in its modern-day counterpart, Competing on Analytics (Davenport &#38; Harris, 2007), there are only two direct mention of OR/MS, but a total of 59 mentions of the terms “statistics” and “statistical”. In the course of the research four papers were found that directly list the disciplines perceived to comprise analytics (Chiang et al., 2012; Evans, 2012; Silvi, Moeller, &#38; Schlaefke, 2010; Varshney &#38; Mojsilovic, 2011); of which only Evans (2012) directly cites OR/MS (although Chiang et al. (2012) list “optimization” as a key component).This discussion highlights not only the importance of promoting the role of OR/MS in analytics, but that it exists within what could be described as an ecosystem of disciplines associated with analytical decision making in business. This includes a range of quantitative, computing and other disciplines, and can be considered to have its roots in the events of the start of the 20th Century.One logical reason for the similarities between analytics, BI, OR/MS, and some of the fields discussed is that fundamentally they all share a similar purpose: the improvement of business operations and decision making through the utilisation of information, quantitative analyses, and/or technologies. However, rather than merely coincidence, an alternative interpretation would be that they are all components of a larger, and broader movement, which, we argue, has had significant effect on the patterns and practices of management for some considerable time. This movement, using the concepts introduced by Kuhn (1962), can therefore be described as the dominant paradigm in the ‘science’ of business management.Though it has precursors, particularly Adam Smith’s The Wealth of Nations, the second industrial revolution (c1867–1914) can be seen as the main catalyst for the inception of the paradigm, a “paradigmatic shift” in Kuhn’s terminology. In the new industrialised cities of the early 20th century the ideologies of scientific management, mostly attributable to the work of Frederick Taylor, came to prominence. The approach championed the use of statistical measures, efficiency, rationality, and the application of scientific approaches to the problems of process and people management. Whilst the movement’s momentum eventually waned, it had significant impact at the time, as well as leaving a clear legacy on management practice (Taksa, 1992). Accordingly it would seem appropriate to consider this new approach to management as the start of a new management paradigm. Not only is there the notion of “inconsummerability” with the practices of proceeding periods, but also that there has been the progression of “normal science” in the years since (Kuhn, 1962).This is supported by the work of Locke (1989) into what he regards as the start of a new academic paradigm at a similar time. He argues this brought a new approach of management training through education, opposing the tradition of coming up the ranks from “apprentice” to “master-craftsmen”, a practice he argues as being without “applied science” (Locke, 1989, p. 4). The argument here is that the stimulus for this paradigmatic shift in management training is preceded by a paradigmatic shift in attitudes to the practice of management; the latter of which being the focus of this study.The proposed management paradigm will be labelled dianoetic management: dianoetic being defined in the Collins English Dictionary as “of or relating to thought, [especially] to discursive reasoning rather than intuition”. The term, although somewhat obscure, has the benefit that it does not have the connotations with pre-existing terminology (e.g. scientific- or analytical management). However, the meaning is appropriate to the practices and purposes of the paradigm: the development of management based upon logic and evidence rather than ‘gut-feeling’. This is not to reduce the importance of intuition, which still has an integral and essential role in effective decision making. The advances and applications of the paradigm have sought to make available data, tools and analyses to provide the evidence to allow decision makers access to discursive evidence that can supplement their use of intuition and experience for more effective decision making (see Shah, Horne, &#38; Capellá (2012) for further discussion on this area).This paper will seek to analyse the dianoetic management paradigm through analysing its historical development. Having defined the object of the study and the timeframe included (from 1910 to the present day), a remaining concern is the sources to use. The paradigm clearly incorporates a wide range of traditional academic disciplines, as highlighted in the earlier discussions about those that inform analytics. These can be summarised as fitting into one or more of the following categories:Technological: incorporating the various tools used such as hardware, software, and networks, which together support the efficient processing of data.Quantitative methods: the applied quantitative approaches to analysing business data, such as statistics, machine learning, econometrics and OR/MS.Decision making: represents the tools, theories, and practices used to support and understand the decision making process. This inherently interdisciplinary area is incorporated into many academic traditions, most obviously in psychology and behavioural science, but also in many of the other disciplines of the paradigm (e.g. studies into human–computer interaction and visualisation in information systems, or problem structuring methods in OR/MS).Based upon this categorisation a taxonomy has been created in Fig. 1, incorporating the disciplines each contains. Each includes disciplines that are effectively located in just one category, such as electrical engineering (technologies), mathematics (quantitative methods) and psychology (decision making). Contrastingly, some disciplines can be considered part of more than one category. Machine learning, a branch of artificial intelligence, has both technological and quantitative components. Information Systems, the study of the use of information technologies in organisations, has obvious connection to computing (technologies), as well as behavioural studies linked to decision making. Finally OR/MS, which has a clear quantitative aspect, has evolved to include focus on the more subjective areas of decision making. This is particularly evident in ‘soft OR’ (Rosenhead &#38; Mingers, 2001) and ‘behavioural OR’ (Hämälläinen, Luoma, &#38; Saarinen, 2013), but also, in approaches such as multi-criteria decision analysis (MCDA), the use of more subjective expert or decision maker judgement as a data input (see Köksalan, Wallenius, &#38; Zionts (2011) for further discussion of the development of these methods). Indeed, arguably it is this focus on decision making and decision makers that differentiates the discipline, in both its ‘hard’ and ‘soft’ variants, particularly its use in practice.As these disciplines are argued to be a relevant part of analytics, and therefore the dianoetic management paradigm, they should be a relevant part of the recording of its history. Accordingly sources from each of these academic and practitioner traditions will be evaluated alongside developments in data processing and management, as essentially each of these disciplines can be seen to be dependent on the consumption of data (albeit qualitative data in some cases) and each, at least in their use in business contexts, is typically used to support business management.The final aspect of this analysis is the division of the history into periods. This serves two particular purposes. Firstly it is an abstraction allowing the history to be ‘shaped’ into segments, and then more easily analysed. Whilst there is some arbitrariness to abstractions of this kind, the periods do demonstrate specific characteristics. Secondly the periods chosen reflect the years in which the different fields/disciplines were in particular prominence. The paradigm will be divided into six periods:1.Scientific Management: the years between 1910 (the publication of Taylor’s monograph The Principles of Scientific Management) and the end of the Second World War.The Scientific Method: the period between the end of the war and the mid-1960s, marked by the increased use of OR/MS in businesses.Management Information Systems: the mid-1960s to early-1970s, characterised by the growth of management information systems (MIS).Decision Support Systems: the early-1970s to late 1980s when DSS were particularly prominent.Business Intelligence: the early 1990s to the mid-2000s when BI architecture and techniques were of principal concern.Analytics: the mid-2000s to the present day marked by the increased prominence of analytics.Some selected events in the paradigm, divided into their respective periods, are shown in Table 1, before each of these periods is discussed in chronological sequence.As stated, the proposed start of the first period, and overall dianoetic management paradigm, is circa 1910; not only marked by the publication of Scientific Management but also the closing stages of the Second Industrial Revolution (also referred to as the Technological Revolution). Smil (2005, p. 8) argues these “widespread and truly revolutionary innovations not only changed the course of the innovating societies but were also translated into profound global impacts”. These global impacts can in part be seen in the changing approaches to management of this paradigm. New technologies begot new products, services and industries, but also new methodologies that impacted upon not only physical labour and methods of production, but also management approaches (e.g. Fordism). The principles, methods and philosophies of process management developed by Taylor, Ford and others were to have sustained influence, much as the technologies themselves influenced them.World War Two was a period of significant innovation, most famously in Bletchley Park where Colossus, the first programmable digital computer, and decryption machines (such as Alan Turing’s Bombe) were created (Flowers, 1983; Randell, 1972). Similarly the work of Edward Tizard, Patrick Blackett and the Aeronautical Research Committee, arguably the originators of the OR/MS discipline, played a significant influence on Britain’s war effort (Kirby, 2003; Ormerod, 1999), as well as many of the quantitative methods of the dianoetic management paradigm. Whilst the work carried out in Bletchley Park became so widely acknowledged it ultimately become almost folklore, less celebrated advancements were occurring around the world. In Germany Konrad Zuse created the Z1 (the first digital computer) predating Colossus by two years (Giloi, 1998), whilst mathematics became increasingly important in military operations of the US (Rees, 1980) and Canada (Laporte, 2008).In summary, this period is when the innovations of the Technological Revolution began to impact on managerial theory and process. Similarly the period demonstrates the domino-effect of interactions between different disciplines and society: new technological innovations led to changes in working lives and practices, which in turn inspired new approaches to management and the new paradigm.Following the conclusion of the war, the pioneers of the nascent computer technologies and the OR/MS discipline sought new applications for their tools and methodologies. Moreover a recognition of the potential cost savings each offered was not lost on the cash-strapped governments of Europe and North America. In the UK the newly elected Labour government, seeking to increase the size of the public sector, engaged Blackett and colleagues to utilise OR/MS in a succession of new industries such as steel and coal mining (Kirby, 2003; Ormerod, 1999). Although mostly regarded in the UK as a smorgasbord of techniques from a variety of approaches, in the US a formulisation of the methodologies occurred and by the 1960s many of OR/MS’ principal techniques were established (Kirby, 2003).The second period also saw an explosion of innovation in computing, what Ceruzzi (1999, p. 13) describes as the “advent of commercial computing”. The list of innovations in the period include the von Neumann architecture (the division of processing and storage memory), the conceptualisation of FORTRAN and COBAL (the first higher-level programming languages), core memory, and the UNIVAC computer (Aspray, 1990; Pugh, 1984). Arguably it was the latter of these which had the greatest public impact by successfully predicting the 1952 US presidential election (Ceruzzi, 1999). The reaction to this was a major public relations coup for the burgeoning computing industry. Indeed there are many parallels with the reporting of Nate Silver successfully predicting the 2012 election, and the positive attention it has brought to analytics (e.g. Thaler, 2012).Developments in decision making were more limited, though the period did see the formalisation of the disciplines of behavioural science and ergonomics (Senn, 1966; Waterson, 2011). However, the more significant aspects of the period were in the commercial applications of computers and OR/MS, capitalising upon the appetite for a more scientific methodology to business and decision making by demonstrating the actual benefits this can bring.Whilst the computers of the previous period had demonstrated the potential value of such machines in business, their actual dispersion was far more limited. For example, only 19 UNIVAC computers, the most famous of the period, were sold between 1951 and 1954, in what was effectively the machine’s heyday (Ceruzzi, 1999). It was not until the mid-1960s that computers became accessible to many more businesses. In particular IBM’s System/360, so named due to its targeting of “the full circle of customers, from business to science” Ceruzzi (1999, p. 144). Alongside mainframe computers, the period saw the introduction of mini-computers where new efficiencies in storage and logic, combined with a low retail price, generated significant sales across many industries (Ceruzzi, 1999). The growth in computing had strong influence on the application of these methods. One specific example is the development of the RASCEL computer, designed to implement stochastic methods which until this point were too time and resource consuming for practical application in business (Esch, 1969). Indeed many of the OR/MS practices such as simulation were particularly boosted by the advent of the computer programs and increased processing power of the age (Ormerod, 1999).The period saw many developments in academia, with the inception of the University of Minnesota‘s influential MIS department and the first UK OR/MS master’s degree at Lancaster University. The decision making aspect of the paradigm also came to prominence, with research conducted at the Carnegie Institute of Technology and MIT, and publications from Simon (1965) and Anthony (1965) particularly influential (Power, 2007). Alongside this more general work into the interface between ‘man-and-machine’, notable research was published by Scott Morton (1969) and Ferguson and Jones (1969) into how practical system can be devised that would better support decision making.It was this work (in the main) that provided the stimulus for the transition from this period into the next. Whilst these significant developments in both hardware and software made information systems and data far more pervasive and integrated into businesses, there was still a gap between the potential of the systems and their realised value to quantitative analysts and decision makers. It was attempts to address this gap that provided the catalyst for the start of the next period.As discussed in the previous section the fourth period was characterised by a desire to increase the usability of MIS and to further integrate computers into business processes and decision making. This was manifest in two new applications of computing technologies: expert systems and decision support systems (DSS). Whilst both of the systems had essentially the same goal, to assist decision makers and improve the efficacy of their decisions, how they sought to achieve this was fundamentally different. Expert systems sought to guide the user to a suggested action, dependent on the specific circumstances of the situation, whilst DSS provided more general decision support, displaying the relevant data or model results to do this (Nelson Ford, 1985). Critically, however, another similarity between the two was that both sought to combine the three categories of the paradigm. Computer technologies underpinned the systems; quantitative methods were used in the algorithms and models which analysed the data; and finally graphical user interfaces (GUIs), influenced by the growing work in disciplines associated with decision making, were designed to maximise accessibility and the influence of the systems.As such, this movement can be characterised as a convergent period, whereby developments in technology, quantitative methods, and decision making were sought to be consolidated into single systems, maximising the impact of each. As an example by the end of the period many of the leading OR/MS groups began to publish computing-related journals: the Operations Research Society of America (ORSA) with the Journal of Computing; the Institute of Management Sciences (TIMS) with Information Systems Research; and the OR Society began publishing the European Journal of Information Systems. The period also saw the emergence of human–computer interaction (HCI) as both a term and a specific area of academic research, emphasising the overlap of technology and decision making in the paradigm (e.g. Card, Moran, &#38; Newell, 1983).However, that is not to say that all commentators were entirely united on the subject. Echoing the earlier discussion about distinctions between BI and analytics, controversies occurred as to whether DSS was a subset of MIS (Davis, 1982), its evolution, or “just another buzzword to justify the next round of visits from the vendors” (Sprague, 1980, p. 1). In parts of the OR/MS community the period too saw disagreement about the influence of the ‘softer’ side of the paradigm (decision making) on its methods and models. Firstly the period saw the emergence of MCDA, and related approaches such as Analytic Hierarchy Process (Saaty, 1980), methods that framed problems as a combination of “a set of objectively defined alternatives and a set of subjectively defined criteria” (Buchanan, Henig, &#38; Henig, 1998, p. 334). Elsewhere, attempts were made to create solutions to “wicked” problems (Churchman, 1967); problems which are harder to structure and define due to conflicting perspectives amongst relevant stakeholders. This led to the development of the soft systems methodology (Checkland, 1981) and strategic options development and analysis (Ackerman &#38; Eden, 2010). However, these methods were more qualitative in their approach, leading to some degree of polarisation in the OR/MS community as to whether such “soft” methods were appropriate to the discipline; what Dando and Bennett (1981, p. 91) would describe as a “Kuhnian crisis”.In summary, perhaps the most significant contribution of the period was to highlight the growing levels of interconnectivity and interdependency across the paradigm. Firstly this can be considered a conscious effort by researchers such as Keen and Scott-Morton to unify such disciplines, but also this is visible in the ripple effects that the growing influence decision making disciplines had on both technological and quantitative disciplines.One of the main catalysts for the start of the fifth period came from an unexpected source: the supermarkets. Whilst barcode scanners had been first introduced in 1973, there had been a relatively slow uptake in US supermarkets. However, by 1985, 29 percent had installed the technology (Basker, 2012). A by-product was the availability of vast amounts of transactional data for retailers and brands. In particular, US consumer goods giant Proctor &#38; Gamble, in conjunction with Metaphor Computer Systems, were instrumental in demonstrating the value and the methodology of a new form of architecture (Nylund, 1999). The architecture amalgamated existing DSS, databases, market research, and the transactional data collected at the supermarket tills into new data warehouses.However, increased data volumes not only presented technological challenges, but also stimulated demand for new quantitative and decision making approaches. The discipline of data mining attained both credibility and momentum, primarily due to the challenges created by the comparatively large datasets that became available in the period. Through combining statistics, SQL, and machine learning, data mining grew to offer credible and effective solutions. Similarly the period saw the development of dashboards. Whilst these were still essentially GUIs, in contrast with the first DSS, these dashboards were pre-populated with key performance indicators (KPIs) designed to speedily convey the critical measures of business performance (Few, 2006). The use of such metrics as management tools had become popularised by Kaplan and Norton’s (1992)balanced scorecard. Through a combination of this framework and dashboard technologies, the period created something of a culture of management by metrics whereby KPIs determined everything from staff bonuses to strategic and operational decision making (Beatham, Anumba, Thorpe, &#38; Hedges, 2004).In summary, the BI period was most notable for the introduction of new architectures and procedures which made the storage, management and delivery of data within the organisation far more efficient and consistent. Much of the catalyst for this was the significant increases of data available at the start of the period. However, the development of the internet during the period, would, by the start of the next, produce an influx of data the scale of which was incomparable.Analytics as a term can be traced back to Aristotle and his work on deductive reasoning (Malnik, 2012). In business, the term is first used around 2000 (e.g. Whiting, 2000), and in the context of BI software. The first academic article identified in this research explicitly discussing the subject is from 2002. In this article Kohavi et al. (2002) highlight five particular drivers: “verticalization” (the creation of bespoke software for more industries); increased accessibility of models to different business users; analysis tools better integrated into information systems; cross-functional usage in different business ‘silos’; and uses in performance management. However they also specifically acknowledge another major factor, the growing amounts of data. Similarly, Davenport and Harris (2007, p. 11) cite key catalysts as the fact there is far more business data available than ever before and “a new generation of technically literate executives – the first to grow up with computers”.The growth in data, a key factor as indicated above, is mostly attributable to the ubiquitousness of the internet in the new period. This has had significant ramifications for businesses in terms of data-availability including data from competitors, customers, the general public (through social networks and user-generated content), machines and products (the ‘internet of things’), and in the business itself. This data is of such scale as to limit the application of BI architecture and relational databases (Stonebraker et al., 2007), creating a demand for new technologies and architectures. Most notable is perhaps Hadoop, a distributed file system (DFS), designed to store, process and analyse such data, but also includes NoSQL and NewSQL databases (Cattell, 2010); the proliferation of cloud computing; and API-streams from data-rich sites such as Facebook and Twitter. In short, there has been a completely new ecosystem of businesses, technologies and cottage industries built to tackle the challenges of big data (see Feinleib (2012) for a visual representation of this ecosystem).As mentioned, data scale and complexity has also created challenges for quantitative analysts, and indeed ideological debates. The prevalence of unstructured data (mostly from online sources) has led to further developments in text mining, network analysis and natural language processing. Whilst this led to considerable advancements, in the main it employed traditional scientific methodologies. However, the challenges and opportunities presented by working with the extremely large datasets of the period has led to new approaches, which led Anderson (2008) to claim that the ‘scientific method’ is “obsolete”. He argues that as opposed to the deductive approach of hypothesis testing, the new big datasets require an inductive approach where correlations are the key to the process:“This is a world where massive amounts of data and applied mathematics replace every other tool that might be brought to bear […] Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves.” (Anderson, 2008).Undoubtedly analysis of big data may lend itself more to inductive approaches than model building, which invariably seeks to reduce data in the interest of model performance and parsimony (Pidd, 1999). However, the demise of the scientific methodology may be somewhat exaggerated, as argued in the many ripostes to the article (e.g. Dyson et al., 2008; Granville, 2013). Obviously correlation depends on linearity, and also the adage that correlation does not mean causality is an important concern. Whilst correlations in big datasets are a valid and growing approach to analysis in the period, in many scenarios a deeper analysis will be more fruitful and appropriate to the problem.Decision making maintains equal prominence in the period, with data visualisation attracting much attention and influence in particular. Secondly, there have been many efforts to provide decision support and automation in ‘real-time’ (e.g. Davenport &#38; Harris, 2007; Niedermann, Radeschütz, &#38; Mitschang, 2011). Critical to this is the availability of technology, and specifically processing power. Another key influence has been the effectiveness of search engines in recommending results for users, and the success of product recommendation agents on websites. As a natural extension of this businesses have sought to provide real-time recommendations for employees such as upsell opportunities and customer churn identification. The result of such initiatives is to provide fast, accurate and useful information, improving the speed and precision of decision making (Panian, 2008).In summary, the sixth and current period has seen new changes to the dianoetic management paradigm, particularly in the form of new data architectures and processing techniques in response to the abundance of data available. The availability of both the data, and the tools that complement it, have had significant impact on decision makers, the demands of businesses for new and further reaching forms of analysis, and indeed the central methodology of the paradigm itself.The history presented in this analysis charts the development of dianoetic management from time-and-motion studies and basic calculators a century ago, through to the computerised models of the modern age that are automating millions of decisions every second. These changes are evident not only in the physical evolution of the paradigm, the technologies and mathematical models that are used, but also in attitudes to how businesses should be managed. The use of these methods has extended far beyond the factories of Ford and the battlefields of the world wars, into doctor’s surgeries, design studios, sports arenas and beyond.The most obvious and apparent area of growth has been in computing, data processing and telecommunications, with many modern mobile phones boasting 64,000 times the memory of a typical installation of IBM’s ground breaking System/360 of the 1960s. The growing amounts of data now available is matched by the growing ability to store, process and analyse vast quantities at ever increasing speeds. Taylor’s original calculations, based on sampling the activities of a handful of workers, are in stark contrast to the data-intensive operations of search engines, where simple queries can involve iterating over billions of data-points. Similar progress has been made towards better understanding the decision making process and the effective communication of information. The various disciplines that act both as components and informants of analytics have individually been developing over this period, as has been widely documented (e.g. Ceruzzi, 1999; Kirby, 2003). However, through considering the development of each discipline simultaneously some of the important interactions and ‘ripple-effects’ between them can be captured.As such this represents our study’s first significant contribution. Regarding these histories collectively a clear evolution can be seen, with the paradigm growing in both sophistication and in influence. It has been demonstrated that this evolution goes beyond the ‘sum-of-its-parts’; as new innovations resonate between each discipline then new applications and opportunities have been exploited and even greater impact achieved. For example, presented in the form of the analysis above, a clear correlation is shown between the growth of ‘soft OR’ in the 1970s coinciding with the similar growth in influence of many of the ‘softer’ decision making disciplines and methods into information systems and computer science (e.g. the popularisation of DSS and human–computer interaction). Similar synergies can be seen between the availability of big data, the popularisation of alternative database systems (e.g. NoSQL), and indeed the quantitative methods that Anderson (2008) argues are changing the scientific methodology.The ripple effects of innovations and influences offer new insights as to the nature of the relationship between the disciplines involved in the paradigm. Whilst each has clear and significant differences, and its own academic tradition and history, equally they are intertwined within an ecosystem. As with any ecosystem, the tendency is to revert to type and maintain its usual practice (its process of “normal science” in Kuhnian terminology). When this is disrupted through new ideas, innovations, and methodologies, the system will seek to adapt and find a new equilibrium, described as a succession in biological ecosystems. This succession is likely to resemble previous states, however, if the scale of the disruption is significant, it is likely to produce significant changes to the ecosystem.In discussing analytics we are therefore discussing the current period of the dianoetic management paradigm and the ecosystem in its current state of equilibrium after the initial disruption of big data and the other factors that marked the beginning of the analytics period. As such we may choose to define “analytics” as simply the most recent and most evolved moment in the history of the paradigm, and the current state of the ecosystem the underlying disciplines co-inhabit.However, to view the development of the paradigm purely as a straight-line evolution means that the periodization of this history is either irrelevant or solely a convenience serving to carve up this history into more manageable chunks. This conclusion, however, does not seem to fit the data. Of the periods identified a clear case can be made that each displays particular characteristics; are marked by new ideological, methodological and/or technical innovations; and moreover have their own preoccupations and causes. In other words, whilst we conceptualise this research as detailing the development of a single paradigm, to more completely describe this history our conceptualisation must also incorporate the separate periods and their individual characteristics.This conclusion confirms that periodization is not only the product of theory, but it is also a producer of theory (Green, 1995). In what can be considered as the second significant contribution of the research, this facet allows us to generate a new and more satisfactory theory of the relationships between disciplines such as OR/MS and information systems; periods such as analytics and BI; and of the overall dianoetic management paradigm. Whilst many have sought to develop taxonomies that categorise concepts such as MIS, DSS, BI and analytics into super- and subsets, in this theoretical framework such distinctions are in effect not of hierarchy, orientation or methodology but rather they are of chronology. In other words the question is not what differences there are between each, but what concerns, technologies, practices and environmental contexts are prevalent in their time period. Concerns about distinguishing and defining each is more a preoccupation of vendors and academic communities; as Theodore Levitt infamously observed “people don’t want to buy a quarter-inch drill. They want a quarter-inch hole” (Christensen, Cook, &#38; Hall, 2005, p. 74).Similarly this gives a new perspective on the differences between these periods and the associated quantitative, technological or decision making disciplines shown in Fig. 1. Analytics effectively represents a snapshot in time of the overall ecosystem within which they each co-exist. On the other hand a discipline such as OR/MS represents both a well-established, independent and resilient area of study and practice, which yet also contributes to the dianoetic management paradigm.To summarise we consider the history charted in this research to be of the whole (the overall paradigm) and simultaneously its sub-sections (each period). This history runs in parallel with the histories of the related technological, quantitative and decision making disciplines from which it draws. The two contributions discussed thus far afford a greater understanding of what analytics actually is, and how it relates to a discipline such as OR/MS. Accordingly this answers the first research question of the study. However, the second, ascertaining how OR/MS should react to analytics remains unanswered and will be the subject of the next section of this study.The previous section has offered new insight and perspective through considering the history of OR/MS concurrently with the histories of the many other disciplines involved in the paradigm. This shared history not only informs our understanding of how periods such as analytics and business intelligence, develop, but also can be used to infer new insights into the relationship between OR/MS and analytics, and therefore how the OR/MS community should react to its development.Whilst the technological, quantitative and decision making disciplines associated with the dianoetic management paradigm interact, and notable ripple-effects have been identified between each, within the paradigm itself this is all the more prevalent. In a reciprocal relationship, new techniques and innovations developed in the concurrent histories of its related discipline are absorbed and incorporated into the paradigm. This, in return, affords greater attention and reach into the wider business community for their parent disciplines. These relationships are demonstrated in Fig. 2.The structure of the ecosystem not only gives us insight into how we may distinguish the different disciplines and the periods of the dianoetic management paradigm, but also into the relationship between disciplines such as OR/MS and the others in the ecosystem; relationships which can be both co-operative and competitive. The consequences of this give some indication as to the likely impact of further engagement with analytics may have for the academic OR/MS community. This will be demonstrated by discussing the probable implications of the two extreme positions that the OR/MS community may take in respect to analytics: the isolationist approach and the faddist approach.One option available to the OR/MS community is to distance itself from the overall paradigm. Instead of seeking to engage with each new period or the paradigm as a whole OR/MS can instead focus on best serving its current academic and practitioner communities. An additional benefit of such an approach is to distance the discipline from the uncertainty and hype that is associated with the faster paced developments of the paradigm. However, the trade-off is that the overall reach of the discipline is potentially diminished. As indicated in Fig. 2, disciplines have their own direct customers who will seek to utilise their methods directly. In the public sector, manufacturing and transportation industries (to name but a few) the OR/MS methodology is relatively well-known and well-used, employing specialist teams and OR/MS consultants alike. However, the number of industries and businesses of which this is true is dwarfed by the number that could benefit from the methods of the discipline. A policy of ignoring both the paradigm and its periods seriously limits the access of OR/MS to the greater numbers of potential customers in the wider ecosystem.A similar, more moderate approach may be to seek to separate paradigm and period. The paradigm has drawn upon research, innovations and methodologies from across a spectrum of technological, quantitative and decision making disciplines, of which OR/MS has had a clear, prominent and substantial role. However, does that mean that OR/MS should engage in each of the periods? If the paradigm will continue, and a new period is inevitably around the corner, is it necessary to engage in debate and research into an individual period such as analytics? Irrespective of the appeal such an approach may have, in reality separating the paradigm from its periods is not so straightforward. The current period is the current incarnation of the paradigm and even if not all of its trends and characteristics resonate entirely with the core concepts of the OR/MS discipline, as concerns of the wider business community they retain relevancy. Whilst each period inevitably gives way to the next, the progresses associated with it continue and are built upon as the paradigm evolves.Ultimately OR/MS is in competition with many other disciplines for the attention of business users (customers), both now and in the future. Whilst this may seem counter-intuitive to the argument that these disciplines are sharing the same ecosystem, and the reciprocal relationships this entails, the organisms in biological ecosystems compete for natural resources, and with varying degrees of success. To ignore this fact could have highly detrimental results for OR/MS. The devotion the deities of ancient Egypt, Greece and Rome once received did not prevent their decline; a religion without followers soon becomes a footnote in history.The opposite to the isolationist approach of complete disassociation would be a policy of high engagement and convergence with analytics. This would likely take the form of reinventing the discipline to adopt the new aspects and technologies of the period and renaming many of its societies and publications. Accordingly the problems associated with the former are reversed; by pushing the connection with analytics, OR/MS could increase its exposure and reach to the considerably greater number of customers in the ecosystem as a whole.However, there are equally dangers with this approach. Whilst the concerns of the wider ecosystem should therefore have clear relevancy for both the academic and practitioner OR/MS communities, this does not mean that the discipline is, or should be, entirely subsumed by analytics, or that it should seek to entirely reinvent itself. By default the model necessitates that eventually each period will give way to the next, and the concerns, preoccupations and the terminology will again move on. To have engaged in a complete reinvention can lock the discipline with a moment in time likely to soon be seen as dated and detached from future periods and their principal concerns.Both of these approaches have clear benefits, however, each too carry risks or reduce the potential value business interest in analytics may generate. As with many such situations, the answer probably lies somewhere in the middle. It is important for the OR/MS community to engage with both the paradigm as a whole, and also the current period of analytics, in order to maximise its reach and ensure its relevancy to businesses, practitioners, academics and students. However, it is also important for OR/MS to maintain its distinctiveness and unique selling points so to enjoy longevity and the continued support of its direct customers. Consequentially, a balanced approach is recommended that can both highlight the many qualities and successes of the discipline, as well as engaging with the new concerns of analytics and the wider ecosystem.This recommendation not only provides an answer to our second research question, how the OR/MS community should react to the growth of analytics, but also represents the third contribution of this research. An appreciation of the reciprocal relationship between OR/MS and the paradigm re-enforces the need to promote interdisciplinary research and training to the OR/MS community, and to seek to encourage new debate and engagement across the paradigm’s business users. This insight would go beyond the concerns of the current period (analytics) into whatever direction the paradigm next goes. Such an approach, however, needs to be enacted across the breadth of the OR/MS community and therefore the lack of academic research is a concern that needs to be addressed. This paper will conclude by suggesting some specific research themes, thus answering the third question: what directions can be suggested that may unite OR/MS and analytics.As discussed in the previous section, research into analytics should seek to both incorporate the unique aspects of the OR/MS discipline, as well as the innovations, concerns and characteristics of the analytics period. To this end, and in order to answer the third research question, five areas of innovation and key developments associated with analytics are suggested as the starting point for future OR/MS research. These areas, by no means comprises an exhaustive list, are: big data, new data architectures, unstructured data, real-time analytics, and data visualisation.One of the most noted aspects of the analytics age has been the growth in data volume, and in the size of datasets. The latter represented a significant challenge for both the technologies, discussed in the next section, and also the quantitative methods used. One such implication surrounds the use of statistical significance in very large datasets. Whilst a pressing concern traditionally has been collecting enough data to find significant effects, in very large datasets the opposite can be of issue: almost every relationship can be measured as significant at the 5 percent level. Further research and debate should be encouraged in the wider quantitative community as to what methods can be used for hypothesis testing and model validation in such datasets.Secondly, and more specifically, the use of big data has significant implications for many of the typical models used in OR/MS practice. Traditionally in such models simplicity has been advocated (e.g. Ward, 1989), which is not necessarily concordant with using the vast, varied and complex datasets becoming available in the analytics period. To some this may present something of a Catch-22: either abandon certain key principals of OR/MS modelling or ignore the potential benefits that big data may bring. However, some practitioner examples are emerging of the use of optimisation techniques in big data (e.g. FICO, 2013). Future research of this kind, or into the limitations and applications of optimisation and other OR/MS techniques to such datasets should be strongly encouraged.A third possibility is to explore the use of dimension-reduction techniques such as singular value decomposition (SVD), principal component analysis (PCA) or kernel-based methods to transform or separate big datasets prior to their use in OR/MS models. Finally, a fourth direction could be to investigate the possibility that OR/MS models could in fact be the producers of big data. Large-scale simulation models for example often produce large volumes of experimental results which have traditionally only been considered in aggregate. Mining such datasets could well provide new and actionable insights for businesses.Often synonymous with the subject of big data are the new types of databases, techniques and architectures popularised in the period such as NoSQL, Massively Parallel Processing (MPP) and Hadoop. Whilst in the main such systems are at the more technological end of the spectrum than usually inhabited by OR/MS, that is not to say they are without relevance. As these systems grow in usage in the wider community, or even become de facto, so too does the need to demonstrate how OR/MS applications can be aligned with this architecture.Whilst examples of data mining and machine learning algorithms applied within distributed systems are numerous (e.g. Zaki &#38; Ho, 2000), no academic literature on the application of OR/MS methods within these new architectures was found. Providing case-studies and reports of experimentation which explore these opportunities is recommended. Such studies can inform the community about these tools, as well as demonstrate their potential benefits and growing prominence.As discussed, data in the analytics period has not only been characterised by its unprecedented scale, but also its variety. In particular, this is due to the proliferation of online user-generated content (e.g. blogs, online customer reviews and “tweets”) which can be used for a wide range of tasks such as customer research, epidemiology, security, and risk-analysis. The overarching value inherent in this data lies in the fact that much of it provides highly immediate and uncensored access to the activities, views and interactions of ordinary people. The implications of such access are significant in understanding how social systems work, how information passes through networks and communities, and to predict future events significantly earlier than with traditional data types.Data of this kind could clearly add additional value in a variety of OR/MS models including simulation, systems dynamics, supply chain management, logistics, and forecasting. As such a variety of research directions in this area should be encouraged: how such data is pre-processed (again dimension-reduction is likely to be necessary due to the sparsity of text and multimedia datasets); how such data can be used effectively in OR/MS models; and case studies demonstrating and/or promoting the use of such data in OR/MS applications.An additional consequence of the explosion of online data is that many valuable sources of data are now available online, via application programming interfaces (APIs) or file transfer protocol (FTP) from external websites. This, in combination with ever increasing computer processing power, has significant implications for modelling as it effectively can allow some data collection and processing to occur in close to real-time and ‘streams’ of data to flow into models autonomously. Meanwhile, real-time applications of OR/MS are relatively prominent in the literature. Examples can be found in various areas including:•Optimisation (Diehla et al., 2002; Powell, Marar, Gelfand, &#38; Bowers, 2002; Seguin, Potvin, Gendreau, Crainic, &#38; Marcotte, 1997).Simulation (Better, Glover, &#38; Laguna, 2007; Bruzzone &#38; Giribone, 1998; Davis &#38; Jones, 1988).Logistics &#38; Scheduling (Durbin &#38; Hoffman, 2008; Giaglis, Minis, Tatarakis, &#38; Zeimpekis, 2004;Seguin et al., 1997).Stochastic Modelling (Davis &#38; Jones, 1988; Sand &#38; Engell, 2004).Clearly this demonstrates that such research is indeed being generated, and has been for nearly thirty years. Further research may seek to promote this area and bring it to the attention of the wider community, through case studies and/or literature review(s).Data visualisation has become one of the main ‘buzzwords’ of the analytics age, but, as the valuation of Tableau (one of the main software vendors) at $2billion dollars just two days after its initial public offering on the stock market (Cook, 2013) indicates, there has been more to this than just hype. Visualisation is again not necessarily new to the period (Friendly, 2005), but is becoming an area of significant growth partly due to the ability to display visuals on interactive internet browsers, allowing increased distribution and increased power. The potential of these techniques and technologies as tools for effective communication, to increase the impact of analytical findings, and even as an analysis tool in their own right, has been widely acknowledged in the ecosystem at large.OR/MS, as a discipline closely focused on decision making, can see genuine benefits from visualisation such as improving the ease of model validation and increased buy-in from stakeholders. Methods such as simulation have long utilised graphical displays for these purposes (Hurrion, 1976) and whilst there has been research into their design and use (e.g. Belton &#38; Elder, 1994), further studies into best practices, in particular with respect to recent visualisation work should be encouraged. Similarly, research into the use of visualisation techniques across the breadth of OR/MS methods, both in theory and practice, may again offer new opportunities for the discipline, and also increase awareness amongst OR/MS professionals as well as the wider community.Although not directly linked to OR/MS and analytics, the implication of positioning OR/MS as a constituent member of a wider ecosystem that includes many related disciplines sharing similar goals and concerns equally suggests future work. The main implication of this representation is that, from a business perspective at least, it is in combination that the disciplines can have greater impact and influence. Consequently one of the major recommendations would be to encourage future collaborative research between these disciplines, research which could be mutually beneficial for the wider ecosystem, and the prominence, effectiveness and impact of the OR/MS methodology.One opportunity would be to expand the work started here into a more comprehensive history of the overall ecosystem, particularly in expanding the scope beyond the 100 years explored in this study. Secondly, studies into how the disruptions and ripple effects spread through the ecosystem and how new successions are reached, may shed further light on this phenomenon, as well as inform the disciplines on how to better manage and react to innovations emerging from related disciplines. Thirdly, studies could also focus on the actual process of academic collaboration between these disciplines, with the purpose of identifying barriers and critical success factors, and developing best practice guidelines. Through work such as this, and indeed other opportunities may be identified, a greater understanding of the paradigm as a whole can be reached, an understanding that can help shape the future of the ecosystem rather than simply exploiting the current opportunities it offers.

@&#CONCLUSIONS@&#
