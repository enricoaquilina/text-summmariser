@&#MAIN-TITLE@&#
Single-image super-resolution reconstruction based on global non-zero gradient penalty and non-local Laplacian sparse coding

@&#HIGHLIGHTS@&#
Global non-zero gradient penalty is developed to reconstruct the edge component.Non-local Laplacian sparse coding is developed to reconstruct the texture component.Global and local function is developed to further improve the imageʼs quality.

@&#KEYPHRASES@&#
Sparse coding,Super-resolution reconstruction,Global non-zero gradient penalty,Non-local Laplacian sparse coding,Global and local optimization,

@&#ABSTRACT@&#
Methods based on sparse coding have been successfully used in single-image super-resolution reconstruction. However, they tend to reconstruct incorrectly the edge structure and lose the difference among the image patches to be reconstructed. To overcome these problems, we propose a new approach based on global non-zero gradient penalty and non-local Laplacian sparse coding. Firstly, we assume that the high resolution image consists of two components: the edge component and the texture component. Secondly, we develop the global non-zero gradient penalty to reconstruct correctly the edge component and the non-local Laplacian sparse coding to preserve the difference among texture component patches to be reconstructed respectively. Finally, we develop a global and local optimization on the initial image, which is composed of the reconstructed edge component and texture component, to remove possible artifacts. Experimental results demonstrate that the proposed approach can achieve more competitive single-image super-resolution quality compared with other state-of-the-art methods.

@&#INTRODUCTION@&#
High resolution (HR) images are desired in most electronic imaging applications such as biometrics identification, medical imaging, military surveillance and so on. Unfortunately, due to the physical limitation of relevant imaging devices, the images we observed are usually noisy, blurred and downsampled. To obtain the HR image, we can either reduce the pixel size by sensor manufacturing techniques or increase the chip size of charge-coupled device sensors, which are both severely limited in increasing the cost of digital imaging systems and reducing the processing efficiency of real-time environment [1]. Therefore, the signal processing methods are selected to reconstruct potential details and features hidden in the low resolution (LR) image.Generally, the existing methods can be classified into three categories: interpolation-based methods [2–5], regularization-based methods [6–12] and example-based methods [13–32]. However, the interpolation-based methods are usually prone to yield overly smooth images with ringing and jagged artifacts when a larger magnification ratio (such as a factor of more than double) is performed. The regularization-based methods are limited in modeling the visual complexity of the real images and selecting correct regularization parameters. The focus of this paper is the example-based methods because the methods are of stronger capability of image super-resolution reconstruction as the magnification becomes larger.In recent years, the example-based methods have been explored. This kind of methods presumes that the high-frequency details lost in the LR image can be predicted by learning the co-occurrence relationship between LR training patches and their corresponding HR patches. Freeman et al. [13] first proposed a relation model between the local regions of images and scenes by using the Markov network. However, this approach depends heavily on a large training data set. Chang et al. [14] introduced locally linear embedding from manifold learning to process the image super resolution task. Although this method has advantages over Freemanʼs, the problems of the number of neighbor and feature representation of LR and HR image patches remain unsettled. Others based on learning primal sketch prior are proposed [15–17]. However, due to the lack of priors of textures and details, they are weak in hallucinating both textures and details. Recently, Yang et al. [20] proposed a sparse coding to reconstruct HR images. In their works, HR image patches are sparsely coded under over-complete dictionary learned with coupled pattern. Considering that there are different types of image patches (such as smooth regions, texture regions and edge regions) in image, Jing et al. [21] proposed a multi-space sparse representation method, which first decomposes image into structural and textural components, and then the HR image is recovered by coding the structural and textural components respectively. And Yang et al. [22] also proposed a multiple-geometric-dictionaries-based clustered sparse coding scheme, which first trains the geometric dictionaries of geometric clusters, and then HR image patches are sparsely coded under different geometric dictionaries. Recently, the geometric structure information of image patches has been successfully used in various image processing applications [33–35]. Some research works have pointed out that the reconstruction quality greatly depends on geometrical structures of the data [31]. Hence, it is important to explore these potential geometrical structures to enhance existing sparse coding stability. By transferring the non-local information of images patches into the sparse coefficients, the non-local sparse coding methods [30–32] are widely proposed for image reconstruction. However, the methods lose the difference among the image patches. Moreover, they are not effective in reconstructing images which contain the patterns with strong edge and reconstruct incorrectly the edge structures (such as continuity and orientation) [23].To resolve the above problem, we propose a new approach based on global non-zero gradient penalty and non-local Laplacian sparse coding. The overall framework of proposed approach is illustrated in Fig. 1. As shown in Fig. 1, firstly, by exploring the global non-zero gradient penalty (GGP) which can globally sharpen major edges and preserve their geometric structure by increasing the steepness of transition in a sparsity-control manner, the HR edge component can be reconstructed. Meanwhile, by exploring the non-local Laplacian sparse coding (NLSC) which can preserve the difference by exploring the one-to-one relationship of the image patches and the non-local prior simultaneously, the HR texture component can be reconstructed. Then, the global and local optimization (GLO) is applied on the initial image for removing the possible artifacts and making the final image more natural. Figs. 2(c)–(d) show the edge component and the texture component of “Butterfly” image. Fig. 3shows the decomposition process. Due to the different image components reconstructed by different methods, it makes the obtaining of desired HR image possible. The performance of the approach is tested by various typical experiments in terms of visual evaluation, peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). Compared with the related single image super resolution (SISR) approaches, the proposed approach has the following characteristics:(1)GGP is proposed for reconstructing edge component.NLSC is proposed for reconstructing texture component.GLO is applied on the initial HR image to further improve the imageʼs quality.The rest of the paper is organized as follows. In Section 2, we present our SISR approach in detail. The experimental results together with relevant discussions are given in Section 3. Finally, conclusions are discussed in Section 4. In addition, the descriptions of the acronyms used in this paper are listed in Table 1.In this section, we first show how to reconstruct edge component of the desired HR image by the GGP. And then develop the NLSC to reconstruct its texture component. Finally, we present the GLO to further improve the quality of reconstruction image.To effectively reconstruct the edge component, it is important to explore the prior information of the edge component. As shown in Fig. 2(c), only smooth region and major edges are contained in the edge component. In other words, a large number of pixels of zero gradient distribute in smooth region, and less pixels of non-zero gradient distribute nearby in major edges. Globally, the HR edge component of LR image can be obtained by penalizing the number of non-zero gradients in reconstruction. This kind of prior information (called as the sparse gradient counting tool) from [36] for image smoothing has been already explored. It is expressed as:(1)C(∂hXp,∂vXp)=#{p||∂hXp|+|∂vXp|≠0}where X represents the desired target image.∂hXpand∂vXprepresent the gradients of X at pixel p in the horizontal and vertical directions, respectively.#{}is the counting operator, outputting the number of p that satisfies|∂hXp|+|∂vXp|≠0. The main merit of this prior is that it can globally sharpen major edges and preserve their geometric structure by increasing the steepness of transition. Hence, we employ it to reconstruct the edge component. Based on the above analysis, the proposed GGP is defined as follows:(2)Xˆ=argminX{‖Y−AX‖22+λ⋅C(∂hXp,∂vXp)}where Y is the input LR image, A is the projection matrix, X represents the desired HR edge component, and λ is the smoothing parameter, all in vector-form obtained by lexicographical ordering. The first term‖Y−AX‖22constrains image structure similarity.Another noteworthy feature of the proposed GGP is that the edge component without blurred edges can be obtained due to the avoidance of weighted averaging operation similar to non-local methods [30–32].Considering that Eq. (2) involves a discrete counting metric, we employ a half-quadratic splitting optimization strategy [36,37]. Here we introduce two auxiliary variablesmhpandmvp, corresponding to∂hXpand∂vXprespectively, rewrite Eq. (2) as:(3)Xˆ=argminX,mh,mv{‖Y−AX‖22+λC(mh,mv)+β‖∇X−M‖22}whereM=(mh,mv)T. The symbol∇=(∂h,∂v)Trepresents the gradient operator.C(mh,mv)=#{p||mhp|+|mvp|≠0}. The superscript T is the transpose operator.mhpandmvpdenote the gradients ofmhandmvin p, respectively. Eq. (3) can be solved by alternatively minimizing terms.Fixing (mh,mv), we calculate X subproblem:(4)X⁎=argminX{‖Y−AX‖22+β‖∇X−M‖22}Differentiating Eq. (4) with respect to X and setting the derivative to be zero, we can derive:(5)(ATA+β∇T∇)X=ATY+β∇TMwhere the symbol∇T=(∂h,∂v). Instead of using gradient descend method to solve Eq. (5), we diagonalize derivative operators after Fast Fourier Transform (FFT) for speedup. Then, we can derive:(6)X⁎=FFT−1(FFT(A)⁎FFT(Y)+β(FFT(∂h)⁎FFT(mh)+FFT(∂v)⁎FFT(mv))FFT(A)⁎FFT(A)+β(FFT(∂h)⁎FFT(∂h)+FFT(∂v)⁎FFT(∂v)))whereFFT(•)⁎denotes the complex conjugate operator. The plus, multiplication, and division are all component-wise operators.Fixing X, we calculate(mh,mv)subproblem:(7)(mh⁎,mv⁎)=argminmh,mv{λβC(mh,mv)+‖∇X−M‖22}Xu et al. [36] proposed to solve the minimum solution of Eq. (7) by rewriting it as:(8)argminmhp,mvp∑p{(mhp−∂hXp)2+(mvp−∂vXp)2+λβH(|mhp|+|mvp|)}whereH(|mhp|+|mvp|)={1|mhp|+|mvp|≠00otherwiseThen, we can derive:(9)(mhp,mvp)={(0,0)(∂hXp)2+(∂vXp)2⩽λβ(∂hXp,∂vXp)otherwiseBased on the above derivation, we can compute all(mhp,mvp)to yield the global optimum for Eq. (7). The convergence evidence can be referred to [36] for details.We now outline the edge component reconstruction by the GGP in Algorithm 1. In our experiment,β0andβmaxhave fixed values 2λ and1E5, respectively. Considering the efficiency and performance of the algorithm, we set k as 2. The critical parameter λ is allowed to be adjusted to effectively control the level of edge component reconstruction. In our study, we observe that too large λ might lead to an oversharped edge component, while smaller λ will remain more details.Clustering of the training image patch pairs is important to the performance of our dictionary learning. In terms of collected patch pair, namely HR patch together with LR patch, Yang et al. [24] proposed that the geometry information of LR patch as the clustering index is more reliable than that of HR patch when training pairs are clustered. Recently, considering that the histogram of oriented gradients (HoG) can effectively characterize the local geometry structure of LR image patch, Gao et al. [29] employed the HoG to perform unsupervised K-means clustering on the collected training patch pairs. However, image patches with dissimilar geometry structures may be clustered in the same cluster when the K is set as smaller value. Similar patch pairs which should belong to the same cluster may be clustered into some sub-clusters when the K is set as larger value, which will lead that many clusters are very similar, as well as patch pairs within these clusters. It is undesired that many similar dictionaries or a dictionary representing various geometry structures are trained. Therefore, introducing a supervised and deterministic clustering method into the patches classification is necessary. Yang et al. [22] also indicated that the geometric information of image patch as a supervised prior can improve the performance of unsupervised clustering. In this section, we present a supervised HoG clustering strategy. Each record within the cluster is an example patch pair, namely an HR texture component patch and the corresponding LR patch, which can be obtained by randomly sampling from HR texture component and the corresponding LR images. Note that the HR texture component can be constructed by the following steps: firstly, the HR image is downsampled as the LR image by the desired factor s. Then the HR edge component of the LR image is constructed by Algorithm 1. Finally, we can obtain the HR texture component by calculating the residual between HR and HR edge component. Fig. 3 shows the decomposition process. Once these example patch pairs are collected, we employed HoG of LR patch to perform unsupervised K-means clustering on the collected patch pairs. To make patch pairs within each final cluster be as much similar as possible, K is set to a large value. Large K means that there exist many similar clusters according to the above analysis about the K value. Hence, patch pairs are also very similar within each final cluster consisting of these similar clusters. In order to obtain the final clusters, denote t as the LR patch, and the gradient map of t asG=[g1,g2,…,gn]T, wheregi=[∂hti,∂vti]represents the ith pixelʼs gradients and n is the total number of the pixels in the patch. Typically, perform the SVD [22] onG∈Rn×2to obtainG=U˜S˜V˜T, and the dominant orientationωiof the LR patch can be solved byωi=arctan(v1(2)v1(1)), wherev1=(v1(1),v1(2))Tis the first column inV˜. By computing|ωi−l|<7.5, allωiin each cluster are voted inl∘box, which belongs to 0°–180° at intervals of15∘. The dominant orientation of each cluster can be obtained by selecting the most voted box. We make the clusters with similar dominant orientation into the new cluster, thus we have 12 clusters in total. Specifically, the final training cluster sets are presented as follows:{(Q1y1),(Q2y2),…,(Qiyi)}j, whereyirepresents the ith training LR patch,Qirepresents the corresponding ith training HR texture component patch, j represents the jth cluster. Figs. 4(a)–(f) show some LR example patches determined by the above method. We can see that the geometric information of patches within each cluster is consistent, and the geometric information in different clusters is different. We callωias supervised parameter and the method as supervised HoG clustering method.Once the clustering work is completed, the corresponding geometric dictionaries are learned by the NLSC, which will be introduced in Section 2.2.2.The original sparse coding method is briefly reviewed as follows [20]: LetB=[b1,…,bn]∈Rm×nbe the data matrix, letD=[d1,…,dk]∈Rm×kbe the dictionary matrix, where eachdirepresents a basis vector in D, and letS=[s1,…,sn]∈Rk×nbe the coefficient matrix, where each column is a sparse representation for a data pointbi. A good representation together with dictionary should minimize the empirical loss function, which can be represented asargminD,S‖B−DS‖F2. The standard objective function of sparse coding can be defined as:(10)argminD,S{‖B−DS‖F2+α‖S‖1}subject to:‖di‖2⩽c,i=1,2,…,kwhere α is a regularization parameter.Research works have shown that the non-local prior has been successfully applied into image reconstruction [30–32], namely:(11)∑i=1n‖si−∑jwjisj‖22=‖S−SW‖F2=Tr(SUST)wherewjiis the weight assigned tosjandsirepresents a sparse coefficient for data pointbi.wji=ci⋅e−‖bi−bj‖2hi.hiis a parameter enforcing the similarity andciis the normalization factor.U=(I−W)(I−W)TWji={wji,ifbjis within the firstkclosest tobi0,otherwiseBy substituting Eq. (11) into Eq. (10), the non-local sparse coding is formulated as:(12)argminD,S{‖B−DS‖F2+α1Tr(SUST)+α‖S‖1}subject to:‖di‖2⩽c,i=1,2,…,kwhereα1is a regularization parameter.A noteworthy feature of sparse coding method based on non-local prior that it can reconstruct fine details. The main role of non-local prior is a fusion process. By fusing the similar patches of the given patch in non-local region, some details lost in the given patch can be recovered. However, some components out of the given patch maybe absorbed. As a result, these reconstructed non-local patches are very similar to each other after the fusion process and the reconstructed image becomes over-smoothed. In other words, the difference among patches is lost in the fusion process. In order to better preserve the difference, we introduce the prior that is already explored in [38,39] and only used for image representation. The prior is defined as:(13)12∑i=1n∑j=1n(si−sj)2wji⁎=Tr(SLST)whereL=F⁎−W⁎is the Laplacian matrix.W⁎is the weight matrix that preserves the difference among patches, and its entrywji⁎measures the similarity between a vertex pair (bi,bj). Ifbiis among the k-nearest neighbors ofbjorbjis among the k-nearest neighbors ofbi,wji⁎=e−‖bi−bj‖2hi, otherwise,wji⁎=0.F⁎is a diagonal matrix, and the ith entryFii⁎corresponds to the summation of all the similarities related tobi, such as:Fii⁎=∑j=1nwji⁎.By substituting Eq. (13) into Eq. (12) simultaneously, the NLSC is formulated as:(14)argminD,S{‖B−DS‖F2+α1Tr(SUST)+α2Tr(SLST)+α3∑i=1n‖si‖1}subject to:‖di‖2⩽c,i=1,2,…,kwhereα2andα3are a regularization parameter.Thel1-minimization problem (Eq. (14)) can be solved by techniques such as the feature-sign search algorithm proposed in [39] and the iterative optimization method in [40].The proposed NLSC explores the one-to-one relationship of image patches and the non-local prior simultaneously. Hence, it is more capable of reconstructing details. Based on the above analysis, we will use the NLSC to reconstruct the texture component.Joint dictionary training method is used to train two coupled dictionaries for each cluster consisting of HR texture component patch together with LR image patch pairs by using the proposed NLSC. Similar to [20], the single dictionary training problems in the HR texture component patch and LR patch spaces for each cluster are(15)argminDhj,S{‖Qhj−DhjS‖F2+α1Tr(SUST)+α2Tr(SLST)+α3∑i=1n‖si‖1}and(16)argminDlj,S{‖Ylj−DljS‖F2+α1Tr(SUST)+α2Tr(SLST)+α3∑i=1n‖si‖1}respectively, whereQhjrepresents all HR texture component patch set in the jth cluster,Yhjrepresents the corresponding all LR patch set in the jth cluster,DhjandDljrepresent jth clusterʼs coupled dictionaries. By forcing the HR texture component and LR representations to share the same codes, Eq. (15) and Eq. (16) can be jointly transformed as following:(17)argminDhj,Dlj,S{1N1‖Qhj−DhjS‖F2+1N2‖Ylj−DljS‖F2+α1(1N1+1N2)Tr(SUST)+α2(1N1+1N2)Tr(SLST)+α3(1N1+1N2)∑i=1n‖si‖1}whereN1andN2are the dimensions of the HR texture component and LR patches in vector form respectively. Here,1/N1and1/N2balance the two cost terms of Eq. (15) and Eq. (16). So the joint dictionary training function (Eq. (17)) can be rewritten as:(18)argminDcj,S{‖Bcj−DcjS‖F2+αˆ1Tr(SUST)+αˆ2Tr(SLST)+αˆ3∑i=1n‖si‖1}whereBcj=[1N1Qhj,1N2Ylj]TDcj=[1N1Dhj,1N2Dlj]T,αˆ1=α1(1N1+1N2)αˆ2=α2(1N1+1N2),αˆ3=α3(1N1+1N2)For the given test LR patchyi, we aim to recover the corresponding HR texture component patchQiusing the above-learned geometric dictionary. The reconstruction process is as follows: we first compute the sparse coefficientsiofyiunder the dictionaryDljwith Eq. (19):(19)si⁎=argminsi{‖yi−Dljsi‖22+α1‖si−∑j=1nwijsj‖22+α2∑j=1n‖si−sj‖22wij⁎+α3‖si‖1}As soon as the optimal solutionsi⁎is determined from Eq. (19), we can obtain the estimationQi⁎=Dhjsi⁎. To adaptively select coupled dictionariesDhjandDlj, the most similar cluster of test LR patchyican be found by computingωi−ωj⩽d, where theωiis orientation parameter ofyi,ωjis orientation parameter of the jth training cluster and d is threshold. Once the cluster is found, the corresponding coupled dictionariesDhjandDljwill be selected.Subsequently, the whole texture component can be reconstructed by averaging all the reconstructedQi⁎patches. And then the reconstructed edge component and the reconstructed texture component are composed to obtain an initial HR imageX0.Due to the simple addition operation between the texture component and edge component, unexpected artifacts from different components will be brought in the initial HR imageX0. By projectingX0onto the solution space ofAX˜=Y, these artifacts can be eliminated. Yang et al. [20] explored a global constraint (GC) to regularize the solution:(20)X⁎=argminX˜{‖Y−AX˜‖22+c‖X˜−X0‖22}where c is a regularization parameter andX˜is the desired HR image. However, the global method fails to preserve the recovered clear edges from the edge component. To overcome the drawback, we introduce the locally adapted steering kernel [41], which assumes that the given HR pixel can be predicted from a small neighborhood area. Namely,(21)xˆ=argminx{∑i=1n‖xi−wi⋅Li‖22}wherexiis the ith pixel in the HR image to be estimated andLirepresents a column vector by stacking the corresponding neighborhood pixels within a small local area, all in vector-form obtained by lexicographical ordering.wiis the row vectorized version by arranging the steering kernelswijof neighbors ofxi.wijis defined as:(22)wij=det(Ci)2πh2exp{−(xi−xj)TCi(xi−xj)2h2}whereCidenotes the symmetric gradient covariance atxiin the vertical and horizontal directions.xjis a neighbor ofxi. h is the global smoothing parameter which controls the support of the steering kernel.Because the locally adapted kernel is of an outstanding feature which enforces most strongly along the edges rather than across them, the details and edges can be strong preserved in optimization. By substituting Eq. (21) into Eq. (20), a global and local optimization, the GLO is formulated as:(23)X⁎=argminX˜{‖Y−AX˜‖22+c1‖X˜−X0‖22+c2‖(I−K˜)X˜‖22}where I is identity matrix,K˜is defined as:(24)K˜(i,j)={wij,j∈N(xi)0,otherwisewhereN(xi)denotes the neighbors centered atxi.c1andc2are two regularization parameters.The solution to this optimization problem can be efficiently computed using gradient descent method. The update for this iterative method is:(25)X˜t+1=X˜t+τ{AT(Y−AX˜t)−uτ(X˜t−X0)−vτ(I−K˜)T(I−K˜)X˜t}where t represents the iteration times. τ stands for the step size for gradient descent. u and v are two regularization parameters to balance the global and local terms in the iterative procedure respectively.In the section, the procedure of our proposed SISR approach can be summarized as Algorithm 2.As outlined in Algorithm 2, it takes major cost on three parts: GGP, NLSC and GLO. Let the super-resolved image size ben1×n2. Let the size of LR image patch bep×p. Let the number of patches be P. Let the number of cluster be C. Let the size of dictionary bedh×dw. For GGP, in Algorithm 1, Step 2.1 takes aboutO(nn1n2)in compare operators. Step 2.2 takes about 7n FFTs andO(nn1n2)component-wise operation in iteratively computing HR edge component for n iterations. For NLSC, the training work for couple dictionaries is offline. Hence, selecting the best couple dictionaries, K-NN similar patches and the feature-sign search algorithm proposed in [40] spend much of the time. Therein, the SVD takes aboutO(4Pp2)toward the local gradient matrix of LR patch to obtain its dominant orientation. It takes aboutO(kP2p2)for searching the K-NN similar patches for all test patches. The feature-sign search algorithm takes aboutO(Pdwdhdw+Pdwdh+Pdw)for calculating the analytical solution. For GLO, let the size of local analysis window be r. The major cost is computing the steering kernel matrix. Therein, the SVD toward the local gradient matrix of each local analysis window is required. It takes aboutO(4tn1n2r2)for all the pixels in the processed image for t iterations. Moreover, it takes about four times matrix multiplication and six times matrix addition in Eq. (25), which takes aboutO(tn12n22+tnn1n2)for t iterations. Based on our experiments, it costs about 5 minutes to reconstruct an LR image of size128×128to an HR image of size384×384by running Algorithm 2 on an Intel Core2 Duo 2.2G PC under the Matlab R2010a programming environment.In this section, we perform 3× magnification experiments on ten test images (refer to Fig. 5) to validate the effectiveness and robustness of the proposed SISR approach. In Fig. 5, Moth, Boats, Tiger, Koala and Parthenon come from http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping, and the rests come from [12,20].In our experiments, considering that the patch pairs within a cluster are similar to each other, there is no need to select too many patch pairs in dictionary training process. Therefore, for each cluster, the coupled dictionaries are trained from 1000 patch pairs randomly sampled from 150 training images collected from BSDS300 segmentation image database. The image database contains different types, such as flowers, human faces, architectures, animals, cars and so on. The size of LR training patch and that of the corresponding HR TC patch are set as5×5and15×15, respectively. In the clustering of the geometric patch pairs, these patch pairs are divided into 12 clusters by a uniform sampling of the supervised orientation parameter ω in the range (0°–180°). And the orientation threshold d is set as 7.5°. The dictionary size is always fixed as 512 considering computation and image quality. In Eq. (19), the nearest neighbors parameter k from 4 to 16 with step 2 (refer to Eq. (11) and Eq. (13)), non-local parameterαˆ1from 0.1 to 3.5 with step 0.2, similarity parameterαˆ2from 0.1 to 3.5 with step 0.3, and sparsity parameterαˆ3from 0.04 to 0.2 with step 0.02 are set as 8, 1.5, 1 and 0.1, respectively. In Eq. (25), the step size τ from 1 to 3.5 with step 0.5, global parameter u from 0.01 to 0.1 with step 0.01, and local parameter v from 0.1 to 1.5 with step 0.2 are set as 2.5, 0.06 and 0.7, respectively. In our study, the main function of the proposed approach is to preserve the continuity and orientation of the major edges. We found that our approach is insensitive to above-mentioned parameters in a reasonable range.Comparatively, how to choose the proper regularization parameter λ from 0.002 to 0.03 with step 0.002 is crucially important to achieve good reconstruction performance. Larger λ means that the texture component contains most of edges. However, Eq. (19) tends to smooth edges due to the non-local prior. Smaller λ means that the edge component contains most of details. However, Eq. (2) is only used to reconstruct major edges. Fig. 6shows examples of the reconstructed HR edge component with different λ values, and Fig. 7shows examples of the reconstructed initial image with different λ values. By experience, we setλ=0.018to achieve a good balance between objective evaluation and good visual quality.Here, we give the way of tuning above-mentioned parameters by two steps. The first step, by fixing parameters (k,αˆ1,αˆ2, andαˆ3), we can obtain the best parameter λ from its test values when the objective and visual evaluations of the reconstructed initial HR image are best. Similar to the parameter λ, the best values of parameters k,αˆ1,αˆ2, andαˆ3can also be found. The second step, by fixing parameters (u and v), we can obtain the best parameter τ from its test values when the objective and visual evaluations of the reconstructed final HR image are best. Similar to the parameter τ, the best values of parameters u and v can also be found.For color images, we only apply the proposed approach to the luminance channel and the bicubic interpolation to chromatic channels.To demonstrate the effectiveness of the GGP, NLSC and GLO, we compare the proposed methods with other four representative methods:(1)The SISR with the steering kernel regression method [41].The SISR with the neighborhood embedding method [14].The SISR with the sparse coding method [20].The SISR with the non-local means and steering kernel regression method [12].Our method: The SISR with NLSC and GC (called as NLSC_GC).Our method: The SISR with GGP, NLSC, and GC (called as GGP_NLSC_GC).Our method: The SISR with GGP, NLSC, and GLO (called as GGP_NLSC_GLO).Objectively, we employ PSNR and SSIM [42,43] to evaluate the reconstruction quality of different methods. Table 2gives the PSNR and SSIM results of different algorithms. From Table 2, we can observe that method [41] always gives the lowest performance. Both method [14] and method [20] can achieve better results than method [41]. In terms of sparse codings, both of the proposed GGP_NLSC_GC and NLSC_GC methods achieve better results than method [20]. However, compared with method [12], the proposed NLSC_GC and GGP_NLSC_GC methods are both obviously inferior to it. Among all the methods, the proposed GGP_NLSC_GLO method achieves the highest PSNR and SSIM measures on almost all the test images. On one hand, this is because the geometrical structure information of image patches is considered into sparse coding to enhance the sparse coding stability, and the correct edge is reconstructed by GGP. On the other hand, this is because the local steering kernel regression constraint is considered into global constraint equation (23) to preserve the recovered edge reconstructed. All of the above information can effectively reduce the ill-posed problem, and thus can produce more reliable and robust image reconstruction.To further illustrate the effectiveness of the proposed methods, the 3× magnification experimental results of the “Boats”, “Butterfly” and “Parrot” images for visual quality comparison are shown in Figs. 8–10, respectively. As shown in Fig. 8, method [41] reconstructs some high-frequency details, but it cannot recover the weak edges and fine texture details well. Although method [14] reproduces some high-frequency details, it also produces artifacts along edge due to the participation of noisy neighbors during reconstruction, leading to a smooth result. Method [20] reproduces plenty of high frequency details and sharpens edges. Unfortunately, the reconstructed image contains blurred edges and jagged artifacts. The proposed NLSC_GC method can achieve better result than method [20] on reducing artifacts. And the proposed GGP_NLSC_GC method further achieves better result than the proposed NLSC_GC method on sharpness and orientation of the edge. For instance, the sign of “650” looks more visible for GGP_NLSC_GC method in Fig. 8. Method [12] is capable of both suppressing jagged artifacts and sharping the edge, but it generates obvious ringing effects, and also leads to a slight smooth result. Compared with method [12], visually, the proposed GGP_NLSC_GC method shows an outstanding capability to reconstruct correct edges, although the values of PSNR and SSIM of the proposed GGP_NLSC_GC method are obviously inferior to those of method [12]. For instance, the white edge of “Butterfly” (refer to Fig. 9(f)) is continuous. In contrast, the white edge of “Butterfly” (refer to Fig. 9(g)) is discontinuous. In other words, the proposed GGP can effectively reconstruct correct edges. Compared with the outcomes of the others, the proposed GGP_NLSC_GLO method can produce fewer artifacts and achieve both preservation edges and finer details, which are most faithful to the ground truth. In Figs. 8–9, we can see that our result demonstrates better visual quality in terms of the sharpness and preservation of edges and fineness of textures. As shown in Fig. 10, we obtain similar observations to these obtained in Figs. 8–9.We added some Gaussian noise (with zero mean and variance σ) on the four test images (Butterfly, Parrot, Boats, and Parthenon) randomly selected from our ten test images and investigate the performance of our proposed GGP_NLSC_GLO method with the variation of variance of noise. When the noise withσ=4,σ=6, andσ=8are added on the test images, we investigate our proposed GGP_NLSC_GLO method with methods [12,14,20,41]. The reconstruction results of different methods are shown in Table 3. From it we can see that the heavier the noise becomes the worse of the reconstruction results of the five methods are. But among the five methods, our GGP_NLSC_GLO method outperforms others.To further illustrate the robustness of our proposed GGP_NLSC_GLO method, the 3× magnification experimental results of the “Boats” image for visual quality evaluation are shown in Fig. 11. As shown in Fig. 11, although method [41] is capable of suppressing noise, it generates obvious over-smoothed result. Method [14] leads to noisy result while it is good at preserving image edges. Method [20] obtains the denoised result at the expense of smoothing away fine details. Method [12] shows an outstanding capability to reconstruct less noisy image. But, visually, the reconstructed image fails to suppress the ringing effects along the major edges. By contrast, the proposed GGP_NLSC_GLO method is capable of suppressing noise and reconstructing correct edges. Thus, the reconstructed image looks more natural than others. This indicates that the proposed GGP_NLSC_GLO method has stronger robustness against noise.

@&#CONCLUSIONS@&#
The state-of-the-art sparse coding methods have two common drawbacks. The first one is that they easily reconstruct incorrectly the edge structures of image. The second one is that they easily lose the difference among the patches. To resolve the two problems, we proposed a new approach based on global non-zero gradient penalty and non-local Laplacian sparse coding. Firstly, we developed the global non-zero gradient penalty to reconstruct correctly edge component and the non-local Laplacian sparse coding which can preserve the difference to reconstruct texture component respectively. Then, we applied the global and local optimization to finally enhance the performance. A large number of experimental results have demonstrated the effectiveness and robustness of the proposed approach. In Algorithm 2, texture component patch sparse coding and steering kernel calculation are most computationally heavy, which can be speeded up by parallel computing. Hence, the computational cost of the proposed approach can be further reduced.