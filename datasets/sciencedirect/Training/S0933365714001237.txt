@&#MAIN-TITLE@&#
Approaching the axiomatic enrichment of the Gene Ontology from a lexical perspective

@&#HIGHLIGHTS@&#
We propose a method for detecting lexical regularities in ontology labels.We present a metric that measures how to decompose classes that exhibit regularity.We evaluate our method against the Gene Ontology Cross Product Extensions.Our method can contribute to the axiomatic enrichment of biomedical ontologies.

@&#KEYPHRASES@&#
Ontology engineering,Axiomatic enrichment,Biomedical ontologies,Gene Ontology,

@&#ABSTRACT@&#
ObjectiveThe main goal of this work is to measure how lexical regularities in biomedical ontology labels can be used for the automatic creation of formal relationships between classes, and to evaluate the results of applying our approach to the Gene Ontology (GO).MethodsIn recent years, we have developed a method for the lexical analysis of regularities in biomedical ontology labels, and we showed that the labels can present a high degree of regularity. In this work, we extend our method with a cross-products extension (CPE) metric, which estimates the potential interest of a specific regularity for axiomatic enrichment in the lexical analysis, using information on exact matches in external ontologies. The GO consortium recently enriched the GO by using so-called cross-product extensions. Cross-products are generated by establishing axioms that relate a given GO class with classes from the GO or other biomedical ontologies. We apply our method to the GO and study how its lexical analysis can identify and reconstruct the cross-products that are defined by the GO consortium.ResultsThe label of the classes of the GO are highly regular in lexical terms, and the exact matches with labels of external ontologies affect 80% of the GO classes. The CPE metric reveals that 31.48% of the classes that exhibit regularities have fragments that are classes into two external ontologies that are selected for our experiment, namely, the Cell Ontology and the Chemical Entities of Biological Interest ontology, and 18.90% of them are fully decomposable into smaller parts. Our results show that the CPE metric permits our method to detect GO cross-product extensions with a mean recall of 62% and a mean precision of 28%. The study is completed with an analysis of false positives to explain this precision value.ConclusionsWe think that our results support the claim that our lexical approach can contribute to the axiomatic enrichment of biomedical ontologies and that it can provide new insights into the engineering of biomedical ontologies.

@&#INTRODUCTION@&#
Many biomedical ontologies have been developed in recent years, and their development has been stimulated by their increasing importance in the scientific community [1]. An indicator of such an increasing importance is that ontologies are considered to be a key technology for semantic interoperability in healthcare; see the semantic health project [2] and SemanticHealthNet11http://www.semantichealthnet.eu accessed September 2014.for examples. According to [3], an ontology is a set of logical axioms that are designed to account for the intended meaning of a vocabulary; in other words, it is a representation that captures the categories of objects in a field of interest and the relationships that those objects have to each other in such a way that it is possible to recognise category membership. For example, the Gene Ontology (GO) [4] has the aim of standardising the representation of gene product attributes across species and thus across databases. The objects of an ontology encompass different components, such as classes, individuals and object properties/relationships [5]. For human readability, ontology authors include strings of characters as labels that describe an ontology component. However, machines need logical axioms that are expressed in a formal language with which to reason.The Open Biomedical Ontologies (OBO) Foundry [6] contributes to the development of an orthogonal collection of biomedical ontologies and defines criteria22http://obofoundry.org/crit.shtml accessed September 2014.to be followed by biomedical ontology authors who contribute to the OBO Foundry. Ideally, different contributors would model an ontology that focuses on a specific sub-domain, but they would re-use components from other ontologies, where appropriate. However, the high level of activity in biomedical ontologies [7] makes reaching this goal a complex task. Moreover, the largest repository of biomedical ontologies is the National Center for Biomedical Ontology's BioPortal [1], which has 372 ontologies at the time of this writing.According to [8], the labels in biomedical ontologies can embed a meaning that is not always represented as logical axioms in the ontology. Such hidden semantics constitute not only implicit references to components within an ontology but also implicit references to other ontologies. For example, the GO class ‘oocyte differentiation’ is a type of ‘cell differentiation’ that implicitly references the class ‘oocyte’ from the Cell Ontology [9]. The goal of axiomatic enrichment is to make explicit such implicit relationships.The enrichment of ontologies should establish new formal relationships between existing ontologies, increasing the potential and usefulness of the biomedical applications that are supported by such ontologies [10]. In recent years, different approaches have been proposed within this research area:•Reference [11] defined the “lexically suggested logical closure” metric for medical terminology maturity. This metric was based on the evaluation of relationships that were proposed by lexical processing programs.The Gene Ontology Next Generation project aimed to provide a method for the migration of biological ontologies to formal languages such as the Web Ontology Language (OWL) and to explore issues that are related to the maintenance of large biological ontologies [12,13].The Open Bio-Ontology Language (OBOL) project [14] generated formal relationships for existing OBO ontologies using reverse engineering. Later, reference [15] described a frame-based integration of the GO and two other ontologies for improving the logical axioms between classes of biological concepts.Additionally, [16] proposed a method for the enrichment of ontologies by defining ontology design patterns [17] and their corresponding implementation in the Ontology Pre-Processor Language.33http://oppl2.sourceforge.net/ accessed September 2014.Reference [18] addressed the normalisation of GO by explicitly stating the labels of the compositional classes and partitioning them into mutually exclusive cross-product sets; they used a combination of OBOL and manual curation to generate logical axioms, which they called logical definitions, for selected parts of GO.Reference [19] detected hidden semantics, which were named underspecification, in classes from the Systematised Nomenclature of Medicine (SNOMED) that were without logical axioms; the authors used natural language processing, which associated each class with a set of equivalence classes that grouped lexical variants (based on their labels), synonyms and translations.Reference [10] represented the Foundational Model of Anatomy ontology in OWL2, exploiting the naming conventions in its labels to make explicit some hidden semantics. For example, the pattern A_of_B was used to enrich the class ‘Lobe_of_Lung’. In most cases, the name A of B is a contraction that is formed from A and B that omits some logical axiom p that relates the two entities, A and B. The missing p was recovered from scanning the list of property restrictions that are attached to the class. For example, ‘regional_part_of’ is the p for ‘Lobe_of_Lung’.Our approach [16] used a manual analysis of lexical regularities; the results were used for detecting linguistic patterns from a GO sub-hierarchy such as the following: (1) ‘X binding’: the selective, non-covalent, often stoichiometric interaction of a molecule with one or more specific sites on another molecule; or (2) ‘translation X factor activity’: any molecular function that is involved in the initiation, activation, perpetuation, repression or termination of polypeptide synthesis at the ribosome. These linguistic patterns inspired the core concept of this work. In the previous examples, the lexical regularities are the fixed part of the patterns (e.g., binding, translation or factor activity). Another example of a lexical regularity is ‘negative regulation’, which in general stands for the prevention or reduction of a biological process. This linguistic expression appears in several biomedical ontologies, but it is not usually represented with logical axioms. The ‘negative regulation of transcription’ and the ‘negative regulation of translation’ in the Gene Regulation Ontology or the ‘negative regulation’ in the Phenotypic Quality Ontology are similar examples.Our initial hypothesis was that classes that exhibit lexical regularity encode the meaning of a domain object, and there should be a relation between this class and other classes that exhibit that regularity. In previous work, our method demonstrated its ability to retrieve a large set of classes that exhibited regularities, but not all of them are relevant for enriching the ontology. Hence, we identified the need for methods that select which sets are relevant for such a purpose. Therefore, in this paper, we extend our method with a new metric that analyses the relation between the lexical regularities exhibited by the labels of the classes and the labels of the classes that are defined in the ontologies and used for enrichment, namely, the cross product extension (CPE). This metric can be understood to be an estimation of the enrichment of those classes that exhibit such regularities. Moreover, we propose three different conditions of the CPE metric that define different types of matches. Our hypothesis here is that such conditions provide information about the degree and type of enrichment that can be expected. For example, in GO, if ‘translation’ is a lexical regularity that can be generalised as the pattern ‘X translation’, then the usefulness of the pattern can be estimated by the percentage of classes that exhibit the regularity and that are decomposable as cross-products.Here, we focus on the GO for several reasons. First, the GO provides a controlled vocabulary for the functional annotation of gene products. To date, GO classes have been used to produce millions of annotations, which are available in resources such as the GO annotation database [20]. Its enrichment would have an impact on the exploitation possibilities of the GO. Such enrichment would enable machines to not only exploit the GO labels but also manage and exploit more fine-grained objects, such as biochemical substances or links between molecular functions, biological processes and cellular components. Consequently, enrichment provides additional dimensions for analysis, in this case, functional biomedical data. Second, our analysis of BioPortal ontologies revealed the prima facie suitability of the GO for its enrichment: 100% of the classes have labels, 92% of the words of the labels are repeated, and 85% of the ontology labels exhibited 67 lexical regularities [21]. Finally, the GO consortium and other scientists have already identified the necessity of increasing the axiomatic richness of GO, and they have recently developed a partially enriched version, the GO cross-product extensions [18]. In this work, we will compare our results with these GO cross-product extensions. Although each applies different techniques, the comparison will help to evaluate our method and suggest improvements.In this paper, we consider ontologies that are expressed in OWL. We analyse classes (e.g., owl:Class) and their associated labels, which are specified with the owl:AnnotationProperty of the type rdfs:label; both the labels and classes are in the source file of the ontology. Although one class could have more than one label that is associated, we assume a 1:1 relationship between the labels and classes. This assumption is based on our experiments, which revealed that the ratio of the number of labels/number of classes is lower than 1.2 for 98.36% of the ontologies (over a corpus of 244 ontologies).The method applies tokenisation to labels, using a blank (white space) character as a delimiter. A token (Ti) is the smallest fragment of text into which a label can be decomposed using a blank. Thus, each label can be expressed as a token decomposition: an ordered list of tokens T1, T2, …, Tn. For example, the GO has the class GO_2000256 with the label ‘positive regulation of male germ cell proliferation’, and its token decomposition is {T1=‘positive’, T2=‘regulation’, T3=‘of’, T4=‘male’, T5=‘germ’, T6=‘cell’, T7=‘proliferation’}.Our basic assumption is that groups of tokens that appear in many class labels are likely to encode some domain meaning. We refer to such groups of repeated tokens as lexical regularities.Definition 1Lexical regularity (LR)A lexical regularity is a group of consecutive, ordered tokens that appear in more than one class of an ontology θ. Because a lexical regularity can be identified by its sequence of tokens Ti, …, T(i+k) (where k∈{0, 1, 2, 3, …}), LR⊆the set of labels. Every lexical regularity is related to the set of classes that exhibits it, CS{LR}={C1, …, Cl}. CS{LR}⊆the set of ontology classes. Each LR has a frequency that is equal to the size of the set CS{LR}, which allows them to be ordered. The more frequent the LR is, the more general it is.Given an ontology θ, its lexical analysis comprises the whole set of lexical regularities that are found in the ontology, LA={LR1, …, LRn}.The previous definition of lexical regularity considers the most general case, which requires only one repetition for a lexical regularity. However, two repetitions in hundreds of classes might be irrelevant; to address this issue, we define an input parameter of a lexical analysis: the coverage threshold.Definition 3Coverage threshold (CV)The coverage of a lexical regularity is the minimum percentage of classes in which a lexical regularity must appear to be included in the lexical analysis.The value of the coverage threshold has a clear impact on the number of lexical regularities that are retrieved, and this number depends on different factors. For example, an ontology that follows a systematic naming convention in its labels would produce a larger number of regularities. The reason is that the descendant classes include some of the labels that belong to their ancestors.The coverage threshold is a minimal threshold. Once the lexical regularities have been identified and meet the coverage threshold, they are grouped and studied by their frequencies. In this way, we group the lexical regularities whose frequency belongs to concrete intervals [(MinFrequency, MaxFrequency)], which would depend on the specific study, as will be illustrated later in the results section.Linguistic patterns such as X binding are composed of a fixed part (the lexical regularity ‘binding’) and a variable part (X). The lexical regularities encode such fixed parts. In addition, the text of the lexical regularity can be the entire label of a class that already exists. For example, ‘binding’ is a lexical regularity that appears to be a self-standing label of the class GO_0005488, but it is also a part of the class labels ‘frizzled binding’, ‘transcription factor binding’, and ‘FMN binding’. In this case, ‘binding’ is the most general class, and the others are specialisations, which should be formalised with logical axioms such as is_a.Given that our method can identify overlaps between tokens in ontology labels, concepts such as external ontologies and exact matches must be defined.Definition 4External ontologyAny ontology that is not directly imported by the ontology being analysed. An external ontology can be used to enrich such an ontology.The type of overlap between a label of the ontology being analysed and a label of the same ontology or an external ontology. This arrangement occurs when an ordered group of tokens from the label of a class of the ontology that is being analysed is found in the same order as the whole set of tokens of a different class label in the same ontology or in an external ontology.For example, the search for the lexical regularity ‘binding’ in BioPortal retrieved 20 external matches in ontologies such as the Neural-Immune Gene Ontology (reusing the class from the GO) or the National Institute Thesaurus (without reusing the class from the GO).A lexical regularity has some associated descriptors, such as its content (tokens), length (number of tokens), or frequency in an ontology. Next, we summarise the general metrics that our approach uses to analyse the content and structure of the labels of an ontology. These metrics are classified into the following three groups:•Metrics of an ontologyθ: (1) number of classes in an ontology; (2) number of labels; and (3) the type token ratio (TTR), which measures the lexical diversity of the ontology labels. This ratio is calculated as the number of unique tokens (types)/the total number of tokens.Metrics of the lexical regularities: (1) percentage of classes in which the lexical regularity appears; and (2) number of tokens (e.g., length) of the lexical regularity.Metrics of an ontologyθbased on its lexical regularities: (1) number of lexical regularities found in the whole ontology for a given coverage threshold; (2) set of classes that exhibit lexical regularities: number and percentage of classes that exhibit lexical regularities in a lexical analysis; (3) number of lexical regularities that have external matches; (4) set of classes that exhibit lexical regularities with matches: number and percentage of classes that exhibit a lexical regularity and have at least an exact match in external ontologies; and (5) mean number of external matches by lexical regularities.We represent the set of labels of a given ontology using a graph that is similar to the graph in Fig. 1. Each token is a node in the graph, and the arrows represent the order of the tokens in a given label (see Fig. 1). We also store additional information, such as the index in the label (because the same token could appear several times in the same label) and the uniform resource identifier (URI) of the class. The graph is built as the ontology labels are parsed. For example, Fig. 1 shows the part of the graph that highlights the regularity ‘regulation of isoprenoid’ of length 3 (tokens).The graph shows the analysis of four class labels: (1) ‘positive regulation of isoprenoid’, (2) ‘negative regulation of isoprenoid’, (3) ‘vitamin binding’ and (4) ‘isoprenoid binding’. Their lexical analysis yields a graph of 7 nodes (tokens) and highlights 4 shared tokens across the four labels. The token ‘regulation’ is common in labels 1 and 2; thus, the corresponding node has two input arrows in the graph. Similarly, token ‘of’ is shared across labels 1 and 2; thus, the incoming arrow of the corresponding node in Fig. 1 has the label ids on the top. The direction of the arrow depicts the order of the tokens. For example, the ‘regulation of isoprenoid’ regularity consists of three consecutive tokens that are used in labels 1 and 2. Similarly, ‘binding’ is shared across labels 3 and 4.Algorithms 1 and 2 describe how the lexical graph is created (lines 1–19 of Algorithm 1) and how to extract lexical regularities from an ontology (lines 21–25 of Algorithms 1 and 2).Algorithm 1Pseudo-code of the algorithm for loading an ontology, extracting the labels, creating the graph and finding lexical regularities. The variables are represented in redThe GO cross-product extensions [18] provided logical definitions for GO classes using genus-differentia constructs of the form “an X is a G that D”. Here, X is the class that we are defining, G is the genus (more general class), and D is the differentia, a collection of characteristics that serves to discriminate instances of X from other instances of G. For example, the class ‘mitochondrial translation’ can be seen as the genus ‘translation’, and the differentia occurs inside a ‘mitochondrion’. Such logical definitions can be partitioned into mutually exclusive sets that are called cross-products. Each XP is a subset of the cross-product between one genus and one differentia between two ontologies, and such a cross-product is identified by genus_X_differentia (i.e., GeneOntology_X_CellOntology).If the labels of the classes of the source ontology have exact matches in an enriching ontology, then part of the domain that is defined in the source ontology refers to concepts that are defined in an enriching ontology. For example, the class ‘oocyte differentiation’ is formally defined using the parent class ‘cell differentiation’ from the GO biological process ontology and using discriminating characteristics that reference ‘oocyte’ in the Cell Ontology. This approach can be represented in OWL Manchester syntax asThis style of definition is a direct counterpart to that of our approach.•Source ontology (θS): the ontology whose lexical analysis is performed and for which the lexical regularities are obtained. This ontology is the ontology that we want to enrich, and it plays the role of genus.Enriching ontology (θE): the ontology used for finding exact matches from tokens of those classes where a lexical regularity appears (from the source ontology θS). This ontology is not used to find any lexical regularity but plays the role of filler for the differentia that extend the description in the source ontology.The selection of θE depends on the domain described in θS. An ontology must play the role of θS if the user has the intuition that its concepts can be defined by reusing concepts from θE. For this reason, given the ontologies A and B, the meaning of the process A=θS and B=θE (A×B) would be very different from the inverse process A=θE and B=θS. For example, one of the GO sub-domains is the cellular component ontology, which describes the locations for the gene products at the levels of subcellular structures and macromolecular complexes. Examples of cellular components include ‘nuclear inner membrane’; thus, parts of these classes can be enriched using an ontology that is focused on cells, for example, the Cell Ontology. The inverse approach, which would involve defining types of cells by reusing cellular components, might not make sense.Moreover, a lexical regularity could have several exact matches in the enriching ontology. For example, ‘motor neuron apoptotic process’ defines a specific type of biological process (θS). Its groups of tokens ‘motor neuron’ and ‘motor’ have exact matches in the Cell Ontology (θE). This arrangement is a consequence of the hierarchy of concepts in ontologies, where specialisations are expressed as compound nouns in natural language. For example, ‘motor neuron’ is a specific type of ‘neuron’. Multiple exact matches basically differ in the tokens that are involved and represent different alternatives for enriching the class. This arrangement has led us to propose three different conditions that impose different criteria on the exact matches.Definition 6Cross product extension condition of a class (CPE-class)Given the token decomposition (TD) of a label, the CPE-class is a Boolean condition, and it has three variations/versions that are controlled by the user. For each version, CPE is true when•CPE – Condition 1 (CPE-c1): at least one single token of TD has an exact match in the enriching ontology θE.CPE – Condition 2 (CPE-c2): at least one sub-list of TD has an exact match in the enriching ontology θE. The sub-list is created using combinations of consecutive tokens. The length of the sub-list ranges from 1 to the maximum number of tokens, and thus, it includes condition 1. There could be sub-lists that have the cardinality 2 (or more), which would correspond to all of the tokens of a label, but their corresponding sub-lists of size 1 would not.CPE – Condition 3 (CPE-c3): the sub-lists of TD that have exact matches in the enriching ontology θE or the source ontology θS include all of the elements in TD. If all of the elements are found in θS, then we call it an intra-decomposition.The three versions of the CPE provide complementary information, not only about our ontology but also about the enrichment ontology that is used. Given an ontology and two different θEs, the CPE values show some properties of the relation of our ontology with the enrichment ontologies. The three conditions of the CPE provide information about how partial and specific the enrichment can be for the different classes. Let us suppose that we perform an analysis on our class with the label ‘positive regulation of biological process’ and two classes with the labels ‘regulation’ and ‘positive regulation’ in two different enrichment ontologies, A and B.•CPE-c1 would be true for A and not for B, which means that partial enrichment could be achieved using A.CPE-c2 would be true when using both A and B, which means that partial enrichment could be achieved with both ontologies.CPE-c3 would be false for both A and B, which means that the class cannot be completely enriched with both ontologies. The complete enrichment of a class can be ensured only when CPE-c3 is true.The CPE-class condition allows for filtering classes that are based on exact matches; in other words, they are based on an estimation of the enrichment of the lexical regularities that are associated with the classes, as follows:Definition 7Degree of CPE of a lexical regularity (CPE-metric)Given a lexical regularity and the set of labels in which it appears, we estimate the enrichment of the regularity by measuring the percentage of the members of this set that have the CPE-class condition true. This percentage depends on the CPE-class condition that is chosen as well as the selected θE.For example, the lexical regularity ‘binding’ is found in 1592 labels of the molecular function sub-ontology of the GO, which plays the role of θS. Using the Chemical Entities of Biological Interest (ChEBI) as θE, the degree of CPE of ‘binding’ using CPE-c3 is 1087 labels; thus, 68.27% of the labels that exhibit regularity are fully decomposable using the class ‘binding’ from θS and the other classes from θE. We could not automatically enrich the remaining classes that have CPE-c3 as false, although the results that are provided by less restrictive versions of the CPE and that search for partial decomposition (CPE-c1 or CPE-c2) could help the ontology authors to understand the regularity.Fig. 2shows the decomposition of the label ‘ammonium ion metabolic process’ (GO_009714), using GO as θS and ChEBI as θE. This metabolic process stands for the chemical reactions and pathways (metabolic processes) that involve ammonium ions (as chemical entities). Fig. 2 shows the graph representation of the 5 labels that illustrate the decomposition in the example. The token decomposition of ‘ammonium ion metabolic process’ has 4 tokens: ‘ammonium’, ‘ion’, ‘metabolic’ and ‘process’. These tokens are, respectively, in positions 1–4. The CPE algorithm finds ‘metabolic process’ as the entire class label in θS (see the cross-hatched circle in Fig. 2). The algorithm inspects the edges and detects that these two tokens are the class label that has the identifier L2; thus, the tokens in positions 3 and 4 are marked. Moreover, ‘ammonium’, ‘ion’ and ‘ammonium ion’ are the entire labels of three classes in θE (see the hatched circles in Fig. 2); then, the tokens in positions 1 and 2 are marked as well. As a result, the value of the metric CPE-c3 for this annotation is true because all of the tokens of the label are found in θS or θE. CPE-c1 and CPE-c2 are also true because single (‘ion’ and ‘ammonium’) and multiple (‘ion ammonium’) matches are found in the θE. We think that using the three conditions permits us to obtain complementary information that could help the ontology author to make the best decisions to enrich the ontology.Fig. 3shows the workflow of the lexical analysis. The workflow consists of 2 main stages, which are implemented in the new version of our OntoEnrich software [22]. Fig. 3 also includes the validation stage that is used in this paper but that is not a part of the general method.•(Stage 1): the user specifies an ontology (ontology file A) in OBO or OWL that plays the role of θS. The lexical analysis is saved into an eXtensible Markup Language (XML) file (lexical analysis A) that is the input to the OntoEnrich module that calculates the metrics. An extract of this file is shown in Fig. 4and contains two main sections. Section 1 includes information about the ontology and other input parameters of the lexical analysis, such as the value of the coverage threshold. Section 2 includes the lexical regularities that are detected in the lexical analysis.(Stage 2): the module for calculating metrics takes as inputs the files that have the lexical analysis of θS and θE. The calculation of all of the CPE conditions is performed and saved into a new XML file. This XML file contains only those classes for which the CPE metric is true, and they are grouped by lexical regularities. We call this process thereduction of a lexical analysis, which includes additional information about the decomposition of the CPE (see node <decomposition> in Fig. 4), similar to other classes in θS or θE for which each label is matched.(Validation stage): this stage focuses on the evaluation and comparison of our method against a gold standard. To accomplish this goal, we create two independent files that have URIs of classes in our lexical analysis and the enriched file from Mungall et al. (2011). We explain our strategy in Section 3.3.

@&#CONCLUSIONS@&#
Biomedical ontologies are typically rich in text content (labels and annotations), but such information is often missing in the logical axioms. Our previous work revealed that many of the ontologies from BioPortal present lexical regularities in the structure and content of the labels [21].Our method has retrieved 44 lexical regularities from the GO that were found in other BioPortal ontologies, which cover 80% of the classes. The application of the CPE conditions allows us to reduce the classes that exhibit regularity, which reduces the number of results to those that meet the criteria that are defined under such conditions in terms of only one enriching ontology. We have compared our method for detecting useful regularities with the GO cross-product extension effort. Our method, after removing intra-decompositions, showed a mean recall of 62% and a mean precision of 28%. This study has been completed with an analysis of both false negatives and false positives. Concretely, CPE-c3 false positives could be useful for generating new axioms that are based on the decompositions.Our automatic, lexical approach (CPE-c3) covers 48% of the decompositions that are found in the reference method. This finding confirms the hypothesis that classes that exhibit regularities together with information on token matches (decompositions) are prone to be enriched.To conclude, we think that our results support the claim that our approach can contribute to the axiomatic enrichment of biomedical ontologies and can provide new insights into the engineering of biomedical ontologies.