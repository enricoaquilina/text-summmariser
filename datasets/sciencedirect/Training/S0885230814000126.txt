@&#MAIN-TITLE@&#
Speaker adaptive voice source modeling with applications to speech coding and processing

@&#HIGHLIGHTS@&#
We model the speech signal by a speaker adapted glottal source and a vocal tract filter.The source model used is a physically based dynamical model representing vocal fold oscillation.The model is fitted to different speaker voice samples.Transformations are operated effectively through control of the glottal model.Experimental evidence of the effectiveness of the model is provided through objective and subjective assessment.

@&#KEYPHRASES@&#
Glottal modeling,Model inversion,Model-based transformations,Speech synthesis and processing,

@&#ABSTRACT@&#
We discuss the use of low-dimensional physical models of the voice source for speech coding and processing applications. A class of waveform-adaptive dynamic glottal models and parameter identification procedures are illustrated. The model and the identification procedures are assessed by addressing signal transformations on recorded speech, achievable by fitting the model to the data, and then acting on the physically oriented parameters of the voice source. The class of models proposed provides in principle a tool for both the estimation of glottal source signals, and the encoding of the speech signal for transformation purposes. The application of this model to time stretching and to fundamental frequency control (pitch shifting) is also illustrated. The experiments show that copy synthesis is perceptually very similar to the target, and that time stretching and “pitch extrapolation” effects can be obtained by simple control strategies.

@&#INTRODUCTION@&#
Despite the fact that dynamical physical models of speech production including the glottal source have nowadays reached a high degree of accuracy, it is remarkable that they are rarely used in common applications like speech processing and speech synthesis. The widespread linear prediction (LP) technique for speech coding, is only loosely inspired by voice acoustics and it is a signal model rather than a physical one, even if LPC coefficients are related to the shape of the vocal tract (Makhoul, 1975). If we look at the computer graphics community, we note how much effort is being devoted recently to the development of effective physically based models and model-based parameter tracking algorithms, and how this has led to highly realistic and natural animations. The reason for such a difference is most probably the lack of compact articulatory speech models and robust model inversion techniques that can provide a framework to accurately represent recorded data and allow robust parameter control at the same time. On the other hand, growing interest toward accurate glottal source coding for speech technology research and applications has been recently demonstrated in various specific fields, e.g. text-to-speech (TTS) synthesis (Raitio et al., 2011), voice conversion (Childers, 1995), emotional speech analysis and synthesis (Gobl and Chasaide, 2003).Various approaches have been proposed to date for the modeling of the voice source, i.e. the volume velocity of air passing through the glottis, modulated by the opening and closing of the vocal folds during voiced phonation. The analytical model approach represents the glottal flow waveform in terms of piecewise analytical functions, providing a compact parameterization of the glottal flow cycle. Among these, Rosenberg's model (Rosenberg, 1971) and the Liljencrants–Fant (LF) model (Fant et al., 1985) are widely known and often used as reference models for glottal flow estimation and representation (Krishnamurthy, 1992; Plumpe et al., 1999; Drugman et al., 2012). Recent investigations relying on analytical models of the voice source have also addressed the representation of speech through joint source and vocal tract filter optimization (Fu and Murphy, 2006; Jinachitra and Smith, 2007; Agiomyrgiannakis and Rosec, 2009; Ghosh and Narayanan, 2011), with effective results.The class of analytical source models however does not attempt to reproduce the dynamical phenomena underlying the self-sustained oscillations of the vocal folds and their interaction with the airflow through the glottis, ruled by fluid-dynamics laws. The reproduction of the source dynamics is instead addressed by a class of physically inspired models, proposed originally by Flanagan and co-workers (Ishizaka and Flanagan, 1972), which represent the vocal folds by two or more damped mass-spring systems coupled to each other, and which derive the nonlinear interaction with the airflow from aerodynamic equations describing the pressure drop from the lungs to the supraglottal region. Since then, a wide range of variations and improvements have been proposed, which were mostly intended to provide more accurate and detailed descriptions of the glottis dynamics (Koizumi et al., 1987; Liljencrants, 1991; Titze, 1988). More accurate modeling has considerably increased our understanding of the phonatory process, at a price, however, of increased computational complexity and increased difficulty in fitting the model to observed data. One of the first papers addressing the issue of dynamical model inversion is Schroeter and Sondhi (1991), in which experiments targeted at demonstrating the feasibility of deriving the control parameters of a dynamical physical model are reported. It is also argued in Schroeter and Sondhi (1991), that dynamical physical models are potentially interesting since they can provide realistic excitation signals, by reproducing such natural effects as transients in the dynamical behavior due to changes in the various physiologically motivated control parameters (e.g., lung pressure, or vocal fold tension). This perspective motivated the choice of the authors of pursuing research toward glottal models and inversion methods aimed at representing and reproducing the essential dynamical characteristics underlying the glottal flow waveform, while keeping the possibility of being effectively fitted to real data and controlled by physiologically motivated parameters.In this paper, we discuss the use of a class of glottis models characterized by a low dimensional dynamics, for applications in the framework of model-based speech coding, glottal source estimation and voice transformation. The voice source model proposed is a source-filter scheme in which the vocal tract is represented by an all-pole filter and the voice source model relies on a lumped mechano aerodynamic scheme inspired by the mass-spring paradigm. In previous investigations, we discussed the possibility of fitting this class of low-dimensional physically constrained models to real voice samples (Drioli, 2003), and illustrated its stability and control characteristics (Drioli and Avanzini, 2003). Here, we focus on the fitting to time varying voice samples (i.e., short speech utterances), and provide the basis for voice transformations. Possible applications of the method discussed include acoustic database coding for TTS systems, emotional speech synthesis, speaker characterization, speaker voice conversion, and speech compression.The paper is organized as follows. In Section 2, the model is illustrated and the inversion procedure used to fit voice data is discussed; in Section 3, the proposed method is applied to speech data and its performance is evaluated with respect to speech encoding. Results on simple time stretching and pitch shifting transformations are reported; in Section 4, some experiments and perceptual assessment results are discussed, and in Section 5, the conclusions are drawn.In this section we describe the model used to represent the vibration of the vocal folds, and the procedure to fit the model to real data (also referred as model inversion). It is worth noting how the inversion of dynamical models of speech is known to be a non-trivial task, due to their nonlinear nature and to the high number of parameters usually involved. We thus propose to use a particular class of glottal models, which have been designed to simplify the overall numerical scheme and reduce the computational complexity, while retaining the principal characteristics of flow-induced oscillation of vocal folds.Let the pressure signal measured by the microphone at the lips be given by(1)y(t)=−∑k=1Naky(t−k)+u˙g(t)where a1, …, aNare the auto regressive (AR) coefficients of an all-pole model of the vocal tract, andu˙g(t)is the derivative of ug(t), the glottal pulse waveform. The voice source model used to represent ugrelies on the mass-spring paradigm adopted, among others, by the well known Ishizaka–Flanagan one-mass and two-mass models. The details of the glottal excitation model, illustrated in Fig. 1, can be found elsewhere (Drioli, 2005), and here we only briefly recall the essential components.The lower edge of the folds is represented by a single mass-spring system k, r, m (Hres) and the propagation of the displacement x along the thickness Th of the folds is represented by a delay line of length τ. Let x1 be the displacement of the fold at glottis entrance, and x2 the displacement at the exit. An impact model reproduces the impact distortions on the fold displacement and adds an offset x0 (the resting position of the folds). The driving pressure Pmacting on the folds is computed from the lung pressure Pl, the flow ugand the lower glottal area A1, using Bernoulli's law: Pm=Pl−1/2ρug/A1 (ρ being the air density). In Fig. 1, the vocal folds and the Bernoulli term (HresandB, respectively) are enclosed in the fluid mechanical component of the discrete-time model. A flow modelFconverts the glottis area given by the fold displacements into the airflow at the entrance of the vocal tract. In its simplest form, the glottis area is computed as the minimum cross-sectional area between the area at lower vocal fold edge, A1=L·x1, and the area at upper vocal fold edge, A2=L·x2. The flow is then assumed proportional to the glottal area, i.e.ug=F(x1,x2)=kgmin(x1,x2)(where the lung pressure Plis included in kg). The delay line of length τ reproduces the vertical phase difference of the vibration of the cord edges, which is essential for the production of self-sustained oscillations without a vocal tract load. The lung pressure, Pl, has a role in determining the onset and offset of the oscillation. In our simulations, it is kept constant during the system evolution and is omitted for simplicity in what follows. The mass-spring system k, r, m is modeled as a second-order resonant filter, characterized by a resonance frequencyf0=1/2πk/m.A refined flow model in which a kernel machine componentF1(x1,x2)is aimed at improving the flow waveform matching properties of the basic model, was introduced in (Drioli, 2005) (Fig. 1, dashed signal path). We recall here thatF1(x1,x2)=∑i=0Mwiψi(x1,x2), with ψi(x1, x2) being the M radial kernels of the expansion (usually a set of Gaussian kernels, centered along the path drawn by the system dynamics, is the preferred choice), andwibeing the M expansion coefficients. We further explore here this solution by using a modified scheme (illustrated in Fig. 1 with a continuous path in place of the dotted path), in which the kernel machine component does not interfere with the dynamics of the main iterated mapug(n)=M[ug(n−1)], where the mapMis defined by the composition of the various component in the computation loop, i.e. the vocal folds model, the Bernoulli term and the flow model. This solution ensures that the stability of the system is not affected by the flow modifications introduced by the kernel machine component. The details of the training procedure to match real glottal flow data have been discussed in Drioli (2005), in which it is shown how the termF1(x1,x2)is aimed at “reshaping” the surface on which the trajectory of the system dynamics, observed at the flow model inputs and output, lies during the periodic motion. In other words, the kernel component provides a refinement of the rough flow model. Here we are interested in model based voice transformations, including changing the frequency of oscillations while keeping the waveform characteristics learned from the data and stored in the kernel machine component. Changes of the frequency of oscillations of the glottal pulse, while preserving waveform characteristics and formants, will ideally provide a physiologically constrained pitch shift transformation. Pitch control with this scheme, however, has experimentally proven to often result in performance degradation, due to the influence of the kernel component in the dynamics computation loop (Drioli, 2005). This situation is illustrated in Fig. 2, in which the glottal waveforms as well as the trajectories in the (x1,x2,ug) space are depicted. In the alternative solution, since the contribution of the kernel machine does not affect the iterated map dynamics of the glottal model, the resulting glottal waveform retain the same characteristics of the original period shape at the new oscillation frequency, as shown in Fig. 2. For this reason, this solution seems to be a better choice for the modeling aimed at speech transformations, although the scheme in which the refined glottal flow is injected in the computational loop would be more correct from a modeling point of view. In the following, when talking of refined glottal flow waveform, we will refer to the stable scheme in which the flow refinement term does not enter the dynamical computational loop. Note that in this case the dimensionality of the dynamical part of the system is kept low, and in principle we could look at the refinement term as to a tool to control the shape of the glottal flow period, without modifying the dynamical characteristics of the self-sustained oscillations.In the following, the model is fitted to time-varying recorded speech data with a pitch-synchronous parameter identification procedure, summarized in Fig. 3. In the present investigation, we decided to restrict the identification of the mechanical part of the model only to the resonance frequency of the mass-spring system (f0), and to keep constant during the model evolution all other free parameters (i.e., the thickness of the folds τ, the folds resting position x0, and the lung pressure Pl). Typical values providing stable behavior and a balanced closed phase to open phase ratio were used, i.e. x0=0.8mm, τ=1mm, and Pl=2000Pa. A multidimensional optimization concerning the fine tuning of these parameters, will be the subject of future research.The procedure performs a joint source-vocal tract identification through the following steps:1A fixed length running analysis window is shifted by a variable hop size equal to the period length.On the current analysis frame, whose length corresponds to around three periods of speech, a conventional LPC analysis is performed to obtain a rough estimate of the vocal tract filter.The fundamental frequency, estimated through a pitch detector, is used to tune the mass-spring system representing the folds, and the glottal model is used to generate a synchronized and phase-aligned glottal pulse.A fitting procedure is used to solve the estimation problem which provides the parameters of the vocal tract filter, given its time aligned input (the glottal source) and output (the target speech signal).The glottal pulse is finally refined by training the kernel machine componentF1(x1,x2)to match the target glottal pulse, obtained by inverse filtering the target speech waveform through the vocal tract filter obtained in the previous step.Iterate steps 4 and 5 to improve the accuracy of data fitting.The time-varying parameters a1, …, aNof the AR filter representing the vocal tract are calculated pitch-synchronously (step 4), by solving a set of linear equations obtained from Eq. (1) for a glottal cycle time interval [t0<t<t0+P], P being the period length. Given the target speech data y(t), t∈[t0, t0+P], the problem can be stated in vector form:(2)y(t)=θϕ(t)+ϵ(t)=y˜(t;θ)+ϵ(t),with θ=[a1, …, aN, b1],ϕ(t)=[−y(t−1),−y(t−2),…,−y(t−N),u˙g(t)]T,y˜(t;θ)being the reconstructed signal, and ϵ(t) being the estimation error sequence.The optimal estimateθˆfor the vocal tract parameters can then be found by a least-square optimization: given the vector yP=[y(t0), …, y(t0+P)]Tand the matrix ΦP=[ϕ(t0)|ϕ(t1)|⋯|ϕ(t0+P)]T, thenθˆ=(ΦPTΦP)−1ΦPTyP. As an alternative, an iterative optimization which calculates the vocal tract parameters given a set of starting values can be used. This can be achieved for example by using Newton or Levenberg Marquardt algorithms, minimizing the cost function given byC(θ)=∑i=1P(y(ti)−y˜(ti;θ))2. In our experiments, the former least-square solution showed to be more prone to result in discontinuous filter poles tracks, whereas the latter showed to provide desirable pole tracks smoothing properties when the parameters of the previous analysis frame are used as the starting point for the search. An iterative optimization procedure was thus used in the last vocal tract identification step.At each analysis frame, the AR filter coefficients are converted into pairs of conjugate roots zk=rke±θk, k=1, …, N/2, representing peaks in the energy spectrum which are related to vocal tract resonances, and the frequency and bandwidth of each pair are computed by Fk=Fs/(2π)θkand Bk=−Fs/πlnrk, Fsbeing the sampling rate. This information can be used to provide a visualization of the time varying vocal tract identification performance along the voice sample, as shown in Fig. 4(only first three pole tracks are shown in this case). In the upper right plot of 4 it can be seen that the proposed procedure is pitch synchronous, since the distance of track dots increases as the pitch of speech decreases.During the parameter identification process, the tuning of the vocal fold model is performed in two steps: first, a rough estimate of the mass-spring system resonance is given by a pitch detection algorithm; in the second step, this estimate is refined through an iterative procedure which at each iteration j attempts at reducing the time lag ξ(j−1), evaluated through the autocorrelation between the glottal pulse and the target signal, inverse filtered using the LPC filter. The fine tuning of the pitch is achieved using the adaptation formula f0(j)=f0(j−1)−ϵξ(j−1). This two-step procedure is required to ensure that the glottal pulse signal and the target waveform are kept synchronized. Due to the nonlinear nature of the dynamical glottal model, the resulting glottal pulse may in fact be characterized by an actual fundamental frequencyf0′which can deviate from the control frequency f0. Thus, a standard pitch detection procedure is in general not sufficient to correctly synchronize the model and the data.When a refined glottal flow identification is desired, the kernel machine time varying parameterswi, i=1, …, M, are identified in step 5 through a least squares parametric matching, aiming at minimizing the difference D(n) between the generated rough glottal flow ug(n) and the glottal flowugIF(n)obtained by inverse filtering the target speech waveform through the estimated vocal tract filter:D(n)=||F1(x1,x2)−(ug(n)−ugIF(n))||2. Since the minimization of D(n) is done over the whole glottal period interval, the least squares solution is obtained as usual through matrix inversion (Drioli, 2005). Note that the Gaussian kernels are preliminary centered along the path drawn by the system dynamics (spanned by x1 and x2) and are held constant during the training.The adaptation method described so far proved to be rather robust on a wide number of experiments. There are however a few factors that can impact on the effectiveness of the procedure. The method is rather sensitive to starting conditions, since an accurate positioning of the starting analysis window and an accurate initial alignment between glottal flow and target waveform is required. In our experiments the analysis range is selected manually, whereas the first frame alignment is performed automatically through a cross-correlation maximization. Being a time-domain matching algorithm, it should also be stressed that no phase distortions should be introduced in the target speech data, since this would affect the vocal tract identification step. Finally, since no explicit formant smoothing algorithm is included, the pitch synchronous update of the vocal tract filter might occasionally be the source of audible discontinuities and artifacts if the filter optimization procedure results in abrupt filter coefficient changes.The voice model inversion procedure discussed so far is now illustrated on actual voice recordings featuring short speech utterances (isolated words). For words containing both vowels and consonants, the model is adapted only to voiced parts of the speech samples.To illustrate the tracking and encoding procedure, we refer to a male voice sample reproducing the Italian word aiuola, and to a female voice sample reproducing the English word park. Both were mono recordings with 16-bit resolution and 16kHz sampling rate. Fig. 4 shows qualitative results in terms of reconstructed glottal waveform. In Table 1, coding performance of the proposed model is reported in terms of segmental signal to noise ratio (SNR), defined here as the ratio of signal power to the reconstruction error power, and Itakura–Saito distance (IS) (Basseville, 1989), providing a measure of the distance of the reconstructed speech spectrum to the target spectrum. The first column refers to a reference LPC analysis procedure in which a standard LPC analysis of order 20 is used to compute the AR filter, an autocorrelation pitch detection algorithm is used to control the generation of a glottal pulse (rough version) used to excite the AR filter, and no fine pitch tuning is performed. Thus, the target and reconstructed speech may lose synchronization, and this explains the very poor SNR performance; the second column differs from the first in that the fine tuning step is introduced, thus the two waveforms are guaranteed to be in phase; third column refers to the situation in which the vocal tract estimate of order 20 is performed by solving a least squares problem considering the generated glottal pulse as input, and the target speech signal as output. Input and output are kept in phase by the fine tuning procedure. The last column differs from the preceding one, in that the refinement step of the glottal pulse is introduced. The kernel machine used in these experiments was a radial basis function (RBF) with Gaussian kernels. A constant number of 30 kernels was used for each analysis frame. It can be seen how the fine tuning and the glottal pulse refinements steps improve considerably the matching performance.It is worth noting that using too many kernel components can lead to an overfitted model which will be extremely accurate in reproducing the glottal flow subtleties, including noise, but will provide in turn poor generalization properties. Fig. 5shows the period-by-period evolution of the kernel expansion coefficientswiover a short segment of speech, for two values of M (the number of kernels) taken at the lower and upper limits of the range considered in our experiments. To provide a qualitative picture of the stability of coefficient trajectories over time, one can fit each trajectory with a polynomial curve and take the fitting error energy (averaged over all coefficients) as a smoothness measure. Fig. 6shows the waveform fitting error energy and the polynomial fitting error energy, both normalized, for different values of M in the range [5, 60]. As expected, as the number of kernels grows, the speech waveform fitting error decreases and the error of coefficient trajectory polynomial fitting increases. Based on these considerations and on our experience, M=30 appears to be a reasonable choice. We will thus use this value for the experiments discussed in the remaining of the paper.The analysis performed with the tracking procedure was then used to synthesize transformed versions of the original sample. The following transformations are evaluated:•Time stretch, obtained by allowing the glottal model to run with a given set of analysis parameters for longer or shorter time intervals with respect to the corresponding analysis hop time intervals.Pitch shift, obtained by multiplying by a scale factor the analysis mass-spring system parameters responsible for the oscillation frequency.In the present implementation of time stretching, the analysis parameters are not interpolated over time (i.e., when the excitation is generated for a longer duration than the original one, the same values are kept constant for more than one period).Other feasible transformations, to be investigated in the future, include concatenation of variable length speech units (e.g., phonemes, diphones, words, etc.), and transformations of voice quality obtained by acting on other parameters of the source model.Fig. 7shows the spectrograms of the result of time compression (upper panels) and expansion (lower panel). Fig. 8shows the details of two pitch shifting transformations, produced by Δf0=+30% (middle plots) and by Δf0=−30%. A selection of audio samples featuring copy synthesis and pitch or time transformations are provided as supplementary files.The proposed voice coding and processing method was assessed by computing objective measures and a perceptual test on a collection of voice samples. The voice test material used for the objective evaluation consisted of a selection of 10 samples from the UCL Speaker Database (Markham and Hazan, 2002), reproducing the isolated word “park” uttered by five male and five female adult English speakers. The speech database was originally recorded at a sampling rate of 44.1kHz with 16-bit resolution, and a publicly available, 16kHz downsampled version of the samples, was used in our experiments. The analysis region of each sample was manually selected in order to exactly include the voiced part between the two occlusives.Objective measures concerned the quality of the speech sample encoding, i.e., the copy synthesis. The results are illustrated in Table 2, in which the segmental SNR and IS distance values are reported, for distinct modeling settings. Segmental SNR and IS values for each sample are averaged over 20 frames, each one corresponding to a waveform period, and the values reported in table are averages over two distinct sets, containing respectively all the female and all the male voice samples. It can be noticed how female voice samples were characterized by a slightly inferior quality performance both in the SNR and in the IS measure. The difference in the measures is due to poorer performance in the vocal tract optimization step, given the glottal input and target speech waveform. One possible issue that could motivate this behavior is that the glottal source parameters that were held constant during the optimization, i.e. x0,τ, and Pl, were the same for both male and female samples. Since the open/closed phase ratio of the flow is influenced by these parameters, it is likely that the female voice samples were fitted with a glottal source characterized by a closed phase longer than the true closed phase. This issue will need to be further investigated by adapting the open/closed phase ratio of the source to the target voice.Perceptual measures concerned both the quality of the speech sample encoding (copy synthesis) and the quality of pitch-shifted and time-scaled versions, obtained through the model based transformations discussed in this paper. The voice test material used for the perceptual evaluation consisted of a selection of 6 samples from the UCL Speaker Database reproducing the isolated word “park” (3 male voice samples and 3 female voice samples), plus a selection of 4 samples from the North Texas vowel database (Assmann et al., 2008), uttered by the same speaker (male, adult) and each one reproducing one isolated word: “hayed” (for diphthong /ei/), “heed” (for vowel /i/), “hoed” (for vowel /o/), and “who’d” (for vowel /u/). The North Texas vowel database samples were also converted to a 16 kHz sampling rate.From a perceptual point of view, the copy synthesis version of the target speech samples obtained using the rough version of the glottal pulse model were sometimes characterized by a low-pass average quality. The characteristics of the original speech and speaker are however always retained, and the uttered word as well as the speaker are perfectly recognizable. When the refined glottal pulse is used in the copy synthesis, the reconstructed speech can be made as similar as desired to the target, by using an adequate number of kernel terms. Note however, that this can lead to data overfitting and to poor generalization properties, as discussed in Section 3. In the experiment reported here, 30 kernel terms were used. When transformations are performed by acting on the analysis parameters as described, the resulting speech signal retains the characteristics of the copy synthesis, although a slight degradation of the sound quality is audible. This is more pronounced in pitch shifting transformations, where a slight loss of speech timbre naturalness is observed as the distance from original pitch increases. We believe that this can be due to two factors: first, the more the new pitch differs from the original one, the more there is the possibility that the transformation operated by the kernel machine on the stretched pulse differs from the one learned during the model inversion; second, the analysis parameters of the formants are not modified when rising or lowering the pitch of the glottal source, which is actually not too realistic since the original interaction relating source and vocal tract is not retained. Further investigation is foreseen with respect to these points. In time stretching transformations, fewer artifacts are noticed. These are probably due to signal discontinuities arising from the pitch-synchronous vocal tract filter parameters updates. In any case, the resulting time stretched or pitch shifted signal, is not affected by the well known phase-related degradation, typical of processing based on phase vocoder or sinusoidal modeling (Laroche and Dolson, 1997).Two different opinion score tests were performed to assess the voice quality of reproduced samples: the first one focusing on copy synthesis, and the second one focusing on time and pitch transformations. A total of 15 subjects, all of which were experts in a speech processing related field or having a good knowledge on the state of the art of speech synthesis, participated in the tests.In the first test, the subjects were asked to listen to 3 samples at a time: (1) the original sample, (2) the copy synthesis based on LPC vocal tract identification and on non-refined glottal source reconstruction (i.e., the method referred to as “LPC” in Table 1), and (3) the copy synthesis based on least squares vocal tract identification and on refined glottal source reconstruction (i.e., the method referred to as “Gl(ref)+LS” in Table 1). No indication was given to distinguish which was which. The subjects were allowed to listen to each word sample as many times as desired during the test, and for each sample, they were asked to evaluate the overall speech quality according to a Bad, Poor, Fair, Good, and Excellent scale. As a general guideline, it was suggested to first attempt at recognizing the original sample and to assign a score to it, and then to rate the other two accordingly. Each test consisted of 9 repetitions, for a total of 27 samples presented, randomly chosen among a set of 40 containing the original samples, the LPC based non-refined copy synthesis, and the model based refined copy synthesis.In the second test, focusing on the voice quality assessment of transformed samples (obtained through the refined identification procedure and subsequent time or pitch controlled resynthesis), the subjects were asked to listen to 3 samples at a time, each of which reproduced a TDPSOLA11The TDPSOLA algorithm was implemented as described in Zoelzer and Sondhi (2002, Chapter 7).(Moulines and Laroche, 1995) transformed sample, a transformed sample obtained through the LPC based synthesis with non-refined glottal source, and a transformed sample obtained through the LS based vocal tract identification and refined glottal source. Transformations were either time stretching (50% time scale dilation and 20% time compression) or pitch shifting (20% for both pitch rising and lowering). The subjects were allowed to listen to each word sample as many times as desired during the test and to compare it to the original sample, provided as a listening reference besides the transformed samples. For each sample, they were asked to evaluate the overall speech quality according to the bad-excellent scale as for the first test. Each test consisted of 9 repetitions, for a total of 27 samples presented, randomly chosen among a set of 40 as before.The results of the perceptual opinion score tests are shown in Figs. 9, showing results concerning copy synthesis, and 10, showing results concerning pitch and time scale transformations. Average scores and 95% confidence intervals (CI) are reported in left hand plots. However, since the score data are not always normally distributed, box plots providing information on score distributions are also shown in right hand plots. It can be observed that original samples (“Orig.”) were correctly recognized with good accuracy in the first test, and that the perceived quality of copy synthesis was high for the refined inversion procedure (“LS”), with a “Fair” value for the mean and a “Good” value for the median, and slightly inferior scores for the rough copy synthesis with non-refined glottal source (“LPC”), although with a “Fair” median value in this case.The second test, addressing pitch and time scale transformations, shows that the speech quality obtained with the refined parametrization (“LS”) was perceived as inferior to the TDPSOLA transformed samples (judged as “Good”), with a “Fair” value for mean and median. The transformations obtained with the non-refined parametrization (“LPC”) were judged only slightly inferior.The quality of transformed samples (Test 2, Fig. 10) is in general perceived as inferior with respect to the quality of copy synthesis (Test 1, Fig. 9). This can be due to several factors, as already mentioned: pitch shifting entails possibly less accurate period waveform refinement by the kernel machine and unmodeled interaction between source and vocal tract, and time stretching tends to emphasize many of possible analysis inaccuracies such as non-smooth parameter changes due to the pitch synchronous vocal tract filter update.As a final comment on voice transformations, we note that the quality obtained through the proposed model was judged inferior if compared to TDPSOLA, a well established speech processing algorithm based on direct waveform manipulation. Waveform manipulation approaches, however, have their limits in the lack of a model that describes the phenomena underlying the acoustic outcome, and their use is often restricted to few specific processing tasks (in fact, TDPSOLA is only effective in addressing time scale and pitch transformations). On the other hand, the proposed model-based encoding approach offers in principle a natural framework for the control of a wide range of speech cues, including time scale and pitch, voice quality, irregular phonation as in pathologic voices, and speaker-specific phonatory characteristics.We would also like to stress here the fact that our main objective was to demonstrate the feasibility of encoding a speech waveform through a particular type of physical model, which can be easily inverted and subsequently used to transform the original sample on a physically motivated basis. For the time being, a rather basic time and pitch processing scheme was implemented and used in our tests. We are however confident that further refinements in the model inversion and control strategies could lead to significant improvements in the parametric identification and processing quality.

@&#CONCLUSIONS@&#
We discussed the use of low-dimensional physically based speech models in the frameworks of speech coding and speech processing. The voice model used provides self-sustained oscillations and data fitting capability that can be used to adapt the model to recorded speech. The class of models proposed provides in principle a tool for both estimating glottal source signals, as well as for encoding the speech signal for transformation purposes. The application to time stretching and to frequency control (pitch shifting) of these schemes was also reported. The experimental results showed effective results as for time stretching, and that in principle “pitch extrapolation” is effectively obtained with the class of models proposed. Improvements in the tracking and smoothing of parameters identification and in the control of formants for pitch shifting, might further improve the final quality of the signal.Future work will investigate the model versatility with respect to other transformations, especially voice quality, and whether the inherent dynamical structure can improve the perceived naturalness of transformed speech, if compared to non-dynamic glottal models.