@&#MAIN-TITLE@&#
Analysis of the impact of digital watermarking on computer-aided diagnosis in medical imaging

@&#HIGHLIGHTS@&#
A deep and detailed analysis of watermarking implications on CADx was carried out.A procedure to evaluate the impact of watermarking on CADx was proposed.The diagnosis in breast ultrasound imaging is guaranteed by the HCDH algorithm.

@&#KEYPHRASES@&#
Breast ultrasound,Computer-aided diagnosis,Data security,Segmentation,Watermarking,

@&#ABSTRACT@&#
Medical images (MI) are relevant sources of information for detecting and diagnosing a large number of illnesses and abnormalities. Due to their importance, this study is focused on breast ultrasound (BUS), which is the main adjunct for mammography to detect common breast lesions among women worldwide. On the other hand, aiming to enhance data security, image fidelity, authenticity, and content verification in e-health environments, MI watermarking has been widely used, whose main goal is to embed patient meta-data into MI so that the resulting image keeps its original quality. In this sense, this paper deals with the comparison of two watermarking approaches, namely spread spectrum based on the discrete cosine transform (SS-DCT) and the high-capacity data-hiding (HCDH) algorithm, so that the watermarked BUS images are guaranteed to be adequate for a computer-aided diagnosis (CADx) system, whose two principal outcomes are lesion segmentation and classification. Experimental results show that HCDH algorithm is highly recommended for watermarking medical images, maintaining the image quality and without introducing distortion into the output of CADx.

@&#INTRODUCTION@&#
Clinical data are one of the main sources of information for the diagnosis and treatment of a large number of illnesses and abnormalities. This includes physiological variables such as electrocardiograms (ECG or EKG), electroencephalograms (EEG), electromyograms (EMG), and, also, different types of medical imaging such as computed tomography (CT), ultrasound (US), magnetic resonance imaging (MRI), and X-rays. Medical images (MI) are usually collected in hospitals or research centers due to the specialized nature of the equipment. There are standards, such as DICOM (Digital Imaging and Communications in Medicine), that have enabled the management, storage and printing of MI in standard formats. DICOM-based files facilitate sending MI to specialists or researchers in remote places by electronic means. However, during an information exchange, the potential risk of altering the MI contents increases within the processing tasks that they may be exposed to [1]. In addition, specialists usually capture sensitive, confidential diagnostic information about MI as flat text, which is normally electronically, compromising the confidentiality of the patient with respect to potential illnesses or injuries that the patient may suffer. In most countries, strict regulations apply to protect a patient׳s confidentiality, such as electronic patient records (EPR), identification, and participation in any trials or programs [2,3]. From the above, the constant need for security procedures to keep MI information unaltered is widely accepted.MI watermarking has been widely recognized as a technique for enhancing data security, image fidelity, authenticity, and content verification in e-health environments, where MI are stored, retrieved, and transmitted electronically [4]. In addition, it helps control the integrity of MI for protection purposes, as a key objective of MI watermarking is to embed data into the MI so that the watermarked MI contains useful information with a perfect linking with the patient. The embedded information could include the hospital, patient records, diagnostic information, etc., in this way concealing such information. In this context, a number of MI watermarking techniques have been proposed to find appropriate trade-offs between the payload (i.e., the hidden message or watermark) and its imperceptibility (i.e., the quality of the image). Moreover, image degradation due to aggressive or greedy watermarking impacts directly on the image fidelity and, consequently, on key medical activities like specialists׳ diagnoses and computer-aided diagnosis (CADx) [5]. Hence, finding the appropriate techniques that guarantee an adequate trade-off between payload and imperceptibility are necessary, so that clinical diagnosis can be performed appropriately on watermarked MI. To the best of our knowledge, a deep and detailed analysis of the implications of MI watermarking techniques over CADx has received little attention.This study deals with the critical nature of identifying an adequate watermarking approach such that the resulting watermarked MI guarantees the suitability of the CADx systems. The main contribution of the present paper is the identification of an appropriate embedding algorithm, payload parameters, and limits, that guarantee an acceptable trade-off between image quality and computerized segmentation. Due to their importance, our analysis is focused on breast ultrasound (BUS) images, which are crucial for detecting the most common cancer among women worldwide.The present paper is organized as follows. Section 2 presents related research. Section 3 describes background information on computer-aided diagnosis. Section 4 describes the implemented watermarking techniques for data hiding, which are applied to the BUS images. Section 5 presents the experimental results obtained through the former in terms of payload (i.e., the hidden message or watermark) and medical image quality. Section 6 provides some important discussions of our findings and some conclusions. Finally, Section 7 concludes this paper with a summary.The application of watermarking techniques in MI has attracted attention mainly for authentication and protection purposes, as discussed by Coatrieux et al. [6]. The relevance of watermarking in MI for security and privacy has been pivotal for qualitative enhancement in imaging technology in medical and health information systems, as suggested by Rao and Kumari [4]. In this sense, the zero-watermarking method has been preferred, since the watermark is not embedded physically in the image, but both the master and the secret shares are created out of the host image as well as the watermark image at the sender׳s end, so that the watermark is reconstructed by the combination of these two at the receiver end [7]. Dong et al. [8] proposed a zero-watermarking algorithm based on the discrete cosine transform (DCT), which combines visual feature vectors, encryption, and third party authentication to address issues of security, confidentiality, and integrity. Also, Seenivasagam and Velumani [9] proposed a general framework for patient authentication and controlled access to Electronic Health Records (EHR) in tele-radiology environments based on the zero-watermarking scheme.On the other hand, watermarking schemes applied to breast screenings are rather scarce. Li et al. [10] proposed a DCT-based scheme for protecting mammograms on Picture Archiving and Communication Systems (PACSs). The goal was to protect the textual information on mammograms as well as verifying their authenticity and integrity when the data extraction process does not require the availability of the originals. A similar approach is taken by Manaf et al. [11], aiming to identify the best location on the mammogram to embed the patient׳s information without affecting the quality of the image as well as to develop an authentication technique of watermarking mammogram using the least significant bits (LSB) technique. Likewise, Hajjaji et al. [12] developed a watermarking algorithm based on DCT for hiding information in MRI, radiographic, and echographic data.Watermarked images could potentially be used for CADx systems to detect and diagnose suspected regions such as breast tumors, for instance. A critical stage within a CADx system is the image segmentation, whereby a region of interest (ROI) is isolated from the adjacent structures for further analysis. In this sense, a watermarked image should preserve the relevant information about the tissue morphology and texture patterns, which are commonly used to detect accurately suspected structures like tumors or injuries. The term “accurately” means that the segmented region corresponds to a specialist׳s perception. Usually, the segmentation stage is implemented within a computer-aided detection (CADe) module, where a wide variety of techniques, such as edge-based methods, region-based approaches, active contour models, split-and-merge, and morphological watersheds, have been explored [13].Some segmentation-oriented watermarking schemes have been addressed by Lim and Feng [14], Rathi [15], and Gunjal and Mali [16]. These approaches use segmentation information of medical image contents to embed watermarks in medical images; however, they are mainly focused on secure distribution [14], protection and authentication [15], and security and copyright protection [16] rather than payload maximization (i.e., maximization of the length of the hidden message or watermark). A recent study of embedding capacity was presented by Al-Qershi and Khoo [17]; however, the impact of the amount of information hidden by distinct watermarking algorithms on the accuracy of detected abnormalities has not yet been studied. Therefore, we will here analyze the effect of watermarking on the outcomes of a CADe system developed for BUS images.Computer-aided diagnosis (CADx) systems have been developed to assist specialists in locating and diagnosing potential abnormalities by using the outcomes from a computerized analysis of the medical images. Commonly, CADx systems involve four main stages [18]: image preprocessing, lesion segmentation, feature extraction, and lesion classification. Many types of CADx systems have been proposed to diagnose different lesions in medical imaging, such as ultrasound (US), X-ray, computed tomography (CT), and magnetic resonance imaging (MRI). In addition, CADx has been used to analyze various human organs, such as the breast, lung, colon, brain, liver, and vascular system [19].Regarding breast ultrasound (BUS), CADx systems have been used to segment masses that are then depicted so as to quantify their malignancy. Hence, lesion segmentation is a critical stage within CADx systems, whereby the lesion should be separated accurately from the background and other structures [18].As discussed in Section 2, an important aspect of digital watermarking consists in hiding meta-data in the image, where the embedded information remains invisible to the user and the quality of the watermarked image is preserved [20]. In this sense, when a watermarked BUS image is analyzed by a CADx system, the classification performance should be similar to that of the classification without watermarking. For this reason, a watermarking approach should avoid critical image data distortion.Hence, in this study, the goal is to quantify the impact of watermarking on the performance of a CADx for BUS that was developed by our research group. It follows the basic aforementioned stages [21–23]:1.Image preprocessing: Contrast enhancement is performed by means of the contrast-limited adaptive histogram equalization (CLAHE) technique and speckle is reduced by using an anisotropic diffusion filter guided by texture descriptors. Next, using a constraint Gaussian function, the lesion region is enhanced to attenuate distant pixels (far from the lesion) whose intensity values are similar to those of the tumor region.Segmentation: An iterative threshold procedure creates binary masks for the marker-controlled watershed transformed to create potential lesion-like margins. The goal is to preserve the fine details of the tumor boundary. Then, the margin that maximizes the average radial derivative (ARD) function approximates the final lesion contour.Feature extraction: Five morphological descriptors are computed from binary blobs to describe the following features: elliptic-normalized skeleton, lesion orientation, number of substantial protuberances and depressions, depth-to-width ratio, and overlap ratio.Classification: A linear discriminant analysis (LDA) classifier is trained to distinguish benign from malignant breast lesions, based on the five morphological features extracted in the previous stage.Following the CADx pipeline, the input is a single BUS image and the outcomes are the segmented image and its class label.In this section, the proposed data hiding solution is described. First, the traditional solution for digital images is outlined, then, the additive interpolation-error expansion algorithm is reviewed, and finally the proposed data hiding solution is exposited.The spread spectrum (SS) watermarking technique is the most popular data hiding strategy nowadays. Introduced by Cox et al. [24], SS watermarking consists of spreading the secret data along the host signal׳s frequency spectrum as follows:(1)Y=X+bαWwhereYis the watermarked signal,Xis the host signal,Wis a pseudorandom signal (a.k.a. a watermark), α is a robustness factor, and b is the bit being embedded,b∈[−1,1](in SS, the bit value “0” is modulated as −1). SS watermarking is highly robust against intentional and unintentional attacks, however, it is inferior in terms of its payload, as several host samples are required to embed one bit. The optimal way of recovering the secret data is to compute the linear correlation between the watermark and the watermarked signal:(2)corr(Y,W)=1NY·Wwhere N is the number of samples used for the embedding/extraction process. The embedded data is extracted as follows:(3)b={1,corr(Y,W)>00,otherwiseCox et al. [24] developed the case of digital images using the Discrete Cosine Transform domain as the host signal; in the present paper, that strategy is referred to as SS-DCT.The proposed solution for watermarking MI is based on the additive interpolation-error expansion (AIEE) strategy [25]. AIEE has been mainly used for reversible watermarking in multimedia [25–27].The AIEE approach is performed as follows. First, interpolation samples,x′, of the host signal, x, are calculated using an interpolator; then, the interpolation error is computed as(4)e=x−x′Two parameters, LM and RM, which are the highest points of the interpolation error histogram, are obtained by(5)LM=argmaxe∈Ehist(e)RM=argmaxe∈E−{LM}hist(e)where hist(·) is the histogram function and E denotes the interpolation error set. Then, the interpolation error set is split into two parts:1.Left interpolation errors (LE): e satisfiese≤LM.Right interpolation errors (RE): e satisfiese≥RM.Two more parameters, LN and RN, are defined by(6)LN=argmine∈LEhist(e)RN=argmine∈REhist(e)The additive interpolation error expansion process is carried out as follows:(7)e′={e+sign(e)×b,e=LMorRMe+sign(e)×1,e∈(LN,LM)⋃(RM,RN)e,otherwisewheree′is the expanded interpolation error, b is the bit being embedded, andsign(·)is the sign function, defined by(8)sign(e)={1,e∈RE−1,e∈LEFinally, the watermarked samplex″results from the addition of the interpolated sample to the expanded interpolation error:(9)x′′=x′+e′In the extraction stage, the interpolation values,x′, are computed by using the same interpolation algorithm as in the insertion stage; the interpolation errors,e′, are also obtained:(10)e′=x′′−x′Then, the embedded data is extracted as follows:(11)b={0,e′=LMorRM1,e′=LM−1orRM+1The inverse function of additive interpolation error expansion is used to recover the original interpolation errors:(12)e={e′−sign(e′)×b,e′∈[LM−1,LM]⋃[RM,RM+1]e′−sign(e′)×1,e′∈[LN,LM−1)⋃(RM+1,RN]e′,otherwiseRestoration of original signal samples is carried out by(13)x=x′+eAlthough the additive interpolation error expansion guarantees reversibility, it also produces under/overflow. Therefore, a boundary map or similar strategy is needed.The proposed solution is called the High-Capacity Data-Hiding (HCDH) algorithm. HCDH is an AIEE-based steganography system for watermarking digital images [28]. Herein, we propose integrating the HCDH system into the CADe for BUS images, as described earlier in Section 3. Although there are other schemes in the literature with better performance in terms of payload and distortion metrics, such as [29–33], in this study, the HCDH algorithm has been selected due to its low complexity. In the Mobile Health (mHealth) field, mobile devices working in real-time are greatly desirable as they enable communications between the patients and health providers within critical time constraints [34]. In this context, HCDH has an additional advantage as a hardware architecture, as has been recently reported in [35]: this HW architecture showed multi-channel real-time performance when implemented in a midrange Field Programmable Gate Array (FPGA). Although in [36] there was proposed an HW architecture which implements the reversible watermarking scheme reported in [29], that HW architecture is unable to carry a useful payload as both the watermarked image and the watermark are needed as inputs. The application field of [36] is limited to tamper detection, in contrast to that of [35] which guarantees useful payload to the user. Therefore, HCDH is a natural solution for mHealth applications.The embedding process consists of two parts: interpolation and embedding. In the first stage, the interpolated samples and interpolation errors are computed. The possible samples used for embedding are determined by the parameter jump. For embedding, only multiples of jump are considered, therefore, versatility between the payload and the distortion is achieved. In the embedding stage, where additive expansion is applied, a preprocessing is carried out in order to avoid under/overflow: the image׳s dynamic range is compressed from [0, 255] to [1, 254]. The full embedding process is as follows:1.Compress the image׳s dynamic range to [1, 254] by using(14)x=round(253×xfull255)+1where xfullis the original image with dynamic range [0, 255] andround(.)is the round function.Reshape the 2D image to an 1D signal.Compute the interpolated samplesx′and the interpolation errors e using (4).Obtain LM, RM, LN and RN by using (5) and (6).Compute the interpolation error expansione′using (7).Compute the watermarked samplesx″using (9).Reshape the 1D signal to 2D representation.The parameters LM, LN, RM and RN can be considered as the keys to the system. Fig. 1illustrates the general scheme of the embedding process.The extraction stage recovers the embedded data as follows:1.Reshape the 2D image to an 1D signal.Compute the interpolated valuesx′using the same interpolation technique used in the insertion process and compute the interpolation error expansione′using (10).Extract the embedded data b using (11) and LM, LN, RM and RN.It is important to mention that the reversible capacity of the additive interpolation-error expansion technique is lost due to dynamic range compression in (14). However, for the purposes of this paper (data hiding, rather than reversible watermarking), this loss is tolerable. Fig. 2shows the general scheme of the extraction process.This section treats the validation of the proposed approach, where the procedure designed to evaluate the effect of the watermarking on the CADx system depicted in Section 3 is described. The goal is to quantify statistically the performance of CADx when comparing the original segmented and classified BUS images with their watermarked versions.The dataset consists of 500 BUS images, one for each patient, acquired during routine breast diagnostic procedures at the National Cancer Institute (INCa) of Rio de Janeiro, Brazil. The sonograms depict 250 carcinomas and an equal number of benign lesions that were histopathologically proven. Every image was obtained with a SonolineSienna®(Siemens, Erlangen, Germany) machine, using a 7.5-MHz linear array B-mode 40-mm ultrasound transducer. As the beam resolution is about 0.5mm and the pixel size is 0.33mm/pixel, the image resolution is nearly 1.5pixels. Also, the images were captured directly from the 8-bit video signal (i.e., 256 gray levels) and saved in BMP format. Moreover, considering the major axis of the injuries, their sizes are approximately in the range of 10–60mm, with a mean value of 27mm. The INCa Research Ethics Committee approved this study (no. 38/2001). Additionally, aiming to preserve the patients׳ anonymity, only the ultrasonographic data is cropped from the original image: the outer frame, containing the patient׳s information (e.g., name, age, and ID number), is removed.The general experimental setup with a block diagram, the metrics used to measure the performance of the watermarking and segmentation, and the statistical tests used for validating the proposed method, are detailed in the following:Fig. 3illustrates the experimental setup, where every original image, Io, from the BUS dataset is processed in three ways. In the first procedure, Iois watermarked by two watermarking schemes: SS-DCT and HCDH, for which the resulting watermarked images, Iw, are compared with Ioto quantify three indices: Peak Signal-to-Noise Ratio (PSNR), the Watson metric, and the payload (bpp, bits-per-pixel). The second procedure involves the image segmentation, where both Ioand Iware segmented by our method based on the watershed transformation [21], and the corresponding resulting binary blobs, Soand Sw, are compared with each other to determine their mutual similarity in terms of the Matthews correlation coefficient (MCC) and the sensibility (SEN). In the third procedure, round robin evaluations of the LDA classifier are performed, where five morphological features are extracted from the segmented images [23]. In a round robin procedure, one of the cases is removed from the original data and the same case is also removed from the watermarked data. Next, the removed cases are classified according to an LDA trained with the remainder of the original cases. This process is repeated for each image in the BUS dataset [37]. The area under the ROC curve index (AUC) is used to assess the performance of the classifier given any configuration of watermarking schemes, Cw, as well as the original data, Co, in relation to the known histopathology (benign and malignant classes), Ct[38].In this analysis, only the computerized analytical evaluations were performed, that is, human evaluations were not considered, to avoid potential interpretation errors.It is worth noting that the parameters of the SS-DCT and HCDH algorithms drive the amount of information embedding in the BUS image. For the SS-DCT algorithm, the amount of embedded information is defined by the pairwise combination of parameters α and M. For testing purposes all possible values have been given to both parameters, namelyM=8,…,n2,…,256andα=10,15,20,…,100. The minimum amount of information was obtained by the combination α=any value, M=256, whereas the maximum amount was obtained by the combination α=any value, M=8. On the other hand, for the HCDH algorithm, the amount of information embedded in the image is defined by the parameter jump. For testing purposes the jump parameter took all possible integral values in the range [2, 10]. The minimum amount of information was embedded when jump=10 and the maximum when jump=2. Therefore, for every image in the BUS dataset, 114 and 9 watermarked images were generated by the SS-DCT and HCDH algorithms, respectively.Two robust statistics for estimating the location (the sample median, MED) and dispersion (the Qnestimator) of the assessment results were used. We chose these estimators since they are capable of coping with outliers and non-normal distributions. The sample median is the middle value in an ordered sequence of data values, that is, the 50th percentile. The Qnestimator computes all possible distances between pairs of observations, sorts them, and picks out the smallest distance, corresponding to the first quartile of all interpoint distances [39].In addition, concerning both the distortion (PSNR, Watson, and bpp) and the segmentation (MCC and SEN) results, a statistical significance analysis was conducted by means of the Kruskal–Wallis test(α=0.05)to evaluate whether the medians of the compared results are different [40]. Also, the correction for multiple testing on the basis of the same data was made by the Bonferroni correction [41].In this evaluation, no attacks, either intentional and unintentional, have been considered, as the studied systems are evaluated for medical applications where imperceptibility is one of the main goals, while robustness is less important [42].To evaluate the outcomes of both the segmentation and the classification procedures, a confusion matrix has been obtained for each one. As illustrated in Fig. 4, every matrix entry counts the true positives (TP), the true negatives (TN), the false positives (FP), and the false negatives (FN) obtained when contrasting the algorithm׳s output (predicted class) with its corresponding gold standard (actual class) [43].In the BUS images, the amount of lesion and background pixels is generally uneven. Hence, the MCC is adequate for measuring the similarity between Soand Sw, because it makes a balanced measure when the areas of the lesion and the background are of different sizes. The MCC is calculated as [44](15)MCC=TP×TN−FP×FN(TP+FP)(TP+FN)(TN+FP)(TN+FN),where a value of “+1” represents perfect matching, “0” denotes random segmentation, and “−1” indicates total disagreement.In addition, the sensitivity measures the proportion of lesion pixels correctly identified; it is computed as [44](16)SEN=TPTP+FP,where a “1” value indicates perfect lesion matching between Soand Sw.The AUC index is a common measure of expected classifier performance. It is usually provided within the range [0, 1], where unity stands for ideal classification results (i.e., perfect discrimination) [38]. The AUC value represents a relation between the sensitivity and the specificity via [43]:(17)AUC=12(TPTP+FN+TNTN+FP).The Peak Signal-to-Noise Ratio (PSNR) measures the similarity of two images, typically a reference image and a processed version of it, which defines the relation between the maximum energy of a signal and the noise affecting it, expressing this ratio in decibels [45,46]. Given an 8-bit grayscale image f and a copy of the processed image g, both of sizeM×N, the PSNR between f and g is computed by(18)PSNR(f,g)=10·log10(2552MSE(f,g))(19)MSE(f,g)=1(M·N)∑i=1M∑j=1N(fij−gij)2As to the Mean Square Error (MSE), the difference between the pixelsfijandgijis considered as an error that generates image quality loss. The lower is the MSE, the higher the PSNR, therefore, the higher the PSNR (f, g) values, the higher the image quality. For digital images, sometimes a PSNR>35dBis considered as good quality.Another interesting quality evaluation tool is the Watson metric, which quantifies the distortion of an image based on Just Noticeable Differences [47]. If the Watson metric is equal to “1” no difference in the image can be determined by an expert. The Watson metric is based on measuring the errors for each DCT coefficient in each block by its corresponding sensitivity threshold. That threshold is a function of the contrast sensitivity, luminance masking, and contrast masking.In the Watson model, for each ij DCT coefficients the relation between the luminance and frequency is considered, as follows:(20)tijk=tij(c00kc¯00)atwhere tijis the threshold for the smallest frequency coefficient that yields a visible signal, c00kis the DC coefficient of block k,c¯00is the DC coefficient corresponding to the mean luminance of the display (1024 for an 8bit image), and atdetermines the degree of masking (set to 0.65) [48].When the visibility of a pattern is reduced by the presence of another pattern in the image, this phenomenon is known as texture masking. Watson extends the results of luminance and frequency masking to include texture masking as follows:(21)mijk=max[tijk,|cijk|wijtijk1−wij]where mijkis the masked threshold and wijdetermines the degree of texture masking. Typically,w00=0andwij=0.7for all other coefficients.The perceptual error in each frequency of each block is given by(22)dijk=eijkmijkwhere eijkis the quantization error.To associate the errors in the model, the Minkowski metric is used as follows:(23)pij=(∑k|dijk|βs)1/βswhere different values of the exponent βsimplement different types or degrees of pooling. In practice,βs=100is commonly used.A typical threshold for the Watson metric is 0.4, since measures below this point guarantee visual imperceptibility [49].Regarding the experimental results of the SS-DCT algorithm, both the perceptual distortion and the effect of the embedded watermark on the CADx outcomes (segmentation and classification) are presented.Fig. 5(a) and (b) summarizes the median (location) and Qnestimator (scale) values for the PSNR measures for the BUS dataset. In Fig. 5(a), the set of the statistically significant groups within the permissible distortion region is highlighted by triangles. The highest PSNR is achieved with combination (10,8).Fig. 5(c) and (d) shows the median and Qnvalues for the Watson metric measures for the medical image dataset: the set of the statistically significant groups is highlighted with triangles. For the Watson metric, the set of the statistically significant groups is the result of adding the combination (8,25) to that for the PSNR set.The payload SS-DCT algorithm is uncorrelated with α as it depends only on M, for the dataset in this study, the payload is 0.015bpp for M=8, 0.004bpp for M=16, 0.001bpp for M=32, and so on. From the results presented therein, we conclude that the value of α has no repercussions on the payload, but does affect the perceptual distortion.Fig. 6illustrates the segmentation performance results attained for each combination of parameters of the SS-DCT algorithm. It is noticeable that the best performance is reached by the combination M=8 andα=10, whereMCC=0.98andSEN=0.99, which indicates an almost perfect agreement with the segmented original image. Also, none of the M values related toα=10are statistically different. However, as α increases, the segmentation performance decreases significantly and the dispersion increases.Concerning the classification results, Fig. 7illustrates the ROC space and the related AUC values for each combination of parameters of the SS-DCT algorithm. A behavior is observed similar to that for the segmentation results, where the classification performance decays as α increases. Also, it is noticeable that the largest AUC values (in the range 0.90–0.92) were obtained with M=8, which are quite closer to the performance of the original dataset withAUC=0.91.Fig. 8shows an example of a BUS image with a malignant lesion watermarked by the SS-DCT algorithm, where distinct values of α and M parameters are employed. For every image, the lesion contour was delineated by the segmentation algorithm. Notice that the image suffers an important visual distortion as α increases, which impacts negatively on the actual lesion shape and predicted class.Concerning the experimental results of the HCDH algorithm, both the perceptual distortion and the effect of the embedded watermark on the CADx outcomes (segmentation and classification) are also presented.Fig. 9(a) shows, highlighted with triangles, the set of the statistically significant groups of PSNR measures from the HCDH algorithm. Fig. 9(b) shows the best group of Watson metric measures from the HCDH algorithm. The payload for each value of jump within the best group is also presented in Fig. 9(c). The lower this value and the PSNR, the higher the payload and the Watson value.Fig. 10illustrates the segmentation results of the HCDH algorithm as a function of the jump parameter. Notice that independently of the jump value, the segmentation is quite similar to the segmentation obtained from the original data, because both the MCC and SEN median values are greater than 0.9 for all cases. Also, the dispersion, measured by the Qnestimator, is relatively low and constant. These results suggest that the HCDH algorithm is capable of embedding meta-data in BUS images without distorting the shape of the tumors.On the other hand, Fig. 11presents the classification results of the HCDH algorithm as a function of the jump parameter. It is notable that the AUC median values, for the entire range of jump, are greater than 0.90, which is quite close to the performance of the original dataset withAUC=0.91. As with the segmentation results, these findings reveal that the HCDH algorithm is capable of embedding meta-data in BUS images without impacting negatively the tumor class.Fig. 12shows an example of a BUS image with a malignant lesion watermarked by the HCDH algorithm, where various values of the jump parameter have been employed. For every image, the lesion contour was delineated by the segmentation algorithm. Notice that independently of jump, the image does not present any visual distortion and, consequently, the actual lesion shape and predicted class are preserved.

@&#CONCLUSIONS@&#
