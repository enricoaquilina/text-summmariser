@&#MAIN-TITLE@&#
Segmentation of retinal vessels by means of directional response vector similarity and region growing

@&#HIGHLIGHTS@&#
A novel retinal vessel segmentation method is proposed.A symmetry constrained multi-scale matched filtering technique is presented.A unique directional response statistics based vessel score formula is given.Proposal of a response vector similarity based region growing segmentation.Performance of the method is comparable to that of a human observer.

@&#KEYPHRASES@&#
Retinal image analysis,Vessel segmentation,Directional filters,Multiscale matched filtering,Directional response similarity,

@&#ABSTRACT@&#
This paper presents a novel retinal vessel segmentation method. Opposed to the general approach in similar directional methods, where only the maximal or summed responses of a pixel are used, here, the directional responses of a pixel are considered as a vector. The segmentation method is a unique region growing procedure which combines a hysteresis thresholding scheme with the response vector similarity of adjacent pixels. A vessel score map is constructed as the combination of the statistical measures of the response vectors and its local maxima to provide the seeds for the region growing procedure. A nearest neighbor classifier based on a rotation invariant response vector similarity measure is used to filter the seed points. Many techniques in the literature that capture the Gaussian-like cross-section of vessels suffer from the drawback of giving false high responses to the steep intensity transitions at the boundary of the optic disc and bright lesions. To overcome this issue, we also propose a symmetry constrained multiscale matched filtering technique. The proposed vessel segmentation method has been tested on three publicly available image sets, where its performance proved to be competitive with the state-of-the-art and comparable to the accuracy of a human observer, as well.

@&#INTRODUCTION@&#
The automatic segmentation of vessels in color retinal images is an important and nonetheless challenging task when considering a computer aided diagnostic (CAD) system for screening diabetic retinopathy (DR). This disease is the complication of diabetes and the most common cause of blindness in the developed world. Automatic vessel segmentation can serve several purposes in such a CAD system [1]. In later stages of DR, or in the case of high blood pressure, the vessels may get distorted, and to detect these deformations continuous monitoring and a precise vessel mask is needed. However, while this is a serious issue, diagnosis of DR would be desirable in earlier stages when the progression can be stopped and vision loss is avoidable. The earliest symptom of DR is the presence of microaneurysms (MAs), small red circular bleedings on the surface of the retina. Many automatic MA detection methods rely on a vessel mask to exclude crossings of vessels that are locally similar to MAs. Exudates are also early symptoms and appear as bright patches; however, in the case of images of young patients similar bright regions may appear close to the veins. In order to eliminate these false detections, a vessel mask is required [2]. Besides being an aid to MA, hemorrhage [3] and exudate [4] detectors, a precise vessel mask can also be used to locate the macula and the optic disc [5,6], and form the basis of registering retinal images [7]. Vessel segmentation is a complex problem even for healthy images, and it gets more complicated as the images start to show pathological signs, such as heamorrhages and bright lesions.The literature on automatic retinal vessel extraction is rather extensive. Authors have categorized existing methods according to several aspects, such as region based, edge based, tracing/tracking based, morphological, matched filter based, multi-scale, supervised, unsupervised, model-based ones [8–13]. However, it might not be the most practical to describe a method based solely on one property of its operation, since most of them combine several techniques, e.g., a supervised learning based method may apply multiple lower level pixel- or region-wise feature extractors while these can also be used in a tracking or region growing scheme.Vessels in retina photographs can be described as Gaussian like structures perpendicular to their local orientation in the intensity plane; the usage of matched filters and morphological operators in a rotational/directional manner for their segmentation are some of the very fundamental techniques in the literature [14–16]. Methods that apply this approach at some point of their operation usually proceed by rotating a filter or structuring element around its center with a specific angle to cover a circle, and match every pixel of the input ROI with all the possible masks, considering the maximal response as the vessel strength at that position. In the case of matched filters, the filters can be one or two dimensional, and the matching is usually performed by convolution. There are several types of filters, such as zero mean Gaussians [14,15], Gaussian mask where one side is negative and the other is positive [17], Gabor filter [8,18], simple Gaussian [19], first-order derivative of Gaussian [20,21], filters obtained from perpendicular profiles of sample vessels [22]. In the case of morphological approaches sum of top-hats of rotated linear structuring elements is one of the fundamental techniques [16]. There are similar directional methods, such as the tramline filter proposed by Lowell et al. [23] and Al Diri et al. [24], the approach of Ricci and Perfetti [25], where the average intensity along rotated linear segments are considered as line strength measures, or the method of You et al. [26], which employs rotated radial projections similar to Radon transform. The method proposed by Nguyen et al. [27] is also based on the line measure in [25], with an additional normalization step and the usage of the raw green channel intensity information as a feature. In [28], Wang et al. employed convolution with a multiwavelet kernel filter for all possible directions at each pixel and considered the maximal responses. Similarly, Qian et al. [29] used the maximal response of rotated Gabor wavelet transforms.A possible way of handling the varying width of vessels is multi-scale analysis. In some matched filter methods this is accomplished by considering different scale parameter for the filter [8,19,21]. Lupascu et al. [11] and Fraz et al. [8] also consider the maximal value of directional Gabor filters for multiple scales over all possible directions as a feature for every pixel. Franklin et al. [30] utilized Gabor and moment invariants-based features fed into a multilayer perceptron neural network to identify vessels. The methods of Martinez-Perez et al. [31] and Palomera-Perez et al. [32] apply smoothing with Gaussians of different scales and extract the gradient magnitude and principal curvature of the Hessian tensor. A diameter–dependent equalization factor is introduced to normalize both features along the scales, and local maxima are kept as final features in the classification process. Eigenvalue analysis of the Hessian matrix for vessel curvature evaluation is also considered by Yin et al. [33] and a similar method has been proposed by Yu et al. in [34]. The ridge measure proposed by Staal et al. [35] is based on the sign of the largest absolute eigenvalue of the Hessian, and in [11] it is calculated at multiple scales, considering the frequency of the negatives as a feature. The filter construction from manually selected blood vessel samples as proposed by Jan et al. [22] handles the different vessel widths by constructing multiple filters, each for a different vessel width. The method proposed by Vlachos and Dermatas [36] applies a line-tracking method by calculating a cross-sectional profile parameter for the candidate pixels based on the intensities of two opposite pixels with a given distance from the candidate and the intensity of the candidate pixel itself. The multi-scale nature of the method comes from considering multiple distance values, i.e., multiple widths for the cross-sectional profile parameter. The combination of different scales is calculated as the weighted average of the cross-sectional profile parameters at different scales by assigning higher weight to larger width arguments. The method proposed by Odstrcilik et al. [37] employs a matched filtering approach with predefined filters for the different vessel widths. The paper also presents a new high-resolution image set. The method of Annunziata et al. [38] utilizes a multiscale Hessian approach for vessel enhancement with also proposing a novel exudate inpainting technique to improve the detection performance of pathological images. Miri and Mahloojifar [39] employs discrete curvelet transform (DCT) as part of image enhancement, followed by a morphological segmentation step. DCT makes it possible to obtain multi-scale and directional representation of the underlying structures, while differing from other directional wavelet transforms in that the directional resolution depends on the scale.The most challenging issues concerning retinal vessel segmentation are the presence of pathologies in the image, such as heamorrhages and bright lesions. Moreover, nonvascular structures in healthy images such as the boundaries of the optic disc cause strong responses in many existing methods. Those approaches that address these issues may consider additional steps to exclude false detection, e.g. in [22] external optic disc detector is used to erase structures in the region, or in [40] Lam and Hong Yan considers a pruning operator based on centerlines applied to such spurious vessel-like objects. Classification as a post-segmentation step is also considered in some of the previously described methods. However, classification used in a pixelwise manner to construct vessel probability or likelihood maps for segmentation can only be successful in distinguishing false positives, if the problem itself is considered in the design of the lower level processing; e.g., in [25] the authors claim that the gray level in combination with a modification on the line strength measure can eliminate the effects of the unmodified line strength measure at the edge of the optic disc. Lam et al. [12] proposed the Smooth Imaging and Structurally Differentiable planes to deal with the so called ringing effect caused by bright lesions. To achieve similar effect, zero-mean Gaussian matched filter and its first order derivative are used by Zhang et al. [20]. Lei Zhang et al. [19] considered a double sided thresholding on the Gaussian matched filter to eliminate non-vessel edges.The method proposed in this paper is also a directional multi-scale approach, in some aspects similar to the discussed literature techniques. The main difference and novelty lies in the manner of how the directional responses are utilized. These can be summarized briefly as follows. First, we propose a symmetry constrained multiscale matched filter technique which overcomes the problem of bright intensity transitions at the boundaries of the optic disc and bright lesions. Opposed to literature methods, we consider the directional responses of a pixel as a vector and utilize this information in multiple ways. We propose a response vector correlation based similarity measure and use it in a nearest neighbor classifier setup to filter the seeds for the subsequent region growing segmentation. The proposed segmentation technique then also considers the response vector similarity of adjacent pixels. A vessel score measure proposed by the authors earlier [41] is also reused in the proposed method with the extension that local minima of the score map are used as region growing seed points. Besides the proposed matched filtering response calculation we also utilize a well-known morphological approach and give an algorithm to merge the segmentations in order to strengthen the individual advantages.The rest of the paper is organized as follows. In Section 2, the steps of the proposed method are described in details. In Section 3, methodology of the performance evaluation and experimental results on three publicly available datasets are presented. Main points are summarized and conclusions are drawn in Section 4, with also discussing on future applications.In this section, the detailed description of the proposed method is presented. The input of the algorithm is the green channel of a color retinal image, preferably along with its binary ROI mask. Retinal images have the highest contrast in the green channel, and accordingly it is the common practice to operate on this color channel. While the ROI is not necessary, it can significantly lower the computational time and be used to exclude some spurious candidates at boundaries. There are some spatial parameters of the method which correspond to a certain ROI diameter, e.g., the maximal vessel diameter. These either need to be adjusted if images of different ROI diameter are processed, or the images need to be rescaled accordingly. This subject will be discussed in details later on. The proposed method does not require a specific preprocessing step, in our implementation we used simple Gaussian smoothing with a standard deviation of 1.0 on the extracted green channel. One might consider other image enhancement techniques, this solely depends on the quality of the input images. The schematic workflow of the proposed method is shown inFig. 1.In the first phase of its operation, the proposed method applies a pixel-wise directional scheme that is similar to the operation of some of the previously discussed methods in the literature. For every pixel inside the ROI, the intensity values along discrete line segments of different orientations centered at the pixel under examination are considered. The orientations of these segments uniformly cover 180°, i.e., the Δφ rotation step between consequent segments is a constant, which was set to 6° in our implementation. The vector consisting of the intensity values along such a line segment is referred to as a cross-sectional intensity profile. Its length, i.e., the number of its values is 2r+1. Let P denote such a profile and P[i] its ith value, where the range of i is from −r to +r, thus the central value, i.e., the intensity of the pixel whose surroundings is being examined is P[0]. The value of r was set to 10 in our implementation, however it will be later shown that this is not a critical parameter.The two operations described in the following are applied on all cross-sections of a pixel, both resulting in a response value. This way, two directional response vectors (DRVs) are assigned to every pixel. The difference between the proposed approach and those described earlier lies in the way of utilizing these directional responses. Here, the entire response vectors are used, instead of considering only the maximal or summed responses over the directions.Fig. 2 gives a depiction of the workflow of the directional processing.The second order derivative of the Gaussian (SDG) filter is widely used in signal and image processing tasks. Its negative normalized variant is often referred to as the Mexican-hat due to its shape. The two dimensional counterpart is known as the Laplacian of Gaussian (LoG) filter and is a fundamental tool in corner, blob and edge detection tasks. The filter function of the SDG with σ scale parameter is given as:(1)Gσ``(x)=(x2−σ2)/σ4∙exp(−x2/2σ2).Two favorable properties of the SDG filter are that it is zero-mean and the filter flattens out to zero. Hence, the response is less dependent on the length of the cross-section than it would be in the case of e.g., zero-mean Gaussian masks [14,15]. The only constraint is that the cross-section length should be sufficiently large to allow the SDG filter with the largest scale to flatten out. This property can be observed inFig. 3 which shows the plots of five SDG filters that correspond to different scale parameters.The general way to calculate the matched filter response is the discrete cross-correlation of the signal and the mask. If both data are real and the mask is central symmetric, this is the same as the discrete convolution. Thus, both expressions occur in the literature. In the case of the proposed technique, the size of the cross-section profile and the mask are equal. Since only the response at the central position is relevant, the operation simplifies to the sum-product of the two vectors. That is, the matched filter response for profile P with a σ parameter SDG is given as:(2)MFRP,σ=∑i=−rrP[i]∙Gσ′′(i).The most important drawback of this correlation based matching of directional SDGs in the case of retinal images is the high response for asymmetric bright intensity transitions, such as those occurring at the boundary of the optic disc and bright lesions. The solution proposed here is to split the sum-product to a left and right part, excluding the central element, and subtracting the absolute difference of these two from the entire response. Thus, a symmetry constraint is incorporated. In the case of an SDG filter, the sum-products may be negative, yielding erroneous effects in later steps. In such case, the response is considered to be zero. The formal description can be given as:(3)MFRP,σ=MFRP,σL+P[0]∙Gσ′′(0)+MFRP,σR,where(4)MFRP,σL=∑i=−r−1P[i]∙Gσ′′(i)and(5)MFRP,σR=∑i=1rP[i]∙Gσ′′(i)In order to help the better understanding of Eqs. (3)–(5)Fig. 4 shows a vessel cross-section profile along with an SDG filter. The intervals for the determination of the left, right, and total sum-products are also indicated.This way, the symmetric matched filter response (SMFR) is expressed as:(6)SMFRP,σ=max(MFRP,σ−|MFRP,σR−MFRP,σL|,0).To handle the varying width of vessels, SDG masks corresponding to different σ scale parameters are matched against the profile, and the maximal response is selected. Formally, the final multiscale symmetric matched filter (MSMF) response for cross-section profile P is given as:(7)MSMFRP=maxσMSFRP,σ.In our implementation, the σ scale values range from 1.0 to 3.0 with a step of 0.1. To demonstrate the effect of simple directional SDG filters and the proposed symmetry constrained technique, parts of retinal images containing optic disks and bright lesions are shown inFig. 5, along with the results of the directional SDG and the proposed filtering technique. For this experiment the maximal directional responses were selected at each point. In Section 2.2.1 a more suitable formula is given, however, the superiority of the proposed MSMF for vessel enhancement is clearly visible even this way.Besides the described multiscale symmetry constrained matched filtering, grayscale morphology closing with a flat structuring element is also applied on the current profile. The length of the structuring element is chosen as the maximal vessel diameter. This is a medically established value and is in direct proportion to the ROI diameter. The response of the profile is the difference between the central value of the closed profile and the original one, also known as the bottom-hat or black tophat. The same grayscale morphological approach is used in [16], only that since vessels are lighter than the background in that case, grayscale opening with rotated linear structuring elements and top-hat transformation are considered. The advantage of this operation is that it gives almost no response for bright lesion edges and the optic disc boundary. Unfortunately, it does give high response to more irregular cross-sections, such as those of heamorrhages.Due to the constant structuring function in this case, the grayscale dilation and erosion operations may be simplified to the selection of maximum and minimum profile values in a translated window, whose size is the maximal vessel width. That is, for a profile P, using the previous index ranges and notations, dilation and erosion are defined as:(8)δω(P)[x]=maxmax(−r,x−ω)≤y≤min(r,x+ω)P[y],and(9)εω(P)[x]=minmax(−r,x−ω)≤y≤min(r,x+ω)P[y],respectively.The value of ω is set as the integer half of the maximal vessel width. The bottom-hat (BH) is then defined as:(10)BHω(P)=εω(δω(P))−P.Finally, the response of the profile is the central value of the BH profile, i.e.:(11)BHRP=BHω(P)[0].Resulting from the previous step, two directional response vector maps (DRVMs), the multi-scale symmetric matched filter (MSMF-DRVM) and bottom-hat (BH-DRVM) are obtained. The DRVM may be considered as a function that assigns a directional response vector (DRV) to a pixel inside the ROI. Note that, the length of a directional response vector X, denoted by lX, equals to 180°/Δφ, where Δφ stands for the angular resolution. In our experiments lX=180°/6°=30. The segmentation procedure described in this section is considered on both vector maps separately, and the resulting components are combined to form the final segmentation, which will be described in details in Section 2.3.InFig. 6, six examples of DRVs of vessel segments and vessel crossings are shown. The horizontal and vertical axes of the diagrams indicate the orientation and the response value, respectively. It can be seen how the drops in the values correspond to the orientation of the underlying structure, and that thicker vessels cause larger valleys in the DRVs.In order to obtain a single value that describes the likelihood of a pixel being part of a vessel, a score for every pixel using the statistical measures of its response vector is calculated. While most of the previously discussed similar directional methods only consider the maximal or summed response over the directions, here, a more suitable formula that considers the mean, standard deviation and maximal value of the response vector is considered [41]. The idea behind this is that vessel points have low or zero response at directions matching the orientation of the corresponding vessel, thus the variation of responses over the directions is higher. Therefore, the vessel score of a pixel is calculated by multiplying the response vector mean with its standard deviation, and then divide the product by the maximal response value to achieve a certain level of normalization, i.e.:(12)score(DRV)=μDRV∙σDRV/maxDRV,whereμDRV,σDRV, andmaxDRVdenote the mean, standard deviation, and maximum of a DRV, respectively. InFig. 7, the resulting MSMF and BH score maps are given for a sample retinal image from the DRIVE dataset.In order to correct the different ranges of the resulting score maps, statistical normalization is applied, i.e., each score value sc is replaced with(sc−μscore)/σscore, whereμscoreandσscoreare the mean and standard deviations of the unmodified score map. This makes it possible to use the same score thresholdthscorein the segmentation of the MSMF and BH maps. This value is the main threshold parameter of the proposed method and is used to filter the region growing seeds, as it will be described in the next section.The segmentation procedure described in Section 2.2.3 is a special region growing approach that uses both the DRVM and the corresponding vessel score map. The seeds of the method are those local maxima of the score map whose values are greater thanthscore. One advantage of this approach over, e.g, the simple thresholding of the score map to extract seed regions, is that this way the vessel seeds are located at the center of the vessels. This property gains importance in the next section where the seeds are classified based on their DRVs.There are several methods to extract local maxima. The approach used here is a simple yet effective search to test whether a point may be considered a possible maximum by recursively testing neighboring points for the condition and updating a flag map to avoid infinite loops. More details on this subject are given in [42].The purpose of the classification step is to exclude seed points that come from e.g. MAs, hemorrhages, or regions between bright lesions such as exudates. While it is less difficult to distinguish MAs, images showing a high number of bright lesions close to each other are a lot more complicated to deal with.The DRV of a pixel provides information about its surroundings to a certain level. This is utilized in such a way that the seed points are filtered based on whether their DRVs are sufficiently similar to that of a set of manually selected training points. The used technique is a nearest neighbor search, basically a one class kNN classification. However, instead of Euclidean distance metric, a cross-correlation based measure is considered.Each element of a DRV corresponds to a given direction, thus points of two identical structures that differ only in their orientation, e.g. two vessel segments of the same width, have different DRVs. To overcome this difficulty, a similarity measure of the DRVs that is invariant to the orientation of the underlying structure is proposed. This is accomplished by successively rotating (circularly shifting) either vector, at each step calculating the normalized cross-correlation of the rotated and the other one. The rotation is performed as many times as the length of the DRV. That is, finally all possible orientations are checked and the maximal correlation will give the similarity of the two vectors. Whether the rotation is to the left or right is irrelevant, here the latter is considered, i.e., the rotation of a vector is performed by replacing each element of it with the one to the left, while the value shifted out at the last index is brought in at the first place.To formulate this procedure, let X and Y denote two DRVs. The maximal rotated cross-correlation (MRCC) is calculated as follows:(13)MRCC(X,Y)=maxk=1…lXρ(R(X,k),Y),whereρdenotes the Pearson correlation coefficient between the two DRVs, i.e.,(14)ρ(A,B)=∑i=1lA(A[i]−μA)/σA∙(B[i]−μB)/σB,and R denotes the rotation operation defined as(15)R(A,k)[i]={R(A,k−1)[i−1],ifi>0,R(A,k−1)[lA−1],ifi=0,whereR(A,0)=R(A,lA)=A.The classification of a DRV is done by comparing it to a given set of sample vessel point DRVs, and recording the k highest MRCC, whose mean value will provide the confidence measure of the seed point. If the confidence is less than a predefined minimal value, then the corresponding seed point is omitted from the following region growing step. The reason for considering one class classification is that this way assembling the sample vectors is more straightforward, either by marking vessel points manually, or using the given binary masks of some publicly available image sets. The only important requirement is that the marked points should be as close to the center of the vessel as possible, since the DRVs change as getting closer to the edges. This is also the reason why the seed points are extracted by considering the maxima of the corresponding vessel score map.The proposed region growing segmentation operates by iteratively expanding a seed region through processing its contour points in a sequential manner, considering their non-region 8 neighbors as possible candidates. Such a candidate point is added to the region if the product of its score divided bythscore, and the correlation coefficient between its DRV and that of the current contour point is higher than a predefined rg_coeff parameter. That is, an np neighboring point of a cp contour point is added to the region if:(16)ρ(DRVcp,DRVnp)∙score(DRVnp)/thscore≥rg_coeff.The growing is continued until there are no valid candidates to add. It is possible that a seed pixel is grown into another region in which case it will not be processed individually, since the result would be the same.Region growing criteria (16) expresses local similarity as the correlation of the DRVs of adjacent pixels, and allows certain level of deviation in vessel score fromthscore, depending on the rg_coeff parameter. By letting the vessel score to be lower thanthscore, technically a hysteresis thresholding scenario is achieved. The only difference is that instead of using a secondary lower threshold expressed in ratio tothscore, the degree of how much difference in score is allowed depends on the similarity of the corresponding DRVs. That is, in case of adjacent pixels that show high correlation in their DRVs, a larger drop in vessel score is allowed. The aim of this approach is to prevent small non-vessel structures to be connected to the peripheries of vessels, which occasionally happen when considering thresholding based solely on vessel score. In order to demonstrate this effect,Fig. 8 shows portions of three example segmentations obtained by the proposed region growing method, and by the hysteresis thresholding of the respective vessel score maps. For the latter case, the high threshold was set tothscoreand the low threshold was the product ofthscoreand rg_coeff. This way, the two techniques can be compared. It can be seen that by using the proposed vector correlation based region growing artifacts that would be present otherwise are removed. While it is true that such cases are rather rare in an image, it is important to mention that such deformations would affect the results of other methods, e.g., skeletonization which is later used to measure segment lengths.As described at the beginning of Section 2.2, the proposed segmentation is applied to both the MSMF- and BH-DRVMs, resulting in two primary vessel segmentations, basically two sets of connected components. In this final step, the components of these two segmentations are merged to construct the final binary vessel mask.Our experiments showed that on the MSMF segmentations large vessels are thinner than on the manually annotated ground truth images, while on the BH masks the width of these vessels are more appropriate. However, the MSMF is more sensitive for thin vessels, though it produces quite a lot artifact, too. The BH masks on the other hand are less susceptible for thin vessels, though usually some parts of them are present, even if the structure is not connected. Fortunately, BH masks are less sensitive to noise, thus there are less artifacts on these segmentations.First, we define the length of a binary connected component as the number of its non-intersecting skeleton points, i.e., those that have at most two 8-connected neighbors. In order to obtain the skeleton of a component the corresponding method from the ImageJ [43] image processing library has been utilized. The method used to combine the two segmentations is the following. Components on either segmentation whose length is higher than high_length are copied to the final vessel mask image. Considering the remaining components, those will belong to the final mask whose intersection with at least one component from the other segmentation is not empty, and the length of the component chain is at least low_length. For this calculation, a temporary label map T is maintained, which is initially filled with zeroes. Whenever a component from either segmentation is processed, first it is checked whether it is in overlap with a non-zero label from T. If so, the points of the processed component are set to this value on T, i.e., the union of the two sets is constructed. If there were multiple non-zero labels, then the label equivalences are noted using a convenient data structure and the component is copied to T with one of the labels. Otherwise, if all values were zero, then it is checked whether there are components in overlap from the other segmentation, and if so, their union with a new label is copied to T. Finally, when components of both segmentations are processed, the components of T are tested for their length, with also taking into consideration the label equivalences. Those components that pass are copied to the final vessel map in a binary form.Resulting from the presented merging of the MSMF and BH components, those that are only present on either segmentation and too small are removed. This becomes useful in the case of the MSMF segmentation as discussed before. Regarding thin vessels, we utilize that MSMF is more sensitive in this case, yet some fragments are usually present on the BH too. Thus, the combination of the two makes a fair compromise. Also, the width of large vessels is mostly corrected this way, simply because the BH is the more prominent in such case. InFig. 9, binary examples of the MSMF and the BH segmentations of the retinal image in Fig. 7, along with the result of their merging and the ground truth manual vessel segmentation are shown. The vessel score threshold was 0.5 in this case, and the rg_coeff parameter was set to 0.6.Most authors base the evaluation of retinal vessel segmentation methods on receiver operating characteristic (ROC) analysis. Though originally intended for the performance comparison of binary classifiers, it is also widely used in image processing. An ROC curve plots true positive rate (TPR, sensitivity) against false positive rate (FPR, 1-specificity) as the discrimination threshold of the system varies. TPR is calculated as the fraction of true positives to the number of actual positives, i.e.,TPR=TP/(TP+FN), where TP denotes the total number of true positives and FN denotes the total number of false negatives, respectively. Likewise, FPR is the fraction of false positives to the number of actual negatives, i.e.,FPR=FP/(FP+TN), where FP denotes the total number of false positives, and TN denotes the total number of true negatives, respectively. The accuracy is another measure in ROC analysis, and is calculated as the fraction of all positive detections to the number of all detections, i.e.,Acc=(TP+TN)/(TP+FN+FP+TN).In order to test a vessel segmentation result, a manually labeled ground truth image is required to which the result can be compared pixel by pixel. The determination of the TP, FP, TN, FN values are done at pixel level, considering only the points inside the ROI. Since the methods are usually tested on a set of images, the values are summed over all images. Thus, finally one point in the ROC space will describe the performance of the method at a given level of confidence. The area under the curve (AUC) value may be used to describe the performance of the system at all FPRs. However, in the case of medical decision support, only lower FPRs have diagnostic significance. It is possible that methods whose sensitivity is low at high specificity can outperform other techniques whose sensitivity is higher at low FPRs in terms of AUC. Some publicly available retinal datasets provide two manual segmentations of the vessels for each image made by different ophthalmologists. By comparing the second segmentation to the first one a performance baseline can be established based on the FPR and TPR of a secondary human observer.The performance of the proposed method has been tested on three publicly available image sets.The DRIVE database [35] consists of 40 color retinal images with an FOV of 45°. The spatial resolution of the images is 565×584 pixels; the diameter of the ROI is approximately 540 pixels on each image. The image set is equally divided into a training and a test set. The binary ROI masks are given for every image. The manual segmentations of the vasculature are given for both the training and test images, and secondary manual segmentations by a different observer are given for the test images.The STARE database [15] consists of 20 color retinal images with spatial resolution of 700×605 pixels, and an FOV of 35°. Two manual vessel segmentations are available for each image. The binary ROI masks are also given, with an average diameter of 650 pixels.The High-Resolution Fundus (HRF) Image Database [37] consists of 15 healthy, 15 diabetic retinopathy, and 15 glaucomatic images. The spatial resolution of the images is 3504×2336 pixels. One manual vessel segmentation is available for each image and the ROI masks are also provided. The diameter of the ROI is approximately 1015 pixels.The parameter values of the proposed method given so far correspond to the ROI diameter of the DRIVE images. Images of different spatial resolution should be either rescaled or the parameter values should be altered accordingly. The maximal vessel width parameter which is used for the bottom-hat response calculation in Section 2.1.2 was set to 9 for the DRIVE images. Also, the low_length and high_length parameters in Section 2.3 were experimentally determined as 25 and 15, respectively. The rg_coeff value in Section 2.2.3 was also experimentally established at 0.6. The sample DRVs for the classification step were obtained by manually marking 218 vessel points on two of the DRIVE training images. The minimal confidence and k parameters for the seed point classification described in Section 2.2.2 were set to 0.95 and 21, respectively. These values were also established by manual experimentation. Probably more optimal parameter configuration could be found by exhaustive testing, however, in this paper we aim to focus on the algorithm itself rather than its optimization.

@&#CONCLUSIONS@&#
