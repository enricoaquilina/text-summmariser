@&#MAIN-TITLE@&#
Simplified algorithms for rate-distortion optimization in high efficiency video coding

@&#HIGHLIGHTS@&#
Analysis of the previous research for H.264/AVC RDO and its application to HEVC RDO.Proposing new simplified algorithms for HEVC RDO.Analysis of the relation between computation complexity and quality degradation for proposed algorithms.Hardware estimation for proposed algorithms.

@&#KEYPHRASES@&#
High Efficiency Video Coding,Rate-distortion optimization,Simplified context adaptive binary arithmetic coding,Simplified sum of squared error,

@&#ABSTRACT@&#
HEVC is the latest coding standard to improve the coding efficiency by a factor of two over the previous H.264/AVC standard at the cost of the increased complexity of computation rate-distortion optimization (RDO) is one of the computationally demanding operations in HEVC and makes it difficult to process the HEVC compression in real time with a reasonable computing power. This paper aims to present various simplified RDO algorithms with the evaluation of their RD performance and computational complexity. The algorithms for the simplified estimation of the sum of squared error (SSE) and context-adaptive binary arithmetic coding (CABAC) proposed for H.264/AVC are reviewed and then they are applied to the simplification of HEVC RDO. By modifying the previous algorithm for H.264/AVC, a new simplified RDO algorithm is proposed for modifying the previous algorithm for H.264/AVC to be optimized for the hierarchical coding structure of HEVC. Further simplification is attempted to avoid the transforms operations in RDO. The effectiveness of the existing H.264/AVC algorithms as well as the proposed algorithms targeted for HEVC is evaluated and the trade-off relationship between the RD performance and computational complexity is presented for various simplification algorithms. Experimental results show that reasonable combinations of RDO algorithms reduce the computation by 80–85% at the sacrifice of the BD-BR by 3.46–5.93% for low-delay configuration.

@&#INTRODUCTION@&#
High Efficiency Video Coding (HEVC) [1] is the latest video compression standard developed by ISO/IEC MPEG and ITU-T/VCEG. The HEVC standard aims to improve the coding efficiency over H.264/AVC [2] by a factor of two by adopting several new compression tools including a flexible block structure, the intra-coding with new spatial prediction directions and sophisticated interpolation filters. The improved compression efficiency gives the HEVC a high potential to be adopted by consumer products such as smart phones, security systems, mobile TVs and video conferencing systems which currently use the H.264/AVC as the standard for video compression. Therefore, an efficient implementation of the HEVC standard may give a positive impact on the competitiveness of these consumer products.The complex coding structure of HEVC makes it difficult to select the optimal mode for the best rate-distortion (RD) performance. Thus, the RDO based on the precise estimation of RD costs is critical to achieve the coding efficiency aimed by HEVC.For higher coding efficiency, HEVC supports a hierarchical and flexible block structure. The improved coding efficiency is achieved by selecting the best mode that minimizes the bit rate while optimizing the visual quality. The best mode is decided by comparing the Lagrangian cost. The cost evaluation for RDO [3] requires the sum of squared errors (SSE) between the original and reconstructed signals as well as the amount of allocated bits.(1)J=SSE+λ×Bitswhere λ indicates the Lagrangian multiplier which depends on the quantization parameter (QP). In order to evaluate the impact of RDO on the compression efficiency for both H.264/AVC and HEVC, experiments are performed to measure the RD degradation with RDO turned off. For H.264/AVC and HEVC, the reference software JM18.0 [4] and HM5.0 [5] are used respectively. For H.264/AVC, the option turning off the RDO is provided by JM18.0. On the other hand, the same option is not available in HM5.0. Thus, HM5.0 is modified so that every RDO cost can be replaced by the cost based on the sum of the absolute transformed differences (SATD). It is similar to the option to turn off RDO for H.264/AVC [6].Table 1shows the increase in the bitrate by turning off RDO using four sequences in Class C with a resolution of 832×480. These four video sequences are selected to cover various video characteristics by ISO/IEC MPEG and ITU-T/VCEG for the performance evaluation. The Bjontegaard-Delta Bitrate (BD-BR) is one of the popular performance metrics to evaluate the efficiency of the video compression tool [7]. Note that a video compression tool generally needs to handle the trade-off relationship between the bit rate and image quality. BD-BR is an efficient metric to measure the balanced efficiency in this trade-off relationship because it evaluates the increase of the bit rate for a fixed video quality. Therefore, BD-BR is used in Table 1 to evaluate the effectiveness of the RDO tool in HEVC. BD-BR for H.264/AVC increases by 4.25% on average, whereas BD-BR for HEVC increases by 14.17% on average. This result shows that the RDO in HEVC is critical and must be used for achieving the high coding efficiency aimed by HEVC.For H.264/AVC, extensive efforts have been made to reduce the computational complexity of RDO. In [8], context-update dependence is removed for fast execution of context-adaptive binary arithmetic coding (CABAC). A further speed-up is achieved by reducing the number of contexts and by enhancing bin-based parallelism in [9]. In [10], the relationship between the bits and the quantized transform coefficients is modeled for the fast bits estimation of CABAC. In [11], the algorithmic complexity of RDO and CABAC is investigated and a hardware accelerator to reduce it by more than an order of magnitude is proposed. In [12], fast SSE calculation and quantization with look-up tables are proposed and the RD performance is evaluated with the fast estimation of the bitstream length for CAVLC.The simplified RDO for H.264/AVC has been successful by effectively reducing the complexity without a significant RD degradation. Therefore, this paper attempts to apply the simplified RDO for H.264/AVC to HEVC to evaluate its effectiveness. Since HM5.0 excludes CAVLC, only the simplification for CABAC is considered in this paper. By modifying the RDO for H.264/AVC, this paper also proposes new simplified algorithms for HEVC RDO. The effectiveness of the previous algorithms as well as the proposed algorithms targeted for HEVC is evaluated and the trade-off between the RD performance and computational complexity is presented.This paper is organized as follows. Section 2 introduces previous research on simplified RDO for H.264/AVC and Section 3 proposes a low-complexity CABAC targeted for HEVC. For further reduction of computational complexity, Section 4 proposes novel algorithms to reduce the transform operations for RDO. In Section 5, various simplified RDO algorithms including those for H.264/AVC and the proposed algorithms in this paper are combined and then the RD degradation and the computation complexity are evaluated by experiments. Finally, conclusions are given in Section 6.The effect of simplification on RD cost estimation is evaluated with HM5.0 [5]. Four sequences, “Parkscene”, “Cactus”, “BQTerrace” and “Basketballdrive” in Class B (1920×1080) [13] and four sequences, “Racehorses”, “BQMall”, “PartyScene” and “Basketballdrill” in Class C (832×480) [13] are used for evaluation of the RD performance. 20, 24, 28 and 32 are selected as QPs for measuring RD degradation. Asymmetric motion partitioning (AMP) and Non-Square Quad Tree (NSQT) options are turned off and the depth of the transform quad-tree is chosen as 1. Note that the maximum depth for the transform is 3 in HEVC. These encoder options cause a slight impact on the RD degradation which is shown in Table 2. The second and third columns show the BD-BR increases of 1.38% and 2.58% for these configurations, respectively. In HM5.0 reference software, the bits allocated for quantized transform coefficients are calculated twice in function, named xEstimateResidualQT(), and once in another function, named xAddSymbolBitsInter(). For clear explanation, the function names used in the HM5.0 reference software are used in this paper. To simplify experiments, the bits calculated first in xEstimateResidualQT() are used for both the second and third calculations. When all these options are turned off, BD-BR increases by an average of 3.21%. The conditions described above are common to all the experiments reported in this paper.Fig. 1presents the operations for HEVC RDO. The input of the RDO operations is the residual signals (R) whereas the outputs are the distortion represented by SSE and the bit rate denoted by Bits in Fig. 1. The generation of the SSE requires a sequence of operations: DCT, quantization (Q), inverse Q (IQ) and inverse DCT (IDCT). The evaluation of the amount of bits needs the DCT and Q followed by entropy coding. In HEVC, CABAC is used as the entropy coding module.A simplified algorithm to calculate the SSE for H.264/AVC RDO is proposed in [12]. For description of this algorithm, the following notations are used:S: original signalsRS: reconstructed signalsP: predicted signalsR: residual signalsRR: reconstructed residual signalsThe CABAC of HEVC is the same as that of H.264/AVC except that the binarization and the context modeler are slightly modified for HEVC. In H.264/AVC, several algorithms [8–10] attempt to reduce the computational complexity by estimating the number of generated bits instead of deriving the exact number. The subsection reviews the previous algorithms for simplified CABAC. Then, the BD-BR increases for the RD degradations are measured and presented at the end of this subsection.In [8], two algorithms are proposed for fast estimation of the bit-stream size. The first algorithm replaces the binary arithmetic coding operation with a table operation. As a result, the interval subdivision and renormalization are no longer necessary. This algorithm is already adopted by HM5.0 [14]. The second algorithm attempts to reduce the number of contexts in the context modeler. For the application to HEVC, a modification is made suitable for HEVC. To this end, most frequently used contexts are experimentally obtained and context modeling is modified to utilize the new contexts. The numbers of contexts for the significant map and level are reduced from 48 and 56 to 26 and 12, respectively. The number of contexts for the last significant XY (the position of the last significant coefficient) does not change.Extending the high-complexity algorithm proposed in [8], further simplification is attempted in [9]. The main idea is the update of multiple bins at a time. The context update is also performed for multiple bins at a time. Note that this context update is faster than the previous algorithm in which the context is updated in every binary symbol. For the estimation of the generated bits in the algorithm in [9], three main steps are performed. The first step creates groups of binary symbols that use the same contexts. Note that the number of the created groups is the same as the number of contexts used by the binary symbols. In the second step, the numbers of most probable symbol (MPS) and the least probable symbol (LPS) are counted for every group generated in the first step. In the third step, the counted number in step 2 is used to estimate the number of generated bits. The performance of this algorithm can be controlled by adjusting the number of binary symbols for which the generated bit is estimated at the same time. This number is denoted by Lmax. As Lmax increases, the computation speed also increases whereas the RD performance decreases. Note that the above algorithm corresponds to the case of Lmax=∞. This algorithm for H.264/AVC is applicable to HEVC with a slight modification because H.264/AVC and HEVC utilize the same probability estimation. For HEVC, binary symbol groups are generated as explained above, that is, 58 groups for the last significant XY, 26 groups for the significant map and 12 groups for the level are generated. Then, the number of bits is estimated by counting the MPS and LPS for each group. The counting result is used to estimate the number of bits and to update the context. The value of Lmax is chosen as 16 based on the experiment observing about the trade-off relationship between the speed and the RD performance according to the value of Lmax.The technique in [10] does not estimate bits by using CABAC operation. Instead, it makes use of the information about the quantized coefficients. The following notations are used for description of this algorithm:RSign: the bits for sign of coefficientsRSignificance Map: the bits for significance mapRLevel: the bits for the absolute value of a coefficientRCoeff_abs_level: the sum of RLevel for all coefficients (∑RLevel)Ns: the number of non-zero (significant) coefficientsNz: the number of zero coefficients before the last nonzero coefficientThe increase in BD-BR using CABACs with a various complexity is evaluated and presented in Table 4. Like the experiments for Table 3, both low delay and random access configurations are used for evaluation. The BD-BR increase is averaged over all the test sequences in each class. Simplified SSE is turned off for this evaluation. The high-complexity and medium-complexity CABACs show a little BD-BR increase. The increase is larger for Class C sequences than for Class B sequences. For the medium-complexity CABAC with the low delay configuration, the BD-BR is increased by 0.55% which is still very small. For the low-complexity CABAC, the BD-BR increase is relatively large averaging by 2.96% of increase for four test configurations. The RD degradation by the low-complexity CABAC may not be very significant considering the dramatic decrease of the computation by avoiding most CABAC operations.In this section, the low-complexity CABAC is modified for HEVC. To this end, statistical data are collected and used for the enhancement of the algorithm. The initial 20 frames of Class C sequences are used for the data collection, whereas an RD degradation is measured from 100 frames of Classes B and C sequences. The estimation of RSignificance Map in (9) is modified to improve the accuracy. RSignificance Map in (9) is modified to new Eq. (12). Since HEVC requires various sizes of DCT, it is necessary to estimate the weighting factors for each DCT. Based on the experimental observation, the modified version of (9) is obtained as follows.(12)RSignificance Map=0.5×Nz+1.2×Nsfor32×32=0.5×Nz+1.5×Nsfor16×16=Nz+1.3×Nsfor8×8=Nz+1.2×Nsfor4×4For further improvement, Eq. (10) is modified for the precise estimation of RLevel. Fig. 2shows the relationship between the average number of the bits generated for the level and the absolute value of the level. Note that this level represents the level of the DCT coefficient after quantization. For example, if the DCT coefficient is 9 and the quantization step is 8, the level becomes 1. The graph in Fig. 2 is approximated as a piece-wise linear function by dividing it into small segments and then approximating the segment as a line function. The result of the piece-wise linear approximation between RLevel and the absolute level is formulated as (13).(13)if(Levelabs≤1)RLevel=0;else if(Levelabs≤2)RLevel=2;else if(Levelabs≤3)RLevel=5;else if(Levelabs≤4)RLevel=5;else if(Levelabs≤5)RLevel=6;else if(Levelabs≤15)RLevel=0.4×Levelabs+6;else if(Levelabs≤90)RLevel=0.14×Levelabs+9;else if(Levelabs≤200)RLevel=0.03×Levelabs+20;elseRLevel=0.008×Levelabs+25;Finally, RSign is equal to Nsbecause RSign is generated by the bypassed path. Table 5presents the BD-BR when the original method ((9) and (10)) and the modified method ((12) and (13)) are applied. As shown in the table, the modified method improves the BD-BR change for all cases. The modified method increases the BD-BR by an average of 1.81% for all cases whereas the previous method increases the BD-BR by an average of 2.96%. This implies that the modified method reduces the BD-BR increase by 39%.As explained before, the low-complexity CABAC depends on Nz, Nsand Levelabs. Since weighting factors are determined experimentally for various DCT sizes, it is difficult to find the optimal weighting factors. Thus, the low-complexity CABAC with only Nsis considered. Recall that a large number of quantized coefficients are close to zero and the expected magnitude of non-zero coefficients is small. Thus, the relationship between Levelabs and Nsis assumed to be correlated positively. This assumption is justified by the experimental results shown in Fig. 3(a). The horizontal axis represents Nswhile the vertical axis shows the average Levelabs for Ns. As shown in the figure, Levelabs and Nsare strongly correlated. These data are obtained from experiments with DCT 32×32 while the data with the other DCT sizes are similar. Because of space limitation, the data only for DCT 32×32 are presented here. In Fig. 3(b), the similar correlation between Nsand the average Nzis observed. From this observation shown in Fig. 3(a) and (b), the terms Nzand Levelabs in (11) are replaced by Nsresulting in the following equation with new coefficient K(WDCT):(14)Restimation=K(WDCT)×Nswhere WDCT represents the DCT width. In order to decide the value of K(WDCT), the relationship between the real bits from CABAC and Nsis obtained from experimental results. Based on the experimental results, the values of K(WDCT) are chosen as 4.31, 4.63, 5.5, and 5.13 for the 32×32, 16×16, 8×8, and 4×4 DCTs, respectively.For evaluation, the BD-BR of the low-complexity CABAC with only Ns(Eq. (14)) is compared with that of the modified method ((12) and (13)). The experimental results are presented in Table 6which shows that the low-complexity CABAC with only Nsoffers a slightly better RD performance for both Classes B and C in low-delay configuration while it does a slightly worse RD performance for random access configuration. The largest difference is 0.51% for Class B in low delay configuration which is not very large. Note that the bitrate estimation using only Nsis very simple and thereby effective for hardware implementation. Thus, the low-complexity CABAC with only Nsis used as the low-complexity CABAC in Sections 4 and 5.The simplified RDO in the previous sections requires DCT and Q. This section proposes additional simplification for RDO that avoids or reduces the computation for DCT and Q. Like the experiments in Section 3, statistical data for the proposed algorithms are collected from the initial 20 frames of four Class C sequences whereas the RD degradation is measured from 100 frames of Classes B and C sequences.For DCT of size m×m (=n), the simplified SSE in (7) is re-written as (15). Consider the case when all quantized transform coefficients are very close to zero. Then, SSE′ approximates toSSE″in (16). Note that SSE″ is the energy measured in the frequency domain. According to the law of energy conservation, it is equal to the energy measured in the spatial domain. Thus, SSE″ in (16) is the sum of the squared residual signals (SSR) in (17).(15)SSE′=(F1-F′1)2+…+(Fn-F′n)2(16)SSE″=F12+…+Fn2(17)SSR=R12+…+Rn2To simplify the test for whether most coefficients are close to zero or not, this paper uses the average SSR (=SSR/n), denoted by SSRavg and then compares SSRavg with a predefined threshold. This simplification is used only when SSRavg is less than the threshold and the amount of bits is approximated to zero. If this condition is not satisfied, then the accurate RDO is estimated. The threshold is selected as a function of QP because Nsdepends on QP.(18)if(SSRavg<Threshold(QP))SSE=SSR;Bits=0;elseSSE=‖S-RS‖2;Bits=output of CABAC;The proposed algorithm is evaluated by experiments and the results are shown in Table 7. This result allows to select the criterion to determine if the proposed algorithm is acceptable or not. The largest BD-BR increase is 0.36% for Class B videos with random access configuration while the average BD-BR increase is 0.31%. The threshold value is set as 3 for QP=20. For other QP values, the corresponding threshold values are chosen experimentally to make the RD drop similar to that by QP=20.The proposed simplification is applied only for inter prediction. For the “else” condition, the simplified SSE as well as the three simplified CABAC algorithms in Sections 2 and 3 are used. Table 8presents the BD-BR increase for various options. The result of the threshold algorithm with the original RDO is given in the third row denoted by the combination of Real SSE and Real CABAC. From the fourth and sixth rows, the results with simplified SSE (SSE′) are presented. The CABAC operations are also simplified as high-, medium-, and low-complexity CABAC operations in the fourth, fifth, and sixth rows, respectively. When compared to the original RDO, the SSE′ with high- or medium-complexity CABAC shows a negligible RD drop less than 0.47%. On the other hand, SSE′ with low-complexity CABAC results in an average of 2.29% BD-BR increase. This result shows that the low-complexity CABAC suffers from an RD degradation although it significantly reduces the computational complexity.In the else-condition of (18), Nsmay be much larger than that in the if-condition of (18). Thus, the proportion of “Bits” in the else-condition may be larger than that in the if-condition. As a result, the proportion of the SSE is decreased in the else-condition. Therefore, further simplification of the SSE estimation may not result in a significant RD drop. Note that the expected value of SSE″ in (17) may increase as Threshold(QP) increases. Thus, the estimation of SSE″ is further approximated asSSE‴.(19)SSE‴=Threshold(QP)×nThis simplification is made from experimental observation with the RDO cost estimation from the following formulation:(20)if(SSRavg<Threshold(QP))SSE=SSR;Bits=0;elseSSE‴=Threshold(QP)×n;Bits=output of CABACFig. 4shows a graph with the vertical axis of the RD cost estimated from (20) and the horizontal axis of the real RD cost. This data is for DCT 32×32 and other size DCT shows a similar tendency. Due to space limitation, the data only from DCT 32×32 is presented. When the estimated cost is generated from the if-condition, it is a little larger than the real cost. On the contrary, the estimated cost is slightly smaller than the precise cost for the else-condition. Overall, the relationship is approximated to y=x line.Table 9shows the RD degradation with the RDO estimation given in (20). The results are obtained with the precise estimation of the “Bits”. The BD-BR increase is the largest of 0.9% for Class B resolution with low delay configuration. For other cases, the BD-BR increase is somewhat negligible. If the estimation of the “Bits” is simplified, then the RD degradation is worse than that given in Table 9.The last step for simplification is to predict Nswithout DCT operations. Recall that the Restimation in (14) uses Nswhich requires DCT operations. To avoid the DCT operations, an additional simplification is made to approximate the value of Ns. To this end, the SAD of residual signals (denoted by SADres) is to be used because a large value of SADres may imply a large value of Ns. This implication is experimentally tested and the results are presented in Fig. 5. The horizontal axis represents the average of SADres and the vertical axis does Ns. This data is once again obtained for DCT 32×32 and the results of the other sizes are similar. In this figure, Nsincreases as the average SADres increases although the two increases are not exactly proportional. For a practical solution, the data distribution is approximated to a line which is obtained by minimizing the errors between the data and the line. Although there exists an error between the approximated line and Ns, experimental results show that the line offers a good approximation without a significant drop of RD performance. From this approximation, Nsis expressed as (21). The slope of the approximation line depends on the QP and the DCT size.(21)Ns=slope(QP,WDCT)×SADresFrom (14), (18) and (21), the estimated bits are formulated as (22).(22)Bits=K(WDCT)×slope(QP,WDCT)×SADresThe values of slope (QP, WDCT) are determined experimentally by averaging over all Class C sequences. If Eq. (22) replaces the “Bits” of the else-condition in (20), the algorithm to skip transform is formulated as follows.(23)if(SSRavg<Threshold(QP))SSE=SSR;Bits=0;elseSSE=Threshold(QP)×n;Bits=K(WDCT)×slope(QP,WDCT)×SADres;Table 10shows the RD degradation of the simplified RDO for various skip options with all test sequences. The removal of DCT operations also imply the elimination of the operations followed by the DCT which are Quantization, Inverse Quantization, Inverse DCT and CABAC. For non-skipping transforms, the precise RDO costs (i.e., the outputs of the original CABAC) are estimated. The leftmost column represents the transforms that are skipped. The third row denoted by “Inter 32” represents the option that 32×32 DCT for inter prediction is skipped while the other DCTs are performed for the execution of the original CABAC. In this option, the BD-BRs are increased by 5.02% and 1.52% for low delay and random access configurations, respectively. The next row denoted by “Inter 32, 16” represents the option that 32×32 and 16×16 DCTs are skipped. As shown in the table, the BD-BR is slightly increased. The seventh row denoted by “Inter all/Intra 32, 16” represents the option that all DCTs are skipped for inter prediction whereas 32×32 and 16×16 DCTs are skipped for intra prediction. The last row denoted by “Inter/Intra all” means that all DCTs are skipped in both inter- and intra-predictions. As shown in Table 10, the skip of all DCTs for the inter-prediction and intra-prediction results in 13.14% increase in BD-BR on average with low-delay configuration. Overall, the RD drop increases as the computation saving increases.In this section, various simplified RDO algorithms are combined and the trade-off between the computational complexity and the RD degradation is observed. The effect of the computational complexity on the cost of a hardwired HEVC encoder chip is also discussed.The simplification options presented in this paper are combined in various manners and the operating conditions for the experiments are listed in Table 11. All the simplified RDO algorithms of the previous sections consider only luma prediction whereas this section considers both luma and chroma prediction. The second column denoted by “low-complexity CABAC” represents the estimation of the “Bits” from (14). The simplified SSE in the third column represents the value obtained from (7). From the fourth to the seventh columns, the simplified SSE and CABAC without transform proposed in Section 4.2 are applied where “32 TR” means the 32×32 DCT. The last column shows the threshold algorithm presented in Section 4.1. The simplified SSE and CABAC without transform for 32×32 DCT achieve the second largest computation saving. Thus, the operating condition 3 skips only the 32×32 DCT. The next operating condition (condition 4) skips 32×32 and 4×4 DCTs. The reason why 4×4 DCT is skipped next is because this skip causes a less RD drop than that by either a 16×16 or an 8×8 DCT skip. The computation saving by the threshold algorithm proposed in Section 4.1 is represented by condition 7.Fig. 6shows the relationship between the computation saving and the RD degradation with the operating condition presented in Table 11. The horizontal axis represents the ratio of the number of multiplications required by the simplified RDO to that in the original RDO. The vertical axis represents the BD-BR increase. For simplicity, only the number of multiplications is used to compare the computational complexity because multiplication is a most complex operation. The complexity of the CABAC operation is not considered in this figure but it is presented in the next experiments. For this experiment, the low-delay configuration is used and the frames encoded in the inter-frame prediction are evaluated. As shown in Fig. 6, the BD-BR increases as the complexity decreases. The BD-BR increase is relatively small for conditions 1, 2, 3 and 4 while it increases rapidly for conditions 5 and 6. Conditions 3 and 4 seem to be reasonable choices for simplification without a significant RD degradation. With operating condition 3, the computational complexity is decreased by 80% and the BD-BR increase is 5.13% whereas the computational complexity is decreased by 85% and the BD-BR is increased by 5.93% with operating condition 4.Fig. 7shows the RD curves with operating condition 3 for all test sequences. The RD curves with option 3 are compared with the RD curves with the reference software. Four test sequences are used for the evaluation for Classes B and C resolutions, respectively. As shown in the figure, the corresponding two RD curves for each test sequence almost overlap for a given QP range. It means that the RD degradation due to condition 3 is negligible.The computational complexity of CABAC depends mainly on the number of bins. Thus, it is difficult to estimate the amount of computation by using the number of operations. Instead, the processing time for each simplified CABAC is measured and compared to that in the original CABAC. The ratios of three complexity CABACs are described in Table 12. This result shows the reduced computational complexity of each CABAC option compared to the original. High- and medium-complexity CABACs reduce the processing time by 20% and 32%, respectively, whereas low-complexity CABAC reduces it by 90%. Three complexity CABACs with conditions 3 and 4 are applied to RDO because conditions 3 and 4 are practical options which provides a negligible degradation with a large reduction in the computation complexity. In these conditions, the simplified CABAC in (23) is used for the skipped transforms while one of the high-, medium-, or low-complexity CABACs is used for the non-skipped transforms. BD-BR degradations are listed in Table 13. It allows to select the criterion to determine if each complexity CABAC is acceptable or not. The combination of various simplified options and three complexity CABACs provides a complexity reduction from 80% to 85% and a BD-BR increase from 3.46% to 5.93%.This subsection presents the estimation of the effect of the reduced complexity on the hardware cost when an HEVC encoder is implemented in a hardware chip. This cost analysis may show the impact of the proposed RDO simplification on the development of consumer products that support video communication or recording as one of the main features.For the estimation of the RDO cost in (1), both SSE and bits terms in (1) need to be derived. The evaluation of the SSE requires a sequence of operations: DCT, Q, IQ and IDCT. On the other hand, the evaluation of the number of generated bits needs DCT and Q followed by CABAC. Compared to DCT and IDCT, the computational complexities of Q and IQ are relatively low. Thus, Q and IQ are excluded in the hardware cost estimation. For the estimation of DCT hardware costs, the results in [15,16] are used and presented in Table 14, in which the second and the third columns show the gate count and the latency of the DCT hardware designed for H.264. In this table, “Latency” represents the number of cycles to process a single block from the time to receive the input data to generate the output DCT coefficients and “gate count” represents the number of 2-input NAND gates to compose the DCT hardware. The fifth column represents the gate count estimated for an HEVC DCT hardware module. For this evaluation, the required latency (presented in the fourth column) for HEVC is compared with the latency for H.264 (in the second column) because the hardware cost, in general, increases in inverse proportion to the required performance. For the derivation of the required latency for HEVC, the number of DCT operations per frame is counted by simulation with the HEVC reference software and then the minimum execution cycle of the DCT hardware to process the required DCT operations is obtained. For this derivation, it is assumed that the encoder processes 1920×1080 size video at the rate of 60 frames per second with the operating clock frequency of 200MHz. Adding all the estimated gate counts, the total estimated gate count of DCT in RDO is 709.5K. The operating condition for Table 14 represents one of the typical operating conditions similar to those used by the literature for the design of an H.264/AVC hardware encoder [17–20]. If another operating condition is used, the estimated gate count increases in proportion to the increase of the size or frame rate of videos and also decreases in proportion to the increase of the operating clock frequency.The derivation of the hardware CABAC cost uses the estimation for H.264/AVC [21,22] because the CABAC of HEVC is almost same as that of H.264/AVC. Since the CABAC in [22] is more efficient than the CABAC in [21], the CABAC in [22] is chosen for estimating the hardware cost of CABAC for HEVC RDO. The CABAC in [22] is able to process 1,133million bins per second and its hardware cost is 36.14K gates. The hardware cost of CABAC for HEVC RDO is estimated from the throughput of [22] and the number of symbols generated by HEVC RDO. The number of symbols for CABAC depends on the test sequence and QP. When four sequences of Class B (1920×1080) [14] are encoded with QP equal to 20, the average number of symbols is measured. It is approximately 13billion symbols per second. Note that HEVC requires a much larger number of symbols because of the complex RDO operations while H.264/AVC RDO is turned off by most hardware-based encoders. Therefore, the hardware cost of CABAC for HEVC RDO is estimated to be 414.7K gates. Consequently, the total hardware cost is 1,124K gates which is a substantial amount of the hardware cost in an encoder chip design.Consider the reduced hardware cost by the simplification given in Table 14 (i.e., the condition 3 or 4 with the low-complexity CABAC). For simple estimation, it is assumed that the cost increases in proportion to the computational complexity. Recall that the complexity is reduced to 80% and 85%, respectively by conditions of 3 and 4 for DCT operations (see Fig. 6). Furthermore, the hardware cost of the low-complexity CABAC is assumed to be zero because it computes only a few operations, and consequently, does not need a CABAC engine as discussed earlier. Then, the estimated gate counts for the simplified RDOs are 106K gates and 142K gates, respectively for conditions 3 and 4 with low-complexity CABAC.

@&#CONCLUSIONS@&#
In this paper, simplified SSE and CABAC algorithms for H.264/AVC are introduced and then they are modified for the application to HEVC. These algorithms do not suffer from a noticeable RD degradation but their computation savings are relatively small. The low-complexity CABAC is modified to be optimized for various transforms of HEVC. As a result, the RD performance is further improved over the previous low-complexity CABAC. In order to reduce the computation for DCT in HEVC RDO, additional simplification algorithms are proposed. These algorithms allow the selection of a specific combination of simplification techniques and control the trade-off relationship between the computation saving and RD degradation. Experimental results show that various combinations of simplified techniques achieve computation saving from 80% to 85% at the cost of BD-BR increase from 3.46% to 5.93%.