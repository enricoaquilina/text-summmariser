@&#MAIN-TITLE@&#
Hybrid method based on singular value decomposition and embedded zero tree wavelet technique for ECG signal compression

@&#HIGHLIGHTS@&#
A hybrid compression method proposed with SVD and EZW for ECG signals.Three different techniques such as average period length, zero padding and interpolation exploited for obtaining inter and intra beat correlation.Correlated beats are utilized to construct a 2-D array.Here, two stage compressions achieve with SVD and EZW; where initially compression obtained with SVD and further compression process controlled with EZW.

@&#KEYPHRASES@&#
ECG compression,EZW,Healthcare,SVD,Telemedicine,Wavelet,

@&#ABSTRACT@&#
Background and objectiveIn the field of biomedical, it becomes necessary to reduce data quantity due to the limitation of storage in real-time ambulatory system and telemedicine system. Research has been underway since very beginning for the development of an efficient and simple technique for longer term benefits.MethodThis paper, presents an algorithm based on singular value decomposition (SVD), and embedded zero tree wavelet (EZW) techniques for ECG signal compression which deals with the huge data of ambulatory system. The proposed method utilizes the low rank matrix for initial compression on two dimensional (2-D) ECG data array using SVD, and then EZW is initiated for final compression. Initially, 2-D array construction has key issue for the proposed technique in pre-processing. Here, three different beat segmentation approaches have been exploited for 2-D array construction using segmented beat alignment with exploitation of beat correlation. The proposed algorithm has been tested on MIT-BIH arrhythmia record, and it was found that it is very efficient in compression of different types of ECG signal with lower signal distortion based on different fidelity assessments.ResultsThe evaluation results illustrate that the proposed algorithm has achieved the compression ratio of 24.25:1 with excellent quality of signal reconstruction in terms of percentage-root-mean square difference (PRD) as 1.89% for ECG signal Rec. 100 and consumes only 162bps data instead of 3960bps uncompressed data.ConclusionThe proposed method is efficient and flexible with different types of ECG signal for compression, and controls quality of reconstruction. Simulated results are clearly illustrate the proposed method can play a big role to save the memory space of health data centres as well as save the bandwidth in telemedicine based healthcare systems.

@&#INTRODUCTION@&#
Electrocardiogram (ECG) is a graphical representation of electrical impulses due to ionic activity in the cardiac muscles of human heart. It is an important physiological signal, which is exploited to diagnose the heart disease because each arrhythmia in ECG signals can be relevant to heart functionality or disease [1]. ECG signals are recorded from patients for monitoring and diagnostic purposes both. Therefore, the storage of computerized ECG has become necessary. However, the storage has limitation which has made ECG signal compression as an important issue of research in biomedical signal processing. ECG signal compression is a very critical task when information loss is not negotiable at any cost. Although, signal compression is necessary due to huge data collected during monitoring and recording from different channels, it provides solution for huge data handling and limited bandwidth in transmission and limited power resources in under-developing or developed countries. ECG compression system is a very essential part of telemedicine or remote analysis based healthcare system. It should be very efficient in compression as well as in information preservation [1–3].In healthcare sector, heart related disease has been recognized as a very critical issue among the large number of population due to causes of death. ECG signal provides basic or primary examination results regarding health condition of the human heart. In digital era, health care has also been transformed into the telemedicine healthcare system by information and communication technologies for exchanging health information, diagnosis reports/results between the medical person and patient. Developing countries or economically/socially undeveloped areas need more medical persons due to increased disease rate as compared to developed countries. These countries don’t have sufficient trained man power in healthcare sector, and there telemedicine plays a great role in health check-ups with limited time and resources. Telemedicine also provides help for child, old age and pregnant ladies in regular check-ups, because these masses need to connect with their medical person regularly.In this context, telemedicine healthcare system provides the cardiac diagnosis in form of real time analysis or offline analysis. These healthcare system works, based on biomedical signals and images or pathological observations, as similar to traditional heath care systems. As discussed earlier, these signals and images are processed by signal/image processing algorithms to extract the information of human health condition. Therefore, these signals are needed to be stored for the analysis in real-time or later as needed. Fig. 1illustrates the telemedicine system based on ECG signal processing for cardiac health observations. It clearly shows that the compression system is a very important part of the telemedicine system. It can save memory space, bandwidth and power saving of transmission system leading to a low cost healthcare [1–5]. From ECG signal/waveform analysis, it has been found that the signals have quasi-periodic nature with two different correlation such as short/full-term adjacent beat correlation and adjacent sample correlation, known as interbeat and intrabeat correlation respectively. This correlation property plays a big role in heart rate variability analysis and data compression.In context of ECG signal compression, several algorithms have been proposed using correlation properties during last few years [6–10], based on signal and image processing and coding techniques.In early stage of research, ECG signal compression was achieved with direct compression and transform based compression schemes. Transform based techniques were found to be superior than the direct compression schemes in terms of compression as well as signal reconstruction quality. In the past, a marked progress has been made in different transforms such as Discrete Cosine Transform (DCT), Fast Fourier Transform (FFT) and Discrete Wavelet Transform (DWT) [6,7–10,11–14,15–21]. Here, most popular image techniques [7–9,14] such as embedded zero tree wavelet (EZW) coding and set partitioning in hierarchical trees (SPIHT) have been applied on ECG signal. Original SPIHT based techniques work for integer values due to which loss of data was very high [10,15–21]. Similarly, singular value decomposition (SVD) based techniques have been presented, based on beat correlation properties of the ECG signal to enhance compression performance of the algorithm [26]. In this method, low rank matrix is obtained from the correlated beats of ECG signal. Therefore, rank truncation process computes the compressed data that is stored with fewer bits. Truncated singular value based technique has explored the different direction of low rank approximation to achieve compression for ECG data, based on correlation that can be further enhanced with different encoding techniques.In this paper, three different methods have been exploited to construct the 2-D array of correlated beats; based on average beat length using average R–R duration, zero padding and interpolation. The proposed compression technique is tested on constructed 2-D ECG array, based on low rank approximation using SVD and wavelet based zero tree encoding technique. Singular value decomposition (SVD) [22,26] has shown marked progress in the field of data compression with loss-less nature of reconstruction. Similarly, embedded zero tree wavelet (EZW) [23] analysis has also been established as a great tool for image compression for achieving high compression rate. It reduces the bit rate of signal, and generates low bit reconstructed signal or image. Proposed algorithm has the capability to achieve high compression rate with low reconstruction error or distortion in the recovered signal based on SVD and EZW. The technique utilizes the SVD property to obtain compressed data using lower rank of singular values with high peak-signal-to-noise ratio. The compressed data is further processed with EZW encoding technique to achieve more compression.The quantitative experimental and simulated results based on compression ratio (CR), percentage root-mean square difference (PRD), cross-correlation, signal-to-noise ratio (SNR) and coefficient of variance (CV), depict the performance and efficiency of the proposed algorithm. This paper is presented as follows: in Section 2, a brief discussion is presented about the proposed compression technique and its process. Results and discussion are included in Section 3, followed by the concluding remark in Section 4.An electrocardiogram (ECG) compression is still an emerging topic of research in the field of biomedical signal processing due to increasing demand of different telemedicine healthcare system. In this paper, an algorithm is proposed for ECG signal compression based on singular value and EZW analysis. The proposed method is applied on two dimensional (2-D) structure of data; therefore, an ECG signal needs to be converted from one vector row signal to 2-D data with respect to number of samples in a beat and number of beats. 2-D based compression of ECG data has several advantages such as algorithm can analyze the signal features such as R wave and period information, and compact visualization of long duration ECG signal. It also has ability to provide efficient data compression via exploitation of better correlation. The proposed methodology consists of following steps for obtaining the compressed ECG data: pre-processing of ECG signal as 2-D signal, singular value decomposition and analysis, and EZW analysis as illustrated in Fig. 2.An electrocardiogram (ECG) signal having quasi-periodic nature represents considerable correlation between the adjacent heart beats as well as short-term correlation between the adjacent samples. In 2-D ECG signal compression, first step is transforming the original one-dimensional (1-D) ECG signal into 2-D array, followed by the various image compression techniques [6,7–10,11–14,15–21]. Therefore, the pre-processing step for 2-D ECG compression consists of QRS detection, segmentation, and image construction based on 2-D array of the segmented ECG beats, period normalization, amplitude normalization, mean removal, transform and coding.The QRS complex is an important waveform of electrocardiogram signal having different shapes in different cases, and represents cardiac cycle and information about the heart rate. Different techniques have been proposed to detect the QRS complex such as template matching algorithm, differentiator based algorithm, filters and transform based algorithm [5,24,25]. In context of 2-D ECG data array construction, QRS wave or R peak detection is a very important part of pre-processing. It gives information about the QRS complex or R–R wave interval. This information of R–R intervals of period of QRS wave helps in alignment of different ECG beats in 2-D array. Here, in this work, QRS complex detection algorithm developed by Pan and Tompkins for pre-processing has been exploited as it is computationally efficient, more accurate for QRS detection and is also efficient for estimation of period, slope and amplitude information of QRS complex [5]. In addition to this, it gives improved performance in case of linear and non-linear filtering of noises in ECG signal.In pre-processing of ECG signal, QRS beat detection and period selection is the key features for 2-D data array construction. Then, using correlations between the adjacent heart beats of 1-D ECG signal, it is segmented and aligned properly in 2-D array, based on QRS beat information obtained from the ECG signal. In this work, three different approaches have been exploited to enhance the interbeat and intrabeat correlation in 2-D array: average period length, zero padding, and interpolation.Beat selection in pre-processing step helps in segmenting the ECG signal for construction of 2-D array. In beat selection process, QRS peak detection technique is applied for beat selection. Therefore, an average length difference between R–R peaks is chosen for the segmentation.Assume an ECG signal x(n)=[x(1), x(2), ..., x(N)], which is quasi-periodic in nature and contains M number of R peaks. The R peaks in ECG signal represents the maximum amplitude of QRS complex which is defined as(1)R(m)=[r(1),r(2),…,r(M)],where, M and m represent the number of peaks, and peak sample index in signal x(n), respectively. Therefore, the average R–R period difference is defined asLavR−R:(2)LavR−R=[r(2)−r(1)]+[r(3)−r(2)]+⋯+[r(m)−r(m−1)]M,which is considered as row length (k) of 2-D array of ECG signal given as(3)ECG2Dav=x(1),x(2),…,x(k)x(k+1),…,x(2k)⋮x((m−1)k+1),...,x(mk)k×mFig. 3illustrates that the short-term correlation and correlation exist between each row of 2-D data array and between the adjacent samples, respectively. In this paper, the average R–R period difference has been adopted for successive beat segmentation in 2-D array formation for ECG signal as this approach gives riddance from period normalization, and also gives benefit over the quantization error due to period normalization as well as amplitude normalization [9].Let an ECG signal x(n), represented as x(1), x(2), …, x(N) contains M number of R peaks. Then, ECG signal x(n) is segmented as(4)s(1)=[x(1),x(2),…r(1)],andx(k)=r(1);s(2)=[x(k+1),x(k+2),…,r(2)]⋮s(m)=[x((m−1)k+1),…,r(m)]where, m shows the segmented beats having different period length. Therefore, all the segments are needed to be normalized for same period length for perfect alignment in 2-D array.Let ‘L’ is the maximum period length of any one segment, then some zeros are padded to smaller period (N) of beat for period normalization as per required length of respective beat. After period normalization, all the segments are arranged in 2-D array defined as(5)ECG2DZP=s(1),zeros(L−length(s(1)))s(2),zeros(L−length(s(2)))⋮s(m),zeros(L−length(s(m)))L×mFig. 4shows the segmentation of QRS beats normalized in terms of period length using zero padding method; where, blue colour of ECG segments represents the original ECG, and red colour of segments shows the padded zero in original signal. In compression application, beat information is needed to be saved and sent to decoder for accurate reconstruction and alignment of beats. The constructed 2-D array has the correlated beats, which are exploited for compression.As discussed above, the segmented blocks of ECG signal have different periods in case of zero padding method. Therefore, all the blocks are needed to be normalized for equal length L (maximum period length) for perfect alignment of beats in 2-D array and also for utilization of maximum beat correlation. Here, Fast Fourier Transform (FFT) based interpolation given in [37] has been used for ECG signal period normalization using following steps [37]:Step 1: Compute FFT of the segmented ECG beat s(n) of length N using(6)S(k)=∑n=0N−1s(n)Wnk,k=0,1,2,…,N−1andW=e−j2πN;Step 2: Compute a new sequence Y(k) of a complex number of length L, defined as:(7)Y(k)=S(k),k=0,1,2,...,N2−10,k=N2,N2+1,...,L−N2−1S(k),k=L−N2,L−N2+1,...,L−1,where, L–N number of zero to be padded in case of zero padding technique, and depends upon the length of respective segmented beat period and maximum period length;Step 3: Determine the multiplication of Y(k) with L+1;Step 4: Compute inverse FFT of the sequence Y(k) to obtain y(l) using(8)y(l)=1L∑k=0L−1Y(k)W−lk,l=0,1,2,…,L−1In Eq. (8), y(l) is the desired interpolation version of respective segmented block. The interpolated block are arranged in 2-D array as(9)ECG2DIP=y(1)y(2)⋮y(l)L×mThe interpolation based period normalization is shown in Fig. 5, which illustrates the full-term correlation of beat and samples. In this method, similar to zero padding technique, original beat period information is needed to be preserved at the time of encoding the data as well as to be sent to decoder for accurate alignment of beats during reconstruction.In this paper, obtained 2-D ECG data array has been exploited as an input of proposed compression technique to obtain compressed data for saving storage space as well as bandwidth in several applications such as database, remote health care, transmission, e-health or telemedicine.The proposed compression scheme for ECG signal is based on a hybrid method of low rank singular value approximation and embedded zero tree wavelet encoding based algorithms. In this technique, 2-D array of ECG data is decomposed into SVD that contains full rank matrix information. The proposed scheme is clearly illustrated in Figs. 2 and 6, based on SVD decomposition and embedded zero-tree wavelet (EZW) coding technique, respectively.In literature, SVD has been reported for ECG signal compression that fails in case of higher rank truncation for identical reconstruction. Although, EZW algorithm is reported for ECG signal compression for 1-D analysis; where, limited amount of compression is achieved for the acceptable reconstruction. In this paper, a hybrid compression technique is proposed based on SVD and EZW. It works as two stage compression scheme based on the correlated ECG block in 2-D data. These stages give strength to algorithm to achieve different compression score with different rank of SVD approximation and different iteration of EZW algorithm.Both the algorithms have capability to compress signal or image at the cost of loss of some data in insignificance manner. Therefore, both the techniques are cascaded to obtain the compressed data of 2-D ECG signal as shown in Fig. 6. The proposed hybrid technique has good efficiency of compression with good quality of signal reconstruction in terms of SNR, PRD and other fidelity parameters due to the fact that SVD technique offers a very good PSNR value, and EZW offers a very good compression rate.The singular value decomposition is very efficient in representation of low rank matrix of highly correlated data. In this paper, an ECG signal is represented as 2-D array using correlated beats placed as consecutive row in N×M size of matrix; where, N is the length of row and M is the number of row in matrix. 2-D array of ECG data is decomposed with SVD into three triplets [26]:(10)XN×M=UN×N×∑N×M×VM×MTwhere, U, ∑andV are the sub-matrixes, U and V are known as left and right singular orthogonal matrixes, respectively, while ∑ is known as diagonal singular matrix. In Eq. (10), XN×Marray is a matrix of correlated ECG beat arranged in consecutive row as described by Eqs. (3), (5) and (9). These triplets contain the basic information of XN×Msuch as amplitude, correlation and basic pattern, respectively as discussed in Wai et al. [26]. The singular matrix (∑) contains the full rank (B) matrix of 2-D ECG data array. It can be truncated in decreasing order to retain the desired signal quality. Therefore, singular matrix is truncated as a low rank matrix (b≪B) and retained with b rank of singular matrix. Here, truncation of rank can also affect both orthogonal matrixU=ℝN×NandV=ℝM×M. Since, rank b of singular matrix has been truncated, then both left and right orthogonal matrix size has been truncated as per considered rank.Eq. (10) can be rewritten as(11)X=∑i=1KUiΣiViT=[U1Σ1V1T+U2Σ2V2T+⋯+UkΣkVkT+⋯+UKΣKVKT],It describes the basic information of quasi-periodic signal, which can be represented using linear combination of singular triplets [26]. Here, low value coefficients or lower rank of triplets are discarded using the rank B truncation. Therefore, remaining triplets retain the highly correlated coefficients. After truncation, the decomposed singular triplets can be represented as(12)X¯N×M=UN×N×∑¯N×M×VM×MT,∑¯N×M=∑¯b×b00⋱,b≤Nandb≤MX¯N×M=UN×b×∑b×b×Vb×MTwhere, output is the reconstructed array with b rank or triplets having low bit of coefficients due to the truncation of singular triplets (Wie et al., 2001).The embedded zero-tree wavelet (EZW) technique is a very popular coding technique for wavelet coefficients of original signal or image to be represented in compressed form, originally developed by Shapiro in 1993 [23]. It is proven to be an efficient compression technique for image at low bit rate. This technique offers an elegant solution to huge data handling problem of image database.An embedded code is represented with sequence of binary bit stream of gray scale images. It is similar to binary representation of any real number or pixel of image. Basically, EZW algorithm was implemented by Shapiro as an universal coding scheme in lossy and loss-less nature of compression. It has following properties and features [23]:Multi-resolution analysis (MRA) of an image is obtained using discrete wavelet transform (DWT) decomposition,Zero tree coding allows the prediction of significance and insignificance coefficients across the MRA scales for efficient representation of exponentially growing tree structure.Initially, wavelet transform represents the MRA analysis of signal or image; it decomposes the signal into two scales called low frequency and high frequency wavelet coefficients or approximation and detailed coefficients, respectively using wavelet filters such as a low pass filter (LPF) and high pass filter (HPF) as shown in Fig. 7(a).Algorithm 1Step 1: Initialize: Set initial threshold (T), such that wacelet coefficient w(m) satisfy|w(m)|<T and at least one wavelet coefficient satisfies |w(m)|≥T/2.Step 2: Update threshold: Let Tn=Tn−1/2.Step 3: Significance pass: select the significance pass using thresholding criteriaon baseline of scaning zero tree. Scan each coefficient w(m) as follows:if |w(m)|≥Tn, then Output sign of w(m)set w(m)=TnElse if |w(m)|<Tn, thenlet w(m) retain its initial value of 0.Step 4: Refinement pass: Scan through significant coefficient found withhigher threshold values Tn. For each significant coefficient value w(m), scanvalues as following:if |w(m)|∈[w(m),w(m)+Tn), thenOutput bit is 0.Elseif |w(m)|∈[w(m)+Tn, w(m)+2Tn), thenOutput bit is 1Update value of w(m) by w(m)+Tn.Step 5: Loop: Repeat step 2 through step 4.In case of image wavelet decomposition, MRA analysis is represented with four different scale or wavelet coefficients as LL, LH, HL and HH frequency bands as illustrated in Fig. 7(b).The EZW analysis works on zero tree type data structure mapping; where, low scale coefficients are the root of tree structure, and sub-tree contains the high scale coefficients as illustrated in Fig. 8. Here, zero tree structure plays a key role in finding the significant coefficients using thresholding criteria. The threshold function is initiated for selecting the significant coefficient as defined [23]:(13)x(n)=x(n)>T,significantx(n)<T,insignificantThe EZW uses four different symbols to represent the root, isolated nodes, and significant positive and significant negative wavelet coefficient of zero tree structure. The compression process is initiated with the first iteration of thresholding (i.e. initial thresholdT=2log2(max(X))) criteria to obtain significant map as discussed in [23]. The threshold value is updated with each iteration, i.e.Tnew=Told/2to obtain the new significant coefficients for reducing the loss of data. There are two types of coefficients or node present in the map; one is dominant pass and another is sub-ordinate pass. Dominant pass represents the coefficient, which is not obtained as significant coefficient in previous iteration, where sub-ordinate pass is found as significant coefficient represented with 1 bit and dominant pass is represented with 0bit. EZW technique is summarized in algorithm 1, and brief discussion can be found in reference [23,27,28]. It is widely used for image compression, and is also called bit-plane coding of zero tree wavelet coefficients.The constructed image (XN×M) of ECG signal is decomposed with SVD to obtain the low rank compressed array(X¯N×M)using lower rank singular matrix(∑¯N×M). Further, low rank compressed array is processed with EZW coding technique. In this process, EZW algorithm iterates up to maximum 20 times to identify the significant coefficients. The overall compression efficiency is calculated based on the number of bit required to represent the compressed data stream with respect to bit required for representing the original signal. The block diagram of the proposed hybrid compression scheme shown in Fig. 6 produces the compressed embedded bit stream of an ECG signal, and can be summarized with following steps:Step1: Pre-processing(i)Detection of R wave in ECG signal using QRS detection algorithm given in [5].Step2: Analysis with SVD(i)Decomposition of constructed 2-D array of ECG signal with SVD using Eq. (10).Low rank matrix approximation is obtained using Eq. (12), compressed data obtained as illustrated in Fig. 6.Step 3: Encoding with EZW technique: Compressed data is further processed with wavelet based compression coding technique EZW, based on algorithm 1 as illustrated in Figs. 2 and 6.Step 4: Finally, compressed data stream is obtained.In this section, experimental results and analysis are reported. Several examples are included to illustrate the effectiveness of proposed algorithm in the field of ECG signal data compression. Performance of the algorithm can be evaluated by considering the fidelity of reconstructed signal to original signal. For this, the following fidelity assessment parameters are considered [2,29]:(14)CompressionRatio(CR)=RequirednumberofbitsinOriginalSignalRequirednumberofbitsinCompressedSignal•Percent root mean square difference (PRD in %):(15)PRD=ReconstructednoiseenergyOrigionalsignalenergy1/2×100=∑x(n)−y(n)2∑x(n)2×100Signal-to-noise Ratio (SNR in db)(16)SNR=10log10∑x(n)2∑(x(n)−y(n))2Correlation (CC)(17)rxy=∑n=1N(xn−x¯)(yn−y¯)∑n=1N(xn−x¯)2(yn−y¯)2Coefficient of variation(18)Cv=StandardDeviationMeanIn this paper, several ECG records have been obtained from MIT-BIH Arrhythmia Database, and wavelet filters are exploited for ECG signal compression using the proposed hybrid algorithm, based on SVD and EZW. Here, three different 2-D array construction designs have been tested individually with this compression approach. The proposed method is evaluated on approximately 10 second long duration ECG signals based on above discussed fidelity parameters. These ECG signals are obtained from MIT-BIH arrhythmia database as signal numbers: 100, 101, 102, 103, 107, 111, 112, 117, 119, 123, 124, and 217 that contain the different cardiac health information of 47–85 year age group of male and female patient. These signals are recorded with a sampling rate of 360Hz with 11bit per sample of resolution. Experimental analysis illustrates that the efficiency of algorithm can vary signal to signal as well as filter to filter. In this work, the test signals are used without offset value 1024 that is added at time of storing the data in MIT-BIH Arrhythmia database. In other words, offset value has been subtracted from the processing signal that is used for quantifying the percentage root mean square difference (PRD). Besides these issues, algorithm possesses good efficiency to compress the ECG signal at minimum cost of distortion as per overall analysis stats.In pre-processing, QRS detection plays a big role in identifying the beat length for array construction, which is obtained based on algorithm given in [5]. A real-time ECG signal has variable beat length of signal; therefore, alignment of beat in 2-D array is also a big task in terms of beat correlation between the segmented blocks. Thus, the three different alignment approaches are presented based on equal length of best segment using average period length, zero padding and interpolation. The statistical analysis and literature [9] presents that the efficiency is dependent on beat correlation in 2-D array. Therefore, design of 2-D array is also an interesting part of pre-processing. Fig. 9represents the 2-D array based on average period length of alignment with short-time beat correlation; where in Fig. 10, the 2-D array based on zero-padding for period normalization, beat of alignment with considerable beat correlation is shown for the original and reconstructed 2-D array data. Similarly, Fig. 11shows the 2-D array based on interpolation using normalized period beat aligned in array with full-term beat correlation.The simulated experimental results obtained using the proposed algorithm with Coiflet (coif5) wavelet filter for different ECG signal records are listed in Tables 1–3 using average period length, zero padding and interpolation, respectively. These results show the efficiency of proposed algorithm as per globally considered standard of ECG signal reconstruction quality in terms of PRD [30]. It is defined as PRD<2%: very good reconstruction, PRD<2–5%: good reconstruction, PRD<5–9%: acceptable quality of reconstruction and PRD>9%: unacceptable quality. Here, higher SNR and correlation value also validates the quality of reconstruction although lower coefficient of variation [29] is needed to recognize the good quality of signal reconstruction.Initially, an analysis has been illustrated that is evident from the compression and reconstruction efficiency of SVD approximation based on rank truncation in Fig. 12. Here, it can be clearly seen that the compression rate is exponentially increasing with the increment of rank truncation at cost of higher reconstruction error in terms of PRD. This experiment has been tested with MIT-BIH rec. 100 where; minimum compression is achieved 3.26:1, 3.45:1 and 3.33:1, and maximum is 6.46:1, 8.66:1 and 6.61:1 for interpolation, zero padding and period length based technique respectively. From Fig. 12, it is evident that higher compression can’t be achieved by rank truncation that inspires to proposed hybrid algorithm to achieve higher compression rate at minimum reconstruction error. In this context, Figs. 13 and 14show the compression and reconstruction efficiency in terms of CR, PRD, SNR and correlation for MIT-BIH Rec. 100 at different iteration of second stage compression based on EZW with first stage compression using SVD at single rank truncation. Although, the rank truncation may be higher as trade-off decided for compression and reconstruction by users in health care systems.In this context, Table 1clearly depicts that the proposed compression technique, based on SVD and EZW using average period length technique, gives best performance for smaller period of segmented ECG blocks in terms of compression such as for ECG records: 100, 102, and 124CR is 21.91:1, 20.61:1 and 22.32:1, respectively. Overall, the average performance of the proposed algorithm in terms of CR, PRD, SNR, CC and COV with average period length technique is 17.50:1, 2.19%, 34.19db, 0.998 and −1.13, respectively.From Table 2, it can be seen that the proposed technique with zero padding gives comparable performance to average period length technique. The average fidelity parameters such as CR, PRD, SNR, CC and COV obtained with the proposed method using zero padding technique are 15.50:1, 2.62%, 32.60db, 0.998 and −1.17, respectivelyTable 3summarizes the simulation results obtained with the proposed compression technique based on interpolation. The experimental results depict that the maximum beat correlation is persisted in interpolation based period normalization. When compared with average period length and zero padding techniques, interpolated based compression technique gives higher compression with better reconstruction in terms of PRD and other fidelity parameters. The average performance with this technique in terms of CR, PRD, SNR, CC and COV is 19.92:1, 1.99%, 34.66db, 0.999, −1.18, respectively.In the proposed compression technique, lower rank of singular approximation gives highly compressed data, and low iteration of EZW algorithm yields highly compressed data at the cost of poor reconstruction quality. These results presented with B−1 rank of singular value are approximated for first stage of compression (B is the maximum rank of matrix) to avoid significant loss of signal, and rest of the process is controlled by EZW algorithm. Although, lower rank can be considered for higher compression at first stage of compression with losing signal features using rank reduction. Therefore, wavelet coefficient coding based compression technique has been exploited to enhance the compression rate of ECG data. As discussed, EZW algorithm selects the significance pass using threshold iterations; therefore, these iterations can control the compression efficiency as shown in Fig. 13. It clearly illustrates that the lower iteration can achieve higher compression as compared to higher iterations; it also shows the efficiency of algorithm for three different 2-D array designs.Similarly, Fig. 14 illustrates the efficiency of proposed algorithm in terms of PRD, SNR and correlation for different compression rate. Here, it is clearly shown that the efficiency of interpolated based design is better as compared to others in terms of all the fidelity parameters. The analysis also presents that the proposed technique is efficient for high compression with control quality of reconstruction. These results clearly show that the performance of SVD-EZW based hybrid algorithm for ECG signal is very effective with lower distortion rate as per fidelity assessments. In this analysis, EZW based coding technique iterates up to 12 times to identify the significance pass in zero tree structure. Therefore, the overall analysis is done with average iteration rate (8); where, good trade-off is present between the compression and quality of reconstruction.An ECG signal is a very important graphical representation of electrical impulses due to ionic activity in the cardiac muscles of human heart being exploited to diagnose the heart health condition. During compression process, it is common to lose some significant information from the reconstructed signal; therefore, evaluation of feature is also important to evaluate the efficiency of compression technique. Here, Pan and Tompkins algorithm has been applied to evaluate the accuracy of proposed technique based on QRS detection. Figs. 15 and 16show the original and reconstructed ECG signal MIT-BIH Rec. 100 and 217 with different compression score, respectively. Here, it is clearly shown that the QRS beats are identified in reconstructed signal; it means that the features are still preserved in compressed data. Correlation between the original and reconstructed signal is also evaluated using correlation score listed in Tables 1–3, which shows that the proposed technique is efficient for retaining the features. Figs. 14 and 15 show the performance of proposed compression scheme for various types of ECG signals, which have different morphologies. Thus, the proposed technique is efficient in compression as well as feature preservation of original signal.In the field of health care sector, telemedicine based treatment is a key solution for the remote area or expert consultancy on demand. However, due to electronic communication, several issues like communication bandwidth and storage space are involved. The main aim of the proposed compression algorithm is to compress the ECG signal that is easily applicable for telemedicine or transmission applications. It is tested on several ECG signal records obtained from MIT-BIH database. These signals are recorded with 360Hz of sampling rate with 11bit per sample of resolution. Therefore, 3960 (360×11)bit/s data are stored from original recorded ECG signal. This analysis illustrates that the proposed algorithm is efficient in reducing the bit rate such as for compressed Rec. 100, the bit rate is 360×0.45=162bit/s, for Rec. 112 is 360×0.38=136bit/s and for Rec. 217 is 360×0.5=180bit/s. This analysis has been done with single channel of data from obtained ECG signal; it changes in case of 12 lead ECG acquisition systems and stored original data increases 12 times (3960×12=44280bit/s). Overall analysis illustrates that the proposed algorithm is beneficial in saving store space as well as consumes low bandwidth in transmission.In the field of ECG signal compression, several techniques have been reported in literature [2,7–9,26,31–35], and have claimed their efficiency in terms of higher compression performance as compared to the existing methods. A comparative study of the performance of proposed method with these methods has been made in Table 4. For this purpose, the proposed method is tested on two signals MIT-BIH records 100 and 117. It is evident that the proposed technique has shown better efficiency over other existing techniques. Previous SVD based technique [26] was limited with lower compression rate at excellent quality of reconstruction. However, the proposed technique based on SVD-EZW has achieved compression with excellent quality of reconstruction as 21.91:1, and 19.67:1 for two different signals using average period length, while compression for interpolation based analysis is 24.25:1 and 12.26:1 for two different signals 100 and 117, respectively. Similarly, the proposed technique has also been compared with other 2-D based techniques [7,8,10,31,35,38] as shown in Fig. 17in terms of compression ratio and PRD. Here, it is clearly shown that the proposed compression technique is efficient as compared with existing techniques in terms of compression as well as less PRD. Overall analysis illustrates that the proposed algorithm has good efficiency to compress the ECG signal at higher rate with tolerable signal distortion.

@&#CONCLUSIONS@&#
