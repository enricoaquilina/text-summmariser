@&#MAIN-TITLE@&#
Portfolio optimization with disutility-based risk measure

@&#HIGHLIGHTS@&#
We propose a disutility-based risk measure (DCVaR) and study its propertiesWe propose the bi-objective portfolio model Mean-DCVaR and equivalent formulationsMean-DCVaR efficient portfolios differ markedly from the other Mean-Risk frontiersDCVaR efficient portfolios constitute improvement over CVaR/Var

@&#KEYPHRASES@&#
Quantile-based risk measures,Mean-Risk model for portfolio optimization,Utility functions,

@&#ABSTRACT@&#
In this paper we propose a quantile-based risk measure which is defined using the modified loss distribution according to the decision maker’s risk and loss aversion. The properties related to different classes of disutility functions are established. A portfolio selection model in the Mean-Risk framework is proposed and equivalent formulations of the model generating the same efficient frontier are given. The advantages of this approach are investigated using real world data from NYSE. The differences between the efficient frontier of the proposed model and the classical Mean-Variance and Mean-CVaR are quantified and interpreted. Extensive experiments show that the efficient portfolios obtained by using the proposed model exhibit lower risk levels and an increased satisfaction compared to the other two Mean-Risk models.

@&#INTRODUCTION@&#
Solving the portfolio selection problem relies on models for preference between random variables representing portfolio returns. Choosing a specific model is itself a problem because each type of models assumes a different vision on choice under risk, different theoretical basis with strengths and weaknesses, and different degrees of computational tractability. In this paper, we present a new Mean-Risk model of portfolio selection. Its novelty consists in using of a new risk measure based on the modified loss distribution function according to the decision maker’s risk and loss aversion preferences. These preferences are usually described by increasing, smooth and concave utility functions, but studies in behavioral finance showed that people systematically violate expected utility theory, see for example Camerer, Kagel, and Roth (1995). Kahneman and Tversky (1979) and Tversky and Kahneman (1992) have found that decisions are driven especially by loss aversion and the prospect of ending up with less than the initial wealth. There is also the power utility function with loss aversion implemented by Maringer, Kontoghiorghes, Rustem, and Winker (2008) where the returns are adjusted before they are evaluated in the utility function: returns lower than a prescribed threshold are given disproportionate weight. Therefore, the utility changes abruptly resulting in a kinked utility function, see Cremers, Kritzman, and Page (2005); Hagstromer and Binner (2009); Maringer et al. (2008); Sharpe (2007). There is a variety of reasons why decision makers have critical thresholds: some investors might violate loan covenants if their assets fall below a specified value, others face regulatory mandates which require a minimum level of reserves, also in the practice of risk when asset levels fall under the loss threshold fund managers are penalized.Apart these approaches relying on utility functions, there are the Mean-Risk models. Variance was the first risk measure used in portfolio optimization. The Mean-Variance (MV) methodology proposed by Markowitz (1952) has played a crucial role in portfolio theory and provided the fundamental basis for the development of a large part of the modern financial theory applied to the portfolio optimization problem; moreover, in his recent paper (Markowitz, 2012), a thoroughly research on mean–variance approximations to expected utility can be found. But regulations for finance businesses formulate some of the risk management requirements in terms of quantiles of loss distributions. The most commonly used is the Value at Risk (VaR). VaR can be efficiently estimated and managed when underlying risk factors are normally distributed. However, for non-normal distributions, VaR may have undesirable properties (see Artzner, Delbaen, Eber, & Heath, 1999) such as the lack of sub-additivity. Also, VaR is difficult to control/optimize for discrete distributions, when it is calculated using scenarios. In this case, VaR is non-convex and non-smooth as a function of positions, and has multiple local extrema. To alleviate these problems, (Artzner et al., 1999) proposed the Conditional VaR (CVaR) which is sub-additive and, consequently, coherent. CVaR continues to be intensively studied and applied in different contexts. For example, in the context of enhanced indexation, the paper of Roman, Mitra, and Zviarovich (2013) provides a unified framework incorporating CVaR and second order stochastic dominance. More detailed discussions on CVaR and new advances on its estimation and asymptotics can be found in Rockafellar and Uryasev (2002) and Chun, Shapiro, and Uryasev (2012), just to name a few.The contribution of this paper is threefold. Firstly, we propose a risk measure defined using the modified loss distribution according to the decision maker’s risk and loss aversion preferences and establish its properties (Section 2). Our motivation is based on the well known fact well acknowledged in the literature that different categories of investors have different modeling needs which are not well met by standard approaches, see (Spronk & Hallerbach, 1997; Cillo & Delquié, 2014; Wächter & Mazzoni, 2013). Investors preferences are often, but not exclusively related to utility functions. Many other different ideas of modeling them were proposed in the literature. For example, investor’s preferences can be captured through various types of constraints such as cardinality constraints in portfolio optimization as in Chang, Meade, Beasley, and Sharaiha (2000) and Woodside-Oriakhi, Lucas, and Beasley (2011), or in energy planning as in Chang (2014), crop planning as in Rădulescu and Rădulescu (2012) and Rădulescu and Rădulescu (2014), socially responsible investments as in Hallerbach, Ning, Soppe, and Spronk (2004), just to name a few. Also, to accommodate the preferences of non-standard investors (expressed as additional stochastic and deterministic objectives such as liquidity, dividends, number of securities in a portfolio, social responsibility,...), portfolio selection models with multiple criteria that ensures portfolio suitability are developed in Steuer, Qi, and Hirschberger (2007). Moreover, the very choice of the risk measure used in the portfolio model is a manifestation of preferences. Apart the classical risk measures, new ones were designed to cover various risk profiles, see for example the Conditional Average (inspired by CVaR but using two confidence levels) introduced by Krzemienowski (2009). The idea of using more than one confidence level is also present in Kalinchenko, Uryasev, and Rockafellar (2012) where risk preferences are calibrated by the coefficients in the mixed CVaR deviation. But usually investors preferences are related to utility functions. Up to now, in conjunction with a Mean-Risk model (most frequently with Mean-Variance), investor’s utility function was used to determine the preferred portfolio out of the investment set represented by the Mean-Risk efficient frontier, see (De Giorgi & Hens, 2009; Hens & Mayer, 2014; Kroll, Levy, & Markowitz, 1984; Levy & Levy, 2004; Pirvu & Schulze, 2012). In this paper, instead of taking into account investor’s preferences only in this second phase, we bring them into the risk measure by using her/his utility function that captures the investor’s risk and loss aversion; consequently, preferences are fully taken into consideration right from the first phase in which the efficient frontier is determined. Thus, this paper addresses one of the main universally acknowledged streams of concerns: the challenge to balance the properties of the risk measure with behavioral and practical considerations. Secondly, we consider a bi-objective portfolio selection model in the Mean-Risk framework using the risk measure previously defined. and give different equivalent representation of the efficient frontier (Section 3). We give three equivalent formulations of the model. They are equivalent in the sense that they produce the same efficient frontier. The equivalence between the three models is proven for the Mean-Variance efficient frontier in Steinbach (2001), for the Mean-Regret efficient frontier in Dembo and Rosen (1999) and for the Reward-CVaR efficient frontier in Krokhmal, Palmquist, and Uryasev (2002). Thirdly, we investigate the practical performances of the model using real data from New York Stock Exchange (Section 4). We present the forecast procedure used and the out-of-sample analysis assessing the reliability of the forecast (Section 4.1). We compare the efficient frontier of the proposed model with the Mean-CVaRand Mean-Variance frontiers quantifying the differences and similarities between them (Section 4.2). Moreover, we assess the investor’s benefits of using the proposed model: out-of-sample experiments show that the efficient portfolios obtained by using it exhibit lower risk levels (at the same return levels).Let n be the number of securities available for the portfolio. The key random inputs in the portfolio management problem are the asset prices at the end of the planning horizon denoted byp(ω)=(p1(ω),…,pn(ω)),ω ∈ Ω or simply byp(we use bold symbols for vectors). The set Ω represents the set of future states of knowledge and has the mathematical structure of a probability space with a probability measure P for comparing the likelihood of future states ω. Let l(x, p) be the loss associated with the decision vectorx∈X⊂Rnand the random vectorp, wherexis interpreted as a portfolio and X is the set of available portfolios subject to various constraints. The loss equals to the difference between the initial wealth W0 and the final random wealth,l(x,p)=W0−W,whereW=xTp.Positive outcomes of loss function are disliked, while negative outcomes are welcome because they represent gains. For eachx∈ X, the loss l(x, p) is a random variable having a distribution inRinduced by that ofp. Throughout this paper, the loss function can have a more general form if it is continuous inx, measurable inpand E(|l(x, p)|) < ∞ ∀x∈ X. The underlying probability distribution ofpinRnis assumed to have the probability density function (pdf) g(p),p∈Rn.Given z a level of losses, the cumulative distribution function (cdf) of l(x, p) is defined byGl(x,p)(z)=P({p|l(x,p)≤z})=∫l(x,p)≤zg(p)dpand is assumed continuous with respect to z. LetGl(x,p)←:(0,1)→Rbe theα−quantile function, given byGl(x,p)←(α)=minGl(x,p)(z)≥αz. Within risk management, it is called the Value at Risk of the loss l(x, p) at a probability level of α ∈ (0, 1), denoted by VaRα(l(x, p)) or zα(x). Artzner et al. (1999) introduced the concept of coherent risk measure. The Conditional Value at Risk (CVaRα)of the loss l(x, p) at probability level α ∈ (0, 1) proved to be coherent, see for example Pflug and Uryasev (2000). The dedicated notation which associates any portfoliox∈ X to its corresponding CVaRαis ϕα: X→Rgiven by(1)ϕα(x)=11−α∫l(x,p)≥zα(x)l(x,p)g(p)dp.Generally, in the literature,l(x,p)=W0−Wand consequently, for a given probability distribution ofp, CVaRαwill be the same for all investors whatever their particular profiles of loss aversion. But in real life, an investor has a certain risk profile and also a critical loss level; it is the case of an investor whose lifestyle might change drastically if a certain critical loss level is reached. Therefore, a more realistic approach is to consider that the decision maker is characterized by an increasing convex disutility function D with loss aversion which exhibits a kink at this critical loss level θ. When θ is reached, the perception of losses changes abruptly: the losses higher than this critical threshold are given disproportionate weight in accordance with a loss aversion parameter λ which yields a kink on the disutility function located at the critical loss value. An example of such a disutility function D that captures the investor’s risk and loss aversion can be written based on the utility function U defined in Adler and Kritzman (2007); Cremers et al. (2005):(2)U(z)={ln(1+z),forz≥θλ(z−θ)+ln(1+θ),forz<θ,whereD(z)=−U(−z),∀z∈R. This function is also similar to the piecewise linear loss-averse utility used in Fortin and Hlouskova (2011). More examples of disutility functions with loss aversion, can be found in Maringer et al. (2008) and for the effect of utility functions on the optimal portfolio see also Yu, Pang, Troutt, and Hou (2009) and Çanakoğlu and Özekici (2010).When making decisions by considering the disutility of the loss as previously described, we define the Conditional Value at Risk of the disutility of the loss at a probability level of α ∈ (0, 1),(3)CVaRα(D(l(x,p)))=E(D(l(x,p))|D(l(x,p))≥VaRα(D(l(x,p)))).VaRα(D(l(x, p))) is denoted by DVaRα(l(x, p)) to distinguish the value at risk of the loss function from the value at risk of the disutility of the loss function. Therefore, we define the DisutilityValue at Risk as(4)DVaRα(l(x,p))=minGD(l(x,p))(y)≥αy,denoted by yα(x), where GD(l(x, p)) is the cdf of D(l(x, p)). For any y,GD(l(x,p))(y)=P({p|l(x,p)≤D→(y)})=Gl(x,p)(D→(y)),whereD→(y)=max{z|D(z)≤y}is the right continuous generalized inverse of D. This allows us to write(5)yα(x)=minGl(x,p)(D→(y))≥αy.Proposition 1For any fixedx,DVaRα(l(x,p))=D(VaRα(l(x,p))).First, we demonstrate that D(zα(x)) ≥ yα(x). Due to (5) we have(6)D(Gl(x,p)←(α))≥minGl(x,p)(D→(y))≥αy.We also have, D→(D(z)) ≥ z for any z. Since Gl(x, p) is increasing, we getGl(x,p)(D→(D(Gl(x,p)←(α))))≥Gl(x,p)(Gl(x,p)←(α)). By definition,Gl(x,p)(Gl(x,p)←(α))=α. Now we can conclude thatD(Gl(x,p)←(α))is feasible for the minimization problem in (6) and the first inequality is proved.In order to prove the reverse inequality, we first note thatD(z)=yα(x)for any z with D←(yα(x)) ≤ z ≤ D→(yα(x)), whereD←(y)=min{z|D(z)≥y},y ∈R. In particular, we have D(D→(yα(x)))=yα(x). Therefore, to finish the proof it suffices to notice that(7)D→(yα(x))≥Gl(x,p)←(α)=minGl(x,p)(z)≥αz.The last inequality is true because D→(yα(x)) is feasible for the minimization problem in (7). This assertion is based on the fact that the optimal solution yα(x) in (5) is feasible and therefore Gl(x, p)(D→(yα(x))) ≥ α.□We consider the general case of an investor which can have the same level of dissatisfaction for a specified range of losses; hence, the graphical representation of the disutility function has flat portions. Letα−andα+be the left end, respectively the right end of the interval of probability levels (depending onx) for which the whole range of corresponding VaRs have the same image D(VaRα(l(x, p))), i.e.α−=Gl(x,p)(D←(D(zα(x))))andα+=Gl(x,p)(D→(D(zα(x)))).Definition 1For any fixed portfoliox∈ X and any specified probability level α ∈ (0, 1) we define the Disutility Conditional Value at Risk (DCVaR) asϕαD(x)=11−α−∫l(x,p)≥D←(D(zα(x)))D(l(x,p))g(p)dp.Combining (3) and Proposition 1 results in the next proposition:CVaRα(D(l(x,p)))=E[D(l(x,p))|D(l(x,p))≥DVaRα(l(x,p))]=E[D(l(x,p))|D(l(x,p))≥D(VaRα(l(x,p)))]=E[D(l(x,p))|l(x,p)≥D←(D(zα(x)))].Proposition 2For any fixedx,DCVaRα(l(x,p))=CVaRα(D(l(x,p))).Therefore DCVaRαof the monetary loss l(x, p) is in fact CVaRαof the modified/altered loss D(l(x, p)); the alteration in the decision maker’s perception of the monetary value is caused by his loss aversion which is captured and represented here by the disutility D. Regarded as a function of the random variable D(l(x, p)), due to Proposition 2 from (Pflug & Uryasev, 2000), CVaRα(D(l(x, p))) is coherent in the sense that it is translation-invariant, convex, positively homogeneous and monotonic with respect to the stochastic dominance of second order, as defined in Artzner et al. (1999). Next, we discuss the properties of DCVaRαregarded as a function of l(x, p).(1) Monotonicity. DCVaRαis monotone i.e. for any two portfoliosx1 andx2, if l(x1,p) ⪯ l(x2,p), then DCVaRα(l(x1,p)) ≤ DCVaRα(l(x2,p)) which is a straightforward consequence of the monotonicity of D and CVaRα. We recall that the previous notation l(x1,p) ⪯ l(x2,p) represents the sample-path dominance: l(x1, p(ω)) ≤ l(x2, p(ω)) for all ω ∈ Ω.Monotonicity with respect to First order Stochastic Dominance FSD. Generally, we say that the random variable X is preferred to Y and we write X≽FSDY if between their cdfs we haveGX(r)≤GY(r),∀r∈R. In the field of decision making under risk, this means that X is preferred to Y within all preference models that prefer larger outcomes. We apply the definition for the loss distributions of two given portfolios two portfoliosx1 andx2: l(x1,p)⪯FSDl(x2,p) ifGl(x1,p)(r)≥Gl(x2,p)(r),∀r∈R.Being written in terms of losses, in order to have DCVaRαconsistent with FSD, we expect to find DCVaRα(l(x1,p)) ≤ DCVaRα(l(x2,p)). This is obviously true because l(x1,p)⪯FSDl(x2,p) ⇒ D(l(x1,p))⪯FSDD(l(x2,p)) for any non-decreasing function D and CVaRαis consistent with FSD.(2) Convexity. DCVaRαis convex i.e. ∀x1,x2 and γ ∈ [0, 1],(8)DCVaRα(γl(x1,p)+(1−γ)l(x2,p))≤γDCVaRα(l(x1,p))+(1−γ)DCVaRα(l(x2,p)).Indeed, the monotonicity and convexity of D and CVaRαimply:DCVaRα(γl(x1,p)+(1−γ)l(x2,p))≤CVaRα(γD(l(x1,p))+(1−γ)D(l(x2,p)))≤γCVaRα(D(l(x1,p)))+(1−γ)CVaRα(D(l(x2,p)))=γDCVaRα(l(x1,p))+(1−γ)DCVaRα(l(x2,p)).(3) Normalization. DCVaRαis normalized i.e.DCVaRα(0)=0. We recall that the normalization property of a risk measure expresses the fact that zero loss implies no risk. Regarding D, the requirementD(0)=0is not restrictive and has the natural interpretation that the dissatisfaction of a zero-loss is null and the disutility function (2 ) satisfies this condition.(4) Positive homogeneity. We recall that the positive homogeneity axiom ensures that if all realizations of the financial risky position under consideration are multiplied by a positive factor, then the corresponding risk scales with the same factor. Follmer and Schied (2002) and Frittelli and Rosazza Gianin (2002) showed that this requirement is questionable in the context of financial applications where the monetary payoff of a financial position is taken into consideration. The reason is that a risk measure satisfying the positive-homogeneity property may fail to detect liquidity risk. Because, when a position is multiplied by a large factor n, an additional liquidity risk may arise and therefore the risk of this whole new position becomes less liquid than n distinct simple positions. There is another aspect that prevents the positive homogeneity property of DCVaRαfrom being satisfied: when multiplying l(x, p) by a positive factor γ, l(x, p) and γl(x, p) might result in opposite sides of the threshold θ, therefore it is natural for DCVaRαto be positive sub-, respectively positive supra-homogeneous in the following sense:(9)DCVaRα(γl(x,p))≤γDCVaRα(l(x,p)),ifγ∈(0,1](10)DCVaRα(γl(x,p))≥γDCVaRα(l(x,p)),ifγ∈[1,∞).The first Eq. (9) is a direct consequence of the convexity of DCVaRαcombined with the normalization property. Indeed, ∀xand γ ∈ (0, 1] we haveDCVaRα(γl(x,p))=DCVaRα(γl(x,p)+(1−γ)(0·1))≤γDCVaRα(l(x,p))+(1−γ)DCVaRα(0·1)=γDCVaRα(l(x,p)).(10) follows from (9) in which γ has been replaced with 1/γ, γ ∈ [1, ∞).(5) The axiom of translation invariance from Artzner et al. (1999) and Follmer and Schied (2002) can be found in different forms: as cash invariance in Follmer and Schied (2004), translation-equivariance in Pflug and Uryasev (2000), cash-additivity in El Karoui and Ravanelli (2009). When assessing the risk of a future payoff, the translation invariance axiom is supported by the following financial interpretation: adding risk-free cash to a risky position reduces its risk by the same amount. But assuming the existence and liquidity of such a risk-free asset is not realistic and any form of uncertainty/stochasticity in interest rates makes the translation invariance assumption too restrictive; the simple consideration of the time value of the money imposes the replacement of translation invariance by a weaker condition called cash-sub-additivity, see El Karoui and Ravanelli (2009). DCVaRαsatisfies the property which will be called translation-supravariance: if l(x, p) ≥ 0 and c ≥ 0,(11)DCVaRα(l(x,p)+c)≥DCVaRα(l(x,p))+D(c).From the translation invariance of CVaRαand the convexity of D we have:DCVaRα(l(x,p)+c)=CVaRα(D(l(x,p)+c))≥CVaRα(D(l(x,p))+D(c))=CVaRα(D(l(x,p)))+D(c).We note that the positivity of the loss is an essential condition here. Indeed, having in mind the graphical representation of the particular disutility function (2), it is easy to find a value l(x, p) ≤ 0 inferior to θ and c ≥ 0 for which the opposite of (11) is true.(6) The axiom of subadditivity is a controversial one. Important papers such as Artzner et al. (1999) explain why the subadditivity property is a natural requirement for risk measures and show that this property holds under certain restrictions upon the discounted risks. But there are also significant voices/opinions that argue that the axiom of subadditivity should be replaced with the less restrictive one of convexity, since the cases when merging leads to a riskier situation are not rare, see for example Dhaene, Laeven, Vanduffel, Darkiewicz, and Goovaerts (2008). An obvious example of such a situation is the case when portfolios merge/split; usually this leads to a change in the management-related costs and maybe even more, the entire business strategy might change. Consequently, the decision of merging/splitting could entail a whole new cost structure that changes the losses under consideration and makes the relationship betweenDCVaRα(l(x1,p)+l(x2,p))andDCVaRα(l(x1,p))+DCVaRα(l(x2,p))strictly conditional on the particular business situation and loss aversion profile.Following the approach in Rockafellar and Uryasev (2000), we will now defineX×R∋(x,y)↦FαD(x,y)=y+11−α−∫Rn[D(l(x,p))−y]+g(p)dp,where[a]+=max{a, 0}. In the present case, all the advantages which are brought by using this auxiliary function, are lost because ofα−.The presence of zα(x) in the definition ofα−makes the minimization of bothFαDandϕαDequally difficult: in both cases, first we have to calculate VaRα(l(x, p)) because both definitions depend on it. In order to benefit from this technique which is intended to allow to obtain VaRα(l(x, p)) as a by-product instead of pre-determining it, we use an approximation of the true disutility function (while having the decision maker’s approval): whenever D is constant on an interval, we replace it with a linear increasing function with a very small slope so that the continuity of the function would be preserved. Thus,α−=αwhile DCVaRα(l(x, p)) can be calculated by minimizingFαDwith respect to z without first having to calculate VaRα(l(x, p)). So, throughout the rest of this paper, the disutility D will be considered a strictly increasing function.Theorem 31.For any fixedx∈ X,y↦FαD(x,y)is a continuously differentiable function maybe excepting for a finite number of points.For any fixedx∈ X,(12)ϕαD(x)=miny∈RFαD(x,y).The Value at Risk yα(x) is a point of the nonempty, closed, bounded interval (possibly reducing to a point)argminy∈RFαD(x,y).For any fixedx∈ X,(13)ϕαD(x)=FαD(x,yα(x)).(14)minx∈XϕαD(x)=min(x,y)∈X×RFαD(x,y).Moreover, (x*, y*) ∈ X ×Ris the optimal solution for the problem on the right hand member of (14) if and only ifx*is the optimal solution for the problem on the left hand member and y* ∈argminy∈RFαD(x*,y). Ifargminy∈RFαD(x*,y)reduces to a single point, then the minimization problem on the right hand produces a pair (x*, y*) ∈ X ×R, not necessarily unique, such thatx*is the optimal solution for the minimization problem of the DCVaRαon the left hand member andy*=yα(x*).The functionsFαD(x,y)andϕαD(x)are convex with respect to (x, y), respectivelyx.Next, we study the effect of adopting Kahnemann and Tversky’s point of view according to which people’s behavior is captured by an S-shaped value function which is concave for gains (implying risk aversion), convex for losses (risk seeking) and steeper for losses than for gains (loss aversion), Kahneman and Tversky (1979), Tversky and Kahneman (1992). We focus on establishing if Theorem 3 remains true in the case of an investor characterized by a S-shaped disutility function. The first part of the theorem relies on Proposition 2.1 of Shapiro and Wardi (1994) applied to the convex functiony↦[D(l(x,p))−y]+,y∈R.The immediate consequence is that the integral term inFαDis convex and continuously differentiable with respect to y and moreover, its derivative with respect to y is equal toGD(l(x,p))(y)−1. Properties 1–4 from Theorem 3 are direct consequences of the application of the first order necessary condition to the minimization problem in (12) combined with the convexity and continuously differentiability ofFαDwith respect to y. The lack of convexity of D does not interfere with the proof, therefore properties 1–4 remain true.The importance of Theorem 3 is due to (14) which allows the replacement of the stochastic problem on the left hand with the more tractable one from the right hand. Both problems are convex and, consequently, they benefit from a plethora of specialized algorithms for stochastic convex optimization. If the decision maker’s attitude towards risk is described through prospect theory, then because of the S-shape of D, the convexity ofFαDwith respect to (x, y) is lost, but the equivalence between the two optimization models in (14) is still valid. When compared to the model on the left hand of (14), the one on the right hand, even if it is non-convex, shows the great advantage of havingxand y independent variables. This allows us to minimize overy∈Rfor a fixedx(which is a stochastic convex optimization problem for any fixedx, regardless the lack of convexity of D) and then minimize overx∈ X.We consider the single-period portfolio problem which involves portfolio decisions in response to new information on market future prices (returns) of the risky assets. The decision maker starts (att=0) with an initial portfoliox0∈Rnhaving full knowledge of the current asset pricesp0. The action taken on asset i at timet=0is denoted by uiand represents the amount of the ith purchased/sold asset. The investor can either hold the asset i (ui=0), buy more (ui> 0), or sell off a part of asset i (ui< 0). The decision vector isu∈Rnand the adjusted portfolio isx=x0+u. We assume that no short selling is allowed, i.e.x≥ 0. Buying and selling causes transaction costs which we assume to be proportional to the amount of asset traded. In our model, 100c represents the transaction costs expressed as a percentage associated with buying/selling one unit of asset i. The budget constraintxTp0+∑i=1np0,i|ui|c=W0represents the assumption that there is no exogenous intervention in the amount of money involved in transactions during the time period.We propose the Mean-DCVaR model with transaction costs:(15)minx∈X(−E(W(x,p)),DCVaRα(l(x,p)))(16)X={x∈Rn|xTp0+∑i=1np0,i|ui|c=W0,0≤xi≤W0p0,i,i=1,n¯}One of the most widely used approaches in solving problems with multiple objectives is the weighting method. The weakness of this technique is that not all the Pareto optimal solutions can be found unless the problem is convex.Theorem 3 allows us to use the equivalent model:(17)min(x,y)∈X×R(−E(W(x,p)),FαD(x,y)).When D is convex,FαDis convex in both arguments and the weighting method provides the efficient frontier:(18)min(x,y)∈X×R(−E(W(x,p))+wFαD(x,y)),w>0,or, we can solve one of any of the two optimization problems(P1){min(x,y)∈X×RFαD(x,y)E(W(x,p))≥μ,or(P2){max(x,y)∈X×RE(W(x,p))FαD(x,y)≤ν,where μ represents the desired level of expected wealth and ν, the acceptable level of risk. Varying the trade-off coefficient w in (18), μ in (P1), ν in (P2) and repeatedly solving the corresponding optimization problems traces out the efficient frontier as the next theorem shows.Theorem 4Models (18), (P1), (P2) generate the same efficient frontier.The proof follows the general lines of similar proofs that can be found in classical textbooks concerning multiobjective optimization. The equivalence between the three problems is proven for the Mean-Variance efficient frontier in Steinbach (2001), for the Mean-Regret efficient frontier in Dembo and Rosen (1999) and for the Reward-CVaR efficient frontier in Krokhmal et al. (2002).The importance and usefulness ofFαDfrom both theoretical and optimization points of view are captured in the next theorem.Theorem 51.The optimization problems (P2) and(19)maxx∈XE(W)(20)ϕαD(x)≤νare equivalent in the sense that their objective functions provide the same minimum values. If the constraint (20) is active, (x*, y*) is optimal for the problem (19) and(20) if and only ifx*achieves the minimum of (P2) andy*∈argminy∈RFαD(x,y). In particular, whenargminy∈RFαD(x,y)reduces to a single point, the minimization in (P2) produces a pair (x*, y*) such thatx*maximizes E(W) and y*represents the corresponding DVaRα(x*).The optimization problems (18) and(21)minx∈X(−E(W)+wϕαD(x)),w>0are equivalent in the sense that their objective functions achieve the same minimum values. Moreover, (x*, y*) is optimal for the problem (18) if and only ifx*achieves the minimum of (21) andy*∈argminy∈RFαD(x,y). In particular, whenargminy∈RFαD(x,y)reduces to a single point, the minimization in (18) produces a pair (x*, y*) such thatx*is optimal in (21) and y*represents the corresponding DVaRα(x*).The computational study is meant to establish how different are the Mean -DCVaR (MD) efficient portfolios compared to the classical Mean-Variance (MV) and Mean-CVaR (MC) efficient portfolios. For the calculation of DCVaR, we use two classes of disutility functions, with various degrees of loss aversion. We also study the influence of box constraints imposing different degrees of diversification.The practical performances of the Mean-DCVaR model are measured using real world data considering closing price data of 20 representative securities from the New York Stock Exchange. The list of stocks full names together with descriptive statistics (calculated with logarithmic weekly returns) showing the departure from normality are presented in Tables A1 and A2 from Supplementary Material (SM). The weekly returns were calculated from the daily stocks adjusted closing prices which were downloaded from Yahoo! Finance and checked against errors (missing data, calculation errors, outliers). To estimate the future values of returns, we use the Filtered Historical Simulation method to bootstrap i.i.d. standardized residuals, filtered from residuals of an econometric model, to generate paths of future asset returns. This way, the nonparametric assumption regarding the probability distribution of returns is retained. What makes this method attractive is the possibility of using complex models: for each of the 20 assets, we use a combination of ARMA(1,1) for the conditional mean and GARCH(1,1) for the conditional variance, (Bollerslev, 1986) and (Bollerslev, Engle, & Nelson, 1994).The available data series of any of the 20 securities is of lengthT=906(weeks) and is denoted by{r1,…,rT}where rtis the tth weekly return of the asset considered,t∈{1,…,T}. The descriptive statistics in Table A2 from SM suggest that the series have the typical characteristics: skewed, mainly positively, presenting excess kurtosis. The data series is divided into two groups:•the estimation set spanning from 3rd January 1997 to 9th September 2011, that corresponds to{r1,…,rT0},whereT0=766,andthe testing set spaning from 10th September 2011 to 18th May 2014, a total of 140 weeks that corresponds to{rT0+1,…,rT}.We mention that 766 represents also the length of the rolling window used when fitting the model. The estimation set is used to extract the filtered model residuals (filtered because, from all residuals, you can retain those having the characteristics relevant for the model - in our simulation we used all the residuals calculated in the estimation period). We briefly describe the forecasting procedure for 1-step to H-step-ahead forH=12weeks (length of the forecast) at eacht∈{T0,…,T−H}. The length of the out-of-sample period is ofT−H−T0weeks.We mention that, in order to develop the MD model and assess its performances, we generated a complete set of data with a maximal value of the forecastH=12weeks that allows a variable time horizon (≤ 12 weeks), a variable number of assets,... By developing independently the modules of forecast and optimization, we achieve an increased flexibility and we reduce the resource requirements.Step 1. Lett=T0(=766)be the initial forecast origin.Step 2. We estimate the model parameters at t using the data{rt−T0+1,…,rt}. For the fitted model, we compute 1-step to H-steps-ahead forecasts at the forecast originr^t(1),…,r^t(H),using the filtered standardized residuals, and also compute the forecast erroret(h)=rt+h−r^t(h),h∈{1,…,H}.Step 3. Lett=t+1. Ift≤T−H,go to Step 2. Otherwise, we use the bootstrap method to generate samples of standardized residuals and the last forecast is repeated with the same values of the parameters, those of the last step. Thus, a number of samples are obtained.Step 4. To assess the predictive accuracy of the forecasting model, we use the out-of-sample measures: Cumulative ErrorCE(h)=∑tet(h),Mean Forecast ErrorMFE(h)=1L∑tet(h),Mean Absolute DeviationMAD(h)=1L∑t|et(h)|,and Root Mean Squared ErrorRMSE(h)=1L∑t(et(h))2,whereh∈{1,…,H}and L is the number of periods being forecasted, see Greene (2012). Each performance indicator measures different characteristics of the forecast error: CE measures the total error, MFE measures the average error or bias, MAD measures the absolute size of errors and RMSE is essentially the sample standard deviation of errors. The smaller the MAD or RMSE values, the more accurate the forecasting model.Results and discussions. The values of model parameters were calculated for all 20 stocks, at all t from the out-of-sample period. The forecasts, the forecast errors and CE, MFE, MAD and RMSE for all t from the out-of-sample period with updated “running” values of forecast error were computed. To illustrate our findings, we use AIG (chosen randomly from our list from Table A1 from SM) for which we present the evolution of all four accuracy measures for 1-step to 5-step-ahead forecast in Fig. 1(considering the origin of time at the beginning of the out-of-sample period). Tracking MFE for 1-step to 5-step-ahead forecast shows that there is a small bias of the forecast at the end of the out-of-sample period. We also notice the typical evolution in time of the bias: it decreases with the increase of time in the out-of-sample period. In Fig. 1 we see also that the bias is small: the largest value is smaller than 0.006 (this value corresponds to the 3-step-ahead MFE).From Fig. 1 we see that the value of MAD is around 0.06 for all steps ahead considered. The value of this performance measure should be considered relative to the values of data, which is 4–5 times higher than MAD. The RMSE is larger than MAD because it is more sensitive to larger values, as it can be seen in Fig. 1; RMSE values are in the interval [0.08; 0.10]. These conclusions are drawn from inspection of only one path. In order to have a better description of the forecast performances, we simulated 1000 alternative paths of evolution of AIG returns. Table 1presents the statistical descriptors of this sample population of 1000 values for the 1-step-ahead forecast. We see that the average values of the two important performance measures, MFE and RMSE are smaller than the values estimated on the path described above: they are actually 0.0049, respectively 0.0488. So, under the usual assumption that the forecast errors follow a normal distribution, for the 1 step ahead forecast, we find, instead of a mean of zero, a MFE mean value of 0.0049 and RMSE mean value of 0.0488. These values are a good starting point for the analysis of the efficient frontiers and in accordance with the values reported in the literature, see for example the values of accuracy measures reported for daily returns in Hansen and Lunde (2005).Implementation. We work with a holding period of four weeks. Every four weeks of the out-of-sample period, a 4-weeks-ahead forecast is calculated, and 10000 alternative paths of future evolution are generated using Monte Carlo simulation. TheNS=10000scenarios were used to compute the empirical cdfs of portfolio returns and to determine the MV, MC and MD efficient frontiers. The models were implemented in MATLAB. We have used the existing Object Oriented Classes for MV and MC models. The MD model was implemented in a new class, inherited from CVaR class. Specific routines have been added and old ones were modified so that compatibility with the rest of the method to be preserved.Constructing the MV efficient frontierrelies on estimating the covariance matrix of stock returns. It is well known that using the standard statistical method consisting of gathering a history of past stock returns followed by computation of their sample covariance matrix leads to instability and unrealistic parameters (extreme values), see Jagannathan and Ma (2003); Jobson and Korkie (1980); Ledoit and Wolf (2004); Michaud (1989) just to name a few. Jagannathan and Ma (2003) show that, by imposing a short sale constraint on the MV portfolio, a form of shrinkage of the elements of the covariance matrix is implicitly applied by the MV optimizers which is also beneficial for improving weights stability, see also DeMiguel, Garlappi, and R. (2009). In this paper, in order to improve the robustness of the MV optimization, we have applied the shrinkage method of Ledoit and Wolf (2004): thus, the estimated coefficients in the sample covariance matrix that are extremely high (and usually contain a high positive error) are brought more closer to central values.Utility functions used in the computational study. Two types of preferences represented by two classes of utility functions with loss aversion are studied.The first class is defined by (2), see Cremers et al. (2005). We work with nine such utility functions exhibiting different levels of loss aversion according to parameters values:(22)Ui,j(r)={ln(1+r),forr≥θj,λi(r−θj)+ln(1+θj),forr<θj,where λi∈ {2; 5; 10},θj∈{−0.05;−0.01;0.05}and i, j ∈ {1, 2, 3}.The second class suggested by the class of S-shaped value functions from Prospect Theory is defined in De Giorgi and Hens (2006). We consider six functions whose parameters A, B > 0, θ1, θ2, and 0 < γ1, γ2, γ3 ≤ 1 control the degree of loss aversion and the curvature of the function for outcomes above/below the return threshold θ:(23)Vlk(r)={−A(e−γk(r−θl)−1),forr≥θl,+B(eγk(r−θl)−1),forr<θl,l∈{1,2},k∈{1,2,3},We useA=6.52,B=14.70,θ1=−0.05,θ2=−0.01,γ1=0.2,γ2=0.5,γ3=0.9.The MV, MC and MD efficient frontiers are determined as follows.(1) The range of expected returns is determined.•The expected return of the global minimum risk portfolio is calculated and, depending on the model, it is denoted byE(R)minMV,E(R)minMC,orE(R)minMD. For example, ifxminMVis the optimal solution of the minimization problemmin{σ2(R(x,r))|x∈Rn,x′1=1,lk≤xk≤uk,1≤k≤20},where the lower and the upper bounds lkand ukare previously fixed, thenE(R)minMV=E(R(xminMV)).The maximum value E(R)max  is obtained by solvingmax{E(R(x,r))|x∈Rn,x′1=1,lk≤xk≤uk,1≤k≤20}.(2) The range of expected returns is divided in sub-intervals of equal length:E(R)min=μ1<μ2<…<μ20=E(R)max.We note that the divisions(μ1MV,…,μ20MV),(μ1MC,…,μ20MC)and(μ1MD,…,μ20MD)are different becauseE(R)minMV,E(R)minMC,andE(R)minMDare different.(3) For each model, 20 optimization problems are solved:(24)minx∈Rnρ(R(x,r))(25)x′1=1(26)lk≤xk≤uk,k∈{1,…,20}(27)E(R(x,r))≥μi,wherei∈{1,…,20}.The risk measure ρ(R(x, r)) in (24) depends on the model: it is either the variance σ2(R(x, r)), or CVaRα(L(x, r)), or DCVaRα(L(x, r)), whereL(x,r)=−R(x,r),andα=0.95. Depending on the risk measure used, the model (24)-(27) will be referred to as(PiMV),(PiMC),respectively(PiMD)and the corresponding optimal solution byxiMV,xiMC,respectivelyxiMD.Box constraints. In our study, we consider several types of box constraints (26). They are frequently imposed by practitioners for different reasons such as to rule out the possibility of short sales and/or to increase the diversification. Firstly, we solve the three models by imposing the usual portfolio weight constraints xk∈ [0; 1],k∈{1,…,20}.Next, we keep the no-short selling constraints, but impose increasingly tighter upper bounds:xk∈[0;0.50],[0; 0.40], [0; 0.30], respectively [0; 0.25].We have also tested the MD model when allowing short selling for one asset (AIG, from the list given in Table A1 from SM)x5∈[−0.25;1.25],and for the rest of the assetsxk∈[0;1],k ≠ 5. Two sets of data were tested: empirical data and simulated data following a multivariate normal distribution. The second set of data was used to test the extent to which the MD efficient portfolios are similar to MC and MV efficient portfolios. This is a work in progress but, up to now the results are promising, the solutions are stable and according to the theoretical expectations. When working with empirical data, solutions are different and in order to assess the similarity between the efficient frontiers, the method of Portfolio Indices defined in Phillips (1993) must be extended to negative weights.The range of expected returns [E(R)min ; E(R)max ] depends on the box constraints chosen. In Table 2we illustrate the E(R)min  values for all three models, the box constraint xk∈ [0; 1],∀k∈{1,…,20},and DCVaR calculated with the utility function defined in (22) withλ1=2and three θ values. We firstly see that, as expected, we haveE(R)minMC>E(R)minMV,as (Alexander & Baptista, 2004) proved for the case of normally distributed asset returns, Corollary 1 (ii). Since DCVaR is CVaR of a modified return distribution, we also findE(R)minMD>E(R)minMV,regardless the value of θ. If investor’s critical return level is−0.01or higher, we haveE(R)minMD>E(R)minMC>E(R)minMV. We notice that an increase in θ leads to an increase inE(R)minMD,because the loss averse investor (whose critical return level becomes higher) will aim higher returns. In Table 3we give E(R)max  values for all box constraints; we note that by imposing an increasingly tighter constraint, the feasible region is getting smaller and consequently E(R)max  decreases.A typical example of efficient frontiers of all three models is presented in Tables A3, A4 and A5 in SM. In these tables, the columns represent the compositions of efficient portfolios and the rows represent the assets. We remark that MD efficient portfolios exhibit a higher diversification compared to the other two models. We mention that DCVaR0.95 is calculated with the utility U11 withλ1=2,θ1=−0.01andxk∈[0;1]for allk∈{1,…,20}.In order to understand the behavior of the similarity indices with respect to λ, θ and the box constraint, we need to follow the way CVaR and DCVaR are related. Let us consider that the optimization solver is at iteration k, the portfolio isxk. Using theNS=10000scenarios, the portfolio loss/gains samples (a total of NSsamples) are calculated. We consider the losses are positive and sorted ascending. For fixing the ideas, we consider that the investor is characterized by the utility function (22), with the corresponding disutility(28)D(l)={−ln(1−l),forl≤−θ,−λ(−θ−l)−ln(1−(−θ)),forl>−θ,wherel=−r. We emphasize that the critical loss value−θremains constant during the iterations of the solver and we keep in mind that the portfolio loss samples change every iteration. The VaR is the (α · NS)th sample - in our caseα=0.95andNS=10000. To calculate DCVaR, the disutility of loss is calculated for every loss sample at the current iteration k, a total of NSdisutility samples. Since D is a monotone function, the disutility sample values are also in ascending order. The DCVaR value at the kth iteration is calculated as the average of the disutility samples larger than DVaR (see Proposition 1) originating from the loss samples larger than VaR. Let us assume that at the current iteration k, VaR is greater than−θ.In this case DCVaR is calculated using the linear part of the disutility function D because all losses are larger than VaR which is larger than−θ. At the next iteration, the algorithm will pick a portfolioxk+1which makes VaR smaller than−θ.In this case, there are a number of samples that are smaller than−θbut larger than VaR for which the corresponding disutility values are calculated with the logarithmic part of D. This leads to lower values for the disutility samples than those calculated at the previous iteration. So, the DCVaR at the(k+1)th iteration has a lower value than the DCVaR calculated at the kth iteration. The solver selects portfolios that increase the contribution of these losses in order to find the smallest positive value for DCVaR, compatible with the scenarios. From here, it follows that increasing the critical loss threshold−θ(i.e. decreasing critical return threshold θ) at a fixed λ will lead to a decrease in DCVaR, verified experimentally in Table 5. Analogously, the same table shows that increasing λ at a fixed θ leads to an increased DCVaR.In our analysis we consider the pairs formed with the MD efficient frontier and MV or MC: (MD/MV) and (MD/MC) . To establish whether solving two models produces similar portfolios, we have to answer to two questions: (i) to what extent the optimal portfolios corresponding to the two models to be compared have the same assets in their compositions? and (ii) to what extent the common assets have similar weights?The analysis relies on the interpretation of three Portfolio Indices defined in Phillips (1993). Firstly, we determine the Average Number of assets (AN)for each efficient frontier, AN(MV), AN(MC), AN(MD). Next, we determine the Average Number of Common Assets (ANCA)in the respective pair as follows: for each pair of efficient portfolios we determine the number of assets with nonzero weights in both portfolios, and then take the average over all pairs considered.For any pair of efficient frontiers, the Portfolio Indices are the following.•The Portfolio Overlap Index (POI) represents the average percentage of common assets and it is defined as the ratio of the number of assets that overlap between the two models to the average number of assets in the union between the two models.The Portfolio Weight Index (PWI) is calculated as follows. For each pair of efficient portfolios we compare the weights of overlapping assets and take the minimum. The sum of all these minimum values represents the total minimum weight of this pair of efficient portfolios. The average value over all pairs of portfolios is PWI.The Portfolio Similarity Index (PSI) is calculated as the product of the respective POI and PWI. This index gives the proportion (percentage) of common assets having similar weights in the efficient frontiers.A graphical and intuitive representation of POI, PWI and PSI for the pair MD/MV of efficient frontiers for DCVaR calculated with the utility U11 withλ1=2,θ1=−0.01andxk∈[0;1]for all k is given in Fig. 2.We quantify the similarity between two efficient frontiers by the values of the Portfolio Indices POI, PWI, and PSI. and show that the similarity between two models depends on utility function parameters, and on the particular system of box constraints (26) chosen when constructing the efficient frontier. To characterize numerically the difference between the MD efficient frontier and MV or MC, one can construct the images of these latter efficient frontiers into MD space, see for example (Gaivoronski & Pflug, 2005). The comparisons involve the coordinates of two points belonging to two different efficient frontiers, one from MD and the other from the image of MV (or MC); it is expected that each comparison to be made at the same level of expected return (or risk). We mention that the model in whose space were built the images of the other two models is clearly favored. Therefore, we compare directly the compositions of the portfolios, not their mean-risk coordinates. We keep the differences between the levels of expected return of portfolios compared in a range as small as possible as the following procedure shows. For example, for the MD/MV pair, the efficient portfolioxiMDwill be paired and subsequently it will be compared with the portfolioxk(i)MVwhich is the closest from the viewpoint of the expected return, i.e.|E(xiMD)−E(xk(i)MV)|=min1≤k≤20|E(xiMD)−E(xkMV)|. To ensure an adequate precision, we have implemented the following rule: if|E(xiMD)−E(xk(i)MV)|is larger than a previously calculated thresholdδi=1100|E(xiMD)|,the portfolioxiMDis neglected. Depending on the number of portfolio neglected, we might recalculate the efficient frontiers with an increased number of points for ensuring a sufficiently large number of pairs of portfolios for comparisons.The class of utility functions that we use first in the calculation of DCVaR is (22). All three models were solved for the types of box constraints (26) previously mentioned and for all nine utility functions Ui, j,  i, j ∈ {1, 2, 3}. To illustrate our findings, Table 4reports the POI, PWI and PSI for the pairs of efficient frontiers: MD/MV in the group of columns formed by the 3rd, 4th and 5th columns, and MD/MC in the last three columns of the table.The results in Table 4 correspond to DCVaRs calculated with U1, jwithλ1=2and all θ values. The confidence level for CVaR and DCVaR isα=0.95. Each row of Table 4 reports the POI, PWI and PSIvalues for both pairs of efficient frontiers (MD/MV) and (MD/MC) for a particular box constraint shown in the first column and a particular θ value written in the second column. For example, for DCVaR calculated withλ1=2,θ3=+0.05andxk∈[0;0.40]for all k,POI(MD/MV)=ANCA(MD/MV)AN(MD)+AN(MV)−ANCA(MD/MV)=46.75percent,PWI(MD/MV)=65.32percent,andPSI(MD/MV)=POI(MD/MV)·PWI(MD/MV)≃30.54percent.Comments onPSIvalues. Firstly, in Table 4 we notice that,. for all box constraints and all θ values, we have PSI(MD/MC) > PSI(MD/MV). In fact, we can say that in all cases PSI(MD/MC) is roughly two times larger than PSI(MD/MV), or at least 1.5 times. This is because both POI and PWI values are with roughly 50 percent higher for MD/MC than for MD/MV, denoting more assets in common and common assets weights having closer values for MD/MC. Therefore, if we consider working with any of the alternatives MV or MC instead of MD, MC is a much better approximation of MD than MV, as expected.Comments onPOIvalues. The previous considerations in 4.2.2.1 help us to better understand the variation of POI values with the variation of θ and λ. When θ increases at a fixed λ value, the “disutility gains” (disutility samples smaller than−θ) are reduced and DCVaR increases. But the solver acts in the sense of decreasing DCVaR by increasing the weights of assets contributing with disutility gains until they reach the upper limit of the box constraint. Once the upper limit has been reached, a non-common asset is selected to enter in the portfolio composition and, possibly, a common asset might be dropped. Consequently, the POI either remains the same or decreases as can be seen in Table 4.Also the dependence of POI on the upper bound of the box constraint and on the θ value (at a fixed λ value) are obvious in Table 4. Forxk∈[0;1],k∈{1,…,20},the POI values are the smallest. When imposing lower upper bounds, the values of POI changes when the values of θ are changing. For example, for the box constraint [0; 0.40], the passage fromθ2=−0.01toθ3=+0.05(which means a switch to a “worse critical threshold” because even a range of positive returns are now subjectively perceived as losses) is clearly delimitated: we see a drop of 12.42 percent: from the POI(MD/MV) value of 53.38 percent (to 46.74 percent). Analogously, POI(MD/MC) falls 9.31 percent from its value: from 70.57 percent it decreases to 64.00 percent. When we lower the upper bound of the box constraints to 0.30 and 0.25, the drop in POI is much smaller, of only 2.5 percent, because POI has a larger value than for higher values of upper bounds and the percentage decrease of dropping one common asset from the set of overlapping assets in POI has a smaller impact.Comments onPWIvalues. For any fixed θ, imposing tighter constraints increases PWI. The main reason is that imposing lower upper bounds increases diversification in all models. Consequently, two frontiers will have more common assets, therefore a larger number of minimum weights to be added up for obtaining an increased PWI, as seen in Table 4. Moreover, for any given box constraint, PWI decreases with the increase in θ. Indeed, as seen before, an increase in θ leads to a decrease in the number of common assets which leads to a decrease in the minimum weights of the common assets. We notice that the average percentage of overlapping assets POI between the two models MD and MC has a value of 65–70 percent. The remaining 30–35 percent is due to the higher diversification of the MD model. But, as shown in the last but one column of the Table 4, the PWIvalues are around 92–94 percent which means that the 65–70 percent common assets of MD and MC models have highly similar weights.Dependence ofDCVaRvalues on disutility function parameters. We consider the utility functions V2k, k ∈ {1, 2, 3}, defined in (23), withθ2=−0.01,A=6.52,andB=14.7and study the variation of Portfolio Indices when parameter γ varies. Table 6reports the POI, PWI and PSI for the pairs of efficient frontiers MD/MV in the group of columns formed by the 2nd, 3rd and 4th columns, and MD/MC in the last three columns. We note that the POI values are smaller than for the utility class defined in (22), PWI are in the same range and consequently PSI are smaller.Comparisons of twoMDefficient frontiers with respect to two different utility functions. Our study is for the two classes of utility functions defined in (22) and (23). We purposely chose the utility class (23) that is resembling with (22) for the parameter values considered: we wanted to measure small differences and to relate them with the changes in DCVaRs. Both classes of utility functions operate in the same manner: the gains are shrunk and the losses are amplified. The monotonicity preserves the order of the loss samples in the disutility space.We use a reference efficient frontier that corresponds to (22) with parametersλ=2,θ=−0.05,and box constraints [0; 1]. The first three columns of the Table 7gives the characteristics of the MD model to be compared to the reference model. The first seven rows presents comparison within the same class of utility functions (22), whilst the following eight rows refer to (23). We have used the following algorithm: the reference model has the smallest values for the parameters (the smallest in our computational study) and the model to be compared with has the highest values. The first three rows in Table 7 have one parameter changed compared to the reference, the following three rows have two parameters changed, and the seventh row has all three parameters changed. This way we have a representation of the changes in the similarity indices in relation with changes in parameter values. The same notations and rules apply for the following rows, but with (23) utility functions.Regarding the comparisons between classes of utility functions presented in the first seven rows of Table 7: for the most restrictive box constraint [0; 0.25] the POI value is limited at 96 percent for all λ and θ considered. This shows a high and similar diversification, with a corresponding PSI values of 88–90 percent. Thus, we can estimate that changing the box constraint from [0; 1] in the reference model to [0; 0.25] induces a change in PSI of about 10 percent and the the influence of the other parameters is of only 1–2 percent. For the box constraint [0; 1] the variation of λ from 2 to 10 induces a substantial drop in PSI, of almost 13 percent. Regarding the variation of the PSI with θ, we can estimate that it is small, less than 5 percent.The comparisons of (23) with the reference show that for a fixed γ and box constraint [0; 1], PSI shows small changes ≃ 1 percent (from 85.40 percent to 86.70 percent, respectively from 91.08 percent to 91.13 percent). The variation of PSI with γ is about 5 percent, for example for θ and [0; 1], from 5.40 percent to 91.08 percent. For the box constraint [0; 0.25], the PSI variation with respect to γ is of 1–2 percent.Global analysis of differences between efficient frontiers. In order to get more insight into the Portfolio Indices,we give examples of the compositions of MV, MC and MD efficient portfolios in Tables A3, A4, and A5 from SM.In order to have a better understanding of the extent to which the compositions of MD efficient portfolios differ from the others, we calculate the differencesδijMD/MV=|xijMD−xijMV|,and analogouslyδijMD/MC=|xijMD−xijMC|,wherexijMDis the jth component ofxiMD,i∈{1,…,20},andj∈{1,…,20}. For the ith pair of portfolios(xiMD;xiMC),i∈{1,…,20},we defineΔiMD/MC=∥xiMD−xiMC∥1=∑j=1n|xijMD−xijMC|that can be can be interpreted as the total error of using the MC model instead of MD. If we store only this numberΔiMD/MCas a characteristic of a pair of efficient portfolios(xiMD,xiMC),we describe the difference between the two efficient frontiers MD and MC by a vector of 20 components (the number of portfolios). We describe this vector by its mean and standard deviation and represent the results of repeating the simulations 25 times in Table 8- the results correspond to the utility function (22) withλ=2,θ=−0.05,and box constraints [0; 1]. In the second column, this table shows an average difference between two efficient portfolios of the pair MD/MC, respectively MD/MV and the third column gives the standard deviation. The data in Table 8 confirm the conclusions aleady drawn: the absolute errors are higher for MD/MV than for MD/MC, but we notice that the total error for MD/MC is significant, it is 9–10 percent. We remind that here the units represent percentages from the total wealth.

@&#CONCLUSIONS@&#
This paper proposed the risk measure called DCVaR defined using the modified loss distribution according to the decision maker’s risk and loss aversion preferences and established its properties. We developed a bi-objective portfolio optimization model in the Mean-Risk framework using the DCVaR risk measure and gave equivalent representations of the MD efficient frontier We investigated the practical performances of the proposed model using real data from New York Stock Exchange by comparing it with the classical MV and MC models. Firstly, we established how different are the efficient portfolios produced by the three models by quantifying the differences/similarities between the efficient frontiers for the class of disutility functions defined with various degrees of loss aversion. Our analysis based on three types of similarity indices showed significant differences between MD and any of MV or MC efficient frontiers, the degree of similarity being relatively low. Extensive experiments showed that the MD efficient portfolios exhibit lower risk levels at the same return levels compared to the other two Mean-Risk models. Working with the disutility of the loss and thus with a distribution modified by the loss-averse investor’s perception makes DCVaR an interesting risk measure because apart suitability, also better performances are obtained.