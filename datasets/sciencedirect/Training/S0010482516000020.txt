@&#MAIN-TITLE@&#
Automatic image classification for the urinoculture screening

@&#HIGHLIGHTS@&#
Realization of the AID software for automatic detection of urinary tract infections.AID is able to acquire and store the image of the Petri plate.AID accurately classifies the infection type and evaluates the bacterial load.AID allows result storing, repeatability and standardization.AID speeds up the analysis procedure and reduces its costs.

@&#KEYPHRASES@&#
Color image processing,Clustering techniques,Artificial neural networks,Support vector machines,Urinoculture screening,

@&#ABSTRACT@&#
Urinary tract infections (UTIs) are considered to be the most common bacterial infection and, actually, it is estimated that about 150 million UTIs occur world wide yearly, giving rise to roughly $6 billion in healthcare expenditures and resulting in 100,000 hospitalizations. Nevertheless, it is difficult to carefully assess the incidence of UTIs, since an accurate diagnosis depends both on the presence of symptoms and on a positive urinoculture, whereas in most outpatient settings this diagnosis is made without an ad hoc analysis protocol. On the other hand, in the traditional urinoculture test, a sample of midstream urine is put onto a Petri dish, where a growth medium favors the proliferation of germ colonies. Then, the infection severity is evaluated by a visual inspection of a human expert, an error prone and lengthy process. In this paper, we propose a fully automated system for the urinoculture screening that can provide quick and easily traceable results for UTIs. Based on advanced image processing and machine learning tools, the infection type recognition, together with the estimation of the bacterial load, can be automatically carried out, yielding accurate diagnoses. The proposed AID (Automatic Infection Detector) system provides support during the whole analysis process: first, digital color images of Petri dishes are automatically captured, then specific preprocessing and spatial clustering algorithms are applied to isolate the colonies from the culture ground and, finally, an accurate classification of the infections and their severity evaluation are performed. The AID system speeds up the analysis, contributes to the standardization of the process, allows result repeatability, and reduces the costs. Moreover, the continuous transition between sterile and external environments (typical of the standard analysis procedure) is completely avoided.

@&#INTRODUCTION@&#
Urinary tract infections (UTIs) are considered to be the most diffuse bacterial diseases, found in common medical practice, and can cause serious health problems. They are mainly due to the presence of Gram-negative microorganisms, with a high prevalence of Escherichia coli (E. coli, 70%), usually found in the digestive system, even if complicated infections caused by Gram-positive or multidrug-resistant germs can also occur, especially in hospitalized or elderly patients, on which the common antimicrobial agents are inevitably ineffective, leading to therapeutic failures.The occurrence of UTIs varies in dependence of age and gender, as well as based on the socioeconomic background. Moreover, specific subpopulations at increased risk of UTIs include infants, pregnant women, the elderly, persons with urological abnormalities, patients with spinal cord injuries and/or catheters, with diabetes, multiple sclerosis, and AIDS. The urinoculture is a screening test22The term screening is used here in its common meaning of a routine test performed on a large population, to identify those who are likely to develop a specified disease. Instead, in in vitro diagnostics it stands for preventive analyses aimed at establishing if a sample is positive or not.in all these cases. In the standard protocol, the urine sample is seeded on a Petri dish equipped with a cell culture substrate, used to artificially recreate the environment required for the bacterial growth, and incubated at 37°C overnight. Each dish must then be examined by a human expert, adding some more time to the medical report emission. This common situation significantly departs from the requirement to have results in quick time, to set a targeted therapy, avoiding the use of broad-spectrum antibiotics and improving the patient management.33Rapid reporting is crucial especially when pediatric patients are involved since in this case, the infection symptoms are not always specific, while it is urgent to decide if an antibiotic therapy is necessary or not and when to start it.Moreover, the traditional analysis procedure suffers from possible errors arising in the visual, qualitative, inspection of the dishes — due to the skills and the expertise of each operator, whereas difficulties also arise in the traceability of samples and results [1].In recent years, significant improvements in biology and medicine applications and decision support systems [2] have been obtained by using hybrid methods, based on a combination of advanced image processing techniques [3,4], artificial intelligence tools [5–7], machine learning [8], fuzzy logic [9], genetic algorithms [10], and Bayesian modeling [11]. In particular, the development of automated tools for results assessment (screening systems) has attracted increasing research interest during the last decade, due to their higher repeatability, accuracy, reduced staff time (that are the main limiting factors of manual screening), and lower costs [12]. Automated urinalysis devices improve the capacity of the laboratory to screen more samples, producing results in less time than by manual screening. Moreover, the redeployment and lower grading of staff with the increased turnover and speed of urine screening, gave economic advantages of automated screening over manual screening [13].Even if some interesting research has been carried out in recent years for the urinoculture screening, obtaining an overview of the state-of-the-art in image processing/AI solutions to the automatic analysis of Petri dishes is difficult, since results are published in various domains — from food and beverage safety to environmental control and specific clinical analyses [14–19], based on different data sets, and they are also often related to subtle variations of the core problem (e.g., in [20], where the colony classification problem is addressed with promising results, but with respect to a very small number of images and based only on the determination of isolated colonies).In this paper, we propose the AID (Automatic Infection Detector) software, an automated tool that provides a decision support system for the urinoculture analysis. Dish images are acquired from a color camera and, thereafter, through a suitable preprocessing phase, involving spatial clustering, colonies are isolated from the culture substrate, even in the presence of ground disuniformities. Detected bacterial infections are then classified based on both artificial neural networks (ANNs) and support vector machines (SVMs). Finally, besides the infection identification and classification, the AID system also performs the bacterial count, giving an estimate of the number of microorganisms per milliliter of urine.AID actually allows a substantial speedup of the whole analysis procedure, also avoiding the continuous transition between sterile and external environments which is typical in the standard protocol. The final outcomes are directly stored, along with the related analysis records (the image, the infection type and the colony count). Experimental data have been provided by DIESSE Ricerche Srl, Siena, a world class manufacturer of innovative biomedical devices and reagents for infectious disease testing. Preliminary experiments show very promising results, in terms of both classification accuracy of the infections and estimation of the bacterial count.The paper is organized as follows. Section 2 introduces the problem and describes the preprocessing procedure, from the image acquisition phase to the background removal. Section 3 presents the classification methods and shows experimental results, whereas Section 4 defines the procedure used to estimate the infection severity and Section 5 introduces a specific approach to recognize the Candida infection. Finally, conclusions are drawn in Section 6.The system model for the AID application considered in this paper is shown in Fig. 1. All the processing steps, from image acquisition to classification and bacterial load count, will be detailed throughout the following sections.First of all, in order to correctly recognize the infection type and to precisely estimate the bacterial load, it is fundamental to acquire a good quality image of the Petri dish. To avoid imperfections due to manual plate handling, images are captured by an automatic camera setup (Fig. 2). After the acquisition, a suitable preprocessing step is applied to locate the region of interest (the Petri dish), and to grant that it is in an appropriate position inside the field of view. At this point the image is saved along with auxiliary information.The automatic acquisition is performed as follows: a simple and fast algorithm, based on change detection [21] and morphological filtering [22], is applied and the image is acquired only when the dish is correctly positioned, the scene is well illuminated, and no movements are observed. Before saving the image, the Petri dish is isolated from the rest of the scene, using a Random Hough circle transform [23], to detect the circular Region of Interest (RoI) (see Fig. 3).The acquisition setup has been used in a real application scenario at DIESSE Ricerche premises, to collect a dataset of 253 images, subsequently divided into a training, a validation, and a test set, containing 154, 64, and 35 images, respectively (see Table 1). As a requirement, eight different classes of infection were detected, namely: E. coli, KES (Klebsiella, Enterobacter, Serratia), Enterococcus faecalis, Streptococcus agalactiae, Pseudomonas, Proteus, Staphylococcus aureus, and Candida.Since a chromogenic medium (UriSelect 4) is used as ground seed, the color of the pixels is the most important feature for classifying different colonies. Therefore, the background color distribution has been analyzed in four different color spaces (i.e., RGB, HSV, CIE-Lab, and YCrCb). A supervised training process has been adopted, during which a human expert selected about 40 different regions belonging to the background and to the foreground. The chromatic components of the pixels belonging to such regions are accumulated to represent the typical background and foreground chromatic values. Then, the Dunns Index has been used to give a quantitative ranking (based on the Centroid Linkage distance and the Centroid Diameter dispersion [24]):(1)DI(X)=min1≤i≤j≤kd(Ci,Cj)max1≤s≤k{Δ(Cs)}d(Ci,Cj)≜1|Ci|+|Cj|(∑c→∈Cid(c→,μj)+∑c→∈Cjd(c→,μi))μi≜1|Ci|∑c→∈Cic→Δ(Ci)≜(∑c→∈Cid(c→,μi)|Ci|)In (1),c→is the chromatic vector (a,b) of each pixel, k is the number of clusters,d(Ci,Cj)is a dissimilarity function between two clusters Ciand Cj,Δ(Ci)is the distance of all points from the mean, and μiis the mean of cluster i.Experiments have shown that CIE-Lab has a higher ranking and also gives an increased separation between the color of the eight infections and the background. Therefore, CIE-Lab [25] has been selected for the chromatic description of images. It is known that the use of the (a,b) chromaticity coordinates makes the histogram more stable with respect to differences in illumination and local variations caused by shadows [26]. Moreover, if only the (a,b) chromaticity components are used, the background colors concentrate in a very compact and stable region (Fig. 4).The classification of infections is performed in a hierarchic way. As a preliminary step, the colonies are separated from the background by a background-removal process based on chromatic information about the specific chromogenic medium used in the culture (Uriselect 4, in this study). To this end, a suitable chromatic background model has been defined.To obtain a chromatic description of the background, a supervised training technique is adopted, during which a human expert selects about 40 different regions belonging to the background of various images coming from the training set. The chromatic components (a,b) of the pixels belonging to such regions are accumulated to represent the typical background chromatic values. The samples have been preliminarily filtered by a fast vector median filter [27] to reduce the effect of noisy samples. The color histogram distribution is estimated by a Parzen-window with a Gaussian shape [28] according to the following equation:(2)pB(c→)=1N∑i=1N1hN2ϕ(c→−c→ihN)wherepB(c→)represents the estimated probability density function of the background, N is the number of observations,ϕ()is a Gaussian kernel function, hNis the selected scale factor, andc→iis the chromatic vector of the ith background sample.A similar approach has been used to model the foreground (infected) regions. Again a supervisor selects about 40 regions belonging to each different infection class coming from the images of the training set, and a Parzen-window approach is used to estimate the probability of the (a,b) chromatic components for each class. Therefore eight estimates of the conditional probability density function relative to the eight possible infections are obtained (pk(c→);k=1,2,…,Nc, where Nc=8). These functions are then compared with the background probability density function to define the chromatic regions that can give rise to classification uncertainty. The uncertainty region is calculated as the union of the intersections of some binary masks obtained by imposing a threshold on the probability level of the background and of the infected regions.Given the threshold α (e.g. 90%) and the estimated pdf׳s,pB(c→)andpk(c→):(3)Bα={c→:∫BαpB(c→)dc→=α}Ik,α={c→:∫Ik,αpk(c→)dc→=α};k=1,2,…,NcCk=Bα⋂Ik,α;k=1,2,…,Ncthe uncertainty region is defined by the following equation:(4)UM=⋃k=1NcCkAt this point, the mask relative to each infected region (Ckfor the kth infected region, based on Eq. (3)) is intersected with the background mask to give a superposition binary mask. Finally, the union UMof the whole set of superposition masks is computed. It is easy to see that the final mask comprises all the chromatic coordinates that belong with a certain degree of probability both to the background and to one of the infected regions. The chromatic coordinates of the points belonging to the final mask are marked as uncertain and used during the subsequent classification stage.Even if the background chromatic model is quite stable and accurate, some minor chromatic variations are still present. To accommodate for these variations, a Mean-Shift segmentation [29] algorithm is used to associate each image pixel to the corresponding modal density value in the (a,b) space (actually, as usual, the chromatic coordinates are mixed with the positional coordinates of each pixel, so that the Mean-Shift algorithm runs in a four-dimensional space). The obtained modal value, is compared with the background chromatic model (by using the corresponding likelihood), to establish if the pixel belongs to the background region or not. In this way, a first approximated background segment is obtained. Unfortunately, such an approximation is rarely satisfying since the background slightly changes its colors according to the type of bacterium grown on the dish.To solve this problem, we use the previously defined uncertainty chromatic mask UM. In particular, when some pixels belong to the mask (i.e., they cannot be assigned with reasonable certainty on the basis of chromatic coordinates), we assign them to a fictitious class of uncertain points. In the image space, such points form a set of uncertainty regions and specific post-processing steps are applied to each of them.Uncertainty regions are analyzed by taking into account also local spatial properties like discontinuities (edges), that are typically present between the colonies and the background. In particular, we have considered the following five classes:(1)colonies (E. coli, KES, E. faecalis, S. agalactiae);background without edges (blue in Fig. 6);background with edges (pink in Fig. 6);uncertainty regions without edges (red in Fig. 6);uncertainty regions with edges (green in Fig. 6).The classification procedure can be described as follows: at first, the background chromatic model is used to decide if a segment (obtained by Mean-Shift segmentation) belongs to a colony, to the background or to an uncertainty region. Thereafter, a Sobel [30] based edge enhancement is applied to distinguish between classes (3) and (5). Finally, uncertainty regions (4) and (5) are analyzed to assign them to the background or to the colonies.During the experiments, it has been noted that, if the HSV space [31] is used to describe the uncertainty regions, then if the region belongs to the background, the H (hue) channel shows a peak that is near to the one obtained by taking the same histogram but relative to the region of class (2). Instead, if the uncertainty region belongs to a colony, its H channel shows a peak that is far from the one shown by class (2) (Fig. 5).To take advantage of this observation, the uncertainty regions of class (4) and (5) are analyzed separately by applying the same procedure, summarized in the following.1.The Otsu method [32] is used to threshold the H values of uncertainty regions in classes (4) and (5) and to segment them.(a)Based on the computed threshold, the considered uncertainty region is divided into two sub-regions.The histograms of the two sub-regions are computed and compared, to establish if a significant separation exists (i.e. if the peaks of the two sub-regions are far enough in the histogram of the H channel). If the peaks are well separated, the two sub-regions are identified as (6) and (7) and processed separately. If the peaks are not separated, the two sub-regions are kept together.The peaks of the histogram (H channel) of the region of class (2) and of the analyzed regions ((6) and (7) separately or together, depending on the previous step) are compared.If the peaks of the background and of the current region ((6) and (7) separately or together) are distant enough, the current region cannot be assigned to the background and it is passed to the final classification step to assign it to the appropriate colony.Instead, if the peaks are almost coincident, the uncertainty region shows a hue value H similar to the background, and it is assigned to it.In other words, for both regions (4) and (5), we identify different sub-regions (if any) and, for each “homogeneous” zone, we establish its membership to the background or not.Further problems arise when considering Candida colonies, since their color is practically the same as that of the culture ground (Uriselect 4). To classify this kind of colonies, an ad hoc procedure has been devised, particularly focused on analyzing segments belonging to region (3).The performance of the background segmentation method has been evaluated on the test set, comprising 35 images. The results are reported in Table 2.The classification of bacteria grown on a Petri dish is a very difficult task and, actually, biologists are able to perform this operation using their a priori knowledge of the problem and thanks to the extraordinary ability of the human visual system.The culture ground used in our experiments is UriSelect 4, a chromogenic, milky, and opaque medium, used to isolate and enumerate microorganisms of the urinary tract. UriSelect 4 is specifically designed to identify infections by color. It incorporates two chromogenic substrates for the detection of β-galactosidase and β-glucosidase enzymes. Strains that produce β-glucosidase, such as enterococci and the KES group, form colonies that generate a turquoise/purplish blue coloration. Instead, Escherichia coli evidences red-pink colonies, because of the β-galactosidase production. Finally, Uriselect 4 also contains tryptophan, in order to detect members of the Proteae group (Proteus–Providencia–Morganella), that appear as brown-orange colonies, due to tryptophane désaminase. However, distinguishing different types of infections within these macro-classes is a very difficult task, at least based on color information only. To face this problem, a multi-stage procedure was settled, aimed at partitioning, at first, among infections which share similar chromatic features, producing a sort of pre-classification. After that, different classifiers, trained on both chromatic features and class-specific auxiliary information, are implemented to distinguish within each group. Finally, a special procedure is applied to recognize the Candida infection.Actually, the pre-classification phase reveals the (expected) existence of three main groups, that can be easily identified by their color: red for E. coli, blue for Enterococcus faecalis, KES and Streptococcus agalactiae, and yellow for Pseudomonas, Proteus and Staphylococcus aureus.44By the way, according to the manufacturer specification, Uriselect 4 can be used for the direct identification of E. coli (pink-red colony), Enterococcus (blue colony), and Proteus (yellow-brown colony), as well as for the presumptive identification of other species.Among the eight diverse types of UTIs, only E. coli is characterized by red colonies, so that it can be easily recognized as a result of this step. With respect to the other two classes, instead, the pre-tag phase allows only an infected/not-infected response, with further, specific, information needed to identify each particular kind of infection. For instance, in the blue class, the colony diameter is useful for discriminating between Enterococcus faecalis (small colonies, 0.5–1.5mm) and KES (2–3mm), whereas, in the yellow class, Proteus infections can be distinguished from the others by the presence of a halo surrounding the colonies.To collect the data for the pre-tag classifier, a Mean-Shift segmentation algorithm has been preliminarily executed, and then the(a,b)color components of the colony in the CIE-Lab space have been extracted. A multi-layer perceptron (MLP) network with two inputs, a single hidden layer with six neurons, and three output neurons, with sigmoid activations (see Fig. 7), was trained using BackPropagation [33]. For comparison, we also trained a multiclass SVM classifier with a Gaussian kernel55The Gaussian kernel computed with a support vector is an exponentially decaying function in the input feature space, the maximum value of which is attained at the support vector and which decays uniformly in all directions around the support vector, leading to hyper-spherical contours of the kernel function. An SVM classifier with a Gaussian kernel is simply a weighted linear combination of the kernel function computed between a data point and each of the support vectors.(see Fig. 8), withγ=0.1and C=7.75.66A standard SVM seeks to find a margin that separates all positive and negative examples. However, this can lead to poorly fit models if any examples are mislabeled or extremely unusual. To account for this, in [34] the idea of a “soft margin” SVM was proposed, that allows some examples to be “ignored” or placed on the wrong side of the margin; this often leads to a better overall fit. C is the parameter for the soft margin cost function, which controls the influence of each individual support vector; this process involves trading error penalty for stability. On the other hand, γ is inversely proportional to the variance of the Gaussian functionThe basic SVM model is just a binary linear classifier. To face the multiclass problem at hand, we implement three classifiers able to recognize one class out of three each, in a one-vs-all framework. The Gaussian kernel has been chosen because it reflects the nature of the input data, which from histogram inspection, appear to be clusterized and not linearly separated.The Weka software (http://www.cs.waikato.ac.nz/ml/weka/) was used to implement both MLPs and SVMs. All the architectural parameters for the two models (number of hidden layers and number of neurons per layer, learning rate, error threshold for the stopping criterion, etc., for MLPs, and γ and C, for SVMs) were chosen via a trial-and-error procedure77Trial-and-error is a primitive method of solving problems. It is characterized by repeated model training with different parameters, continued until success.; the validation set has been used to tune their values. Results for the pre-classification phase (accuracy and confusion matrices88A confusion matrix allows the visualization of the performance of a supervised learning classifier. Each column represents the instances in the predicted class, while each row represents the instances in the actual class. Its name stems from the fact that it clearly shows if the system is confusing two classes (i.e. commonly mislabeling one as another).) are reported in Tables 3 and 4.With respect to the classification of blue colonies (Enterococcus faecalis, KES, Streptococcus agalactiae) two main issues arised: mainly for E. faecalis, the background extraction module was sometimes unable to eliminate all the background segments, badly affecting the classification accuracy; moreover, unpredictable chromatic variations may be revealed when multiple infections are present and overlap on the same Petri dish.To address the first problem, the information coming both from the background extractor and from the pre-tag classifier are used as input to a GrabCut algorithm [35], to remove the remaining background segments (Fig. 9).Instead, the second problem was addressed by first recognizing isolated colonies and then by using this information to forecast the kind of UTIs possibly present in the overlapping regions. A relevant example is related to the contemporary presence of E. coli and E. faecalis, which produce overlapping regions very similar, in color, to a KES infection. This is a well-known situation and, therefore, such an a priori knowledge may be used during the classification stage. When isolated colonies of E. coli and E. faecalis are detected, if a KES region is also detected on the same dish, the latter is classified as a possible Coli/Faecalis overlapping region, which is also statistically more likely than having the simultaneous presence of E. coli, E. faecalis and KES.99Actually, Petri dishes on which many different infections are simultaneously present are considered to be contaminated, and they are of little interest to biologists.Based on experiments, such an assumption significantly improves the classification performances.Results — obtained using an MLP (with two inputs, two hidden layers with three and six sigmoid neurons, respectively, and three sigmoid outputs) and an SVM (with a Gaussian kernel,γ=0.12and C=1) — are described in Tables 5 and 6.A similar procedure was implemented for the yellow class (Pseudomonas, Proteus and Staphylococcus aureus) — using an MLP (with two inputs, three hidden and three output sigmoid neurons) and an SVM (with a Gaussian kernel,γ=0.12and C=0.88) — showing very promising results (see Tables 7 and 8). However, such results are very preliminary since they were achieved on a small image set; further experiments should be carried out to draw statistically significant conclusions.It is worth noting, in fact, that, for the yellow class, the significance of the obtained results, from the statistical point of view, is very low, due to the very small number of available examples. Technically speaking, since the three types of infections that produce yellow/brown colony are quite distinguishable from a visual inspection, it is likely that a greater number of examples will actually guarantee a performance boost. This constitutes just one of the future matters of research.Finally, in Table 9, we report the image wise classification results obtained on the test set. It is worth noting that about 70% of the urinary tract infections are due to E. coli bacteria, so that the AID high accuracy for this class represents a remarkable result. Again, we point out that the yellow class was not been taken into account, due to the scarcity of data (only four test samples) belonging to it.There is some inherent human error and a lot of time involved in manually counting the grown colonies on a Petri dish. Moreover, the accuracy of calculating the microbial density from the colony count does have some inherent limitations, due to the fact that the colony-forming units can be a single cell, a chain of cells or a whole clump of cells. Besides the infection identification and classification, the AID system performs also the bacterial count, giving an estimate of the number of microorganisms per milliliter of urine. Such estimation is expressed in CFU/ml (Colony-Forming Units per ml) by using a logarithmic evaluation scale, as shown in Fig. 10.The actual bacterial load is then obtained by multiplying the number of colonies counted on the dish by the inverse of the seeding dilution rate.The automatic procedure aimed at estimating the infection severity is realized by a multistep algorithm, based on a prior search of individual, not overlapping, colonies which are successively used to enucleate colonies belonging to slightly overlapping regions. After the ground seed identification phase, a binary image is constructed, where the background is represented by the substrate and the foreground by the colonies. Single colonies normally show a roughly circular shape and can be easily identified according to this feature. In particular, the smallest enclosing circle is evaluated for each connected component and, if the ratio between the circular area and the area of the component is less than a fixed threshold (chosen via a trial-and-error procedure), it is considered to be a colony.Obviously, this simple approach is not effective in significantly overlapping regions. In this case, the convexity of each colony contour is calculated, also evidencing all the sub-contours with a convex shape. Then, the best ellipse (in the least square sense), that fits each sub-contour, is selected, and used to build a score matrix, that takes into account both the axes rate and the ellipse points belonging (or not) to the contour. Finally, the score matrix is used to remove all the non-relevant ellipses (Fig. 11).Only single colonies discovered in this way, and located in slightly overlapping regions, are counted in order to estimate the infection severity. In particular, using the dimension of the discovered single colonies, combined with the area of the infected region, our system calculates the bacterial load, which is an estimate of the number of microorganisms per milliliter of urine (CFU/ml). The actual measurement value is calculated by multiplying the number of bacterial colonies counted on the dish by the inverse of the seeding dilution rate. Based on this procedure, the AID responses coincide with those of the biologists (which represent our ground truth) for 233 out of 253 images constituting the dataset, obtaining an accuracy of 92.1%.Candidiasis is a fungal infection caused by yeasts that belong to the genus Candida, with Candida albicans as the leading cause of fungal UTIs. The typical color produced by Candida colonies is nearly the same as that of the Uriselect 4 substrate, making it very difficult to identify and isolate this kind of infection from the background. Actually, a human expert can detect the presence of Candida by observing Petri dishes from different points of view, to capture the three-dimensional structure of the grown colonies, with their typical small dome extrusions. On the contrary, AID can only use a planar representation of the plate, since the camera catches just a frontal view of it. However, the presence of edges on the culture media — produced by reflection phenomena on the dome surfaces in a controlled lighting system — can actually suggest the presence of an undetected colony, even if noise can interfere by producing false edges.In order to reduce false positives, shape features, such as the circular appearance of the extrusion contours, may be employed to distinguish colonies from noise. Finally, single non-overlapping colonies were searched on the edge mask using the approach just described. Therefore, if a significant number of circular edges can be detected, we assume that they correspond to the actual presence of Candida and not to a noisy data acquisition (see Fig. 12).

@&#CONCLUSIONS@&#
Urinary tract infections can be caused by diverse microbes, including fungi, viruses, and bacteria. Bacteria are the most common cause of UTIs. Normally, bacteria that enter the urinary tract are rapidly removed by the body before they cause symptoms. However, sometimes bacteria overcome the body׳s natural defenses and, actually, 150 millions of infections occur annually worldwide. In this paper, the AID tool was described, which is able to detect and classify UTIs, automatically estimating the infection severity. The system shows a very good accuracy on typical microorganisms present in humans. Preliminary promising results have been reported, based on field-proven tests of AID carried out on real data by DIESSE biologists. It is a future matter of research the refinement of the classification procedure related to colonies with very similar colors, based on a larger dataset of images, and the improvement of the detection ability in the presence of Candida. AID will also be extended to treat diverse types of culture grounds (possibly transparent and/or based on enzymes that produce different chromatic reactions), and different sowing mode, including those (both linear and radial) produced via automatic seeding tools.None declared.