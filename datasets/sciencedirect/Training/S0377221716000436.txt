@&#MAIN-TITLE@&#
Nested general variable neighborhood search for the periodic maintenance problem

@&#HIGHLIGHTS@&#
It is proposed new variant of VNS heuristic called Nested General VNS (NGVNS).Proposed new mathematical programming formulation of periodic maintenance problem (PMP).New NGVNS heuristic solves exactly all 110 instances from the literature.Comparative study of 4 exact solution methods of PMP is conducted.

@&#KEYPHRASES@&#
Scheduling,Preventive maintenance,Mixed-integer linear programming,Variable neighborhood search,Nested general VNS,

@&#ABSTRACT@&#
In this paper we study the periodic maintenance problem: given a set of m machines and a horizon of T periods, find indefinitely repeating itself maintenance schedule such that at most one machine can be serviced at each period. In addition, all the machines must be serviced at least once for any cycle. In each period the machine i generates a servicing cost bior an operating cost which depends on the last period in which i was serviced. The operating cost of each machine i in a period equals aitimes the number of periods since the last servicing of that machine. The main objective is to find a cyclic maintenance schedule of a periodicity T that minimizes total cost. To solve this problem we propose a new Mixed Integer programming formulation and a new heuristic method based on general Variable neighborhood search called Nested general variable neighborhood search. The performance of this heuristic is shown through an extensive experimentation on a diverse set of problem instances.

@&#INTRODUCTION@&#
Companies usually have developed long term strategies to remain competitive, innovative and profitable. At an operational level, an efficient use of their resources is crucial to remain successful. As a consequence, the human organization and the manufacturing systems in these companies have to be adapted consequently to support managerial decisions. To achieve this goal, the production tools must be available almost all the time.Given that manufacturing systems constitute the vast majority of company’s investment and constitute their production tools, they must be in perfect conditions whenever needed. Unfortunately, these systems are subject to random failures and to deterioration and therefore have to undergo corrective maintenance (Benmansour, Allaoui, Artiba, Iassinovski, & Pellerin, 2011). Systems can also be stopped for preventive maintenance reasons to avoid (or minimize) the consequences of failures. This kind of maintenance is designed to preserve and restore equipment reliability by replacing worn components before they actually fail. Preventive maintenance activities take time that could otherwise be used for production, but delaying preventive maintenance for production may increase the probability of machine failures (Cassady & Kutanoglu, 2005). Hence, there are conflicts between maintenance planning, and production scheduling and consequently there are good reasons to try minimizing the cost of the two functions (Weinstein & Chung, 1999).The preventive maintenance problem arises especially in large manufacturing companies. Since the capacity of the maintenance department is limited, we are trying to schedule the maintenance of a number of machines throughout the year (e.g. 52 weeks). Each machine must be serviced at least once throughout the year; otherwise the operating cost of that machine will continue to increase and the reliability of the machine will decrease to such an extent that will affect the quality of the product. In addition, during each week, the maintenance service can not service more than one machine. Finally, the desired schedule aims to determine, for each week, which machine has to be serviced (if any).Any interruption of the line caused by any equipment malfunction or failure will result in a major disruption of output or even line or factory shutdown. Thus, an effective maintenance program should be designed to provide the required availability of machinery and output quality. Furthermore, analysis of maintenance costs indicates that a repair performed in the reactive or run to failure mode is, on average, about three times higher than the same repair made within a scheduled or preventive mode (Mobley, 2002). Scheduling the repair minimizes the repair time and associated labor costs. It also reduces the negative impact of expedited shipments and lost production.In this paper we consider the periodic maintenance problem (PMP). PMP is NP-hard problem stated in the following way. There is a set of machinesM={1,2,…,m},and there is a set of periodsU={1,2,…,T}with T ≥ m. The PMP consists of finding an optimal cyclic maintenance schedule of length T that is indefinitely repeated. At most one machine is serviced at each period and all the machines must be serviced at least once for any cycle. When machine i ∈ M is serviced, a given non-negative servicing cost of biis incurred, regardless of the period. At period t ∈ U, a machine i ∈ M that is not serviced during some period is in operation and incurs an operation cost of ni(t) × aiwhere aiis a given positive integer, and where ni(t) is the number of periods elapsed since last servicing of machine i. The main objective of this problem is to determine a feasible maintenance schedule with a minimum cost, i.e. to decide for each period t ≤ T which machine to service (if any), such that the total servicing costs and operating costs are minimized. We give here an example to well understand the present problem. If cycle length T is a decision variable then the problem is called the Free periodic maintenance problem. Here we consider T as an input parameter.Illustrative example. Let the length of the maintenance cycleT=8and the total number of machinesm=4. We suppose furthermore that the servicing costs areb1=1,b2=2,b3=3,andb4=4and the operation costs area1=1,a2=10,a3=1anda4=5.We explain the problem using the optimal solutionπ*=(2,4,2,1,2,4,2,3)obtained by a MIP formulation of the problem (that will be given later in Section 2). Solution π* indicates that machine 2 is serviced in the first period, 4 in the second period, etc. The total corresponding cost is as follows: Servicing cost =b2+b4+b2+b1+b2+b4+b2+b3=2+4+2+1+2+4+2+3=20. The operating costs are computed as follows. For Machine 1, costs are incurred in periods 1, 2, 3, 5, 6, 7 and 8. In periods 5, 6, 7, 8, 1, 2 and 3 these costs are equal respectively to a1, 2a1, 3a1, 4a1, 5a1, 6a1 and 7a1. Thus the total cost equals 28 for machine 1. Similarly we compute the total cost for the other machines. The total cost of machine 2 is equal to0+a2+0+a2+0+a2+0+a2=40. The total cost of machine 3 is equal toa3+2a3+3a3+4a3+5a3+6a3+7a3+0=28a3=28. For machine 4, the total cost isa4+2a4+3a4+0+a4+2a4+3a4+0=12a4=60. Therefore, the objective value of this optimal solution isf(π*)=176. Fig. 1, also presents it.The contributions of the paper are:(i)New variant of Variable Neighborhood Search (VNS) called Nested General VNS (NGVNS) is proposed;New mathematical programming formulation of periodic maintenance problem (PMP) is proposed;New NGVNS heuristic solves exactly all 110 instances from the literature;Comparative study of 4 exact solution methods for PMP is conducted.The rest of the paper is organized as follows. In the next section we give four existing mathematical programming formulations of PMP and then our new formulation. In Section 3 we describe our new variant of VNS called NGVNS. Section 4 contains computational results obtained on 110 instances while Section 5 concludes the paper.Grigoriev, Van De Klundert, and Spieksma (2006) presented several mathematical models to solve the PMP. Hereafter we first give four models from the literature and then we present a new mathematical model.In this model, it is assumed that servicing cost equals to zero, i.e., bi’s are assumed to be null. The quadratic model uses the integer variable xi, tthat corresponds to the number of periods between the current period t ∈ U and the last period before t when machine i ∈ M has been serviced. So, the quadratic formulation of PMP is stated as follows:(1)minx∑i∈M∑t∈Uaixi,t(2)s.t.xi,t+1(xi,t+1−xi,t−1)=0,i∈M,t∈U,(3)xi,1(xi,1−xi,T−1)=0,i∈M,(4)xi,t+xk,t≥1,i≠k,i∈M,k∈M,t∈U,(5)xi,t∈Z+,i∈M,t∈U.The objective function (1) minimizes the total operating cost. Eqs. (2) and (3) ensure the required behavior of the xi, tvariables. Eq. (4) imply that each pair of machines cannot be serviced simultaneously.The authors in Grigoriev et al. (2006) also gave a linearization of this model where the servicing costs biare taken into account. This linearization is given in the next section.Aforementioned quadratic model is linearized by introducing the binary variable yi, tthat takes value 1 if the machine i is serviced in period t and 0 otherwise. The formulation of linearized model is given bellow:(6)minx∑i∈M∑t∈U(aixi,t+biyi,t)(7)s.t.xi,t+1≥xi,t+1−Tyi,t+1,i∈M,t∈U,(8)xi,1≥xi,T+1−Tyi,1,i∈M,(9)∑i∈Myi,t≤1,t∈U,(10)xi,t∈Z+,i∈M,t∈U,(11)yi,t∈{0,1},i∈M,t∈U.The objective function (6) minimizes the sum of operating costs and servicing costs. Eqs. (7) and (8) enforce the variables xi, tto behave in the same way as in the previous model. Inequality (9) assure that we cannot service more than one machine in a single period. Restrictions (10) and (11) are usual integrality constraints.The PMP may be modeled using the binary variablexis,twhich equals 1 if machine i ∈ M is serviced in period s ∈ U, and serviced next (cyclically) in periodt+1∈U,and 0 otherwise. In this model cost c(s, t) is defined as:c(s,t)={(t−s)(t−s+1)2ifs≤t,(T−s+t)(T−s+t+1)2ifs>t,Hence, the flow formulation model is stated as:(12)min∑i∈M∑s∈U∑t∈U(aic(s,t)xis,t+bixis,t)(13)s.t.∑i∈M∑s∈Uxis,t≤1,t∈U(14)∑s∈Uxis,t=∑s∈Uxit+1,s,i∈M,t∈U,(15)∑s∈Uxis,T=∑s∈Uxi1,s,i∈M,(16)∑s∈U∑t∈Uxis,t≥1,i∈M(17)xis,t∈{0,1},i∈M,s∈U,t∈U.The objective function (12) minimizes the total operating costs and servicing costs. Inequalities (13) assure that, at each period, at most one machine can be serviced. Equality constraints (14) and (15) imply that there is a next period in which a machine will be serviced. Constraint (16) assures that each machine is serviced at least once. Finally, restrictions (17) represent the integrality conditions.Let S be the set of all non-empty subsets of U. Clearly, every s ∈ S is a possible set of periods for servicing a machine i ∈ M. Let us call s ∈ S a service strategy or simply strategy. For every pair consisting of a machine i ∈ M and a strategy s ∈ S, we can compute the cost ci, sincurred when servicing machine i in the periods contained in s as follows: let psbe the cardinality of s and let qj,j∈{1,2,…,ps},be the distance between neighboring services in s. The total service and operating cost associated with machine i ∈ M and strategy s ∈ S isc(i,s)=bips+ai∑j=1ps(qj−1)qj/2.The set-partitioning formulation (SP) is as follows: The binary variable xi, sis equal to 1 if the machine i ∈ M is serviced in the periods contained in strategy s ∈ S, and 0 otherwise.(18)min∑i∈M∑s∈Sci,sxi,s(19)s.t.∑s∈Sxi,s=1,i∈M(20)∑i∈M∑s∈S:t∈sxi,s≤1,t∈T(21)xi,s∈{0,1},i∈M,s∈S.The total servicing and operating cost is minimized by objective function (18). Constraints (19) imply that one service strategy has to be selected for each machine. Constraints (20) ensure that no two strategies make use of a same period, while constraints (21) represent usual integrality constraints.Despite the fact that the set-partitioning formulation (SP) has an exponential number of variables, its linear relaxation, which is quite strong, is solvable in a polynomial time in m and T (see Grigoriev et al., 2006). Furthermore, the LP relaxation of SP is stronger than the LP relaxation of FF (see Grigoriev et al., 2006).The PMP may be modeled in terms of the following variables. Let xi, tbe a binary variable that takes the value of 1 if machine i is serviced in the time period t and 0 otherwise. Further, let zi, tbe a variable such that the difference(t−zi,t)is equal to 0 if the machine i is serviced in the time period t, while otherwise, it is equal to the number of time periods elapsed since the last service of machine i. Mathematically, the variable zi, tmay be stated as:(22)zi,t=max{τ∈{h|xi,h=1,1≤h≤t}∪{h−T|xi,h=1,t+1≤h≤T}}Note that we also introduce the variable zi, tfort=0that corresponds to the last period before starting new cycle. Then the PMP may be formulated as follows:(23)min∑i∈M∑t∈Ubixi,t+ai(t−zi,t)(24)s.t.∑i∈Mxi,t≤1,t∈U(25)∑t∈Uxi,t≥1,i∈M(26)zi,t≥xi,t(t+T)−T,t∈U,i∈M(27)zi,t≥zi,t−1,t∈U,i∈M(28)zi,t−1+xi,t(t+T)−zi,t≥0,t∈U,i∈M(29)zi,0=zi,T−Ti∈M(30)−T≤zi,t≤t,t∈U,i∈M(31)xi,t∈{0,1},i∈M,t∈U.The objective (23) minimizes the sum of operating costs and servicing costs. The meaning of the constraints are as follows: constraint (24) guarantees that in each time period at least one machine will be serviced, while the constraint (25) allows the servicing of each machine at least once. From the definition of variables zi, t(see (22)) follows that zi, tequals to t ifxi,t=1andzi,t−1otherwise. This simple observation is used for modeling the constraints (26–30) keeping in mind that the whole process is cyclic (constraint (29)).The model is illustrated using the example given in the Section 1. The optimal solution π* of the formulation is presented in Table 1.In what follows, we present a refinement of the model. Since we consider the minimization, the all constraints which bound variables zi, tfrom below are redundant. So, constraint (26) and (27) can be excluded from the model in order to obtain a model with smaller number of constraints. Such model is given below.(32)min∑i∈M∑t∈Ubixi,t+ai(t−zi,t)(33)s.t.∑i∈Mxi,t≤1,t∈U(34)∑t∈Uxi,t≥1,i∈M(35)zi,t−1+xi,t(t+T)−zi,t≥0,t∈U,i∈M(36)zi,0=zi,T−Ti∈M(37)−T≤zi,t≤t,t∈U,i∈M(38)xi,t∈{0,1},i∈M,t∈U.The following Table (2) gives a brief comparison of four formulations of the studied PMP problem. In this table, the # symbol stands for “number”.It appears that models 1 and 4 contains the less number of variables than other two.Variable Neighborhood Search (VNS) (Hansen & Mladenović, 2001; Hansen, Mladenović, & Pérez, 2008; 2010; Mladenović & Hansen, 1997) is a flexible framework for building heuristics. VNS changes systematically the neighborhood structures during the search for an optimal (or near-optimal) solution. The changing of neighborhood structures is based on the following observations: (i) A local optimum relatively to one neighborhood structure is not necessarily a local optimal for another neighborhood structure; (ii) A global optimum is a local optimum with respect to all neighborhood structures; (iii) Empirical evidence shows that for many problems all local optima are relatively close to each other. The first property is exploited by increasingly using complex moves in order to find local optima with respect to all neighborhood structures used. The second property suggests using several neighborhoods, if local optima found are of poor quality. Finally, the third property suggests exploitation of the vicinity of the current incumbent solution. The VNS based heuristics have been successfully applied for solving many optimization problems (see e.g. Carrizosa, Mladenović, and Todosijević, 2013; Guo, Chen, and Wang, 2014; Hanafi, Lazic, Mladenovic, Wilbaut, and Crevits, 2015; Hansen et al., 2008; 2010; Lazić, Todosijević, Hanafi, and Mladenović, 2014; Mladenović, Urošević, Hanafi, and Ilić, 2012 for recent applications).In this section we give details of our Nested general variable neighborhood search (NGVNS) based heuristic. Before giving its pseudo-code and explaining in details each its step, we first discuss important question in applying each heuristic: how to represent the solution of PMP in the computer.The following necessary condition allow us to efficiently define the solution space of the PMP.Property 3.1If there is a machine j such that aj> bjand if solution of PMP is optimal then, exactly one machine is serviced in each time period.Let us assume that opposite is true, i.e. that there is an optimal solution such that in the time period t′ none of machines is serviced. In that case, in the time period t′ operating costop_cost(i,t′)=ni(t′)×aioccurs for each machine i. Furthermore, the operating cost of machine j,op_cost(j,t′)is greater or equal to aj. Therefore, in the case when aj> bj, if we service the machine j in the time period t′, we would obtain better solution than the optimal one. This is obviously a contradiction.□In addition, we may draw the following property.Property 3.2Let us assume that there is a machine j such thataj=bjand that in a given solution π of PMP in time period t′ none of machines is serviced, then servicing machine j in the time period t′ will yield the solution with objective value better than or equal to that one of a given solution.Let π be a solution such that in time period t′ none of machines is serviced and f(π) its corresponding objective value. Therefore, the operating cost of machine j incurred in time period t′, i.e.op_cost(j,t′)is greater or equal to aj. However, if we service machine j in the time period t′,op_cost(j,t′)will be zero, while servicing cost induced by machine j in time period t′ will be bj. So, the value of such obtained solution π′ will bef(π′)=f(π)−op_cost(j,t′)+bj. Hence, objective value of resulting solution π′ can not be greater than the solution value of a given solution π.□Solution space.Based on the problem definition (including T ≥ m), the features of test instances (see Section 4) and Properties 3.1 and 3.2, we may conclude that the solution space of PMP consists of all vectorsπ=(π1,π2,…,πT),with πt∈ M for t ∈ U such that M ⊂ π. In such representation, πtcorresponds to the index of a machine serviced in the tthtime period. In what follows the solution space of PMP will be denoted by P. For example ifM={1,2,3}andT=6then solution π may be represented asπ={1,1,2,2,3,1}In order to explore the solution space we propose new variant of VNS that we call Nested GVNS. It may be seen as an extension of the nested variable neighborhood descent (NVND) already proposed in Hansen et al. (2008); Ilić, Urošević, Brimberg, and Mladenović (2010). It applies general variable neighborhood search (GVNS) on each element of the preselected neighborhood structure, unlike NVND that applies sequential Variable neighborhood descent (VND) instead. The steps of our NGVNS are depicted at Algorithm 1.The proposed NGVNS applies GVNS starting from each element of the neighborhood structure Replace of the current solution π. The neighborhood Replace(π) contains all sets π′ ∈ P that may be derived from the set π by replacing one element of π (say πj) with one from the set M, e.g πk∈ M, πk≠ πj. Therefore the following property holds.Property 3.3The cardinality of the neighborhood Replace(π) is O(m · T).If an improvement is detected, it is accepted as a new incumbent solution π and whole process is repeated starting from that solution. NGVNS finishes its work if there is no improvement. An initial solution for the proposed NGVNS is built as follows. In the first m periods all m machines are chosen to be serviced. In the remainingT−mperiods, machines to be serviced are chosen at random. In that way the feasibility of the initial solution is achieved. The reason why we decide to use NGVNS instead of NVND is that solution obtained by GVNS can not be worse than one obtained by VND, used within GVNS. Therefore the solution quality found by NGVNS is at least as good as one found by NVND.Note that in Algorithm 1 the GVNS based heuristic is applied in each point of only one, i.e., Replace neighborhood. Clearly, as in building Nested VND, more than one neighborhood structures could be nested before GVNS is applied. That would obviously increase the procedure complexity, but enable much deeper exploration of the solution space. In solving PMP we got very good results with only one initial or higher level neighborhood structure. That is why we did not include more structures in NGVNS.In NGVNS all neighborhoods used may be divided in 2 groups: higher level neighborhoods that are nested and lower level neighborhood structures that are used in GVNS. Of course, within GVNS, lower level neighborhoods can be used in sequential, nested and mixed nested manner (Ilić et al., 2010).General variable neighborhood search (GVNS) (Hansen et al., 2008; 2010) is a variant of VNS (Mladenović & Hansen, 1997) which uses Variable neighborhood descent (VND) as a local search. VND may be seen as a generalization of a local search since it explores several neighborhood structures at once instead of exploring just one. The different neighborhood structures may be explored in sequential, nested or mixed nested fashion (Ilić et al., 2010).The proposed GVNS (Algorithm 2) includes a shaking phase used in order to escape from the local minima traps and an intensification phase in which sequential VND (seqVND) is applied. Within seqVND the following neighborhood structures of a solution π are explored:Reverse_two_consecutive(π),Shift_backward(π),Shift_forward(π)andReverse_part(π).Neighborhood structures.•Reverse_two_consecutive(π)(1-opt) – the neighborhood structure consists of all solutions obtained from the solution π swapping two consecutive elements of π (see e.g. Mladenovic, Todosijevic, & Urosevic, 2012). The complexity of this neighborhood structure is O(T).Shift_backward(π)(Or-opt) – the neighborhood structure consists of all solutions obtained from the solution π moving some element πtbackward immediately after some element πsfor all s > t. The complexity of this neighborhood structure is O(T2).Shift_forward(π)(Or-opt)– the neighborhood structure consists of all solutions obtained from the solution π moving some element πtimmediately after some element πsfor all s > t. The complexity of this neighborhood structure is O(T2).Reverse_part(π)(2-opt) – the neighborhood structure consisted of all solutions obtained from the solution π reversing a sub-sequence of π. Each solution in this neighborhood structure is deduced from the solution π reversing the part starting at πtand ending at πs(t < s) and therefore the complexity of this neighborhood structure is O(T2). In other words from a solutionπ={π1,…,πt,πt+1,…,πs,…,πT}we will obtainπ′={π1,…,πs,…,πt+1,πt,…,πT}. In fact, this neighborhood structure is a generalization of theReverse_two_consecutive(π)since it permits reversing the part of solution π consisted of more than two consecutive elements.The reason why we embedded these neighborhood structures within seqVND scheme is that all of them are based on changing order of servicing machines. In Algorithm 3we give pseudo-code for our seqVND. Note that neighborhoods are changed according to “first improvement” strategy.Shaking. The Shaking phase of GVNS, is presented at Algorithm 4. It takes as input the solution π and the parameter k. At the output it returns the solution obtained after performing k-times random shift move on π. Each random shift consists of inserting an element in π at random either backward or forward (Shift_backwardandShift_forward).All experiments described in this section have been carried out on a personal computer with Intel i3 2.53 gigahertz CPU and 3 gigabyte RAM memory. For testing purposes we consider the test instances proposed in Grigoriev et al. (2006) as well as a set of large test instances generated by us. The instances proposed in Grigoriev et al. (2006) have no more than 10 machines. Thus, we propose new set of 30 instances generated setting the parameter T to 52 (what corresponds to the number of weeks of a year) and setting the number of machines m to 15, 20 and 30. For each choice of T and m values 10 instances were generated choosing aiand bivalues as random integer numbers from intervals [10,50] and [1,20], respectively. These instances as well as the corresponding best known solutions are publicly available at https://sites.google.com/site/dataforpmp/data.Note that in tables presented in this section, for each instance we report the average maintenance and operating cost of a solution (i.e., the objective value divided by T) as it was done in Grigoriev et al. (2006).In this section, we examine the influence of the parameter kmaxon NGVNS heuristic. We tested different values for kmaxfor instances of all sizes. However, to save the space, here, we present results on 10 test instances generated by us withm=20andT=52. These instances are of large size and reveal the typical performance of NGVNS on most of instances. The testing is performed by varying the value of kmaxfrom 5 to 30 with step 5. The obtained results are presented in Table 3. For each choice of kmaxvalue, we report the average solution value found, as well as the average CPU time consumed upon reaching these solutions.From the results presented in Table 3, it follows that that NGVNS is not very sensitive on value of kmaxparameter. Namely the average solution values as well as the average CPU times consumed for different values of kmaxare very close. However, it turns out that NGVNS offers the best solution values when the parameter kmaxis set to 10 consuming the least amount of CPU time. Therefore, for the rest of testing, we set kmaxto 10.In this section, we compare local searches in the five defined neighborhood structures ( i.e.,Reverse_two_consecutive(π),Shift_backward(π),Shift_forward(π),Reverse_part(π),and Replace(π)). These local searches are tested on the instance withm=20andT=52. Each local search is executed 1000 times, starting each time from a different random solution. The summarized results are reported in Table 4, where columns 2, 3, and 4 give respectively the minimum, the average, and the maximum deviation percent from the best known solution over 1000 runs. Columns 5, 6, and 7 report the minimum, average and maximum distance between the generated local optima over 1000 runs and the best known solution. The distance between solutions π1 and π2 is defined as follows:d(π1,π2)=|{t:πt1≠πt2}|.The last column reports the average computing time spent to reach a local minimum (in seconds). Fig. 2(also known as a distance-to-target diagram) shows the distribution of local minima, where each point (x, y) plots the distance x and percentage deviation y of the local minimum from the best-known solution.Comparing the results in Table 4 we observe that:•It turns out that local searches inReverse_two_consecutive,Shift_backward,Shift_forwardandReverse_partneighborhoods return solutions of very similar quality.The local search in theReverse_two_consecutiveneighborhood is faster than the others, but it provides the worst quality (regarding the average deviation objective value).The local search with respect to Replace neighborhood significantly outperforms all the others regarding quality of the obtained local optima (i.e., percentage deviation of objective value). In addition this local search is the second fastest.These observations justify the chosen order of neighborhoods within seqVND. Indeed, it is usual to explore neighborhoods in the increasing order with respect to their power. Also it should be emphasized that in papers (Ilić et al., 2010; Todosijević, Urošević, Mladenović, & Hanafi, 2015), the most powerful neighborhood is chosen as higher level neighborhood that is nested as it is done here nesting Replace neighborhood.In this section we compare NGVNS proposed in Section 3 and GVNS heuristic that follows rules described in Section 3.3. The compared GVNS heuristic, denoted GVNS_PMP, uses as a shaking procedure one that has been presented in Algorithm 4 while as a local search uses a seqVND that exploresReverse_two_consecutive,Shift_backward,Shift_forward,Reverse_partand Replace neighborhoods in that order. Note that steps of such one seqVND procedure may de deduced directly from the Algorithm 3. As a stoping criterion, GVNS_PMP uses the maximum CPU time allowed which is set to 300 seconds.Here we present comparison of GVNS_PMP and NGVNS on the largest instances generated by us since on small instances from Grigoriev et al. (2006) there is no significant difference between GVNS_PMP and NGVNS. The comparison is presented in Table 5. For each heuristic we report the value found on each test instance (Columns ‘value’) and time consumed upon reaching this value (Columns ‘time’). Finally, in columns ‘Dev. (percent)’ we report the percentage deviations of values returned by GVNS_PMP from corresponding values offered by NGVNS.From the presented results follows that NGVNS significantly outperform GVNS_PMP regarding the solution values returned. Regarding average CPU time consumed upon reaching the reported value it follows that GVNS_PMP is faster than NGVNS on instances withm=15andm=30,while on instances withm=20NGVNS is faster. Such behavior of NGVNS may be explained by the fact that NGVNS performs more thorough exploration of the solution space (based on nesting neighborhoods) than GVNS_PMP. Thus, within the imposed time limit, NGVNS is able reach high quality solutions and efficiently avoid possible local optima traps.Keeping in mind that NGVNS performs much better than GVNS_PMP, in this section, we compare it with four exact methods for solving the PMP. These exact methods differ in mathematical programming formulation: our new formulation (see Section 2.5 of this paper) and another three taken from Grigoriev et al. (2006): MIP model (see Section 2.2), flow formulation (FF) model (see Section 2.3) and set partitioning formulation (SP) (see Section 2.4). All mathematical models, except SP model, were solved using the MIP solver IBM ILOG CPLEX 12.4. The time limit for MIP solver were set to 3600 seconds.For testing purposes we consider the same test instances proposed in Grigoriev et al. (2006). Comparative results are reported in Tables 6–10. The results reported for NGVNS heuristic corresponds to the results of a single run. All results reported in Tables 6–10 are obtained on the same computer except those obtained by SP based model. Due to different computing facilities (SP based model were run on a computer with AMD Athlon 2400 XP+ CPU, while all the others were run on an Intel i3 machine), we have normalized the computational times of SP based model using the approach described in Dongarra (2014) and data from http://www.cpubenchmark.net/. All comparisons were made according to the Passmark CPU Score (PCPUS). The running times were normalized by using our machine as the reference point, i.e., Norm.Time(SP)= PCPUS(AMD Athlon 2400 XP+)Time(SP)/PCPUS(Intel i3).In Tables 6–10 the following abbreviations are used:•OPT – the average maintenance and operating cost of the optimal solution (i.e., the objective value divided by T)MIP value – the average maintenance and operating cost of solution obtained solving MIP formulation proposed in Grigoriev et al. (2006)MIP time – CPU time, in seconds, consumed by MIP solver to solve MIP formulation proposed in Grigoriev et al. (2006).SP – normalized CPU time, in seconds, consumed to solve an instance using set-partitioning (SP) formulation.FF – CPU time, in seconds, needed to solve an instance using flow formulation (FF) formulation.new-MIP – CPU time, in seconds, spent by MIP solver to solve MIP formulation proposed in this paper.NGVNS – CPU time (in seconds) consumed by NGVNS based heuristic to solve an instance of PMP.Note that Table 9 does not provide results obtained by SP model since not all solution values had been provided in Grigoriev et al. (2006).The Table 11 provides the average CPU times consumed by each solution approach on a considered data set.From Tables 6–11 the following conclusions may be drawn:(i)Overall NGVNS approach appears to be most reliable. It solved all test instances to the optimality in the shortest CPU time (i.e., 0.831 seconds on average for all test instances).NGVNS needed, in most of instances, less than a second to get an optimal solution, except on instances in Table 10 which appear to be the hardest (since these instances consider the largest number of machines m (the number of constraints and variables in MIP formulations depend on m)).Regarding exact solution methods, several interesting observations may be derived:(i)The behavior of SP formulation is interesting. It is the worst exact method for small instances in Table 6 but the best one for the largest instances presented in Table 10. This may be explained by the fact that increasing the number of machines by one, SP formulation gets just one additional constraint, while the other formulations get O(T) additional constraints. In addition, as shown in Grigoriev et al. (2006) the LP relaxation of SP formulation turns out to be very strong.The average computational times of FF and our new MIPformulation are very similar. Further, the optimality of the solution found for one test instance (Table 10) were not proven solving new MIP formulation, while solving FF formulation the optimality were not proven for 4 test instances (2 instances in Tables 9 and 2 instances in Table 10). For all these instances reported times are boldfaced.The advantage of FF over new MIP formulation comes from the fourth test instance in Table 10. There, new MIP formulation needs about 2500 seconds to provide an optimal solution, while FF formulation does so within 12 seconds.The old MIP model is the least reliable. For example in Tables 9 and10, for only two instance (out of 35) the optimal solutions have been proven within 3600 seconds. However, optimal solutions have not been reached on three instances (boldfaced values in these tables).In this section we present results obtained testing NGVNS (NGVNS is again run only once on each test instance), our new formulation (see Section 2.5 of this paper), MIP formulation (see Section 2.2), and flow formulation (FF) (see Section 2.3) on large test instances generated by us. Again, all mathematical models were solved using the MIP solver IBM ILOG CPLEX 12.4 setting time limit to 3600 seconds.The results are provided in Tables 12–14. In each table we report the average maintenance and operating costs of obtained solutions (Columns ‘value’) as well as CPU times in seconds consumed by certain method to solve certain test instance (Columns ‘time’). Finally, in Columns ‘Dev. (percent)’ the percentage deviations of values found by exact methods from corresponding values offered by NGVNS are reported.From Tables 12–14 the following conclusions may be drawn:(i)NGVNS significantly outperforms the exact methods regarding both solution quality and average computation time. There is no test instance where NGVNS offered worse solution than any of exact methods. Furthermore, NGVNS consumes not more than 270 seconds to solve an instance while exact methods spend 3600 seconds on each test instance.Regarding the solution quality the considered formulations may be ranked as follows. The best one turns out to be our new MIP (the percentage deviations of new MIP solutions from corresponding NGVNS solutions lies in range 0.10–0.75 percent), followed by old MIP formulation (the percentage deviations of new MIP solutions from corresponding NGVNS solutions lies in range 1.21–9.69 percent). Finally, the last place is taken by FF formulation which offers solution values 10 percent or more far from those obtained applying NGVNS.In this paper, we study the periodic maintenance problem (PMP) that consists of finding the cyclic maintenance schedule of machines in a given time period. We present a new MIP formulation for PMP and compare its performance with the models from the literature. Due to the limitations of these models, we also propose a heuristic method based on the Nested General Variable Neighborhood Search (NGVNS) to tackle hard instances. Computational results show that the proposed NGVNS approach is very efficient. On all 110 test instances with known optimal solutions NGVNS succeeded to find these optimal solutions. Moreover, NGVNS heuristic needed only 0.831 seconds on average to solve them. In addition, on large test instances proposed in this paper NGVNS performs much better than any exact approach. These large test instances also reveal superiority of our new MIP formulation over two previous formulations.In future work it will be interesting to compare different metaheuristic approaches for solving PMP (such as Simulated Annealing, Genetic Algorithm, Tabu Search, etc. or even hybrid approaches (e.g., matheuristics)). It will be very convenient in the future research to generalize the PMP model taking into account more practical issues. For example number of machines serviced in each period may be greater than one. Future research may also include proposing extensions of PMP model as well as development of NGVNS based heuristics to solve resulting problems.

@&#CONCLUSIONS@&#
