@&#MAIN-TITLE@&#
Construction and improvement algorithms for dispersion problems

@&#HIGHLIGHTS@&#
We investigate two equity-concerned dispersion problems: max-minsum and min-diffsum.We present ILP formulations and we discuss their strengthening.We propose construction heuristics and a local search metaheuristic.We investigate the key features of these algorithms.We test our algorithms on publicly available benchmark instances up to 500 elements.

@&#KEYPHRASES@&#
Combinatorial optimization,Dispersion problems,Binary quadratic programming,Tabu Search,

@&#ABSTRACT@&#
Given a set N, a pairwise distance function d and an integer number m, the Dispersion Problems (DPs) require to extract from N a subset M of cardinality m, so as to optimize a suitable function of the distances between the elements in M. Different functions give rise to a whole family of combinatorial optimization problems. In particular, the max-sum DP and the max-min DP have received strong attention in the literature. Other problems (e.g., the max-minsum DP and the min-diffsum DP) have been recently proposed with the aim to model the optimization of equity requirements, as opposed to that of more classical efficiency requirements. Building on the main ideas which underly some state-of-the-art methods for the max-sum DP and the max-min DP, this work proposes some constructive procedures and a Tabu Search algorithm for the new problems. In particular, we investigate the extension to the new context of key features such as initialization, tenure management and diversification mechanisms. The computational experiments show that the algorithms applying these ideas perform effectively on the publicly available benchmarks, but also that there are some interesting differences with respect to the DPs more studied in the literature. As a result of this investigation, we also provide optimal results and bounds as a useful reference for further studies.

@&#INTRODUCTION@&#
Let N be a set of n elements, m a positive integer number smaller than n andd:N×N→Ra distance function on the elements of N, such that dii= 0 for all i ∈ N, dij≥ 0 and dij= djifor all i, j ∈ N. The literature denotes by Dispersion Problems (DPs) a family of problems which require to extract from N a subset M of cardinality m, so as to optimize a suitable function of the distances between the extracted elements (Erkut, 1990; Prokopyev et al., 2009). The natural mathematical programming formulations for these problems associate a binary variable xito each element i ∈ N and set xi= 1 if i belongs to M, xi= 0 otherwise:(1a)maxz=fd(x)(1b)s.t.∑i∈Nxi=m(1c)xi∈{0,1}i∈Nwhere notation fd(x) means that the objective is a composite function of vector x through the distance function d, and specifically it depends only on the distances dijbetween pairs of elements (i, j) such that xi= xj= 1.A whole family of problems can be derived from (1) by specifying in different ways the expression of fd( · ). All of them share the same set of feasible solutions, but the properties and behaviour of their objective functions can be strongly different. In particular, the classical application of DPs has been the maximization of some dispersion index used as a measure of operational efficiency. This may refer to the location of facilities (Erkut and Neuman, 1989; Kuby, 1987), but also to the protection of biological diversity, the formulation of admission policies, the formation of committees, the composition of medical crews (Adil and Ghosh, 2005; Aringhieri, 2009; Glover et al., 1998; Kuo et al., 1993; Weitz and Lakshminarayanan, 1998) and, more theoretically, the identification of densest subgraphs (Brimberg et al., 2009). For example, the max-sum DP, more commonly known as Maximum Diversity Problem (MDP) aims to maximize the sum of the pairwise distances between all selected elements (Kuo et al., 1993):(2)fd(x)=12∑i,j∈Ndijxixjwhereas the max-min DP aims to maximize the distance between the two closest elements (Erkut, 1990):(3)fd(x)=mini,j∈N:xi=xj=1dijxixjIn contrast to the classical line of research, Erkut and Neuman (1991) and Prokopyev et al. (2009) introduced alternative definitions of fd( · ) to express equity requirements, referring in particular to the idea of fairness among candidate sites for urban public facilities. This alternative approach is focused on an intermediate aggregate dispersion measure(4)Di(x)=∑j∈Ndijxji∈Nthat is the sum of the distances between each single element and the selected ones, and can be equivalently expressed as ∑j ∈ Mdij. Both papers investigate the optimization of the max-minsum DP, which aims to guarantee that each selected element is as distant as possible from the other ones, setting:(5)fd(x)=mini∈N:xi=1Di(x)which is the minimum aggregate dispersion for the selected elements, and which should be maximized. Prokopyev et al. (2009) also consider the min-diffsum DP, which aims to guarantee that each selected element has approximately the same total distance from the other ones, setting(6)fd(x)=maxi∈N:xi=1Di(x)−minj∈N:xj=1Dj(x)that is the maximum difference between the aggregate dispersions of the selected elements. Notice that function fd( · ) should be minimized here, instead of maximized.This work proposes heuristic algorithms for the max-minsum DP and the min-diffsum DP, inspired by the state-of-the-art methods for the max-sum DP and max-min DP.Our first aim is to investigate whether the main ideas which guarantee a strong performance on efficiency-concerned DPs maintain their effectiveness when applied to equity-concerned DPs. On one hand, the identical structure of the feasible set for these two subfamilies of DPs suggests that it might be the case. On the other hand, the completely different structure of the objective function, and consequently of the so called landscape of the problem (Stadler, 1992), poses reasonable doubts on this assumption. See also Resende et al. (2010) for a discussion on the weak correlation between the optimal solutions of the max-sum DP and the max-min DP. From this perspective, we investigate the impact of some constructive heuristics based on the idea of determining a more favourable initial solution and compare them with the use of a random restart procedure as in Aringhieri and Cordone (2011).The second aim of this work is to provide best known results for publicly available benchmark instances of equity-concerned DPs, thus stimulating further research on the topic, as done for the max-sum DP in Martì et al. (2011). Since the instances considered in Prokopyev et al. (2009) are not publicly available and their size (50–100 elements) is currently too small for a significant algorithmic comparison, we adopted the benchmark instances of the Optsicom web site (http://www.optsicom.es/mdp). These were originally proposed for the max-sum DP, but can be directly employed for all DPs. Specifically, we consider instances up to 500 elements. For some of them, we also provide optimal results, or at least bounds, obtained with a general purpose Mixed Integer Linear Programming (MILP) solver.The paper is organized as follows. Section 2 surveys the relevant literature. Section 3 presents the algorithms here proposed to solve the max-minsum DP and the min-diffsum DP, discussing in detail the basic ideas inspired by the literature on efficiency-concerned DPs. Section 4 reports and discusses the computational results. Appendix A (Tables A.1–A.6) reports the best known results on all the tested instances.Most of the literature on DPs concerns the max-sum DP and the max-min DP. Briefly summarizing, the exact methods for the max-sum DP can solve instances up to 100–150 elements (Aringhieri et al., 2009; Erkut, 1990; Martì et al., 2010; Pisinger, 2006), whereas larger instances require heuristic approaches. Most of these approaches are local search metaheuristics based on the simple exchange of elements in and out of the current solution. In particular, the hybrid metaheuristic proposed by Wu and Hao (2013) provides the best known results for a large set of benchmark instances, whose size goes up to 5000 elements. Other approaches exhibiting remarkable performances are Variable Neighbourhood Search (Aringhieri and Cordone, 2011; Brimberg et al., 2009), Iterated Tabu Search (Palubeckis, 2007), Learnable Tabu Search (Wang et al., 2012), basic Tabu Search (Aringhieri et al., 2008; Duarte and Martì, 2007), Scatter Search (Aringhieri and Cordone, 2011; Gallego et al., 2009) and GRASP (Duarte and Martì, 2007; Silva et al., 2007). According to our experience on this problem, the key to impressively good performances and fast execution times is the use of strong, though not necessarily sophisticated, diversification mechanisms (Aringhieri and Cordone, 2011).The max-min DP, on the other hand, suffers from a very flat landscape of the objective function (several different solutions have exactly the same value). This poses a severe challenge on local search metaheuristics, as discussed in Resende et al. (2010), where different heuristics are extensively compared, among which a GRASP with evolutionary path relinking exhibits the best performance. To partly overcome the issue of the flat landscape, this work minimizes also a secondary objective function, that is the number of pairs (i, j) in the solution such that dijis minimum. Della Croce et al. (2009) reformulate the max-min DP as a dichotomic search on a sequence of instances of the Maximum Clique Problem (MCP), which are solved with the powerful Iterated Local Search (ILS) heuristic proposed in Grosso et al. (2008). This approach allows to prove the optimality of the solution for several instances up to n = 250 elements, provided that the clique subproblem is solved with an exact algorithm. In the end, the Tabu Search algorithm described in Porumbel et al. (2011) applies separate add and drop operations to reduce the complexity of each iteration from quadratic to linear, and it adopts an extremely simple tabu rule: the drop operation always removes the oldest selected element. In this way, each element remains in the solution for exactly m iterations. The algorithm also exploits the sum of all pairwise distances between the elements of the solution as an auxiliary objective function to perturb the flat landscape of the problem.Switching to equity-concerned models, the max-minsum DP has been introduced by Erkut and Neuman (1991) and the min-diffsum DP by Prokopyev et al. (2009), who provide MILP formulations and discuss the computational complexity of both problems, and of other related ones. They also apply a general-purpose solver on instances from 30 to 100 elements and a GRASP metaheuristic on the instances with 50 and 100 elements. This algorithm generates a starting solution adding one element at a time, chosen randomly from a restricted candidate list of random length, which includes the elements yielding the best partial solutions. Then, the starting solution is improved with a sort of first-improvement local search on a restricted neighbourhood. This attempts a random exchange between one element in the solution and one out of it: if the objective improves, the new solution is accepted and the search restarts from it. If it is rejected for a specified number of times, the improvement phase gives place to a new constructive phase. The whole algorithm terminates after a given number of constructive and improvement phases.Some works on equity-concerned models (Prokopyev et al., 2009) allow the distance function d to assume also negative values. Notice that, due to the cardinality constraint, if all distances between two distinct elements are increased by a uniform amount δ > 0, the value of each feasible solution correspondingly increases by a fixed amount depending on δ and on the cardinality m:•for the max-sum DP, objective function (2) increases by m(m − 1)δ/2;for the max-min DP, objective function (3) increases by δ;for the max-minsum DP, objective function (5) increases by (m − 1) δ, because all aggregate dispersions (4) increase by (m − 1) δ;for the min-diffsum DP, objective function (6) remains unmodified, because all aggregate dispersions (4) increase by (m − 1) δ.This implies the following simplifying remark.Remark 1The assumption that the distance function d is nonnegative does not introduce any loss of generality.A problem related to the ones here considered is the Equitable Dispersion Problem, or max-mean DP, which maximizes the average distance between the elements of the solution. This problem, contrary to the ones here considered, does not impose a cardinality constraint. The assumption that the distance function can assume both positive and negative values, then, becomes crucial. Martí and Sandoya (2012) propose a GRASP algorithm with path relinking for the max-mean DP, applying it to instances up to 500 elements, drawn from the Optsicom web site.This section describes a number of two-phase algorithms for the max-minsum DP and the min-diffsum DP inspired by the authors’ work on max-sum and the max-min DP. The constructive phase exploits the relation between these problems and the MCP, computing a sequence of candidate solutions as maximum cliques on a progressively sparsified auxiliary graph (Section 3.1). The improvement phase is a Tabu Search procedure based on the exchange of an element belonging to the current solution with an element out of it (Section 3.2). The two phases repeat iteratively; at each iteration, a simple diversification mechanism rules the constructive phase so as to differentiate the solution built from the one returned by the previous improvement phase (Section 3.3).As discussed in Prokopyev et al. (2009), several DPs are stronglyNP-hard. The reduction associates the vertices of a MCP instance to the elements of a DP instance, and the edges to suitable pairs of elements, such as those with a large distance.Procedure BuildDP (see Algorithm 1) heuristically exploits this concept. It receives the element set N, the distance function d, the desired cardinality m and the indication of the problem to solve (max-minsum DP or min-diffsum DP). After building an auxiliary complete graph G = (N, E) and an empty best known solution M* of value f* = 0, it applies procedure Sparsify to trim G removing its less promising components, as explained later in detail. Procedure FindClique applies the ILS heuristic of Grosso et al. (2008) to find a clique M of m vertices on the reduced graph. The solution corresponding to that clique is evaluated according to the selected objective function by applying Eq. (5) or (6) and, if better, replaces the best solution found so far. When no clique can be found by procedure FindClique, the algorithm terminates, and returns the best solution found overall.Procedure Sparsify applies one of two alternative removal strategies:•edge removal: delete from E the edges with the minimum distance for the max-minsum DPE:={(i,j)∈E:dij>min(h,k)∈Edhk}and those with the minimum and the maximum distance for the min-diffsum DPE:={(i,j)∈E:min(h,k)∈Edhk<dij<max(h,k)∈Edhk}vertex removal: denoting byD˜hthe sum of the (m − 1) largest distances dhk, which is an estimate of the unknown aggregate dispersion Dh, delete from N the elements with the minimum estimate for the max-minsum DPN:={i∈N:D˜i>minh∈ND˜h}and those with the minimum and the maximum estimate for the min-diffsum DPN:={i∈N:minh∈ND˜h<D˜i<maxh∈ND˜h}Both strategies remove the less promising components of the graph, in order to drive the search towards cliques which correspond to solutions of higher quality. Notice that procedure Sparsify does not necessarily remove elements of the last clique M found by FindClique. Thus, M could be found more than once. However, the randomized nature and the diversification mechanisms built in procedure FindClique make this rather unlikely (see Grosso et al. (2008) for details).The vertex removal strategy recalls a stingy heuristic, while the edge removal strategy is inspired by the exact max-min DP algorithm proposed by Della Croce et al. (2009). However, both return the best solution found during the process, instead of the last one. Notice that the vertex removal strategy computes O(n) solutions (each step forbids at least one vertex), whereas the edge removal strategy computes O(n2) solutions (each step forbids at least one edge). Consequently, the latter is slower, but more gradual, and possibly less prone to incorrect choices in its first steps.The improvement phase is a Tabu Search procedure. Tabu Search (TS) is a well known metaheuristic approach introduced in Glover (1986) to enhance the performance of local search. A complete exposition of Tabu Search can be found in Glover and Laguna (1997). We here focus on our application to the equity-concerned DPs.As already remarked, the feasible solutions of these problems are characterized by their cardinality: they should include exactly m elements. It is therefore a common choice, as well as natural, to define a move as the removal of an element s ∈ M, compensated by the introduction of an element t ∈ N∖M. If M′ denotes the resulting neighbour solution, we have:M′=M∪{t}∖{s}Each solution has exactly m(n − m) neighbours. Our Tabu Search procedure visits and evaluates all of them before selecting the incumbent one, i.e., the one which will replace the current solution.The procedure is described in pseudocode format in Algorithm 2. Drawing inspiration from the basic procedure applied to the max-sum DP in Aringhieri et al. (2008), the algorithm divides the possible moves into tabu and nontabu on the basis of two parameters ℓin and ℓout. These are denoted as tabu tenures, respectively for the insertion and removal of an element. At each iteration, the procedure evaluates all possible moves and returns the nontabu move (s, t) which yields the best solution. An aspiration criterium overcomes this general rule, stating that the best move must be returned, even if classified as tabu, if it yields the best solution found so far. The Tabu Search terminates after a specified number of iterations K returning the best solution found in the run.Management of the tabu mechanism. Our implementation of the tabu mechanism works as follows (Gendreau et al., 1994). A suitable vector L stores for each element i ∈ N the iteration Liin which i has joined the current solution (if i ∈ M) or left it (if i ∈ N∖M) for the last time. All moves which remove an element s ∈ M from the solution are labelled as tabu until iteration Ls+ ℓout; as well, all moves which introduce an element t ∈ N∖M in the solution are labelled as tabu until iteration Lt+ ℓin. At the beginning, all elements of vector L are set to a very large negative value, represented by symbol − ∞, so that all moves are nontabu.To refine the search, intensifying or diversifying it according to its latest results, the values of the two tenures are not fixed once for all, but adaptively tuned from iteration to iteration by procedure UpdateTabuTenure, based on the vector f of the values assumed by the objective in the previous iterations. More specifically, the tabu tenure for insertion, ℓin, varies within[ℓinm,ℓinM]. At the beginning of the algorithm, it is set to the middle point of this range(ℓinm+ℓinM)/2; at the ith iteration, if in the Kwprevious consecutive iterations the objective f always worsened, ℓin increases by 1 (up to the maximumℓinM), while it decreases by 1 (down toℓinm) after Kiconsecutive improving iterations. The same occurs for ℓout, which ranges fromℓoutmtoℓoutM,starting at(ℓoutm+ℓoutM)/2and increasing or decreasing by 1 according to the values of f in the last iterations. The rationale of this update mechanism is to decrease the tabu tenure if the objective function has steadily improved in the most recent iterations, in order to intensify the search in a region which appears more promising; symmetrically, the tabu tenure increases if the objective function has steadily worsened, in order to diversify the search driving it out of a region which appears less promising.We set ℓout < ℓin because usually n − m > m, i.e., more elements are out of the solution than inside it. Consequently, the number of exchanges which remove each element in M is larger than the number of moves which introduce each element out of it. This suggests that the prohibition should last longer for the insertion than for the removal.Objective function evaluation and computational complexity. The most time-consuming operation of procedure ImproveDP is, of course, the evaluation of the objective function for each neighbour solution. Both the considered objectives depend on the minimum value of the aggregate dispersions Difor the elements in M; one of them depends on the maximum value (see Eqs. (5) and (6)). Since a move modifies all the aggregate dispersions, it is in general necessary to compute all indices Diassociated to the m selected elements i ∈ M. A straightforward recomputation of these indices would require O(m2) time. However, the modified value of each Diafter the removal of s and the insertion of t can be computed in constant time with the following formula:(7)Di:=Di−dis+ditso that the value of the objective function can be computed in O(m) time for each neighbour solution. Since the number of neighbour solutions evaluated is m(n − m), the overall computational complexity of a single iteration is O(m2n).Algorithm 3gives a unified pseudocode of our algorithms. The constructive and improvement phases are repeated a prespecified number of times T. At the first application, the constructive phase works on the full set of elements N. In the following iterations, on the contrary, it works on a reduced set N′ which is obtained forbidding the elements of the best solution found in the previous improvement phase.This simple mechanism, based on the perturbation of the data, aims to diversify the search, inducing the constructive procedure BuildDP to produce a different starting point M for each iteration of the improvement procedure ImproveDP. It is true that the tabu search might actually reintroduce some, or even all, of the original elements, frustrating this aim. However, the reduced set N′ moves the search to a solution as different as possible from the original one, therefore limiting as much as possible the probability to replicate it.Notice that the mechanism actually breaks down when m > n/2, because the reduced set N′ does not include enough elements to build a full solution. In this case, which never occurs in the instances available in the literature and is less common in practical applications, the mechanism should be modified: instead of removing the elements ofM˜from the data, we should modify procedure BuildDP (in particular its subroutines Sparsify and FindClique) so as to include in the new solution M all the elements ofN∖M˜. This, in fact, would still guarantee the strongest possible differentiation with respect to the best solution found in the previous phase.The whole mechanism can also be interpreted as a form of Variable Neighbourhood Search (Hansen and Mladenovic, 2003) with a nonstandard shaking procedure which generates a new starting solution with the maximum number of different elements with respect to the previous one, instead of gradually increasing the difference from iteration to iteration. Such an approach is reasonable if one does not expect to find better solution near the ones already explored.Diversification is also supported by the random choices of the maximum clique heuristic used in BuildDP. Thus, even if different improvement steps find the same solutionM˜and consequently yield the same reduced set N′, the following constructive steps will usually build different starting points. Experience on the max-sum DP shows that a similar combination of data perturbation and randomness outperforms other more complex algorithmic strategies (Aringhieri and Cordone, 2011).This section presents our computational experiments on the algorithms described above for the max-minsum DP and the min-diffsum DP. First we introduce the computational environment, i.e., the machine, the software and the instances used during the experiments (Section 4.1). Then, we discuss the application of a general-purpose MILP solver to estimate the largest size of the instances which can be solved to optimality and to provide some reference results to assess the quality of the heuristic algorithms (Section 4.2). The last subsection presents the results of the heuristic algorithms.The heuristic algorithms have been coded in C, while the max-clique heuristic of Grosso et al. (2008), which is used as a subroutine in the construction phase, is coded in C++. All of them have been compiled by gcc and run on a 2.1 gigahertz AMD Opteron 8425HE with 12 cores and 16 gigabytes of memory. The MILP formulation discussed in Section 4.2 has been implemented via OPL scripts and solved on the same machine. While the MILP solver exploits parallel computation, the heuristics are purely sequential.As anticipated in the introduction, we do not make a comparison with the GRASP algorithm of Prokopyev et al. (2009). The first reason for this is that they only provide results for the max-minsum DP, ignoring the min-diffsum DP. The second is that the range of sizes they consider, i.e., from 30 to 100 elements, is much smaller than the one here taken into account (from 50 to 500 elements). A preliminary phase of experiments showed that the heuristics here proposed can solve in a few seconds instances with n = 100, systematically returning the same solution in nearly all runs. The MILP solver is never able to improve these solutions, and usually proves their optimality, or at least their proximity to the best achievable bound. A third reason is that the GRASP algorithm adopts the same neighbourhood considered in our work, but limits the exploration to at most 100 neighbours and stops as soon as an improving one has been found, according to the so called first-best exploration strategy. The computational times reported for 1000 restarts, but an indeterminate number of local search iterations, range from 5 to 15 seconds on the instances with n = 100, running on a 2.66 gigahertz Intel Core 2 CPU with 3 gigabytes of RAM. As discussed later, our heuristics, running on instances of the same size and on a roughly comparable machine, take a similar time to perform 50 000 local search iterations while exploring the whole neighbourhood, which includes from 900 to 2400 solutions.Hence, we decided to skip a detailed comparison with this algorithm and to derive new benchmarks of a larger size from the instances of the max-sum DP which are publicly available on the web site of the Optsicom project11http://www.optsicom.es/mdp.and on our own.22http://www.di.unito.it/~aringhie/benchmarks.html.The structure of these instances is compatible with any DP, as it consists of a set of elements N, a distance functiond:N×N→Rand an integer number m < |N|. We consider the following benchmarks, which cover the range of sizes for which significant remarks can be made:•benchmark APOM, which consists of 40 instances with a number of elements n ranging from 50 to 250, while m is equal to 0.2n or 0.4n; the distance function is Euclidean for 10 instances, random for the other ones;benchmark SOM, which consists of 20 instances, with integer-valued distances uniformly extracted at random from [0, 9]; n ranges from 100 to 500 and m from 0.1n to 0.4n;benchmark GKD, which consists of 20 instances, with Euclidean distances, n = 500 and m = 50;benchmark DM1a, which consists of 20 instances, with real-valued distances uniformly extracted at random from [0, 10], n = 500 and m = 200;benchmark DM1c, which consists of 20 instances, with real-valued distances uniformly extracted at random from [0, 10], n = 500 and m = 50;benchmark DM2, which consists of 20 instances with real-valued distances uniformly extracted at random from [0, 1000], n = 500 and m = 50.This section investigates the application of a general-purpose MILP solver, in order to estimate the limit size of the instances which can be solved to optimality without ad hoc algorithms, and to assess the quality of the proposed heuristics, at least on the instances for which the mathematical programming bounds remain tight. We remind that, according to previous works, exact methods can solve max-sum DP instances up to 100–150 elements, adopting semidefinite programming (Aringhieri et al., 2009) or combinatorial techniques (Martì et al., 2010).The max-minsum DP admits the following MILP formulation, proposed in Prokopyev et al. (2009), where the binary variables xidistinguish the elements belonging to the solution (xi= 1) from the other ones (xi= 0) and the continuous variable ϕ represents the value of the objective function:(8a)maxz=ϕ(8b)ϕ≤∑j∈Ndijxj+Q(1−xi)i∈N(8c)∑i∈Nxi=m(8d)ϕ∈R,xi∈{0,1}i∈NWhile constraint (8c) imposes the correct cardinality and constraints (8d) the integrality of the xivariables, constraints (8b) guarantee that the maximum value of ϕ is identical to the minimum aggregate dispersion Diof the elements belonging to the solution. In fact, thanks to the “big-M” coefficient Q, when xi= 0 the right-hand side of the constraint associated to element i becomes much larger than all aggregate dispersions and the constraint is relaxed. To this purpose, Q must overestimate any possible aggregate dispersion in the optimal solution. The original paper sets Q = 1 + maxi ∈ N∑j ∈ Nmax (dij, 0) − ∑j ∈ Nmin (dij, 0), which can be simplified, with no loss of generality, to Q = 1 + maxi ∈ N∑j ∈ Ndij, assuming that dij≥ 0 for all i, j ∈ N.In our experiments, we strengthen the continuous relaxation of Formulation (8) by minimizing the value of coefficient Q, under the condition that no feasible solution should be forbidden. Defining a specific coefficient Qifor each element i ∈ N and observing that the aggregate dispersion Disums only m − 1 distances between i and other elements, we can replace Q in (8b) with:(9)Qi=∑j∈Nimdiji∈NwhereNimis composed of the m − 1 elements with the largest distance from i.The min-diffsum DP admits a similar MILP formulation, where the binary variables xiare defined as above, while the continuous variables ϕ and ψ represent, respectively, the smallest and the largest aggregate dispersion:(10a)minz=(ψ−ϕ)(10b)ϕ≤∑j∈Ndijxj+Q(1−xi)i∈N(10c)ψ≥∑j∈Ndijxj−Q′(1−xi)i∈N(10d)∑i∈Nxi=m(10e)ϕ,ψ∈R,xi∈{0,1}i∈Nwhere Q is the same coefficient used above and Q′ relaxes constraint (10c) for all elements i ∈ N such that xi= 0. The original paper sets Q′ = 1 − mini ∈ N∑j ∈ Nmin (dij, 0) + ∑j ∈ Nmax (dij, 0), which can be simplified to Q′ = Q = 1 + maxi ∈ N∑j ∈ Ndijwith the usual nonnegativity assumption. In our experiments, we strengthen the formulation replacing Q or Q′ in each constraint with the specific coefficient Qidefined in (9).The discussion on the MILP formulations focuses on benchmark APOM, because the other benchmarks consist of larger instances, for which no meaningful result can be obtained with a MILP solver. Table 1reports the results obtained with a limit time of 4 hours, i.e., 14 400 seconds on our 12-core parallel machine. The first column provides the number of elements. The following four ones refer to the original setting of Q: first, the average percentage gap(UB−z˜)/z˜between the best valuez˜found by the MILP solver and the value UB of the upper bound; then, the average percentage gap(z*−z˜)/z˜between the best value z* found in the whole experimental campaign and that found by the MILP solver; then, the number of instances solved to optimality; finally, the average computational time in seconds. The last four columns provide the same information for the formulation strengthened with the Qicoefficients. It is clear that this strengthening consistently reduces the solving time and the residual gaps, and increases the number of solved instances. In particular, the largest size for which at least one instance can be solved to optimality grows from n = 150 to n = 200. Though the improvement is not huge, the reduced coefficients are so easy to compute that their introduction is definitely recommendable. The very limited gap betweenz˜and the overall best known result z* suggests that the use of a general-purpose MILP solver is a viable approach, if the computational time is not strictly limited. An additional remark of some interest is that the instances with random distance values distributed in a large range have the largest gaps. This supports the identification of DM2 as the hardest benchmark in our experiments, which will be also confirmed by the results of the heuristic algorithms.The results obtained applying the MILP solver to Formulation (10) are quite different. The MILP bound, in fact, is very often equal to zero, even after 4 hours of computation, and consequently provides no useful information. Since the problem is a minimization problem, the gap between the MILP heuristic value and the overall best known result is expressed as(z˜−z*)/z*. Only the smallest instances, up to 50 elements, can be solved to optimality: specifically, the average residual gap is 2.31 percent and only two instances out of 8 are solved exactly. For the larger instances, the residual gap ranges around 20–25 percent, though it does not exhibit a sharp increase with size. As for the structure of the instances, there is a consistent difference between the instances in which the cardinality m is set to 0.2n and those with m = 0.4n: the former are harder. Rather unexpectedly, the introduction of the reduced coefficients does not bring any improvement. On the contrary, sometimes it yields worse results, probably because the information provided by the MILP relaxation is scarcely useful. In fact, the heuristics here proposed clearly outperform the MILP solver, even neglecting the fact that the computational time they require is orders of magnitude smaller. The direct use of a general-purpose solver on the min-diffsum DP is, therefore, almost ineffective, and specific heuristics must be applied to obtain solutions of acceptable quality. On the other hand, part of this huge difference between the percentage gaps obtained on the max-minsum DP and the min-diffsum DP is due to the fact that the optimal objective value for the former is typically large, being an aggregate dispersion, whereas it can be very small (potentially, even zero) for the latter.The algorithms proposed in this paper iteratively apply a constructive procedure and an improvement procedure, with an auxiliary diversification mechanism. This section first compares the quality of the solutions produced by the two constructive procedures. Then, it discusses the tuning of the Tabu Search parameters and of the total number of iterations which according to experience are required to obtain stable results. Finally, it investigates the impact on the final result of the restart frequency and of the constructive procedure adopted. For comparison purposes, we also test a simple random initialization, verifying that, in practice, the use of a refined constructive procedure is not justified since the advantage of a good initialization fades away after a sufficient number of improvement steps. For the sake of briefness, the preliminary phases of this analysis focus on a restricted set of benchmarks, namely APOM, which includes the smallest instances, and DM2, which includes the hardest ones.Constructive procedures. We first applied the edge removal and the vertex removal strategies as standalone algorithms, to estimate the quality of the solutions they can provide to a subsequent improvement procedure.The first two columns of Table 2report the size of the instances considered for the max-minsum DP: those with n ranging from 50 to 250 belong to benchmark APOM (8 for each size), whereas those with n = 500 belong to benchmark DM2 (20 overall). The horizontal line stresses the separation between the two benchmarks. The following two pairs of columns report, for each initialization procedure, the average computational time in seconds and the average percentage gap with respect to the best result obtained in the whole experimental campaign. This is assumed as the best possible approximation for the optimum, since the lower bounds yielded by the MILP formulations are very weak. Table 3provides the same information for the min-diffsum DP. As expected, the edge removal strategy outperforms the vertex removal strategy but requires a longer computational time. The quality of both procedures is, however, modest.The main interest of these results, then, concerns the different performance on the two benchmarks and on the two problems. Benchmark DM2, in fact, exhibits smaller gaps and a stronger difference between the computational times of the two methods. This is because the distance function has a wider range of values, so that the edge removal strategy removes less edges at each step and evaluates more solutions overall.Table 3 reports the corresponding results for the min-diffsum DP: they exhibit the same dependences, but much larger gaps, thus confirming that this problem is harder.Tabu Search parameters. The improvement procedure is a Tabu Search algorithm with two adaptively varying tabu tenures, one for the insertion and one for the removal of elements. After a preliminary phase of experiments, we tuned the range of the former tenure, ℓin, as [8; 14]: at first, the tenure is set equal to 11, which is the middle point of the range; then, it decreases after Ki= 3 consecutive improving iterations and increases after Kw= 5 consecutive worsening iterations. The range of the tenure for removal, ℓout, is [3; 7]: its starting value is 5 and it is updated with the same rule of the other tenure. These values confirm the general remark we made on the max-sum DP (Aringhieri et al., 2008; Aringhieri and Cordone, 2011) that the tabu tenure for insertion should be larger than that for removal, because the number of elements out of the solution exceeds the number of those inside it.Total number of iterations. We then experimentally identified the number of iterations after which the objective function tends, for all the available instances, to converge to a stable value with only occasional spaced out improvements. This occurs between 10 000 and 50 000 iterations for the max-minsum DP and between 50 000 and 100 000 iterations for the min-diffsum DP. On the basis of these experiments, in the following we decided to set the total number of local search iterations to 50 000 for the max-minsum DP and 100 000 iterations for the min-diffsum DP. This is approximately twice the average number of iterations k* after which the heuristic finds the last improving solution on the benchmarks considered (see Table 4).Restart frequency. The following phase of experiments focused on investigating whether it is more profitable to concentrate the improvement iterations in a single run of the Tabu Search procedure or to distribute them among independent runs. We kept the same total number of iterations determined above, i.e., 50 000 for the max-minsum DP and 100 000 for the min-diffsum DP and divided it into T blocks of K iterations each. At the beginning of each block, the constructive procedure builds a new starting solution, operating on the auxiliary graph defined by the diversification mechanism. The number of restarts T and the number of local search iterations per restart K are, therefore, inversely proportional.This experiment also allows to investigate whether the constructive procedure exerts or not a lasting influence on the final result. In fact, a refined initialization is justified only if the time spent to perform it is compensated by a significantly better final solution. Otherwise, the same time could be employed to increase the number of improvement iterations. In order to evaluate the long-term influence of the starting solution on the final result, we have applied the same total number of iterations KT to the solutions produced by the edge removal strategy, by the vertex removal strategy and by a simple random initialization, denoted in the following as random strategy. If the final result exhibits little or no dependence on the initialization, we will be authorized to prefer faster and simpler mechanisms. If, on the contrary, a better starting solution is related to a better final result, we will need to investigate further the balance between the time spent in the constructive and the improvement phase.Starting, as usual, with the max-minsum DP, Figs. 1and 2show, respectively for benchmark APOM and benchmark DM2, the average percentage gap (z* − z)/z between the best value z* found in the whole experimental campaign and the value found by the heuristics. For each strategy, we test the following restart frequencies: T = 1, 5, 10, 20, 50 or 100 restarts, which correspond to K = 50 000, 10 000, 5000, 2500, 1000 and 500 local search iterations for each restart.Summarising, when applied to the max-minsum DP, all of the three strategies provide solutions very close to the best known ones, and probably also to the optimum (though this can be guaranteed only for n ≤ 100).To estimate in detail the sensitivity of the algorithm performance to the restart frequency, we have applied Wilcoxon’s matched-pairs signed-ranks test(Wilcoxon, 1945). With respect to the random strategy, the test indicates that the setting with T = 10 restarts with K = 5000 iterations each, which is the best on average, is not significantly different from T = 5 and T = 20 (i.e., the probability that the difference is produced by random fluctuations exceeds 5 percent), but it dominates the other restart frequencies considered. For the vertex removal strategy, the best setting is T = 5, but the other settings with T ≤ 50 are not significantly worse. For the edge removal strategy, the best setting is T = 1, but the settings with T ≤ 20 are not significantly worse. These results suggest that, while a random initialization has a specific range of effective restart frequencies, a good initialization allows the algorithm to perform well with less restarts, and to be more robust with respect to the restart frequency.The results on benchmark DM2 partly confirm these indications. In fact, the random strategy performs best with T = 5 restarts, but T = 1 and T = 10 are not significantly worse. So, there is once again an optimal range of values, largely overlapping with the previous one. The vertex removal strategy and the edge removal strategy perform best with T = 20, but all settings with T ≤ 50 have similar performance. Thus, a good initialization still improves the robustness of the heuristic, and the optimal range of parameter values is more or less the same. The fact that the parameter setting which performs best has a larger value of T could be related to the larger size of these instances, but this does not hold for the random strategy.Similar comments can be made on the other benchmarks, on which we give here only summarised comments for the sake of briefness. The Euclidean benchmark GKD exhibits very small gaps (always < 0.14 percent) with nearly no dependence on the value of T. For the other three benchmarks, the best value for T varies, but there is always a range of statistically equivalent values which never includes the setting T = 100 and often excludes T = 50. The range for the random initialization, in particular, tends to be smaller and usually excludes also T = 1.Figs. 3and 4show the corresponding information for the min-diffsum DP with KT = 100 000. The values considered for the number of restarts T are T = 1, 10, 20, 40, 100 or 200, and the corresponding number of local search iterations for each restart are K = 100 000, 10 000, 5000, 2500, 1000 and 500. The gap here is expressed as (z − z*)/z*, because this is a minimization problem. In summary, all of the three strategies yield a 5–8 percent gap with respect to the best known result. This gap is not huge, but it is one order of magnitude larger than that observed on the max-minsum DP, confirming that the min-diffsum DP is harder. Moreover, the best known result is also less likely to be optimal.The random strategy performs best with T = 40 restarts and K = 2500 iterations each, but lower frequencies are not significantly worse. The vertex removal strategy performs best with T = 20, but the setting with T = 10 is statistically equivalent. The edge removal strategy, in the end, performs best with T = 20, though all settings with T ≤ 40 are statistically equivalent.The results on benchmark DM2(Fig. 4) with the random strategy show an unexpected minimum gap with T = 1 restart, with a maximum in T = 10 followed by steady improvements as T increases. Wilcoxon’s test suggests that the results obtained with T ≥ 20 are not statistically different from those obtained with T = 1. The vertex removal strategy and the edge removal strategy also perform best with many restarts (T = 200), though, once again, Wilcoxon’s test suggests that the difference with respect to the other settings is not statistically dominated. So, there is a slightly improving trend with higher restart frequencies, but the strength of this trend is not statistically significant. The other benchmarks tend to confirm the remarks made on APOM, rather than those made on DM2: the three strategies very often perform best with T = 10, while the gap tends to rise with more frequent restarts. The increase is slow on benchmark SOM, for which many different settings are statistically equivalent, whereas it is rather quick on the other benchmarks.Comparison of the initialization procedures. The experiments on the restart frequency also suggest that none of the three initialization strategies dominates the others. The random strategy is often slightly better on average, but it seems to be less robust, since its optimal range of frequencies tends to be smaller. Indeed, we have also applied Wilcoxon’s test to compare the three strategies, each one with the best setting of the restart frequency, on the overall collection of benchmark instances. The test fails to reveal any statistically significant difference.A complementary point of view can be found in Table 5, which reports, for both problems (first column) and all benchmark classes (second column), the total number of instances (third column) and the number of instances on which each of the three reinitialization procedures hits the best known result (last three columns). With respect to this index, none of the alternatives outperforms the others, though the edge removal strategy tends to find more best results than the other two.Summarising, there is no statistical dominance among the three heuristics considered. The random initialization is much faster, especially on large instances, and it has the nonnegligible advantage of being simpler. Though it is less robust with respect to the restart frequency, this parameter can vary within a reasonably wide range without significantly affecting the quality of the final solution (for example, setting the number of restarts to T = 10 guarantees an effective performance on all benchmark classes). Our conclusion is that it is reasonable to prefer a simple random initialization, since it allows to gain additional time, which could be exploited to increase the number of improvement iterations.Average gap and computational time of the best parameter setting. To confirm these conclusions, we have adopted the random initialization strategy and compared its performance to the best results obtained in the whole experimental campaign. We keep the total number of improvement iterations to KT = 50 000 for the max-minsum DP and to KT = 100 000 for the min-diffsum DP. We set the number of restarts to T = 10, so that each improvement phase consists of K = 5000 iterations for the max-minsum DP and to K = 10 000 iterations for the min-diffsum DP.Table 6reports, for both problems (first column) and for each class of benchmark instances (second column), the number of instances (third column), the average percentage gap obtained with this setting with respect to the best known results (fourth column) and the average CPU time in seconds required (fifth column).The first remark is that the percentage gap obtained for the max-minsum DP is small (nearly always < 1 percent), while it is still significant for the min-diffsum DP (between 3 and 10 percent on average). The computational times are in good accordance with the theoretical analysis of Section 3.2. In fact, they are approximately proportional to m2(n − m), and the time required to solve the max-minsum DP is half that required for the min-diffsum DP, given that the number of local search iterations is also half as much.For reference purposes, we report in Appendix A (Tables A.1–A.6) our best known results for each instance of the available benchmarks.

@&#CONCLUSIONS@&#
We have proposed constructive and improvement heuristics for two equity-concerned DPs, namely the max-minsum DP and the min-diffsum DP, based on the fundamental ideas which underly the state-of-the-art algorithms on efficiency-concerned DPs.The investigation of smart techniques to reduce the computational complexity of each iteration has allowed a shift from the straightforward quadratic evaluation to a linear update mechanism. In this way, it is possible to solve in a matter of few minutes instances up to 500 elements, much larger than the ones previously considered in the literature. Ongoing work is devoted to devise auxiliary data structure or different neighbourhoods, which could improve the average case complexity, possibly trading a loss in the quality of the solution for a reduction of the computational time. In this regard, the equity-concerned DPs appear intrinsically challenging, due to the hybrid nature of their objective function, which combines two different operators: a sum on the lower level to compute the Dicoefficients, and a minimization or maximization at the upper level. Exchanging each pair of elements modifies each aggregate dispersion by an independent amount (see Eq. (7)). This makes unlikely that the worst-case time to update the minimum (and the maximum) aggregate dispersion could become less than linear.The comparison of different initialization procedures and different restart frequencies suggests that the best approach for these problems is to apply a simple random initialization, as it is for the max-sum DP and contrary to the max-min DP. However, the best restart frequency appears to be larger than that reported for the max-sum DP in Brimberg et al. (2009) and Aringhieri and Cordone (2011), and more specific for each class of instances. Moreover, while the max-minsum DP appears to be easily solved to near optimality, the min-diffsum DP exhibits larger gaps and much less stable results. In other words, these problems partly confirm and partly disprove what was known for the more investigated efficiency-concerned DPs.We have also estimated the practicability of directly applying a general-purpose solver to a MILP formulation of the two problems, obtaining very different outcomes. On one hand, the max-minsum DP can be solved exactly up to n = 150 elements, obtaining limited gaps and solutions comparable to those provided by tailored heuristics for larger instances, up to n = 500 elements. On the other hand, the general-purpose solver is unable to solve even small instances of the min-diffsum DP (n = 50), and it does not provide useful lower bounds.