@&#MAIN-TITLE@&#
Obtaining three-dimensional models from conical perspectives

@&#HIGHLIGHTS@&#
The proposed algorithms represent a significant advance in solid geometry reconstruction.The reconstruction process is carried out automatically without user interaction.The methods have been implemented and simulated, obtaining a success rate of 100%.

@&#KEYPHRASES@&#
Image reconstruction,Single image technique,Image-based modeling,Conical perspective,

@&#ABSTRACT@&#
One of the most important challenges in the computer vision has long been to obtain three-dimensional models from the information given by a projection of the model. In this work we show an automatic system which allows obtaining three-dimensional models from entities that represent the conical projection of a polyhedral model with normalon or quasi-normalon typology. The results obtained on a total of 160 tests, with a success ratio of 100%, make the method a proposal to be considered for obtaining models from conical perspectives automatically.

@&#INTRODUCTION@&#
The examination of the surrounding environment is an essential task for the development of the autonomous navigation applications. Its aim is to obtain the three-dimensional reconstruction of the objects which are around us, allowing, in this way, interacting with them from the vision provided by the cameras. This is demonstrated by the numerous studies carried out to date, such as the one presented in [1] where the authors present a geometrical method to locate objects allowing the autonomous robot guidance.The methods for the reconstruction of models from conical perspectives developed so far can be classified according to the number of captures of images which are available to start the process. The most significant advances have been obtained when there are, at least, two images of a same model available, which is obvious if we consider the increase of information that it implies.In these terms, we can mention a wide range of work carried out as set out in [2], where a new method for reconstructing environments occurs from stereo images and the obtained results are a pixilated pattern. The work developed in [3] was reconstructed from two images with a proposal based on a hybrid method that combines several existing reconstruction technique models. Other authors have presented works in the line of calibration images obtained from multiple cameras as in [4] where it works with 12 cameras. In [5], the necessary conditions are set to calibrate two identical cameras by identifying four points of the image without knowing if the intrinsic parameters of the cameras are set conditions.With regard to the methods based on a single image, it must be stressed that most of them have focused on the study of the parallel projection. We can group them, paying attention to the technique used, in four blocks: labeling methods, based on the gradient space methods, based on linear programming methods, and perceptual methods.Labeling methods are based on a classification of the vertexes according to the directions of the edges which come together in each corner. The first valid labeling methods are presented in the work carried out in parallel in [6] and [7] where the vertexes of a cube were classified after considering all the corners from all possible viewpoints. However, this labeling system had a problem, it could only reconstruct polyhedra and also that these could not present hidden edges.From this work, new methods were developed in order to improve and expand the procedure of labeling [8,9], but all of them were based on heuristic rules and restrictions were presented. In [10] for example, we needed to distinguish between visible and hidden edges. Finally in [11] a new labeling scheme of drawings, including non-necessarily polygonal objects, was developed. However the procedure allows labeling the same drawing in more than one way, which contrasts with human perception in which a projection has very few ways of dimensional interpretation.The latest contributions in this line are the labeling methods as shown in [12] and [13] where the geometry of the hidden parts can be established, and where the front model geometry can be defined.Significantly, among the methods based on the gradient space work, we can mention [14]. It is an established method based on the correspondence between the gradients of polyhedral surfaces and lines that make up a projection, and try to determine whether a line drawing is realizable or not. This causes these methods to be generally regarded as methods of interpretation rather than reconstruction methods. However, the existence of a gradient image is necessary but not enough for the drawing to be realized. Some examples can be found in [15].As for the methods based on linear programming, [16] shows a computational mechanism based on linear programming to extract three-dimensional polyhedral structures from lineal drawings achieving a necessary and sufficient condition for that lineal drawing to represent a polyhedral object in terms of linear programming. However, the condition is as mathematically accurate as some drawings that are simply rejected because the vertexes deviate slightly from the correct positions.In [17] and [18] reconstruction was done in terms of linear programming but this method was based on the labeling scheme presented in [10]. In [19] we can see the problem of reconstruction based on rules of geometry. This method establishes the mathematical formulation of a system of equations that represents a set of geometrical conditions where the 3D model must be verified from the analysis of a projection or a portion of the remains. Topologically, it´s assumed that all vertexes of the object are trihedral and the projection always represents an Eulerian polyhedron.Finally, the perceptual methods are characterized by trying to implement, through the sequential language of computers, the way humans perceive it. In [20], the first perceptual method is designed based on the proportionality between the projection and the three-dimensional model, starting from a labeling method that allows us to obtain a graph of adjacency to define the orientation of each edge regarding the main axes. In their algorithm, the parallel lines of the projection are parallel in the model and the parallel edges to the main axes are drawn proportional to the actual dimensions, thus allowing us to define parallelograms with faces parallel to the planes of projection. Although the method allowed flexibility to inaccuracies in the drawing, the algorithm is characterized by a high degree of user interaction needed to designate the principal axes (intersection of the planes of projection). Furthermore, the method was very limited since rebuilding models should not contain hidden edges given the ambiguities that cause the representation of these edges.The other methods have been based on perceptual optimization methods. It is considered that such methods are the mathematical process that more closely resembles the way humans interpret a projection. The strategy called “inflation”, applied to an axonometric projection of a model, works assigning coordinates “Z” to vertexes of a projection while maintaining its coordinates (x, y) by minimizing an objective function.The function to be optimized has been modified and extended by different authors. In [21] the objective function is formed by a single component, the MSDA (minimum standard deviation of angles) in [22,23] the mentioned objective function was expanded with the DP (deviation from flatness of the faces of a model) and [24–27] proposes an objective function composed of a sum of sub-functions representing regularities of the projection, i.e. characteristics of the model that can be deduced from the observation of the projection.Finally in [28–30] they have worked on rebuilding, applying optimization processes trying to reduce the high rate of errors that occur with the application of these methods.The rapid attainment of a three-dimensional model from a single projection is very practical for developing tasks in which the treatment of a large number of images, as autonomous robot guidance, is required. Therefore, in this paper we have focused on the search of an algorithm that allows us to obtain, with a low computational cost, a valid reconstruction of a three-dimensional geometry of a model. Progress in the reconstruction of images of normalon and quasi-normalon defined types, is according to the proposal given in [31].The process of converting the captured image of a three-dimensional model can be divided into two phases. The first of them is focused on the image processing (bitmap) with the objective of determining the set of entities that define the outline of the object (graph). There are several authors with different aims and objectives who have worked in this line [32,33]. The second phase is focused on providing the graph with three-dimensional coordinates in order to turn this into a three-dimensional model (Fig. 1).This work has been focused on the second phase, that is, assuming that we have a vectorized image and defined from its edges (graph 2D), obtaining the three-dimensional model (graph 3D). Previous works aimed at this reconstruction phase, are based on labeling methods [34] or on the prior detection of the vanishing point [35].As we said before, this paper focuses on the study of graphs of normalon and quasi-normalon typologies, which we define as:•Normalon graph: The name is a generalization to the world of polyhedra, related to the normalones polygons concept, such as those with the property in which all angles between two concurrent edges are 90°. In Fig. 2you can see a graph of this type since all edges converge toward three vanishing points (one improper).Quasi-normalon graph: In these graphs, despite not belonging to the normalon type, it is possible to reach all vertexes, exclusively through edges that are parallel to three directions, and which form 90° to each other. That is, they are graphs that meet the condition where the elimination of all non-parallel edges to these three directions does not imply the loss of all vertexes also allowing them to remain connected. We name them main directions. In Fig. 2 we can see a graph of this type in which the removal of non-parallel edges in three main directions (1–2, 1–5, 4–6, 5–7, 7–12, 5–12, 5–8, 1–8, 1–9, 2–9) does not imply the loss of vertexes and they remain connected (there is only one graph).By definition of typologies and prior to the detection of the type of graph, it is necessary to identify which are the main directions. That is, the three directions among those existing in the graph which are going to be considered as directions corresponding to edges that are mutually perpendicular in the reconstructed model.As input data, the picture size and distance from the point of view to the picture plane is considered. These parameters are intrinsic variables of the device used to capture the image and can be extracted from the image file itself.In order to detect the main directions the following considerations have been taken into account. On the one hand, the conical perspective studies the laws to represent accurately what is observed. In photography, it's very similar to the optical system used, where every picture is an image in central projection and, according with the conical perspective foundations, the parallel edges of a three-dimensional model will vanish to a same point of the graph. Therefore, determining the main directions of a graph can be summed up in determining to which the main directions the vanishing points belongs (this study is focused on models which have their base in the geometric plane, which implies, from the view of the conical projection system, focusing on parallel conical and oblique conical perspectives with two vanishing points).On the other hand, given that it is assumed that the graph comes from the vectorization of a photographic image, it's logical to consider that the main point is centered in the frame that defines the size of the picture and that the vanishing points corresponding to the main directions, because of the very basis of the conical perspective, will have to be aligned with this according to the horizontal and located in opposite sides regarding the main point.Based on these considerations, the proposed method allows a simplification of the commented ideas in [36] where all the points candidates to be vanishing points are explored. In our work we have implemented a simple algorithm that goes through the list of edges of the graph taking them in pairs, calculating their intersection points according to the following considerations:(a)If the edges converge at a vertex of the graph, the point is rejected.If between the edges there are verticals or horizontals, the calculation of intersection points is disregarded and the existence of this type of edges is recorded.If the edges are intercepted on the horizontal traced by the midpoint of the framework, the intersection point is considered vanishing point.Given that some inaccuracies because of truncation of decimals in the analytic resolution of the problem, an error tolerance has been established whose value has been set in an experimental way at 3% of the maximum dimension of the graph.(a)If the distance between two intersection points of two edges is less than the error tolerance, those points are grouped as an only vanishing point whose coordinates are fixed to the first intersection point obtained.If the distance from an intersection point of two edges to the horizontal traced by the main point is less than the error tolerance, it is assumed that the intersection point is on the horizontal.The main directions are determined from the following considerations:(a)If the main point coincides with a vanishing point and there are vertical or horizontal edges in the graph, the representation is considered parallel perspective and the vertical, the horizontal and the set of edges that vanish to the main point are taken as main directions.If there are two vanishing points that are aligned with the main point, and also there are vertical edges in the graph, the representation is considered oblique perspective and we take as main directions the vertical and the set of edges, that vanishing to points located on the horizontal traced by the main point meet the conditions of being placed in opposite sides in relation to the vanishing point, and that its geometric mean with respect to the main point coincides with the focal distance.As an example, the graph of a model in oblique perspective is shown in Fig. 3. In it the position of the main point (P) as the central point of the framework is obtained, and the vanishing points VP1 VP2 and VP3 are selected as they are on the horizontal traced in P. Next, the pairs of vanishing points VP1–VP2 and VP1–VP3 are analyzed as candidates to be points where the main directions vanish given that both pairs are positioned in opposite sides in relation to P. Finally, the edges that converge at VP1 y VP2, along with the vertical, are selected as main directions given that their geometric mean regarding the point P coincides with the focal distance.The detection of vanishing points is a matter that has been addressed by researchers from different approaches. Some authors [35,37] start from an analysis of bitmap, while others [38–40] start from a set of sketched entities. Since this work is exclusively focused on the reconstruction of the three-dimensional model, it is assumed that the starting graph does not contain errors or distortions.The method proposed is based on the own foundation of the conical perspective and on the ideas initially presented in [20] and later revised in [41]. As it will be shown in Section 4, this totally automatized method allows increasing the index of graphs that can be reconstructed. Also this method allows to know if they contain hidden edges or not in the representation.In Fig. 4there is a form defined by the edges A'B’, A'C’ and A'D’. Principal Point “P” (projection from the “V” point of view) is obtained as the central point if the drawing (central point of the framework) and the two vanishing points in the graph F1 and F2 are obtained through the alignment with the principal point. In accordance with the conic perspective basis, point B shall be situated on the line that joins the point of view and the projection of the point in the picture plane (straight line VB’) which defines a geometric position of the prospecting points to represent point B in the area (B1, B2, … , Bn– 1, Bn).Given the particularity of the images in which all of the edges are perpendicular, we may define a new geometrical locus formed by the plane perpendicular to edge AD (Fig. 5). The mentioned locus is defined by the infinite points, united to vertex A, create edges perpendicular to AD.From the intersection of the locus defined before (straight line VB’ and plane perpendicular to AD) we obtain the coordinates of the searched vertex “B” and in a similar manner those of vertex “C”.The proposed method may be applied in an identical manner to “quasi-normalon” type graphs previously applying a small transformation which consists in the elimination of all those edges in the graph that are not parallel to the principal directions. Later, once the graph is reconstructed, the mentioned edges may be added without causing any modifications to the geometry of the model (Fig. 6).It is necessary to highlight slight differences in the reconstruction procedure of the models depending on the type of perspective from which we are working. Due to this, in the following sections, the proposed methods for parallel and oblique perspectives are discussed separately.Assuming that every edge in the graph is defined by an initial vertex and final vertex, the reconstruction process commences from a vertex in the graph that complies with the condition of being an initial vertex of a horizontal or vertical edge carrying out the following steps:1.We maintain the coordinates (x, y) of the initial vertex and assign coordinates Z = 0 adding the initial vertex to a model list of vertexes (MLV).We analyze all the horizontal and vertical edges in the graph that pass through the initial vertex maintaining the coordinates (x, y) in their final vertexes as we assign coordinates Z = 0. The final vertexes are then added to the MLV.If other edges exist in the image and they pass through the initial vertex and their final vertexes have not yet been defined (they are not in the MLV), we search for another edge in the graph that is not adjoined with it and passes through the initial vertex and as well as having its final vertex in the MLV. We obtain the perpendicular plane to this, in the initial vertex; determine the coordinates of the final vertexes as the intersection of the mentioned plane and the straight line that joins the point of view with the projection of the final vertex in the graph. The final vertexes are then added to the MLV.We take as the initial vertex the next one on the MLV and repeat the process from step 3 until the total amount of vertexes in the graph are on the MLV or all the vertexes on the MLV have been considered as initial vertexes.To understand the proposed method, we have applied it to a simple graph including the vertexes A’, B’, C’, D’, E’ F’, G’ and H’ as well as the edges A'B’, B'C’, C'D’, A'D’, A'E’, E'F’, B'F’, F'G’, C'G’, G'H’, D'H’ and E'H’ that represent a hexahedron in a parallel conic projection (Fig. 7).The mentioned graph is considered a parallel perspective given that the main point coincides with the vanishing point of the edges A'E’, B'F’ C'G’ and D'H’, thus defining the principal directions, as mentioned beforehand, from the edges that converge to the mentioned vanishing point and the horizontal and vertical drawn on the picture plane.Following the steps described before we begin the reconstruction process at vertex A’, being that it is a vertex that is met by a horizontal edge. The coordinates (x, y) are maintained at vertex A and we assign the coordinate Z = 0. Taking A as the initial vertex, we obtain the coordinates of the final vertexes B and D that define the horizontal and vertical edges respectively in the graph maintaining their coordinates (x, y) and assigning them coordinate Z = 0. The coordinates of vertex E are later obtained as the intersection of plane P1 (perpendicular to edge AB on A) and the straight line VE’. Following the proposed order, the MLV shall be defined in the form [A, B, D, E] (Fig. 8a).Taking B as the initial vertex being that it is next on the MLV, the vertexes C and F are obtained as the intersection on plane P2 (perpendicular on B to the edges BA) and the straights lines VC’ y VF’ respectively, adding the new final vertexes to the MLV. The final vertex A is not analyzed from the initial vertex B being that it is already on the MLV and is in the form [A,B,D,E,C,F] (Fig. 8b).Now taking D, the next one on the MLV, as the initial vertex, the coordinates of vertex H are defined by the intersection of the perpendicular plane on D to the edge DA (coinciding with the ground plane) and the straight line VH’. The MLV shall remain in the form [A,B,D,E,C,F,H] (Fig. 8c).E would be the following vertex to consider as initial according to the order established on the MLV, however this vertex does not provide new information given that the vertexes connected to it by edges (A, F, and G) are already on the MLV.Finally, taking C as the initial vertex, we obtain vertex G as the intersection of the perpendicular plane on C to the edge CB (coinciding with the ground plane) and the straight line VG’. The MLV shall remain in the form [A,B,D,E,C,F,H,G] (Fig. 8d). The process finalizes given that the size of the MLV corresponds to the number of vertexes in the graph.We must take into consideration that there are several possibilities for the initial election of the reference edge in order to start the reconstruction process. It can result in two different models. In other words, the election of this reference edge has effects on the achievement of a model or in its respective Necker inversion as shown in Fig. 9.Since the graph is considered to be obtained from the vectorization of a picture, in our method we have considered that the bigger edges in the graph correspond to those edges in the model closest to the point of view whereas the smaller edges in the graph correspond to those further from the point of view. Due to this, we have established a criterion to select the initial vertex in order to consider it as such among all those possible, the one which may coincide with the longest horizontal or vertical edge.Please refer to point three of the described method in this section, where we can see that those edges are taken as a reference to obtain the perpendicular plane. According to that, the proposed method can't be applied to the edges of which we expect to obtain the coordinates of the final vertex where those edges are adjoining edges. This fact is due to the error that the mentioned edges cause in obtaining the tridimensional coordinates of the vertexes.In Fig. 10you are ableto observe a graph defined by the edges A'B’, A'C’, A'D’ and D'E’ that serves as an example to clarify this concept. In accordance with the method previously described, the reconstruction process shall begin at vertex A, being that it is the only vertex to coincide with a vertical edge, assigning to vertex A the coordinates (x, y) of the vertex A’ and making Z = 0 its coordinate. Vertex B’ is in this same situation being that it is on a vertical edge with the initial vertex on A’ allowing to obtain the coordinates of vertex B maintaining the coordinates (x, y) of the vertex B’ and assigning coordinate Z = 0. Afterwards we obtain the coordinates of vertexes C and D through the intersection of plane P1 perpendicular to edge AB on A and the straights lines VC’ and VD’ respectively.Now we need to obtain the coordinates of vertex E’, but this vertex is only connected to the vertex D’. However the only edge to reach vertex D’ with both of its vertexes on the MLV is D'A’ that in turn coincides with D'E’, being why it must not be used to obtain the coordinates of the vertex E’ given that, on using edge DA to calculate the perpendicular plane P2 and determine its intersection with the straight line VE’, it would provide incorrect coordinates for the vertex E.The method applied is similar to the aforementioned with the exception being that because it is from an oblique perspective, there are no horizontal edges in the graph that represent a principal direction. This forces the reconstruction process to commence at a vertex in the graph, considering it an initial vertex, through which a vertical edge passes, maintaining the coordinates (x, y) of the initial vertex and assigning coordinate Z = 0. Finally, the initial vertex is added to the MLV.Subsequently, the vertical edges in the graph that pass through the initial vertex are examined maintaining at its final vertex the coordinates (x, y) assigning coordinates Z = 0 and adding them to the MLV. Then the process is repeated from point number 3 in the previous section.To understand the method proposed, we have once more applied a simple graph composed of the vertexes A’, B’, C’, D’, E’ F’, G’ and H’ and the edges A'B’, B'F’, F'E’, A'E’, C'G’, C'D’, D'H’, G'H’, A'D’, B'C’, F'G’ and E'H’ that represent a hexahedron in an oblique conic perspective (Fig. 11).The mentioned graph is considered an oblique perspective given that the principal point is aligned with the vanishing points F1 and F2 defining the principal directions from the edges that converge at the mentioned vanishing points and the vertical drawn in the picture plane. Following the steps described beforehand, we initiate the reconstruction process at vertex A’, being that it is a vertex that coincides with a vertical edge of greater size. We maintain the coordinates (x, y) at vertex A and assign coordinate Z = 0. Taking A as the initial vertex, we obtain the coordinates of final vertex D to define a vertical edge maintaining its coordinates (x, y) and assigning coordinate Z = 0. We later obtain the coordinates of the vertexes B and E as the intersection of the plane P1 (perpendicular to edge AD and A) and the straights lines VB’ and VE’ respectively. Following the order here proposed, the MLV shall be defined inthe form [A,D,B,E] (Fig. 12a).Later, taking D as the initial vertex, being that it is next on the MLV, we obtain the vertexes C and H as the intersection of the perpendicular plane on D to the edges DA (coinciding with the ground plane) and the straights lines VC’ and VH’ respectively adding the new final vertexes to the MLV. Final vertex A is not examined from the initial vertex B being that it is already on the MLV and is in the form [A,D,B,E,C,H] (Fig. 12b).Now taking B as the initial vertex, the next one on the MLV, we determine the coordinates of vertex F through intersection of the perpendicular plane on B to the edge BA and the straight line VF’. The MLV shall be in the form [A,D,B,E,C,H,F] (Fig. 12c).E would be the next vertex to consider as initial according to the order established on the MLV, however this vertex does not provide new information, given that the vertexes connected to it through edges (A, F, and H) are already on the MLV.Finally,taking C as the initial vertex, we obtain vertex G as the intersection on plane P2 (perpendicular on C to edge CD) and the straight line VG’. The MLV shall be in the form [A,D,B,E,C,H,F,G] (Fig. 12d). The process concludes given the size of the MLV coincides with the number of vertexes in the graph.The method described allows the reconstruction of a great variety of graphs. However, there are a certain number of them that are not suitable for reconstructing at first, but by adding a certain amount of fictitious or “dummy” edges, can be transformed to graphs to which the method described may be applied. Once the reconstruction of the graph is carried out, the fictitious edges must be removed from the model.Further below, we describe the previous modifications applied to the image by means of fictitious edges that have been considered in order to enlarge the group of images that may be reconstructed by applying the proposed method.Given that the process of reconstruction described in the case of oblique perspectives commences at a vertex through which passes a vertical edge, this process shall not commence if we come across “origami” type graphs like the one shown in Fig. 13.For these cases, an algorithm has been implemented. It adds a fictitious vertical edge to any vertex in the graph thus allowing the commencement of the reconstruction process.In the example of Fig. 13, the fictitious or “Dummy” edge AM is previously added to the graph before the reconstruction process which in turn allows the reconstruction process to begin at vertex “A” following the order shown in Table 1.Previously, we defined the “quasi-normalon” graphs as those in which the elimination of all those edges not parallel to the principal directions did not imply the loss of vertexes and all of them remained interconnected.However on occasions, this transformation of the graph can mean the loss of connections among its vertexes hence not corresponding to a “quasi-normalon” type making reconstruction impossible.For these cases we have implemented a tool that analyzes the graph in a way that, if after removing those edges that are not parallel to the principal directions the graph is left divided in two independent graphs and if there are collinear edges between two vertexes in the independent graphs, dummy edges are generated to connect the mentioned vertexes in a way that the graph complies with the “quasi-normalon” features and allows reconstruction.In theexample shown in Fig. 14, the graph resulting from removing those edges not parallel to the principal directions creates two independent graphs. The union of vertexes B and S along which coincide edges AB and SQ respectively and also coincide themselves through dummy edge BS, give the graph a quasi-normalon trait allowing the reconstruction. In Table 2, the propagation of the reconstruction method is indicated.The transformation of a quasi-normalon graph by the removal of those edges that are not parallel to the principal directions may producing vertexes along which only coincide adjoining edges. According to described in point number 3 of the section; “method for parallel perspectives”, in order to be able to propagate the reconstruction method on the vertexes in the graph, on each of the vertexes it is necessary to have at least one edge parallel to one of the principal directions, and this edge must not coincide with the rest of the edges that coincides with the vertex.To guarantee the propagation of the reconstruction method, a tool has been implemented in order to analyze the graph in a way, that if any vertex in the graph coincides only with adjoining edges, dummy edges parallel to one principal direction are generated, this being different to that of the edges that coincide with the vertex.In the example shown in Fig. 15 the removal of edges that are not parallel to the principal directions, produces from “M” and “N” two vertexes along which only coincide adjoining edges, for this reason the reconstruction method cannot be applied on the graph. The modification of the image proposed in this section, adds the dummy edges MS and NT parallel to the principal vertical direction allowing the application of the reconstruction method as shown in Table 3.Given that a vectorization algorithm has not been implemented in this work, the capture of images has been carried out from software that allows the positioning of cameras and the exportation of perspectives to dxf format. In the different examples tested the framework that defines the size of the picture has been added, and the focal distance has been modified using angle lens of 24, 35 and standard of 50 mm, being the width/height coefficient of 4:3. In Fig. 16 the graph obtained following this process is shown. In it, the positioning of the camera in the software used, the image captured by the camera and the graph obtained once the image is exported to dxf format can be seen.In Figs. 17, 18, 19 and 20 the 160 graphs tested, extracted from 80 models (80 graphs in parallel perspective and 80 graphs in oblique perspective), are shown. 28 of them are normalon typology and the rest of them are quasi-normalon typology.The methods proposed have been implemented in Visual C# under the platform of Visual Studio (WinForm) using the libraries CsGl (OpenGl for Visual C#).In the settings of the application shown in Fig. 21, two windows have been defined. In one of them (left window), you may observe the starting point graph where it is possible to see the detected vanishing points, the principal directions, the graph typology and the type of perspective detected. In the other one (on the right), we show the model obtained from the reconstruction of the graph. This window has a tool that allows us to rebuild the graph step by step.The success rate in the graphs tested is of 100%. Moreover, although in a wide majority the graphs have been represented with hidden edges, tests with graphs without hidden edges have been carried out obtaining their correct representation, although, obviously, the final model does not constitute a solid but a model without depth.

@&#CONCLUSIONS@&#
We have presented a few algorithms for the reconstruction of “normalon” type graphs as well as “quasi-normalon” type from a parallel and oblique conic perspective. The graphs may or may not contain hidden edges, respectively providing solid or models without depth as results. The reconstruction process is carried out without the need of guidance on automatically detecting vanishing points as well as principal directions.The methods have been implemented in Visual C# under the platform of Visual Studio (WinForm) using the libraries CsGl (OpenGl for Visual C#) carrying out a total of 160 tests obtaining a success rate of 100%. The results achieved reveal the interest of the method proposed in the field of obtaining models from conical perspectives.