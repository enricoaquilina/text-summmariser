@&#MAIN-TITLE@&#
Onyx: A Linked Data approach to emotion representation

@&#HIGHLIGHTS@&#
Definition of an ontology for emotion representation.Linking to the linguistic linked open data cloud through lemon.Emotion lexicon annotation in several languages and domains available via the EuroSentiment portal.Emotion service specification based on NIF.Vocabularies for different emotion models, including EmotionML and WordNet-Affect.

@&#KEYPHRASES@&#
Emotion analysis,Ontology,Provenance,Linked data,EmotionML,Lexical resources,

@&#ABSTRACT@&#
Extracting opinions and emotions from text is becoming increasingly important, especially since the advent of micro-blogging and social networking. Opinion mining is particularly popular and now gathers many public services, datasets and lexical resources. Unfortunately, there are few available lexical and semantic resources for emotion recognition that could foster the development of new emotion aware services and applications. The diversity of theories of emotion and the absence of a common vocabulary are two of the main barriers to the development of such resources. This situation motivated the creation of Onyx, a semantic vocabulary of emotions with a focus on lexical resources and emotion analysis services. It follows a linguistic Linked Data approach, it is aligned with the Provenance Ontology, and it has been integrated with the Lexicon Model for Ontologies (lemon), a popular RDF model for representing lexical entries. This approach also means a new and interesting way to work with different theories of emotion. As part of this work, Onyx has been aligned with EmotionML and WordNet-Affect.

@&#INTRODUCTION@&#
With the rise of social media, more and more users are sharing their opinions and emotions online (Pang & Lee, 2008). The increasing volume of information and number of users are drawing the attention of researchers and companies alike, which seek not only academical results but also profitable applications such as brand monitoring. As a result, many tools and services have been created to enrich or make sense out of human generated content. Unfortunately, they are isolated data silos or tools that use very different annotation schemata. Even worse, the scarce available resources are also suffering from the heterogeneity of formats and models of emotion, making it hard to combine different resources.Linked Data can change this situation, with its lingua franca for data representation as well as a set of tools to process and share such information. Plenty of services have already embraced the Linked Data concepts and are providing tools to interconnect the previously closed silos of information (Tummarello, Delbru, & Oren, 2007). In fact, the Linked Data approach has proven useful for fields like Opinion Mining. Some schemata offer semantic representation of opinions (Westerski, Iglesias, & Tapia, 2011), allowing richer processing and interoperability.Emotions have a crucial role in our lives, and even change the way we communicate (Pang & Lee, 2008). They can be passed on just like any other kind of information, in what some authors call emotional contagion (Barsade, 2002). That is a phenomenon that is clearly visible in social networks (Kramer, Guillory, & Hancock, 2014). Public APIs make it relatively easy to study the social networks and their information flow. For this very reason Social Network Analysis is an active field (Mislove, Marcon, Gummadi, Druschel, & Bhattacharjee, 2007), with Emotion Mining as one of its components. On the other hand, the growing popularity of services like micro-blogging will inevitably lead to services that exchange and use emotion in their interactions. Some social sites are already using emotions natively, giving their users the chance to share emotions or use them in queries. A noteworthy example is Facebook, which recently updated the way its users can share personal statuses.Nevertheless, the impact of emotion analysis goes well beyond social networks. For instance, there are a variety of systems whose only human–machine communication is purely text-based. Such systems can use the emotive information to change their behavior and responses (Pang & Lee, 2008).Furthermore, there are many sources that can be used for sentiment analysis beyond pure text, including video and audio. Multimodal analysis, or making use of several of these sources, is an active field that gathers experts from different disciplines. A unified schema and appropriate tooling would open up new possibilities in this field.Lastly, combining subjective information from emotion analysis with facts already published as Linked Data could enable a wide array of new services. This would require a widely accepted Linked Data representation for emotions, which does not exist yet. In this paper we present Onyx, a new vocabulary that aims to bridge this gap and allow for interoperable tools and resources. We also provide a set of example applications, additional vocabularies to use existing models, and multilingual resources that use Onyx to annotate emotion.The rest of this paper is structured as follows. Section 2 introduces the technologies that Onyx is based upon, as well as the challenges related to emotion analysis and creating a standard model for emotions, including a succinct overview of the formats currently in use. Section 3 covers the Onyx ontology in detail, including some vocabularies or models of emotions, and several examples. Section 4 presents the results of our evaluation of the Ontology, focusing on the coverage of current formats like Emotion Markup Language (EmotionML). Finally, Section 5 completes this paper with conclusions and future work.To work with emotions and reason about them, we first need to have a solid understanding and model of emotions. This, however, turns out to be a rather complex task. It is comprised of two main components: modeling (including categorization) and representation.Confusingly, the terms opinion, sentiment, emotion, feeling and affect are commonly used interchangeably. Throughout this article we follow the terminology by Cambria, Schuller, Xia, and Havasi (2013) where opinion mining and sentiment analysis are focused on polarity detection and emotion recognition, respectively.1A more detailed terminology discussion can be found in Munezero, Montero, Sutinen, and Pajunen (2014).1There are also several models for emotions, ranging from the most simplistic and ancient that come from Chinese philosophers to the most modern theories that refine and expand older models (Ekman, 1999; Prinz, 2004). The literature on the topic is vast, and it is out of the scope of this paper to reproduce it. The recent work by Cambria, Livingstone, and Hussain (2012a) contains a comprehensive state of the art on the topic, as well as an introduction to a novel model, the Hourglass of emotions, inspired by Plutchik’s studies (Plutchik, 1980). Plutchik’s model is a model of categories that has been extensively used (Borth, Chen, Ji, & Chang, 2013; Cambria, Havasi, & Hussain, 2012b; Mohammad & Turney, 2013) in the area of emotion analysis and affective computing, relating all the different emotions to each other in what is called the wheel of emotions.All the existing motions are mainly divided in two groups: discrete and dimensional models. In discrete models, emotions belong to one of a predefined set of categories, which varies from model to model. In dimensional models, an emotion is represented by the value in different axes or dimensions. A third category, mixed models, merges both views.Other models are more general and model affects, including emotions as a subset. One of them is the work done by Strapparava and Valitutti in WordNet-Affect (Strapparava et al., 2004), an affective lexicon on top of WordNet. WordNet-Affect comprises more than 300 affective labels linked by concept–superconcept relationships, many of which are considered emotions. What makes this categorization interesting is that it effectively provides a taxonomy of emotions. It both gives information about relationships between emotions and makes it possible to decide the level of granularity of the emotions expressed. Section 3.2.1 discusses how we formalized this taxonomy using SKOS, and converted it into an Onyx vocabulary.Despite all, there does not seem to be a universally accepted model for emotions (Schröder, Pirker, & Lamolle, 2006). This complicates the task of representing emotions. In a discussion regarding EmotionML, Schroder et al. pose that given the fact that even emotion theorists have very diverse definitions of what an emotion is, and that very different representations have been proposed in different research strand, any attempt to propose a standard way of representing emotions for technological contexts seems doomed to fail (Schröder et al., 2007). Instead, they claim that the markup should offer users choice of representation, including the option to specify the affective state that is being labeled, different emotional dimensions and appraisal scales. The level of intensity completes the definition of an affect in their proposal.EmotionML (Baggia, Pelachaud, Peter, & Zovato, 2014) is one of the most notable general-purpose emotion annotation and representation languages. It was born from the efforts made for Emotion Annotation and Representation Language (EARL) (H.N. of Excellence, 2006; Schröder et al., 2006) by Human–Machine Interaction Network on Emotion (HUMAINE). EARL originally included 48 emotions divided into 10 different categories. EmotionML offers twelve vocabularies for categories, appraisals, dimensions and action tendencies. A vocabulary is a set of possible values for any given attribute of the emotion. There is a complete description of those vocabularies and their computer-readable form available (Ashimura et al., 2012).In the field of Semantic Technologies, Grassi introduced Human Emotion Ontology (HEO), an ontology for human emotions meant for annotating emotions in multimedia data. We discuss some differences between Onyx and HEO in Section 5. Another work worth mentioning is that of Hastings, Ceusters, Smith, and Mulligan (2011) in Emotion Ontology (EMO), an ontology that tries to reconcile the discrepancies in affective phenomena terminology. It is, however, too general to be used in the context of emotion analysis: it provides a qualitative notion of emotions, when a quantitative one would be needed.For Opinion Mining we find the Marl vocabulary (Westerski et al., 2011). Marl was designed to annotate and describe subjective opinions expressed in text. In essence, it provides the conceptual tools to annotate opinions and results from Opinion Mining in an open and sensible format.LLOD (Chiarcos, Hellmann, & Nordhoff, 2011; Chiarcos, McCrae, Cimiano, & Fellbaum, 2013) is an initiative that promotes the use of linked data technologies for modeling, publishing and interlinking linguistic resources. The main benefit of using linked data principles to model linguistic resources is that it provides a graph-based model that allows representing different kinds of linguistic resources (such as lexical-semantic resources, linguistic annotations or corpora) in a uniform way, thus supporting querying across resources. The creation of an LLOD cloud is a cooperative task that is been managed by several communities, such as Open Linguistics Working Group (OWLG) of the Open Knowledge Foundation and Ontology-Lexica Community Group (OntoLex) of W3C. As a result of this activity, an initial LLOD is currently available as shown in Fig. 1, where several types of resources have been identified: lexical-semantic resources (e.g. machine readable dictionaries, semantic networks, semantic knowledge bases, ontologies and terminologies), annotated corpora and linguistic annotations.With regards to modeling lexical-semantic resources, Lexicon Model for Ontologies (lemon) (Buitelaar, Cimiano, McCrae, Montiel-Ponsoda, & Declerck, 2011) proposes a framework for modeling and publishing lexicon and machine-readable dictionaries as linked data. lemon provides a bridge between the most influential lexical-semantic resources, WordNet (Fellbaum, 1998) and DBPedia (Bizer et al., 2009). With regards to annotated corpora, there are two initiatives (Chiarcos, Hellmann, & Nordhoff, 2012), POWLA (Chiarcos, 2012a) and NLP Interchange Format (NIF) (Hellmann, 2013) that enable to link lexical-semantic resources to corpora. Finally, Ontologies of Linguistic Annotation (OLiA) (Chiarcos, 2012b) are a repository of annotation terminology for various linguistic phenomena that can be used in combination with POWLA, NIF or lemon. OLiA ontologies allow to represent linguistic annotations in corpora, grammatical specifications in dictionaries, and their respective meaning within the LLOD cloud in an operable way.The main benefits of modeling linguistic resources as linked data include (Chiarcos et al., 2013) interoperability and integration of linguistic resources, unambiguous identification of elements of linguistic description, unambiguous links between different resources, possibility to annotate and query across distributed resources and availability of mature technological infrastructure.Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness. The PROV Family of Documents defines a model, corresponding serializations and other supporting definitions to enable the inter-operable interchange of provenance information in heterogeneous environments such as the Web (Moreau et al., 2011). It includes a full-fledged ontology that other ontologies like Onyx can link to. Fig. 2shows the very basic classes in PROV-O, which should be enough to understand the role of Provenance in Onyx. The complete ontology is covered by the PROV-O Specification (Groth & Moreau, 2013).As we can see, Agents take part in Activities to transform Entities (data) into different Entities (modified data). This process can be aggregation of information, translation, adaptation, etc. In our case, this activity is an emotion analysis, which turns plain data into semantic emotion information.There are many advantages to adding provenance information in emotion analysis in particular, as different algorithms may produce different results.This section gives a comprehensive view of the ontology and is structured in three parts. Section 3.1 presents the ontology in full. Section 3.2 shows how different vocabularies are represented with the ontology, using three known models of emotion. Lastly, Section 3.3 exemplifies how to annotate data using the ontology and vocabularies from the previous section.Onyx is a vocabulary that models emotions and the emotion analysis process itself. It can be used represent the results of an emotion analysis service or the lexical resources involved (e.g. corpora and lexicons). This vocabulary can connect results from different providers and applications, even when different models of emotions are used.At its core, the ontology has three main classes: Emotion, EmotionAnalysis and EmotionSet. In a standard emotion analysis, these three classes are related as follows: an EmotionAnalysis is run on a source (generally text, e.g. a status update), the result is represented as one or more EmotionSet instances that contain one or more Emotion instances each.The model of emotions in Onyx is very generic, which reflects the lack of consensus on modeling and categorizing emotions. An advantage of this approach is that the representation and psychological models are decoupled.The EmotionAnalysis instance contains information about the source (e.g. dataset) from which the information was taken, the algorithm used to process it, and the emotion model followed (e.g. Plutchik’s categories). Additionally, it can make use of Provenance to specify the Agent in charge of the analysis, the resources used (e.g.dictionaries), and other useful information.An EmotionSet contains a group of emotions found in the text or in one of its parts. As such, it contains information about: the original text (extractedFrom); the exact excerpt that reflects the emotion or emotions (emotionText); the person that showed the emotions (sioc:has_creator); the entity that the emotion is related to (describesObject); the concrete part of that object it refers to (describesObjectPart); the feature about that part or object that triggers the emotion (describesFeature); and, lastly, the domain detected. All these properties are straightforward, but a note should be given about the domain property. Different emotions could have different interpretations in different contexts (e.g., fear is positive when referred to a thriller, but negative when it comes to cars and safety).When several EmotionSet instances are related, an AggregatedEmotionSet can be created that links to all of them. AggregatedEmotionSet is a subclass of EmotionSet that contains additional information about the original EmotionSet instances it aggregates. For instance, we could aggregate all the emotions related to a particular movie, or all the emotions shown by a particular user, and still be able to trace back to the original individual emotions.Onyx’s Emotion model includes: EmotionCategory which is a specific category of emotion (e.g. “sadness”, although more than one could be specified), linked through the hasEmotionCategory property; the emotion intensity via hasEmotionIntensity; action tendencies related to this emotion, or actions that are triggered by the emotion; appraisals and dimensions. Lastly, specific appraisals, dimensions and action tendencies can be defined by sub-classing Appraisal, Dimension and ActionTendency, whose value should be a float number.On top of that generic model we have included two different models: the WordNet-Affect taxonomy, and the EmotionML vocabularies for categories, dimensions and appraisals, which are detailed in Section 3.2.Although emotional models and categories differ in how they classify or quantify emotions, they describe different aspects of the same complex phenomenon emotion (Schröder, 2010). Hence, there are equivalence relationships between different categories or emotions in different models. To state such equivalence between emotion categories in Onyx one can use the properties defined in SKOS2http://www.w3.org/TR/skos-reference/#mapping.2such as skos:exactMatch or skos:closeMatch. This approach falls short when dealing with dimensional emotional theories or complex category theories. Since dimensional models are widely used in practice, Section 4.4 covers how to deal with this issue in detail.Within a single model, it is also possible that two separate emotions, when found simultaneously, imply a third one. For instance, “thinking of the awful things I’ve done makes me want to cry” might reveal sadness and disgust, which together might be interpreted as remorse. Some representations would refer to remorse as a complex emotion. Onyx purposely does not include the notion of complex emotions. It follows the same approach as EmotionML in this respect, as HUMAINE EARL included this distinction between simple and complex emotions, but it was not included in the EmotionML specification. This simplifies the ontology and avoids discussion about the definition of complex emotions, since there are several possible definitions of a complex emotion, and different levels of emotions (e.g.the Hourglass of Emotions model). One possible way to deal with such situation is to add an AggregatedEmotion that represents remorse to the EmotionSet, linking it to the primary emotions with the aggregatesEmotion property.Table 1, contains a comprehensive list of the properties associated with each of these classes. Fig. 3shows a complete overview of all these classes and their properties.To group all the attributes that correspond to a specific emotion model, we created the EmotionModel class. Each EmotionModel will be linked to the different categories it contains (hasEmotionCategory), the Appraisal or Dimension instances it introduces (through hasAppraisal and hasDimension), etc.Having a formal representation of the categories and dimensions proves very useful when dealing with heterogeneous datasets in emotion analysis. In addition to being necessary to interpret the results, this information can be used to filter out results and for automation.An EmotionModel, or at least an EmotionCategory, has to be defined in order to make a valid annotation. Annotators can define their own ad-hoc models and categories, but the Linked Data approach dictates that vocabularies and entities should be reused when appropriate. Hence, we offer several EmotionModel vocabularies that can be used with Onyx.As of this writing, we have modeled the quite extensive WordNet-Affect taxonomy as an EmotionModel, to be used as the reference for categorical representation. We also ported the main vocabularies defined for EmotionML (Ashimura et al., 2012), and created a model based on the The Hourglass of Emotions (Cambria et al., 2012a). A list of vocabularies with a detailed explanation is publicly available.3http://www.gsi.dit.upm.es/ontologies/onyx/vocabularies.3Onyx’s Github repository4https://github.com/gsi-upm/onyx.4contains the tools used to generate all these models.WordNet-Affect (Strapparava et al., 2004) contains a subset of synsets suitable to represent affective concepts. Each synset is given one or more affective labels (a-labels) or categories. These labels are linked via concept/superconcept relationships. We processed the list of labels in WordNet-Affect 1.1 and generated a SKOS taxonomy. This taxonomy and its specification are available on our website.5http://gsi.dit.upm.es/ontologies/wnaffect/.5In this specification we included a navigable tree with all the affects and their relationships. This tree makes it trivial to select an affect that represents the desired emotion. Fig. 4shows part of the tree, with some nodes collapsed.The full taxonomy contains 305 affects, 291 of which are related to emotions. The RDF version of the taxonomy also includes an EmotionModel that contains these 291 affects as EmotionCategory entities.Besides providing a good starting point for other ontologies, the resulting taxonomy also serves as reference for mapping between several different ontologies in the future.EmotionML does not include any emotion vocabulary in itself. However, the Multimodal Interaction Working Group released a series of vocabularies that cover the most frequent models of emotions (Ashimura et al., 2012). Users can either define their own vocabularies or reuse one of the existing ones.We have developed a tool that generates an EmotionModel model from a vocabulary definition, including all its dimension, category, appraisal or action tendency entries. Using this tool, we have processed the vocabularies released by the Multimodal Interaction Working Group.EmotionML has four types of vocabularies, according to the type of characteristic of the emotion phenomenon they represent: emotion categories, emotion dimensions, appraisals and action tendencies. If an emotion model addresses several of these characteristics, there will be an independent vocabulary for each. For instance, Frijda’s model defines action tendencies and categories, which results in the Frijda-categories and Frijda-action-tendencies vocabularies. In Onyx, instead of following this approach, we opted for adding all characteristics in the same model. This results in cleaner URIs, and helps represent the emotion model as a whole.With these vocabularies it is possible to translate EmotionML resources into Onyx for their use in the Semantic Web. Table 2contains an example of how EmotionML resources can be translated to Onyx.The Hourglass of Emotions (Cambria et al., 2012a) is an interesting example of mixed models, including both dimensions and categories. Based on the paper by Cambria et al. we have created a basic model in Onyx, which includes the four dimensions and 24 first-level emotions, and 32 second-level emotions. Using the generated Onyx vocabulary, we can perform simple experiments with this interesting model. Nonetheless, a complete representation would include the restrictions or relationships between the different categories and the dimensions.After this introduction to the ontology, we will present several use cases for it. Tables 3 and 4should give a better understanding of the whole ontology. Rather than exhaustive and complex real life applications, these examples are simple self-contained showcases of the capabilities of semantic emotion annotation using Onyx. For the sake of brevity, we will omit the prefix declaration in the examples.This section examines how Onyx has been applied in several use cases, such as modeling and publication of emotion lexicons (Section 4.1), annotation of emotion in corpora (Section 4.2), enabling interoperability of emotion services (Section 4.3) or mapping and composition heterogeneous emotion representations (Section 4.4).Annotated lexical resources are the bases for analysis of emotions in text. These resources currently available can be classified into opinion and emotion lexicons.Opinion lexicons supply a polarity value for a given lexical entry. Some examples of opinion lexicons are SentiWordNet (Esuli & Sebastiani, 2006), SenticNet 1.0 (Cambria, Speer, Havasi, & Hussain, 2010), Multi-Perspective Question Answering (MPQA) (Wiebe, Wilson, & Cardie, 2005) or GermanPolarityClues (Waltinger, 2010).Emotion lexicons supply an emotion description for a given lexical entry. Some examples of emotion lexicons are WordNet-Affect (Strapparava et al., 2004), the Affective Norms for English Words (ANEW) (Bradley & Lang, 1999), EmoLex (Mohammad & Turney, 2013) or SenticNet 3.0 (Cambria, Olsher, & Rajagopal, 2014) (see Listings 1 and 2).In this section we present the application of Onyx for annotating lexical entries with emotion representations. This application has been carried out in the context of the Eurosentiment R&D project where a LLOD approach has been followed (Buitelaar, Arcan, Iglesias, Sánchez-Rada, & Strapparava, 2013). In particular, lexical entries described with the lemon model have been extended with sentiment and emotion features using Marl and Onyx, respectively, as illustrated in Listing 3.In this example, we illustrate how a lexical entry (terrifying) has a positive polarity value (0.7) and a emotion category (fear) when referring to the word book. In other words, a terrifying book is linked to feeling fear, but it usually represents a positive quality. In contrast, terrifying is a negative quality when referred to news. For a more in-depth explanation of the format, see Gabriela et al. (2014a) and Buitelaar et al. (2013).The main benefits of this approach are:•Lexical entries are aligned with WordNet (Fellbaum, 1998). This enables interoperability with other affect lexicons, such as WordNet-Affect, SentiWordNet or GermanPolarityClues are also aligned with WordNet. Moreover, WordNetDomains has been used to define the domain of the lexical entry.Lexical entries are aligned with Linked Data entities in datasets such as DBPedia. None of the reviewed affect lexicons provide this feature yet, except for SenticNet 3.0.Most of the affect lexicons assign prior polarities or emotions to lexical entries, with the exception of SenticNet, that uses multi-word expressions (i.e. small room). The use of multi-word expressions is also possible in lemon (e.g. Siamese_cat), which provides a formalism for describing its decomposition into their component words.Onyx is extensible and the same formalism can be used for different emotion descriptions and it is not tied to a particular emotion representation, as the other affect lexicons. Following the EmotionML model, Onyx uses pluggable ontologies (vocabularies) that complement the central ontology.This formalism has been used to generate the Eurosentiment dataset as detailed in Gabriela et al. (2014a) and Sánchez-Rada, Vulcu, Iglesias, and Buitelaar (2014). This dataset is composed of fourteen domain-specific opinion and emotion lexicons covering six languages (German, English, Spanish, Catalan, Portuguese and French) and two domain (Hotels and Electronics) as shown in Table 5.One common use case for affective technologies (Baggia et al., 2014) is the annotation of material involving emotionality, such as texts, videos or speech recordings.Onyx has been used for emotion annotation of corpora as described in Gabriela et al. (2014a), Gabriela et al. (2014b), and Sánchez-Rada et al. (2014).6A tool for translating other formats to Eurosentiment is available at http://eurosentiment.readthedocs.org/en/latest/corpusconverter.html.6An overview of this lexical resources is provided in Table 6.These corpora were used as gold standard for the evaluation of the services in the Eurosentiment (Sánchez-Rada et al., 2014) pool. The evaluation material is publicly available7https://github.com/EuroSentiment/evaluation.7and can be used as an example of evaluating semantic emotion analysis services using semantic resources in Onyx.Defining a common service API and format is important for interoperability between services and to boost the ecosystem of emotion analysis services. This section shows how this can be achieved through a combination of NIF, originally intended for NLP services, and Onyx for annotation of emotion.NLP InterchangeFormat (NIF) 2.0 (Hellmann, 2013) defines a semantic format and API for improving interoperability among natural language processing services. The classes to represent linguistic data are defined in the NIF Core Ontology. All ontology classes are derived from the main class nif:String which represents strings of Unicode characters. One important subclass of nif:String is the nif:Context class. It represents the whole string of the text and is used to calculate the indices of the substrings. There are other classes (nif:Word, nif:Sentence, nif:Phrase) for representing partitions of a text. NIF individuals are identified by URIs following a nif:URIScheme which restricts URI’s syntax. NIF can be extended via vocabularies modules. It uses Marl for sentiment annotations and Onyx have been proposed as a NIF vocabulary for emotions.In addition, NIF defines an input and output format for REST web services in the NIF 2.0 public API specification. This specification defines a set of parameters that should be supported by NIF compliant services.Listing 4 shows the output of a service call with the input parameter value “My IPad is an awesome device”.8More details about the service output of sentiment and emotion services based on NIF, Marl and Onyx can be found at http://eurosentiment.readthedocs.org/en/latest/format/servicesformat.html.8The main benefit of using NIF for emotion services is that NIF compliant services can be easily combined as shown in the NIF combinator (Hellmann, Lehmann, Auer, & Nitzschke, 2012),9The NIF combinator is available at http://demo.nlp2rdf.aksw.org/.9where well known NLP tools are combined thanks to the use of NIF wrappers.To demonstrate the creation of an emotion analysis service using this specification, we developed a proof-of-concept web service on top of the Synesketch (Krcadinac, Pasquier, Jovanovic, & Devedzic, 2013) library.Synesketch is a library and application that detects emotions in English texts and generates images that reflect those emotions. Originally written in Java, it has been unofficially ported to several programming languages (including PHP), which shows the interest of the community in this tool. The aim of the PHP port was, among others, to offer a public endpoint for emotion analysis, which later had to be taken down due to misuse. The relevance of this tool and its Open Source license were the leading factors in choosing this tool. The service can be accessed via a REST API and its results are presented in Onyx, using the RDF format.The Synesketch library uses the six categories of emotion proposed by Ekman (1999). This model is included among the vocabularies of EmotionML under the name big6, and can be represented in Onyx as shown in Section 3.2.2. Each emotion is present in the input text with a certain weight that ranges from 0 to 1. Additionally, it has two attributes more that correspond to the general emotional valence (positive, negative or neutral) and the general emotional weight. These two attributes together show how positive, negative or neutral the overall emotion is.The Synesketch weight directly maps to hasEmotionIntensity in Onyx. However, the general emotional valence and weight do not directly match any Onyx property or class. To solve it, we simply add an AggregatedEmotion to the EmotionSet with the PositiveEmotion, NeutralEmotion or NegativeEmotion category (as defined by WordNet-Affect) depending on the value of the valence. The general emotional weight is then the intensity of this AggregatedEmotion, just like in the other cases.The final result is a REST service that is publicly available at our website.10http://demos.gsi.dit.upm.es/onyxemote/.10Several other implementations have been developed in the context of the Eurosentiment project, mainly as wrappers of already existing resources. The majority of them uses the WordNet-Affect categories, although there are some that required the specification of ad-hoc categories.Some of the potential benefits of the use of ontologies (Schröder, 2011) are: mapping between different emotion representations, the definition of the relationship between concepts in an emotion description, and emotion composition. Each of these topics is a subject of study in its own right. However, we want to illustrate how Onyx’s semantic approach could be used in this direction. In particular, we will focus on SPARQL Inference Notation(SPIN)11http://spinrdf.org/spin.html.11rules.SPIN is a powerful tool to create rules and logical constraints to any entity using standard SPARQL queries. It does this by using a set of RDF classes and properties defined in its specification. For our purposes, the simplest use of SPIN is to attach a SPARQL query (rule from now on) to a certain class, so that it is performed on entity creation, update or deletion. What is interesting about SPIN is that it has mechanisms to generalize this procedure, and to create templates from these rules so that they can be applied to several classes. An Open Source Java API12http://topbraid.org/spin/api/.12is also publicly available which can be used to test the examples in this section.Exploring the full potential of SPIN is out of the scope of this paper. However, we will cover two ways in which Onyx and SPIN can be used together to provide more flexibility than any non-semantic approach could. For the sake of clarity, we will only include the relevant rules that should be used in each case, rather than the complete SPIN RDF excerpt.The first example (Listing 5) shows the rule that should be added to the EmotionSet class in order to infer a complex Plutchik emotion from two basic ones. In particular, it annotates an emotion with the Optimism category if it is already annotated with Anticipation and Joy. The query also shows how to add new entities and specifying their URIs using a random identifier and the base URI.The second example (Listing 6) assigns an emotional category based on dimensional values. It takes as an example the Hourglass of Emotions (Cambria et al., 2012a) model where second-level emotions can be expressed as a combination of two sentic levels. In this case, a positive level of attention and pleasantness results in optimism. Its dimensions and the main emotional categories have been represented with Onyx (Section 3.2.3).Finally, by using these two rules together and a simple mapping of both hourglass’ and Plutchik’s Optimism categories, it is possible to find optimistic results among entries annotated using Plutchik’s basic categories and entries annotated using the dimensions from the Hourglass of Emotions.

@&#CONCLUSIONS@&#
With this work we have introduced the Onyx ontology, which can represent emotions taking advantage of the work conducted in theWeb of Data (Linked Data) and in emotion research community (EmotionML). The ontology is extendable through pluggable vocabularies that enable its adaptation to different emotion models and application domains.This paper discusses several applications and use cases, such as the emotion annotation of lexical entries and corpora, the specification of inter-operable emotion analysis services, as well as the definition of emotion mappings. To this end, Onyx has been linked with vocabularies such as lemon, NIF and the Provenance Ontology. One remarkable example is the role of Onyx in the R&D European project Eurosentiment,13http://eurosentiment.eu.13whose aim is the creation of a language resource pool for Sentiment Analysis. As a result, a set of lexical resources are publicly available annotated with Onyx.A key factor for the adoption of proposals such as Onyx is its use and extension by the emotion research community. To this end, the W3C Community Group Linked Data Models for Emotion and Sentiment Analysis14http://www.w3.org/community/sentiment/.14has been set up with participants from industry and academia. We hope that it will contribute to the evolution of Onyx, shaping it to address the issues arising from feedback of the community. The next step for Onyx is to go beyond the applications in this paper (Section 4) and be leveraged in state-of-the-art sentiment analysis applications. As a start point, it could be used in any of the several sentiment analysis challenges available. In particular, it is a perfect fit for semantic sentiment analysis challenges such as SemEval.15SemEval’s sentiment analysis track: http://alt.qcri.org/semeval2015/index.php?id=tasks.15For the most part, Onyx relies on the main elements introduced by EmotionML. That seems to be the case with HEO as well, which explains the similarities between both ontologies. Given these similarities, we will discuss some of the differences between both ontologies that justify the use of Onyx.First and foremost, Onyx intends to be a model as generic as possible. It has been integrates with other ontologies, When in doubt about a property or concept, we chose to leave it outside the ontology and link to other vocabularies (e.g. OpenAnnotation (Ciccarese, Soiland-Reyes, & Clark, 2013), NIF (Hellmann et al., 2012)). It also integrates perfectly with the provenance ontology, adding great value to the ontology. Although HEO also provides a generic model of emotion, it is tailored to a specific use case and includes concepts that would now be better expressed with other ontologies. For instance, Open Annotation or Prov-O for annotation. The fact that Onyx follows an approach analogous to Marl also facilitates the integration of Opinion and Emotion, which is crucial for sentiment analysis.There are other practical differences between the wo, such as action tendencies and appraisal being properties in Onyx. This reduces the number of nodes necessary for annotation, and makes annotations more convenient.These differences prove that HEO and Onyx are actually very different. Not only on the ontological level, but also in approach. We believe Onyx was a missing piece in the Linked Data puzzle, it integrates with other ontologies and covers aspects that no other ontology for emotions did.Moreover, the presented applications show the applicability and usefulness of the ontology. Using the concepts shown in Section 4.4, it would be possible to combine resources that use different emotion models. For instance, an application could leverage the power of WordNet-Affect (Strapparava et al., 2004), EmoLex (Mohammad & Turney, 2013) (Plutchik’s categories) and DepecheMood (Staiano et al., 2014) (Ekman’s categories).As future work, we will study how emotion synthesis and emotional embodied conversational agents can be applied in e-learning. In particular, our aim is to explore how conversational agents can benefit from integration of semantic, emotion and user models for improving user engagement. There are two interesting aspects in this sense. The first one is using a behavioral model based on emotions to interact with students on a deeper level. For this, we will build on our experience with conversational agents and make use of Onyx annotations to reason about emotions. The second one is trying to gain a better understanding of students. This analysis will build on the concepts in Section 4.4 to use various models that characterize different aspects of emotions.