@&#MAIN-TITLE@&#
Solving nonlinear principal-agent problems using bilevel programming

@&#HIGHLIGHTS@&#
We show that the principal agent problem is a bilevel nonlinear program.We develop a numerical nonlinear principal agent problem (not tractable to solve in closed form).We solve the problem using the ellipsoid algorithm.We approximate LEN model and show that LEN does not closely approximate our numerical results.We conclude that our method can provide insights not achievable with LEN or closed form solutions.

@&#KEYPHRASES@&#
Agency theory,Compensation contracts,Performance measures,Nonlinear optimization,Principal-agent problems,Bilevel nonlinear programming,

@&#ABSTRACT@&#
While significant progress has been made, analytic research on principal-agent problems that seek closed-form solutions faces limitations due to tractability issues that arise because of the mathematical complexity of the problem. The principal must maximize expected utility subject to the agent’s participation and incentive compatibility constraints. Linearity of performance measures is often assumed and the Linear, Exponential, Normal (LEN) model is often used to deal with this complexity. These assumptions may be too restrictive for researchers to explore the variety of relationships between compensation contracts offered by the principal and the effort of the agent. In this paper we show how to numerically solve principal-agent problems with nonlinear contracts. In our procedure, we deal directly with the agent’s incentive compatibility constraint. We illustrate our solution procedure with numerical examples and use optimization methods to make the problem tractable without using the simplifying assumptions of a LEN model. We also show that using linear contracts to approximate nonlinear contracts leads to solutions that are far from the optimal solutions obtained using nonlinear contracts. A principal-agent problem is a special instance of a bilevel nonlinear programming problem. We show how to solve principal-agent problems by solving bilevel programming problems using the ellipsoid algorithm. The approach we present can give researchers new insights into the relationships between nonlinear compensation schemes and employee effort.

@&#INTRODUCTION@&#
From a management control perspective it is important to determine appropriate compensation systems to maximize the objectives of the principal. The principal’s objective is to maximize his utility (generally profit). This is constrained by the agent’s utility, where the agent generally tries to minimize effort and risk. The tension between the two is resolved via a contract where the principal decides on the compensation contract and the agent decides the effort he is willing to put in based on the contract. This is the general principal-agent problem.Analytic research on principal-agent problems that seek closed-form solutions faces limitations due to tractability issues that arise because of the mathematical complexity of the problem. These limitations have led to a rich body of methodological work that attempts to find ways around the tractability problem. These procedures typically use simplifying assumptions. These include the use of the first best solution, the use of first order conditions, and those that are essential for the use of the Linear, Exponential, Normal (LEN) model (e.g., Holmstrom and Milgrom, 1987; Feltham and Xie, 1994; Lambert, 2001; Hemmer, 2004; Demski et al., 2008). Some of these assumptions are useful, but others are not applicable in many settings as will become clear in Section 5.Linearity of performance measures is one of the major assumptions made to improve the tractability of solutions for many agency problems. See Lambert (2001) for numerous references where authors make it clear that the assumptions regarding linear combinations of performance measures are chosen mainly for tractability purposes. In Section 2 below we introduce the vector y of performance measures. In this paper we show that relaxation of these linearity assumptions leads to richer models that provide new insights into the complex relationships between compensation contracts and employee effort. Another issue is that closed form mathematical solutions, while very valuable in providing many economic insights, may have their limits (due to tractability issues) in extending our understanding of the complex relationship between contracts (compensation schemes) and effort. Lambert (2007, p. 250) states, “One of the primary reasons that agency literature is running out of steam is the inability of researchers to set up interesting models that are tractable enough to be solved”. On the same page, Lambert also states, “In other fields, numerical solutions or simulation analysis is a common solution technique. These solutions should at least be considered by researchers in accounting as well”. One of the main goals of this paper is to show how to use optimization methods to numerically solve nonlinear principal-agent problems.Specifically, we view principal-agent problems as bilevel nonlinear programming problems and obtain solutions using the ellipsoid algorithm, see for example, Bland et al. (1981) and Ecker and Kupferschmid (1983). We chose the ellipsoid algorithm because it is simple, robust, and does not easily get trapped at local maximizing points (see Ecker and Kupferschmid, 1985). Dempe (1995) modeled a convex agency problem using bilevel programming but did not solve the problem numerically (although a solution methodology was suggested). In our models, we make no prior convexity assumption or linearity assumptions.The rest of the paper is organized as follows. In Section 2 we present the general structure of a principal-agent problem. In Section 3 we explain some of the difficulties in solving the principal agent problem and then explain some linearity assumptions (including the LEN model) and some problems inherent in these assumptions. In Section 4 we introduce a nonlinear model. In Section 5 we discuss numerical results for our basic model and provide some insights that can be deduced from our results. In this section, we also compare the results using our nonlinear model with those obtained using our version of a LEN model. Conclusions and future work are given in Section 6.Of the several problems facing management in the process of developing effective performance measures, the two most difficult ones are that principals cannot directly observe agents’ effort (actions) and that events outside of the agents’ control can influence the measured outcomes (Feltham and Xie, 1994). These and other confounding problems make the principal’s selection of a contract difficult. Nevertheless, agency theory provides an important framework to model links between information, incentives, and performance of the agent and the principal, when both act in their own interests, to explore the implications of non-observable actions and uncontrollable events.A principal-agent problem can be described as follows. The principal determines the contract s, which is a function of a vector of performance measures. We consider two measures, y1 and y2 for expository purposes. These measures can be observed by both the principal and the agent. The agent then selects an action (effort) a. We also use a single action for expository purposes but discuss in our conclusions section that extensions may be made to include more performance measures and actions. The agent is risk and work averse and the principal and agent both consider to be random variables with a joint probability density function,f(y1,y2|a).The principal’s gross return x results from the action a and the agent is compensated based on the performance measures. y1 and y2. The agent is paids(y1,y2)and the principal keeps the residual, x−s(y1,y2). The principal’s expected profit is denoted by E[x−s(y1,y2)]. We assume the principal always prefers more to less and is risk neutral. Therefore, the principal’s utility function is equivalent to expected profit. The principal wishes to maximize expected profit while offering the agent some acceptable level, H, of expected utility. The agent has a negative exponential utility function U and the agent’s utility for the contract contains two components, the utility gained from the expected value of the compensation and the cost incurred for exerting effort. The agent’s compensation is denoted bys(y1,y2)and his utility for the compensation is given by U(s(y1,y2)). Given the density function,f(y1,y2|a)the expected value of the agent’s utility for compensation becomes:E[U(s(y1,y2))]=∬U(s(y1,y2))f(y1,y2|a)dy1dy2Let V(a) be the agent’s disutility of effort. The agent must ultimately select an action a to maximize his utility function, which includes both his utility for compensation and disutility for effort and is denoted mathematically as: E[U(s(y1,y2))]−V(a). The principal’s problem then becomes:(1)maximize∬[(x-s(y1,y2)]f(y1,y2|a)dy1dy2subjectto∬U(s(y-1,y2))f(y1,y2|a)dy1dy2-V(a)⩾H(2)andtheconstraintthatasolvesmaximizea∬[(x-s(y1,y2)]f(y1,y2|a)dy1dy2-V(a)(3)The principal’s problem is an instance of a bilevel nonlinear programming problem. This fact is crucial to our ability to solve numerical instances of this problem, which is the primary contribution of this paper. For a comprehensive review of the fundamentals of bilevel programming, see Dempe (2002).Constraint (2) assumes the agent will not participate unless an acceptable utility level H is offered by the principal. Constraint (2) is called the participation constraint and H is called the reservation wage for the agent. Requiring a to solve (3) is called the incentive compatibility constraint. The incentive compatibility constraint represents the link between the contract chosen by the principal and the agent’s action that maximizes the agent’s expected utility. Given the contracts(y1,y2)offered by the principal, the expected profit for the principal depends on the value of a that satisfies the incentive compatibility constraint (3). As pointed out by Lambert (2001), this constraint is not very tractable, making the principal’s problem difficult to solve. In this paper, we present a method for numerically solving principal-agent problems that deals directly with the incentive compatibility constraint and eliminates the need for the many simplifying assumptions (discussed in Section 3) that are used to make the problem more tractable.In the next section we explain the LEN model and other simplifying assumptions commonly found in the literature along with some of their inherent weaknesses.Due to the complexity of the incentive compatibility constraint (3), solutions to agency problems are very difficult to obtain because the principal has to solve an optimization problem (3) within an optimization problem (1). As a result many simplifying assumptions have been proposed. The problem with these assumptions is that they restrict the scope of problems that may be explored within the agency framework. One approach is to consider a finite set of actions available to the agent and model the incentive compatibility constraint (3) as a set of inequality constraints (Grossman and Hart, 1981). The problem with this approach is that it is often difficult to generate solutions that are easy to express (Lambert, 2001). Another approach is to use the “first best” solution as a benchmark for exploring agency relationships (Lambert, 2001). In using the “first best” solution, a contract is chosen to maximize the principal’s utility subject to the agent’s acceptable utility level H, where the agent’s incentive compatibility constraint (3) is not explicitly considered. Using another approach, Banker and Datar (1989) replace Eq. (3) with the first order condition, and set it equal to zero to make the analysis more tractable. Here the agent’s optimal choice is restricted to one where the derivative of his expected utility with respect to effort is set equal to 0. As such, the optimal contract is fairly easy to derive if the agent’s expected utility is a concave function of actions and the contract is linear. There is a wide class of contracts for which the “first order” solution works. However, for more complicated contracts where the agent’s utility is not a nice concave function of effort and the contract is nonlinear, the first order approach is problematic (Lambert, 2007, p. 251). A common bonus contract where the agent is compensated via salary and bonus, where the bonus is achieved when a certain target is met, otherwise the bonus is 0, is an example of a nonlinear contract. This is not a well-behaved linear function of agent action. Lambert (2007) illustrates the problems with a similar options contract where the agent’s compensation is actually a convex function of agent effort.Holmstrom and Milgrom (1987) develop a more tractable formulation of the agency model to address multiple action and multiple agent problems. Their method is commonly known as the Linear-exponential- normal (LEN) model. In a LEN model, the contracts(y1,y2)in the above principal-agent problem (1)–(3) is assumed to be a linear function of the performance measures y1 and y2 (Lambert, 2001). In a LEN model, the agent is assumed to have a negative exponential utility function and the performance measures are assumed to be random variables with a bivariate normal distribution. In our basic model presented in Section 4 we also make these last two assumptions. The only difference between our basic model and a LEN model is that our contracts are nonlinear functions of the performance measures y1 and y2 instead of linear contracts used in a LEN model.The assumptions of LEN allow the agent’s expected utility (Eq. (3)) to be transformed into a more tractable measure, a certainty equivalent (see Lambert, 2001 for an overview of LEN). The resulting measure is the expected compensation plus the cost of bearing the risk. The agent’s certainty equivalent simplifies the task by eliminating the variance terms among the measures and actions. Taking this approach the agent’s first order condition further simplifies the problem such that the principal’s problem can be expressed without any constraints and can be solved in closed form (Lambert, 2001).Although well accepted as an important methodological tool, LEN is not without its controversy. Hemmer (2004) argues that while LEN is simple, elegant, and allows for closed form solutions, it is limited when not grounded in the dynamic model proposed by Holmstrom and Milgrom (1987, 1991), which is founded on Brownian motion. Various assumptions have to hold for this dynamic model to work. While the LEN model is more tractable and enables researchers to solve interesting problems that would not heretofore be possible to solve with nonlinear contracts, the LEN is restrictive in terms of the assumptions that form the basis of its applicability. The assumption we relax in this paper is the assumption of the linear contract.In practice, there are both linear and nonlinear contracts. A common example of a nonlinear contract is a bonus contract where the bonus is paid only after a certain number of units have been sold. Common bonus as well as stock option contracts are nonlinear since they are piecewise linear. In Section 4, we develop our basic model with nonlinear contracts having breakpoints (thresholds) q after which a bonus is paid to the agent.In practice there is both linear and nonlinear aggregation of performance measures in contracts. If y1 and y2 are performance measures then an example of a linear aggregation could be weighted values of y1 and y2 (for example 2y1+3y2). The linear aggregation assumption is made in many papers (e.g., Holmstrom and Milgrom, 1987; Banker and Datar, 1989; Feltham and Xie, 1994; Evans et al., 2006; Demski et al., 2008). An example of nonlinear aggregation is one where the two performance measures are multiplied together, such as when is y1 number of units sold and y1 is contribution margin per unit. The product of these performance measures y1y2 is the total contribution margin and this product is a nonlinear aggregation. Our basic model presented in Section 4 below involves nonlinear contracts and nonlinearly aggregated performance measures. For different values of the breakpoint q, we solve these principal agent problems numerically in lieu of providing the traditional closed form analysis that is often difficult, if not impossible, to obtain. In the next section we explain our basic model and our solution method in detail.In this section, we present an example of a single-period, single-action agency model with two performance measures that are defined below. Because we are interested in numerical solutions, we need to develop a specific and realistic model. It is important to use appropriate units because the quantities involved and the variables used are not dimensionless. For example, the expected profit for the principal is measured in dollars and the expected utility and the disutility of effort for the agent needs to be measured in dollars.In our basic model that we use to illustrate our approach to solving agency problems, the principal is the owner of a car dealership that sells one type of car and the agent is a salesperson. The contribution margin is the difference between the selling price and variable cost of the car. As in many agency relationships, the principal cannot directly observe the agent’s effort but can view performance measures that are correlated with that effort. The model has two performance measures that the principal and agent can observe. These measures are:y1=average contribution margin obtained by the agent for all cars sold andy2=the number of cars sold in a weekThese two performance measures of the agent’s action have a negative correlation since the agent can sell more cars by allowing y1 to be smaller. We assume that y1 and y2 are random variables having a bivariate normal density function with a negative correlation coefficient. We assume the sticker price on the car is $5000 above cost. The agent cannot sell a car for more than the sticker price or below cost so we truncate the density so that 0⩽y1⩽5000. In the discussion below, we also truncate. We assume that the principal can control three variables r, b, and q and where:r=the fraction of the total contribution margin that the principal pays the agent,b=bonus in dollars per car sold that the principal pays the agent, andq=the target above which the agent receives a bonus for each car sold.Note that y1 is just the sum of all contribution margins for all the cars sold divided by y2. Therefore, y1y2is the total contribution margin for all the cars sold. The principal pays the agent a fraction of this amount, namely ry1y2. In addition, the principal pays the agent a bonus of b dollars for every car sold above a target (or breakpoint) q. Thus, in our basic model, the contract determined by the principal is given by s(y1,y2)=ry1y2+b max(y2−q,0), which is a nonlinear contract with a nonlinear aggregation of measures. The gross income for the principal is x=y1y2 and the principal’s profit Z becomesZ=x-s(y1,y2)=y1y2-(ry1y2+bmax(y2-q,0)The principal wants to maximize the expected value of the profit, namely, P=E(Z). The agent has a single action denoted by the variable a for effort. In this application, a=agent’s effort in minutes worked each 5day work week, so 0⩽a⩽2400. The agent has a negative exponential utility function U(y1,y2) for the contract s(y1,y2) with U(w)=1800(1−e−ρw) where w=s(y1,y2)=ry1y2+b max(y2−q,0) and the coefficient of risk aversion is given by ρ=1/1000, a typically small value that is commonly used in the literature, Demski (1997, p. 466). The constant 1800 comes from the fact that the agent’s utility is measured in dollars and we assume that the agent makes $1800 per week.The agent also has a disutility of effort measured in dollars given by V(a)=ka2 for some constant k. Effort a is measured in minutes so the constant k must be measured in dollars per minutes squared. We need a numerical value for k and cannot use k=1/2 that is typically used for the dimensionless closed form analyses considered in the literature. If the agent makes $1800 per week then k would have to satisfy 1800=k(2400)2 yielding k=1800/24002=.0003. But if the agent makes $1000 or $750 per week then we obtain k=.0002 or k=.0001, respectively. In our model, we use k=.0002 and let V(a)=.0002a2. For the constant H in the participation constraint (2) in Section 2 we assume that H=500 dollars. In Section 5, we discuss the sensitivity of solutions to the value of H.Given r and b set by the principal, the agent wishes to maximize expected utility minus disutility of effort, namely A=E(U(y1,y2))−V(a). The random variables y1 and y2 depend on the effort a of the agent and this is determined by the mean values used in the bivariate normal density function F(y1,y2∣a) given byF(y1,y2|a)=12πσ1σ21-p2e-12(1-p2)y1-μ1σ12-2p(y1-μ1)σ1(y2-μ2)σ2+y2-μ2σ22Here, p is the correlation coefficient and, because y1 and y2 are negatively correlated, we use p=−1/2. The random variables y1 and y2 have means of μ1 and μ2, respectively. The parameters σ1 and σ2 are the standard deviations of y1 and y2. In our model, we use σ1=8 to allow for a slightly wider range of selling prices, y1, around the mean μ1 than would occur with σ1=1. We use σ2=1 so that the values of y2 are more tightly clustered about the mean number of cars sold.μ2Thus, in our model y1 is a more noisy measure of agent’s effort than y2.In the bivariate density function, F(y1,y2∣a), we truncate y2 so that 0⩽y2⩽μ2+3σ2 to give a wide range of values for the random variable y2. Since 0⩽y1⩽5000, we scale the above function F(y1,y2∣a) by calculatingc=∫0μ2+3σ2∫05000F(y1,y2|a)dy1dy2and then we use the resulting truncated density function f(y1,y2∣a)=(1/c)F(y1,y2 ∣a) to calculate expected values.In our model, we assume that the mean μ1=2500, the midpoint between $0 and the maximum possible contribution of $5000 per car sold. If the agent sells 6 cars a week (2400min) on average, then we assume thatμ2=1400asince.14002400=6The density function f(y1,y2∣a) depends on the variable a and the contract s(y1,y2)=ry1y2+b max(y2−q,0) depends on the variables r and b. The value of the principal’s expected profit P=E[x−s(y1,y2)]=E[y1y2−(ry1y2+bmax(y2−q,0)] depends on the variables r, b, and a.A=E(U(y1,y2))-V(a), The value of, the agent’s expected utility minus the agent’s disutility of effort, also depends on r, b,and a. Given fixed valuesr¯andb¯determined by the principal, the agent wants to maximizeA(r¯,b¯,a)over the variable a. The principal offers the agent some acceptable level of expected utility by using the constraint A(r,b,a)⩾H. We also constrain, r, b and a using the simple bounds 0⩽r⩽1, 0⩽b⩽5000, and 0⩽a⩽ 2400, where the upper bounds on r, b, and a are 100% of the contribution of a sale, the maximum selling price possible, and the number of minutes in a work week, respectively. The principal’s problem then becomes the following nonlinear bilevel maximization problem.(4)maximizer,b,aP(r,b,a)subjecttoA(r,b,a)⩾H0⩽r⩽1and0⩽b⩽5000andtheconstraintthatasolvesmaximizeaA(r,b,a)subjectto0⩽a⩽2400More explicitly, given the contract s(y1,y2)=ry1y2+b max(y2−q,0), the principal’s net profit is given by x−s(y1,y2) where x=y1y2 and the principal’s expected profit is given by(5)P(r,b,a)=∫0μ2+3σ2∫05000[y1y2-s(y1,y2)]f(y1,y2|a)dy1dy2The agent’s expected utility minus the agent’s disutility is given by(6)A(r,b,a)=∫0μ2+3σ2∫050001800[1-e-s(y1,y2)/1000]f(y1,y2|a)dy1dy2-.0002a2For given values of r and b, in order to evaluate the functionP(r,b,a)or to see if the constraint A(r,b,a)⩾H is satisfied, the value of the variable a is needed. For fixed values of r and b, the corresponding value of a is obtained by using the ellipsoid algorithm to solve the agent’s “inner problem” that is enclosed in the square brackets in (4).r=r¯andb=b¯When and, the inner problem becomes(7)maximizeaA(r¯,b¯,a)subjectto0⩽a⩽2400To discuss the details our algorithm for solving the principal agent problem (4), it will help to have a brief description of the ellipsoid algorithm for solving problems of the form:minimizef0(z)subjecttoz∈S=z∈Rn|fi(z)⩽0,i=1…mFor a maximization problem, we can equivalently minimize the negative of the objective function. The method assumes that there exists an optimal point z∗∈S and that an initial ellipsoidE0=z∈Rn|(z-z0)TQ0-1(z-z0)⩽1centered at z0 with a symmetric positive definite matrix Q0 can be found with z∗∈E0.The Ellipsoid Algorithm:Step 0. Select a starting point z0 and a symmetric positive definite matrix Q0 with z∗∈E0. Set k=0Step 1. Let fvbe a constraint function for which fv(zk)>0 or the objective function f0(z) if fi(zk)⩽0, i=1…m. Calculate the gradient gkof fvat zk. If gk=0, STOP because zkis a minimizing point. Calculated=-Qkgk/gkTQkgkprovidedgkTQkgk>0, otherwise STOP.Step 2. Letzk+1=zk+1n+1dandQk+1=n2n2-1Qk-2n+1ddT. Return to Step 1 with k+1 replacing k.Given gk, the ellipsoid Ek+1 determined by Qk+1 and centered at zkis actually the ellipsoid of minimum volume containing the half of the ellipsoid EkwheregkTz⩽gkTzkas indicated in Fig. 1(see Bland et al., 1981).The ellipsoid algorithm is an n dimensional generalization of the bisection method. We should note that our code for the algorithm is written so that when the number of variables is equal to one, the algorithm is the bisection method for maximizing a function of a single variable. The initial matrix Q0 can be generated as a positive definite diagonal matrix using bounds on the variables known to bracket a minimizing point. When all the functions fi(z),i=0…m are convex the ellipsoid algorithm is known to converge to a global optimal point, see Goffin (1983). However, the ellipsoid algorithm is remarkably robust in finding global optimal solutions for optimization problems where not all of the functions are convex. In Ecker and Kupferschmid (1983), numerical results on using the ellipsoid algorithm on 50 well studied test problems are presented. Of the 50 test problems, 37 were not convex problems but the ellipsoid algorithm converged to the known global solution on each of the 50 test problems.We will now consider important details showing how we use the ellipsoid algorithm to solve the principal agent problem (4). Letr¯,b¯be a starting point, use the ellipsoid algorithm to find a solutiona¯to the inner problem (7). Ifr¯,b¯,a¯satisfy the constraints(8)A(r,b,a)⩾H,0⩽r⩽1,0⩽b⩽5000then in Step 1 of the ellipsoid algorithm we calculate the gradient ofP(r,b,a¯)with respect to r and b at the pointr¯,b¯. This gradient cannot be calculated analytically and we approximate this gradient using central differencing. It will be convenient to refer to the constraints in (8) as the “outer” constraints.To approximate∂P∂ratr=r¯andb=b¯, we need to evaluate the function P at(r¯+δ,b¯)and at(r¯-δ,b¯)for a small value of δ (in our numerical calculations, we use δ=10−6). But in order to find these function values, we first need to solve the inner problem (7) to find the value of a that solves the inner problem (7) for(r,b)=(r¯+δ,b¯). We also need to solve the inner problem to find the value of a for(r,b)=(r¯-δ,b¯). Let arfbe the value of a that solves the inner problem for the forward point(r¯+δ,b¯)and let arbbe the value of a that solves the inner problem for the backward point(r¯-δ,b¯). Then, using central differencing we obtain∂P∂r≈P(r¯+δ,b¯,arf)-P(r¯-δ,b¯,arb)2δ.Similarly∂P∂b≈P(r¯,b¯+δ,abf)-P(r¯,b¯-δ,abb)2δ,where abfand abbare the values of a that solve the inner problem (7) for the forward and backward points(r¯,b¯+δ)and(r¯,b¯-δ), respectively. In subsequent iterations of the ellipsoid algorithm, we approximate the gradient of P at the current values of r and b in a similar manner. We should note that the ellipsoid algorithm typically converges to the correct optimal solution (for well-studied test problems whose correct optimal solutions are known) even if the gradients and function values are calculated imprecisely, see Ecker and Kupferschmid (1987).It is important to note that in order to evaluate P(r,b,a) or A(r,b,a) for any values of r, b, and a, the double integrals in (5) and (6) need to be evaluated. For these integrals, the integration with respect to y1 can be calculated analytically using the computer algebra system Maple. Details of this integration are presented in Appendix A.For both (5) and (6), we numerically evaluate the remaining single integral with respect to y2 using an adaptive Simpson’s rule approach, see Burden and Faires (1993) for details and examples.Ifr¯,b¯,a¯does not satisfy the outer constraints (8), then in Step 1 of the ellipsoid algorithm, the gradient of the violated constraint needs to be calculated. If one of the simple bound constraints is not satisfied, then the gradient can be calculated directly. However, if the constraint A(r,b,a)⩾H is violated, then the gradient ofA(r,b,a¯)with respect to r and b at the pointr¯,b¯needs to be calculated. This gradient cannot be calculated analytically and we approximate∂A∂rand∂A∂batr¯,b¯using central differencing as illustrated above for P.Finally, givenr¯,b¯, in order to solve the inner problem (7) using the ellipsoid algorithm, the gradient (derivative) ofA(r¯,b¯,a)needs to be calculated and we approximate this by∂A∂a≈A(r¯,b¯,a+δ)-A(r¯,b¯,a-δ)2δ. If one of the two constraint inequalities in (7) is violated, then that gradient need not be approximated and can be calculated directly.With the above background we can now present more details of our algorithm.First, we replace maximize P(r,b,a) with minimize−P(r,b,a) and write the outer constraints (8) in the form(9)r-1⩽0,-r⩽0,b-5000⩽0,-b⩽0,-A(r,b,a)+H⩽0to obtain the same problem format we used in the above ellipsoid algorithm discussion.Note that the variable a depends on r and b because a is the solution to the inner problem (7) for a given r and b. In the algorithm description below, it will be convenient to refer to a function called finda(r,b). The function finda(r,b) returns the value of a that solves the inner problem for the given r and b. As shown in Ecker and Kupferschmid (1985, 1987), convergence of the ellipsoid algorithm is very robust with respect to the starting point.The ellipsoid algorithm for solving the principal agent problem (4):Step 0. Select a starting point (r0,b0) satisfying the bounds given in (9). Let E0 be an ellipsoid containing {(r,b)∣0⩽r⩽1,0⩽b⩽5000} with symmetric positive definite matrix Q0.Let a0=finda(r0,b0). Set δ=10−6 and set k=0,Step 1. Find the gradient of the first violated constraint in (9) at (rk,bk,ak)if r−1⩽0 is not satisfied at (rk,bk,ak),gk=10else if −r⩽0 is not satisfied at (rk,bk,ak),gk=-10else if b−5000⩽0 is not satisfied at (rk,bk,ak),gk=01else if −b⩽0 is not satisfied at (rk,bk,ak),gk=0-1end ifLet arf=finda(rk+δ,bk),arb=finda(rk−δ,bk)abf=finda(rk,bk+δ),abb=finda(rk,bk-δ)if −A(r,b,a)+H⩽0 is not satisfied at (rk,bk,ak)gk=-A(rk+δ,bk,arf)/2+A(rk-δ,bk,arb)/2-A(rk,bk+δ,abf)/2+A(rk,bk-δ,abb)/2otherwise, all constraints are satisfied at (rk,bk,ak), andgk=-P(rk+δ,bk,arf)/2+P(rk-δ,bk,arb)/2-P(rk,bk+δ,abf)/2+P(rk,bk-δ,abb)/2Calculated=-Qkgk/gkTQkgkStep 2. Setrk+1bk+1=rkbk+13dandQk+1=43Qk-23ddTReturn to Step 1 with k+1 replacing k.As a starting point for our numerical results, we used the contract s(y1,y2)=ry1y2+b max(y2−q,0) with q=0 so the agent is paid a bonus for every car sold. The ellipsoid algorithm obtained the following solutionr∗=.1057,b∗=0,a∗=1295.46,P∗=7232,A∗=672It is surprising that the optimal bonus is b∗=0. However, the fact that the bonus at the maximizing point is b∗=0 is consistent with the fact that when q=0 the contract becomes s(y1,y2)=ry1y2+by2 and the contribution margin y1y2 is more likely to affect profit directly than sales volume. This is interesting because in our model the principal and the agent are maximizing their respective utility functions in a noisy environment where y1 and y2 are random variables modeled by a bivariate normal distribution with a negative correlation. Intuitively, one would think the principal could do better by providing at least some level of bonus based on the number of cars sold (piece rate). Prior research suggests that both performance measures would enter the contract (Holmstrom, 1979). However, the principal is able to find a contract that induces profit-maximizing effort without offering a bonus and instead encouraging the agent to focus on the contribution margin. The negative correlation between y1 and y2 may also be driving this result because the aggregation of y1 and y2 is less noisy than y2 alone.It is well known that a bilevel programming problem is equivalent to maximizing the objective P(r,b,a) over the “inducible region”, see Dempe (2002) and Luo et al. (1996). For our principal-agent problem (4), the inducible region is the set of points (r,b,a) in 3-space where a solves the inner problem for the given r and b set by the principal in (4). Fig. 2shows a slice of the inducible region when b=0 along with contours of the objective P(r,b,a). Fig. 2 shows that if b∗=0 at the global maximizing point, then P(r,b,a) is maximized over the inducible region at the point r∗=.1057.To get a better understanding of how the values of P(r,b,a) change as r and b vary, we plotted a “cloud of points” graph in 3-space. For discrete values of r and b in the range 0⩽r⩽0.2 and 0⩽b⩽250, we calculated the corresponding value of a that solves the inner problem. This allowed us to calculate P(r,b,a) for each of the pairs r and b. Fig. 3gives this cloud of points graph along with the point (r∗,b∗) and another reference point. Fig. 3 shows that the global maximizing point for the principal-agent problem (4) when q=0 is the point (r∗,b∗,a∗) given above with P∗=7232.As suggested by one of the referees, it would be interesting to compare our numerical results to those of a LEN model where the performance measures y1 and y2 are linearly aggregated and the contract is a linear function of y1 and y2. We will make this comparison for various values of the breakpoint q starting with q=0.When q=0, our nonlinear contract is s(y1,y2)=ry1y2+by2. One way to approximate this contract with a linear one would be to replace the random variable y2 in the term ry1y2 with its mean value, μ2. The gross profit for the principal would then be given by y1μ2, namely the average contribution margin over all cars sold times the expected number of cars sold. This gives the linear contract L(y1,y2)=ry1μ2+by2. Replacing s(y1,y2) in (4)–(6) with L(y1,y2), the solution we obtained using our version of the LEN model (henceforth called LEN) was(10)r=0,b=264.77,a=1295.37,P=7239,A=674Recall that our solution using the nonlinear contract s(y1,y2) wasr∗=.1057,b∗=0,a∗=1295.46,P∗=7232,A∗=672.So for q=0 the LEN solution is different from our solution in the optimal values for r and b but the maximum value of P(r,b,a)=7239 is close to our optimal value of P∗=7232. If the optimal values for r and b in the LEN solution (10) are used in the nonlinear contract s(y1,y2), the corresponding value of P is 7229.53 Note that the optimal point for the LEN model is on the same ridge in Fig. 3 as the optimal point for the nonlinear model. So when q=0, the LEN model is a reasonable approximation to our nonlinear model. We will continue this comparison after we present our numerical solutions for breakpoints q≠0.The breakpoints q are integers because y2 is the number of cars sold. When q≠0 in the nonlinear contract s(y1,y2)=ry1y2+b max(y2−q,0), the numerical solutions obtained by the ellipsoid algorithm differ dramatically from the solution obtained when q=0. The rounded off values for the optimal solutions obtained by the ellipsoid algorithm for q=0 through q=5 are given in Table 1.For values of q⩾6, the maximum value of P(r,b,a) is less than 8000 no matter what values are given to r and b. This further suggests that targets should be set so that they are easily achievable as noted in Merchant and Van der Stede (2007) and in our example q⩾6 may not be easily achieved.Table 1 shows that the principal’s expected profit P is maximized at 11,287 when the breakpoint is set at q=4 with 3.5% of the total contribution margin paid to the agent along with a bonus of 2160 for each car sold above 4 cars. We discuss below why the solutions in Table 1 are global maximizing points.The numerical results for the contract s(y1,y2) show that breakpoints play an important role in the bilevel problem (4). When the breakpoint is q=0, the expected profit of the principal is maximized by giving no bonus and letting the profit sharing fraction be r∗=0.1057. But if the principal sets a breakpoint q=1, the expected profit increases to P∗=8621 by letting the share r of the total contribution be zero and giving a bonus of 288 for each car sold above one car. It is not to the principal’s advantage to allow any contribution margin sharing until the breakpoint reaches q=4 where the principal’s expected profit P achieves it overall maximum. For all of the nonzero values of the breakpoint, the constraint A(r,b,a)⩾H=500 is active at the optimal points. Later, we discuss the sensitivity of the optimal value P∗ to the value of H.A comparison of the solutions to the nonlinear model with those of an extended approximation LEN when q≠0 is quite revealing. First, when q≠0, we need to find a reasonable way to approximate the nonlinear contract s(y1,y2)=ry1y2+b max(y2−q,0) with a linear contract. When q=0, we replaced the term ry1y2 with ry1μ2 where μ2 is the mean of the random variable y2 to get a linear contract. When q≠0, we can make the same replacement to get a term linear in y1. But we need to approximate the nonlinear term b max(y2−q,0) with a term that is linear in y2. We assume that the agent sells no more than 10 cars per week. The solid piecewise linear curve in Fig. 4shows the graph of b max(y2−q,0) when q=1 over the interval [0,10].The dotted line passing through the points (0,0) and (10,9 b) is given byl(y2)=9b10y2. If we replace the piecewise linear term b max(y2−1,0) with l(y2) we obtain the linear contractL(y1,y2)=ry1μ2+910by2. In general for any q≠ 0, approximating the nonlinear contract in this manner gives the linear contractL(y1,y2)=ry1μ2+10-q10by2. We did try other ways of obtaining a linear contract. For example, one could construct the line through (0,0) and passing through a point below (10,9 b) so that the area under that line equals the area under the solid line in Fig. 4 over [0,10]. These areas represent the total bonus received by the agent. The numerical results for that approach were not as favorable for LEN as those obtained using the line l(y2).Table 2gives the rounded off optimal values for the solution of the LEN model for values of q=0 through q=5.It is remarkable that for all values of q, the value a∗ that maximizes A(r,b,a) never changes. This demands an explanation and we begin by looking at the definition of A(r,b,a) given in Eq. (6). When the linear contract L(y1,y2) replaces the nonlinear contract s(y1,y2) in (6), we obtain(11)A(r,b,a)=∫0μ2+3σ2∫050001800[1-e-L(y1,y2)/1000]f(y1,y2|a)dy1dy2-.0002a2Below we will show that at the optimal values r∗ and b∗, the double integral in (11) is identical for each value of q. A detailed examination of (11) will show why this is true. We will illustrate this using q=0 and q=3.For example, when q=0, the optimal values of r and b are r∗=0 and b∗=264.7726578. (We used Maple with 50 digits of precision to get the optimal value of b to 10 digits of precision. Details of the Maple code are presented in Appendix B.) The variable b appears in (11) only in the contract L(y1,y2). When q=0, at the optimal values of r and b, L(y1,y2)=264.7726578y2. The integral in (11) with respect to y1 can be calculated analytically using Maple. Appendix A gives the details for calculating A for any values of r, b, and a. When r=0 and b=b0=264.7726578, we obtain(12)A0=∫00.0025a+3w24502π(erf(w1)-erf(w3))(1-e-0.2647726578y2)dy2-0.0002a2where w1,w2, and w3 are given in Appendix A.Note in (12) that1-e-0.2647726578y2=1-e-b0y2/1000.When q=3, the optimal values of r and b, are r=0 and b3=378.2466540.UsingL(y1,y2)=10-q10b3y2in (11) and integrating with respect to y1 gives(13)A3=∫00.0025a+3w24502π(erf(w1)-erf(w3))(1-e-0.2647726578y2)dy2-0.0002a2where w1,w2, and w3 are given in Appendix A.Examining (12) and (13), we see that A3 = A0.Also, becauseL(y1,y2)=10-q10b3y2does not depend on y1, the term1-e-L(y1,y2)/1000is not affected by the integration with respect to y1 and it follows that1-e-0.264772658y2=1-e-10-q10b3y2/1000forq=3.But1-e-0.264772658y2=1-e-b0y2/1000and thus10-q10b3=b0which means thatb3=1010-qb0forq=3.The same analysis shows that for this LEN model,(14)Aq=A0andbq=1010-qb0forq=1,2,3,4,5where bqis the optimal value of the variable b for the breakpoint q.Thus, an unexpected consequence of using LEN is that the inner problem (7) always has the same solution for any r, b, and q. Therefore, when using this linear contract, the principal agent problem (4) is not a bilevel programming problem because given any r and b the optimal value returned by the inner problem is a∗=1295.37 for q=1, 2, 3, 4, 5. Thus solving the principal agent problem (4) is a maximization of P(r,b,a∗) subject to the constraint A(r,b,a∗)⩾H and the bounds on r and b.The relation between bqand b0 given in (14) also explains why the optimal value of P is P∗=7239.26 for each value of q even though the optimal values of b depend on q as shown in Table 2. In the linear contract,L(y1,y2)=ry1μ2+10-q10by2, when the optimal value of b is given by1010-qb0as in (14), then L(y1,y2)=ry1μ2+b0y2 is equivalent to the linear contract when q=0.We still need to investigate how the LEN model solutions compare with the results obtained in Table 1 using nonlinear contracts. For the case q=0, we saw a slight difference in the optimal value of the principal’s expected profit P. For q=1, the LEN model solutions are r∗=0 and b∗=294.19184201. To evaluate P for the nonlinear model at this r∗ and b∗, we solve the inner problem using the nonlinear contract and obtain the corresponding solution a∗=1514. This yields P(r∗,b∗,a∗)=8627 and A(r∗,b∗,a∗)=513. For q=1, Table 1 shows that the nonlinear model gave P∗=8621 and A∗=500. So for q=1, the LEN model optimal values for r and b can be used in the nonlinear model to get a reasonable value for P. However, as q increases this is not the case. Table 3gives the results for other values of q when the LEN solutions are used to find values for P and A in the nonlinear model.Comparing the values of P and A in Table 3 with the corresponding values in Table 1 obtained using the nonlinear model, we see that as q increases the solutions from the LEN model are not good approximations for solutions to the nonlinear model. In particular, the values of r and b for q=2,3,4, and 5, are not even feasible for the nonlinear model because the constraint A(r,b,a)⩾H=500 is not satisfied. However, for a smaller value of H, for example H=300, then the above LEN solution for q=2 would be feasible. To check the sensitivity of solutions to the nonlinear model to the value of H when q=2, we calculated values of P and A for a range of values for b with r=0 as in Table 3. For each value of b to evaluate P and A, we solved the inner problem to get the corresponding value of a, which allows us to evaluate P(r,b,a).If we replaced the constraint A(r,b,a)⩾500 with A(r,b,a)⩾ 300, Table 4shows that the optimal value of P would be near 10178 with A near 372. In fact, solving (4) with the constraint A(r,b,a)⩾300 yields the solution r=0 and b=364 with P=10,179 and A=379. Therefore, if the constraint A(r,b,a)⩾ 300 is used in the nonlinear model, the value of P=10,153 obtained by the LEN model for q=2 in Table 3 is not far from the optimal value of P=10,179 obtained by using the nonlinear model.The above discussion shows that depending on the value of H used, one could argue that for q=0, 1, and 2 the solutions to the LEN model give values of P that are reasonably close to the optimal values obtained using the nonlinear model. To see why the LEN solutions degrade as q increases, it is instructive to look at the graphs of A for the nonlinear model as q increases. For a particular value of q, given r and b optimal for the LEN model, we can graph A over [0,2400]. These graphs for q=0 through q=5 are given in Fig. 5.For q=3, A is maximized when a=2014 with A=98 but this solution is far from being feasible for the nonlinear model. As shown in Fig. 5, for q=4, A is maximized when a=0, so the agent expends no effort and the principal’s expected profit of P=1974 given in Table 3 is far from the optimal value of P=11,287 given in Table 1 for the nonlinear model. The optimal LEN solution for q=5 also has A being maximized at a=0 and the principal’s expected profit is again far from the optimal value of P=10,657 given in Table 1 for the nonlinear model.From this comparison of the nonlinear model with the LEN model, it is clear that the LEN model solutions are not good solutions for the nonlinear model when the nonlinear model uses the constraint A(r,b,a)⩾500. If that constraint is replaced by A(r,b,a)⩾ 300, one could argue that the LEN solutions are reasonable approximations to the nonlinear model solutions for q⩽2 but not for q⩾3.Finally, we should note that the principal’s expected utility function P(r,b,a) in (4) is not a concave function and, for fixed r and b, the agent’s utility function A(r,b,a) in the inner problem (7) is not necessarily concave. However, for 0⩽q⩽4, the Maple code given in Appendix B can be used to show that for fixed values of r and b, A is a unimodal function of the variable a for all values of a for which the constraint A(r,b,a)⩾500 holds. Even though A(a) is not concave, for q⩽4 the inner problem does not have different local maximizing points. However, for q=5, A may not be unimodal for some values of r and b. Fig. 6gives such an example with two local maximizing pointsa¯=1410.66andaˆ=1933.78for A whereA(a¯)is slightly larger thanA(aˆ).The existence of local maximizing points for A affects the calculation of the gradient gkin Step 1 of the Ellipsoid Algorithm as described above. For example, using the pointaˆin Fig. 4 for the solution of the inner problem gives gk=〈 0.118,0.000005〉 whereas using the pointa¯gives gk=〈−0.011,−0.000001〉. In Step 2 of the Ellipsoid Algorithm, the next ellipsoid Ek+1, centered at (rk+1,bk+1) with matrix Qk+1, would be significantly different depending on whethera¯oraˆis used as a solution to the inner problem. In fact, this is because the above two gradients point in nearly opposite directions. As indicated in Fig. 1, the next ellipsoid Ek+1 would contain a very different part of Ekdepending on the solution used for the inner problem. Thus there is no guarantee that the ellipsoid algorithm will converge to a globally optimal solution to the principal-agent problem (4). However, for each value of q, calculating values of P over a fine grid of values for r and b (as in Fig. 2 where q=0) shows that the solutions obtained in Table 1 are globally optimal solutions.

@&#CONCLUSIONS@&#
Agency research has given many insights into the relationship between compensation contracts and employee effort. Solving principal agent problems can add to those insights and improve our understanding of the effects of management control systems and its contracts. While the use of closed form solutions to agency problems have provided considerable insight into this relationship, additional insights can be obtained by relaxing some of the simplifying assumptions and using numerical approaches as illustrated in this paper. In particular, solving principal agent problems with nonlinear compensation contracts as well as those that aggregate measures nonlinearly can allow researchers to relax the standard linearity assumptions found in the literature. The method we propose explicitly considers the agent’s incentive compatibility constraint, enabling researchers to simultaneously consider both the principal and the agent’s utility functions to find compensation systems that will ultimately maximize the principal’s utility. We do this without many of the simplifying assumptions made in the past to cope with the difficulty of dealing with the incentive compatibility constraint (3).We compare the numerical results from our nonlinear model with those of an approximation of a LEN model, since LEN is the standard solution method used in principal agent research in accounting. We show that for small values of the breakpoints (minimum number of cars sold to achieve a bonus) the solutions of LEN are reasonable approximations to the solutions of the nonlinear model. However, for larger values of the breakpoints, the solutions of our LEN model are not good approximations of the nonlinear model.The solution methodology we explain in this paper shows how a researcher can relax the linearity assumptions and solve agency problems directly in a noisy environment. Using numerical methods and constructing a bilevel optimization program, we use the very robust ellipsoid algorithm to solve this problem. As pointed out in Lambert (2007, p. 252), “numerical methods could be used to find the optimal response by the agent for any given contract”. We believe that additional insights into the relationships between compensation contracts and employee efforts can be gained from numerical solutions to optimal contracts.Our current model, which includes a single period, a single action, a single agent, and two performance metrics, can be extended in many directions. Using our numerical approach, we can extend our current model to consider multiple periods, multiple actions, multiple agents, and numerous performance metrics. We can further extend our model to explore various contract shapes and various aggregation styles, allowing us to gain in our understanding of the ramifications of performance contracts. In short, numerical solutions, such as the one presented here using nonlinear contracts, allow us to analyze a wide variety of compensation models that have been heretofore difficult to study. A specific example is the common stock option contract (Lambert, 2007) which is used in compensation plans for employees of publicly traded firms. This contract is highly nonlinear. Using our numerical approach we can explore the implications of the stock option contract, allowing for potentially new insights which have been previously untapped due to the rigid requirements of closed form solutions. In general, using our approach many common real world contracts in a wide variety of environments that have not been studied due to tractability issues can be explored.