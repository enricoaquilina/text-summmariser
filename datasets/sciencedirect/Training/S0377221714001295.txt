@&#MAIN-TITLE@&#
Upper and lower bounding procedures for the multiple knapsack assignment problem

@&#HIGHLIGHTS@&#
We formulate the multiple knapsack assignment problem as an extended problem.We propose three types of upper-bounding procedures and show their coincidence.These upper-bound algorithms cause a procedure to obtain approximate solutions.Our approximate algorithm can solve larger instances quickly and accurately.

@&#KEYPHRASES@&#
Combinatorial optimization,Heuristics,Multiple knapsack problem,Assignment problem,Lagrangian relaxation,

@&#ABSTRACT@&#
We formulate the multiple knapsack assignment problem (MKAP) as an extension of the multiple knapsack problem (MKP), as well as of the assignment problem. Except for small instances, MKAP is hard to solve to optimality. We present a heuristic algorithm to solve this problem approximately but very quickly. We first discuss three approaches to evaluate its upper bound, and prove that these methods compute an identical upper bound. In this process, reference capacities are derived, which enables us to decompose the problem into mutually independent MKPs. These MKPs are solved euristically, and in total give an approximate solution to MKAP. Through numerical experiments, we evaluate the performance of our algorithm. Although the algorithm is weak for small instances, we find it prospective for large instances. Indeed, for instances with more than a few thousand items we usually obtain solutions with relative errors less than 0.1% within one CPU second.

@&#INTRODUCTION@&#
This article is concerned with the multiple knapsack assignment problem (MKAP), as an extension of the multiple knapsack problem (MKP, Kellerer, Pferschy, & Pisinger, 2004; Martello & Toth, 1990; Pisinger, 1999), as well as of the assignment problem (Burkard, Dell’Amico, & Martello, 2009; Kuhn, 2005; Pentico, 2007), where we are given a set of n itemsN={1,2,…,n}to be packed into m possible knapsacksM={1,2,…,m}. As in ordinary MKP, bywjandpjwe denote the weight and profit of itemj∈Nrespectively, and the capacity of knapsacki∈Misci. However, items are divided into K mutually disjoint subsets of itemsNk(k=1,…,K), thus we haveN=∪k=1KNk,nk≔|Nk|, andn=∑k=1Knk. The problem is to determine the assignment of knapsacks to each subset, and fill knapsacks with items in that subset, so as to maximize the total profit of accepted items. To formulate this mathematically, we introduce binary decision variablesxijandyiksuch thatxij=1if item j is included in knapsack i, andxij=0otherwise. Also,yik=1if we assign knapsack i to subsetNk, andyik=0otherwise. Then, we have the following.MKAP:(1)maximizez(x,y)≔∑i=1m∑k=1K∑j∈Nkpjxij,(2)subjectto∑j∈Nkwjxij⩽ciyik,i=1,…,m,k=1,…,K,(3)∑i=1mxij⩽1,j=1,…,n,(4)∑k=1Kyik⩽1,i=1,…,m,(5)xij,yik∈{0,1},∀i,j,k.Here, (1) gives the total profit of items accepted, and (2) and (3) represent the same conditions as in MKP with respect to eachNkand the set of knapsacks assigned to this subset of items. Constraint (4) means that each knapsack can be assigned to at most one subset.Such a problem may be encountered by a marine shipping company in drawing up a cargo plan. Here items are to be shipped to respective destinations, and we have m ships for this transportation. LetNkrepresent the set of items destined to the kth destination, andciis the capacity of ship i. Cargo planning is to allocate ships to destinations, and for each k load the items inNkto the allocated ships.MKAP isNP-hard, since the special case ofK=1is simply an MKP, which is alreadyNP-hard. For recent works on MKP, readers are referred to Chekuri and Khanna (2006), Dawande, Kalagnanam, Keskinocak, Ravi, and Salman (2000), and Lalami, Elkihel, Baz, and Boyer (2012). Since MKAP described as above is a linear 0–1 programming problem, small instance of this problem may be solved using free or commercial MIP (mixed integer program) solvers such as Gurobi (2012). However, as we shall see later, solvers can solve only small instances within a reasonable CPU time.Instead of solving MKAP exactly, we present an approach to solve larger instances approximately, but very quickly. More specifically, we first apply the Lagrangian relaxation to (2), and obtain an upper bound quickly. Here, we show that only one multiplier suffices to eliminate these mK inequalities, and the obtained upper bound is shown to be identical to the upper bound derived by the continuous (LP) relaxation of MKAP. In addition, we present an efficient way to solve this LP problem by decomposing it into K independent continuous knapsack problems.We exploit the result of this computation to derive a heuristic solution, which gives a lower bound to MKAP. Through numerical experiments on a series of randomly generated instances, we evaluate the quality (CPU time and relative errors) of the obtained solutions.To discuss upper bounds, without much loss of generality, we assume the following.A1:Problem datapj,wj(j=1,2,…,n), andci(i=1,2,…,m)are all positive integers.Within each subset, items are arranged in non-increasing order of profit per weight, i.e., for allk=1,…,Kthe following is satisfied:With non-negative multipliersλikassociated with (2), the Lagrangian relaxation (Fisher, 1981) of MKAP is as follows.LMKAP(λ):maximizeL(λ,x,y)≔∑i∑k∑j∈Nk(pj-λikwj)xij+∑i∑kciλikyik,subjectto(3)–(5).Withλ⩾0fixed, this problem is easily solved, and the optimal objective value is(6)z‾(λ)=∑k∑j∈Nkmaxi{(pj-λikwj)+}+∑imaxk{λik}ci,where(·)+≔max{·,0}. Then,z‾(λ)is a piecewise linear and convex function ofλ. Moreover, if we considerLagrangian DUAL:minimizez‾(λ)subjecttoλ⩾0,we have the following.Theorem 1There exists an optimal solutionλ†=(λik†)to Lagrangian DUAL such thatλik†is constant over i and k, i.e.,λik†≡λ†.Letλ=(λik)be a feasible solution to the above problem, and putk†(i)≔argmaxk{λik}. Then, for all k we haveλik⩽λik†(i). Since(pj-λikwj)+is a non-increasing function ofλik, this is minimized atλik=λik†(i), for all k. Thus, in the Lagrangian dual we can assume thatλik≡λi, i.e., constant over k.Next, letλ†≔mini{λi}. Then, we havemaxi{(pj-λiwj)+}=(pj-λ†wj)+, and thusz‾(λ)=∑k∑j∈Nk(pj-λ†wj)++∑iλici,which is minimized atλi≡λ†. □Due to the fact that the coefficients of (2) are identical for all i, this is obtained as an extension of the known result for MKP (i.e.,K=1, Martello & Toth, 1990, pp. 164–165). See also (Yamada & Takeoka, 2009).From this theorem, to obtainλ†it suffices to minimize the one-dimensional(7)z‾(λ)=∑k∑j∈Nk(pj-λwj)++λCoverλ⩾0, where C is the total knapsack capacity, i.e.,(8)C≔∑ici.At differentiableλ⩾0, we have(9)dz‾(λ)/dλ=C-∑k∑j∈Nk(λ)wj,withNk(λ)≔{j∈Nk|pj-λwj>0}. Thus,z‾(λ)is a piecewise-linear, convex function ofλ, and the optimal solutionλ†to the Lagrangian dual is characterized by(10)λ≷λ†⇒C-∑k=1K∑j∈Nk(λ)wj≷0.Such aλ†can be found by the standard binary search method, and we obtain the corresponding Lagrangian upper boundz‾L≔z‾(λ†).By replacing the 0–1 condition (5) with non-negativity requirements, we obtain the continuous relaxation of MKAP as follows.CMKAP:maximize(1),subjectto(2)–(4)andxij⩾0,yik⩾0,∀i,j,k.Letz‾Cbe the optimal objective value to this problem. This gives the upper bound by the continuous relaxation of MKAP. Then, the following states the relation between the Lagrangian and continuous relaxations.Theorem 2Upper bounds derived from the Lagrangian and continuous relaxations are identical, i.e.,z‾L=z‾C.We note that the coefficient matrix of constraints (3) and (4) in LMKAP(λ) is totally unimodular. Then, this theorem follows immediately from Theorem 10.3 (p. 172) of Wolsey (1998).Instead of applying LP algorithms such as the simplex method directly, CMKAP may be solved efficiently as follows. Letuk≔∑i=1mciyikandxj≔∑i=1mxij. Here,ukis the knapsack capacity allocated (from the total knapsack capacity C) to subsetNk. Then, adding (2) fori=1,…,m, the problem is decomposed into K independent subproblems for each subset as follows.CKPk(uk):maximize∑j∈Nkpjxj,subjectto∑j∈Nkwjxj⩽uk,0⩽xj⩽1,∀j∈Nk.This is a continuous knapsack problem, and it is well known that its optimal objective valuez¯k(uk)is a piecewise linear, monotonically non-decreasing, and (under assumption A2) concave function ofuk(Martello & Toth, 1990).The total profit obtained from the capacity allocationu=(uk)is(11)z¯(u)=∑k=1Kz¯k(uk),and we consider the following total problem of the resource allocation type (Ibaraki & Katoh, 1988).TP:maximizez¯(u),subjectto∑k=1Kuk⩽C,uk⩾0.Byu♮=(uk♮)we denote an optimal solution to TP, andz¯C♮is the corresponding objective value, i.e.,z¯C♮=z¯(u♮). Then, we have the following.Theorem 3z¯C♮=z¯C. Also, an optimal solution to TP is obtained from any optimal solution to CMKAP, and vice versa.(i)Proof ofz¯C⩽z¯C♮.Let (x∘,y∘) denote an optimal solution to CMKAP. The upper boundz¯Cis given as(12)z¯C=z(x∘,y∘)=∑i=1m∑k=1K∑j∈Nkpjxij∘,wherex∘=(xij∘)andy∘=(yik∘). Then, withxj∘≔∑i=1mxij∘,uk∘≔∑i=1mciyik∘,we have∑k=1Kuk∘=∑i=1mci∑k=1Kyik∘⩽C,and∑j∈Nkwjxj∘=∑i=1m∑j∈Nkwjxij∘⩽∑i=1mciyik∘=uk∘.These imply thatu∘=(uk∘)is feasible to TP, and(xj∘|j∈Nk)is feasible to CKPk(uk∘). Thus, we havez¯C♮⩾∑k=1Kz¯k(uk∘)=∑k=1K∑j∈Nkpjxj∘=∑i=1m∑k=1K∑j∈Nkpjxij∘=z¯C.Proof ofz¯C⩾z¯C♮.Letxk♮=(xj♮|j∈Nk)denote an optimal solution to CKPk(uk♮), and putIn TP, sincedz¯k(uk)/dukis a monotonically non-increasing, right-continuous step function (Martello & Toth, 1990), we see that there existsλ♮⩾0such that for any realλ≷λ♮impliesuk♮≷∑j∈Nk(λ)wj. Adding these fork=1,…,K, we have(13)λ≷λ♮⇒C≷∑k=1K∑j∈Nk(λ)wj.Comparing this with (10), we obtain the following.Theorem 4λ♮obtained by solving TP is identical to the optimal Lagrangian multiplier characterized by(10), i.e.,λ♮=λ†.In preliminary numerical experiments, we find that many variables in CMKAP take non-integer values in optimality, and thus it is not practical to expect a good approximate solution to MKAP by rounding those variables either to 0 or 1. As an alternative approach, we propose to allocate (from the total knapsack capacity C)uk♮as the capacity for subsetNk, and decompose MKAP into K mutually independent MKPs for eachNk. Here,u♮=(uk♮)is obtained in Section 2.3 as a solution to TP, and hereafter referred to as the reference capacity.Next, we try to assign knapsacks, i.e., determiney, so thatu♮is most closely approximated. This may be accomplished heuristically, as we shall discuss in Section 3.1.Finally, once knapsacks are thus assigned to subsets, we obtain an approximate solution, and correspondingly a lower bound to MKAP, by solving (exactly or approximately) the resulting K independent MKPs.For an assignment vectorysatisfying (4),(14)uk(y)≔∑i=1mciyikdenotes the capacity allocated toNkby this assignment of knapsacks. Let the difference betweenu(y)andu♮beδ(y)≔∑k=1K|uk(y)-uk♮|.Then, the problem is:minimizeδ(y)subjectto(4).This may be converted into a linear 0–1 integer program, and solved exactly using MIP solvers. However, to obtain solution more quickly, we present a heuristic approach as follows.First, we obtain a feasibleyby the following greedy algorithm.Algorithm 1GREEDYStep 1. Letuk≔0,yik≔0,∀i,∀k, andi≔1;Step 2. Findk̲≔argmaxk{uk♮-uk}, and assign knapsack i toNk̲, i.e.,uk̲≔uk̲+ci,yik̲≔1;Step 3. Stop ifi=m. Otherwise, leti≔i+1and go to Step 2.Next, we apply local search to obtain improved solutions. This is accomplished by exchanging some parts of the assignment. Lety=(yik)be a current solution, and assume thatyik=yi′k′=1in this solution. Byy(i,i′)we denote the solution obtained fromyby exchanging the assignments at rows i andi′, i.e.,yik′(i,i′)=yi′k(i,i′)=1. For a feasibley,U(y)denotes the neighborhood ofy, i.e., the set of solutions obtained fromythis way. Then, the algorithm is:Algorithm 2LOCAL_SEARCHStep 1. Letybe the assignment vector obtained from GREEDY described above;Step 2. Findy′∈U(y)such thatδ(y′)<δ(y);Step 3. If such ay′is found, puty≔y′and go to Step 2;Step 4. Otherwise, outputy̲≔yand stop.The output from this algorithm is denoted asy̲.Oncey̲=(y̲ik)is obtained, MKAP is decomposed into MKPs for each subset. Let the set of knapsacks assigned toNkbe(15)Ik(y̲)≔{i|y̲ik=1}.Then, for subsetNkthe problem isMKPk(y):maximize∑i∈Ik(y̲)∑j∈Nkpjxij,subjectto∑j∈Nkwjxij⩽ci,∀i∈Ik(y̲),∑i∈Ik(y̲)xij⩽1,∀j∈Nk,xij∈{0,1}.This problem may be solved exactly using the MULKNAP code (Pisinger, 1999), which is a specialized solver for MKPs. However, we note that in solving the original MKAP, sinceuk♮is only an approximation for the capacity toNk, exact solutions of MKPk(y) may neither be required nor useful. Furthermore, solving K MKPs exactly can be quite time-consuming. Thus, we prefer to solve MKPs only approximately but quickly. This is accomplished by truncating MULKNAP as soon as an approximate (and feasible) solution is obtained.Letx̲kbe an approximate solution to MKPk(y) thus obtained with the corresponding objective valuez̲k, and letx̲≔(x̲1,…,x̲K). Then (x̲,y̲) is a feasible solution to MKAP, and(16)z̲≔∑k=1Kz̲kgives a lower bound to MKAP.We evaluate the performance of the MKAP algorithm developed in the previous section through a series of numerical experiments. We implemented the algorithm in ANSI C language and conducted computation on a DELL Precision T7400 computer (CPU: Xeon X5482 Quad-Core×2 3.20gigahertz×2, RAM: 64gigabyte), with Red Hat Enterprise Linux 5 operating system.The size of instances tested is SMALL and LARGE as follows.–SMALL:n=20,40,60,K=2,5, andm=10,20,LARGE:n=4000,8000,K=50,100, andm=200,400,800, and we setnk=n/K(k=1,…,K).These sizes come from the following considerations: in SMALL we intend to compare the upper and lower bounds against the optimal objective values; thus to solve instances exactly the problem size has to be limited. On the other hand, LARGE explores the behavior of the heuristic algorithm for large (or huge) instances.Let R denote the range ofwj, i.e., the weightwjis distributed uniformly random over the integer interval [1,R], and profitpjis related to the weights in the following ways.–UNCOR (uncorrelated): Uniformly random over[1,R], independent ofwj,WEAK (weakly correlated):pj≔0.6wj+θj, whereθjis uniformly random over[1,0.4R],STRONG (strongly correlated):pj≔wj+0.2R.BINARY:pjis independent ofwj, and takes value 1 or 100, both with probability 0.5.Here, BINARY aims at exploring the effects of smaller number of possible objective values of MKAP, as we shall experiment in Section 4.6 In addition, throughout experiments R is fixed at103, except in Section 4.5 where we conduct sensitivity analysis on this parameter.Knapsack capacity is determined by(17)ci=ρ·∑j=1nwj·ξi,where (ξi) is uniformly distributed over{(ξ1,…,ξm)∑i=1mξi=1,ξi⩾0}andρis another experimental parameter which takes either a value of 0.25, 0.50 or 0.75.For each combination of correlation types and values ofK,mand n as shown in SMALL, we prepared 10 randomly generated instances, and computed their optimal objective values as well as upper and lower bounds. Table 1summarizes the results of this computation, with each row showing the average of respective values over the 10 instances. Here the column ‘Exact’ gives the optimal objective value (z★) and CPU time in seconds obtained using MIP solver Gurobi Version 5.0.1 (2012), with computation being truncated at 1200 CPU seconds. We show the number of instances solved to optimality within this time limit as #sol, and if truncated,z★gives the best incumbent objective value obtained at that time.The columns ‘Upper bound’ and ‘Lower bound’ investigate the performance of the heuristic algorithm for the same instances. We show the upper and lower bounds (z‾andz̲), and their relative errors in percentage, i.e.,ErrU=100·(z‾-z★)/z★andErrL=100·(z★-z̲)/z★. CPU time for computing these bounds was far less than a second in these instances, and thus negligible.From this table, we see that MKAP can be solved easily to optimality by MIP solvers if instances are as small asn⩽40. For larger values of n we often encounter difficulty, irrespective to the correlation types and the values of K and m.It is clear that the quality of the heuristic solution is unsatisfactory for these SMALL instances, with relative errors sometimes higher than 100%. In particular, upper bound is far from the optimal value in instances withn=20, although errors decrease rapidly as n increases. The relative error of the lower bound remains less than a few dozens percent for all values of n, and decreases with the increase of n.To investigate the behavior of the heuristic algorithm for small to large n, Table 2gives the gap between the bounds (absolute error=z¯-z̲) and their relative error (Err=100·(z¯-z̲)/z̲), again as the average over 10 randomly generated instances for some pairs of K and m, as n increases from 20 to 1000 andρ=0.5fixed. We observe that the gap (z¯-z̲) decreases rapidly with the increase of n, and this is even accelerated in relative errors. This strength of the approximation algorithm can be further ascertained in Tables 3 and 4, where we give the results for larger instances.We may attribute this strength for larger instances to a sort of ‘granularity effect,’ as explained below. We note that in our experiments the knapsack capacity was determined by (17), which meansci=O(n)for alli∈M. Sincewjandpjdo not increase commensurately with n, for large n we have an MKAP with relatively ‘small’ items. In such a circumstance, each knapsack will be packed with many small objects, and it is natural to conjecture that objects of smaller weights (relative to knapsack capacities) can be packed to near capacity in many different ways, whereas when object weights are large relative to capacity, heuristic packings may end up far from capacity. This fact is obvious for ordinary 0–1 knapsack problem, and we observe the similar phenomenon for MKAP.Tables 3 and 4 summarize the results of computation for LARGE instances, again as average over 10 randomly generated instances. Table 3 is for UNCOR case with various values ofρ, while Table 4 is forρ=0.5with correlation types varied. The observations from Table 3 are:•The heuristic algorithm described in Section 3 gives quite accurate approximate solutions for LARGE instances in small CPU time, irrespective of the values ofρ,Kand m within the range of experiments tested. Indeed, except for a few instances, relative errors are far less than a percent, and CPU time is less than one second.Parameterρis relatively insensitive to the accuracy of solutions and CPU time.From Table 4, we observe the following.•For the values ofK,mand n tested, the algorithm remains efficient, irrespective of the correlation types of the problem.So far, in the experiments we assumed thatwj(andpj) is distributed over[1,R]. Table 5gives a result of the sensitivity analysis with respect to this range, i.e., we compare the cases ofR=102,103andR=104. Although the absolute error increases commensurately with R, the algorithm stably produces approximate solutions of at most a few percent relative errors, irrespective of the correlation type of the instance.Finally, Table 6compares the results of BINARY against those of UNCOR. In both of these types, absolute errors decrease monotonically with the increase ofρ. This may be explained as follows. Asρincreases, we have knapsacks of capacities sufficiently large to accept almost all the items of larger relative efficiency (pj/wj), irrespective of specific assignment of knapsacks to subsets. The remaining capacities will be filled with items of smaller efficiency, but this does not make big difference in objective values. This is especially significant in BINARY withρ=0.75, where knapsacks will include all the items ofpj=100(and in addition some ofpj=1). Absolute errors are also smaller for larger n, as we have observed in Table 2.Except for the case ofρ=0.75, relative errors are larger in BINARY than in UNCOR, but throughout the experiments tested these are always less than a few per cent. Indeed, no significant differences were observed (both in accuracy of solutions and computing time) between BINARY and other type of instances.We have formulated MKAP, and developed a solution algorithm to solve this problem approximately, but very quickly. For small instances, the quality of the solutions produced remains poor. Such a problem may better be solved using MIP solvers, although exact solutions are hard to obtain by this method as well. Through numerical experiments we found our algorithm prospective for larger instances. We discussed this strength of the heuristic algorithm for larger instances in relation with the granularity effect of the knapsack problem.Finally, we mention the cost of assignments which has been ignored in our formulation of the problem. It is natural to consider that different knapsack-subset pairs would incur different assignment costs. Thus, instead of (1) the objective function may be modified asz(x,y)≔∑i=1m∑k=1K∑j∈Nkpjxij-∑i=1m∑k=1Kdikyik,wheredikis the cost of allocating knapsack i to subsetNk. In addition, we may introduce some constraints on(yik).Unfortunately, the theorems given in this paper are no longer valid and the heuristic algorithm based on these theorems is inapplicable in this extended framework. We need some different approaches to explore such an important issue related to MKAP, and we leave this as a future research direction.

@&#CONCLUSIONS@&#
