@&#MAIN-TITLE@&#
MILP formulations for the modularity density maximization problem

@&#HIGHLIGHTS@&#
We consider a clustering method modularity density maximization, originally modeled as 0–1 NLP.We show theoretical properties of the optimal solution.We derive four exact MILP reformulations of the 0–1 NLP.The MILPs outperform the 0–1 NLP in term of computational time to find the optimum.Computational experiments allow to identify the most efficient MILP reformulation.

@&#KEYPHRASES@&#
Clustering,Mixed integer linear programming,Modularity density maximization,Reformulations,

@&#ABSTRACT@&#
Cluster analysis refers to finding subsets of vertices of a graph (called clusters) which are more likely to be joined pairwise than vertices in different clusters. In the last years this topic has been studied by many researchers, and several methods have been proposed. One of the most popular is to maximize the modularity, which represents the fraction of edges within clusters minus the expected fraction of such edges in a random graph with the same degree distribution. However, this criterion presents some issues, for example the resolution limit, i.e., the difficulty to detect clusters having small sizes. In this paper we focus on a recent measure, called modularity density, which improves the resolution limit issue of modularity. The problem of maximizing the modularity density can be described by means of a 0–1 NLP formulation. We derive some properties of the optimal solution which will be used to tighten the formulation, and we propose some MILP reformulations which yield an improvement of the resolution time.

@&#INTRODUCTION@&#
Cluster analysis refers to finding subset of vertices in a graph (called clusters, or communities, or modules) which are densely connected among themselves but less connected with vertices in other clusters. There are many ways to formalize this idea. One could specify some rules that the vertices in a cluster must respect (Cafieri, Caporossi, Hansen, Perron, & Costa, 2012; Radicchi, Castellano, Cecconi, Loreto, & Parisi, 2004). For example, the strong rule of Radicchi et al. (2004) imposes that each vertex must have more neighbors within its own cluster than neighbors in other clusters. Another way to identify clusters is to specify an objective function to maximize or minimize. One among the most famous of such functions is modularity, which represents the fraction of edges within clusters minus the expected fraction of such edges in a random graph with the same degree distribution (Girvan & Newman, 2002; Newman & Girvan, 2004). Given an unweighted simple graph G = (V, E), the modularity is expressed as:(1)Q=12|E|∑vi∈V∑vj∈V(ai,j−kikj2|E|)Xi,j,where ai, jis an element of the adjacency matrix of G (i.e., ai, j= 1 if {vi, vj} ∈ E, and 0 otherwise), kiis the degree of the vertex vi(i.e., the number of neighbors of vi), and Xi, jis a binary variable equal to 1 if the vertices viand vjbelong to the same cluster, and 0 otherwise. Modularity can be defined in an equivalent way as:(2)Q=∑c∈C(mc|E|−Kc24|E|2),where C is the set of clusters (whose cardinality is not known in advance), mcis the number of edges within cluster c, and Kcis the sum of the degrees of the vertices which are inside this cluster. Notice that in (1) there is no information about the number of clusters, unlike (2).A good partition of the vertex set of a graph into clusters is obtained when the modularity is maximized. Using Definition (2) the corresponding problem can be expressed by means of a convex Mixed Integer Quadratic Programming (MIQP) formulation (Xu, Tsoka, & Papageorgiou, 2007). On the other hand, using Definition (1) we obtain a Mixed Integer Linear Programming (MILP) model (Brandes et al., 2008) which extends the clique partitioning formulation (Grötschel & Wakabayashi, 1989). Recently, some improved versions of the latter (where the number of constraints has been reduced from O(|V|3) to O(|V|2)) have been put forward (Dinh & Thai, 2014; Miyauchi & Sukegawa, 2015).Some authors pointed out that Modularity Maximization (MM) presents some issues, the main ones being resolution limit and degeneracy. Resolution limit refers to the fact that in some cases small clusters may not be detected, and they remain hidden within another cluster, as reported in Fortunato and Barthélemi (2007) and Good, de Montjoye, and Clauset (2010). Degeneracy is related to the possible presence of several high modularity partitions which makes it hard to find the global optimum (Good et al., 2010). For a more detailed discussion of the strengths and weaknesses of modularity see Fortunato and Barthélemi (2007) and Fortunato (2010). In addition, interesting insights concerning computational complexity of modularity, approximability results, hardness results for sparse graphs, and relationships between the MM problem and the small-set expansion problem have been recently presented in (Dasgupta & Desai 2013, 2014).In order to overcome the resolution limit of modularity a new measure called modularity density has been proposed in Li, Zhang, Wang, Zhang, and Chen (2008). More precisely, the modularity density D can be expressed as:(3)D=∑c∈C(2mc−m¯cnc),where mcis again the number of edges of G having both end vertices inside the cluster c (inner edges),m¯cis the number of edges joining a vertex in c to another vertex not in c (cut edges), and ncis the number of vertices inside the cluster c (size of c). Actually, in Li et al. (2008) the modularity density has been expressed this way:(4)∑c∈C(∑vi∈V∑vj∈Vai,jYi,cYj,c−∑vi∈V∑vj∈Vai,jYi,c(1−Yj,c)∑vi∈VYi,c),where Yi, cis a binary variable equal to 1 if vertex vibelongs to cluster c, and 0 otherwise. To show that (4) is equivalent to (3), we can first rewrite (4) as follows:(5)∑c∈C(2∑vi∈V∑vj∈Vai,jYi,cYj,c−∑vi∈VkiYi,c∑vi∈VYi,c),where kiis the degree of the vertex vi. We can now express the double sum over the edge set E (ai, j= 1 if and only if {vi, vj} ∈ E), and add a factor 2 since we are counting these elements two times (i.e., ai, j= aj, i, since the graphs considered are undirected). This way, we can rewrite Eq. (5) in a more compact way:(6)∑c∈C(4∑{vi,vj}∈EYi,cYj,c−∑vi∈VkiYi,c∑vi∈VYi,c).Finally, we can obtain the expression (6) from (3) using the fact thatmc=∑{vi,vj}∈EYi,cYj,cand the relationshipm¯c+2mc=∑vi∈VkiYi,c. Notice that we will employ (6) to derive the modularity density maximization models presented in the rest of the paper.As for modularity, the modularity density should be maximized. The most intuitive mathematical programming formulation for the modularity density maximization (MDM) problem is a binary Nonlinear Programming (0–1 NLP) model, and the main cause of nonlinearity is the denominator in (6). Furthermore, it is not straightforward to employ the clique partitioning formulation for MDM, because this would require to reformulate (6) in terms of variables Xi, jas in (1). Hence, the MDM problem seems to be more complicated than the MM problem, at least from a mathematical programming point of view.The goal of this paper is to derive some exact MILP reformulations of the 0–1 NLP which are more efficient in terms of computational time needed to obtain the (same) optimal solution. The rest of the paper is organized as follows: in Section 2 we present some properties of the optimal solution of MDM which will be used to derive some constraints to tighten the formulations considered. In Section 3 we introduce the 0–1 NLP model, and in Section 4 we introduce some MILP reformulations. Then, in Section 5 we compare the performance of the different formulations using some instances of the literature as test bed. Finally, Section 6 presents the conclusions.In this section we present some properties of the optimal solution of MDM. In particular, we derive an upper bound on the number of clusters in the optimal solution and some lower and upper bounds on the size of each cluster. Moreover, we discuss with an example a counterintuitive result obtained by maximizing the modularity density on a graph with a particular structure. In the rest of the paper we always consider to have at least two clusters, otherwise the value of the modularity density could be computed directly without solving an optimization problem.Lemma 1The isolated vertices (i.e., vertices having degree 0) can be assigned a posteriori to clusters.According to Eq. (3), the modularity density contribution of a cluster is computed as twice the number of inner edges minus the number of cut edges over the number of vertices inside the cluster. Suppose now to remove the isolated vertices and to solve the MDM problem for the reduced graph. Once the optimal solution is known, if each cluster has got a modularity density value greater than or equal to 0, then the isolated vertices can be put together in a new cluster having modularity density 0. In fact, if we put a vertex with degree 0 in another cluster, that would decrease the modularity density of that cluster because the denominator of (3) would become larger, and the numerator would not change. On the other hand, if the optimal solution contains some clusters having a negative value of modularity density, then the isolated vertices can be assigned to these clusters in order to increase their modularity density. Notice that, as shown in Costa (2014), there could be cases where the optimal solution contains some clusters with negative modularity density, even though in Li et al. (2008) it is stated that this cannot happen.□Actually, isolated vertices are not so frequent in the instances of the literature, and they are not present in the instances we have tested. Hence, from now on we only consider graphs without isolated vertices.Proposition 1In the optimal solution of MDM for a graph G = (V, E) with |V| ≥ 2, each cluster contains at least two vertices.First, notice that obviously a cluster must contain at least one vertex. Hence, empty clusters are not considered.Now suppose, for contradiction, that there is a cluster cicontaining only one vertex vihaving degree ki. For Lemma 1, ki≥ 1. We show that moving viin a cluster cjcontaining a neighbor vjof vi(and deleting the empty cluster ci) yields an increase of modularity density. The smallest possible increase of the modularity density of the graph is obtained when moving viin a cluster cjcontaining only one neighbor of vi, because the value mcin Eq. (3) would increase only by one, and the value ofm¯cwould increase by ki− 2. We compare now the values of modularity density obtained before and after moving the vertex viin the cluster cj. The former can be expressed as follows:(7)D1=DR+2mcj−m¯cjncj−ki,where2mcj−m¯cjncjis the modularity density of the cluster cj, − kiis that of the cluster ci, and DRis that of the rest of the graph. After moving the vertex viin the cluster cjthe modularity density becomes:(8)D2=DR+2(mcj+1)−(m¯cj−1+ki−1)ncj+1.In the expression of the new modularity density of cjthe denominator has increased by one because of the new vertex vi. The number of edges inside the cluster has increased by one because of the edge {vi, vj} with vj∈ cj. The number of cut edges has decreased by one because the edge {vi, vj} is now inside the cluster, but increased by ki− 1 because now we should take into account all the other ki− 1 neighbors of viwhich are outside cj. We want to prove that ΔD= D2 − D1 > 0. We can rewrite that condition as:(9)ΔD=2mcj−m¯cj−ki+4ncj+1−2mcj−m¯cjncj+ki>0.After a few manipulations, we obtain:(10)kincj2+4ncj+m¯cj>2mcj.To prove (10), recall that in an undirected simple graph the maximum number of edges inside a cluster having n vertices isn(n−1)2(in case of a clique). Hence the following condition holds:(11)2mcj≤ncj(ncj−1).Using (11), and noticing thatkincj2+4ncj+m¯cj>ncj(ncj−1)since ki≥ 1, we can write:kincj2+4ncj+m¯cj>ncj(ncj−1)≥2mcj.Hence, (10) holds and this proves the proposition.□Notice that the result of this proposition is not that given a number of clusters the optimal solution does not contain clusters having only one vertex. This can happen, but in this case the solution would not be optimal with respect to the number of clusters, as we can find a better value of modularity density with a smaller number of clusters (by moving the isolated vertex in another cluster and then removing the resulting empty cluster). This happens for the journal index dataset, as noticed in Li et al. (2008): the optimal value of modularity density is obtained with four clusters, and the solution with five clusters is the same as that with four clusters except for one vertex which forms by itself a new cluster. In this case, having a cluster with a single vertex was the option yielding the smallest possible decrease of modularity density.Corollary 1The number of clusters in the optimal solution of MDM for a graph G = (V, E) is bounded above by⌊|V|2⌋.This follows directly from Proposition 1.Corollary 2The size of each cluster in the optimal solution of MDM is between 2 and |V| − 2(|C| − 1).The lower bound is the direct result of Proposition 1. Concerning the upper bound, if we focus on a cluster c there are other |C| − 1 clusters having at least two vertices, hence c cannot contain more than |V| − 2(|C| − 1) vertices.From Proposition 1 one could think that a vertex with degree 1 and its neighbor must belong to the same cluster in the optimal solution. This is indeed intuitive, and it is true in most of the cases (as those tested in Section 5). However, it is not true in general. To show this, consider the graph with 37 vertices presented in Fig. 1. In this graph there is a clique containing three vertices in the center, connected to seven cliques containing four vertices each and to a clique containing five vertices together with a vertex having degree 1.The optimal solution (found using the models described in Section 4) consists of nine clusters, represented with different shapes/colors in Fig. 1. It would be reasonable to expect vertex 37 to belong to the same cluster of vertex 10 (triangle shaped cluster). Instead, it belongs to the cluster containing the clique with three vertices (circle shape cluster). More precisely, the modularity density value of the partition represented in Fig. 1 is 22.1, whereas the value obtained when imposing vertex 37 to belong to the same cluster of its neighbor is 22.083. This behavior seems to be related to what already observed in Costa (2014), i.e., the fact that in particular cases there are clusters with negative modularity density. For such clusters a large number of vertices (that is a large value of the denominator of (3)) is more beneficial than a large number of vertices for a cluster with positive modularity density. In our example, the modularity density of the triangle shaped cluster in Fig. 1 is 3.6, whereas that of the circle shaped cluster (containing vertices 1, 2, 3, and 37) is − 0.75. If vertex 37 belongs to the triangle shape cluster, the modularity density of that cluster becomes 3.5, whereas the modularity density of the circle shaped cluster (containing vertices 1, 2, and 3) is − 0.667. The values for all the other clusters remain the same. This is an example of what stated earlier: increasing the size of the cluster with negative modularity density can produce the overall effect of increasing the total modularity density of the partition.In order to fix this issue, one could modify the modularity density formulation by adjoining a constraint imposing that each vertex having degree one must belong to the same cluster of its neighbor. Using the variables and notation introduced earlier, this can be expressed as follows:(12)∀c∈C,∀{vi,vj}∈E|(ki=1orkj=1),Yi,c=Yj,c.However, this would produce a different problem than the modularity density maximization as originally presented in Li et al. (2008). It is interesting to notice that modularity seems not to be affected by this issue. In fact, the modularity value associated with the partition of Fig. 1 is lower than the value obtained when vertex 37 belongs to the triangle shape cluster.In Li et al. (2008) the authors presented a nonlinear programming formulation to describe the maximization of the modularity density using the objective function (4). An equivalent and more compact model (obtained using the objective function (6)), that will be called MDN, is as follows:(13)max∑c∈C(4∑{vi,vj}∈EYi,cYj,c−∑vi∈VkiYi,c∑vi∈VYi,c)(14)s.t.∀c∈C,1≤∑vi∈VYi,c≤|V|−1(15)∀vi∈V,∑c∈CYi,c=1(16)∀c∈C,∀vi∈V,Yi,c∈{0,1},where Yi, cis a binary variable equal to 1 if the vertex vibelongs to the cluster c, and 0 otherwise. The constraint (14) imposes lower and upper bounds on the size of each cluster, while (15) forces each vertex to belong to only one cluster.We show in this section how to reformulate the MDN model (13)–(16). From now on, we use the tighter inequality of Corollary 2 (i.e.,2≤∑vi∈VYi,c≤|V|−2(|C|−1)) instead of (14).We show now how to obtain a MILP model for the MDM problem. The products between Y variables in (13) can be linearized exactly by introducing the variables W and using the Fortet inequalities (Fortet, 1960, actually only two of them are needed, as we are maximizing the products among variables Y). To this aim, we replace each product Yi, cYj, cwith a new variable Wi, j, c, and we add the following inequalities:(17)∀c∈C,Wi,j,c≤Yi,c(18)∀c∈C,Wi,j,c≤Yj,c.Moreover, the fractions can be reformulated by introducing some additional variables αcwhich will be maximized. More precisely, ∀c ∈ C we can write:(19)4∑{vi,vj}∈EWi,j,c−∑vi∈VkiYi,c∑vi∈VYi,c≥αc⇒4∑{vi,vj}∈EWi,j,c−∑vi∈VkiYi,c≥αc∑vi∈VYi,c,where we can employ inequalities instead of equalities because we are maximizing the terms αc. We still need to linearize the products αcYi, c. First, let Lαand Uαbe the lower and upper bounds of αc, respectively (how to compute them is discussed later). We can now introduce some new variables Si, cto replace each term αcYi, cand use the McCormick inequalities (McCormick, 1976):(20)Si,c≤UαYi,c(21)Si,c≤αc−Lα(1−Yi,c)(22)Si,c≥LαYi,c(23)Si,c≥αc−Uα(1−Yi,c).Since these products involve a binary and a continuous variable, the linearization is exact. In fact, it can be easily checked that these inequalities impose Si, c= αcYi, cfor both values of Yi, c(i.e., 0 and 1). However, we need the lower and the upper bounds on the continuous variables αc(i.e., Lαand Uα). It is not easy to derive a tight upper bound theoretically, but we can find one by solving an auxiliary NLP problem where we focus only on one cluster (hence we can discard the index of the cluster from the variables Y):(24)Uα=max4∑{vi,vj}∈EYiYj−∑vi∈VkiYi∑vi∈VYi(25)s.t.2≤∑vi∈VYi≤|V|−2(|C|−1)(26)∀vi∈V,Yi∈[0,1].Notice that in this NLP problem the constraint (15) is not needed. Moreover, we have relaxed the integrality constraints on Y because on the one hand we want a tight upper bound, but on the other hand we do not want to spend too much time for finding it. Concerning the lower bound Lα, we should minimize the objective function in (24)–(26). However, looking at (24) it turns out that a possible value of the lower bound corresponds to the situation where only two variables Y are equal to one, i.e., those corresponding to the two vertices with highest degree (kmax1andkmax2), and they are not connected by an edge. Hence, we can deriveLα=−kmax1+kmax22. This value if often very close to the optimal solution obtained by minimizing (24)–(26), so we use it directly. Notice that, if the modularity density of each cluster was nonnegative, as reported in Li et al. (2008), we could have set Lα= 0. However, as stated earlier, this is not true in general (Costa, 2014). We can now write the MDL model:(MDL)max∑c∈Cαcs.t.∀c∈C,2≤∑vi∈VYi,c≤|V|−2(|C|−1)∀vi∈V,∑c∈CYi,c=1∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yi,c∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yj,c∀c∈C,4∑{vi,vj}∈EWi,j,c−∑vi∈VkiYi,c≥∑vi∈VSi,c∀c∈C,∀vi∈V,LαYi,c≤Si,c≤UαYi,c∀c∈C,∀vi∈V,αc−Uα(1−Yi,c)≤Si,c≤αc−Lα(1−Yi,c)∀c∈C,∀{vi,vj}∈E,Wi,j,c∈R∀c∈C,∀vi∈V,Si,c∈R∀c∈C,αc∈[Lα,Uα]∀c∈C,∀vi∈V,Yi,c∈{0,1}.It can be noticed that the formulation MDL presents |C||V| linearization variables S. Using the binary decomposition technique (as already done for some special cases of MM in Cafieri, Costa, and Hansen, 2014b and Costa and Hansen, 2014 and general clustering problems in Boulle, 2004), we can reduce the numbers of these linearization variables to O(|C|log (|V|)). As a matter of fact, in the MDL formulation we have one variable Yi, c(and as a consequence one variable Si, c) for each vertex viand for each cluster c. However, the expression we want to linearize involves∑vi∈VYi,c,hence linearizing each product αcYi, cseparately is not the most efficient approach. The idea we want to exploit here is to represent the term∑vi∈VYi,cusing fewer variables, thus yielding a smaller number of linearization variables (which will now be called R, instead of S as in the previous formulation). Let H = {0, …, tD}. We can express the term∑vi∈VYi,cthis way:(27)∑vi∈VYi,c=∑h∈H2hbh,c,where the binary variables bh, care the coefficients of the decomposition. Therefore, constraint (27) forces the new binary variables bh, cto correspond to the coefficients of the binary expansion of the integer number∑vi∈VYi,c. From the previous considerations the maximum value that the term∑vi∈VYi,ccan assume is |V| − 2(|C| − 1), and the maximum value which can be expressed using the binary decomposition in (27) is2tD+1−1,hence the parameter tDcan be set this way:2tD+1−1≥|V|−2(|C|−1)⇒tD=⌈log2(|V|−2|C|+3)−1⌉.Using (27), the termαc∑vi∈VYi,ccan be rewritten as:αc∑vi∈VYi,c=∑h∈H2hbh,cαc.We can now linearize the products αcbh, cusing additional variables R and the McCormick inequalities (similarly to (20)–(23)). The resulting model MDB is defined as follows:(MDB)max∑c∈Cαcs.t.∀c∈C,2≤∑vi∈VYi,c≤|V|−2(|C|−1)∀vi∈V,∑c∈CYi,c=1∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yi,c∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yj,c∀c∈C,4∑{vi,vj}∈EWi,j,c−∑vi∈VkiYi,c≥∑h∈H2hRh,c∀c∈C,∑vi∈VYi,c=∑h∈H2hbh,c∀c∈C,∀h∈H,Lαbh,c≤Rh,c≤Uαbh,c∀c∈C,∀h∈H,αc−Uα(1−bh,c)≤Rh,c≤αc−Lα(1−bh,c)∀c∈C,∀{vi,vj}∈E,Wi,j,c∈R∀c∈C,∀h∈H,Rh,c∈R∀c∈C,αc∈[Lα,Uα]∀c∈C,∀h∈H,bh,c∈{0,1}∀c∈C,∀vi∈V,Yi,c∈{0,1}.An alternative way to obtain a MILP is to split the two terms in the numerator of (13) and to linearize them separately. This way the lower and upper bounds used for the McCormick linearizations are tighter, but the number of variables needed is larger. Consider the expression of the modularity density of a cluster. Instead of writing it as in (19), we can express it this way:(28)4∑{vi,vj}∈EWi,j,c∑vi∈VYi,c−∑vi∈VkiYi,c∑vi∈VYi,c,and then linearize the two terms separately by introducing two new variables βcand γc:(29)∑{vi,vj}∈EWi,j,c∑vi∈VYi,c≥βc⇒∑{vi,vj}∈EWi,j,c≥βc∑vi∈VYi,c(30)∑vi∈VkiYi,c∑vi∈VYi,c≤γc⇒∑vi∈VkiYi,c≤γc∑vi∈VYi,c.Hence, the objective function becomes:(31)max∑c∈C(4βc−γc).As for the MDL formulation, we have to linearize the products between the variables βc(γc), and Yi, c, hence we need some lower and upper bounds for the variables βc(γc). Letkmax1,kmax2,kmin1,andkmin2be respectively the highest, second highest, lowest and second lowest degrees among the vertices in V. Looking at (30), it turns out that a lower bound for γcisLγ=kmin1+kmin22,while the upper bound isUγ=kmax1+kmax22(remember that each cluster contains at least two vertices). Concerning β, we can easily derive a lower bound Lβ= 0. In order to find an upper bound, we should solve an optimization problem similar to (24)–(26). More precisely, the upper bound Uβis found as the optimal solution of this NLP problem:(32)Uβ=max∑{vi,vj}∈EYiYj∑vi∈VYi(33)s.t.2≤∑vi∈VYi≤|V|−2(|C|−1)(34)∀vi∈V,Yi∈[0,1].Calling Si, cthe linearization variable associated with the term βcYi, cand Ti, cthat of the term γcYi, c, we can now define the formulation MDL2:(MDL2)max∑c∈C(4βc−γc)s.t.∀c∈C,2≤∑vi∈VYi,c≤|V|−2(|C|−1)∀vi∈V,∑c∈CYi,c=1∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yi,c∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yj,c∀c∈C,∑{vi,vj}∈EWi,j,c≥∑vi∈VSi,c∀c∈C,∑vi∈VkiYi,c≤∑vi∈VTi,c∀c∈C,∀vi∈V,LβYi,c≤Si,c≤UβYi,c∀c∈C,∀vi∈V,βc−Uβ(1−Yi,c)≤Si,c≤βc−Lβ(1−Yi,c)∀c∈C,∀vi∈V,LγYi,c≤Ti,c≤UγYi,c∀c∈C,∀vi∈V,γc−Uγ(1−Yi,c)≤Ti,c≤γc−Lγ(1−Yi,c)∀c∈C,∀{vi,vj}∈E,Wi,j,c∈R∀c∈C,∀vi∈V,Si,c∈R∀c∈C,∀vi∈V,Ti,c∈R∀c∈C,βc∈[Lβ,Uβ]∀c∈C,γc∈[Lγ,Uγ]∀c∈C,∀vi∈V,Yi,c∈{0,1}.Starting from the formulation MDL2 we can apply the binary decomposition technique introduced in Section 4.2 to obtain the formulation MDB2. More precisely, we express the term∑vi∈VYi,cas in (27). By doing so, the constraints (29) and (30) become:(35)∑{vi,vj}∈EWi,j,c≥∑h∈H2hbh,cβc(36)∑vi∈VkiYi,c≤∑h∈H2hbh,cγc.As done for MDB, we can linearize the products between the variables b and β (γ) by introducing new variables R (P) and the McCormick inequalities. The resulting model is the following:(MDB2)max∑c∈C(4βc−γc)s.t.∀c∈C,2≤∑vi∈VYi,c≤|V|−2(|C|−1)∀vi∈V,∑c∈CYi,c=1∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yi,c∀c∈C,∀{vi,vj}∈E,Wi,j,c≤Yj,c∀c∈C,∑{vi,vj}∈EWi,j,c≥∑h∈H2hRh,c∀c∈C,∑vi∈VkiYi,c≤∑h∈H2hPh,c∀c∈C,∑vi∈VYi,c=∑h∈H2hbh,c∀c∈C,∀h∈H,Lβbh,c≤Rh,c≤Uβbh,c∀c∈C,∀h∈H,βc−Uβ(1−bh,c)≤Rh,c≤βc−Lβ(1−bh,c)∀c∈C,∀h∈H,Lγbh,c≤Ph,c≤Uγbh,c∀c∈C,∀h∈H,γc−Uγ(1−bh,c)≤Ph,c≤γc−Lγ(1−bh,c)∀c∈C,∀{vi,vj}∈E,Wi,j,c∈R∀c∈C,∀h∈H,Rh,c∈R∀c∈C,∀h∈H,Ph,c∈R∀c∈C,βc∈[Lβ,Uβ]∀c∈C,γc∈[Lγ,Uγ]∀c∈C,∀h∈H,bh,c∈{0,1}∀c∈C,∀vi∈V,Yi,c∈{0,1}.We can adjoin to the previous models some constraints which will speed up the resolution time needed to find the optimal solution. For example, we can employ some symmetry breaking constraints (SBCs) useful to reduce the size of the Branch-and-Bound tree, as already observed in Cafieri et al. (2014b), Costa and Hansen (2014), Costa, Hansen, and Liberti (2013), and Plastria (2002). The best results in term of reduction of Branch-and-Bound nodes have been obtained using the SBC, already employed in Cafieri et al. (2014b), which imposes that the vertex having the highest degree (i.e., the one involved in more constraints) belongs to the cluster having index 1:(37)Yj,1=1,j=argmax{ki,∀vi∈V}.In case the vertex with the highest degree is not unique, we use the one with the smallest index.In this section we present the results obtained by solving some small size instances of the literature using the MILP formulations presented in the previous sections. The experiments were performed on a PC with 4 Intel Xeon E5-4620 CPU at 2.20 gigahertz (8 cores each, Hyper Threading and Turbo Boost disabled), 128 gigabytes RAM (32 gigabytes for each processor) running Linux. We now shortly comment the instances, which were mostly retrieved from the Pajek website (http://vlado.fmf.uni-lj.si/pub/networks/data/). Notice that multiple edges and loops were removed, if any, and the weights on the edges as well as the orientation of the arcs were ignored, if present, in order to obtain simple undirected unweighted graphs.Strike and sawmill refer to a wood-processing facility: the vertices represent the employees and two vertices are joined by an edge if the corresponding employees discussed frequently about work matters. Galesburg F (friendship) and D (discussion) refers to the Columbia University Drug Study, which investigated the diffusion of a new drug (gammanym). These graphs represent friendship ties and discussion links, respectively, between the physicians involved in the first subscription of this drug. Karate is the famous Zachary’s karate club graph, representing friendship relationships between the members of a karate club. In Korea 1 and Korea 2 the vertices are associated with Korean women. An edge joining two vertices indicates that the two women discussed about family planning. Mexico represents political, kinship, friendship, or business ties among Mexican political elite (i.e., presidents and close collaborators). Dolphins small represents the interactions among bottlenose dolphins studied by Lusseau in Doubtful Sound, New Zealand, from 1995 to 2001. Finally, in journal index the vertices are journals of different fields (i.e., multidisciplinary physics, chemistry, biology, and ecology) and the presence of an edge indicates that at least one article from one of the journals cited an article in the other journal in 2004.The details of the instances, such as the number of vertices and edges, are reported in Table 1, together with the optimal solutions (in terms of number of clusters and modularity density value D) obtained by maximizing the modularity density. Since modularity density is strictly related to modularity, we also reported the modularity value QDassociated with the partition found by maximizing the modularity density, and the optimal solution (in terms of number of clusters and modularity value Q) found by maximizing the modularity (using the MIQP formulation presented in Cafieri, Costa, & Hansen, 2014a). It can be noticed from the table that only in 3 cases over 10 the optimal partition is the same.To solve the modularity density maximization problem we used the MILP formulations presented in the previous sections, i.e., MDL, MDB, MDL2, and MDB2, and the solver CPLEX 12.6 (IBM, 2013). We did not consider MDN, because some experiments performed with the nonlinear solvers Couenne 0.4.7 (Belotti, Lee, Liberti, Margot, & Wächter, 2009) and SCIP 3.1.0 (Achterberg, 2009) showed that this formulation is not efficient. As a matter of fact, considering the smallest instance (i.e., strike), both the solvers Couenne and SCIP were still running after 2000 seconds (using the formulation MDN), but employing CPLEX with the MDB formulation the same instance was solved in 1.21 seconds (plus 0.19 seconds for the computation of the upper bound Uα).Tables 2and 3show the statistics associated with the different MILPs on the 10 instances tested (the best results are highlighted in bold). More precisely, for each formulation it is reported the number of variables (nv) and constraints (nc) of the formulation, the number of Branch-and-Bound nodes (nb), the best value of the objective function found (f*), the gap still open (gap) within 2 hours, and the computational time in seconds (t) to find the optimal solution. If the optimal solution has not been found within 2 hours we use “t.l.” (time limit). Finally, “aux” refers to the time (in seconds) needed to solve (using SCIP, which finds a global optimal solution) the auxiliary problems which yield the upper bounds on the variables α and β. More precisely, Table 2 reports the time needed to solve (24)–(26), whereas Table 3 shows the time to solve (32)–(34). In some cases (e.g., Mexico, journal index) the time to solve them is larger than that needed to solve the main problem. Nevertheless, the total time is still much lower than that of MDN. There are two aspects to take into account: first, our version of SCIP does not take advantage of parallelism of the hardware architecture. Second, very often a good bound is found in a short time, and the difficult part is to close the gap. Thus, one could stop the search earlier, when the gap is small but not exactly 0, and take the best upper bound found. As a matter of fact, we just need a good upper bound to express the McCormick inequalities.From the tables we can notice that: (i) the formulations employing the binary decomposition are more efficient than those employing the simple linearization. In fact MDB is better than MDL, and MDB2 is better than MDL2 in terms of size of the formulation (i.e., number of variables and constraints), number of Branch-and-Bound nodes and computational time to find the optimal solution; (ii) the formulations where the nonlinear expression (13) has been split into two parts (i.e., MDB2 and MDL2) are less efficient that those for which the expression has not been split. Indeed, the bounds on the linearization variables are tighter for MDB2 and MDL2, but the size of the formulations (i.e., the number of variables and constraints) increases. Hence, in this case it seems that having a more compact formulation is more important than having tighter bounds. In any case, the bounds are in general quite tight because they are computed by solving the auxiliary problems.Thus, it is possible to derive a ranking of the formulations, from the most to the least efficient in terms of computational time to find the optimal solution: MDB, MDB2, MDL, MDL2, and MDN (except for Mexico, where MDB2 was faster than MDB if considering also the time to solve the auxiliary problem, and to a lesser extent for Galesburg F).

@&#CONCLUSIONS@&#
In this paper we have presented the modularity density maximization problem with the 0–1 NLP model originally introduced in Li et al. (2008). We then have derived some theoretical properties which yield some constraints useful to improve the model, and we also have presented four MILP reformulations of the original nonlinear model. The best formulation, i.e., MDB, is way more efficient than the nonlinear one. As a matter of fact, as remarked in the previous section, the computational time to find the optimum for the smallest instance was at least three order of magnitude lower than that of MDN using the solvers Couenne or SCIP. Hence, by using the models proposed in this paper it is possible to solve to the optimum small size instances. This is very important to understand the behavior (and possibly to identify the issues) of clustering techniques, and it could be even more effective if combined to a theoretical analysis of the modularity density, similarly to what done in Dasgupta and Desai (2013).The future work has three main directions: first, to use these models as a starting point to derive some heuristics, as in Cafieri et al. (2014b) and Costa and Hansen (2014). Second, employ them within a column generation framework in order to solve larger instances, as done for modularity maximization (Aloise et al., 2010). Third, study the approximation capability of linear relaxations of the proposed formulations, using an approach similar to that of Dasgupta and Desai (2013).The author would like to thank Xi Chen and Leo Liberti for the precious suggestions and comments, and Martin Rosvall for providing the journal index dataset. Moreover, the author would like to thank the anonymous referees for their remarks, which helped to improve the quality of the paper. Financial support by the SUTD-MIT International Design Center under grant IDG21300102.