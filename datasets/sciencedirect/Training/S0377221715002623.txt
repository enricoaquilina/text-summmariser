@&#MAIN-TITLE@&#
Algebraic simplex initialization combined with the nonfeasible basis method

@&#HIGHLIGHTS@&#
Proposes an algebraic simplex initialization exploring the infeasibility principle.This method does not involve any artificial variables, it is relatively rapid.A new pivoting rule for the NonFeasible Basis Method is proposed.An algorithm (PFNFB) for LP is derived from the formal tableau notion.PFNFB is advantageous in both numerical complexity and running time.

@&#KEYPHRASES@&#
Linear programming,Simplex algorithm,Nonfeasible basis method,Formal tableau,

@&#ABSTRACT@&#
We propose, in this paper, a new method to initialize the simplex algorithm. This approach does not involve any artificial variables. It can detect also the redundant constraints or infeasibility, if any. Generally, the basis found by this approach is not feasible. To achieve feasibility, this algorithm appeals to the nonfeasible basis method (NFB). Furthermore, we propose a new pivoting rule for NFB method, which shows to be beneficial in both numerical and time complexity. When solving a linear program, we develop an efficient criterion to decide in advance which algorithm between NFB and formal nonfeasible basis method seems to be more rapid. Comparative analysis is carried out with a set of standard test problems from Netlib. Our computational results indicate that the proposed algorithm is more advantageous than two-phase and perturbation algorithm in terms of number of iterations, number of involved variables, and also computational time.

@&#INTRODUCTION@&#
The simplex algorithm, proposed by Dantzig (1951), is the most used method to solve linear programming problems. A feasible basis is a principal data for starting the latter. Outside the canonical form, it is not easy in practice to exhibit an initial basis even infeasible. Many methods exist in the literature for initializing the simplex algorithm. Two-phase and big M are the most known methods to find an initial feasible basis. They require both artificial variables to get the identity matrix as initial basis. But the addition of artificial variables leads to increase the size of the problem. Stojkovic and Stanimirovic (2001) used “the cosine criterion” to get an initial basis for the simplex algorithm. Paparrizos, Samars, and Stephanides (2003) developed a method that starts resolution by an infeasible basis. This method involves two artificial variables and two big numbers. Csizmadia, Illés, and Nagy (2012) developed the concept of s-monotone index selection rule which unifies the finiteness proof of some anti-cycling pivot rules. The work by Hu (2007) gives a new technique for searching a basis, not necessary feasible, based on LU decomposition. In order to reach feasibility, the author used the perturbation method (Pan, 2000). The main idea of this technique consists in perturbing the economical function; so that the vector of reduced costs becomes nonpositive. This approach applies thenceforward the dual-simplex algorithm. The optimal basis found by the perturbed problem is feasible but not necessarily optimal for the original problem. At this stage, the standard simplex algorithm can be executed normally. Recently, Nabli (2009) suggested a method, termed nonfeasible method (NFB), in order to construct an initial feasible solution from an infeasible one. This method operates without artificial variables or a big M number and without any perturbation in the objective function. The outcome of the feasibility is via a modification of the structure of the simplex algorithm in the choice of the entering and leaving variables. This method is a new approach which is completely different from the standard simplex method and also from the dual-simplex algorithm. In the same paper (Nabli, 2009), Nabli introduced the notion of formal tableau. As a consequence, he developed another new method called formal nonfeasible basis and denoted by FNFB. Nabli, Chahdoura, and Dammak (2013), have combined the method of Hu (2007) with the nonfeasible basis method.Extracting a basis even infeasible is not a simple issue. Also, to find a basic solution of the linear system My = b, related to a standard form, we need to eliminate first all redundant constraints, if any. Otherwise it is not possible to find a basis of order m, where m is the number of rows in matrix M. In this paper, we introduce a new approach which initializes the simplex algorithm by a feasible basis of adequate order. We modify slightly the nonfeasible basis method. When solving a linear program, we develop an efficient criterion to decide in advance which algorithm between NFB and FNFB seems to be less consuming in number of iterations.The paper is organized as follows. After this introduction, the simplex algorithm is briefly described. In Section 3, we explain our algorithm which is able to extract a basis from the matrix governing the constraints after detecting possible redundancy. An example is proposed to illustrate our approach. In Section 4, the nonfeasible basis method is recalled and a slight modification on its pivoting rule is carried out. We describe likewise our choice criterion. Section 5 is dedicated to a comparative study between our approach, two-phase method and the method of Hu (2007). The comparison of different methods is based on the number of involved iterations and the time complexity. Finally, Section 6 summarizes our contribution.It is well known that the executing of simplex algorithm is restricted only on standard forms. Each linear program, in canonical or general form, must be beforehand written in standard form to ensure its implementation by the simplex algorithm. Any linear program in standard form is expressed as follows:{max(ormin)[Z(y)=c*y]My=by≥0Rn,where M is a (m, n) matrix satisfying 1 ≤ m < n,c∈Rnandb∈Rmare assumed to be column vectors. The mathematical symbol * stands for the transpose operator. The following notations will be used throughout this paper: M· j= M(:, j) the jth column of M; Mi·= M(i, :) the ith row of M; Mijthe (i, j) entry of M; M(i: j, :) all rows from i to j of the matrix M and M(:, i: j) all columns from i to j of the matrix M.We assume that the rank of matrix M is maximal equal to m, (rank(M) = m), otherwise all linearly dependent row vectors must be imperatively removed. This hypothesis ensures the existence of a non-singular sub-matrix of dimension m called basis, which is commonly denoted by B. The matrix M is partitioned as M = [BN], where N is the matrix composed of the remaining columns. Let JBbe the set of basic variable indices and JN= {1,…, n}∖ JBthe set of nonbasic variable indices. According to the partition JBand JN, the data of linear problem can be expressed asc*=(cB*cN*)andy=(yByN). The vector yB= (yi, i ∈ JB) is composed by the basic variables associated to the basis B and yN= (yi, i ∈ JN) by the nonbasic variables. A solutiony=(yByN)is feasible if and only if it satisfies the constraints My = b andy≥0Rn,otherwise it is called infeasible. Being given a basis B, the associated solutiony=(yByN)=(B−1b0N)is called a basic solution, it is feasible if and only if B−1b ≥ 0B. Its objective function value is equal toZ(B−1b0N)=cB*B−1b. The reduced cost vector associated to the basis B is defined as follows:wN*={cN*−cB*B−1N,if``max""−cN*+cB*B−1N,if``min""It is well-known that, under the hypothesis of feasibility of B, the conditionwN*≤0N*is sufficient to state that B is an optimal basis or equivalently(B−1b0N)is an optimal solution. It becomes necessary in case of non-degeneracy (B−1b > 0B). If the optimality condition is not satisfied, (wN*≰0N*), an adjacent feasible basic solution(B′−1b0N′)admitting a better objective value (Nabli, 2006; Wolfe, 1985), is selected. The change from B to B′ is done by swapping a column of B with one of N. So there are two operations for this exchange. The first is to determine the index column of N which must enter in JB. This index is chosen among the set{j∈JNwj=±(cj−cB*B−1N·j)>0}. Generally, this set is not reduced to a singleton so there are several choices. There are many rules (Dantzig, 1963; Dantzig & Thapa, 1997; 2003), called pivoting rule, to fix the entering variable. Among the rules we choose steepest-edge rule, proposed by Goldfarb and Ried (1977). It consists in choosing the maximum reduced cost vector normalized; and determining the index s ∈ {1,…, n − m} for which this maximum is reached:s=argmax{wj∥ηj∥wj>0,forj=1,…,n−m},whereηj=(−B−1Nejej).In the identity above, ejdesignates the jth vector of the canonical basis ofRn−m. The steepest-edge rule is adopted because it is the best pivoting rule in practice (Todd, 2002). The second operation consists in selecting one column of B, to be released from the basis, so that the new basic solution remains feasible. This purpose is achieved by considering the leaving variable index:r=argmin{(B−1b)i(B−1N.s)i(B−1N.s)i>0,fori=1,…,m}.After permuting the sth column of N with the rth column of B, the data Z,wN*,B−1b and B−1N are updated. This procedure is repeated until reaching the optimality conditionwN*≤0N*.For easier handling practice, the elements involved in the simplex algorithm can be recapitulated in a table, called simplex tableau. To each basis B corresponds a simplex tableau. Here, we use the condensed form (Wolfe, 1985), which is a reduced size tableau of dimension (m + 1) × (n − m + 1) whereas the standard simplex tableau is of dimension (m + 1) × (n + 1):The variablesyi1,…,yimcorrespond to the basic variables associated to the current basis B andyj1,…,yjn−mare the nonbasic variables. The interior elements constituting this tableau are concatenated in one matrix denoted by H:H=(B−1NB−1bwN*∓Z).If the pivot is Hrsfor some iteration, then the entries composing the new matrix for the subsequent iteration satisfy the following expression:(1)His←{−HisHrsfori≠r1Hrsfori=r{Hrj←HrjHrs,j≠sHij←Hij−HisHrjHrs,j≠s&i≠rWhen solving a linear program by the simplex method, we are not forced to calculate all the entries of the simplex tableau, only involved elements are computed. The revised simplex algorithm consists of avoiding the wasting time on calculating the elements which are not used.As mentioned before, to apply the simplex algorithm, a nonsingular matrix B of dimension m is required. But in general, it is difficult to detect at first sight such a basis. For a canonical form, the constraints are written in the form Ax ≤ b andx≥0Rp,so the matrix M associated to the standard form is none other than M = [AI], where I is the identity matrix. The size of the matrix I is described by the context. Therefore, ifb≥0Rm,the matrix B = I is a feasible basis sinceB−1b=b≥0Rm. In other words, the slack variables are basic ones for a canonical form satisfyingb≥0Rm,otherwise (b≱0Rm) or in the case where the linear program is not written in canonical form, it is often difficult to extract a feasible basis. For some problems, the rank of the linear system My = b is lower than m: rank(M) < m. In this case, either the linear system is compatible (i.e. there are linearly dependent constraints), or incompatible and therefore the feasible domain is empty. For solving a linear optimization problem, all redundant constraints must be beforehand eliminated.Our aim in this section is to develop a method to initialize the simplex algorithm by a basis of adequate dimension. This technique can also detect that the rank of M is less than m, and give the redundant constraints in case of compatibility. The main idea of the method is based on the notion of linear algebra and Gauss pivoting. Our approach is composed by at most four consecutive steps. The first step is trivial and it is valid only if the considered linear program does not contain any equality constraint. The rest of steps are of course more general. Before describing these steps, a preliminary action should be undertaken. It consists in ordering the constraints of the considered linear problem in such a way that inequalities of type “≤” appears at first, after the inequalities of type “≥” and finally the equality constraints. Once this task is accomplished, we put the problem in standard form. Without loss of generality, the right hand side b of the constraints can be supposed nonnegative. Henceforth, we denote by lc, uc and ec the number of constraints “≤”, “≥” and “=” respectively. Also, the integer p will designate the number of decision variables and n the number of structural variables of the standard form.Step 0.ec = 0.In this case, it is clear that the set of slack variables {yp + 1,…, yp + (lc + uc)} is basic, since the associated basis is exactly:B=(I00−I),which is naturally invertible. The zero in bold character designates a matrix (or vector) with all entries equal to 0. The dimension of this matrix/vector is given by the context. In presence of equality constraints (lc + uc < m), we go to Step 1.ec ≠ 0.In this case, {yp + 1,…, yp + (lc + uc)} is incomplete to set a basic variables system, precisely ec decision variables are missing. They can be added in accordance with the following process.After performing Step 1, two cases are possible: indl = ∅ or indl ≠ ∅. If indl = ∅, then B is a square upper triangular matrix with nonzero diagonal elements, so B is necessarily invertible and therefore B constitutes an initial basis, otherwise we go to Step 2.indl ≠ ∅.In this case, as many variables as the cardinality of indl are needed to complete the basic system. For this purpose, we execute Algorithm 2.After performing Step 2, two cases arise: indp = ∅ or indp ≠ ∅. If indp = ∅ then B is necessarily an invertible matrix of dimension m, since all column vectors are by construction linearly independent. When indp ≠ ∅, we go naturally to Step 3. It is useful to specify that for the transportation or assignment problem, our process finds an initial basis just after finishing Step 2. We recall that the rank of the matrix M governing this kind of problems is m − 1 and that any constraint can be omitted (Nabli, 2006).indp ≠ ∅.In this case, we apply the following approach: for each constraint i ∈ indp, add a variable, that we call pivoting variable, in order to complete the basis B. These variables will be denoted byxpj,for j = 1,…, card(indp). This is equivalent to add for each row i the column vector ei= I(:, i) in M. So the matrix B = [M(:, indB)  I(:, indp)] is actually a basis. These variables are introduced only to add columns to the incomplete basis B in order to obtain an invertible matrix of dimension m. They are different from artificial variables since they are used neither in the objective function nor in the computation of the reduced cost vectorwN*. So the simplex tableau in this phase of eliminating the pivoting variables from basic system does not contain the reduced cost vectorwN*and the objective value ∓Z. To distinguish between the conventional simplex tableau and the tableau free fromwN*and ∓Z, we call the latter pivoting tableau. It is useful to specify that, in practice, the number of pivoting variables is very small compared with the number of constraints m.We illustrate the four steps by the example below. The obtained basis B has the following form:B=(Step0Step1Step2Step3I0••••••••00−I⋮⋮⋮⋮⋮⋮⋮⋮⋮00×•••••••0000×••••••000000000×000000×•••••000000×••••0000000×•••1000000×•••000000000•×00000000×••0)The symbol ‘×’ indicates that the corresponding entry is not null, whereas ‘•’ means that the entry is arbitrary, it can be null or nonzero. In this example, we have card(indl) = 3, card(ind) = 2 and card(indp) = 1.The objective function and the initial problem do not depend on pivoting variables, so we must find a tool to remove these variables. The idea is inspired from the simplex method. In order to get an initial basis B, a modification in the way of choosing the leaving and entering variables is carried out. Our objective is to transform the pivoting variables outside the basic variables set, while keeping the matrix B nonsingular. Since the reduced cost vector is not performed, the entering variable will not be determined by the Dantzig rule. For each pivoting variablexpj,the choice of the entering variable is done as follows:1.Fix the index r ∈ indp corresponding toxpj.The entering variable index s is defined by:s=argmax{|βri|i∈indN},whereβ=B−1N.indN = indN∖{s} and indB = indB∪{s}.Update the pivoting tableau.The principle described above selects each pivot with the largest absolute value from the row of the matrix β = B−1N. This is exactly what partial pivoting performs in Gaussian elimination. It can be performed only ifmax{|βri|i∈indN}is non-null, since the pivot βrscannot be zero. Otherwise, the rth row of β is composed only by zero entries and in this case we have the following result.Theorem 3.1Let r be an index which corresponds to a pivoting variable. We have:(βri,i∈indN)=0⟹rank(M)<mMoreover, if (B−1b)r≠ 0 then the linear system My = b is incompatible and therefore the feasible domain is empty, otherwise (i.e. (B−1b)r= 0) the equation related to index r is redundant and must be removed.The development of this proof will be done in two phases. First, we suppose that the condition (βri, i ∈ indN) = 0 is achieved at the end of the eliminating process: all pivoting variables are replaced by structural variables except the last onexpq,where q is the number of pivoting variables (q = card(indp)). In this case, the pivoting tableau will have the following form:The computation of the columns related to pivoting variables is not necessary. This is the reason why they kept empty in the tableau above. We recall that the content of the right hand side of this tableau is exactly β = B−1N, which is equivalent to Bβ = N. Taking into account of the hypothesis (βmi, i ∈ indN) = 0, the equality Bβ = N leads to express the basic vector of M in terms of the nonbasic ones:(M·i1⋯M·im−1)[•⋯•⋮⋮•⋯•]=(M·j1⋯M·jn−m+1).So, for the matrix M there are exactly (n − m + 1) column vectors which depend linearly of (m − 1) columns. Moreover, the system of vectors(M·i1⋯M·im−1)is linearly independent since it is extracted from the matrixB=(M·i1⋯M·im−1I(:,indp(q))),which is naturally invertible. Then rank(M) = m − 1 and we have precisely:(2)vect(M·i,i=1,…,n)=vect(M·i1,⋯,M·im−1),where vect stands for the spanned space. Concerning the compatibility of the linear system My = b, the condition (B−1b)m= 0 added to the hypothesis (βmi, i ∈ indN) = 0 gives the following:(B−1b)m=0⇔b=∑l=1m−1αlM·il,whereα=B−1b⇔b∈vect(M·i1,…,M·im−1)⇔b∈vect(M·i,i=1,…,n),accordingto(2)⇔My=biscompatible.Let us consider now the general case where the condition (βri, i ∈ indN) = 0 appears in the middle of the elimination process. Besides the variablexpj,where j is the index fulfilling indp(j) = r, it remains other pivoting variables in the basic system. So, the pivoting tableau has the following form:In this case, we go systematically to the next pivoting variable to apply the elimination principle described just before this theorem. According to the iterative formula (1), the row related toxpjremains null. This procedure is repeated until the last pivoting variablexpq. At the end, the pivoting variablexpjand possibly other pivoting variables satisfying the same condition(βr′i,i∈indN′)=0remain in the basic system. The same development used in the first phase leads to conclude that rank(M) = m − a0, where a0 designates the number of zero rows appearing in the last pivoting tableau. The proof of Theorem 3.1 is then completed.□The Step 3 is recapitulated in Algorithm 3.Now, we illustrate our approach by an example where the three steps are run.ExampleFind an initial basis for the following linear problem:{max[Z(y)=2y1+18y2+5y3+14y4]−y1+y2+y3−y4=12y1+7y2+y3+8y4=72y1+10y2+2y3+10y4=10y=(y1,y2,y3,y4)≥0R4For this problem, the matrix M governing the constraints, the right hand side b and the economical vector c are as follows:M=(−111−12718210210),b=(1710)andc*=(218514).Applying Step 1, we obtain: indl = {1, 2} and indB = {2}, so the set {y2} is an incomplete basic variables system. It is useful to specify that indl is composed by row indices and indB contains only column indices. After executing Step 2, since every component of M· 2 is nonzero, we get indp = indl = {1, 2}. According to our approach, Step 3 is a necessary issue, two pivoting variables are required. The obtained basis is:B=(1107011000),where B· 2 and B· 3 are the columns associated to the two pivoting variablesxp1andxp2which have been introduced. The basic variables set is naturallyyB={y2,xp1,xp2}. In order to replace the pivoting variables by structural ones, Algorithm 3 must be performed.Iteration 1:The last row of the simplex tableau containingwN*and ∓Z is omitted, it has no role for the pivoting variables. The number in bold character designates the pivot, so y4 is the entering variable, sincemax{|−65|,|45|,|−2|}=2. At this stage of development, we haveyB={y2,y4,xp2}.Iteration 2:The column related toxp1is kept empty since it is meaningless. According to Theorem 3.1, we have rank(M) = 2 < 3 and the linear system My = b is compatible. More precisely, the 2nd constraint is redundant, the constraint wherexp2is added. The previous tableau is more informative: the two column vectors spanning the vectors of M are M· 2 and M· 4, and the linear dependency of the remaining columns is given by:(−112122)=(1−1781010)(−253535−25).This can be easily explained by recalling that the entries related to the nonbasic variables in a simplex tableau correspond actually to the matrix β = B−1N, or equivalently Bβ = N. Furthermore, at once the second constraint removed from the linear system My = b, the matrices B−1N and B−1b can be deduced from the pivoting tableau above. More precisely, we have:B−1N=(−253535−25)andB−1b=(10),whereB=(1−11010),N=(−1122)andb=(110).Now, if we consider the same example with b3 = 10 instead of b3 = 8, it is clear that the system My = b becomes incompatible. In this case, the executing of Algorithm 3 gives in the second iteration the following tableau:Giving thatB3·−1N=0and(B−1b)3=1510≠0,Theorem 3.1 permits us to conclude that the system is incompatible indeed.Generally, the basis found by this approach is not feasible. Our new algorithm can be combined with nonfeasible basis method (NFB) to achieve feasibility. In next section, we recall the basic idea of NFB and the notion of formal tableau. A new pivoting rule for NFB will be proposed. This pivoting rule shows to be advantageous in number of iterations and computational time. To make in advance an opportune choice between NFB and FNFB, a criterion will be also developed.The general idea of two phase and Big M methods is to preserve the identity matrix as initial basis. Determining such a basis leads to a growth in the size of the problem due to the adding of artificial variables. The number of artificial variables is exactly the sum of the number of constraints “ ≥ ” with the number of equality constraints. When the two types of constraints are predominant, the cost generated by adding artificial variables can be prohibitive in number of iterations and therefore in computation time. The nonfeasible basis method, introduced by Nabli (2009) and denoted by NFB, generates an initial feasible basis from an infeasible one, without involving any artificial variables and with no perturbation in the objective function. The idea of this method is to start solving a linear problem by a basis either feasible or infeasible. If this basis is infeasible, B−1b ≱ 0, then by an iterative process, that we recall below, a feasible solution is constructed. Once reaching feasibility, the simplex algorithm will be proceeded by the desired pivoting rule. In Nabli et al. (2013), the authors have initialized NFB by the method of Hu (2007). A comparative study made in Nabli et al. (2013) shows that NFB consumes less iterations than the perturbation method (Pan, 2000) adopted in Hu (2007). In this paper, we will initialize NFB by the basis generated by our algorithm which has been described in the previous section.For this paragraph, we assume that the chosen basis B is infeasible (B−1b ≱ 0). The NFB method can detect the emptiness of the feasible domain. The algorithm of this method is given below.After reaching feasibility, the simplex algorithm is run as usual. So the unboundedness, if any, will be detected in the second phase of NFB. This phase is denoted in Algorithm 4by (⋆).The notion of formal tableau was introduced by Nabli (2006,2009). For each simplex tableau, a new tableau qualified by formal is constructed. Its content is exactly the opposite transposed of the corresponding simplex tableau. It is obtained via the following corre- spondence:In the simplex tableau, the nonbasic variablesyi1,…,yipare transformed to basic variablesyj1,…,yjpon the formal tableau, but with respect to the new indexing:(3)jl≡il+m[n]Also, the basic variablesyip+1,…,yinmust be transformed to nonbasic variablesyjp+1,…,yjnin the formal tableau by respecting the same indexing formula (3). A premise of this notion has been proposed by Strayer (1989), but the author distinguishes between the decision variables and the slack ones. The congruence formula (3) is likewise non-existent.When the studied linear program is a canonical form, it has been proved (Nabli, 2006) that, at each primal simplex iteration, the corresponding formal tableau is actually a simplex tableau for the dual problem. By analogy with the notion of duality in linear programming, the formal tableau satisfies the following property (Nabli, 2009):(4)TheformaltableauoftheformaltableauistheprimaltableauUsing this property, the formal tableau related to the last iteration gives the optimal solution of the dual problem. So, this alternative leads to solve simultaneously the primal and its dual. Furthermore, it has been proved that the dual-simplex algorithm is exactly the simplex algorithm, with the Dantzig pivoting rule, when it is executed on the formal tableau (Nabli, 2006). So instead of using two codes the simplex and the dual-simplex, it is sufficient to implement the simplex algorithm and run it either on the primal or on the formal tableau. Moreover, when using the simplex algorithm on the formal tableau, the best reduced cost rule is not a fait accompli, one generally finds other pivoting rules in the literature such as the steepest-edge simplex algorithm (Goldfarb & Ried, 1977).A new alternative, which springs naturally from the formal tableau notion, has been suggested in Nabli (2009). This method, which is called formal nonfeasible basis and denoted FNFB, consists of applying NFB on the formal tableau. Thanks to Property (4), the formal tableau applied on the last iteration provides the optimal solution for the original problem.For NFB method, the selection of entering variable is performed according to the following rule:s=argmin{wjβkj1≤j≤n−mandβkj<0},whereβ=B−1N.The purpose of NFB is to get a feasible basis. Since the reduced cost vectorwN*has no relation with the feasible domain, we adopt rather the following new rule:s=argmin{βkjj=1,…,n−mandβkj<0}The minimum value is retained by analogy with the Gauss elimination with partial pivoting. For this new pivoting rule, the computation of the reduced cost vectorwN*is meaningless, which leads to less computation in each iteration vis-a-vis the former rule. We will see in the next section that this new pivoting rule is also more rapid. The NFB and FNFB method using the new pivoting rule are henceforth designated byNFB¯andFNFB¯. Thanks to their advantages, they will be adopted instead of NFB and FNFB.When solving a linear program, two alternatives are possible eitherNFB¯orFNFB¯. The natural question that arises is to decide which of the two approachesNFB¯andFNFB¯is less expensive in number of iterations and/or in computational time. We develop here a criterion to decide in advance which algorithm betweenNFB¯andFNFB¯seems to be more rapid. We appropriate to call this approach Primal-Formal NonFeasible Basis, it is naturally denoted by PFNFB. The algorithm below is applied on the simplex tableau generated by the initializing method described in Section 3, when the corresponding basis is well obviously infeasible.In practice and according to Chvatal (1983), “the typical number of iterations increases proportionally to m and only very slow to n”. If m ≤ nbv, PFNFB selects generally the primal algorithmNFB¯since the condition(nbBm≤0.95)is more likely than its negation. On the other side, when m > nbv, the formal tableau will have fewer rows than columns and in this case, PFNFB selects mostly the dual algorithmFNFB¯since the condition(nbwnbv≥0.05)is more likely. The rates 95 percent and 5 percent are inspired from the significance level in statistical hypothesis testing. In the next section, we will see that PFNFB is globally beneficial in number of iterations and time complexity.In this section several comparisons are performed. First, (NFB, FNFB) will be compared with(NFB¯,FNFB¯)in order to show the pertinency of our new pivoting rule. Second, the PFNFB method will be implicated so as to discuss the advantage of our approach. The natural criterion of comparison is both the number of iterations and the computational time. The results will show that PFNFB method is better thanNFB¯andFNFB¯. Finally, another comparison will be achieved between PFNFB, two-phase and DBP methods in terms of number of iterations and number of involved variables. We notify that DBP designates the method developed by J.F. Hu in his paper (Hu, 2007). All these algorithms are implemented in MATLAB 7 with the revised form. For our computational study, 24 standard test problems from Netlib (http://www.netlib.org/lp/data/) are selected. They have different forms (canonical and general), they do not have BOUNDS and RANGERS sections in their MPS files.Henceforth, the number of constraints and the number of decision variables, for each linear program, are denoted by m and p respectively. At the beginning of this paper, the number of structural (decision+slack) variables has been denoted by n. So the integer p + m − n corresponds exactly to the number of equality constraints in the studied linear program. The number of nonbasic variables is denoted by nbv, it is always less or equal to p. The equality nbv = p holds only in the absence of equality constraints. According to Table 1, the number of equality constraints is equal to ∑(p − nbv) = 6043 − 3786 = 2257. It represents about 46 percent (22574872≃0.4632) of the total of all constraints. At last, we specify that the retained 24 linear programs (LP) are sorted in increasing order of p + m.The number of iterations obtained by NFB, FNFB,NFB¯,FNFB¯and PFNFB are shown in Table 1. It is clear that our new pivoting rule generates less iterations than the original one. Actually, the resolution of whole problems requires only 4147 iterations byNFB¯and 4470 iterations byFNFB¯,however 5996 and 6762 iterations are carried out using NFB and FNFB respectively. The gain in number of iterations is about 45 percent (59964147≃1.445) in favor ofNFB¯versus NFB, and it is close to 51 percent(67624470≃1.512)forFNFB¯against FNFB. Table 2, which gives the computational time for the different methods, confirms this observation. In conclusion, the new pivoting rule is better in both number of iterations and computation time than the one proposed in Nabli (2009). Moreover, PFNFB method uses exclusivelyNFB¯orFNFB¯. The decision to choose one or the other is made in advance by a simple criterion. This explains the fact that the number of iterations related to PFNFB is either equal toNFB¯orFNFB¯. The same observation holds for the computation time except a slight difference due to nested conditions “IF” in the choice criterion. The last column S/F of Table 1 is a binary variable which indicates if the adopted algorithm PFNFB choose successfully betweenNFB¯andFNFB¯. According to the sum of different values of this variable S/F, the success rate is greater than 75 percent (1824≃0.75). Fortunately, we remark that even PFNFB “fails” in number of iterations for a LP, it generally “wins” in computational time for the same LP (compare Tables 1 and 2). This means that our criterion generating PFNFB is beneficial in both number of iterations and time complexity. The results of Tables 1 and 2 confirm the advantage of PFNFB relatively toNFB¯andFNFB¯. Basically, if we adopt PFNFB as fundamental approach, which combines nonfeasible basis method with the notion of formal tableau, the gain in number of iterations is about 51 percent (59963977≃1.507) and 70 percent (67623977≃1.700) compared with NFB and FNFB respectively. Concerning the computational time, the gain is around 66 percent and 89 percent respectively (66.174439.7632≃1.664and74.979839.7632≃1.885).In Table 3, the variable Iter indicates the number of iterations required for each LP. The number of pivoting variables and artificial variables are denoted by np and na respectively. Table 3 shows that the number of pivoting variables represents only 5 percent (3958590≃0.046) of the structural variables involved in the sample. However, the ratio of artificial variables used by the two-phase method is approximatively 30 percent (25578590≃0.297). This means that, even if Step 3 is reached, the number of pivoting variables is in practice negligible against the number of structural variables. It is useful to specify that the case where np = 0 indicates that the basis is found before Step 3. For the DBP method, it does neither involve artificial nor pivoting variables. Concerning the number of iterations, the gain of our algorithm PFNFB is, respectively, about 103 percent (80803977≃2.031) and 44 percent (57383977≃1.442) in comparison with two-phase and DBP methods.On the other hand, our initialization algorithm has another interesting advantage at the detecting the rank of the system compared with two-phase method. For all examples, only scorpion problem has redundant constraints. In order to determine the index of the first redundant constraint, 391 iterations are needed by two-phase method. While using our algorithm developed in Section 3, after only four iterations, it was concluded that rank(M) < m. Our computations show that Scorpion allows 30 redundant constraints which are compatible with the rest of equality constraints. This may explain the number, relatively large, of pivoting variables (np = 113) for this example.

@&#CONCLUSIONS@&#
