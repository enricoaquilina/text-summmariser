@&#MAIN-TITLE@&#
MedTime: A temporal information extraction system for clinical narratives

@&#HIGHLIGHTS@&#
The hybrid and cascading pipeline of the MedTime system (Fig. 1).Three novel clinical temporal normalization strategies (Section 3.5).Analysis of temporal normalization strategies (Section 5.1).

@&#KEYPHRASES@&#
Temporal information extraction,Temporal expression recognition and normalization,Event recognition,i2b2,

@&#ABSTRACT@&#
Temporal information extraction from clinical narratives is of critical importance to many clinical applications. We participated in the EVENT/TIMEX3 track of the 2012 i2b2 clinical temporal relations challenge, and presented our temporal information extraction system, MedTime. MedTime comprises a cascade of rule-based and machine-learning pattern recognition procedures. It achieved a micro-averaged f-measure of 0.88 in both the recognitions of clinical events and temporal expressions. We proposed and evaluated three time normalization strategies to normalize relative time expressions in clinical texts. The accuracy was 0.68 in normalizing temporal expressions of dates, times, durations, and frequencies. This study demonstrates and evaluates the integration of rule-based and machine-learning-based approaches for high performance temporal information extraction from clinical narratives.

@&#INTRODUCTION@&#
The 2012 i2b2 NLP challenge is on temporal relation identification [1]. The objective is to be able to construct patient’s clinical timeline from text. To accomplish this end, the challenge comprises three tracks: (a) recognize the extents (text spans) and attributes of events and temporal expressions (TEs) given raw records (the EVENT/TIMEX3 track), (b) determine temporal relations given raw records and gold standard EVENT/TIMEX3 tags (the TLINK track), and (c) determine temporal relations given raw records (the end-to-end track).We address the EVENT/TIMEX3 track and develop a temporal information extraction system. The reasons to focus on the EVENT/TIMEX3 track are two-fold. First, recognitions of events and TEs from text are the most fundamental tasks for temporal information extraction. Advanced analyses and applications on temporal NLP are not possible without having an event/TE recognition component to start with. Second, there exists no a systematic study on event and TE recognition from clinical narratives. Previous studies have shown that the system performance of TE tagging varies significantly from one document domain to another [2]. This may suggest that the usage of TEs in each domain presents certain unique traits. Most prior work was developed and evaluated on newswire articles, and thus little is known about the characteristics of events and TEs in clinical narratives.The EVENT/TIMEX3 track is comprised of two tasks: EVENT annotation and TIMEX3 annotation. The first task, EVENT annotation, is to determine clinically relevant events from clinical narratives. The event recognition (ER) resembles the 2010 i2b2 challenges with regards to extracting medical concepts from clinical notes [3]. However, the events here have a much broader range of semantic and linguistic characteristics. Moreover, the events here are not limited to be just noun phrases as medical concepts are. For instance, “asleep” and “consult” are considered clinical events which are neither a medical concept nor a noun phrase. The second task, TIMEX3 annotation, is concerned with temporal expression recognition and normalization (TERN). It requires not only the recognition of clinical TEs but also the retrieval of temporal information from each TE. Several perplexing issues quickly arise, for example, as one tries to determine what date is referred to when “today” is arbitrarily used in a sentence. Similarly, confusion arises when the phrase “postoperative day #2” is used when a document is devoid of an overt operation date.The paper is structured as follows. Section 2 introduces a brief research background of prior studies. Section 3 delineates the framework of our system, MedTime. Section 4 presents the evaluation results. Section 5 analyzes the effects of normalization strategies, offers an error analysis, and compares the performance of MedTime with other systems. Section 6 concludes this paper.Temporal information processing has been an important area in biomedical and health informatics research. Temporal information systems are developed to facilitate healthcare management, predict disease risk or progression, and search for similar clinical patterns [4–6]. Most work, however, has been confined to representing and analyzing numerical or categorical electronic health record (EHR) data. Despite the proliferation of medical NLP studies in the past decade, there has been no concerted effort to address the problem of temporal information extraction from clinical narratives [7]. On the other hand, temporal tagging of natural language text has gained considerable attention recently in computational linguistics and artificial intelligence. One major motivation is the practical need for temporal-aware NLP applications, e.g., event monitoring, temporal question answering, and document summarization.As a central functionality in temporal information extraction, TERN plays a pivotal role in determining temporal relations and understanding messages. To be useful in temporal-aware NLP applications, TEs need to be recognized and normalized such that their temporal information is encoded explicitly in a standard format. However, the rich representations of temporal information in natural language make automatic TERN a challenging task. Because TEs are often vague or underspecified, TERN is difficult even for human annotators.Based on how temporal information is represented, Alonso et al. categorized TEs into three groups: explicit, implicit, and relative [8]. Explicit TEs are the TEs that have fully specified and self-contained temporal information, such as “Nov. 24th, 2011” or “three times a week.” Explicit TEs can be normalized without resorting to any external information, which is not the case in normalizing implicit and relative TEs. Implicit TEs use an alias to represent the actual temporal information, such as “Thanksgiving 2011” or “admission date.” Normalizing implicit TEs involves knowledge about the aliases, e.g., the exact date of Thanksgiving or admission in the previous examples. Finally, relative TEs anchor their temporal information to a contextual reference point, such as “last evening” with respect to the present time. Note that relative TEs can anchor on implicit TEs. For instance, “postoperative day #3” is a relative TE anchored on an implicit TE “operation date” which needs to be determined from the document.Over the years several temporal information extraction systems have been developed. Most of them evolved from shared tasks such as MUC-6, MUC-7, ACE 2004, ACE 2007, and TempEval-2. Given the similarity between the TempEval-2 competition [9] and the 2012 i2b2 challenge, the results from the former offer important insights for the current study. The first implication is about extent detection. We have found that conditional random fields (CRF) are a very effective technique for detecting the extent of events and TEs. Two CRF-based machine learning applications, TIPSem [10] and TRIOS [11], both obtained high f-measures in recognizing events and TEs. The second implication is from the val score, which is an evaluation metric quantifying the performance of temporal normalization. Compared to the f-measures, the val scores reported by the teams in the TempEval-2 competition have greater variance and lower average value, with a mean of 0.57 and median of 0.59. The highest val score 0.85 was from a rule-based system named HeidelTime. This suggests that temporal normalization is a more difficult procedure than temporal recognition and that a rule-based approach is an effective design for temporal normalization tasks. Indeed, there is still no elegant machine learning approach that could normalize temporal expressions. Even the top machine learners in TempEval-2 need to develop rules to normalize TEs after the extents were determined by their supervised models.This section describes the design of our proposed MedTime system (Fig. 1). Our design is a hybrid and cascade framework, interweaving rule-based and machine learning procedures for temporal information extraction in six major steps: (1) pre-processing, (2) temporal tagging by HeidelTime, (3) Clinical FREQUENCY TE tagging, (4) sequence labeling, (5) clinical temporal normalization strategies, and (6) post-processing.Pre-processing consists of subroutines that support the core information extraction procedures.The clinical narratives in the challenge corpus contain two types of section times: ADMISSION and DISCHARGE. The section times have important clinical implications and can be meaningful reference dates for temporal normalization. They are analogous to the document creation times in the TimeML corpora but with a less standardized format. The document creation times in the TimeML corpora are considered as metadata. They are in a uniform format, and each document must associate with one document creation time. By contrast, the section times in the clinical narratives are part of the text. They are expressed in diverse formats, and in some cases, may not even exist in a clinical narrative.Given its importance to our temporal normalization procedure, we extract section times before we proceed to our regular temporal tagging. We observed that, when present, the section time expressions are placed in the first few lines of a clinical narrative, under the headings of “Admission Date” and “Discharge Date.” In addition, we also found that section times are represented as explicit TEs. As such, we develop a simple regular expression algorithm to extract and normalize section times.One requirement from the challenge is that the system needs to be able to process different formatted clinical narratives, which could have originated from different health care institutions. The text cleaning subroutine aims to address two document formatting issues. First, many of the clinical narratives are appended with a section of electronic signature, which contains TEs irrelevant to the patient’s clinical timeline. We formulate rules to remove these texts before proceeding to the core TERN procedures. The second issue is from the inconsistent XML encoding. A small portion of the clinical narratives are XML well-formed, which substitute (&, ’ , >, <, “) in the text for predefined entities, e.g., & is replaced by &. To unify text representation, we convert these predefined entities back to their original characters, e.g., from & to &.We extract morphological, syntactic, semantic, and composite features from clinical narratives to enable machine learning (Table 1). The morphological, syntactic, and some of the composite features, i.e., noun phrase (NP) chunks and adjacent features, are common in prior NLP studies. Many other participating systems in the 2012 i2b2 challenge also include these basic features [12,13]. Most of the morphological and syntactic features are generated using the Stanford CoreNLP package [14]. On the other hand, semantic features are domain-specific and knowledge-based. Medical abbreviations are commonly used in clinical narratives for both clinical events (e.g., HTN for hypertension) and clinical temporal expressions (e.g., BID for twice daily). As such, successful identification of medical abbreviations is indispensable to clinical NLP tasks. We incorporate a comprehensive list of medical abbreviations from Wikipedia (http://en.wikipedia.org/wiki/Category:Lists_of_medical_abbreviations) to identify medical abbreviation features from clinical text. The unified medical language system (UMLS) provides standardized medical lexicon and semantic type for every medical concept. It has been known that incorporating domain specific features can improve the performance of NLP tasks. Hence, we use MetaMap [15], a front-end API of UMLS, to extract features of medical lexicon and semantic types. Finally, the diagnosis/finding/temporal NP chunks are composite features integrating semantic types and NP chunks, which aim to bring additional semantic information to NP chunks. Table 2illustrates the core features. All these features are shared by the subsequent CRF-based event and temporal recognizers.While automatic TERN is still an open and emerging area, sophisticated, publicly available tools exist for processing news articles. As the best performing system in TempEval-2, HeidelTime was able to achieve a very high val match score in tagging news articles. Given the high demand for accurate val prediction in creating meaningful clinical timelines, we decided to incorporate HeidelTime as our initial temporal tagger. Because HeidelTime was already tuned towards high precision, no deleterious effect on noise containment was expected, even though HeidelTime did not have rules and patterns specific to clinical narratives.FREQUENCY is a type of TEs unique to the clinical domain. Many of the FREQUENCY TEs are clinical abbreviations, such as BID (twice a day) or q.8.h (every eight hours), which are not well-treated by HeidelTime. We identify two important characteristics from the FREQUENCY TEs in the corpus. First, the FREQUENCY TEs are often explicit. That is, normalizing these TEs does not require any reference information. Second, the FREQUENCY TEs generally have very regular syntactic patterns. For example, [q.6.h], [Q.8.h.], and [q 12 h] are patterns for every 6h, every 8h, and every 12h, respectively. As another example, the patterns [X 2], [3 x], and [x four] denote, respectively, 2 times, 3 times, and 4 times. Given these two characteristics, we choose to develop a set of recognition patterns and normalization rules specially tailored for the FREQUENCY TEs.We use the following clinical FREQUENCY TE pattern to illustrate how we recognize and normalize FREQUENCY TEs. Notice that instead of showing the actual regular expression, we demonstrate the pattern in a more readable format for didactical purposes. Now consider a simple pattern:Pattern:=({Letter“q”}|{Word“every”})+({Dot}|{Hyphen}|{Space}|{Empty String})+({Digit}|{Number Text})+({Dot}|{Hyphen}|{Space}|{Empty String})+({Time Unit}|{Date Unit})This pattern comprises five portions, one in each line. This pattern recognizes FREQUENCY TEs such as [q-6-h], [Q.8.H], [Q1D], and [every eight hours]. In addition, since that the third portion captures the quantity and that the fifth portion captures the unit, this pattern can be further utilized to normalize these FREQUENCY TEs. For example, after recognizing that [every eight hours] is a FREQUENCY TE and knowing that the quantity is eight and the unit is hour, the normalized value “RPT8H” can be trivially derived, in which (1) the RP are the designated leading symbols for FREQUENCY TEs if they involve repetitions, (2) the T symbol comes from the fact that the FREQUENCY TE use a time unit (hour), (3) the 8 is the quantity been captured, and (4) the H symbol is for the actual time unit—hour.As shown in TempEval-2, CRF is an effective technology in recognizing extents of events and TEs in newswire articles. CRF has also been demonstrated to be very effective in extracting clinical concepts, including medical problems, treatments, and tests [16]. We adopted MALLET [17] to train two CRF models, one for EVENT annotation and the other for TIMEX3 annotation. We encoded labels in IOB2 format [18] with type information. That is, the label B-TIMEX3-DATE represents a token which is the beginning of a date TE, and I-EVENT-TREATMENT represents a token which is inside a treatment event. Through this approach, the CRF models predict the extent and the type of an annotation simultaneously.With the initial tagging from HeidelTime and our FREQUENCY TE tagger, the CRF-based temporal recognition aims at extending the coverage to domain specific TEs, e.g., “post-op day four” and “one day prior to admission.” This is achieved by using domain specific documents, i.e., the clinical narratives, to train the CRF models. Note that the CRF-based temporal recognizer may recognize existing TIMEX3 annotations from HeidelTime as well as the FREQUENCY TE Tagger. In this case, we keep the original annotations, given that the existing annotations were originated from rule-based procedures tuned towards high precision.Our rule-based temporal normalizer is built upon JChronic, an open source date parser in Java. We extend and modify JChronic to better handle the implicit and relative TEs in the clinical narratives. The JChronic program requires “present time” and “direction of offset” as parameters to calculate the time of an input TE. Our three novel normalization strategies guide JChronic’s behavior by resolving the required parameters, i.e., the present time and the direction of offset.Algorithm 1 delineates our temporal normalization steps. The recognized TEs from the previous sequence labeling procedure are stored in a list, sorted by their appearance order in the document. That is, the first TE in the list is the first TE mentioned in the document, and the last TE in the list is the last TE mentioned in the document. The nested for-loops iterate all sentences and TEs sequentially, and try to pair TEs with their corresponding sentences. A sentence can provide contextual cues for the encompassed TEs. Therefore, the corresponding sentence of a TE is considered in normalizing the TE. DATE and TIME TEs are normalized with the procedure normalizeDateTime while DURATION TEs are normalized by another procedure normalizeDuration. Notice that here we do not normalize FREQUENCY TEs since they should be normalized by our clinical FREQUENCY TE tagger in a prior step.Even with these temporal normalization steps, some of the TEs passed from the CRF model may still not be normalized—either because that these are false positive TEs or that the TEs have the unusual patterns that have not been captured by our existing normalization rules. In any case, we choose to drop these TEs to ensure the produced TIMEX3 annotations all have values for their val attribute.Our three strategies take place at various procedures in Algorithm 1. As an overview, we propose contextual alias registry (Strategy CAR) and chronological order of TEs (Strategy COTE) to resolve reference time for implicit TE, e.g., [postoperative day #3] and relative TEs [last evening], respectively. For underspecified TEs, e.g., [Tuesday], we propose distance-based direction determination (Strategy DDD), paired with lexical markers, to identify the direction of offset. The design rationales of each strategy are discussed separately in the following.Algorithm 1. Temporal Normalization StepsInput: A clinical narrative document D and a list of TIMEX3 tags L from D, each possessing values of their id, start, end, text, and type attributes (from our CRF-based temporal recognition procedure).Output: A list of TIMEX3 tags with all their val attributes resolved.sort L by the start attribute values in ascending order;letStartα,Endα,Textα,TypeαandValαbe the respective attribute values of α, ∀α ∈L;let R be a map with keys ADMISSION, DISCHARGE, OPERATION, BIRTH, and NOW;initializeContextualAliasRegistry(R,D)for each sentence s in Ddo/∗ Consider sentence as the context for the TEs within the sentence ∗/letStarts,Endsbe the start and end positions of s in D;for each TIMEX3 tag α in L doif (Startα> Ends) or (Endα< Starts) thencontinue on the next TIMEX3 tag;/∗ Ignore TIMEX3 tags if they are not in the sentence s ∗/endif (Typeαis DATE) or (Typeαis TIME) thenValα:= normalizeDateTime(α,s,R);/∗ Normalize TEs with types DATE or TIME ∗/updateContextualAliasRegistry(R,s,Valα);else if (Typeαis DURATION) and (Textαcontains “ to ”) thenValα:= normalizeDuration(α);/∗ Normalize TEs with type DURATION ∗/endifValαis nullthenremove α from L;/∗ Remove TIMEX3 tags if the TEs could not be normalized ∗/endendendreturnL;Procedure initializeContextualAliasRegistry(R,D) :/∗ Strategy CAR ∗/R.ADMISSION := R.NOW := D.SECTIME.ADMISSION;R.DISCHARGE := D.SECTIME.DISCHARGE;R.OPERATION := null; R.BIRTH := null;Procedure updateContextualAliasRegistry(R,s,Valα) :/ ∗ Strategy CAR ∗/if R.OPERATION is null and s has a procedure word then/∗MetaMap semantic type =topp ∗/R.OPERATION := Valα;/∗Found Operation Date ∗/endif R.BIRTH is null and s contains “born” or “birth” thenR.BIRTH := Valα;/∗Found Date of Birth ∗/endif R.NOW ⩽ Valαthen/∗ Strategy COTE ∗/R.NOW := Valα;endFunction normalizeDateTime(α,s, R) :if (Textαmatches any triggers) or (s matches any triggers) thenValα’ := normalizeWithAlias(Textα, s, R);/∗ Strategy CAR;see Algorithm 2 ∗/elseValα’ := normalizeWithJchornic(Textα, s, R);/∗ Strategy COTE&DDD;see Algorithm 3 ∗/endreturnValα’;Function normalizeDuration(α) :(TE1, TE2) := split Textαby “ to ”;Valα’ := normalizeDuration(TE1, TE2);/∗ In that it determines the difference and time granularity ∗/return Valα’;In contrast to newswire articles, there are significant dates that we normally expect in a clinical document: Admission Date, Discharge Date, Operation Date, and/or Date of Birth (for childbearing). We observe from the corpus that it is common for implicit and relative TEs to anchor on these domain-specific contextual alias dates. As such, we maintain a contextual alias registry in the temporal normalization process (Table 3). The actual dates/times for the aliases are initialized by the initializeContextualAliasRegistry procedure and updated by the updateContextualAliasRegistry procedure in Algorithm 1. To use the aliases in the normalization, each alias has a set of triggering rules such that if a TE or its adjacent words match one of the rules, the respective time of the alias will be considered as the reference time (Algorithm 2).Algorithm 2. Temporal Normalization Using Contextual Alias RegistryInput: A temporal expression text Textα, the sentence s which contains Textα, and our contextual alias registry R.Output: A normalized value of Textα.RefTime := retrieve the alias from R by matching Textαor s the with the triggers defined in Table 3;TempShift := determine the temporal shift of Textαwith respect to RefTime;Valα’ := apply TempShift on RefTime;returnValα’;It is common and intuitive to narrate stories in a chronological order. From the training documents, we observed a very high correlation between the appearance order of DATE/TIME TEs in a document and their timestamps (the average spearman rank correlation across all training texts is around 0.80). However, occasionally there are retrospective statements inserted within the main storyline. We posit that anchoring non-explicit TEs to a reference point in the retrospective statements is prone to be erroneous. Therefore, we propose a novel heuristic to improve the resolution of reference time which embodies a chronological constraint.Suppose that the temporal normalization is executed sentence by sentence and from left to right in a sentence, we maintain a reference time denoting the largest timestamp normalized from the TEs thus far. We allow absolute as well as relative TEs as long as the type is DATE or TIME. Fig. 2illustrates the difference between the chronological time heuristic and another common heuristic, the “previously mentioned time.” Suppose that all the TEs in Fig. 2 are DATE TEs and that TE4 is an underspecified TE requiring a reference time as an anchor. The chronological time heuristic chooses TE2 as the reference time because for the content parsed thus far, TE2 represent the rightmost time point on the timeline axis (comparing to TE1 and TE3). The previous mentioned time heuristic, on the other hand, will use TE3 as a reference time for TE4 because TE4 follows TE3.Verb tense and lexical markers (e.g., “past” or “next”) are considered effective devices to determine the direction of implicit and relative TEs in newswire articles. However, we find that tense is not an appropriate strategy in the domain of clinical narratives. This is due to the facts that the statements in clinical narratives are mostly retrospective, which means that the texts are predominately past-tensed. As such, we do not employ tense in determining the direction. We, instead, combine lexical markers with a novel distance-based strategy. That is, when lexical markers are absent from the context, we resolve the direction problem by choosing whichever direction gives a closer temporal distance to the discharge date (Algorithm 3). Akin to the COTE strategy, it is more likely to have a temporal direction which results in a shorter temporal distance to the discharge date. For example, suppose that the normalizing TE is [Tuesday] and that the reference time and the discharge date are known to be “20121015” (Monday) and “20121017” (Wednesday), respectively. If the direction of offset is past, the normalized value for [Tuesday] will be “20121009.” On the other hand, if the direction of offset is future, the normalized value will be “20121016.” Between the two possibilities, the second one seems more likely because it gives a time point that is closer to the discharge date. However, we ignore the direction that will lead to a normalized time which is greater than the discharge date. Continue with the settings in the previous example, but substitute the normalizing TE with [Friday]. We ignore the future direction because it gave a time point “20121019,” which is after the actual discharge date.Algorithm 3. Temporal Normalization Using JChronicInput: A temporal expression text Textα, the sentence s which contains Textα, and our contextual alias registry R.Output: A normalized value of Textα.RefTime := retrieve R.NOW from R;/∗ Strategy CAR ∗/ifTextαor s contains a lexical marker of direction thendirection := determine the direction according to the lexical marker in Textαor s;Valα′:= jchronic(presentTime=RefTime, direction=direction, temporalExpression=Textα);elseValα1:= jchronic(presentTime=RefTime, direction=PAST, temporalExpression=Textα);Valα2:= jchronic(presentTime=RefTime, direction=FUTURE, temporalExpression=Textα);Distance1 := (R.DISCHARGE −Valα1);Distance2 := (R.DISCHARGE −Valα2);if (Distance1 > Distance2) and (Distance2 > 0) then/∗ Strategy DDD ∗/Valα′:=Valα2;elseValα′:=Valα1;endendreturnValα’;The post-processing is a set of classification routines for the remaining EVENT/TIMEX3 attributes. Specifically, there are polarity and modality attributes for EVENT annotation and Mod attribute for TIMEX3 annotation that need to be determined.Polarity is one of the required attributes for EVENT annotations. It specifies whether the described clinical event is negated or not. The polarity tagging in MedTime is performed by NegEx [19]. NegEx is a simple regular expression algorithm for negation determination in clinical documents. It has been widely adopted in clinical NLP systems. We noted that there are some recent studies that apply CRF in determining the scope of negations [20]. We found there are several issues that merit further exploration. To keep this study manageable, we chose to use the well-known NegEx, and plan to examine the efficacy of machine-learning-based polarity tagging in the future.The cascade of CRF-based sequence labeling and SVM-based classification has been demonstrated as an effective design in previous studies of medical information extraction [21]. Here we train an SVM classifier for EVENT modality classification and another for TIMEX3 mod classification using the LIBSVM library [22]. The modality/mod classifications share the same feature set for the CRF-based sequence labeling, except that here we also include token N-grams (1⩽N⩽3) as new features. The reason to have an extended feature set is that the original feature set only captures features at the token level. Although a token-level feature set is sufficient for sequence labeling, we suspect that it may not be adequate for the modality/mod classification because the training and prediction entity here is an event or a TE which can have an arbitrary number tokens. In other words, the token N-grams features of event expressions or TEs can be considered as annotation-level features in building the SVM classifiers.There are principally two categories of evaluation for the EVENT/TIMEX3 task: extent and attribute. We first provide a brief summary of each, followed by the evaluation results of MedTime.There are two ways to define accuracy of an extent prediction: exact extent match and partial extent match. For exact extent match, a prediction is considered accurate only when the predicted extent is exactly the same as the gold standard extent. On the other hand, for partial extent match, we consider a prediction accurate as long as the predicted extent overlaps the gold standard extent. The 2012 i2b2 challenge uses partial extent match as the default extent evaluation criterion. With this definition of correctness, the evaluation metrics for EVENT/TIMEX3 extent recognitions are micro-averaged precision, recall, and f-measure. Given a test corpus D and let TPd,FPd,FNddenote, respectively, the numbers of true positive, false positive, and false negative EVENT/TIMEX3 extent predictions in a document d, whered∈D:Micro-Averaged Precision(P)=∑d∈DTPd∑d∈D(TPd+FPd)Micro-Averaged Recall(R)=∑d∈DTPd∑d∈D(TPd+FNd)Micro-AveragedF-Measure(F)=2(P×R)P+RThe evaluation for attribute match consists of two steps. It first matches the system predictions with the gold standards by their extents. Then, among the total matched predictions, attribute score is calculated as the percentage of correct attribute predictions. Among the attribute match scores, the TIMEX3val match score is arguably the most critical one as it signifies the efficacy of a temporal information extraction system in recovering temporal information from TEs.For event recognition, MedTime achieved an 87.94% accuracy (F-measure) against hand-annotated data in the testing corpus (Table 4). The performance is comparable with the best performing system TIPSem in the TempEval-2 event recognition task.Through our stepwise evaluations on MedTime’s TIMEX3 tagging pipelines, we decompose the contribution of each major procedure in Table 5. The first major procedure was HeidelTime tagging. We observed a very high precision from HeidelTime. However, the recall and val match score at this step were both considerably low. In the second step, the parser tailored for FREQUENCY TEs increased both recall and val match score by about 8%. Given that FREQUENCY only accounts for about 10% of total TIMEX3 tags in the testing corpus, the FREQUENCY TE tagger provided considerable enhancement of the result. The CRF-based sequence labeling in the third step significantly improved the overall recall. This major improvement brought the f-measure to 0.88. Finally, the rule-based temporal normalizer increased the val score from 0.41 to 0.68. This demonstrates the efficacy of our rule-based temporal normalizer as well as our normalization strategies.

@&#CONCLUSIONS@&#
Temporal information extraction from clinical narratives is of critical importance to many clinical applications. For the 2012 i2b2 clinical temporal relations challenge, we demonstrated an effective solution to the EVENT/TIMEX3 track and presented a temporal information extraction system, MedTime.Rule-based systems tend to have very high precision, but often with relatively low recall. On the other hand, machine learning approaches enable reasonable treatments of unanticipated and novel cases. For complex problems, such as temporal information extraction, it seems to be a reasonable design to combine the two approaches. Our experiments demonstrate the efficacy of this hybrid design.MedTime is still under a continuous development towards a comprehensive temporal information extraction platform. Our error analysis suggested several directions for further enhancement. One limitation of current MedTime is the lack of temporal relation identification (i.e., TLINK annotation). We are working on building such component, which could enable MedTime to provide a broader range of practical applications in these clinical contexts in the future.