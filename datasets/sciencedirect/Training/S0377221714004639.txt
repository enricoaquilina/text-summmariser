@&#MAIN-TITLE@&#
Distributed localized bi-objective search

@&#HIGHLIGHTS@&#
A new distributed heuristic approach is designed for approximating the Pareto set of bi-objective optimization problems (DLBS).DLBS is based on parallel cooperative computation, objective space decomposition, and adaptive search.DLBS is studied, experimented, and deployed on a cluster of hundreds of core.The DLBS efficiency is measured in terms of approximation quality, computational time and scalability.

@&#KEYPHRASES@&#
Multiple objective programming,Combinatorial optimization,Parallel and distributed computing,Evolutionary computation,

@&#ABSTRACT@&#
We propose a new distributed heuristic for approximating the Pareto set of bi-objective optimization problems. Our approach is at the crossroads of parallel cooperative computation, objective space decomposition, and adaptive search. Given a number of computing nodes, we self-coordinate them locally, in order to cooperatively search different regions of the Pareto front. This offers a trade-off between a fully independent approach, where each node would operate independently of the others, and a fully centralized approach, where a global knowledge of the entire population is required at every step. More specifically, the population of solutions is structured and mapped into computing nodes. As local information, every node uses only the positions of its neighbors in the objective space and evolves its local solution based on what we term a ‘localized fitness function’. This has the effect of making the distributed search evolve, over all nodes, to a high quality approximation set, with minimum communications. We deploy our distributed algorithm using a computer cluster of hundreds of cores and study its properties and performance onρMNK-landscapes. Through extensive large-scale experiments, our approach is shown to be very effective in terms of approximation quality, computational time and scalability.

@&#INTRODUCTION@&#
Many real-life problems arising in a wide range of application fields can be modeled as multi-objective optimization problems. One of the most challenging issues in multi-objective optimization is to identify the set of Pareto optimal solutions, i.e., solutions providing the best compromises between the objectives. It is well understood that computing such a set is a difficult task. Designing efficient heuristic algorithms for multi-objective optimization requires one to tackle the classical issues arising in the single-objective case (e.g., intensification vs. diversification), but also and more importantly, to find a set of solutions having good properties in terms of trade-off distribution in the objective space.When dealing with such sophisticated problems, it is with no surprise that most existing approaches are costly in terms of computational complexity. A natural idea is to subdivide the problem being solved into subtasks which can be processed in parallel. This is a very intuitive idea when dealing with computing intensive applications, not only in the optimization field but in computer science in general. Besides, with the increasing popularity of high performance (e.g., clusters), massively parallel (e.g., multi-cores, GPUs), and large-scale distributed platforms (e.g., grids, clouds), it is more and more common to distribute the computations among available resources taking much benefit of the induced huge computational power. Many parallel/distributed models and algorithms have been designed for specific optimization contexts. This witnesses the hardness of the tackled problems and the complexity of related algorithmic issues. Multi-objective optimization does not stand for an exception, since the multi-objective nature of the problem being solved induces additional computing intensive tasks.One can find an extensive literature on designing parallel/distributed multi-objective solving methods (Van Veldhuizen, Zydallis, & Lamont, 2003; Coello Coello, Lamont, & Van Veldhuizen, 2007; Talbi et al., 2008; Bui, Abbass, & Essam, 2009). Most existing approaches are designed in a top-down manner, starting with a centralized algorithm requiring a global information about the search state; and then trying to adapt its components to the distributed/parallel computing environment. This design process usually requires to tackle parallel-computing issues which are challenging to solve efficiently and/or may impact the performance of the original sequential optimization algorithm. In contrast, locality in distributed computing is a well-known general paradigm that states that global information is not always necessary to solve a given problem and local information is often sufficient (see e.g., Peleg (2000)). Therefore, adopting a localized approach when tackling a given problem can allow one to derive novel algorithms which are by essence parallel and designed in a bottom-up manner. Those algorithms are more likely to allow distributed resources to coordinate their actions/decisions locally, and to take full benefit of the available computational power.In this paper, we describe a new simple and effective generic scheme dedicated to bi-objective heuristic search in distributed/parallel environments. Our approach is inherently local, meaning that it is thought to be independent of any global knowledge. Consequently, its deployment on a large-scale distributed environment does not raise parallel-specific issues.Generally speaking, each computing node contains a candidate solution and is able to search in a region of the search space in coordination with other neighboring nodes. The sub-region where a node operates is delimited implicitly in an adaptive way based on the relative position of its cooperating neighbors in the objective space. The way local cooperation is designed, as well as its induced optimization process, are the heart of our approach. In our study, we propose novel localized cooperative strategies inspired by the classical weighted-sum scalarizing function (Ehrgott, 2005) and hypervolume-based approaches (Zitzler & Thiele, 1999), without requiring any global knowledge about the search state. The designed rules allow distributed nodes to self-coordinate their decisions adaptively and in an autonomous way while communicating a minimal amount of information; thus being effective when deployed on a real and large-scale distributed environment. To evaluate the performance of our approach, we conduct extensive experiments involving more than two hundred computing cores, and usingρMNK-landscapes (Verel, Liefooghe, Jourdan, & Dhaenens, 2013) as a benchmark. As baseline algorithms, we consider both a pure parallel strategy and an inherently sequential approach. Our experimental results show that our localized approach is extremely competitive in terms of approximation quality; while being able to achieve near-linear speed-ups in terms of computational complexity. Besides, we provide a comprehensive analysis of our approach highlighting its properties and dynamics.In Section 2, we review existing works related to multi-objective optimization, especially those dealing with parallel and distributed issues. In Section 3, we describe the distributed localized bi-objective search approach proposed in the paper, and give a generic fully distributed scheme which can be instantiated in several ways. In Section 4, we provide the experimental setup of our analysis. In Section 5, we present numerical results and we discuss the properties of our approach. Finally, we conclude the paper in Section 6 and we discuss some open research issues.In the following, we first introduce the basics of multi-objective optimization and then we position our work with respect to the literature.A multi-objective optimization problem can be defined by an objective function vectorf=(f1,f2,…,fM)withM⩾2, and a setXof feasible solutions in the solution space. In the combinatorial case,Xis a discrete set. LetZ=f(X)⊆RMbe the set of feasible outcome vectors in the objective space. To each solutionx∈Xis then assigned exactly one objective vectorz∈Z, on the basis of the function vectorf:X→Zwithz=f(x). In a maximization context, an objective vectorz∈Zis dominated by an objective vectorz′∈Z, denoted byz≺z′, iff∀m∈{1,2,…,M},zm⩽zm′and∃m∈{1,2,…,M}such thatzm<zm′. By extension, a solutionx∈Xis dominated by a solutionx′∈X, denoted byx≺x′, ifff(x)≺f(x′). A solutionx★∈Xis said to be Pareto optimal (or efficient, non-dominated), if there does not exist any other solutionx∈Xsuch thatx★≺x. The set of all Pareto optimal solutions is called the Pareto set (or the efficient set). Its mapping in the objective space is called the Pareto front. One of the most challenging task in multi-objective optimization is to identify a complete Pareto set of minimal size, i.e. one Pareto optimal solution for each point from the Pareto front.However, in the combinatorial case, generating a complete Pareto set is often infeasible for two main reasons (Ehrgott, 2005): (i) the number of Pareto optimal solutions is typically exponential in the size of the problem instance and (ii) deciding if a feasible solution belongs to the Pareto set may be NP-complete. Therefore, the overall goal is often to identify a good Pareto set approximation. To this end, heuristics in general, and evolutionary algorithms in particular, have received a growing interest since the late eighties (Deb, 2001; Coello Coello et al., 2007).A large body of literature exists concerning parallel multi-objective algorithms. Two interdependent issues are usually addressed: (i) how to decrease the computational complexity of a specific multi-objective algorithms and (ii) how to make parallel processes cooperate to improve the quality of the Pareto set approximation, see e.g., Zhu and Leung (2002), Jozefowiez, Semet, and Talbi (2002), Deb, Zope, and Jain (2003), Coello Coello and Sierra (2004), Melab, Talbi, and Cahon (2006), Tan, Yang, and Goh (2006), Coello Coello et al. (2007), Mostaghim, Branke, and Schmeck (2007), Hiroyasu, Yoshii, and Miki (2007), Durillo, Nebro, Luna, and Alba (2008), Talbi et al. (2008), Figueira, Liefooghe, Talbi, and Wierzbicki (2010), Mostaghim (2010). Often, parallel and cooperative techniques implicitly come with the idea of decomposing the search into many sub-problems so that a diversified set of solutions, in terms of Pareto front quality, can be obtained. The main challenge is on defining efficient strategies to either divide the search space or the objective space.For instance, the population induced by a particle swarm multi-objective algorithm is divided by Mostaghim et al. (2007) into sub-swarms which are then coordinated through a master–slave approach by injecting the so-called subswarm-guides in each sub-population. The diffusion model (Van Veldhuizen et al., 2003) and the island model (Tomassini, 2005) have also been extensively adopted to design distributed cooperative methods. In the so-called cone separation technique (Branke, Schmeck, Deb, & Reddy, 2004), the objective space is divided into regions distributed over some islands. Each island explores the same search space. When a solution is outside its corresponding objective space region, it is migrated to neighboring islands. This idea is refined by Streichert, Ulmer, and Zell (2005) using a clustering approach. Bui et al. (2009) propose a distributed framework where a number of adaptive spheres spanning the search space and controlled by an evolutionary algorithm is studied. In Zhu and Leung (2002), a model where fully connected islands exchange information about their explored regions is considered. A strength Pareto evolutionary algorithm (Zitzler & Thiele, 1999) is then adopted to form the backbone for each island, but it is additionally equipped with a so-called adjusting instructive phenotype/genotype distance measure, computed according to the information exchanged with all other islands. In Zhang and Li (2007), the authors described a decomposition-based approach, the so-called MOEA/D, which associates with each single solution a fixed scalar single-objective function called a sub-problem. Given a solution and its corresponding sub-problem, a new offspring is created using the genotypes of solutions corresponding to neighboring sub-problems. This process is then repeated iteratively for each sub-problem which makes it inherently sequential. Some recent attempts exist in order to adaptively define the sub-problem parameters in the sequential setting (Qi et al., 2014). Parallel extensions and models for MOEA/D are described by Nebro and Durillo (2010) and Durillo, Zhang, Nebro, and Alba (2011) for shared memory systems. The so-obtained approximation quality is however shown to deteriorate significantly for more than 8 parallel processes.To the best of our knowledge, existing parallel and cooperative algorithms usually treat a multi-objective optimization process in a global manner and do not fully explore other more local alternatives when thinking the role of cooperation.The approach proposed in this paper can be viewed as a parallel and cooperative method, since solutions in our approach shall both evolve in parallel while cooperating locally. However, the information exchanged between neighboring nodes does not involve any migration of solutions as it is the case in most island-based approaches. It can also be viewed as a decomposition-oriented strategy since it implicitly induces a partition of the global search in many sub-search processes, focusing on different regions of the objective space. The search process is however dynamically distributed over the objective space without relying on any global information, e.g., elite solutions, external population, global fitness measure, etc. In other words, we do not explicitly partition the search space through cooperating entities (islands, processes, etc.), nor we explicitly partition the objective space among parallel entities. We simply evolve solutions in an adaptive manner based on localized fitness functions, which are instantiated dynamically. Unlike previous centralized/sequential adaptive approaches, we focus on distributing the search among cooperating computing entities, while relying on a strictly local information learned from neighbors.Let us consider that we are given a set of n computing nodes scattered over a network. Our idea is to distribute a population ofμsolutions among the n computing nodes with the aim of (i) evolving them towards a good Pareto set approximation and (ii) naturally fitting the distributed nature of the computing environment to significantly gain in terms of execution time. For this purpose, we structure the population of solutions following a line where every solution, except those being at the two extremes of the line, have exactly two distinct neighbors. According to this logical line structure, we design local rules based on the relative positions of neighboring solutions in the objective space. These rules are based on the definition of localized fitness functions allowing current solutions to be replaced by new candidate solutions cooperatively; and to evolve distributively while exploring diversified regions of the objective space. The localized fitness function, denoted byLF, is the key ingredient of our approach.In the following, we start describing our approach in the scenario where each solution is mapped to a single computing node. This specific scenario shall allow us to better illustrate the locality of our distributed approach and its parallel nature in a more comprehensive way. Later, we shall show how we can extend to other scenarios where an arbitrary number of computing nodes is considered.In the following sections, we consider that each solution is assigned to one computed node such thatn=μ. In this case, and since we structure the population according to a line, we can also view computing nodes as organized in a logical communication line graphLn=(v1,v2,…,vn), i.e., nodev1(resp.vn) holding solutionx1can communicate with neighborv2(resp.vn-1) and any other nodevi, withi∈{2,…,n-1}, holds solutionxiand can communicate with neighborsvi-1andvi+1, holding respectively solutionsxi-1andxi+1. In the following, we interchangeably use the terms node and solution to describe both the evolution and the communication mechanisms involved in our approach.Algorithm 1Dlbs – Pseudo-code for every nodevi∈Ln1xi←initial solution corresponding to nodevi;2 repeat3 /∗ communicate positions ∗/4zi←z1i,z2ithe position of solutionxiin the bi-objective space,zi=f(xi);5 Sendzito neighboring nodes;6Zi←receive neighboring positions;7 /∗ variation ∗/8Si←New_Solutions(xi)9 /∗ selection for replacement ∗/10xi←Select(Si,LFZi);11 untilstopping_condition;The proposed distributed localized bi-objective search (Dlbs) algorithm is illustrated in the high-level pseudo-code of Algorithm 1. Distributively in parallel, every computing node in the line graphLnoperates in local rounds until a stopping condition is satisfied. At each communication round, a node simply exchanges the current position of its incumbent solution in the objective space with its neighbors, i.e., every nodevi∈Lnsends the positionf(xi)=zi=z1i,z2iof its current solutionxito its neighbors and receives the positionsZi=(zi-1,zi+1)sent symmetrically by its neighbors.After each local communication round, a nodevievolves its current solutionxiin the following way. First, it generates a bunch of new solutionsSibased on the current solutionxi, (functionNew_Solutions, Line 8). This function is to be understood as any component that, given a solution, is able to generate a set of candidate solutionsSiby means of a problem specific variation operator. Among the candidate setSi, a new solution is selected to replace the current one (functionSelect, Line 10), and so on, concurrently for all nodes.The line graph connecting solutions can then be viewed as a line linking some points in the objective space. The goal is to push the line a little bit more towards the Pareto front at each round by replacing current solutions with new ones. The selection for replacement is made on the basis of a scalar value computed by means of a localized fitness function, denoted byLF. Notice that functionLFis itself parametrized by the pairZi, referring to the positions communicated by neighboring nodes. We emphasize the fact that functionLFdoes not use any other kind of information but the position of neighboring solutions; thus making it very local in nature. In the following paragraphs, we describe in detail how the selection for replacement instruction (Line 10) is instantiated in the proposed Dlbs algorithm.We start by describing the local rules for both nodesv1andvn, holding the extreme solutionsx1andxn, which play a particular role in our distributed algorithm. In fact, extreme nodesv1andvnshall guide the search through the extreme points of the Pareto front, following the lexicographic order implied by the objective functions. For nodev1, we consider that a solution x is lexicographically better than or equal to a solutionx′, iff1(x)>f1(x′)or iff1(x)=f1(x′)andf2(x)>f2(x′). Symmetrically, for nodevn, a solution x is lexicographically better than or equal to a solutionx′, iff2(x)>f2(x′)or iff2(x)=f2(x′)andf1(x)>f1(x′). Using respectively these lexicographical orders, the local selection used by nodesv1andvnto replace their current solutions is then fully defined. Notice that each lexicographic optimal solution is a Pareto optimal solution of the initial multi-objective problem, mapping to an extreme point of the Pareto front (Ehrgott, 2005).The local strategy applied by nodesv1andvnis independent of their respective neighborsv2andvn-1. This is essentially due to the fact that we want the extreme nodes to push the line graph as much as possible to the extreme regions of the Pareto front. For other nodesvi,i∈{2,…,n-1}, the selection for replacement is based on a localized fitness functionLFthat depends on neighbors’ positions. At each step, the candidate solution with the bestLF-value is selected for the next round. In the next paragraphs, we define and discuss the localized fitness functions designed for Dlbs.Two localized fitness functions, to be used within the Dlbs algorithm, are proposed below. They are based on two different strategies for aggregating the objective function values.Our first localized fitness function, denoted byLFOD, is based on a classical scalarizing approach from multi-objective optimization, namely a weighted-sum aggregation. At each nodevi,i∈{2,…,n-1}, letZibe the pair of neighboring positions for nodevi. More specifically,z1i-1,z2i-1(resp.z1i+1,z2i+1) refers to positionzi-1(resp.zi+1) communicated by neighborvi-1(resp.vi+1). Without loss of generality, we assume thatz1i-1⩽z1i+1, otherwise nodevisimply interchanges the coordinate of its neighbors in the following equations. Given a candidate solution x taken from the candidate setSigenerated at nodevi,xis scored according to the following function.(1)LFODZi(x)=w1·f1(x)+w2·f2(x)wherew1=z2i-1-z2i+1,w2=z1i+1-z1i-1Notation OD stands for Orthogonal Direction. This is inspired by the dichotomic scheme proposed by Aneja and Nair (1979). In such approach, weighting coefficient vectors are determined according to the position of solutions found in previous iterations. However, in our approach we use the current neighboring positions at each node to evolve the corresponding solution at runtime. The weighting coefficient vectorw=(w1,w2)is then calculated distributively at each node as the orthogonal of the segment defined byzi-1andzi+1, as illustrated in Fig. 1. This localized fitness function defines the search direction of the distributed algorithm concurrently at each node of the line graph. It is important to remark that the computed weighting coefficient vectors can change from one round to another. It may also happen that a weighting coefficient has a negative value, which should not be necessarily perceived as a drawback, since it could help to explore diversified regions. Notice moreover that a number of Pareto optimal solutions, known as unsupported solutions, are not optimal for any definition of the weighting coefficients (Ehrgott, 2005). Our distributed strategy using an orthogonal-directed localized fitness functionLFODwill be denoted by DlbsOD in the remainder of the paper.The second variant of our localized fitness function, denoted byLFH, is based on the hypervolume indicator (Zitzler & Thiele, 1999; Zitzler, Thiele, Laumanns, Foneseca, & Grunert da Fonseca, 2003). Many efficient evolutionary multi-objective optimization algorithms are based on optimizing the hypervolume value of the output set, see e.g.Beume, Naujoks, and Emmerich (2007), Bader and Zitzler (2011). Given M objective functions, the hypervolume indicator value of a set A of mutually non-dominated objective vectors can be defined as follows.(2)IH(A)=Λ⋃z∈A[z1,z1ref]×⋯×zM,zMrefwithzref∈Za reference point andΛ(·)the Lebesgue measure. The hypervolume contribution of a pointz∈Zwith respect to a non-dominated set A is then given as follows (Beume et al., 2007).(3)ΔH(z,A)=IH(A)-IH(A⧹{z})Dominated points do not contribute to the hypervolume. In the two-objective case, if we assume that the elements of the non-dominated set A are sorted in the increasing order with respect tof1-values, the hypervolume contribution can be reduced as follows.(4)ΔH(zi,A)=z1i-z1i-1·z2i-z2i+1In our distributed approach, a node does not have a global view of the current population of solutions being processed in parallel by other nodes. The only information a nodevican use is the position of its two neighboring solutions in objective space, i.e.Zi. Without loss of generality, let us assume thatz1i-1⩽z1i+1. Our second hybrid hypervolume-based localized fitness function is defined as follows.(5)LFHZi(x)=f1(x)-z1i-1·f2(x)-z2i+1iff1(x)⩾z1i-1andf2(x)⩾z2i+10otherwiseThis is illustrated in Fig. 1. Notice thatLFHis though to be the local adaptation/version of Eq. (4). In particular, it intuitively states that, by selecting those candidate solutions maximizing the local hypervolume contribution at each node, the global hypervolume of the new set of solutions is likely to be better than the previous one. However, it may happen that all solutions generated in the candidate set have aLFH-value of 0, e.g. when they are all dominated by at least one neighboring position. Therefore, in this special case where no solution has a positive hypervolume contribution, we use the orthogonal-directed localized fitness function in order to avoid a random selection and make the current solutions evolving closer to the Pareto front. When using the hybrid hypervolume-based localized fitness functionLFH, our approach is denoted by DlbsH.In the previous paragraphs, the number of computing nodes n is assumed to be equal to the population sizeμ, i.e.,n=μ. However, in order to achieve a better Pareto set approximation, one might want to use a population size which is substantially larger than the number of computing nodes available in practice. In this case, we argue that restrictions on the number of available computing resources cannot prevent the implementation and the deployment of the Dlbs approach for a large population size.For the scenario wheren<μ, we shall simply increase the number of solutions evolving at every computing node. For simplicity, let us assume thatμis a multiple of n. As done previously, the population is then structured following a line graphLμand every solution in the line graph is evolved following the previously defined localized rules. However, the line graph is now split into n contiguous sub-lines of lengthμ/n. In other words, we distribute the population evenly among available computing resources by assigning a unique sub-line to every single computing node. Every nodevj∈{1,…,n}is then responsible for evolving the whole path of solutionsLnj=x(j-1)·μn+1,…,xj·μnaccording to the same localized rules. It is easy to see that no communication is required for any solution inside a sub-lineLnj; since the position of solutions insideLnjare available at the same computing nodevj. Communication is only required in order to exchange the positions of solutions being at the boundaries of the sub-line, i.e. solutionsx(j-1)·μn+1andxj·μnfor computing nodevj. Notice that in the case whereμbmodn≠0, it is also easy to manage the size of the sub-lines to be the same up to a difference of one.In the remainder of the paper, we use the term granularity to refer to the number of computing nodes with respect to the population size in Dlbs. The lowest granularity is for the configuration wheren=μ, i.e., one solution per node as depicted in the pseudo-code of Algorithm 1; and the highest one is forn=1, i.e., all solutions are assigned to a single computing node. Different granularities in these two extreme ranges will be investigated in order to evaluate the performance of Dlbs from a purely parallel perspective. For clarity, notation Dlbs(n,μ)shall refer to a configuration with n computing nodes and a population of sizeμ. It is important to remark that for a given population size and a given stopping condition, the granularity induced by the number of computing nodes n does not have any impact on the quality of the obtained Pareto set approximation.This section summarizes the experimental setting allowing us to analyze the proposed approach on the bi-objectiveρMNK-landscapes, with a broad range of problems with different structures and sizes.In the single-objective case, the family of NK-landscapes is a problem-independent model used for constructing multimodal landscapes (Kauffman, 1993). Feasible solutions are represented as binary strings of size N, i.e. the solution space isX=0,1N. Parameter N refers to the problem dimension (i.e. the bit-string length), and K to the number of variables that influence a particular position from the bit-string (i.e. the epistatic interactions). In single-objective NK-landscapes, the objective functionf:0,1N→[0,1)is defined as follows.(6)f(x)=1N∑i=1Nci(xi,xi1,…,xiK)whereci:0,1K+1→[0,1)defines the component function associated with variablei∈{1,…,N}, and whereK<N. By increasing the number of variable interactions K from 0 to(N-1), NK-landscapes can be gradually tuned from smooth to rugged. In this work, we set the position of these interactions uniformly at random.In multi-objective NK-landscapes (Aguirre & Tanaka, 2007), component values are defined randomly and independently for every objective so that it results in a set of M independent objective functions. More recently, multi-objective NK-landscapes with correlated objective functions have been proposed (Verel et al., 2013). Component values now follow a multivariate uniform law of dimension M, defined by a correlation matrix. We here consider the same correlation between all pairs of objective functions, given by a correlation coefficientρ>-1M-1. The same epistasis degreeKm=Kis used for allm∈{1,…,M}. For more details onρMNK-landscapes, the reader is referred to Verel et al. (2013).We recall that our distributed strategies are denoted by DlbsOD and DlbsH when an orthogonal-directed localized fitness functionLFOD, or respectively, a hybrid hypervolume-based localized fitness functionLFH, is used. To evaluate the relative approximation quality of our algorithms, we compare them against a pure parallel approach, denoted by Piws, and a pure sequential one, denoted by Hemo. They are sketched below.•Piws (Parallel Independent Weights Search) is a weighted-sum scalarized approach, where weighting coefficient vectors are uniformly defined a priori, and do not change during the search process. For each nodevi,i∈{1,…,n}, the weighting coefficient vector is defined as follows.(7)w1i=n-in-1andw2i=1-w1iPiws consists in running multiple rounds of parallel independent heuristic search algorithms following different fixed weighting coefficient vectors. Compared to our localized strategies, no information is communicated between nodes when running Piws. This allows us to appreciate the impact of our localized strategies on approximation quality and also the impact of distributed communications on running time.Hemo is a sequential and global hypervolume-based evolutionary multi-objective optimization algorithm (Hemo). It is based on dominance-depth ranking, and on the contributing hypervolume at the second-level sorting criterion. In other words, the second-level sorting criterion of NSGA-II (Deb, Agrawal, Pratap, & Meyarivan, 2002), i.e. the crowding distance, is replaced by the contributing hypervolume, as in the hypervolume-based localized fitness function, but here used in a more global way. The resulting algorithm can also be seen as a (μ+λ) variant of SMS-EMOA (Beume et al., 2007), with a one-shot replacement strategy. Notice that we have implemented Hemo using the fastO(μlogμ)dominance-depth ranking procedure (Deb, 2001). Hemo allows us to appreciate how efficient our local strategies are compared with a global strategy having a full global knowledge of the search state, i.e. the whole current population.We remind that N refers to the problem dimension ofρMNK-landscapes. The number of computing nodes is denoted by n. The population size is denotedμ. The initial population is generated as random binary strings. At every round/iteration of Dlbs or Piws, we generate a set ofλoffspring per solution using an independent bit-flip mutation operator, where each bit is mutated at random with a probability1/N. In other words, a(1+λ)-evolutionary algorithm iteration with stochastic bit-flip mutation is performed for each single solution in the population. In the reported results, we shall consider the case whereλis set to N. For each solution in the population, we perform N iterations. The total number of evaluations for Dlbs and Piws is thusμ×λ×N=μ×N2.For the competing Hemo algorithm, the population sizeμand the number of offspringλare set to same values than Dlbs and Piws, i.e.,λ=N. The Hemo variation operator is also based on bit-flip mutation only; i.e., no recombination operator is used. For comparison purposes, the stopping condition of Hemo is given in terms of a maximum number of evaluations which is chosen to be same than the other algorithms, i.e.,μ×Ngenerations and henceμ×N2evaluations in total.All algorithms have been implemented with the help of the Paradiseo software framework (Liefooghe, Jourdan, & Talbi, 2011; Humeau, Liefooghe, Talbi, & Verel, 2013), available at the following URL: http://paradiseo.gforge.inria.fr/. The distributed implementation and the communication between nodes have been done using the standard MPI library. In our parallel implementation, every two MPI processes exchanging the solution positions are implicitly synchronized using standard MPI send and receive blocking primitives. However, no barrier is used to synchronize the whole MPI processes. In this way, our implementation is very faithful to the semi-synchronous pseudo-code given in Algorithm 1. The experiments have been conducted on a cluster of 70 computing nodes inter-connected in a distributed computing environment running under CentOS5.2, with a total number of 600 cores, 6 TeraFlops, and 1872GB RAM. The following nodes have been used during our experiments: up to 30 computing nodes with two quad-core Opterons Shangai processors (2.5GHz, 16GB RAM), and up to 22 computing nodes with two quad-core Intel Xeon L5520 processors (2.26GHz, 24GB RAM).In the following, we conduct an experimental study on the influence of the problem dimension (N), the non-linearity (K), and the objective correlation (ρ) for bi-objectiveρMNK-landscapes (M=2) on the performance of the algorithms under study in the paper. In particular, we investigate the following parameters:N∈{128,256,512,2048},K∈{4,8}andρ∈{-0.7,0.0,+0.7}. One instance, generated at random, is considered per parameter setting. The correspondingρMNK-landscape instances can be found at the following URL: http://mocobench.sourceforge.net/.For the Dlbs algorithm, we shall consider several configurations by varying the population sizeμ∈{8,16,32,64,128,256}. If not stated explicitly, the finest granularity is considered when deploying Dlbs; which corresponds to the situation where n is set to be equal toμ(i.e., one single solution per computing node). Nevertheless, we shall also study Dlbs under different granularities to experimentally investigate the issues discussed in Section 3.4. More specifically, for a fixed population sizeμ, results are reported forn∈{1,8,16,32,64,128}. For each tuple of parameter setting and algorithm variant, 30 independent executions are performed.Due to the parallel nature of Dlbs, one should examine simultaneously approximation quality and running time in order to fully appreciate its performance with respect to other competing algorithms. The running time of Dlbs depends on the granularity chosen when effectively deploying it on a computational environment (see Section 3.4). For our first set of experiments, the number of nodes n is set to the population sizeμ, corresponding to the finest possible granularity. We start discussing approximation quality and then we relate it to running time.A set of 30 runs per instance is performed for each algorithm. In order to evaluate the quality of the approximations found for every considered instance, we follow the performance assessment protocol proposed by Knowles, Thiele, and Zitzler, 2006. Given aρMNK-landscape instance, we compute a reference setZN★containing the non-dominated points of all the Pareto front approximations we obtained during all our experiments. To measure the quality of a Pareto front approximation A in comparison toZN★, we use both the hypervolume difference indicatorIH-and the multiplicative epsilon indicatorI∊1(Zitzler et al., 2003). TheIH-indicator gives the portion of the objective space that is dominated byZN★and not by A. The reference point is set to the worst objective value on every dimension of the objective space obtained in all approximation sets found during our experiments. TheI∊1-indicator gives the minimum multiplicative factor by which an approximation A has to be translated in the objective space in order to dominate the reference setZN★. Note that bothIH-- andI∊1-values are to be minimized. The experimental results report the descriptive statistics on the indicator values, together with a Wilcoxon signed-rank statistical test with a p-value of0.05. This procedure has been achieved using R as well as the performance assessment tools provided in PISA (Bleuler, Laumanns, Thiele, & Zitzler, 2003; Knowles et al., 2006). Table 1gives the rank of the different competing algorithms for different configurations. The lower the rank, the better the algorithm.According to both indicators, for all instances, the hypervolume-based localized scalar strategy DlbsH never outperforms the orthogonal-directed one DlbsOD; which indicates thatLFODis a better localized fitness function to select locally the next solution when compared toLFH. Although the hypervolume indicator, when used by global algorithms, can outperform algorithms using weighted-sum, the local information induced by the hypervolume at each node in DlbsH turns to be less efficient to guide the search process globally compared to orthogonal weighted-sum directions.When comparing Dlbs to the Piws approach, we can first see that Dlbs performs substantially better with respect to both indicatorsIH-andI∊1for all instances. This is obviously attributed to the local information exchanged in our cooperative strategies; which is to contrast with Piws where search directions are fixed statically. In other words, the adaptive search directions used in Dlbs outperform the directions of Piws, that are fixed prior to the search process. This result advocates the usefulness of adaptive search directions, that enable to fit different shapes of the Pareto front.Comparing the approximation quality of DlbsOD with Hemo, we find that Dlbs performs better than Hemo for instances with conflicting objectives, i.e. whenρ<0. With respect to the hypervolume indicator, Hemo performs significantly better than DlbsOD on 9 over the 18 instances, whereas DlbsOD performs better than Hemo on 6 instances. The local information used in Dlbs seems to be more valuable when the objectives are in conflict. In this case, the search directions computed locally enable to explore more independent and diverse regions of the objective space. On the contrary, when the objective correlation is positive, there are more interactions between the sub-problems induced by the search directions. Thus, diversification seems to play a less important role, and a global information allowing to take into account the interactions between the population is more useful. At this point of the discussion, we can make two important observations to better understand how the very local decisions made by Dlbs can be effectively competitive with respect to the global step-by-step decisions made by the sequential Hemo algorithm.Firstly, when analyzing in more details the Pareto set approximations achieved by Dlbs compared to Hemo, we remark that Dlbs is able to find more diversified solutions spanning a wider range of the Pareto front. This is illustrated in Fig. 2, showing the empirical attainment function of Dlbsvs. Hemo for six illustrative instances with different problem dimensions and objective correlations. Note that similar observations can be made with other instances. Empirical attainment functions (López-Ibáñez, Paquete, & Stützle, 2010, chap. 9) provide the probability, estimated from several executions, that an arbitrary objective vector is dominated by, or equivalent to, a solution obtained by a single run of the algorithm. The difference between the empirical attainment functions for two different algorithms enables to identify the regions of the objective space where one algorithm performs better than another. We can see that for the class of instances with conflicting objectives, where the Pareto front is likely to be more stretched in the objective space, the local strategy induced by Dlbs is able to find more points at the extreme regions of the Pareto front. In the box-plots of Fig. 3, we additionally show the distribution of the achieved hypervolume indicator values for the same set of instances. We can see that the gap between Dlbs and Hemo is relatively small for the instances with a high objective correlation. Notice the relatively high tails of the hypervolume indicator distribution obtained with Hemo.Secondly, the previous discussion holds when the different approaches are experimented using the same fixed number of function evaluations; but with no considerations to execution time. This is one crucial issue in Dlbs due to its parallel nature. Actually, it turns out that the running time of Hemo is dramatically worse than Dlbs. Computing complexity is an important issue which is analyzed in more details in the next section.In Fig. 4, we show the relative execution time of our competing algorithms as a function of the population sizeμ. Since Hemo is inherently a sequential algorithm, we also experiment the ‘sequential’ variant of Dlbs by fixingn=1. This means that Dlbs is executed on a single computing node (i.e., no parallelism is involved). Two main observations can be extracted from Fig. 4. Depending on the size of the considered instance, the execution time of Dlbs is many magnitudes lower than Hemo, even forn=1. This is with no surprise, since in contrast to Hemo, the Dlbs approach does not need sophisticated global operation like non-dominated sorting and ranking. In particular, this suggests that, by allowing Dlbs to consume slightly more evaluations, inducing a very marginal increase in execution time, the approximation found by Dlbs can be substantially improved with respect to Hemo. We also notice that the execution time of Dlbs increases very marginally with respect to the population sizeμ, compared to Piws. This shows that the local communications and the semi-synchronized nature of Dlbs do not have a significant impact on the parallel execution time, even in the fine-grained granularity ofn=μ.In Fig. 5, we push the latter discussion further by studying the approximation quality obtained by DlbsOD, DlbsH, and Piws as a function of the population sizeμ, for three instances of different sizes and in the finest grained scenario ofn=μ. We can see that the approximation quality, in terms of hypervolume, increases with the population size. Although the increase in quality slows down with the population size, these results show that Dlbs can handle increasing population size while providing better approximation quality and a very small increase in parallel execution time.In the previous sections, we were mostly concerned with the analysis of the approximation quality of Dlbs and its relation to execution time. However, from a parallel efficiency perspective, Dlbs exhibits interesting intrinsic properties that we shall study following three complementary axis: (i) the impact of the fitness function evaluation time (Fig. 6), (ii) the acceleration ratio with respect to a sequential execution (Fig. 7), and (iii) the speed-up obtained with different granularities (Fig. 8).In Fig. 6, we first report the parallel efficiency obtained with Dlbs for increasing problem sizesN∈{128,256,2048}and forn=μ=128. The reported values refer to the average ratio of computing time over execution time (including communication). This reflects the proportion of time spent by a node in processing the optimization problem and the proportion of time that a node pays when communicating using message exchange. We observe that the parallel efficiency increases sharply from64%forN=128to up to96%forN=2048. This behavior relates directly to the time it takes for a node to evaluate a solution. In fact, as N increases for theρMNK-landscapes we are considering, the time needed to evaluate a solution increases linearly. In contrast, since only solution coordinates are communicated in Dlbs, the amount of information exchanged by two neighboring nodes is independent of the problem size and stays constant. As a consequence, Dlbs cannot suffer any performance drop and its parallel efficiency reaches relatively high trade-offs. This interesting property is to contrast with classical parallel evaluation model, see e.g. (Talbi et al., 2008), where the whole solution genotypes have to be periodically distributed over computing nodes. Therefore, Dlbs can be highly accurate for real-world applications where the fitness evaluation function is usually very time-consuming.In Fig. 7, we show the acceleration ratio obtained when running Dlbs for two different problem sizesN∈{128,2048}with respect to the population sizeμ>1, and usingn=μcomputing nodes, compared to the Dlbs version where only a single computing node is used. More specifically, in order to analyze the performance of Dlbs in the extreme case of the lowest granularity (n=μ) with respect to the case where no parallelism is available at all (highest granularity ofn=1), we report the ratio of the execution time of Dlbs(n=μ,μ) over the execution time of Dlbs(n=1,μ). Here, it is important to remark that the so-experimented Dlbs(μ,μ) and Dlbs(1,μ) algorithms are exactly the same from a solution quality perspective; only the execution time is different. As one can see in Fig. 7, the acceleration ratio is linear in the population size, independently of the problem size N. Interestingly, the slope of the acceleration (0.58forN=128and0.92forN=2048) roughly corresponds to the parallel efficiency depicted before in Fig. 6. From this set of experiments, we can say that the fine-grained parallelization strategy of Dlbs (i.e.,n=μ) scales efficiently with increasing population sizes. Moreover, the more the problem-dependent fitness function is time consuming, the more Dlbs is able the attain high acceleration ratios, which is in accordance with the results of Fig. 6, e.g., from 76 up to 118 acceleration using 128 computing nodes.To study the performance of Dlbs with a variable granularity, we conduct a new set of experiments where the population size is now fixed toμ=128. We then deploy Dlbs with a variable number n of computing nodes ranging in{8,16,32,64,128}. In this scenario, theμ=128solutions are distributed evenly over the n nodes, as discussed previously in Section 3.4. In Fig. 8, we report the obtained speed-ups; that is the execution time of the sequential Dlbs(1,128) divided by the execution time of the parallel Dlbs(n,128). We can see that the scalability of Dlbs depends on the time needed for fitness evaluation which is again in accordance with the results of Fig. 6. Overall, we can conclude that for a fixed population size, Dlbs is able to scale efficiently with the number of available nodes. A near-linear speedup is obtained for the largest instance, even with the configuration with the highest communication cost (n=μ=128). In practice, deploying Dlbs with a large number of computing nodes (or a large population size) can thus be guaranteed to be very efficient independently of the chosen granularity and without extra-design efforts.We conclude our analysis by providing some insights into the dynamics and the behavior of our distributed strategy.In Fig. 9, we provide qualitative observations to illustrate how the population is cooperatively evolving closer towards a better Pareto front approximation. For instance in Fig. 9 (bottom-left)—showing the average distance of solution objectives to the origin—we see that, as distributed computations are going on, it becomes more and more difficult to push solutions further. This is obviously attributed to the fact that the more solutions are far away from the origin, the more difficult it is for the mutation operator to produce improving solutions. The interesting observation is that, whenever it becomes difficult to get closer to the Pareto front, some solutions start zigzagging right and left in the objective space. As one can see in the trajectories depicted in Fig. 9 (top-left), this has the effect of making nodes traveling parallel to the front instead of going straightly towards it. In Fig. 9 (top-right), one can further see that the line graph defining the neighborhood in the objective space is not planar, meaning that the line is not automatically disentangled. Actually, this is due to the fact that it is difficult to distributively maintain the solutions sorted. This behavior may also be influenced by the stochastic nature of the mutation operator and to the difficulty of finding dominating solutions as nodes are becoming closer to the Pareto front. Notice however the nice distribution of nodes in the objective space. Although the line graph is not planar, Fig. 9 (bottom-right) reveals that the distribution of node angles is rather uniform. This means that the distributed strategy succeeds in guiding nodes to different and diverse regions of the objective space. Moreover, one can see that some solutions stay stable in the sense that their angles are not moving, whereas some others are moving smartly around some fixed values.Fig. 10complements the above observations by reporting the evolution of the hypervolume difference indicator value achieved by Dlbs and Piws during the execution. We can clearly see that, independently of the type of objective correlation, Piws is quickly stuck with a relatively bad approximation set while Dlbs is able to continue improving the hypervolume indicator. This shows that the local decisions made in Dlbs do allow solutions to continue evolving dynamically through a better approximation set.

@&#CONCLUSIONS@&#
