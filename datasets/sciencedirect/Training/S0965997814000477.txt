@&#MAIN-TITLE@&#
Performance of automatic differentiation tools in the dynamic simulation of multibody systems

@&#HIGHLIGHTS@&#
A multibody dynamics code based on a semi-recursive penalty formulation is presented.Two automatic differentiation tools, ADIC2 and ADOL-C, are used.Five numerical models are used for validation, including a realistic coach model.The advantages of exploiting Jacobian sparsity using automatic differentiation are shown.

@&#KEYPHRASES@&#
Multibody dynamics,Semi-recursive penalty formulation,Automatic differentiation,Operator overloading,Source-to-source transformation,ADOL-C,ADIC2,

@&#ABSTRACT@&#
Within the multibody systems literature, few attempts have been made to use automatic differentiation for solving forward multibody dynamics and evaluating its computational efficiency. The most relevant implementations are found in the sensitivity analysis field, but they rarely address automatic differentiation issues in depth. This paper presents a thorough analysis of automatic differentiation tools in the time integration of multibody systems. To that end, a penalty formulation is implemented. First, open-chain generalized positions and velocities are computed recursively, while using Cartesian coordinates to define local geometry. Second, the equations of motion are implicitly integrated by using the trapezoidal rule and a Newton–Raphson iteration. Third, velocity and acceleration projections are carried out to enforce kinematic constraints. For the computation of Newton–Raphson’s tangent matrix, instead of using numerical or analytical differentiation, automatic differentiation is implemented here. Specifically, the source-to-source transformation tool ADIC2 and the operator overloading tool ADOL-C are employed, in both dense and sparse modes. The theoretical approach is backed with the numerical analysis of a 1-DOF spatial four-bar mechanism, three different configurations of a 15-DOF multiple four-bar linkage, and a 16-DOF coach maneuver. Numerical and automatic differentiation are compared in terms of their computational efficiency and accuracy. Overall, we provide a global perspective of the efficiency of automatic differentiation in the field of multibody system dynamics.

@&#INTRODUCTION@&#
Multibody systems (MBS) are mechanical systems made up of rigid or flexible bodies interconnected by perfect or imperfect kinematic joints and subject to various forces. These systems are present in numerous areas of industry, including mechanisms, robots, vehicles, machinery, wind turbines, and aerospace engineering. After more than 35years of simulation of multibody systems, the development of efficient multibody methods is still challenging. The kinematic constraints between the rigid bodies and the presence of closed loops in the mechanisms often make the integration of the differential–algebraic equations (DAEs) tricky, unstable, or slow. Yet, in some applications such as driving simulators, hardware-in-the-loop applications, on-board controllers, and optimization algorithms, the computation of multibody system dynamics in real-time is crucial. In order to improve the efficiency of multibody dynamics software, several strategies can be adopted, some of which are efficient formulations, efficient implementations, and parallel implementations. The first two are addressed here.Among the great variety of contemporary MBS formulations [1], penalty schemes have proven to be a robust and efficient approach for solving forward MBS dynamics using dependent coordinates [2,3]. Basically, they avoid the direct enforcement of kinematic constraints by introducing penalty terms proportional to the nonfulfillment of constraints. When combined with implicit integrators and projections, they allow for long integration time-steps while keeping the simulation stable. One of the most interesting approaches in this direction was presented in [4] and is followed here in some of the stages. Natural (or fully Cartesian) coordinates1Cartesian components of points and unit vectors [2].1are used to define local geometry and constraint equations, which simplifies the modeling phase. Positions and velocities are then computed recursively, exploiting the system’s tree-structured topology.For the time integration of the equations of motion, the trapezoidal rule with velocity and acceleration projections is used. This scheme requires the solution of a nonlinear system of equations, which is generally solved with a Newton–Raphson algorithm. To that end, the Jacobian matrix of the open-chain forces with respect to the relative positions and velocities has to be computed. Since this step takes most of the computation time, it is worth exploring efficient and accurate ways of differentiating computer functions, while preserving the generality of the implementation.There are several ways of computing the derivatives of a mathematical function with respect to its independent variables. For example, one may apply differential calculus by hand and code the differentiated functions; this is usually called analytical differentiation. A similar but more automated technique is symbolic differentiation, which is based on symbolic mathematical programs that generate the derivative equations from the original function. The derivatives must be generated in the third-party software and sometimes exported, reimplemented, and compiled each time a change is introduced in the equation; and only purely analytic equations can be differentiated. This technique thus has considerable drawbacks from the generality point of view.Another way of computing derivatives is through numerical differentiation (ND) techniques such as finite-differences. Let f be a scalar function that depends on variable x. Its derivative can be numerically approximated as:(1)f′x0≡dfdx(x0)≈fx0+h-fx0-h2hwhich corresponds to a centered-difference formula. More accurate formulae can be obtained by evaluating the function in different points. The advantage of these methods is that they only require the original function. However, Eq. (1) demands a very small value of the perturbation h. When h is very small, two similar numbers are being subtracted in the numerator, and, because of the limited computer precision, the derivative is less accurate than the original function. Moreover, in the case of vector functions, the computational cost increases quickly as the problem size grows. The ND error can be avoided through the complex-step derivative approximation [5], but this requires variables in the code to be changed to the complex type.Automatic or algorithmic differentiation (AD) allows differentiating a computer function (implemented in Fortran, C, C++, MATLAB, etc.), automatically computing both first-order derivatives (e.g. gradients and Jacobian matrices) and higher-order derivatives (e.g. Hessian matrices). Its development time is shorter than using analytical differentiation techniques, and it generates machine-precision derivatives. In past investigations with the formulation presented here, the operator overloading tool ADOL-C [6] was used successfully [7]. However, a single AD tool was not enough for assessing the computational efficiency, since the different types of AD tools have very different performances. Also, only academic examples were considered.Little work in the MBS community has thoroughly addressed AD as a way of differentiating computer functions. In 1996, Bischof [8] used the source transformation tools ADIC and ADIFOR on a Fortran code to compute vehicle sensitivities, but general performance conclusions were not given. Three years later, Eberhard and Bischof [9] focused on the time integration of sensitivities using ADIFOR on a 5-DOF robot, and concluded that AD was less efficient but simpler to implement than analytical derivatives. Later, in [10], Dürrbaum et al. proved that the symbolic tool MACSYMA generated derivatives faster than did ADOL-C for two medium-size planar and spatial robots. In 2007, Ambrósio et al. [11] simulated a satellite antenna as a flexible multibody system and recommended AD over ND for accuracy reasons, even though with little implementation details. Recently, Hannemann et al. [12] applied the source transformation tool dcc and an operator overloading tool to dynamic models. In general, rough descriptions of AD tools and their implementation are provided; the results are not compared with other AD tools; and academic rather than industrial numerical examples are considered. Also, to the best of the authors’ knowledge, the benefits of exploiting Jacobian sparsity in MBS formulations by using AD has not been shown before. In this work, both the source-to-source transformation tool ADIC2 [13] and the operator-overloading tool ADOL-C [6] are used on three numerical examples, namely a 1-DOF spatial four-bar mechanism, a 15-DOF multiple four-bar linkage and a 16-DOF coach model. These examples are used as medium to large benchmarks of ND and AD tools, with special focus on computational efficiency and sparse Jacobian exploitation.In this section, a general-purpose MBS formulation is presented [4]. The formulation is explained in four steps: first, the open-chain recursive differential equations are proposed; second, the loops are closed by introducing position penalty terms; third, the trapezoidal rule of integration is introduced; and fourth, velocity and acceleration projections are carried out.In order to apply recursion techniques, the system is considered as a tree-structured multibody system (see Fig. 1(a)). In the case of closed-chain systems, certain joints and rods2Slender bodies with two spherical joints and a negligible moment of inertia around their axis.2are temporarily removed and enforced later through constraint equations. Cartesian coordinates are used to define the velocity and acceleration of bodies:(2)Zi≡ṡiωi(3)Żi≡s¨iω̇iwhereṡiands¨iare, respectively, the velocity and acceleration of the point attached to body i that instantaneously coincides with the origin of the inertial reference frame. In this way, all bodies share the same reference point, which has interesting advantages [14]. The recursive expression of the Cartesian velocities and accelerations of body i in terms of those of bodyi-1is(4)Zi=Zi-1+biżi(5)Żi=Żi-1+biz¨i+diNote the lack of transformation matrices in the previous equations. Scalarziis the relative coordinate of joint i. Vectorbirepresents the velocity of the point of body i that coincides with the origin of the global reference frame whenżi=1andżj=0,j≠i; and vectordiis the increase in acceleration fromi-1to i whenz¨i=0. Bothbianddidepend on the type of joint between i andi-1. Here, only revolute and prismatic joints (and combinations thereof) are considered. VectorsZT≡{Z1T,Z2T,…,ZnT}andŻT≡{Ż1T,Ż2T,…,ŻnT}group the system velocities and accelerations, n being the number of moving bodies. The virtual power of inertia and external forces of the open-chain system can be written as(6)∑i=1nZi∗TM‾iŻi-Q‾i=0(7)M‾≡diag(M‾1,M‾2,…,M‾n)(8)Q‾≡{Q‾1T,Q‾2T,…,Q‾nT}T(9)M‾i=miI3-mig̃imig̃iJi-mig̃ig̃i(10)Q‾i=Fi-miω̃iω̃igig̃iFi-ω̃iJiωi-mig̃iω̃iω̃igiwhereM‾i∈R6×6andQ‾i∈R6×1are, respectively, the inertia matrix and the vector of external and velocity-dependent inertia forces acting on bodyi;miis the mass;Ji∈R3×3is the inertia tensor;giis the position of the center of gravity (COG);ωiis the angular velocity vector; andFiis the applied force vector. The upper bar indicates reference to the origin of the global reference frame. The upper tilde transforms the vector into the associated skew-symmetric matrix, such that, for generic3×1vectorsαandβ,α×β=α̃β.A velocity transformationR∈R6n×nbetween Cartesian (Z) and relative (ż) velocities is now introduced. Bodies (and their corresponding input joints) are numbered from the leaves to the root of the spanning tree. Thejthcolumn of matrixRcontains the Cartesian velocities of all bodies that are upwards of joint j when a unit relative velocity is introduced in j, keeping the others null; since the origin of the global frame is the reference point for all bodies, these Cartesian velocities happen to bebifor all bodies, according to Eq. (4).(11)Z=Rż=Tdiagb1,b2,…,bnż≡TRdż(12)Ż=TRdz¨+TṘdżwhere the connectivity of the mechanism has been defined through an upper triangular path matrixT∈Z6n×6n. SubmatrixTijisI6if body i is upwards of joint j, and06otherwise. IntroducingZ∗T=RdTTTż∗(from Eq. (11)) and Eq. (12) into Eq. (6), and considering that the relative open-chain virtual velocities are independent, one can eliminate virtual velocitiesż∗and obtain a new set of differential equations(13)RdTTTM‾TRd︸MdΣz¨=RdT(TTQ‾-MΣṘdż)︸QdΣwhere some terms have been grouped for the sake of clarity. These recursive equations constitute a set of n ODEs describing the motion of the open-chain system. In closed-loop systems, the constraint equations coming from the closure of the loops still need to be enforced.Closed-loop dynamic equations can be formulated by adding the constraint equations to the open-chain dynamic equations, which have just been obtained. The fulfillment of the position constraint equations is enforced by introducing a penalty term into Eq. (13). Then, velocity and acceleration constraints are imposed by carrying out velocity and acceleration projections.First, let us add a penalty term to Eq. (13):(14)MdΣz¨+ΦzTαΦ=QdΣwhereαis the penalization coefficient,Φ∈Rm×1is the vector of m constraint equations, andΦz∈Rm×nis the Jacobian matrix of the constraint equations with respect to the relative positions. The penalty term has a physical meaning:αΦis the value of the penalty forces (one for each constraint equation) and the columns ofΦzTare the directions of the constraint forces in which penalties are applied. Fig. 1(b) shows the way a closure-of-the-loop revolute joint can be formulated in terms of natural coordinates (for more details see [14]).For the integration of Eq. (14), the implicit single-step trapezoidal rule with time-step h is used. Relative velocities and accelerations in time-stepj+1are:(15)żj+1=2hzj+1-2hzj+żj(16)z¨j+1=4h2zj+1-4h2zj+4hżj+z¨j︸z¨ˆjThen, by introducing Eqs. (15) and (16) in Eq. (14), a nonlinear equationf(zj+1)=0is obtained:(17)Md,j+1Σzj+1+h24Φzj+1TαΦj+1-h24Qd,j+1Σ+h24Md,j+1Σz¨ˆj=0whereMdΣ=MdΣ(z),QdΣ=QdΣ(z,ż),Φ=Φ(z)andΦz=Φz(z).Eq. (17) is a nonlinear system of equations that can be solved for unknown vectorzj+1. To that end, it is customary to use the Newton–Raphson method, which has a quadratic convergence in the neighborhood of the solution. This iterative method implies the evaluation of a tangent matrix, as indicated next. Letk+1be the iteration.(18)zj+1k+1=zj+1k+Δzj+1k(19)∂f(z)∂zj+1kΔzj+1k=-f(z)j+1kThe solution of Eq. (18) entails the evaluation of the tangent matrix in Eq. (19). This tangent matrix can be approximated [4] with the following expression:(20)∂f(z)∂zj+1k≈MdΣ+h2C+h24ΦzTαΦz+Kj+1k(21)K≡-∂QdΣ∂z(22)C≡-∂QdΣ∂żwhereK∈Rn×nandC∈Rn×nhave been introduced. If the state vectory≡{zT,żT}T∈R2n×1is defined, both matrices can be grouped as:(23)J≡-∂QdΣ∂yThe Jacobian matrixJ∈Rn×2nis the key computation of this algorithm. Some authors [4] formulate this matrix analytically, meaning that the derivatives have to be computed by hand for the most typical force types (springs, dampers, etc.). This is obviously not the most general-purpose approach and can lead to error-prone expressions. Regarding numerical differentiation, it might be inefficient, and its error is difficult to control. On the other hand, AD in its various forms can be used as well to calculate these derivatives with minimal effort from the user and reasonable efficiency. This approach is especially interesting when generality and usability are of paramount importance and efficiency is not as critical. The following sections investigate the different ways of computing this Jacobian matrix.The previous equations impose the dynamics and the fulfillment of the position constraint equations, but the velocity and acceleration constraints have not been enforced yet. During the time integration process, Eqs. (15) and (16) yield a set of velocitiesż∗and accelerationsz¨∗that do not satisfy velocity and acceleration constraints. The reason is that both vectors have been obtained numerically from the integrator and not by differentiating the positions. This problem can be solved through velocity and acceleration projections [4]. Applying a projection method with penalty terms, one can obtain a set of velocitiesżthat satisfy the constraints. Introducing a weight matrixP, one can compute the projected velocities as:(24)P+h24ΦzTαΦzż=Pż∗-h24ΦzTαΦt(25)P≡MdΣ+h2C+h24Kwhere the system matrix in the l.h.s. of Eq. (24) is the tangent matrix (20). In this way, the matrix factorization can be reused, and the projection is performed efficiently. Similarly, the expression of the projected accelerations is(26)P+h24ΦzTαΦzz¨=Pz¨∗-h24ΦzTαΦ̇zż-h24ΦzTαΦtAfter solving the velocity and acceleration projections, all constraints (position, velocity and acceleration) are enforced.In standard Newton–Raphson problems, both the value and the factorization of the tangent matrix (20) can be reused over a number of iterations so that only a back substitution is needed to findΔzj+1kin Eq. (19). In this case, however, the tangent matrix factorization is employed later to solve velocity (24) and acceleration (26) projections. These projections need an updated version of the tangent matrix (and its factorization) in order to achieve an accurate enforcement of constraints; hence, reusing the tangent matrix in the Newton–Raphson iteration is not compatible with velocity and acceleration projections. Since the computational burden of projections is greater, we chose to always refactorize Newton–Raphson’s tangent matrix and use the last factorization for projections. In turn, we did reuse Jacobian matrices (21) and (22) for three Newton–Raphson iterations, as they are the heaviest tangent matrix components. This approach has proved to be an effective cost-accuracy tradeoff in real-life mechanical systems.Among the steps of the presented formulation, the computation of the Jacobian matrix in Eq. (23) is critical for the simulation performance. In this section, we introduce AD methodology and discuss how AD can be used to produce the derivatives algorithmically.AD [15,16] is an approach to obtaining derivative computations based on source-code implementations of mathematical functions. AD combines rule-based differentiation of elementary operators (e.g. addition, subtraction) with derivative accumulation according to the chain rule of differential calculus. The derivatives produced by using AD are accurate to machine precision with respect to the original computation (but not necessarily the original mathematical function; in the case of iterative algorithms, convergence rates may differ [17]). It can be used in many contexts, including numerical optimization, solvers for nonlinear partial differential equations, or the solution of inverse problems using least squares. Many tools provide AD for different languages, including Fortran, MATLAB, C, and C++ (e.g. [15,18,19,16]).AD tools typically adopt one of two implementation approaches [15,16]: operator overloading (by overloading the computer language operators) or source transformation (by generating an alternative code containing the derivatives). Operator overloading-based tools are easier to implement; but since they rely on runtime evaluation of partial derivatives, the ways in which the chain rule associativity can be exploited to attain better performing derivative code are limited. On the other hand, source transformation approaches enable static analysis of program source code, presenting opportunities for optimization over much larger scopes than a single statement, often resulting in significantly better performance of the AD computation. Moreover, the resulting code can be tweaked and improved manually if necessary. However, source transformation-based AD has the same limitations as traditional compilers, which includes the complexity of implementing parsing and analysis of general-purpose languages, as well as the reliance on necessarily conservative static analysis (e.g., alias analysis), which may lead to the generation of suboptimal derivative code.ADIC2 is a source (or source-to-source) transformation AD tool for C and C++ with support for two different modes: forward (which propagates the derivatives from the inputs to the outputs) and reverse (from the outputs to the inputs) [13]. It is part of the OpenAD framework [20], illustrated in Fig. 2. The input code is input to the ROSE compiler framework [21,22] which is parsed by EDG C/C++ parsers. Once converted into a ROSE abstract syntax tree (AST), the following processes occur to generate output derivative code:1.Canonicalization: Several code constructs are simplified in order to make the later transformations feasible. For example, all function calls determined to affect the output are converted into subroutine calls.Program analysis: The OpenAnalysis framework [23] is used to analyze the canonicalized code. It generates a call graph, a control flow graph, define-use and use-define chains, a scope hierarchy, and alias analysis results.XAIF generation: The results generated by OpenAnalysis and any code statements that affect the output are converted into the XML Abstract Interface Form (XAIF), a language-independent format to represent code.Derivative propagation: xaifBooster [20] uses transformation algorithms to convert the input XAIF into derivative XAIF (AD-XAIF).Conversion of AD-XAIF: The AD-XAIF is parsed and is converted into ROSE AST nodes.Generation of derivative code: The ROSE AST is converted into C/C++ using ROSE’s codegen facility. The output code can be compiled with a runtime library provided by ADIC2, and executed to generate derivatives.These procedures take place automatically; however, care must be taken at the preprocessing stage to define AD data types and the interfaces with the original code, and at the final compilation to debug minor inconsistencies. Fig. 3is an example of the use of ADIC2. Fig. 3(a) is the classic example attributed to Speelpenning, and Fig. 3(b) is the corresponding output generated by ADIC2. The ADIC2 runtime library defines a structure called DERIV_TYPE (shown in Fig. 3(c)) that contains a value field and an array field holding derivative values. The size of the array field is the number of independent variables. Operations to manipulate the array fields are defined within the library as well. At the end of the computation, the array fields of the dependent variable form the Jacobian matrix.Since Jacobians can be sparse, using an array size that effectively computes a full Jacobian can be inefficient. Furthermore, for large Jacobians, not enough memory may be available to allocate an array for each DERIV_TYPE variable. ADIC2 implements a framework to exploit Jacobian sparsity [24]. Specifically, given a functionQdΣ:R2n×1→Rn×1whose Jacobian matrixJ∈Rn×2n(see Eq. (23)) is sparse, ADIC2 employs the following four steps to efficiently compute matrixJ:1.Determine the sparsity pattern of matrixJ.Using a coloring on an appropriate graph ofJ, obtain ann×pseed matrixSwith the smallest p that defines a partitioning of the columns ofJinto p groups.Compute the numerical values in the compressed matrixB≡JS.Recover the numerical values of the entries ofJfromB.In step 1, the output derivative code is compiled with a runtime library called SparsLinC, which is used to detect the structure of the Jacobian. In step 2, the coloring package ColPack [25] is used. The number of colors p used to partition the Jacobian dictates the number of columns in the compressed matrix and consequently the new size of the array in the DERIV_TYPE structure. When computing the compressed matrix, a smaller array can result in a performance improvement, provided the overheads of steps 1, 2, and 4 can be offset.ADOL-C is an operator overloading AD tool for C and C++ with support for the forward and reverse modes [26]. It generates gradients, Jacobians, Hessians, Jacobian×vector products, Hessian×vector products, among others. Fig. 4is an example of the use of ADOL-C. Fig. 4(a) is the Speelpenning example coded to obtain derivatives using ADOL-C, and Fig. 4(b) is the driver used to run the derivatives. ADOL-C defines a type called adouble to be used for active variables in the computation. Derivative calculation is based on a function representation created during the taping phase, that starts with a call to the routine trace_on provided by ADOL-C, and is finalized by calling the ADOL-C routine trace_off.Jacobians can be computed by ADOL-C in three different modes: forward, reverse and sparse. According to ADOL-C guidelines, the reverse mode should be used over the forward mode when the number of independent coordinates is twice the number of dependent coordinates or larger; otherwise the forward mode should be employed. In the present formulation, the size of the Jacobian lies in between that limit. To compute a sparse Jacobian efficiently, ADOL-C follows a technique similar to that of ADIC2.

@&#CONCLUSIONS@&#
A general-purpose multibody dynamics code, together with two academic examples and a realistic coach model, have been used to evaluate the performance of automatic differentiation tools in the context of multibody systems. Two different C/C++ tools for the automatic generation of derivatives have been used: the source transformation tool ADIC2 and the operator overloading tool ADOL-C. Both tools were relatively easy to use and provided accurate derivatives. The MBS simulation code is the most complex use case that ADIC2 has been applied to, and has required several enhancements to the tool itself, including the ability to handle structures that contain array, pointer and structure fields, and the ability to handle code distributed across multiple files.When the Jacobians are considered to be dense, derivatives generated by AD are slower than using the finite-differences approach. However, support for sparse Jacobians can be provided by ADIC2 and ADOL-C in a direct way. For certain systems, sparse AD derivatives are up to 2.5 times faster than using the finite-differences approach without exploiting sparsity.Whenever AD is faster than ND, probably no other differentiation method could generate more accurate and efficient Jacobian matrices with such a short development time. Techniques like analytical differentiation, which could provide machine-precision and efficient derivatives, would be nearly infeasible for complex formulations like the one considered here, and definitely not as general. Nevertheless, there is still room for the improvement of AD performance, for instance by enhancing memory management and through dependence analyses.Overall, advantages and disadvantages of state-of-the-art tools for the automatic differentiation of C/C++ codes in the field of multibody dynamics have been presented rigorously and backed with meaningful examples.