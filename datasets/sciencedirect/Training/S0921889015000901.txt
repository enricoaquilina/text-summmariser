@&#MAIN-TITLE@&#
A signal pattern recognition approach for mobile devices and its application to braking state classification on robotic mobility devices

@&#HIGHLIGHTS@&#
A mobile application is developed for classification of braking states.The Sparse and Collaborative Representation based Classifications are used.The developed signal filtering and classification modules is accurate and robust.The application can be used to classify different dynamical maneuvers of mobility devices.

@&#KEYPHRASES@&#
Automatic classification of the braking modes,Collaborative Representation based Classification,Context aware Android application for Segway,Mobility robot–society interaction,Complementary filter design,

@&#ABSTRACT@&#
Personal Mobility Robots, such as the Seqway may be the remedy for the transportation related problems in the congested environment, especially for the last and first mile problems of the elderly people. However, the vehicle segmentation issues for the mobility robots, impede the use of these devices on the shared paths. The mobility reports can only be used in the designated areas and private facilities. The traffic regulatory institutions lack robot–society interaction database. In this study, we proposed methods and algorithms which can be employed on a widespread computing device, such as an Android tablet, to gather travel information and rider behavior making use of the motion and position sensors of the tablet PC. The methods we developed, first filter the noisy sensor readings using a complementary filter, then align the body coordinate system of the device to the Segway’s motion coordinate. A couple of state of the art classification methods are integrated to classify the braking states of the Segway. The classification algorithms are not limited to classification of the braking states, but they can be used for other motion related maneuvers on the road surfaces. The detected braking states and the other classified features related to the motion are reflected to the screen of the Android tablet to inform the rider about the riding and motion conditions. The developed Android application also gathers these travel information to build a National database for further statistical analysis of the robot–society interaction.

@&#INTRODUCTION@&#
The portion of elderly people to the overall population of the nations has been increasing  [1]. Easy access to health care services and facilities, new cures and treatments in the medicine contribute to the longevity at older ages. Japan has the fastest growing portion of the aged population; the cohort of 65 years and older ages constitutes 25.1% of the overall population as of August 2014  [2].Along with the slowed reactions, decreased cognitive, perceptual and motor-neurone skills; and frailty of older ages not only make the elderly homebound but also the most vulnerable age group in transportation related injury and fatalities  [3]. The impact of isolation from participating in the societal activities due to the restricted mobility engenders multifaceted burdens to the governments in terms of economical issues, the public health and the rate of transportation related fatality and injuries.The elderly people have only a few modes of mobility options, such as walking, cycling or using Personal Transporter (PT) devices in their first and last mile problems to/from the closest transportation hub and to reach the city amenities in their daily life. The former two pose greater risks for the elderly either being a pedestrian or cyclist on the road related areas including footpaths, bicycle and shared paths. According to the statistics collected by the National Police of Japan, the fatality rates of the senior citizens over 65 years old involved in the bicycle accidents as either being pedestrian or cyclist are 60.4% and 69.4% respectively in the first half of 2014  [4]. The PTs can be a viable solution to the mobility problem of the elderly people. By definition, personal transporters are the two wheeled, self-balancing and electric motor driven devices such as the Segway™. However, the Segway and similar PTs are not permitted on the road related areas in many countries. The main hindrance to the use of the Segway stems from the regulatory issues in the road traffic acts.The Segway PT is the first two-wheeled, self balancing, electric personal transportation device invented in 2001. In the United States, the use of Segway on the road related areas is permitted in most of the states with enacted legislations which categorize the Segway as a newly introduced vehicle category—“Electric Personal Assistive Mobility Device EPAMD.” Only six states do not have any permissive legislation yet  [5]. In many other countries, such as in Australia, Japan and UK in Europe, the Segway is banned on the public spaces except in private properties and designated zones due to the lingering controversy whether it is a motorized vehicle or an EPAMD; it lacks brakes and, the software limited upper speed exceeds the limits defined for the EPAMDs by the traffic legislations.The literature on the Segway and its interaction with the other road users is limited to empirical data, dynamical characteristics of the Segway and subjective assessments based on the surveys and questionnaires which were aimed to guide the policy-makers and traffic regulation bodies.The authors in  [6] and  [7], investigate the approach distance and velocities of the Segway riders to the various obstacles and pedestrians at the different velocity profiles. The experiments were implemented under the controlled conditions by recruiting ten novices and ten experienced operators. A similar study  [8] reports the stopping distance for the different driving maneuvers including emergency braking and response time of the riders when braking. The collected Segway riding data were also compared to the running characteristics of bicycles. In the study  [9], the observed reactions of the vehicle drivers and passing distance to the different types of personal mobility devices including the Segway are given in detail. The experiments in the study were performed on road crossings while the drivers were turning left. The other sources available in the literature are the reports of some pilot projects [10,11] which report the safety requirements of Segway on the shared footpaths, opinion from the various stakeholders and institutions and the subjective assessments of the recruited riders.On one hand, the available reports and publications are far from covering all the aspects of the interaction between the Segway or the PT devices with the other road users in a consistent and methodological way. All the listed experiments are performed at the controlled conditions and the statistical data do not reflect the real interaction. On the other hand, all over the world, the Segway and similar personal transporters have been utilized in the designated zones for patrolling or recreational purposes. No data gathering is concerned in these conditions. However, each of the travel and riding experiences elicits valuable statistical information, which can contribute to the development of more reliable mobility robots and remove the limitations for the public use of these devices.During the investigation of the incidents and accidents in which the robotic mobility riders involve, the answers to the questions; which braking state the device was in, on what type of road, how was the handlebar used, or which kind and to what degree the lateral maneuvers were done, reveal important information for the researchers, manufacturers, insurance companies as well as the policy makers to make the mobility devices safer, solve the legal issues and improve the traffic regulations.The travel information of the Segways can be gathered without any guidance and experimental setups with a simple software application installed on the widespread mobile devices attached to the Segway. We developed the methods, algorithms and applications to collect travel information from the PTs by these devices. The methods do not require any intervention or experimental setup to gather travel information. The algorithms make use of the sensors of a mobile device such as a cell phone or a tablet PC, in our case, an Android tablet. The application we developed for these devices align the sensor measurements to the motion coordinate system first. The aligned sensor readings then become readily available for analyzing the lateral and longitudinal dynamics of the mobility robots, as well as for investigation of the interaction between the other travelers.In this study, we delineate the application of the current state of the art classification algorithms to classify the braking modes of the Segway using the filtered sensor readings to create a complete context aware system for the Segway.Braking is a process which occurs during a period of time and shows a particular signal pattern of the selected features in normal or sudden deceleration states of the device. As a single measurement from a discriminating variable such as the accelerometer and gyroscope measurements is not enough to determine whether the device is in a sudden or normal braking state, the classification can be implemented by using the pattern recognition or signal classification methods.The signal classification algorithms used in this paper are dictionary based. These are the Sparse Representation based Classification (SRC)  [12], the Block Sparse Bayesian Learning (BSBL)  [13] algorithm family and Collaborative Representation based Classification (CRC) method  [14]. The developed and implemented classification methods are not only limited to the classification of the braking states; normal and emergency stops as well as cruising (no stop), but they can be used for the classification of the road surfaces and lateral maneuvers such as slalom or zigzagging. Thereby, the statistical data are automatically collected on board by the classification algorithms without any interference under the real conditions.In summary, the motivation of the project discussed in this paper is threefold:Firstto design a context aware system which can run on an Android device and provide the rider, especially the elderly one with the visual and auditory information about the environment.to collect as much information as possible automatically from the shared Segways during their travel in the designated robotic zone without any guidance and pre-designed experiment setups; thus to assist the policy-makers for the required legislations and traffic rules.to give the details about the complementary filter optimized for the Android device to be able to read the correct values from the sensors, as the Android device fixed on the handlebar of the Segways is under a continuous steering and road related excitations.We have organized the rest of the paper as in the following way. Section  2 gives a brief overview of the designated robotic zone, the Segway sharing system and the software interface. In Section  3, the sensor systems and the complementary filter are explained. Section  4 is dedicated to the classification algorithms. We present the simulation and experimental results in Section  5. The paper concludes with discussions and the future works.Tsukuba science city of Japan is the only city where the robotic mobility and PT devices can be experimented in the designated robotic zone which is actually a footpath ring (Fig. 1).On the close proximity are a couple of research institutions and the universities. The employees of the institutes, the inhabitants and the university students frequently commute on this footpath of 3 m in width. A couple of research groups have been also working on the different aspects of mobility robots in collaboration with the private companies. The dashed path is the mostly used footpath belongs to the robotic zone in Fig. 1.The personal transporters are officially recognized under the robotics category in Japan and they cannot be used on the public road related areas. On the other hand, as the current trends, traffic and transportation requirements suggest that, the future generations of the mobility robots will occupy the road related areas in the near future. Yet, the rationale that led to the designated robotic zone is to lay out a legislative infrastructure for the investigation and testing of the robot–society interaction under the realistic conditions. Additionally, a Segway sharing scheme has been also developed between the two terminal points of this robotic zone. In this framework, each Segway is equipped with an Android tablet facing towards the rider to track the location information using the GPS sensor of the tablet (Fig. 2). The on-board system also shows the speed of the Segway, how hard the stopping conditions occur, the name of the vicinity, travel time to the terminal points as well.The software also records the sensor data from the motion and position sensors. The entire travel is also recorded using the rear camera of the tablet to build a ride information database for further analyses. However, the sensors values are measured in the body coordinate system and cannot be used directly for the motion analysis. Owing to the tilted position of the tablet, perpetual steering excitation of the handlebar and the road irregularities, the accelerometer readings must be transformed from the body to world coordinate system. The Euler angles; roll, pitch and yaw are needed for this transformation and rotation matrix. The Android software development platform, and sensors report both the Euler angles and rotation matrix. The reported measurements are noisy and cannot be used directly for the braking mode classification due to the limitation of the Micro Electro Mechanical System (MEMS) sensors  [15].The classification algorithms require certain types of features which are the most discriminative for the observed signal to be classified. In the braking mode classification (stopping conditions, sudden and normal stops and cruising-no stop), the core of the entire system relies on the motion or inertial sensors; gyroscopes and accelerometers. A standard Android device has a built-in 3-axis accelerometer sensor and a gyroscope which measure acceleration acting on the device and the angular rates in the three axes. The accelerometer also measures the gravity component on the each axis. Thus, the gravity component must be subtracted from the measurements for the analyses.The body coordinate system of the tablet is shown in Fig. 3. The rotatedy-axis is the forward direction of the motion in the current Segway–Android tablet configuration. For the motion classification such as that of the braking modes, the best discriminative features that can be obtained from the inertial sensors are the rotation angle and the angular rate of the Segway’s handlebar around thex-axis which are the pitch angle and angular rate.The Segway’s handlebar has 2 Degree of Freedom (DOF), the rotations around thexandyaxes; pitch and roll. In order to align the measurements of the body coordinate system with the Segway motion coordinates, the only parameters required are the pitch and roll angles. These angles can be obtained by the trigonometric relationships of the 3-axis accelerometer measurements or the integration of the gyroscope readings. However, both of the MEMS sensors exhibit inherent error characteristics. These errors are the bias (drift), scale factor, cross-coupling, environmental conditions and random noise  [16].Accelerometers report reliable measurements at the lower frequencies and they are not discriminative for the braking mode classification. The readings under the high frequencies are inaccurate and have higher signal-to-noise ratio when especially at the braking situations, whereas, those of gyroscopes are subject to low error levels at the higher frequencies  [16,17]. Therefore, the rotation, roll and pitch angles derived from the measurements of the single sensor either exhibit a high signal-to-noise ratio or drift over a period of time  [17] (Figs. 4 and 5).Given these advantages and disadvantages of the inertial sensors over each other, the best strategy is to compensate the error on the derived rotation angles. Among the choices are to use the Kalman or digital complementary filter which is a steady state Kalman filter in some special cases  [18]. We implemented a complementary filter to obtain the filtered pitch (θ) and roll (ϕ) angles due to the fact that, the Kalman filters are computationally expensive for a tablet PC. On the contrary a third order complementary filter only consists of a few coefficients and easier to implement for the real-time applications. The low and high frequency regions of the accelerometer and gyroscope respectively are complementary to each other and each region can be filtered out using a low and high pass filter (Fig. 6).The pitch and roll angles can be derived from the accelerometer measurements of the each axis directions (ax,ay,az) using the gravity vector, as the components of which appear on the each acceleration readings  [19,20]. The gravity vector is expressed as in Eq. (1) when there is no rotation and the device rests on the screen facing up position.(1)G=[00−g].Assuming that there are two sequential rotations around thexandyaxes, and the rotation sequence is not known, two different rotation matrices are obtained (Eqs. (4), (5)), as the multiplication of the rotation matrices for the pitch (Eq. (2)) and roll (Eq. (3)) is not commutative.(2)Rx=[1000CosθSinθ0−SinθCosθ](3)Ry=[Cos(ϕ)0−Sinϕ01S0Sinϕ0Cosϕ](4)Rxy=[Cos(ϕ)0−SinϕSinϕCosθCosθCosϕSinθSinϕCosθ−SinθCosϕCosθ](5)Ryx=[Cos(ϕ)SinϕSinθ−SinϕCosθ0CosθSinθSinϕ−SinθCosϕCosθ.]The last columns of the matrices in Eqs. (4) and (5) are the gravity vectors. In order to avoid double solutions for the pitch and roll angles, the range of either is restricted between[−π,π]. On the Android software development program, the roll rotation around theyaxis and the pitch rotation around thexaxis are restricted between the ranges[−π2,π2]and[−π,π]respectively. In this case, using the trigonometric identities, the roll and pitch angles can be expressed as;(6)ϕ=atan2(ay,az),andθ=atan2(−ax,ay2+az2).The pitch and roll rotations derived from Eq. (6) are given in Figs. 4 and 5. As seen in the figures, the roll and pitch rotation from the accelerometer is noisy with respect to the filtered measurements. For the complementary filter application a Proportional-Integral (PI) controller can be used to implement a high and low pass filter and to reduce the error on the measured signal. The Simulink model of the complementary filter implementation and the use of a PI controller are given in Fig. 7.The gyroscope measurements, pitch and roll rates are first integrated. The first pitch and roll rotation values computed from the accelerometer readings are used as the initial condition for the pitch and roll rate integration. The input of the PI controller is the difference between the pitch and roll angles derived from the gyroscope and accelerometer measurements. The outputs are the filtered pitch and roll angles; the complementary filter outputs.The transfer function for the estimated pitch and roll angles becomes;(7)ϕf=1sϕġ+Kps(Φa−Φf)+Kis2(Φa−Φf).After a series of algebraic manipulations, the transfer function for the roll and pitch angles is obtained as follows.(8)ϕf=s2s2+Kps+Ki(1sϕġ)+Kps+Kis2+Kps+Kiϕa.The filter coefficientsKpandKimust be defined. We used the PID tuning toolbox of Matlab to find the optimum filter coefficients. Once the transfer function and its coefficients are obtained, the difference equation for the digital filtering can be computed using the bilinear transformation. The Matlab’s PID tuning toolbox gives the optimum coefficients asKp=7.5924andKi=20.7015. Upon applying the bilinear transformation, the difference equation for the roll rotation (Eq. (9)) is obtained as follows.(9)ϕf=(0.907z−1−1.814z−2+0.819z−3)ϕg1−1.8091z−1+0.8188z−2+(0.093z−1+0.0048z−2−0.0882z−3)ϕa1−1.8091z−1+0.8188z−2.In Eqs. (7)–(9),ϕf,ϕgandϕarepresent the filtered roll rotations, the roll rotations obtained from the gyroscope and accelerometer measurements. The same difference equation is used to compute the filtered pitch angle. The results of the complementary filter are given in Figs. 4 and 5. As seen in the figures, the pitch and roll angles obtained from the trigonometric entities of gravity vector measurements of the accelerometer are highly noisy and it gives inaccurate values at the higher acceleration rates. Additionally the drift can be seen in Fig. 4 on the integrated pitch and roll angle of the gyroscopes. The rotation matrix is obtained using these filtered pitch and roll rotations. The accelerometer measurements are multiplied with the obtained rotation matrix to align the sensor readings to the Seqway’s motion coordinate system. The rotated accelerometer readings are given in Fig. 8. The dotted curves represent the aligned measurements in the body coordinate system whereas the continuous curves represent the unaligned measurements. The acceleration values were recorded while the Segway was in a stand still position. As seen in the figure, the gravity value measured along thez-axis of the Android device fluctuates around Earth’s gravity value after rotation. As there is no lateral and longitudinal acceleration, the acceleration values fluctuate around the zero line as expected.The classification algorithms which are based on sparse representation and compressed sensing principles have been proven to be more accurate and robust in the face recognition literature. Along with its robustness and accuracy, the recently proposed algorithms and the ever increasing computational power of the computers, make the use of these algorithms more convenient for the signal pattern recognition studies even on the widespread mobile phones and tablets. There have been new application areas of the pronounced classification methods, such as gesture recognition using different sensor and signal domains  [21]. We have implemented these real-time classification and recognition algorithms in this paper for classification of the braking states of a Segway, due to their accuracy levels and robustness.The advent of the compressed sensing research field fueled a deluge of studies in a broad range of disciplines from machine learning to the medical imaging, control theory to the geophysical data analysis. The premises of this new research field rely on acquiring and reconstructing the signals with a sampling rate which is quite below the rate defined by the well-known Nyquist criteria. The Nyquist criteria state that, any signal can be reconstructed by sampling it at a rate at least twice the highest frequency components of the signal.The compressed sensing principles assert that, a sparse signalx∈Rnwithknumber of non-zero entries, wherek≪ncan be reconstructed by takingmnumber of random linear measurements in the measurement domainΨ. The signalxcan be expressed as the linear combination ofknumber of orthogonal vectors. The measurement matrixΘis a random matrix with the Restricted Isometry Property (RIP)  [22,23]. The resulting linear systemy=ΘΨxis then solved byℓ1optimization methods.The sparsity approach and representing an observed (measured) signal as a linear combination of the basis vectors led to a new classification method; the Sparse Representation based Classification which was first proposed for the robust face recognition in the study  [12]. The SRC method admits a dictionary matrixAand observed signal sampley. In  [12], the dictionary matrix consists ofknumber of different face classesvkhavingnsample face images from the same subject (Eq. (10)).(10)A=[A1,A2,…,Ak]=[v1,1,v1,2…,vk,kn].Each sample from the classes is converted to a column vector and put into the dictionary matrix. The sparsest solution vectorx0to the resulting generic CS equationy=Axcontains coefficients which reconstruct the observed face image as a linear combination of the related class samples (Eq. (11)).(11)x0=[0,…,0,α1,α2,…,αn,0,…,0]∈Rnxk.The coefficientsα1…αnof the solution vectorx0, corresponding to the related class location in the dictionary matrix are much larger than the unrelated ones. The coefficients corresponding to the samples of the unrelated classes are either zero or close to zero, thus the magnitude of the residual vector becomes higher than that of the representing class. The SRC method yields the label of the observed signal comparing the magnitude of the residuals (Eq. (12)) between the observed and the approximated signalỹ=Aδi(x1ˆ)by the coefficients from the each signal class individually. In the equationδirefers to the characteristic selection operator of the associated class.(12)miniri(y)=‖y−Aδi(x1ˆ)‖2.In line with the new developments in the compressed sensing theory, the new methods such as the model based compressed sensing, are immediately infused into the SRC based applications. The model based CS algorithms narrow down the search space for the sparsest solution vector assuming a special structure on it. For instance, in the classification applications where a training dictionary is used, the sparsest solution has definitely a structure as they are stacked into the dictionary matrix as the blocks. In this case, only the coefficients of the solution vector corresponding to the related block locations take non-zero values but the rest must be zero.Many methods that exploit the block-sparsity were proposed. One of these methods which is based on the Sparse Bayesian Learning framework proposed in the study  [24] is the Block Sparse Bayesian Learning (BSBL). The BSBL method is more effective in obtaining the sparsest solutions than the many other solvers available in the literature  [25,26].Let us assume that there areknon-overlapping blocks corresponding to the class entries of the dictionary matrix in the solution vectorx(Eq. (14)).(13)x=[x1,…,xd1︸x1T,…,xdk−1+1,…,xdk︸xkT]∈Rnk.And each block,xi∈Rdi×1is also assumed to be generated by a parametrized multivariate Gaussian distribution:(14)p(xi;γi,Bi)∼N(0,γiBi)i=1,…with a non-negative parameterγiwhich controls the block sparsity ofxand a positive definite correlation matrixBi, which keeps the correlation structure of theith block.The second level parameters which generateγi,Biare obtained by applying the type-II maximum likelihood procedure  [27]. The posterior mean and covariance matrices are updated usingγi,Biiteratively by the Expectation Maximization (EM) or Bound Optimization methods  [24,13]. The bound optimization method converges faster than the EM.The BSBL_BO method exhibits superior performance over the methods that use the SRC for the face recognition  [28]. It is also shown in the studies  [25,26], the BSBL_BO algorithms give more accurate recognition results for the classification of the posture and gestures than the other similar counterparts.Although the BSBL_BO algorithm gives very accurate recognition results but it is not suitable to use on a tablet PC or a mobile computing device yet because of the computational power requirement. We deployed a Java version of the BSBL_BO algorithm on the tablet PC for the braking modes classification. The results and comparisons are given under the experiments and simulations section. A single run for the classification on the tablet PC takes 0.2 s. The computation time is not suitable as the Android system reports the signal at the frequency of 50 Hz.The computationally lighter and faster version of the BSBL algorithms, the Fast Marginalized Block Sparse Bayesian Learning (FM_BSBL) method was proposed in the study  [29] for the face recognition. We also tested the (FM_BSBL) method for the braking states classification. Even though it yields results faster than the BSBL_BO method, the accuracy was the worst among the classification methods we employed in this study.Instead of the using iteratively converging methods, we utilized one of the current state of art classification approaches, the Collaborative Representation based Classification (CRC)  [14,30]. Similar to the SRC algorithm, the CRC codes the observed signal on a dictionary matrix. The general form of the optimization problem is given as in Eq. (15).(15)minxxˆ=‖y−Ax‖q+λ‖x‖p.Theqandpnorm values are either 1 or 2. The different combinations ofpandqmanifest the different variants of the CRC. In the SRC algorithm these values areq=1or 2 andp=1depending on whether there is an occluded face image in the face recognition applications. The authors of the study  [30,14] point out that, the SRC method is the special variant of the CRC.In the general form of the CRC optimization equation, whenq=2andp=2, the optimization problem becomes the Regularized Least Square or Ridge regression, dubbed as CRC_RLS. The second version of the CRC, in which theq=1andp=2norms are used, is called as the Robust CRC, as theℓ1norm makes the optimization results more robust, well tolerating the outliers in the problem. The CRC_RLS yields classification results as much accurate as those the SRC yields, but with an outstanding speed. This is because of that, the regression matrix is independent of the observed signalyand can be computed and stored beforehand.In the orthogonal projection theorem, some linear combination of the basis matrix column vectors in the system of equationsy=Axadd up to the solution vectorx. The ordinary least square solution tries to minimize the norm of the residuals squaredmine=‖y−Axˆ‖2. The residuals are orthogonal to each column ofA. In this case, the multiplication of the two orthogonal vectors must be zero.(16)aiT(y−Axˆ)=0.If all the equations are written in the matrix form, the normal equation becomesATAx=ATy. The solution of the equation is;(17)xˆ=(ATA)−1ATy.The projection ofyon the subspaceAis expressed as(18)yˆ=A(ATA)−1ATywhereA(ATA)−1AT=Pis the projection matrix and satisfies the conditions thatP2=PandPis symmetrical.In the ill-conditioned problems where numerical instabilities occur, a regularization parameter, the Lagrange multiplier is introduced into the system. In this case, the regression is called as Ridge regression and the regression matrixPλ=(ATA+λI)−1ATis no longer a projection matrix as the satisfactory conditions are not met. The pseudo-code of the CRC_RLS method is given in Table 1.The signals to be classified by the CRC method must be of the equal lengths. In the SRC, as a random matrix is used for sampling the signal, the signals in the dictionary may not be of the same length. The shorter signals are trailed by zero to the maximum length in the dictionary. The random matrices with the RIP preserve the distances among the points in the signal and appending zero values to the signal does not distort the embedding  [31,23].We run the CRC_RLS algorithm for classification of the gestures provided by the authors of the studies  [26]. The CRC_RLS yields the same recognition accuracy for the 2-dimensional 23 Wiimote gestures with different lengths, as that the BSBL_BO based SRC yields. In this comparison study, the gesture signals were re-sampled to the same length. The CRC_RLS method only gave a few correct recognition when the signals were not re-sampled to the same length and trailed by zeros to the longest signal length.The CRC and SRC methods require a dictionary matrix which consists of the training samples from each of the classes. In order to construct a dictionary matrix, a professional Segway user performed the planned riding tasks. The rider was instructed to accelerate, reach to a cruising speed and stop slowly (normal stop) or suddenly in the different trials. The normal stop conditions refer to that the braking maneuver does not pose any risk to the rider or the other road users. The experiments were done on an asphalt road with a fine surface and a length of 50 m. The length of the test road was enough at least for doing seven counts of normal stops. The rider repeated the maneuvers seven times for each of the braking states, in total 14. Additionally, two cruise tests were performed, to include the normal cruising state in the dictionary matrix. In the cruising mode, the Segway accelerates and continues on a constant speed and stops at the end of the ride. The first three ride data are used for the dictionary matrix, the rest for testing the algorithm performance. The time frames of the braking states were marked by hands by plotting the maneuvers on the Matlab platform. As the CRC_RLS algorithm requires the training samples in the dictionary to be of equal length, we paid extra attention to keep the lengths of the braking modes close to each other that is because, the time required for the sudden stops is shorter than that of the normal.We re-sampled the signals to the same length for not to append zeros to the relatively shorter signals. An Android application records the data that are read from the motion sensors. It also records the video of the travel by the rear camera of the tablet. The sampling frequency of the sensors is 50 Hz. The recorded data contains, the raw accelerometer and gyroscope readings on three axes, GPS coordinates, Euler angles and the rotation matrix computed by the Android platform. As stated in the Android sensor guide  [15], the accelerometer readings are not reliable at the high frequencies. Instead, we exploit the rotation angle and the angular rate around thex-axis as the features. The pitch angle around thex-axis reported by the Android platform is also jittery and inaccurate. We compute the more reliable and accurate Euler angles, roll and pitch by employing the complementary filter. The overall flowchart of the developed Android application is given in Fig. 9.In the braking state classification application, the accelerometer readings during the braking periods are not discriminatory as much as the roll and pitch angles and their rates of change in the simulations. As the variation of the acceleration signals between sudden and normal stops is remarkably high and between the normal stop and cruising modes is low, using the acceleration patterns does not yield expected higher accuracy rates. As seen in the flowchart, first the roll and pitch angles are computed and filtered by a complementary filter and then along with their angular rates, the roll and pitch angles are used as the discriminatory features by the classification algorithms. Accordingly, the training feature samples from each of the braking states in the dictionary matrix have two dimensions. The 2D signals were re-arranged one feature under the other to obtain a 1D signal. Every class consists of 20 training samples in total. The sliding window approach was adopted (Bottom Fig. in Fig. 10). In the every sampling time, the on-board application looks back, and takes the last 100 measurements and labels the observed braking state maneuver.In the cruising experiments, the rider accelerates, then reaches a cruising speed. The experiments take 15 s. At the end of the ride, the Segway stops normally. As seen in Fig. 10, the FM_BSBL exhibits the worst performance whereas the BSBL_BO and CRC_RLS methods perform well for the cruising mode. The FM_BSBL method uses the same framework with the BSBL methods, however, in the correlation levels of the intra-block correlations are either ignored or defined by the empirical values that might not guarantee feasible values for the correlation coefficients. The accuracy is compromised to achieve faster classification results.The results for the normal braking states are shown in Fig. 11. Once again the BSBL_BO and CRC_RLS classification methods yield the best results. The time frame during the normal stops on the BSBL_BO graph is thicker than that of the CRC_RLS. That is due to the fact that, we can adjust the sensitivity and the robustness of the classification by changing the Lagrange multiplierλin the optimization equations of the CRC_RLS method. The main objective is not to obtain a false alarm. For instance, if the Segway is slowing down normally, receiving a sudden stop alarm is not desirable.Fig. 12shows the sudden stop experiment results. Every sudden stop condition includes the regions where normal stops occur. This can also be seen on the pitch rotation shown in every figure. This because of that, the rider can reach the maximum deceleration after passing from a normal stop region and the Seqway stops normally after passing the maximum deceleration region. The BSBL_BO and the CRC_RLS results are nearly the same in this experiment.Upon performing the simulations on the Matlab platform, we exported the regression matrix for implementing the CRC_RLS algorithm into the Java programming environment. The algorithms of the CRC_RLS are easy to code on Java with a few lines. Additional functions, such as the functions for rotation of the coordinate system, subtracting gravity effect on the each accelerometer measurements and the digital complementary filter are also coded for the Android program.The braking state classification results for the real experiment on the robotic zone are given in Fig. 13. The experiment was done on the robotic zone shared path. The return travel takes approximately 23 min which consists of 26,800 measurements from each feature and braking labels. In the figure, the Segway moves at the cruising mode during 96.28% of the entire travel time. The ratios for the sudden and normal stops are 1.16% and 2.56% respectively.Two dense sudden stop regions are seen in Fig. 13(a). The reason for this region is the paved road (right picture in Fig. 14), the surface of which is rough, and generates high frequency fluctuations on the pitch rate. In addition, the road form is undulated and this undulation creates low frequency fluctuations on the pitch rotation constant tilt. Both of the discriminative features are used in the dictionary and the algorithms naturally select the closest braking state. The training samples in the dictionary were obtained on a flat and fine surfaced asphalt road. As the rough road surface and slope were not represented in the dictionary, the algorithm confuses on these conditions. At the beginning of the experiment, the Segway travels on pavement. The sudden stops in this period, occur due to passing over the pavement corner and bumps and the holes on the asphalt road. The length of this road which does not belong to the robotic zone is approximately 600 m.The left picture in Fig. 14 is the robotic zone’s shared path. The path is asphalt with a fine surface. During the travel of the Segway on this road, the rider does a few sudden and normal stops compared the cruising time. The travel period corresponds to the time interval between 8 and 14 min (Fig. 13(b)). The sudden stops occur on this road section due to the road grids and manhole covers.In this study, we design and implement an Android program which is used to classify the braking modes of a two-wheeled mobility robot. The Segway is used for the experiments. The algorithm of the program makes use of the current state of art classification methods. Due to the computational requirements, the lightest and fastest yet efficient CRC_RLS was employed for the classification. The program also aligns the body coordinate system to the motion coordinate system of the Segway.As the experimental results suggest, the Android program runs with a high performance and accuracy when the CRC_RLC is employed. We also modified the classification algorithm to classify the road surface and irregularities. The results of the study will be published in another article. The modified version of the classification algorithm first decomposes the measured and rotated vertical acceleration signals using the Empirical Mode Decomposition (EMD) method. The study detailed by this paper will continue with adding abilities to the Android program for classification of the lateral maneuvers such as slalom or zigzagging. We also have a plan to perform more experiments with the proposed system, and we continue gathering traveling data to analyze, and find interesting relationships among individual features of the interaction with the other sharers, as the data being collected and used will be a good source for the further analysis of data.

@&#CONCLUSIONS@&#
