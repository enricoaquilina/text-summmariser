@&#MAIN-TITLE@&#
An efficient feature descriptor based on synthetic basis functions and uniqueness matching strategy

@&#HIGHLIGHTS@&#
SYBA is built on the basis of the compressed sensing theory.The descriptor is robust, simple and computationally efficient.Evaluated the descriptor performance statistically on BYU feature matching dataset.

@&#KEYPHRASES@&#
Feature detection,Feature descriptor,Synthetic basis functions,Feature matching,

@&#ABSTRACT@&#
Graphical abstractImage, graphical abstract

@&#INTRODUCTION@&#
Computer vision applications often involve computationally-intensive tasks such as target tracking [1–3], object identification [4,5], image rectification, localization, pose estimation [1,6–9], optical flow [10,11] and many more. The initial steps of all these applications are the detection, description, and matching of high quality feature points, with feature description and matching being the most challenging and time-consuming processes. They focus on computing abstractions of image information that are associated with the points of interest detected by the feature detector.There exist a large number of feature descriptors [12–28], but not every one of them is suitable for hardware implementation for real-time applications. An efficient feature descriptor for real-time applications should not be too computationally complex. To be hardware-friendly, it should not use many square root, division, or exponential operations that require floating-point computations. A good feature descriptor is able to describe a feature point and measure its similarity to other feature points. It allows a feature point to be correctly identified and matched to a feature point in another image that has similar characteristics. A well-known orientation and magnitudes-of-intensity gradient-based feature descriptor is Scale Invariant Feature Transform (SIFT) [12]. It works well on intensity images and provides descriptors that are invariant to rotation and scaling. However, increased complexity and robustness come with the increase in computation and storage requirements and make it not suitable for many resource-limited platforms and real-time applications. Another well-known descriptor, Speeded-UP Robust Features (SURF) computes descriptors using integral images and 2-D Haar Wavelet transform [13,14].  A minor drawback is that it requires 256 bytes to encode 64 floating-point values.Ke and Sukthankar [15] developed a descriptor and applied dimensional reduction technique, Principal Component Analysis (PCA), to the normalized image gradient patch. PCA-SIFT performs better than SIFT descriptor on artificially generated data. At the same time, it has the benefit of reducing high frequency noise in the descriptors. The drawback is that it is not tuned to obtain a sub-space that will be discriminative for matching [16]. Another, dimensional reduction technique Linear Discriminant Embedding (LDE) was developed by Hua et al. [16]. In order to perform well, LDE requires labeled training data, which are difficult to obtain. They are both suitable for feature description and require smaller descriptor size than many well-known approaches.Simonyan et al. [17] and Trzcinski et al. [18] developed descriptors based on training data. Both descriptors require complex operations and require computational resources that are not suitable for hardware implementations.  The accuracy of these descriptors may be affected when they are applied to applications that are completely different from the training dataset. Simonyan et al. proposed to use floating point and then convert it to binary which clearly causes the loss of matching accuracy [17]. Similarly, other descriptors [19–22] require time-consuming training process and complex operations. Even though some descriptors [17–21] use smaller descriptor size than SYBA, they are not suitable for low resource platforms. In recent years, new feature descriptors such as Binary Robust Independent Elementary Features (BRIEF) [23,24], Binary Robust Invariant Scalable Keypoints (BRISK) [25], and Aggregated LOcal HAar (ALOHA) [26] have been reported. These feature descriptors are all based on intensity comparisons. ALOHA is based on a set of Haar-like pixel patterns defined within an image patch. It performs intensity difference tests to encode the image patch into a binary string. ALOHA requires larger patch size and slightly fewer operations than BRIEF descriptor. Even with larger patch size the results are not robust to viewpoint changes and illumination changes. BRIEF descriptor trades reliability and robustness for processing speed, consisting of a binary string that contains the results of simple image intensity comparisons at random pre-determined pixel locations. BRISK relies on configurable circular sampling patterns from which it computes brightness comparisons to represent a binary descriptor. Overall, BRISK descriptor requires significantly more computation and slightly more storage space than BRIEF descriptor. Both of these algorithms use faster feature detectors and smaller descriptor size than SIFT and SURF. As another alternative to SIFT and SURF descriptor, Rublee et al. introduced a new version of BRIEF called rBRIEF descriptor [27]. It is based on a specific set of 256 learned pixel pairs selected for reducing correlation among the binary tests.Feature description has been an active area of research in computer vision and machine learning. The main objective of this work is to develop a simple and hardware-friendly feature descriptor to reduce the computational power requirement and increase the speed and accuracy of feature matching. Our new descriptor is inspired by recent work in compressed sensing [29]. Compressed sensing theory is used to encode and decode a signal efficiently and reduces bandwidth and storage requirements. It is able to uniquely describe a signal with synthetic basis functions, which makes it a perfect theory for feature description.To understand the theory, consider the popular game of Battleship, in which the best result can be obtained by using an adaptive strategy of counting the number of hits in recursively subdivided half-planes. The major drawbacks of this adaptive strategy are that it requires memory space to record and processing power to analyze all previous guesses and guess results in order to determine the next guess. Anderson developed a new compressed sensing algorithm based on this adaptive strategy, using synthetic basis functions instead of subdivided half-planes to minimize memory space requirement [29].Using the battleship game as an analogy, the basic idea of using synthetic basis functions for compressed sensing is to use a random pattern (as shown in Fig. 1(b–d)) as a guess. The biggest advantage of using synthetic basis functions is that it does not require memory for storing previous guesses. Reducing memory space requirement makes using synthetic basis functions an excellent choice for feature description for resource-limited systems.As an example, in Fig. 1(a) the orange squares represent battleship locations in a 15×15 area and the black squares in Fig. 1(b–d) represent the guessed locations of the battleships. The maximum number of different random patterns (or turns) that is required to locate all battleships using this non-adaptive approach is surprisingly the same as the original adaptive strategy approach (but with the benefit of significantly reduced memory space), which is given by Anderson [29](1)M=C(KlnNK),where N is the number of squares on the game board (n × n) and K is the number of queried battleship locations. C is round up number to the nearest integer. M is the number of random patterns (turns) required to locate all ships and is the smallest when K = N/2. This very small number of random patterns is sufficient to locate all battleships.Fig. 1(a) shows that there are seven battleships in a 15 × 15 area. As shown in Fig. 1(e), out of seven battleships, six of them (squares in blue) are hit or guessed correctly because their locations coincide with six of the black squares in the random pattern (or turn) shown in Fig. 1(b). One ship is missed (square in orange) using the same pattern (turn) shown in Fig. 1(b) because its location coincides with a white square. Similarly, there are six and five battleships (squares in blue) are hit or guessed correctly using random patterns (or turns) shown in Fig. 1(c) and (d). Their results are shown in Fig. 1(f) and (g), respectively. According to Eq. 1, the number of random patterns or turns required to locate all battleships in a guessing game of this size (15×15), using the unique (non-repetitive) basis patterns (K = N/2), is 113 ln (225/113) or 78.Inspired by this compressed sensing theory, we have developed a new descriptor algorithm using synthetic basis functions, called SYthetic BAsis (SYBA). It uses a number of randomly generated synthetic basis images (SBIs) as the guesses in a “battleship game” to measure the similarity between a small image region surrounding a detected feature point, called a feature region image (FRI), and the SBIs. The similarities between an FRI in the image and all SBIs are then used as the feature descriptor.This work involves a unique way of measuring descriptor similarity in order to match similar features between two images. This unique way of measuring descriptor similarity is less complex than Mahalanobis and Euclidean methods. This work also includes a feature matching strategy that contains a two-pass search to enforce the uniqueness constraint and global minimum requirement to determine the best matching feature pairs. The new descriptor, called SYBA, is introduced in Section 2. Experimental results based on feature matching comparison with two widely used binary descriptors, BRIEF-32 and rBRIEF, are presented in Section 3. In Section 3, also includes the statistical T-test experiments on newly created dataset. Section 4 summaries the paper with discussion of the performance and ideas for future work.Well-known binary descriptors are often used for benchmarking feature description performance. BRIEF descriptor compares the intensity of two randomly selected pixels and uses the intensity difference as a descriptor [23]. Rather than intensity difference, SYBA compares a feature region image with a number of synthetic basis images and uses the similarity measures as the feature descriptor. The creation of the synthetic basis images and the computation of the SYBA descriptor are the two major parts of this algorithm.Synthetic basis images are sparse images. They differ from the basis dictionary images created from natural or man-made objects in our previous work [30,31]. All basis dictionary images created from natural or man-made objects are not always sparse. There are two major differences between the basis functions created from random numbers (i.e. synthetic) and basis images created from natural/man-made objects. The computation time for basis images created from natural and man-made objects require several hours, while basis images created using random numbers (i.e. synthetic) require at most a few seconds. Memory space required to create synthetic basis images is far less than basis images created from natural/man-made objects. These are the reasons the synthetic basis are much better.The number of synthetic basis images (M) represents the number of “turns” as in the battleship game and is calculated according to Eq. (1). Of course, a larger number of synthetic basis images are required for a larger pixel region surrounding the detected feature points or feature region image (FRI). The maximum number of synthetic basis images required is 9 (when K = N/2) for a 5 × 5 FRI, whereas a 30 × 30 FRI requires 312 synthetic basis images.Two examples of synthetic basis images are shown in Fig. 2. One is 30 × 30 and the other is 5 × 5. Synthetic basis images similar to these two are used for SYBA descriptor calculation. The first step to creating a synthetic basis image is to determine its dimension (N = n×n). Once the dimension of the synthetic basis image is determined, K (=N/2) normally distributed pseudo random numbers are generated from [1, … , N] to represent the black squares in the synthetic basis image. Note that even for small SBIs (e.g., 5 × 5) that are generated in this manner, all SBIs in one set (M) will be uniquely represented (with a probability equals to 0.99999893), and thus no specially designed patterns are needed.The main function of the SYBA descriptor is to “describe” the FRI of an image feature point in a unique way so that feature points between two images can be matched. SYBA descriptor does not require complex descriptor calculations and yet is able to provide good feature matching accuracy. SYBA descriptor algorithm is illustrated in Fig. 3.The first step of the SYBA algorithm is to detect feature points and generate a feature list. Any feature detector can be used for this purpose. This work uses SURF as the feature detector because it is several times faster than SIFT [13]. For each feature on the feature list, its feature region is cropped and saved as a 30 × 30 FRI. The second step of the algorithm is to calculate the average intensity (g) of the FRI as(2)g=∑x,yI(x,y)p,where p is the number of pixels in the image (900 in this case), and I(x, y) is the intensity value at pixel location (x, y). A binary FRI is then generated based on the average intensity g. If I(x, y) is brighter than g, the binary FRI at the pixel location (x, y) is set to one, otherwise the value is set to zero. The last step of the algorithm is to calculate the similarity between the binary FRI and each of the SBIs in order to generate a descriptor for each binary FRI on the feature list.A unique SYBA similarity measure (SSM) is developed to measure the similarity between the FRI and a selected number of SBIs. The result of SSM represents an accurate feature description because it takes into account the spatial and structural information of the feature region. The output of the SSM is then used to describe the feature point for feature matching as shown Fig. 3.For the experiments, SYBA with two different sizes was implemented. One was computed with SBIs of size 5 × 5 and named SYBA5 × 5. The maximum number of SBIs required for SYBA5 × 5 is 9 when half of the pixels (N = 25 and K = 13) are black. Fig. 4(a) shows an example of 9 5 × 5 SBIs labeled from 1 to 9. The other size used for experiments was 30 × 30 and named SYBA30 × 30. The maximum number of SBIs required for SYBA30 × 30 is 312 when half of the pixels (N = 900 and K = 450) are black. Once the required SBIs are generated, they should not be changed in order to use the same patterns to test the next image.Fig. 4 shows an example of how the SSM is calculated between a 30 × 30 FRI and SYBA5 × 5. The SSM between a 30 × 30 binary FRI and SYBA30 × 30 is be calculated in a similar manner. The first step of the SSM calculation is to divide the 30 × 30 binary FRI into 36 equal-sized 5 × 5 pixel subregions (as shown in Fig. 4(b)). The next step is to count how many pixels in the 5 × 5 subregion of the binary FRI are hit by each of the 9 SBIs in Fig. 4(a). Each of these 36 5 × 5 subregions is compared with each of the 9 5 × 5 SBIs and the number of times both contain a black pixel at the same location is counted as a hit.The maximum possible number of hits for comparing a 5 × 5 subregion with a 5 × 5 SBI is 13 because there are only 13 (K = 25/2) black pixels in each SBI. For example, the highlighted 5 × 5 subregion shown in Fig. 4 (b) compared with SBI #1 has 5 hits (shown in Fig. 4(c)). The same subregion in Fig. 4(b) compared with the SBI #2 has 4 hits (shown in Fig. 4(d)). After comparing with all 9 SBIs, each subregion will yield 9 numbers ranging from 0 to 13. The number of hits in each subregion is stacked in the feature descriptor. Each subregion will use these 9 numbers as its feature descriptor. Therefore, a 30 × 30 FRI with 36 5 × 5 subregions will require a feature descriptor size of 36 (5 × 5 subregions) × 9 (5 × 5 SBIs) × 4 bits (0–13) = 1,296 bits or 162 bytes.For the SYBA30 × 30 implementation, the entire 30 × 30 FRI is used to compare with 312 30 × 30-pixel SBIs. The maximum number of hits between the FRI and each SBI is 450 because there are only 450 (K = 900/2) black pixels in the entire 30 × 30 SBI. The resulting feature descriptor size for SYBA30 × 30 is 1(FRI 30 × 30 region) ×312 (30 × 30 SBIs) × 9 bits (0–450) = 2,808 bits or 351 bytes.SYBA descriptor size can be easily adjusted by changing the sizes of SBI and FRI. A generalized approach that describes SYBA descriptor size is as follow. Choose the FRI dimension F first and then choose the SBI dimension S to be an integer factor Q of F so that S×Q = F. Note that M is a function of K and N (Eq. (1)), K is a function of N(K=N/2), N divisible by S, and Q = F/S. These relationships allow complete parameterization of SYBA in terms of just F (the dimension of an FRI) and S (the dimension of an SBI). The SYBA descriptor size is Q×Q (# of subregions) × M (# of SBIs) × log2K bits.Although the compressed sensing theory is able to uniquely represent a signal, the feature representation may not be unique due to the way the descriptor is calculated as shown in Fig. 4. We do lose some spatial uniqueness by only counting the number of “hits” and not tracking where the “hits” are like in the Battleship game. The tradeoff we make to simplify our descriptor calculation sacrifices (statistically) the uniqueness a little.The SYBA descriptor is used to find the best matching feature points between two image frames. In this process, 324 (36 (5 × 5 subregions) × 9 (5 × 5 SBIs)) descriptor elements ranging from 0 to 13 are used as feature descriptors for SYBA5 × 5, and 312 (1 (30 × 30 region) × 312 (30 × 30 SBIs)) descriptor elements ranging from 0 to 450 are used as feature descriptors for SYBA30 × 30. To minimize computational complexity, for determining similarity we use the L1 norm rather than other common comparison metrics such as Euclidean or Mahalanobis distance, which require complex operations such as square and square root.The L1 norm is computed as the sum of absolute differences:(3)d=∑i=1n|xi−yi|where, xiis the score for region of the feature point in the first image, and yiis the score for region of the feature point in the second image, n is total number of regions used in the basis comparison (324 for SYBA5 × 5 and 312 for SYBA30 × 30). The similarity between two features is represented by d and the smallest L1 norm (d) represents the best match of features between two images. Eq. (4) shows an example of SYBA descriptor calculation. Each row represents a feature descriptor. The d value for Eq. (4) is 5 between the two example feature descriptors.(4)To match the features, we first determine point-to-point correspondences using the similarity measure. We select each descriptor in the first image and compare it to all descriptors in the second image by calculating the d value as shown above. The remaining process is divided into two steps: (1) two-pass search, and (2) global minimum requirement. First we use a two-pass search to find feature pairs that uniquely match to each other. We then use a global minimum requirement to screen for possible good matching feature pairs from the remaining feature points.1) Two-Pass Search:In this step, the first pass is to find the minimum distance d between one feature in the first image and all features in the second image. The feature that has the smallest distance in the second image is considered a match to the feature in the first image. The second pass it to confirm that the matched feature in the second image also has the shortest distance to its match in the first image. If the second pass fails to confirm the reciprocal of the shortest distance between the two, then they are not matched. They will remain on the feature list and to be tested in the second step. This two-pass search ensures a unique one-to-one match and eliminates any possible ambiguity. Because our aim is to find unique matching feature point pairs between two images, a feature that matches to two or more features that have the same shortest distance is not considered and will remain on the feature list. After the completion of the two-pass search, the matched feature pairs are excluded from any further matching processes. The remaining feature points in both images are then further tested in the second step.Fig. 5shows an example of the two-pass search. As shown in Fig. 5(a), there are 8 feature points in image-1 (vertical) and 7 feature points in image-2 (horizontal). The similarity between feature points in image-1 and feature points in image-2 is calculated using Eq. 3. The last (right) column shows the minimum d value of each row by comparing each feature point in image-1 with all of the feature points in image-2. For feature point-3 of image-1, there are two smallest distances of 3 in image-2: feature point-2 and feature point-3. This distance is shown as (3, 3) in the last column. Also for the feature point-7 in image-1, there are two equal d values (2, 2) for feature point-1 and feature point-3 in image-2. The row minimum d values are highlighted by horizontal black lines in Fig. 5(b). The last (bottom) row shows the minimum d value of each column. The minimum d value is found by comparing each feature point of image-2 with all feature points of image-1. The column minimum d values are highlighted by vertical black lines in Fig. 5(b). Feature points are considered uniquely matched if they have the mutually shortest distance. Four pairs of these mutual matches are highlighted in blue crossed lines in Fig. 5(b).Because the aim is to find unique matching feature point pairs between two images in this step, any matches that have more than one smallest d value are not considered a match. Point 3 in image-1 and Point 2 in image-2 are not considered a match because Point 3 in image-1 and Point 3 in image-2 also have a minimum distance 3. Only a unique smallest d value in the same row or column can be called a matching pair. Three unique matching pairs between feature points in image-1 and feature points in image-2 are highlighted in blue in Fig. 5(c) using this two-pass search. Feature point numbers 1, 4, and 5 in image-1 match to feature point numbers 1, 5, and 3 in image-2, respectively. Since these feature points have been paired with their unique matches, they will not match to any other points. The rows and columns of these matched points in both images are highlighted in 45-degree oblique black lines and removed from further searches. The remaining unmatched feature points (not highlighted in Fig. 5(c)) will be sent to the second matching step.2) Global minimum requirement:After the two-pass search is performed, global minimum requirement is applied to the remaining feature points. In this step, we find the minimum d values for all remaining feature points. For one-to-one matches between two images, the smallest unique d value is considered a match. This process repeats until all possible pairs are found. Any remaining feature points are without a matching point. Fig. 6illustrate the process of applying global minimum requirement.An example of this global minimum requirement applying to the remaining feature points from the two-pass search is shown in Fig. 6. Three global minima are found as shown in Fig. 6(a). Feature point-3 in image-1 is uniquely matched to feature point-2 in image-2. The row and column of this feature point are highlighted with blue rectangles and will not be considered for further search. The remaining possible matches are shown in Fig. 6(b). The next lowest distance in the remaining points is 5. There are three possible matching pairs with a distance 5 but only one is a unique match (Point 7 in image-1 to Point 7 in image-2). Again, the row and column of this matched point are highlighted with blue rectangles and are removed from further search. The remaining possible matches are shown in Fig. 6(c). The next lowest distance in the remaining points is 6, which matches Point 2 in image-1 to Point 6 in image-2. After row 2 and column 6 are removed from this search, the only possible matches are row 8 and column 4 as shown in Fig. 6(d). The same process can be performed until no minimum can be found. As shown in Figs. 5 and 6, seven matches are found. Of these 7 matches, 3 matches were found using the two-pass search and 4 matches were found using global minimum requirement. Note that a global minimum can be adjusted to terminate the search at any stage. A smaller global minimum will return fewer but better matches whereas a larger global minimum will return more but lower quality matches. The matching feature pairs of the example shown in Figs. 5 and 6 are listed in Table 1.

@&#CONCLUSIONS@&#
