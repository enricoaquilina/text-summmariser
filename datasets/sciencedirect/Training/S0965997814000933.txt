@&#MAIN-TITLE@&#
Quantitative assessment of the effectiveness of using display techniques with a haptic device for manipulating 3D objects in virtual environments

@&#HIGHLIGHTS@&#
The effects of two display techniques on 3D manipulation tasks were compared.The two display techniques are 2D and 3D stereoscopic virtual holography display.Experiments involving selected pointing and manipulation tasks were conducted.The use of 3D virtual holography resulted in faster performance of the tasks.The performance gains were quantified through statistical analysis.

@&#KEYPHRASES@&#
Haptic interaction,Virtual holography,Display techniques,Multimodal interaction,Virtual environments,3D manipulation tasks,

@&#ABSTRACT@&#
Quantitative assessment is made of using two display techniques, providing two different levels of depth perception, in conjunction with a haptic device for manipulating 3D objects in virtual environments. The two display techniques are 2D display, and interactive 3D stereoscopic virtual holography display on a zSpace tablet. Experiments were conducted, by several users of different ages and computer training. The experiments involved selected pointing and manipulation tasks. The speed of performing the tasks using the two display techniques were recorded. Statistical analysis of the data is presented. As expected, the use of interactive 3D stereoscopic display resulted in faster performance of the tasks. The improvement in performance was particularly noticeable for the cases wherein the subjects needed to manipulate the haptic arm to reach objects/targets at different depths, and also when the objects/targets were occluded partially by the obstacles.

@&#INTRODUCTION@&#
Haptic interface technologies, which mediate the sense of touch and proprioception, represent a rapidly growing field with wide spectrum of applications ranging from tele-robotics (control of machines and devices), entertainment, and mobile devices to realistic simulators for training and planning of surgical procedures. The use of haptic devices enables the users of virtual environments to reach the virtual 3D objects, and also “touch” and feel the simulated objects they interact with.Several recent advances have been made in haptic interface technologies [1–3], and several national and international meetings have been organized, which were devoted to haptic technologies. Examples include IEEE World Haptics, EuroHaptics, and the ACM Symposium on User Interface Software and Technology [4–6]. Reviews of the status and some of the recent developments in haptic technologies are given in the generalized state of the art survey [7], and in the focused survey on medical training simulator [8].Among the new developments of haptic technologies are the novel haptic input–output devices such as AIREAL [2]. The device uses free air flow to transfer sense of touch information. The user, while not required to be in contact with the physical device, is able to feel virtual objects, experience dynamically varying textures, and receive feedback on full-body gestures. Some recent work has been devoted to haptic representation of data charts, geographic maps, and pictures [9], as well as on creating haptic devices with smaller form-factors, and embedding them into ubiquitous and/or wearable technologies [10]. The present study focuses on coupling interactive stereoscopic tablet display with haptic interaction for manipulating 3D objects. The impact of this coupling on the depth perception along with the performance of users in virtual environments are also investigated. The force feedback capabilities of the haptic device are not used in the study.Modalities are the sensory channels or pathways through which individuals give, receive, and store information. The visual, auditory, tactile/kinesthetic, smell, and taste senses mediate information from the environment to the person. The inbound information bandwidth for different modalities is different for each individual. The average share of each modality on a person’s perception, memory, and sensation abilities was studied by Nørretranders [11] (Fig. 1).Seaborn et al. [12] demonstrated the effect of presenting information through both visual and haptic channels on the efficiency of cognitive load. In their study, the pattern matching tasks were presented to the participants using visual, haptic, or visual+haptic modalities. Their results suggested that the working memory is not strictly shared among the visual and haptic channels. This is important for visuo-haptic coupling studies as it indicates memory recall may be strengthened by utilizing both visual and haptic modalities. Lecuyer et al. [13] examined various ways of combining visual, haptic, and brain-based interfaces. The users of the virtual environment received haptic assistance towards specific goals, such as path-tracking, according to their current mental workload, which was measured by the brain-based interface. The authors measured the path tracking task performance under three conditions: no assistance, mental workload-based haptic assistance, and continuous haptic assistance. Their results showed that using workload-based assistance results in significantly better performance than not receiving any assistance. There was no significant difference between the performances of workload-based assistance and continuous assistance. Evreinova et al. [14] studied the performance of haptic exploration of simple geometric shapes in the absence of visual feedback. Their findings suggested that haptic exploration, in the applications considered, was robust and sufficient even if it was not backed up with a visual feedback.Lawrence et al. [15] studied the effect of synergistic visual/haptic coupling on the perception of scientific data. The visuo-haptic interface allows users to interactively explore scalar, vector, and tensor fields. Their findings suggest that haptic data rendering, when presented as a companion to the visual rendering, helps users to understand the underlying patterns of the presented data more clearly. Ikits and Brederson [16] presented the Visual Haptic Workbench, which is an integrated immersive visual and haptic system for scientific data exploration. In the cited work, the authors augmented the visual sensory-channel with the haptic interaction and therefore made the information exchange more efficient by increasing the sensory bandwidth. Compared with the desktop zSpace tablet, which was used in the present study, the haptic workbench is a larger system and prone to tracking problems due to the underlying magnetic tracking infrastructure. Ikits and Brederson presented several scientific data visualization methods, and identified the quantitative analysis of the usability of their visualization methods as possible future work.In the present study a quantitative assessment is made of the times required to complete spatial manipulation tasks in virtual environments. The tasks involved using a stylus-based haptic device to simulate the use of the robotic arm of a Martian rover in moving rocks from one location to another. The haptic device was used for manipulating 3D objects in the virtual environment (i.e., moving the rocks). No force-feedback capabilities were used in the experiments. Two display techniques were used, namely visualization of the 3D scene on a regular 2D computer display, and a 3D stereoscopic virtual holography display of the scene on a zSpace tablet. The objective of the experiments is to investigate the effect of the used display technique on the time required to perform the task. Although the task completion time using the virtual holography tablet display was expected to be less than that using 2D display, however, the experiment aimed at quantifying the resulting improvement from the additional depth cues introduced by the virtual holography 3D display for a broad spectrum of users.Depth perception process takes advantage of several depth cues that are classified into two main categories: binocular depth cues and monocular depth cues [17,18]. Binocular parallax [19], is the most commonly used depth cue in current consumer stereoscopic displays. This depth cue works by presenting slightly off-set images to both eyes of the viewer, and lets the brain infer the depth information as it naturally does. Motion parallax is used extensively in one’s daily life [20]. It helps in inferring depth information by using the simple relationship between the distance of the object and its relative speed with respect to the viewer. For objects moving in the viewer’s coordinate system, the ones that are closer to the viewer seem to be moving greater distances than the objects that are farther away from the viewer. This fact is inherently used by the brain to infer depth information in such scenes.The zSpace tablet enhances the 3D immersion by providing full motion parallax in addition to the binocular parallax depth cue. This is achieved by infrared cameras that are embedded inside the tablet. These cameras continuously track the viewing angle of the user and adjust the 3D perspective of the virtual environment according to the user’s vantage point. The infrared reflective markers are located on the lightweight polarized passive 3D eyewear. The display of the tablet is a 24in., high-definition (1080p, 120Hz) 3D monitor with full resolution images rendered for each eye (Fig. 2).The zSpace tablet also comes with a custom stylus, whose position and orientation are continuously tracked by the tablet. Although, the uniquely designed stylus is the main tool for managing all interactions in 3D space, an extensive collection of software libraries, and the development platform, allow developers to build their own tools, extensions, and applications and to integrate custom input devices to the zSpace tablet.The zSpace tablet connects to a computer as an external display and allows the user to enable/disable stereoscopic rendering. This functionality allowed the performance of the experiment with the two levels of visualization on the same hardware setup.Haptic interfaces operate on the sense of touch in two ways. Tactile method handles the simulation of surface properties such as roughness, smoothness, and temperature. Force feedback method, on the other hand, enables the users to explore, manipulate, and modify remote/virtual objects in three dimensions, and to receive reaction forces through the actuators of the haptic device. In this study, the Omni model from the Sensable Technologies’ PHANTOM® product line was used as the haptic interface – a 3D input mechanism (Fig. 3).The PHANTOM Omni device can track its stylus in six degrees-of-freedom, providing high precision and high resolution location and orientation data. The device can handle sub-millimeter (0.055mm) position resolution [21], which is more than sufficient for the experiments in the present study. The software development kit (OpenHaptics toolkit), which comes with the PHANTOM Omni allows developing custom applications that utilize the haptic capabilities of the hardware.The zSpace tablet was placed on a flat surface at its default 30° standing configuration. The PHANTOM Omni device was located in front of the zSpace tablet facing towards the tablet in order to match the haptic arm kinematic chain to the virtual robot arm kinematic chain (Fig. 4). The subjects in the experiment held the stylus in a vertical position and moved the haptic arm as if they were controlling the remote robotic arm.Thirty-two subjects volunteered to participate in this study. The subjects ranged in age from 7years to 30years and in education from elementary school to post-graduate students. The age distribution of the participants is clumped at late teens and early twenties. The experiments were organized and supervised by the same person. Consents for participation were obtained from all subjects before the experiments.Each subject performed the experiment for the two display techniques. In order to avoid the biasing due to the prior learning, the starting display technique was randomly chosen with equal probability for each of the subjects. The subjects were first introduced to the equipment through a simple tutorial scene that involves haptic interaction input, and then the procedure that they need to follow in the experiment was described clearly. The subjects were also informed verbally that their performances were being recorded in terms of the time it takes to complete the task. For each of the two display techniques, the task completion times were recorded, and later post-processed using mathematical statistical packages.One of the mostly used models in human–computer interaction is Fitts’s law [22]. It uses an empirical model to predict the time required for rapid aimed movements, and can be used to model a pointing task in both 2D and 3D. In order to engage the participants, the standardized point-to-point transfer tasks were modified as an extraterrestrial robotic mission (Fig. 5).On a terrain with multiple obstacles, the tasks were chosen as moving four sample rocks from their original locations to preselected target locations. Target locations were designated by large X marks. The transfer operations of the rocks were completed as soon as they touched the target locations. Several obstacles with different heights, between the initial and final locations of the rocks, served as additional test involving the depth perception for the participants (Fig. 6). In case the subjects hit any obstacle with the robot arm, they were alerted with audio-visual cues in order to discourage them from passing the virtual arm through the obstacles.For each participant, the times were recorded between picking up the first rock from its initial location and completing the entire set of tasks by placing the last rock at its target location.The data obtained from the experiments for the two display techniques was grouped into two sets. The box-whisker chart of the data showed two extreme, and one questionable outliers, in the 3D stereoscopic virtual holography display data set (Fig. 7). These three data points were in agreement with the authors’ observations and notes about the subjects of the experiments, who were distracted by external stimuli. The three data points were removed from further statistical analysis. The data sets pertaining to the 2D and 3D stereoscopic displays were first compared with the Fisher’s test to see if their precisions were similar or not. The two sided Fisher’s test showed that the standard deviations of the two sets were similar, which means that they can be comparable with Student’s T-test [23].For the null hypothesis being the similarity of the two data sets, the Student’s two tailed T-test was applied. The calculated T-test statistic (2.95091) and the corresponding p-value (0.00456494) suggest that the task completion times obtained from the 3D stereoscopic virtual holography display is significantly different (lower) than the task completion times obtained from the 2D display. On the average, the time spent for the performance of the tasks with the virtual holography display was about 25% lower than that with the 2D display.A quantitative assessment is made of using two display techniques, in conjunction with haptic interaction, for manipulating 3D objects in virtual environments. The two display techniques are 2D and 3D stereoscopic virtual holography tablet display. An experiment was conducted, in which subjects were asked to perform selected point-to-point transfer tasks using the two different display techniques.As expected, the use of 3D stereoscopic virtual holography display resulted in faster performance of the tasks. The improvement in performance is more pronounced for the experiment cases wherein a sharper depth perception was required. The interactive stereoscopic virtual holography zSpace display allows users to look around the 3D objects in an intuitive way, and this important functionality improved the task performance when the objects were occluded by each other. The subjects also identified some additional advantages of the 3D stereoscopic virtual holography over the 2D display, including its intuitive nature and user friendliness. The positive effects were mostly noted by the younger subjects in the experiment (ages 15–24), who described themselves as computer savvy and have been active in computer gaming.The present study paves the way for more advanced studies of visuo-haptic coupling and its impact on mental/cognitive workload. It is also a step towards extending the work to study the effect of the synergistic-coupling of haptics with other modalities, such as brain-based interfaces, on the cognitive workload of the users.

@&#CONCLUSIONS@&#
