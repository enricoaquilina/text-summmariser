@&#MAIN-TITLE@&#
Notes on ‘Hit-And-Run enables efficient weight generation for simulation-based multiple criteria decision analysis’

@&#HIGHLIGHTS@&#
Hit-And-Run enables efficient sampling of weights with linear inequality constraints.A generalized change-of-basis can extend the method to handling equality constraints.A flawed seedpoint generating method should be replaced by a linear program.

@&#KEYPHRASES@&#
Multiple criteria analysis,Simulation,Uncertainty modeling,

@&#ABSTRACT@&#
In our previous work published in this journal, we showed how the Hit-And-Run (HAR) procedure enables efficient sampling of criteria weights from a space formed by restricting a simplex with arbitrary linear inequality constraints. In this short communication, we note that the method for generating a basis of the sampling space can be generalized to also handle arbitrary linear equality constraints. This enables the application of HAR to sampling spaces that do not coincide with the simplex, thereby allowing the combined use of imprecise and precise preference statements. In addition, it has come to our attention that one of the methods we proposed for generating a starting point for the Markov chain was flawed. To correct this, we provide an alternative method that is guaranteed to produce a starting point that lies within the interior of the sampling space.

@&#INTRODUCTION@&#
Multi-Attribute Value Theory (MAVT) is widely applied in multi-criteria decision making contexts to make a choice from a set of alternatives, or to rank them from the best to the worst. This is achieved by constructing a value function that associates with each alternative a real number indicating the total value, or utility, of this alternative to the decision maker. In practical applications of MAVT, it is usually assumed that the decision makers’ preference structures satisfy the preferential independence conditions necessary for the application of the additive value model. The problem of eliciting preferences then reduces to specifying a set of single-attribute value functions and a set of weights that reflect the relative importances of unit increases in these functions (Keeney & Raiffa, 1976).Traditional preference elicitation approaches rely on relatively complex questioning techniques to elicit the required model parameters from a decision maker, such as the bisection method for specifying the partial value functions, and swing weighting for determining the scaling constants (Belton & Stewart, 2002). In practice, however, decision makers are not always able or willing to provide precise preference information, meaning that their preference structures cannot be uniquely specified. In response to this problem, three generic strategies have been developed to extend the use of MAVT to settings where only imprecise preference information is available, or where a mixture of precise and imprecise preference information can be obtained: (i) inference of a single representative value function that is in some way the most consistent one with the provided value judgments (Greco, Kadziński, & Słowiński, 2011; Kadziński, Greco, & Słowiński, 2012), (ii) random sampling of a set of value functions from the restricted parameter space defined by these judgments (Kadziński & Tervonen, 2013a, 2013b), and (iii) exploring the whole set of value functions compatible with the preferences of the decision maker as in the Robust Ordinal Regression (ROR) approach (Greco, Mousseau, & Słowiński, 2008).As both ROR and the inferential approach for handling imprecise preference information are based on linear programming, they can be used with an arbitrary combination of ordinal, categorical, and imprecise numerical judgments provided that each of these judgments can be expressed as linear constraints on the parameter space (Belton & Stewart, 2002). However, due to the lack of efficient sampling algorithms, the practical application of the simulation-based approach was until recently restricted to specific parameter spaces, such as the(n-1)-simplex in n-dimensional space, which reflects complete ignorance of the weights for the additive value function (Tervonen & Lahdelma, 2007). In our previous work (Tervonen, van Valkenhoef, Baştürk, & Postmus, 2013), we provided a partial solution to this problem by showing how the HAR sampler (Smith, 1984) can be applied to enable efficient sampling of the weights from a convex polytope constructed by restricting a simplex with a set of linear inequality constraints. In this short communication, we describe how our previously proposed method for transforming the n-dimensional weight space to an(n-1)-dimensional sampling space can be generalized to allow mixing imprecise and precise preference statements, which provides greater flexibility for the types of statement that can be elicited from the decision maker. In addition, it has come to our attention that one of the methods we proposed to generate the starting point for the Markov chain was flawed. As a remedy to this issue, we describe how the inferential approach for handling imprecise preference information can be utilized to generate a starting point that is guaranteed to lie within the interior of the sampling space.All possible n-dimensional weight vectors lie on the hyperplane defined by the constraint∑i=1nwi=1. To apply HAR to weight generation, the n-dimensional weight space must be reduced to an(n-1)-dimensional sampling space because the hyperplane corresponding to the normalization constraint has zero volume and thus the probability of a random walk staying within the hyperplane is also zero. In our previous work (Tervonen et al., 2013, Section 3.1), we indicated how the normalization constraint∑iwi=1can be eliminated by the composition of a change of basis and a translation. This can be generalized to enable weight sampling with any consistent set of linear constraints. For example, in a problem with three criteria (see Fig. 1), the transformation suggested in our previous paper allows the calculation of intermediate results during ordinal preference elicitation, first with no preferences{}, then with a single statement, e.g.{w1⩾w2,w1⩾w3}, and finally with the full ranking, e.g.{w1⩾w2,w2⩾w3}. The generalization below allows the calculation of intermediate results during the subsequent trade-off weighting, e.g. with preferences such as{w1=1.3w2,w2⩾w3}. This allows for greater flexibility in determining when the preference elicitation process can be terminated, for example due to the alternatives becoming sufficiently discriminated with the given preference statements.Let the sampling space be embedded inRnand defined with the following constraints:Cw⩽b;Fw=g.The solution space of the equality constraints is then given byw=F†g+(I-F†F)y,whereF†is the Moore–Penrose pseudoinverse of F (Penrose, 1955; Penrose & Todd, 1956) and y is an n-vector representing the transformed weights. IfF=UΣVTis the singular value decomposition of F, then the pseudo-inverse is given byF†=VΣ†UT, andΣi,i†=1/Σi,iwhereΣi,i≠0andΣi,j†=0everywhere else. WhenF†F=I, the solutions space consists of a single pointx=F†g. In other cases, the dimension of the solution space isd=rank(I-F†F)<n, and some components of the n-vector y are redundant. A non-redundant orthonormal basis D can be constructed from(I-F†F)by taking the first d columns of the Q component of the QR decomposition of(I-F†F). The solution space is then given by:w=F†g+Dy′,wherey′is a d-vector. Because it is just a change of basis followed by a translation, this relation can be used to transform the inequality constraints defined on the n-dimensional space to the d-dimensional space in which HAR is applied, and its inverse to transform the generated samples to the original weight space (Tervonen et al., 2013).In our previous work (Tervonen et al., 2013), we claimed that a starting point for the Markov chain can be generated by first determining the extreme points along each dimension and then taking a weighted average of those points. If the inequality constraints are given (in the sampling space) byAx⩽b, the extreme points along the k-th dimension can be obtained by solving the following two linear programs (LPs):maximizexkminimizexksubjecttoAx⩽bsubjecttoAx⩽bHowever, if the polytope is oriented in a certain way relative to the axes along which the LP are solved, the extreme points may all lie on a single (hyper) face of the polytope. For example, given the polytope with vertices{(0,0),(1,1),14,34}, if we solve the LP along the natural axes we only get the points(0,0)and(1,1), which thus span a space of only one dimension while the polytope itself is two-dimensional (Fig. 2). In that case the generated starting point will lie the boundary of the polytope rather than in the interior. Due to numerical accuracy issues, the starting point may even lie slightly outside of the polytope, leading to further problems. Replacing the set of extreme points by the vertices of the polytope (as we described in our previous work) would solve this problem, but enumerating the vertices is computationally expensive.Here, we propose a simple, less expensive solution based on the slack-maximizing LP formulation underlying the inferential approach for handling imprecise preference information. If the inequality constraints are given (in sampling space) byAx⩽b, the following LP results in an interior point that maximizes the minimum slack on each constraint defining the polytope:maximizeδsubjecttoAx+e=b∀iδ⩽ei.A randomized interior point can then be generated by randomly rescaling the slack on each constraint:maximizeδsubjecttoAx+e=b∀iδ⩽ciei,where the scaling factorsci∈(0,1]can be drawn from independent uniform distributions. Before solving this program, we eliminate redundant constraints fromAx⩽bto prevent these constraints from biasing the starting point towards a specific region of the polytope. However, even with this precaution, the distribution obtained from this procedure is far from uniform, meaning that it should not be used in place of HAR for the actual weight sampling.

@&#CONCLUSIONS@&#
