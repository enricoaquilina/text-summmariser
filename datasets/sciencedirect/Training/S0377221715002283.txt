@&#MAIN-TITLE@&#
Mathematical programming approaches for classes of random network problems

@&#HIGHLIGHTS@&#
Novel conditionally uniform random networks models based on MILP.Total unimodularity of some network problems with side constraints.Probability density function of LP solutions in terms of the cost vector.Two LP-based procedures for the generation of random networks.Computational results for real-world datasets.

@&#KEYPHRASES@&#
Interior-point methods,Integer programming,Complex networks,Total unimodularity,Central path,

@&#ABSTRACT@&#
Random simulations from complicated combinatorial sets are often needed in many classes of stochastic problems. This is particularly true in the analysis of complex networks, where researchers are usually interested in assessing whether an observed network feature is expected to be found within families of networks under some hypothesis (named conditional random networks, i.e., networks satisfying some linear constraints). This work presents procedures to generate networks with specified structural properties which rely on the solution of classes of integer optimization problems. We show that, for many of them, the constraints matrices are totally unimodular, allowing the efficient generation of conditional random networks by specialized interior-point methods. The computational results suggest that the proposed methods can represent a general framework for the efficient generation of random networks even beyond the models analyzed in this paper. This work also opens the possibility for other applications of mathematical programming in the analysis of complex networks.

@&#INTRODUCTION@&#
The use of random simulation is quite common when statistically studying properties of highly combinatorial sets. In many of those cases, closed-form expressions are hard to be found and the availability of efficient and correct simulation procedures might be of remarkable importance.This is particularly true in the analysis of complex networks, an interdisciplinary field which brings together tools and methods from discrete mathematics and computer science with a great concern toward empirical applications, among others, in business, marketing, epidemiology, engineering, etc. Researchers are often interested in assessing the hypothesis of whether a particular network property is likely to appear under a uniform distribution of all networks verifying given constraints, named conditional random networks (Bollobas, 1985). In the absence of closed-form expressions (as it is often the case for most of random network models), large random samples of networks satisfying particular properties are required to test these hypotheses. This work introduces novel procedures to generate this sample, based on linear and integer optimization. They result in a general approach for random network simulation, which outperforms in versatility some currently available methods.Following the standard notation (Ahuja, Magnanti, & Orlin, 1991), a graph G = (V, E) is defined by a finite set V of n nodes, and a set of m pairs of them E⊆V × V, named edges or arcs. A graph can be represented by a n × n binary matrix X, called adjacency matrix (AM from now on), whose (i, j)-entry, xij, is equal to 1 if there is a link between nodes i and j, and 0 otherwise. We will assume the graph has no loops, so that the diagonal of X is null. A network is a graph whose arcs or nodes have associated numerical values (arc costs, arc capacities, node supplies, etc.). In this work we will make no distinction and the two terms “graph” and “network” will be used as synonyms.The study of random graphs begins with the seminal work of Erdös and Rainyi (1959), who considered a fixed set of nodes and an independent and equal probability of observing edges among them. There are two closely related variants of the Erdös–Rainyi model:•the G(n, p) model, where a network is constructed by connecting nodes randomly with independent probability p;the G(n, m) model, where a network is chosen uniformly at random from the collection of all graphs with n nodes and m edges.Both models possess the considerable advantage of being exactly solvable for many of their average properties: clustering coefficient, average path length, giant component, etc. (For more details about network properties, see Bollobas (1985), and Wasserman and Faust (1994).) In other words, the expectation of many structural properties of networks generated by the Erdös–Rainyi processes is analytically obtainable. Conditional uniform models can be seen as a generalization of the G(n, m) model, when the conditioning information is not necessarily the number of edges but whatever other arbitrary network property. Unfortunately, in this case we have very few analytical results and simulation is required to obtain empirical distributions of their average properties.Although other Operations Research tools have been used in the context of social networks (Berghammer, Rusinowska, & de Swart, 2010; Gómez, Figueira, & Eusébio, 2013), as far as we know, this work is the first attempt to use linear and integer optimization for the generation of several classes of conditional random graphs. Previous approaches, developed within the fields of mathematical and computational sociology, were ad hoc procedures for some particular types of networks, in general difficult to generalize and not very efficient. For instance, the distribution of all networks conditioned to the nodes in- and out-degree has difficult combinatorial properties, as its analytical study involves binary matrices with fixed marginal rows and columns. In this respect, some combinatorial results have been obtained by Ryser (1957), who derived necessary and sufficient conditions for two vectors of non-negative integers to constitute the row sums and column sums of some zero-one matrix. On the other hand, ways to generate uniform random networks with given degree distribution were developed in Snijders (1991), Rao, Jana, and Bandyopadhyay (1996), Charon, Germa, and Hudry (1996), Roberts (2000) and Verhelst (2008), although they were computationally expensive and prohibitive for very large AMs.In practice one would like to go even further in conditioning, which however leads to self-defeating attempts because of combinatorial complexity. This work provides a general methodological framework to generate networks with constraints, representing structural features we wish to control for.Let xijbe entries of the AM of either a directed or undirected graph with no loops or multiples edges. The AM is an element of the set of binary matrices(1)χ={xij∈{0,1},(i,j)∈H},whereH={(i,j):1≤i≤n−1,i<j≤n}forundirectedgraphsorH={(i,j):1≤i≤n,1≤j≤n,i≠j}fordirectedgraphs.The continuous relaxation of χ, name it CR(χ), is obtained by replacing xij∈ {0, 1} by xij∈ [0, 1], in (1). Clearly, all extreme points of CR(χ) are integer. If we consider a conditional graph by adding extra linear constraints to χ, then CR(χ) may contain fractional extreme points, unless its constraints matrix is totally unimodular (TU, from now on). As shown in Heller and Tompkins (1956), the next theorem provides sufficient conditions for a matrix to be TU:Theorem 1Let A ∈ { − 1, 0, 1}m × nbe a matrix obtained by elementary operations of B ∈ Zm × nand consider a partition of the rows of A in two disjoint setsJ1andJ2. The following three conditions together are sufficient forB to be TU:1.Every column of A contains at most two non-zero entries, which are either 1 or − 1.If two non-zero entries in a column of A have the same sign, then the row of one is inJ1,and the other inJ2.If two non-zero entries in a column of A have opposite signs, then the rows of both are either inJ1orJ2.The above theorem will be extensively used in next section. More details on unimodularity in integer programming can be found in Schrijver (1998). If the constraints matrix of CR(χ) is TU, each extreme point of CR(χ) represents a graph. Therefore, it is possible to generate a bunch of graphs by merely solving linear programs (LP) with random gradients in the objective function, or by non-degenerated simplex pivoting, starting from a given initial extreme point (Padberg, 1999). Moreover, they can be generated in polynomial time if interior-point methods are used (Wright, 1996).The paper is organized as follows. Section 2 is devoted to the characterization of the convex hull of polytopes associated to some families of conditional random networks. We will differentiate between families whose constraints are TU, and those which may give rise to fractional AMs. Supported by these results, Section 3 presents two particular procedures for the generation of conditional random networks, and analyzes the probability distribution of the LP solutions. Section 4 illustrates these techniques using some real-world data sets.Throughout the paper we denote the vector of variables associated to the components of the AM as either xT= [x12, …, x1n, x23, …, x(n − 1)n, x21, …, xn(n − 1)] (i.e., the rowwise upper triangle of AM followed by its columnwise lower triangle) for directed graphs, or xT= [x12, …, x1n, x23, …, x(n − 1)n] (only the rowwise upper triangle of AM) for undirected graphs.Let χ be the set of AMs of a family of either directed or undirected networks with n nodes, and let CR(χ) be its continuous relaxation. For about twenty families of networks the extreme points of CR(χ) can be seen to be integer. Although making an extensive list of all these families is out of the scope of this work, some of the most relevant ones will be discussed in the following sections.Next Proposition 1, which provides a sufficient condition for the existence of a bijection between extreme points of CR(χ) and the set of feasible networks, will be useful to show that some constraints matrices are TU.Proposition 1For a given family of either directed or undirected networks with n nodes, letF∈Rl×m,be a matrix of l ≤ m linear constraints characterizing the family of networks under consideration, where m = n(n − 1)or m = n(n − 1)/2 for, respectively, directed and undirected networks. Let CR(χ) = {x ∈ [0, 1]m: Fx = b}be the continuous relaxation of the constraints. Ifbis integer and F can be reduced by elementary row operations to a matrix, call itF′, with a unique unitary element (either + 1 or − 1) per column and all the elements of the same row with the same sign, then there is a bijection between the extreme points of CR(χ) and the set of networks under consideration.In standard form, the system of linear constraints associated to CR(χ) is(2)[IIF′][xs]=[eb],[xs]≥0.From Theorem 1, the constraints matrix of (2) is TU by considering the following partition of rows: set the first m rows (associated to the identities) inJ1; if elements of row i of F′ are negative, then set this row inJ1; otherwise, if they are positive, set the row inJ2. Therefore, all extreme points of CR(χ) are integer and they correspond to the AM of a network. In addition, no integer point may be located in the interior of CR(χ) since it is a subset of the unit hypercube, completing the proof.□In some cases there is no bijective relation between a family of conditional random networks and the extreme points of its polyhedron, since some basic solutions may be fractional. However, if we can ensure that no integer solution is in the interior of the polyhedron, this injective relation (i.e., any random network is associated to an extreme point, but not the opposite) is still useful, whenever some kind of acceptance–rejection technique is considered for fractional solutions. This is the case, for instance, of networks conditioned to the within group densities and in-and-out-degrees, which will be considered in Section 4.3.One of the simplest cases is that of networks conditioned to the density d. The following result is immediate by noting that the system of linear constraints characterizing CR(χ) verifies the hypotheses of Proposition 1:Proposition 2Let CR(χ) = {x ∈ [0, 1]m: ∑(i, j) ∈ Hxij= d}, where H defined in (1) either relates to a directed or undirected graph. Then there is a bijection between the extreme points of CR(χ) and the set of graphs with n nodes and density d.In some situations, nodes might be partitioned into g different groups, γ1, …, γgand our interest might be to keep the within-group densities fixed when simulating random networks. Let Γ be the set of such groups and consider a function, θ: V × V → Γ × Γ, associating to each pair of nodes the pair of groups they belong to. The density constraint between group γkand γh, 1 ≤ k ≤ g, k ≤ h ≤ g, is∑(i,j)∈H:θ(i,j)=(γk,γh)xij=dkh,where dkhis a non-negative integer. Note that when k = h we have a within group density constraint, otherwise a between group density constraint. Since the linear constraints characterizing these networks verify the hypotheses of Proposition 1, the following proposition holds:Proposition 3LetCR(χ)={x∈[0,1]m:∑(i,j)∈H:θ(i,j)=(γk,γh)xij=dkh,1≤k≤g,k≤h≤g}. Then there is a bijection between the extreme points of CR(χ) and the set of graphs with n nodes and within and between group densities dkh.Another widely studied family of networks is that of undirected networks with fixed degree sequence (Newman, 2002; Newman & Park, 2003; Newman, Strogatz, & Watts, 2001), whose associated set of AMs is χ = {x ∈ {0, 1}m:∑j=1i−1xji+∑j=i+1nxij=fi,i=1…n},where fiis the degree of node i. Denoting these linear constraints as Fx = f, we see that each column of F has two + 1, thus it does not verify the hypothesis of Proposition 1, and the constraints matrix is not TU.However, if we only add the constraints associated to the degrees of two particular nodes—with optionally the constraint associated to the number of edges (density)—the resulting matrix is TU by Proposition 1. The information we are conditioning in this case can be seen as a lower bound of the distance between the maximum and minimum degrees. Next proposition summarizes this result.Proposition 4Let i1, i2 ∈ V be two nodes with degreesfi1andfi2,f˜i1andf˜i2their degrees without considering the arcs (i1, i2) and (i2, i1), and d the total number of edges in the network. LetJ(k,h)={j:1≤j≤n,j≠k,j≠h}and CR(χ) = {x ∈ [0, 1]m:∑(i,j)∈Hxij=d;∑j∈J(i1,i2)xij=f˜i,i=i1,i2}. Then, there is a bijection between the extreme points of CR(χ) and the set of graphs with n nodes, d edges and degree range greater than or equal to|fi1−fi2|. This same result holds if the density constraint ∑(i, j) ∈ Hxij= d is removed from CR(χ).The researcher might sometimes be interested in studying networks whose edges are associated to a categorical value (color), generally known under the name of edge-colored networks. The study of edge-colored graphs (i.e., graphs with different types of edges) has given rise to important developments during the last few decades. From the point of view of applicability, problems arising in molecular biology are often modeled using edge-colored graphs (Pevzner, 1995), and the problem of interpersonal ties in social networks might be also modeled considering different types of arcs (Granovetter, 1985).LetCbe a given set of colors,|C|≥2. Formally, an edge-colored graph is a tupleGC=(V,E,τ),where V and E are the sets of nodes and edges, respectively, andτ:E⟶Ca function assigning a color to each edge. They are, in some sense, related to multicommodity networks. Edge-colored graphs can be modeled as(3)∑c=1|C|xijc≤1(i,j)∈Hxijc,xjic∈{0,1}(i,j)∈H,c=1,…,|C|wherexijcis 1 if an arc with color c from node i to node j exists, and 0 otherwise, and H was defined in (1). The first set of constraints of (3)—multicommodity or generalized upper bounding constraints—complicate the structure of the constraints matrix for some structural properties, such as the total number of edges, the number of edges per color, and the lower bound of the degree range.In the case of edge-colored networks conditioned to having dcedges per color c, the constraints∑(i,j)∈H2xijc=dc,c=1,…,|C|should be included.Proposition 5By adding within-color densities constrains the coefficient matrix associated to system (3) becomes(4)[IIII⋱⋱IIFF⋱FGG…GI][x1x2⋮x|C|s1s2⋮s|C|]=[ee⋮ede].whered∈Z|C|is the vector of within-color densities, F = eTand G = I. As matrix F′ = [eI]Tverifies the conditions ofProposition 1, the coefficient matrix of (4) is TU.Note that the slack of the inequality of∑c=1|C|xijc≤1is obtained in (4) by defining an auxiliary color with no specified within-color density, caand an extended set of colorsC*=C⋃{ca}.The two models of networks described in Propositions 3 and 5 can be combined to obtain another family of network which is also characterized by a TU system. Consider an edge-colored network where nodes are partitioned into g different groups: γ1, …, γg. Since the connections within members of the same group might have different colors, our interest is to keep the within-color and between-group (or within-group) densities fixed when simulating random networks. The number of c-color edges between group γkand γh, is∑(i,j)∈H2:θ(i,j)=(γk,γh)xijc=dkhc,wheredkhcis a non-negative integer, forc∈C,1 ≤ k ≤ g, k ≤ h ≤ g. Note that when k = h we have a within group density constraint, otherwise a between group density constraint. This system of linear constraints verifies the hypotheses of Proposition 1.Proposition 6Consider the edge-colored undirected graph conditioned to the within-color and within-group densities. Let CR(χ) be the subset of the m-dimensional unitary cube (that isx ∈ [0, 1]m), verifying the following system(5)∑c∈Cxijc≤1(i,j)∈H2∑θ(i,j)=(γk,γk)xijc=dkcc∈C,1≤k≤g∑(i,j)∈H2xijc=dcc∈Cxijc,xjic∈{0,1}(i,j)∈H2,c∈Cwhose corresponding extended matrix form is equal to (4), except for the fact thatd∈Z|C|(g+1)is now the vector of within-color and within-group densities and F ∈ {0, 1}g + 1 × mis a matrix which can be reduced by elementary row operations to contain a unique unitary element of the same sign per column. As F′ = [FI]Tverifies the conditions ofProposition 1the described system is TU.Another case in which (4) is TU is obtained when the linking constraints are associated to the within-color degree of two nodes and within-color densities, as the family of network described in Proposition 4, so that F ∈ {0, 1}3 × n(n − 1)/2.The described families of edge-colored networks are ways of modeling non-binary connections between nodes, i.e. edges associated to multidimensional properties (colors). The main concern with this class of models is the size of his mathematical programming representation (number of decision variables and constraints) when the number of colors grow large. A possible way of dimensionality reduction is to aggregate the information of edge colors in the corresponding real-valued edge.Formally, a real-valued graph is a tuple Gν= (V, E, ν), where V and E are the sets of nodes and edges, respectively, andν:E⟶[0,1]⊂Ra function assigning a real-value to each edge. By doing so the researcher is assuming a probabilistic model where any symmetric matrix in [0, 1]n × nverifying a specified system of linear constraints Ax = b has a non-null probability density of being observed. Note that a full characterization of these classes of networks does not require matrix A to be TU any more, as fractional solutions still belong to the specified families.Classes of real-valued networks can be defined by relaxing the integrality condition of all families of networks presented in Sections 2.1 and 2.2. In particular relaxing the integrality conditions allows for a wider modeling possibility of families of networks by systems of linear constraints with arbitrary coefficient matrix A.A simple example related to the previously defined model is the class of real-valued networks with fixed between-group valued-densities and valued-degrees:CR(χ)={x∈[0,1]m:∑j∈Vxij=fi;∑(i,j)∈H:θ(i,j)=(γk,γh)xij=dkh,1≤k≤g,k≤h≤g},where dkhis the density between group γkand γh, 1 ≤ k ≤ g, k ≤ h ≤ g, as described in Proposition 3, and fiis the valued-degree of node i ∈ V, as described in Proposition 4.The previous section provided an algebraic characterization of several families of networks by linear constraints. From a constructive point of view, this section proposes LP-based polynomial-time methods to generate instances of networks with given structural properties. Broadly speaking, the goal is to obtain random networks as the solution of a LP by randomly changing the cost vector. To validate these LP-based procedures, first we will derive the probability density function of the primal–dual LP solutions when the cost vector randomly changes. Although this probability density may not be uniform, we will see it can be used to obtain solutions of uniform distribution by considering the acceptance–rejection Metropolis–Hastings method (Robert & Casella, 2004), widely used in Statistics.LetCR(χ)={x∈[0,1]n′:Ax=b}be a polytope whose set of extreme points is bijectively related to a given family of networks and consider the associated (feasible and bounded) LP(6)mincTxs.toAx=b,0≤x≤1,whereA∈Rm′×n′is a full row rank matrix,b∈Rm′andc∈Rn′. By adding slacks, (6) can be written in standard form as(7)minc^Tx^s.toA^x^=b^,x^≥0,whereA^∈Rm^×n^(m^=m′+n′andn^=2n′) is a full row rank matrix,b^=[bTeT]T∈Rm^andc^=[cT0T]T∈Rn^. If the gradient of the objective functionc^is a properly defined random vector of density functionfC(c^),then the solution of (7) is also a random vector whose probability distribution can be computed as(8)P(x^)=∫G−1(c^)=x^fC(c^)dc^,whereG(x^)is the set of gradients for whichx^is an optimal solution andG−1(c^)is the set of optimal solutions of (7) for a fixed objective gradientc^. Defined this way, G would be a set-to-set mapping. We thus consider an alternative definition, as shown by next Lemma, which guarantees a point-to-point function:Lemma 1Dimensionality augmentationConsider the augmented sample space obtained by introducing the auxiliary random vectorsy^andz^and the joint probability function(9)P(x^,y^,z^)=∫G−1(c^,0,0)=(x^,y^,z^)fC(c^)dc^,whereG(x^,y^,z^)is defined though the KKT optimality conditions as(10)G(x^,y^,z^)≜[A^Ty^+z^A^x^−b^X^Z^e]and(x^,z^)≥0,y^andz^being respectively the Lagrangian multipliers of the equations and bounds of (7), andX^andZ^diagonal matrices made up with the components ofx^andz^.We claim that G is a one-to-one continuously differentiable function fromID0={(x^,y^,z^)∈R2n′+m′:x^>0,z^>0,A^x^=b^,A^Ty^+z^=c^,X^Z^e=0e}toIC0=Rn′×{0}m′+n′.To proof that G is a one-to-one function we only need to note that the Lagrangian multipliers associated to an optimal solution of an LP are unique, as long asA^is full rank (see Wright, 1996). The continuous differentiability of G inI0results from its Jacobian(11)J(G(x^,y^,z^))=[A^TIA^Z^X^].□LetG:ID⟶ICbe a one-to-one and continuously differentiable map of the open setIDintoIC,such that J(G(t)) is nonsingular for allt∈ID. Iff:IC⟶Ris a non-negative locally integrable function, then(12)∫IDf(G(t))|detJ(G(t))|dt=∫ICf(s)ds,where the symbol|detJ(G(t))|is used to denote the absolute value of the determinant of the Jacobian of G at pointt∈ID. By the inverse-function theorem,ICis open and the inverse point mapping G−1(s) is continuously differentiable.The applicability of Theorem 2 to solve the integral in (9) is conditioned to the nonsingularity ofJ(G(x^,y^,z^)),which cannot be claimed in the general case. (See Section 3.2 for special conditions of nonsingularity.)However, it can be possible to guarantee the nonsingularity ofJ(G(x^,y^,z^))into a redefined domainIDμ={t=(x^,y^,z^):x^>0,z^>0,A^x^=b^,A^Ty^+z^=c^,X^Z^e=μe}for someμ∈R,μ > 0, which is defined based on the KKT-μ perturbed conditions(13)G(x^,y^,z^)=[c^0μe].The codomain of G is thusICμ={s=(c^,0,μe):μ∈R,μ>0,c^∈Rn^}. For a fixedc^,the set of solutions(x^(μ),y^(μ),z^(μ))of (13) for μ > 0 is an arc of feasible points known as the primal–dual central path (Wright, 1996; Ye, 1997), which is widely used in interior-point methods. When μ → 0, the central path converges to an optimal solution of (7). If instead of a unique solution we have an optimal face, then the central path converges to the single analytic center of this optimal face (Ye, 1997). If the primal–dual strictly feasible set of (7) is nonempty (i.e.,F0={(x^,y^,z^):x^>0,z^>0,A^x^=b^,A^Ty^+z^=c^}≠∅), then the central path exists and it is unique for each μ > 0 (see Wright, 1996; Ye, 1997 for a proof of this result). This uniqueness guarantees that, givens=(c^,0,μe),there is a single pointt=(x^(μ),y^(μ),z^(μ))satisfying (13). The adopted notation makes explicit the dependence of the primal–dual points with respect to the complementarity parameter μ.Lemma 2Nonsingularity of the JacobianThe JacobianJ(G(x^(μ),y^(μ),z^(μ)))—which is the matrix of the Newton system to be solved at each iteration of primal–dual interior-point methods—is nonsingular ifA^is full row rank and(x^(μ),z^(μ))>0.A simpler expression for the determinant can be derived if we are in an interior point, i.e., if μ > 0, thusx^(μ)>0andz^(μ)>0. Denoting by J the Jacobian, and adding to the first block-row of J the last block-row multiplied by the diagonal matrixX^−1(μ)we havedet(J)=det(J1)∏i=1nx^i(μ)whereJ1=[−X^−1(μ)Z^(μ)A^TA^].Since J1 = CDCT, whereC=[I−A^X^(μ)Z^−1(μ)I]andD=[−X^−1Z^A^X^(μ)Z^−1(μ)A^T],using thatdet(C)=1we finally obtain(14)det(J)=det(D)∏i=1nx^i(μ)=(−1)ndet(A^X^(μ)Z^−1(μ)A^T)∏i=1nz^i(μ).A^X^(μ)Z^−1(μ)A^Tis the symmetric and positive definite matrix—ifA^has full row rank—of the normal equations system of interior-point methods and(x^(μ),z^(μ))>0(Wright, 1996).□The applicability of Theorem 2 whenG:IDμ→ICμallows computing the probability density function of t = G−1(s) from that of the random variable s. According to this result:(15)fIDμ(t)=fIC(s)|det(J(G(t)))|=fICμ(s)|det[A^TIA^Z^(μ)X^(μ)]|,wherefIDμandfICμdenote the probability density functions (PDF, from now on) of t and s, respectively.The discussion of Section 3 started by considering a polytopeCR(χ)={x∈[0,1]n′:Ax=b},whose set of extreme points is bijectively related to a given family of networks, and the associated LP in standard form (7). Let Int(CR(χ)) be the interior of CR(χ). The closed-form expression (15), associated to the augmented sample space of primal–dual solutions, suggests a proper definition of a PDF of Int(CR(χ)) (primal strictly feasible solution of (7)), based on the KKT-μ perturbed conditions.Let fCand fμbe the absolutely continuous PDFs (i.e., sets of zero Lebesgue measure have zero probability) of the cost vectorc^and complementarity parameter μ . We assumefICμto have the following form:(16)fICμ(s=[s1s2s3])={fC(s1)fμ(s3)ifs∈ICμ0otherwise.Therefore, under the transformation G we finally have, fort=(x^,y^,z^)∈IDμ:(17)fIDμ(x^(μ),y^(μ),z^(μ))=fC(c^)fμ(μ)|det[A^TIA^Z^(μ)X^(μ)]|.Note that the support offIDμisIDμ,so that it only provides the probability density of central path points for some particular μ.Theorem 3If fC and fμ have non-null probability density overRn′andRrespectively, then everyx^∈Int(CR(χ))has a non-null probability density.LetCμ(c^)={x^(μ)|∃y^(μ),z^(μ)>0,G(x^(μ),y^(μ),z^(μ))=(c^,0,μe),μ>0}be the primal central path of (7), for a fixed gradientc^∈Rn′,and define(18)C∪=⋃c^∈Rn′Cμ(c^).and(19)fIDμ(x^(μ))=∫φfIDμ(x^(μ),y^(μ),z^(μ))dy^dz^whereφ={(y^,z^)|A^Ty^+z^=c^,X^z^=μe}. If fCand fμhave non-null probability overRn′andR,thenC∪is the support of (17), so that a sufficient condition for Theorem 3 to hold is thatInt(CR(χ))⊆C∪—as the opposite inclusion it trivially true.Hence, the proof consists in showing that for anyx^∈Int(CR(χ)),there existsc^∈Rn′and μ > 0, such thatG(x^,y^,z^)=(c^,0,μe),for some Lagrangian multipliersy^andz^>0. Due to the μ-complementarity (X^z^=μe), the required sufficient condition is the existence ofc^∈Rn′and μ > 0, such that for anyx^verifyingA^x^=b^,x^>0,the systemA^Ty^+μX^−1e=c^has a solution for somey^∈Rm′. And the statement immediately follows (for instance, settingy^=0andc^=μX^−1e>0).□The ability to randomly generate primal strictly feasible points and the availability of a closed-form expression of their PDF (17) allow for a straightforward extension of the proposed methodology to simulate from families of real-valued networks with linear constraints. In fact, as it will be shown in Section 3.4, the applicability of well known statistical simulation methodologies (such as the Metropolis–Hastings algorithm) to generate strictly feasible points from arbitrary distribution is guaranteed by (17).The use of the central path in Sections 3.1 and 3.2 resulted in a general methodology to provide arbitrarily close approximations of the extreme points and to extend the range of applicability of the described random graph simulation procedure to the case of real-valued networks.In particular, as far as families of binary networks (characterized by the set of extreme points of algebraically defined polytopes) are concerned, the use of the central-path in the redefined sample spaceIDμin Section 3.1 allowed bypassing the problem of the nonsingularity of theJ(G(x^,y^,z^))for a correct applicability of Theorem 2, by considering arbitrarily close μ-approximations of the extreme points. (It must be noted that in practice numerical solvers require such kind of numerical approximations of the optimal solution, which are governed by some optimality tolerances.)In this section the convergence offIDμ(x^(μ),y^(μ),z^(μ))tofIDμ(x^(0),y^(0),z^(0))is assessed, based on the continuity of the central path in μ = 0, and the nullity of the set of critical values ofG(x^(0),y^(0),z^(0)). For the latter we will need Sard’s Lemma, which is provided below.Lemma 3Sard’s LemmaLetG:S⊆Rq⟶T⊆Rpbe a one-to-one and continuously differentiable map of the open setSintoT. LetLqdenote theq-dimensional Lebesgue-measure and Ξ the set of critical values ofG. Then Ξ hasLq-measure zero.See Abraham and Robbin (1967, Paragraph 15) and Sternberg (1964, Theorem II.3.1).□As just mentioned in Section 3.1, the support offIDμisIDμ,so that it only provides the probability of central path points for some particular μ. As μ → 0 the central path points converge to the solution of (7), and then (15) converges to the probability distribution of the primal–dual solutions of the LP problem in terms of the probability distribution of the cost vector, as shown by the next theorem:Theorem 4The probability density function of the μ-parameterized primal–dual solutions converge to the one of the optimal primal–dual solutions, that is,(20)limμ→0fIDμ(x^(μ),y^(μ),z^(μ))=fID0(x^(0),y^(0),z^(0)).as long as fμ(μ) > 0, for all μ ≥ 0 (mild condition).ProofThe first part of the proof consists in showing that the limit exists. After taking for granted the existence of the limit, we show that this limit is the desired PDF.-Existence of the limitBy Ye (1997, Theorem 2.17), the points(x^(μ),y^(μ),z^(μ))on the central path are bounded, the central path converges to(x^(0),y^(0),z^(0)),andx^(0)andz^(0)are, respectively, the analytic centers of the primal and dual optimal faces (i.e., for anyc^the central path converges to a unique point—the analytic center of the optimal face—even if there are multiple solutions for thisc^). Therefore, (15) exists inID0,as the determinant of (15) computed atZ^(0)andX^(0)is bounded, andlimμ→0fIDμ(x^(μ),y^(μ),z^(μ))exists by continuity of the determinant.Convergence in distributionLetΨμ=IDμ∖Ξ,i.e. the subset ofIDμobtained by removing the set of critical points Ξ ofG(x^(μ),y^(μ),z^(μ)). For μ > 0, Lemma 2 ensures that Ξ = ∅. For μ = 0, by Sard’s Lemma, Ξ hasLq-measure zero, since G is a bijection fromID0toIC0. This fact allows the applicability of Theorem 2 in Ψμ. Thus, as long as fμ(μ) > 0, for all μ ≥ 0, we claim that for any (Lebesgue-integrable) real-valued functiong:IDμ⟶R,the following equality must be true:(21)Eμ[g(t)]=∫Ψμg(t)fIDμ(t)dt=∫IDμg(t)fIDμ(t)dtand limμ → 0Eμ[g(t)] = E0[g(t)].□The above results are illustrated by this small example.Example 1Consider the small two-dimensional problem min c1x1 + c2x2 s. to x1 + Mx2 = 1, (x1, x2) ≥ 0 (M > 0 being a given parameter), which matches (7) forA^=[1M]andb^=1. The feasible region of this problem is the segment between VA= (1, 0) and VB= (0, 1/M). When c2 > Mc1, VAis the optimal extreme point; when c2 < Mc1, the solution is VB; when c2 = Mc1 (which is unlikely if the cost vector is randomly generated) the whole segment is optimal. Unless M = 1, the probability of VAand VBbeing optimal is not uniform, even if the cost vector is randomly generated (in particular we have P(VA) = 1 − M/2 and P(VB) = M/2).The associated KKT-μ perturbed conditions are(22)x1+Mx2=1y+z1=c1My+z2=c2x1z1=μx2z2=μ(x1,x2,z1,z2)>0and, after a few manipulations from the dual feasibility and complementarity conditions, we obtain:(23)Mc1+Mμ1−x1=c2+Mμx1andMc1+μx2=c2+Mμ1−Mx2.Whenc2≠Mc1,the central path is obtained by solving the two quadratic equations (23) with respect to x1(μ) and x2(μ):(24)x1(μ)=c2−Mc1−2Mμ+Δ2(c2−Mc1),x2(μ)=c2−Mc1+2Mμ−Δ2M(c2−Mc1),Δ=4M2μ2+(c2−Mc1)2,z1(μ)=μx1(μ),z2(μ)=μx2(μ),y(μ)=c1−z1(μ).When c2 = Mc1, we directly have(25)x1(μ)=12,x2(μ)=12M,z1(μ)=2μ,z1(μ)=2Mμ,y(μ)=c1−2μ.Forc2≠Mc1,the limit point of the central path can be obtained either by direct substitution (as for x1(μ), x2(μ)) or by applying L’Hôpital’s rule (as for z1(μ), z2(μ)):limμ→0x1(μ)=1limμ→0x1(μ)=0limμ→0x2(μ)=0limμ→0x2(μ)=1Mlimμ→0z1(μ)=0forc2>Mc1,andlimμ→0z1(μ)=Mc1−c2Mforc2<Mc1.limμ→0z2(μ)=c2−Mc1limμ→0z2(μ)=0limμ→0y(μ)=c1limμ→0y(μ)=c2MForc2≠Mc1,the primal solution (x1(μ), x2(μ)) does not depend on μ and it provides the analytic center of the feasible primal segment, as expected. The dual limit point is z1(0) = z2(0) = 0, y(0) = c1.By (17), the asymptotic value of the density function of primal–dual solutions is(26)fIDμ(x1(μ),x2(μ),y(μ),z1(μ),z2(μ))=fIC(c1,c2)|det(J)|,where in this simple problemdet(J)=M2x2(μ)z1(μ)+x1(μ)z2(μ). Therefore, when μ → 0 we have that(27)det(J(x1(0),x2(0),z1(0),z2(0))={(c2−Mc1)ifc2>Mc1(Mc1−c2)ifc2<Mc10ifc2=Mc1.First, we note by (27) that the set of points with 0 determinant (i.e., the critical values{(c1,c2)∈R2:c2=Mc1}) has 0 measure inR2,as expected by Sard’s Lemma 3. The density of those points is 0, according to our development. We also see from (26) and (27) that the probability density of the primal solutions VAand VBincrease, respectively, with c2 − Mc1 and c1 − Mc2, which is consistent with the solution of the primal problem.It is worth to make some observations to (17) and Theorem 4:•From (17), the probability density function of the primal–dual solutions depends on the randomness ofc^and μ, but also on the feasible polyhedron defined by the constraints matrixA^,which appears in the determinant of the Jacobian of G. This is coherent with the intuition.Given a primal–dual central path point(x^(μ),y^(μ),z^(μ))for some cost vectorc^,Eq. (17), which is easily computed, provides the probability densityfIDμof this primal–dual point. However, the probability distribution of the primal points is obtained as the marginal distribution with respect of the Lagrangian multipliers, as in (19). Although (19) is a difficult integral, the expression of the density (17) is enough to compute primal–dual solutions with any desired distribution (as seen in below Section 3.4).A closed form expression for (17) cannot be computed, in general, because of the determinant of the Jacobian of G, which involves the constraints matrixA^and the values of(x^(μ),z^(μ))in the central path (which do not admit a closed form expression, but for toy problems).Consistently with Sard’s Lemma, Example 1 shows that the set of objective gradients such that the optimal solution to the corresponding LP is not a unique vertex has measure zero. As a corollary of Theorem 4, eliminating such a set of points from the support of fCdoes not affect the moments of the primal–dual distribution.Due to the availability of a computable probability density function (17), we can guarantee the uniform distribution (indeed, any distribution) of the primal–dual solutions, by a proper application of Markov chain Monte Carlo methods. One of these approaches is the Metropolis–Hastings algorithm, which is a well-known method to sample from probability distributions for which direct sampling is not possible, though a well defined probability density function is available. A detailed derivation of this algorithm, which is out of the scope of this work, can be found in Robert and Casella (2004). We just outline the main steps of this procedure.When applied to our problem, this method consists in generating a stochastic sequence of primal–dual solutions, from an arbitrary starting pointt0(μ)=(x^0(μ),y^0(μ),z^0(μ)),and the following rule to go from a current statetk(μ)=(x^k(μ),y^k(μ),z^k(μ))to a new statetk+1(μ)=(x^k+1(μ),y^k+1(μ),z^k+1(μ)):1.Initialization: Choose an arbitrary point t0(μ) to be the first sample and let (17) be the proposal probability distribution, which suggests a candidate for the next sample value tk + 1(μ), given the previous sample value tk(μ). (In the case the vectorsc^is independently generated, that isfIC(c^|tk(μ))=fIC(c^),the probability (17) of the candidate point is independent from the previous point.)Candidate state: Propose a candidate point tk + 1(μ) from a proposal distribution (17) that may depend on the current state tk(μ). (In our case the proposal entails the solution of a LP, as the candidate primal–dual solution is obtained by solving the KKT-μ perturbed conditions with a fixed and very close to 0 value of μ and a random value ofc^.)Acceptance criterion: Accept the candidate state with probability(28)α(tk(μ),tk+1(μ))=min(1,fIDμ(tk(μ))fIDμ(tk+1(μ))).The underlying state-space of this Markov chain is the set of primal–dual solutions, associated to a fixed value μ, which are obtained by solving the KKT-μ perturbed conditions.The correctness of the Metropolis–Hastings algorithm to simulate from the target distribution (i.e. to generate uniform primal–dual solutions) occurs under mild regularity conditions: irreducibility and aperiodicity. Broadly speaking, irreducibility means that the proposal distribution should allow to move fromt(μ)tot′(μ)in a finite number of iterations with nonzero probability. Aperiodicity occurs when the number of steps needed to move fromt(μ)tot′(μ)is not required to be a multiple of some integer greater than one. Consider the transition distribution of the defined Metropolis–Hastings chain(29)Q(t′(μ),t(μ))=fIDμ(t′(μ))min(1,fIDμ(t(μ))fIDμ(t′(μ))).•Based on (29), the described properties of the proposal distribution (17) ensure that every state can be generated in one step with non-null probability (due to the positivity of the determinant in Ψμ).Since under mild conditions (29) is non-null in Ψμ, the chain is able to consecutively generate the same primal–dual solutions, so that all the states communicate with each other and the aperiodicity is guaranteed.Thus, the above procedure provides primal–dual feasible points(x^(μ),y^(μ),z^(μ))with uniform distribution. It establishes a probabilistic framework to sample random graphs belonging to specified families (both binary and real-valued). In fact, the uniform distribution of(x^(μ),y^(μ),z^(μ))implies that the distribution ofx^(μ)(the primal solution associated to a random graph) is also uniformly distributed, as requested.An efficient implementation of this method is provided in the next section, where the LPs are solved in each step for a few randomly chosen variables, allowing a consistent reduction of the computational time, while keeping the described probabilistic properties. Such method, which we call sequential r-blocks algorithm, will be numerically analyzed in Section 4 and compared with a simplex-based approach (described in Section 3.6), which we call sequential s-pivots algorithm. The analyzed probabilistic properties do not hold for the sequential s-pivots algorithm, so that no guarantee of uniformity of the generated sample is available when network are generated by random pivots.Let χ be one of the families of networks associated to extreme points of polytopes of the formCR(χ)={x∈[0,1]n′:Ax=b},A∈Rm′×n′. As we noted in Section 3.1, given ac∈Rn′,we can compute a network by solving minycTy, s.to y ∈ CR(χ). Similarly, if we have a given extreme point xkof CR(χ), we might obtain another extreme point xk + 1 by fixing n′ − t variables and optimizing, with a given objective cost vectorc∈Rt,the remaining t variables.Formally, if we partition the set of variables in r blocks of dimensions ti, i = 1, …, r,∑i=1rti=n′,and denote byxFi∈Rn′−tiandxCi∈Rtithe fixed and changing components of x associated to block i, and byAFiandACithe submatrices of A associated toxFiandxCi,the new extreme point is obtained by solving(30)mincTys.toACiy=b−AFixFi0≤y≤1for some random vectorc∈Rn′−tiand i ∈ {1, …, r}. Algorithm 1shows how to obtaink¯random networks by iteratively applying this procedure. For small r values, the r-blocks algorithm generates less dependent networks at the expense of solving from scratch many linear optimization problems. In the extreme case, for r = 1, the cost vectors generated are non-correlated.The sequential r-blocks algorithm can be used as a specific implementation of the Metropolis–Hastings algorithm (as numerically done in Section 4), which accept and reject candidate solutions in accordance with (28), although the acceptance step is not explicitly reported in Algorithm 1.Considering again the polytopeCR(χ)={x∈[0,1]n′:Ax=b},whereA∈Rm′×n′,m′ < n′, we know from LP that there is an equivalence between extreme points and basic solutions, which can be written asxT=[xBT,xNT],xB∈Rm′,xN∈Rn′−m′,A = [BN],B∈Rm′×m′,N∈Rm′×(n′−m′),for a suitable permutation of the variables. Since the extreme points of CR(χ) have been proved to be all integer, it turns out that all basic variables must be at their limits (either at 0 or 1), as well as the non-basic variables. The basic solutions are thus fully degenerate.Denoting by eqthe qth column vector of the identity matrix, and by Bkand Nkthe basic and nonbasic submatrices of A, given a basic solution xkwe can obtain another one by moving along the simplex-like direction(31)Δk(q)=[−Bk−1Nkeqeq].If the nonbasic variable q is 0, then the iteration performed is xk + 1 = xk+ λΔk(q), for some non-negative step-length λ. On the other hand ifxNqk=1then we apply xk + 1 = xk− λΔk(q). It can be easily verified that in both cases Axk + 1 = Axk= b, i.e., the new point satisfies the linear constraints. In addition, since the constraints matrices of Section 2 are TU, the step-lengths λ—computed by a ratio test—are always either 0 or 1. It is thus possible to generate a new basic solution (i.e., a new random graph) by randomly selecting q ∈ {1, …, n′ − m′} and computing xk + 1 = xk± λΔk(q). A sample ofk¯networks can be obtained by iteratively applying this procedure. Since the resulting sample may be claimed to be quite local, every s iterations we can jump to an independent extreme point of the polytope by generating some random cost vector, and solving the associated LP. Two drawbacks of this procedure are: (1) many iterations may be degenerate, i.e., λ = 0, so no new point is obtained; (2) the sample of networks obtained may be highly correlated if s is large because of its proximity in the feasible polytope. On the other hand, this procedure may be very efficient, since it only requires simplex pivots to obtain a new network. Algorithm 2summarizes this procedure. Note that the s-pivots and r-blocks methods are equivalent for s = r = 1. They will be computationally evaluated in Section 4.The sequential s-pivots algorithm is not a specific case of the described Metropolis–Hastings procedures, as a full characterization of the proposal distribution (associated to the random pivots) is not available. It turns out that the probabilistic properties, analyzed in Sections 3.1 and 3.4 do not hold, so that no guarantee of uniformity of the generated sample is available when network are generated by random pivots.The r-blocks and s-pivots procedures of Sections 3.5 and 3.6 require the repeated solution of several LP problems, at each iteration and every s iterations, respectively. Moreover, each one of these LPs may be computationally expensive for large networks. Therefore, although state-of-the-art implementations of the simplex method and polynomial time interior-point algorithms can be used, it is worth to exploit the problem structure whenever possible (Conejo, Castillo, Minguez, & Garcia-Bertrand, 2006).It can be shown that, under a proper row and column permutation, most of the constraints matrices of Section 2 exhibit a primal block-angular structure such as(32)[N1N2⋱NkL1L2…LkI][x1x2⋮xkx0]=[b1b2⋮bkb0].Matrices Niand Lii = 1, …, k, respectively define the block-diagonal and linking constraints, k being the number of blocks. Vectors xi, i = 1, …, k, are the variables for each block. x0 are the slacks of the linking constraints∑i=1kLixi≤b0(x0 = 0 if linking constraints are equalities). bi, i = 1, …, k, is the right-hand side vector for each block of constraints, whereas b0 is for the linking constraints.Consider, for instance, the constraints matrix of the edge-colored network (4). The number of blocks is k = C, the decision variables are the n(n − 1)/2 edges of each one of the C AMs, and Ni= eT, i = 1, …, C. Matrices Niare also row vectors in most of the other families of networks introduced in Section 2.Problems with the constraints structure of (32) can be efficiently solved by specialized approaches, such as the interior-point method of Castro (2000), Castro (2007), and Castro and Cuesta (2011) (BlockIP from now on). A description of this method is out of the scope of this work; details can be found in the above references. For instance, Table 1reports computational results for the solution of several edge-colored network instances. Columns n and C show the number of nodes and colors of the networks. Columns “n. var.” and “n. constr.” give the number of variables and constraints of the resulting LP problems. Note that the largest case has more than 45 million variables, and 900 constraints. The remaining columns of Table 1 give the CPU time and number of iterations (in parentheses) for the three algorithms tested: Cplex 12.5 dual simplex, Cplex 12.5 barrier (interior-point), and the specialized interior-point method of BlockIP. The runs were carried out on a Fujitsu Primergy RX300 server with 3.33 gigahertz Intel Xeon X5680 CPUs (24 cores) and 144 gigabytes of RAM, under a GNU/Linux operating system (Suse 11.4), without exploitation of multithreading capabilities.From Table 1, the simplex method is clearly outperformed by the barrier algorithm, and the gap increases with the size of the instance. BlockIP, the specialized interior-point algorithm, was two to three times faster than the Cplex barrier in the largest instances, resulting to be the most efficient approach for this kind of problems.This section provides numerical results comparing the efficiency and correctness of the r-blocks and s-pivots procedures, both in terms of CPU time and analysis of specified network features. Three network data sets are used: a 62 node undirected graph, representing the social network of frequent associations between dolphins in a community living off Doubtful Sound, New Zealand (Lusseau, 2003, 2004); and two 39 node undirected graphs, representing alliances among workers during extended negotiations for higher wages in a tailor shop in Zambia at two different times (7 months apart) over a period of 1 month (Kapferer, 1972).The runs were carried out on the same hardware used for the results of Section 3.7. According to these results, the LPs were solved with BlockIP, the most efficient approach for these problems. The simplex pivots required by the s-pivots procedure were implemented in Matlab.Consider the previously introduced data set of 62 dolphins and the following families of networks: (1) undirected networks conditioned to the density; (2) undirected networks conditioned to the within and between group densities; (3) undirected networks conditioned to the lower bound of the degree sequence range and density. These three models are specified by the observed parameters of the dolphin’s social network. The within group densities are obtained from the community structure of the observed network, computed by the walk trap community search algorithm of Newman (2004). Table 2shows the number of basic solutions explored by the s-pivots procedure to generate 100 different networks, and the required CPU time. The results confirm the high degeneracy of the s-pivots procedure.For the data sets of dolphins and the two of workers previously introduced, we consider the simple uniform random network conditioned to the density model. Our interest is in two network features: clustering coefficient (CC) and assortativity coefficient (AC). The CC of a network is the average CC of all the nodes, as a measure of how dense is the neighborhood of each node. The AC is the Pearson correlation coefficient of degree between pairs of linked nodes. Positive values of AC indicate a correlation between nodes of similar degree, while negative values indicate relationships between nodes of different degree.For each of the three data sets, eight samples of 1000 networks have been obtained using the r-blocks and the s-pivots methods for different r and s values. Tables 3,5and 7show, respectively for each data set, the mean and standard deviation of the CC and AC over the samples generated by the r-blocks method. Last column reports the CPU time in seconds. The Metropolis–Hastings algorithm has been used to guarantee a uniform distribution of the generated sample; the sixth column informs about the number of rejections.Likewise, Tables 4, 6 and 8summarize the analogous information for networks generated with the s-pivots methods.Theoretical results (Bollobas, 1985) state that the expected clustering coefficient of a uniform random network with n nodes conditioned to d edges is 2d/n2, which in the case of the dolphin social network is 2 × 159/622 = 0.08272633. This is approximately what we obtained in Tables 3 and 4. The expected assortativity coefficient of a uniform random network with n nodes conditioned to d is approximately−1n/2−1(this approximation is based on the multivariate hypergeometric distribution of the degree vector), which in the case of the dolphin social network is−162/2−1=−0.03333,fitting reasonably well the simulated networks.The numerical values of CC and AC obtained for the first data set of workers in Tables 5 and 6 also resemble the theoretical values under the considered probabilistic model, which are 2 × 158/392 = 0.2077581 and−139/2−1=−0.05405405respectively. Beside, the corresponding theoretical values of CC and AC for the second observed network of workers are 2 × 223/392 = 0.2932281 and−139/2−1=−0.05405405,which are consistent with the numerical results in Tables 7 and 8. The observed numerical correctness of the r-blocks method supports the results of Section 3.1.It is worth remarking that this kind of simulations are normally divided into pre- and post-convergence periods, where the pre-convergence part, known as burn-in, is discarded and the post-convergence part is used for inference. The sample means in Tables 3–8 have been calculated discarding the first 200 networks, so they only include a relatively small sample size of 800 instances.The length of the burn-in period depends on the autocorrelation of the resulting sample. The plots in Figs. 1–6 show the autocorrelations function of CC and AC for the 1000 networks obtained in each of the runs of Tables 3–8 with r = 12 and s = 20. It can be observed from the autocorrelation function associated to different values of r and s (not plotted to save space) that the autocorrelations tend to zero faster when r and s are small. Nonetheless, the s-pivots methods maintains a strongly autocorrelated behavior even when s = 20. On the other hand, the autocorrelations of the sample obtained with the r-blocks procedure quickly tend to zero for small lags. Thus, despite the s-pivots outperforms the r-blocks method in terms of efficiency, the generation of less autocorrelated networks by the r-blocks method allows for a much smaller sample size when simulating large networks. Moreover, the availability of (15) allows a more rigorous evaluation of the probabilistic properties of the networks obtained with the r-blocks method and the application of the Metropolis–Hastings algorithm. As it can be seen from Tables 3, 5 and 7, the number of Metropolis–Hastings rejections is approximately one half of the generated sample. One possibility to increase the acceptance rate is to update the probability density function of the objective costs along the iterations, increasing the internal dependencies of the described Markov chain.As already mentioned, the study of uniform random networks conditioned to the density by the s-pivots or r-blocks methods are quite unreasonable, since plenty of theoretical results for this model are available (Bollobas, 1985). However this simple model allowed us to validate our procedures. For more complicated models, as the one of next section, these LP-based network generation procedures are instrumental.In Lusseau (2003) and Lusseau (2004) it was shown that the social network of dolphins exhibits a remarkable level of community structure, i.e., dolphins can be easily grouped into (potentially overlapping) sets such that each set of nodes is densely connected internally. Characterizing those communities is in general a difficult task. We used two of the several algorithms for community finding, the walk trap community and the fast greedy community, as implemented in the igraph library of the R package. The first algorithm finds densely connected subgraphs by simulating random walks on the graph, which tend to stay inside communities. The second algorithm identifies (using the betweenness measure) edges in a network that lie between communities and then removes them, leaving behind just the communities themselves. Both algorithms found almost the same four communities.Using the above four groups, the goal is to decide whether the CC and AC of our social network of dolphins is likely to have been randomly obtained from the distribution of undirected networks conditioned to the observed within-community-densities and degree nodes. As noted in Section 2 the constraints matrix of this model is not TU. However, we can still use the r-blocks procedure, discarding the fractional solutions found.A sample of 100 networks was generated using the observed densities and degree of the dolphin’s social network. Table 9provides the numerical results for r ∈ {4, 5, 6, 8, 10, 13}. Column “Fractional networks” shows the number of rejected fractional solutions. If two consecutive LPs with different objectives provided the same solution (named “loops”), the repeated network is also rejected; they are reported in column “Loops” of Table 9. Last column provide the CPU time in seconds, using the same computational environment than in previous sections.In accordance with the results in Table 9, the number of fractional networks seems to decrease with the number of blocks r. Nonetheless, when r is large, consecutive networks are more likely to be the same, so that we face a trade-off between minimizing the number of loops and minimizing the number of fractional solutions. In any case, the r-blocks procedure was still efficient for this non-TU model.Based on the results in Table 9, we set r = 8 (which guarantees an uncorrelated sample with low number of loops and fractional solutions) and generated 10, 100 networks, removing the first 100 ones as burn-in period.The resulting empirical distribution of CC and AC is shown in the density plot of Fig. 7. Table 10shows the sample mean and standard deviation of the CC and AC over the 10,000 generated networks, the observed values in the dolphins social network, and the associated p-values. From these p-values we conclude that the CC cannot be explained by only using the information concerning the within-community-density and the degree nodes. On the other hand, the AC seems instead to be likely induced by the fixed structural properties we considered. The LP-based sampling procedures developed in this work allowed to easily perform this kind of inference analysis, which otherwise could not have been done with the available theoretical results for these complex network models.

@&#CONCLUSIONS@&#
The constraints matrices associated to several classes of random graph problems have shown to be TU. The resulting MILP problems are thus efficiently solved as LPs. It was observed that specialized interior-point algorithms outperform state-of-the-art simplex solvers for this kind of problems. Two particular procedures, r-blocks and s-pivots, were introduced to generate large samples of random graphs. These two procedures were validated both empirically, using three real-world data sets, and theoretically, obtaining expressions for the density function and entropy of the LP solutions as a function of the distribution and entropy of the cost vectors. Extending this approach to other classes of random graph problems, and showing whether their constraints matrices are TU, is part of the further work to be done. The application of the acceptance-rejection Metropolis–Hastings method (Robert & Casella, 2004) to obtain LP solutions guaranteeing other than the uniform particular distributions should also be explored in the future. Indeed, the observed numerical correctness of the r-blocks method suggests a particularly low rejection ratio in the Metropolis–Hastings algorithm.This work showed how mathematical programming tools can be efficiently used for the analysis of complex networks, and it opens the possibility for other applications in this field.