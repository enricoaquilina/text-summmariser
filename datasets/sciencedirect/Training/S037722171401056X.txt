@&#MAIN-TITLE@&#
Two exact algorithms for the traveling umpire problem

@&#HIGHLIGHTS@&#
Formulated the TUP into two mixed integer programming models.Proposed two exact algorithms to solve the problem.Our models yielded stronger lower bounds than the previous in the literature.One algorithm solved two instances with 14 teams to optimal for the first time.New lower bounds and optimal solutions served as reference for future researchers.

@&#KEYPHRASES@&#
Umpire scheduling,Lagrangian relaxation,Column generation,OR in sports,Mathematical model,

@&#ABSTRACT@&#
In this paper, we study the traveling umpire problem (TUP), a difficult combinatorial optimization problem that is formulated based on the key issues of Major League Baseball. We introduce an arc-flow model and a set partition model to formulate the problem. Based on these two models, we propose a branch-and-bound algorithm and a branch-and-price-and-cut algorithm. The branch-and-bound algorithm relies on lower bounds provided by a Lagrangian relaxation of the arc-flow model, while the branch-and-price-and-cut algorithm exploits lower bounds from the linear programming relaxation of the set partition model strengthened by a family of valid inequalities. In the branch-and-price-and-cut algorithm, we design an efficient label-setting algorithm to solve the pricing problem, and a branching strategy that combines three different branching rules. The two algorithms are tested on a set of well-known benchmark instances. The two exact algorithms are both able to rapidly solve instances with 10 teams or less, while the branch-and-price-and-cut algorithm can solve two instances with 14 teams. This is the first time that instances with 14 teams have been solved to optimality.

@&#INTRODUCTION@&#
The traveling umpire problem (TUP) is a relatively new combinatorial optimization problem that originates from Major League Baseball. Given a double round-robin tournament of 2n teams, in which each team plays against all of the other teams twice at home and away in a season of 4n − 2 time slots, the problem requires to determine an assignment of n umpires to the games in each time slot. Each game must have one umpire, and each umpire must be assigned to one game in each time slot. The objective is to minimize the total travel distance of the umpires. From another point of view, the TUP requires the design of a set of paths, starting from the first time slot and ending at the last time slot, that allow the umpires to visit every game exactly once throughout the season. To capture the most important features of umpire scheduling in the game, the TUP considers two additional requirements. The first, referred to as the frequency requirement, forbids any umpire to visit the home venue of any team more than once in any n − d1 consecutive time slots and to see the same team more than once in any⌊n2⌋−d2consecutive time slots, where d1 and d2 are two integer parameters that satisfy 0 ≤ d1 ≤ n − 1 and0≤d2≤⌊n2⌋−1,respectively. The second requirement, referred to as the visit requirement, enforces each umpire to visit the home venue of every team at least once throughout the season.As the TUP is a relatively new problem, few research papers have addressed it to date. The problem was first introduced by Trick and Yildiz (2007), and was then further addressed by Trick and Yildiz (2011). Trick and Yildiz (2011) formulated the problem as an integer programming (IP) model and a constraint programming model, and designed a Bender’s cuts guided large neighborhood search heuristic to deal with the problem. To test the models and the proposed heuristic, Trick and Yildiz (2011) generated a set of benchmark instances where the number of teams ranged from 4 to 32. Their computational results suggested that the TUP was very difficult to solve to optimality; the commercial IP solver ILOG CPLEX could only exactly solve instances with 10 teams at most. Moreover, finding a feasible solution for medium-sized instances was very difficult; both CPLEX and the large neighborhood search heuristic failed to find any feasible solutions in many medium-sized instances. The background and applications of the TUP, and the set of benchmark instances used by Trick and Yildiz (2011), were further explained by Trick, Yildiz, and Yunes (2012). These benchmark instances are available at http://mat.tepper.cmu.edu/TUP/. Trick et al. (2012) also proposed a simple greedy heuristic to generate initial solutions and a simulated annealing to further improve these initial solutions. Trick and Yildiz (2012) proposed a genetic algorithm to solve the TUP. In this genetic algorithm, when two parent solutions were crossed over to generate offsprings, these offsprings were partially optimized to improve their qualities. This crossover operator is referred to as a locally optimized crossover. Experiments on the benchmark instances showed that this genetic algorithm could find better feasible solutions, or feasible solutions for some medium-sized instances, for which no feasible solution had been found before. de Oliveira, de Souza, and Yunes (2014) introduced a stronger IP model, based on which they implemented a relax-and-fix primal heuristic that iteratively solved relaxations of the IP model and progressively fixed variables until a feasible was found. Recently, Wauters, Van Malderen, and Vanden Berghe (2014) introduced a lower bound approach based on problem decomposition and a local search heuristic, which substantially improved the best-known lower bounds for many instances and find several new best feasible solutions, respectively. Toffolo, Van Malderen, Wauters, and Vanden Berghe (2014) proposed a branch-and-price algorithm, where a specialized branch-and-bound algorithm with multiple pruning techniques was applied to solve the pricing problem. It successfully improved several best-known lower bounds and upper bounds in the literature. The first complexity analysis on the TUP was conducted by de Oliveira, de Souza, and Yunes (2015).In this paper, we propose two new IP models for the TUP: an arc-flow model and a set partition model. These two models use different methods to enforce the frequency requirement and the visit requirement. The arc-flow model uses an exponential number of constraints to eliminate solutions that violate either of the two requirements, while the set partition model defines a decision variable with respect to a path that satisfies both of the two requirements, leading to an exponential number of variables. The set partition model is further strengthened by the subset row (SR) inequalities, which were first applied in the vehicle routing problem (Jepsen, Petersen, Spoorendonk, and Pisinger, 2008). Although these two models cannot be solved directly by existing IP solvers (e.g. CPLEX and Lingo), a Lagrangian relaxation of the arc-flow model and the linear programming (LP) relaxation of the set partition model yield strong lower bounds. These lower bounds can be exploited to design effective exact algorithms. Therefore, we propose a branch-and-bound algorithm based on a Lagrangian relaxation and a branch-and-price-and-cut algorithm based on the LP relaxation. The two algorithms were extensively tested on the benchmark instances proposed by Trick and Yildiz (2011). Both the branch-and-bound algorithm and the branch-and-price-and-cut algorithm can rapidly achieve optimal solutions on instances with up to 10 teams. Moreover, the branch-and-price-and-cut algorithm can solve 2 instances with 14 teams to optimality in 48 hours due to the stronger lower bounds from the LP relaxation. This is the first time instances with 14 teams have been solved to optimality.The remainder of this paper is organized as follows. First, we present the arc-flow model, the set partition model and the SR inequalities in Section 2. We describe the branch-and-bound algorithm in Section 3 and the branch-and-price-and-cut algorithm in Section 4. Section 5 is devoted to the computational results, and Section 6 concludes the paper with some closing remarks.Before presenting the two IP models, we introduce some necessary notations and definitions to simplify our presentation. Let T = {1, …, 2n}, U = {1, …, n} and S = {1, …, 4n − 2} denote the set of teams, the set of umpires and the set of time slots in the season, respectively. Let Gtdenote the set of games taking place in time slot t. Each game in Gtmust have an umpire from U, while each umpire from U must be assigned to one game in Gt. Let di, j(i, j ∈ T) denote the travel distance between the home venues of team i and team j. We use a tuple (i, j) to represent the arc between two games, i and j, which take place in adjacent time slots. LetG=⋃t∈SGtdenote the set of games in the season. For each game g ∈ G, let g− denote the home team and g+ denote the guest team. Let p = (g1, …, gm)tdenote a path that starts from game g1 in Gtand ends at game gmin Gt + m − 1. Let Gpand Epdenote the set of games and the set of arcs in path p, respectively.Definition 1A path p = (g1, …, gm)tis complete if t = 1 and m = 4n − 2.A path p = (g1, …, gm)tis infeasible if it satisfies at least one of the following conditions:1.there exist two games giand gj(gi, gj∈ Gp) such that i − j + 1 ≤ n − d1 andgi−=gj−;there exist two games giand gj(gi, gj∈ Gp) such thati−j+1≤⌊n2⌋−d2and at least one of the following four equations is satisfied:gi−=gj+,gi−=gj−,gi+=gj−andgi+=gj+;p is complete and⋃g∈Gpg−≠T.The first two conditions correspond to the frequency requirement, while the third condition corresponds to the visit requirement. A path that satisfies any one of the above three conditions must violate the frequency or the visit requirement and therefore cannot exist in any feasible solutions.Let P denote the set of infeasible paths. The binary decision variable xi, j(i ∈ Gt, j ∈ Gt + 1, t = 1, …, 4n − 3) is set to one if an umpire travels from game i to game j, and zero otherwise. The arc-flow model can be formulated as follows:(1)min∑t=1,…,4n−3∑i∈Gt∑j∈Gt+1di−,j−xi,j(2)s.t.∑j∈G2xi,j=1,∀i∈G1,(3)∑j∈Gt+1xi,j=∑j∈Gt−1xj,i=1,∀i∈Gt,t=2,…,4n−3,(4)∑j∈G4n−3xj,i=1,∀i∈G4n−2,(5)∑(i,j)∈Epxi,j≤|Ep|−1,∀p∈P,(6)xi,j∈{0,1},∀i∈Gt,j∈Gt+1,t=1,…,4n−3.Objective (1) minimizes the total travel distance of the umpires. Constraints (2) and (4) ensure that all of the games in the first and the last time slot have one umpire. Constraints (3) are the flow conservation constraints for the games from time slot 2 to time slot 4n − 3, and also ensure that these games have one umpire. Constraints (5) are the infeasible path elimination constraints, which ensure that all the paths for the umpires are feasible .The infeasible path elimination constraints (5) are very weak in general, especially when the length of an infeasible path becomes large. We use a technique similar to that used by Kallehauge, Boland, and Madsen (2007) to strengthen the infeasible path elimination constraints. For an infeasible path p = (g1, …, gm)t, letE¯p={(gs,i)|i≠gs+1,(g1,…,gs,i)tbefeasible,ands=1,…,m−1}denote the set of arcs that can destroy the infeasible path p. Then the infeasible path constraints (5) can be re-formulated as follows:(7)∑(i,j)∈E¯pxi,j≥1,∀p∈P.The idea behind (7) is that once at least one arc inE¯pis selected, the infeasible path p is destroyed. In the rest of the paper, we replace constraints (5) with constraints (7) as the infeasible path elimination constraints.Let R be the set of complete feasible paths. Let crbe the distance of path r and αi, r(i ∈ G, r ∈ R) be a binary number, which is equal to one if path r covers game i, and zero otherwise. The binary decision variable θr(r ∈ R) is set to one if path r is selected, and zero otherwise. The set partition model can be formulated as follows:(8)min∑r∈Rcrθr(9)s.t.∑r∈Rαi,rθr=1,∀i∈G,(10)θr∈{0,1},∀r∈R.Objective (8) minimizes the total travel distance of the umpires, and constraints (9) ensure that every game has one umpire.The LP relaxation of the set partitioning model provides strong lower bounds, which can be further strengthened by adding the subset row (SR) inequalities (Jepsen et al., 2008). For a set of games V⊂G and an integer k (1 < k ≤ |V|), the SR inequalities can be defined as follows:(11)∑r∈R⌊1k∑i∈Vαi,r⌋θr≤⌊|V|k⌋.As the SR inequalities are derived from the general set partition model, they are also valid for the TUP. The idea behind the SR inequalities is intuitive. For example, when k = 2 and |V| = 3, the SR inequalities just ensure that at most one path covering more than one node in V can be selected.The branch-and-bound algorithm relies on lower bounds from a Lagrangian relaxation of the arc-flow model. The method used to generate these lower bounds is the Lagrangian relaxation approach, which is a classic decomposition algorithm for solving optimization problems (Fisher, 1981). The main idea behind a Lagrangian relaxation approach comes from the observations that (i) many difficult optimization problems can be viewed as easy problems, complicated by a set of side constraints; and (ii) these side constraints can be dualized into the objective, resulting in a Lagrangian problem. Compared with the original problem, the Lagrangian problem is much easier to solve and the cost of its optimal solution is a valid lower bound. The Lagrangian relaxation approach heuristically searches the best multipliers, which are used to dualize the side constraints, to find the strongest lower bound.The arc-flow model is difficult to solve because of the infeasible path elimination constraints. If we dualize these constraints, the problem can be decomposed into a set of assignment problems, which can be solved efficiently by the Hungarian method (Kuhn, 1955). Let λp≥ 0 (p ∈ P) denote the set of Lagrangian multipliers with respect to constraints (7). The Lagrangian problem LR(λ) can be formulated as follows:(12)LR(λ)=min∑t=1,…,4n−3∑i∈Gt∑j∈Gt+1(di−,j−−∑p∈P,(i,j)∈pλp)xi,j+∑p∈Pλp(13)s.t.∑j∈G2xi,j=1,∀i∈G1,(14)∑j∈Gt+1xi,j=∑j∈Gt−1xj,i=1,∀i∈Gt,t=2,…,4n−3,(15)∑j∈G4n−3xj,i=1,∀i∈G4n−2,(16)xi,j∈{0,1},∀i∈Gt,j∈Gt+1,t=1,…,4n−3.Because the number of infeasible paths is exponential, they cannot all be enumerated at the same time. Moreover, most of them contribute little to improving the lower bound. Therefore, we adopt a dynamic generation strategy to find a set of useful infeasible paths.The Lagrangian relaxation approach is detailed in Algorithm 1. LetP¯denote the set of used infeasible paths, andλ¯denote the set of Lagrangian multipliers with respect to the paths inP¯. The positive parameter maxNonImpr is the maximum number of non-improvement iterations that the algorithm can take, and is set to 10. Another positive parameter ε controls the step size for updatingλ¯. Parameter ub is a given upper bound and parameter nonImprIter is a counter that indicates the number of non-improvement iterations the algorithm has taken. For a (feasible or infeasible) solution s, let c(s) andc¯(s)denote the total travel distance of s in the original problem and the cost of s in the Lagrangian problem, respectively.In every iteration, the algorithm first solvesLR(λ¯)by the Hungarian method and achieves the optimal solution s. If s is feasible and c(s) is less than ub, ub is updated by c(s). Ifc¯(s)is larger than the best-known lower bound c*, c* is updated byc¯(s). If the number of non-improvement iterations exceeds maxNonImpr, ε is divided by 2 and nonImprIter is reset to 0. Next, the algorithm generates the set of infeasible paths with respect to s, denoted byP˜,using the subroutine GenInf. The infeasible paths inP˜are then added toP¯. The Lagrangian multipliers with respect to the infeasible paths inP˜,denoted byλ˜,are set to zero and added toλ¯. In the last step, the algorithm updatesλ¯as follows.(17)λ¯p←max{λ¯p+η(∑(i,j)∈E¯pxi,j−1),0},∀p∈P¯,where η is the step size and is equal toϵ(ub−c(s))∑p∈P¯(∑(i,j)∈Epxi,j−1)2. This process iterates until a stopping criterion is matched. This stopping criterion can be either the number of iterations reaching a limit, or the step size η becoming smaller than a threshold value. In the experiment, we compare the performance of different stopping criteria and select the best one.Subroutine GenInf searches for the infeasible paths with respect to solution s through enumeration. The detail of the algorithm is presented in Algorithm 2. Letnmax=max{n−d1,⌊n2⌋−d2}. Given a path r and a time slot t, let rtdenote the tth game in r. For every path r in s, the subroutine first searches for the infeasible paths that violate the frequency requirement. If no such infeasible path exists, the subroutine then checks whether r violates the visit requirement. If r violates the visit requirement, it is infeasible per se and is added toP˜.The branch-and-bound algorithm is a tree search procedure. At each tree node, a Lagrangian problem is solved to generate a lower bound. If the lower bound is not less than the upper bound, this node is pruned; if the lower bound is less than the upper bound and the solution with respect to this lower bound is infeasible, branching strategies are applied to branch this node into a set of child nodes. The upper bound is updated once a better feasible solution is found. Let s be the infeasible solution with respect to the best lower bound returned by the Lagrangian relaxation approach. Let Ps= GenInf(s) denote the set of infeasible paths that are violated by s. We select an arc (i, j) from⋃p∈PsEp,which minimizesdi−,j−−∑p∈P¯,(i,j)∈pλp. The current node is then branched into two child nodes: one has xi, j= 1 and the other has xi, j= 0. This branching rule ensures the branch-and-bound algorithm can eventually find the optimal solution.A linear programming (LP) problem that involves an exponential number of decision variables is typically solved by column generation (Desaulniers, Desrosiers, and Solomon, 2005; Kuhn, 1955). Column generation is an iterative approach that alternatively solves two problems: a restricted master problem (RMP) and a pricing problem. The RMP usually has the same objective and constraints as the original LP problem, but only considers a small subset of columns. Therefore, the RMP can be solved efficiently by the simplex method. The pricing problem is a new problem formulated to identify the set of columns that have a negative reduced cost with respect to the dual values from the RMP. The RMP is solved first, then the pricing problem. The set of columns with a negative reduced cost are added to the RMP, then it is solved again. This iteration process stops when no columns with a negative reduced cost are found.The LP relaxation of the set partition model yields strong lower bounds, which can be exploited in the branch-and-bound framework to solve the problem to optimality. Meanwhile, the LP relaxation can be further strengthened by adding the SR inequalities, leading to a branch-and-price-and-cut algorithm, which we present in this section. First, we introduce the pricing problem and formulate it into an IP model. Then, we propose an ad hoc label-setting algorithm to solve the pricing problem. Next, we introduce the decremental state-space relaxation, an acceleration strategy to speed up the label-setting algorithm. After that, we show how to incorporate the label-setting algorithm to handle the SR inequalities. Finally, we describe a branching strategy composed of three special branching rules.Let μi(i ∈ G) denote the set of dual values from constraints (9). The pricing problem calls for the determination of a complete feasible path, which minimizes the reduced cost. Therefore, the pricing problem can be modeled as follows:(18)min∑t=1,…,4n−3∑i∈Gt∑j∈Gt+1(di−,j−−μi)xi,j−∑i∈G4n−3∑j∈G4n−2μjxi,j(19)s.t.∑i∈G1∑j∈G2xi,j=1,(20)∑j∈Gt+1xi,j=∑j∈Gt−1xj,i,∀i∈Gt,t=2,…,4n−3,(21)∑i∈G4n−3∑j∈G4n−2xi,j=1,(22)∑(i,j)∈Epxi,j≤|Ep|−1,∀p∈P,(23)xi,j∈{0,1},∀i∈Gt,j∈Gt+1,t=1,…,4n−3.Objective (18) minimizes the reduced cost. Constraints (19) and (21) ensure that a path starts from the first time slot and ends at the last time slot, respectively. Constraints (20) are the flow conservation constraints. The infeasible path elimination constraints (22) guarantee the feasibility of a solution. Note that the number of infeasible path elimination constraints is exponential, therefore this model cannot be solved directly by an IP solver.The pricing problem can be viewed as a variant of the shortest path problem complicated by the infeasible path elimination constraints. Shortest path problems with complex constraints are usually solved by label-setting algorithms, for example, the elementary shortest path problem with resource constraints (Boland, Dethridge, and Dumitrescu, 2006; Feillet, Dejax, Gendreau, and Gueguen, 2004; Righini and Salani, 2008), the quickest path problem (Park, Lee, and Park, 2004) and the multicriteria shortest path problem (Martins, 1984; Tung and Chew, 1992). As dynamic programming, label-setting algorithms typically consist of three key components: state representation, extension functions, and domination criteria. Proper state representation and extension functions ensure that a label-setting algorithm can explore all of the feasible solutions. Domination criteria are used to abandon states that cannot generate optimal solutions, and therefore improve efficiency. The success of a label-setting algorithm relies on the design of these three components. In the rest of this section, we describe these components in detail.Let L = {c, (g1, …, gm)t, T1, …, T2n} be a label representing a path from the first time slot to game gmin time slot t + m − 1, where:•c is the reduced cost of this path;(g1, …, gm)tis the sub-path consisting of the latest m games (m ≤ nmax  − 1); andTi(i = 1, …, 2n) is a binary number, which is equal to one if the home venue of team i has already been visited, and zero otherwise.Given a labelL1={c1,(g11,…,gm1)t1,T11,…,T2n1}and an arc(gm1,i),the algorithm creates a new labelL2={c2,(g12,…,gk2)t2,T12,…,T2n2}by extending label L1 through arc(gm1,i)if path(g11,…,gm1,i)t1is feasible. The new label, L2, is set according to the following extension functions:(24)c2=c1+dgm−,i−−μi,(25)(g12,…,gk2)t2={(g11,…,gm1,i)t1,ifm<nmax−1,(g21,…,gm1,i)t1+1,ifm=nmax−1,(26)Tj2={1,ifj=i−,Tj1,ifj≠i−.According to the extension functions, an existing label may create many new labels as it is extended through different arcs. Hence, the number of labels may increase exponentially. Fortunately, because we are only interested in finding an optimal solution, labels that cannot be extended to generate an optimal solution should be discarded. A sufficient condition to exclude a label’s possibility of becoming an optimal solution is that this label is dominated by another label. LetL1={c1,(g11,…,gm1)t1,T11,…,T2n1}andL2={c2,(g12,…,gk2)t2,T12,…,T2n2}be two labels. Then L1 is dominated by L2 if the following conditions are satisfied:(27)(g11,…,gm1)t1=(g12,…,gk2)t2,(28)c1≥c2,(29)Ti1≤Ti2,i=1,…,2n,and at least one of the above inequalities is strict. If two labels are identical, we arbitrarily discard one.The detail of the label-setting algorithm is presented in Algorithm 3. Let UL denote the set of labels that have not been extended and TL denote the set of labels that have been extended. Let r* be the best path that has been found and c* be the reduced cost of r*. The algorithm starts by creating a set of initial labels IL. For each g ∈ G1, the algorithm creates an initial label Lg= { − μg, (g)1, T1, …, T2n}, where Tiis equal to 1 if i = g−, and 0 otherwise. The algorithm employs a pruning strategy to discard redundant labels that cannot generate an optimal solution. Let lbidenote a lower bound of the reduced cost of paths from game i to the last time slot. If the reduced cost of a label with respect to game i plus lbiis not less than c*, we can discard this label. In each iteration, the algorithm extends the label with the least reduced cost in UL along all of the feasible arcs, and creates a set of new labels. If a new label reaches the last time slot, has visited all of the venues and has a reduced cost smaller than c*, the path with respect to this label is a new best solution and the algorithm records it as such; if the new label does not reach the last time slot and is not dominated by any other labels, it is added to UL. Meanwhile, the labels in UL that are dominated by the new label are discarded. This process terminates when UL becomes empty.Next, we address how to compute the lower bound lbi(i ∈ G). A trivial lower bound is the shortest path length from game i to the last time slot, without restriction from the infeasible path elimination constraints. However, this lower bound is too weak to prune any label, so we use a much stronger lower bound. Let Pidenote the set of paths that start from game i and end in the last time slot, and satisfy the frequency requirement. Letc¯p(p ∈ Pi) denote the reduced cost of path p, then set lbitominp∈Pic¯p. We use the above label-setting algorithm to computeminp∈Pic¯p. First, we ignore elements Ti(i = 1, …, 2n) in the label definition and the pruning strategy in the label-setting algorithm. We reverse the direction of the algorithm, i.e., we compute the states from the last time slot to the first time slot. Let TLidenote the set of labels that represent paths starting in game i to a game in the last slot. Then we haveminp∈Pic¯p=minL∈TLic(L),where c(L) is the reduced cost of label L.The decremental state-space relaxation is a technique used to accelerate a label-setting algorithm. It was first introduced by Boland et al. (2006) and is widely applied in branch-and-price algorithms to solve vehicle routing problems or other problems that include the elementary shortest path problem with resource constraints as the pricing problem (Desaulniers, 2010; Luo, Qin, and Lim, 2014). In our label-setting algorithm, if we relax the visit requirement constraint, we can drop elements Ti(i = 1, …, 2n) in the label definition, which accelerates the label-setting algorithm substantially. However, once we relax the visit requirement constraint, we cannot guarantee that the optimal path obtained by the label-setting algorithm will visit all of the home venues. The decremental state-space relaxation is an iteration procedure in which the visit requirement constraint is first relaxed and then enforced iteratively. Let C denote the set of home venues that a complete path must visit. The decremental state-space relaxation first relaxes the visit requirement, i.e., C = ∅. Then the label-setting algorithm is invoked to find an optimal path. If an optimal path happens to cover all of the home venues, it is also an optimal complete path for the original pricing problem, and hence the algorithm terminates. If the optimal path has a set of uncovered home venues, denoted by U, then U is added to C(C=C⋃U)and the label-setting algorithm is reinvoked. The process terminates when an optimal path that covers all of the home venues is found. U enlarges in every iteration, which ensures that the procedure eventually terminates. Meanwhile, because the label-setting algorithm is faster in each iteration, the overall algorithm is also faster, even though the label-setting algorithm is invoked many times.The effects of the SR inequalities on the branch-and-price-and-cut algorithm are twofold. On the one hand, the SR inequalities can improve the lower bounds yielded by the LP relaxation; on the other hand, the dual values from them destroy the pricing problem’s structure and hence make the pricing problem much more difficult to solve. Therefore, it is crucial to make a good tradeoff between the lower bound’s quality and the pricing problem’s complexity. In our implementation we only use the SR inequalities that can be easily handled by the label-setting algorithm.First, we determine the positive integer parameter k in (11). According to the definition of the SR inequalities, k can be any positive integer greater than 1. Obviously, the more integers we select, the more SR inequalities it is possible to find, and therefore a better lower bound is more likely to be obtained. However, when k becomes larger, the pricing problem’s complexity increases dramatically, but the marginal improvement brought by the SR inequalities decreases. Therefore, in our implementation we only consider k = 2.Next, we consider how to select the subset of games V in (11). As Jepsen et al. (2008) have proven, the problem separating the SR inequalities is NP-Hard. So we do not intend to design a polynomial time algorithm to find the optimal violated inequalities. Therefore, in our implementation we use an enumeration algorithm to search for the violated inequalities. That is, we enumerate all of the subsets of games with a size equal to three and five. When |V| = 3, the coefficient of a complete path in (11) can either be one or zero. That is, if a complete path covers more than one game in V, the coefficient is one; otherwise it is zero. However, when |V| = 5, the coefficient can be zero, one, or two, which complicates the pricing problem. To simplify the pricing problem, we use a relaxed version of the SR inequalities when |V| = 5. That is, if a complete path covers more than one game in V, we set the coefficient to one; otherwise we set it to zero.To enable the existing label-setting algorithm to handle the SR inequalities easily, we impose another restriction on V. LettV−=min{t|Gt∋i,i∈V}andtV+=max{t|Gt∋i,i∈V}be the minimum and maximum time slots covered by V. V should then satisfy the following constraint:(30)tV+−tV−+1≤nmax.This constraint ensures that the time span of V cannot be larger than nmax  time slots.Let νV(V⊂G) denote the dual values from the SR inequalities (11) for k = 2, andVidenote the set of SR inequalities covering game i. We add another element Π to the label definition to record the set of SR inequalities whose dual values have been subtracted from c. The extension functions (25) and (26) remain the same because ν only influences the reduced cost. The extension function (24) with respect to c becomes:(31)c2=c1+dgm−,i−μi−∑V∈Vi∖Π1∑i=1mI{gi1,i}⊂VνV,whereI{gi1,i}⊂Vis an indication function that is equal to 1 if the set{gi1,i}⊂V,and 0 otherwise. Moreover, the extension function with respect to Π is:(32)Π2←Π1∪⋃V∈Vi,∃j=1,…,m{gj1,i}⊂V{V}.The domination criteria (27)–(29) remain the same, because V in (11) satisfies constraint (30). Constraints (30) and (27) ensure that if two labels L1 and L2 follow the same path to the last time slot, the reduced cost increments of L1 and L2 brought by ν will be the same. Therefore if two labels L1 and L2 satisfy the domination criteria (27)–(29), L1 is still dominated by L2.Because the dual value νV(V⊂G) is non-positive, if it is ignored in the computation of the lbi(i ∈ G), lbiis still a valid lower bound. Therefore, when lbiis computed, νVis ignored; otherwise, the complexity of computing lbiwill increase dramatically.The branching strategy is crucial to the success of a branch-and-price-and-cut algorithm. As explained by Lübbecke and Desrosiers (2005), it is not desirable to branch directly on column variables, because it would make the branch-and-bound tree unbalanced and the pricing problem too complicated to solve. Therefore, we design a branching strategy that combines three different branching rules. These branching rules are able to balance the branch-and-bound tree and are compatible with the existing label-setting algorithm.Letθ¯r(r ∈ R) denote the optimal LP solution. Let βi, j, r(i ∈ Gt, j ∈ Gt + 1, t = 1, …, 4n − 3, r ∈ R) be a binary number that is equal to 1 if path r covers arc (i, j), and 0 otherwise. Then we can map column variables θrto arc variables xi, jthrough equation xi, j= ∑r ∈ Rβi, j, rθr. Letx¯i,j(i ∈ Gt, j ∈ Gt + 1, t = 1, …, 4n − 3) denote the set of values of the variables x derived fromθ¯. It is easy to show that there exists a path r (r ∈ R) such thatθ¯ris fractional if and only if there exists an arc (i, j) such thatx¯i,jis fractional. Therefore, we can branch on variables x instead of θ.The first branching rule is based on the following observation. Let (i1, j1, k1)tand (i2, j2, k2)tbe two infeasible paths, where i1 = i2 and k1 = k2 or j1 = j2. Obviously, the following constraints should be satisfied by any feasible solution:(33)xi1,j1+xj1,k1≤1,(34)xi2,j2+xj2,k2≤1,(35)xi1,j1+xi2,j2≤1,(36)xj1,k1+xj2,k2≤1.If all of thex¯i1,j1,x¯j1,k1,x¯i2,j2andx¯j2,k2are fractional and close to 0.5, we branch the current node into three child nodes according to (33)–(36) with the following settings:1.node 1:xi1,j1=1,xj1,k1=0,xi2,j2=0andxj2,k2=1;node 2:xi1,j1=0,xj1,k1=1,xi2,j2=1andxj2,k2=0;node 3:xi1,j1+xj1,k1+xi2,j2+xj2,k2≤1.Note that setting xi, j= 1 is the same as setting xi, k= 0, ∀ k ≠ j. Forbidding an arc is easily handled in the label-setting algorithm by forbidding the extension through this arc. Meanwhile, constraintxi1,j1+xj1,k1+xi2,j2+xj2,k2≤1can be mapped to variables θ as follows:(37)∑r∈R(βi1,j1,r+βj1,k1,r+βi2,j2,r+βj2,k2,r)θr≤1.The dual values from constraints (37) are associated with certain arcs and therefore can be easily handled in the label-setting algorithm: when a label is extended through an arc, the dual values associated with this arc are subtracted from the label’s reduced cost. As there may be many pairs of such infeasible paths with fractional x values, we define a set of criteria to select which one to branch on. Let ρ1 and ρ2 be two positive threshold values. We select the pair of infeasible paths (i1, j1, k1)tand (i2, j2, k2)twhere:1.|x¯i1,j1−0.5|+|x¯j1,k1−0.5|+|x¯i2,j2−0.5|+|x¯j2,k2−0.5|<ρ1;x¯i1,j1+x¯j1,k1+x¯i2,j2+x¯j2,k2is maximized and not less than ρ2.The first criterion ensures that the selected infeasible paths are fractional enough to branch on; if the selected infeasible paths do not satisfy it, this branching rule will have little influence on node 1 or node 2. The second criterion requires the selected infeasible paths to maximize the arc value, and this value cannot be less than ρ2; if this criterion cannot be matched, the influence of this branching rule on node 3 will be very small. In our implementation we set ρ1 to 0.7 and ρ2 to 1.8. If no such infeasible paths exist, we adopt the next branching rule.The second branching rule is to select an infeasible path with three games to branch on. We select an infeasible path (i, j, k)twherex¯i,j+x¯j,kis maximized. If more than one infeasible path which maximizes the arc value at the same time, we select the one with the smallest|x¯i,j−0.5|+|x¯j,k−0.5|. Then the current node is branched into three child nodes with the following setting:1.node 1: xi, j= 1 and xj, k= 0;node 2: xi, j= 0 and xj, k= 1;node 3: xi, j= 0 and xj, k= 0.If the algorithm fails to find such an infeasible path, we adopt the third branching rule.The third branching rule is to branch on arc (i, j), wherex¯i,jis closest to 0.5. The current node is then branched into two child nodes: one has xi, j= 1 and the other has xi, j= 0. The last branching rule ensures the branch-and-price-and-cut algorithm can eventually produce an optimal solution.In this section we present the computational results for the set of benchmark instances proposed by Trick and Yildiz (2011) and available at http://mat.tepper.cmu.edu/TUP/. This benchmark has been widely used to test different kinds of models and to evaluate various algorithms in the TUP literature. It consists of 30 instances ranging in size from 4 to 32 teams. The number in the name of an instance indicates the number of teams it contains. For example, instance “umps14A” has 14 teams. Some instances, for example “umps14”, are used multiple times with different settings for the two input parameters d1 and d2.Both the branch-and-bound algorithm and the branch-and-price-and-cut algorithm were coded in Java whereas the branch-and-price-and-cut algorithm used ILOG CPLEX 12.5.1 Solver to solve the restricted master problem. The experiments of the branch-and-bound algorithm and the branch-and-price-and-cut algorithm were conducted on a Dell personal computer with an Intel i7-4790 3.60 gigahertz CPU, 16 gigabytes RAM and Windows 8.1 operating system.In this section, we present the performance of the Lagrangian approach under different stopping criteria. The computational results are summarized in Table 1. Column maxIter gives the maximum number of iterations that the Lagrangian relaxation approach takes, and column η′ gives the minimum step size for the Lagrangian relaxation approach to terminate. Obviously, when η′ is set to zero, the Lagrangian relaxation approach chooses the maximum number of iterations as the stopping criterion; and when maxIter is set to positive infinity, the Lagrangian relaxation approach chooses the minimum step size as the stopping criterion. The last two columns, Avg. Dist and Avg. Time(s), give the average travel distance and the average computational time in seconds of all of the test instances, respectively. It is apparent from this table that when the maximum number of iterations is set to 1000 and η′ was set to 0, the Lagrangian relaxation approach achieves a very good balance between solution quality and computational time. In the following experiments, therefore, we choose the maximum number of iterations as the stopping criterion of the Lagrangian relaxation approach and set maxIter to 1000.In this section, we present the detailed computational results of the branch-and-bound algorithm in Table 2, where the new best lower bounds are marked in bold. The running time of the algorithm is limited to 3 hours. Columns LB* and UB*, respectively, give the best lower bounds and the best upper bounds in the literature. Columns LR Cost and IP Dist, respectively, give the cost of the Lagrangian relaxation and the total travel distance of the best feasible solution obtained by the branch-and-bound algorithm. The best lower bounds obtained by the branch-and-bound algorithm throughout the search process are shown in column Best bound. Columns LR time (seconds) and Total time (seconds), respectively, report the running time of the Lagrangian relaxation approach in the root node and the total running time of the branch-and-bound algorithm in seconds. Columns Root #IPE and Total #IPE, respectively, give the number of infeasible path elimination inequalities generated in the root node and the total number of these inequalities generated in all of the nodes. The last column, #Node, gives the number of nodes explored by the branch-and-bound algorithm. “*” in the name of an instance means this instance has been solved to optimality by the branch-and-bound algorithm. Note that the instances with 10 teams or less have been solved to optimality in the literature, while instance umps12 has been proved to be infeasible (Trick and Yildiz, 2011). “–” in columns LB* and UB* means a lower bound or upper bound for the corresponding instance does not exist in the literature, while “–” in column IP Dist means that the branch-and-bound algorithm failed to find any feasible solutions for the corresponding instance.As Table 2 shows, the branch-and-bound algorithm only solved instances with 10 teams or less to optimality. It also failed to obtain any feasible solutions for the instances that cannot be optimally solved, mainly because feasible solutions for these instances are rather rare and the branch-and-and algorithm does not have a strong primal heuristic with which to find them. The best lower bounds found by the branch-and-bound algorithm were slightly worse than the best lower bounds in the literature. However, the branch-and-bound algorithm still produced seven lower bounds better than those in the literature, which suggests that the lower bounds yielded by the Lagrangian relaxation approach are quite strong.In this section, we present the computational results of the branch-and-price-and-cut algorithm in Table 3. Also, we mark the new best lower bounds in bold in this table. We imposed a time limit of 48 hours on each run of the algorithm. Columns LP Dist, LPC Dist, and IP Dist give the total travel distance of the optimal LP solution, the total travel distance of the optimal LP solution strengthened by the SR inequalities, and the total travel distance of the best feasible solution obtained by the branch-and-price-and-cut algorithm, respectively. The last column, Best bound, reports the best lower bounds obtained by the branch-and-price-and-cut algorithm throughout the search process. “*” in the name of an instance means that this instance has been solved to optimality by the branch-and-price-and-cut algorithm. “–” in columns LP Dist and LPC Dist means that the optimal LP solution could not be obtained because the label-setting algorithm ran out of memory; and “–” in columns IP Dist and Best Bound means a feasible solution or lower bound cannot be obtained by the branch-and-price-and-cut algorithm.From Table 3, it can be seen that the branch-and-price-and-cut algorithm was able to exactly solve all instances with 10 teams or less and two instances with 14 teams in 48 hours. This is the first time that instances with 14 teams have been exactly solved. Moreover, in most of the instances that cannot be optimally solved, the branch-and-price-and-cut algorithm obtained new best lower bounds. However, the branch-and-price-and-cut algorithm also failed to obtain any feasible solutions for the instances that cannot be optimally solved. In addition, the branch-and-price-and-cut algorithm failed to prove instance umps12 to be infeasible, because the branch-and-price-and-cut algorithm does not involve a strong upper bound approach.Table 4summarizes the details of the branch-and-price-and-cut algorithm. The Root columns present the information on the root node, while the Total columns present a summary of the information on all of the nodes explored by the branch-and-price-and-cut algorithm. Columns LP time (seconds) and LPC time (seconds), respectively, report the time taken to solve the LP relaxation and the time taken to solve the LP relaxation strengthened by the SR cuts in seconds. Column#Column1gives the number of columns added to the model when the LP relaxation is solved, while column#Column2gives the total number of columns added to the model throughout the search process. The number of SR cuts added to the model is reported in column #SR cut. The last two columns, Total time and #Nodes, give the total running time of the branch-and-price-and-cut algorithm and the number of nodes explored by the branch-and-price-and-cut algorithm, respectively.According to Table 4, when the number of teams in an instance is less than or equal to 10, the instance can be solved to optimality by the branch-and-price-and-cut algorithm rapidly. However, when the number of teams in an instance is greater than 10, the instance becomes very difficult to solve. Meanwhile, the two parameters d1 and d2 have a strong influence on the speed of the branch-and-price-and-cut algorithm. On the one hand, when d1 is fixed, the smaller d2 is, and the easier the instance is to solve. On the other hand, when d2 is fixed, the instance can be easier or harder to solve when d1 becomes smaller. This phenomenon can be explained as follows: when d1 becomes smaller, on the one hand, there are more elements in the label definition, namely (g1, …, gm)t, which results in weaker domination rules and therefore more labels; on the other hand, there are fewer feasible extensions and hence fewer labels are generated. Because of these two effects, when d1 becomes smaller, the instance can be easier or harder to solve, depending on which effect is stronger. When d2 becomes smaller, there are fewer feasible extensions, so the instance usually becomes easier to solve.Tables 5and 6 show the detailed scheduling of the umpires in the optimal solutions of instances “umps14” and “umps14A”. Each cell in the tables represents the game that an umpire is assigned to in each time slot. For example, in Table 5umpire 1 is assigned to game (12 6) in the first time slot, where 12 is the home team and 6 is the guest team.

@&#CONCLUSIONS@&#
