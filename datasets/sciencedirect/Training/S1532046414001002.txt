@&#MAIN-TITLE@&#
A Performance Weighted Collaborative Filtering algorithm for personalized radiology education

@&#HIGHLIGHTS@&#
A performance weighted prediction algorithm is proposed to predict the difficulty level of each case for each trainee.The algorithm assigns an optimal weight to each rating of each trainee to make prediction.The assigned weight to a rating is related to the performance level during which the rating was made.Experiment results show that the algorithm outperforms traditional collaborative filtering algorithms in terms of MAE.The algorithm is a promising method to development of personalized training system in radiology education.

@&#KEYPHRASES@&#
Performance weight,Collaborative filtering,Prediction algorithm,Personalized radiology education,

@&#ABSTRACT@&#
Devising an accurate prediction algorithm that can predict the difficulty level of cases for individuals and then selects suitable cases for them is essential to the development of a personalized training system. In this paper, we propose a novel approach, called Performance Weighted Collaborative Filtering (PWCF), to predict the difficulty level of each case for individuals. The main idea of PWCF is to assign an optimal weight to each rating used for predicting the difficulty level of a target case for a trainee, rather than using an equal weight for all ratings as in traditional collaborative filtering methods. The assigned weight is a function of the performance level of the trainee at which the rating was made. The PWCF method and the traditional method are compared using two datasets. The experimental data are then evaluated by means of the MAE metric. Our experimental results show that PWCF outperforms the traditional methods by 8.12% and 17.05%, respectively, over the two datasets, in terms of prediction precision. This suggests that PWCF is a viable method for the development of personalized training systems in radiology education.

@&#INTRODUCTION@&#
Alleviating variability among radiologists and improving their diagnostic accuracy in the interpretation of radiological imaging has always been a concern [1–4]. A number of existing research results suggest that adequate training is an efficient way to improve the performance of radiologists [5,6]. As a complement to the traditional radiology education, computer-aided radiology training is becoming a popular and efficient approach due to the widespread use of the internet in education, and its ability to overcome the limitations of time, location, and personnel associated with traditional radiology training. There exist a number of services available on the internet from various organizations which provide convenient tools and a substantial amount of training resources to facilitate radiology training, such as MyPACS and SonoWorld [6–9]. However, most of these services suffer from a common limitation; specifically, they, following the one-size-fits-all static training paradigm, present the same content to all trainees without taking into account the needs of different individuals. Consequently, the development of personalized radiology training systems, which would intelligently choose suitable cases for each trainee based on individual performance level and the characteristics of cases, deserve increased attention from researchers since they could make training more efficient, both in terms of time and effectiveness.Personalized radiology education in the interpretation of radiologic imaging has been gaining increased attention from researchers. Some researchers were exploring approaches in development of personalized training systems for mammography, and have made some progresses [10,11]. Mazurowski et al. [10] proposed a framework for an individualized computer-aided mammography training system, which utilizes the concept of user modeling to adapt the training protocol to meet the individual needs of the radiologists in training. In another study conducted by Mazurowski et al. [11], the authors explored the potential of traditional collaborative filtering (CF) in user-adaptive mammography education. These results clearly demonstrated the potential of these methods in the development of adaptive computer-aided educational systems for radiology education.However, the existing approaches suffer from two limitations. One is the small sample size, in terms of the number of observers (10) and the number of cases (30) [10]. Another is that the CF method predicts the difficulty level of unseen cases to a trainee based on the previous ratings made by the trainee or other similar trainees, regardless of the performance level at which these ratings were made. In the CF approach, all of the ratings used for making predictions were weighted equally. In the studies [10,11], the experimental data were collected during a short period of time for testing the hypothesis of the authors, rather than from an actual radiology training program which usually spans a much longer time. Therefore, it might be reasonable to ignore the intermediate performance improvement of trainees in their studies. However, in an actual radiology training program, most trainees can achieve different degrees of improvement in their performance levels along the process. Several research results have shown that the performances of radiologists would improve after dedicated trainings [4,19]. A prediction method that utilizes the previous ratings of trainees to predict their ratings for unseen cases by assigning an equal weight to each rating might make for a less accurate prediction. These methods do not take into account the performance improvement of trainees through training and different rates of improvement between them or cases. For example, a difficult case for a trainee at the beginning of the training may become easier later as he or she advances through training stages. Therefore, to achieve a more accurate prediction, prediction algorithms utilized in radiology education context should consider the performance improvement and the rate of improvement of trainees during the training process. We suggest that a strategy that creates a balance between the outdated ratings given at the previous performance level and the recent ratings at recent performance level would have an important impact on the prediction accuracy of a prediction algorithm in the radiology education domain.The issue of balance among the outdated data and the recent data is also encountered in other domains. For example in E-commerce, a popular strategy of establishing a balance between the outdated data and the recent data is to assign less weights to old data, and greater weights to recent data. Among these methods, the sliding time window and time weighting approaches are widely utilized [12–14]. The conventional variant sliding time window approaches consider only recent instances and give the same significance to all instances within the time window under the consideration, while completely discarding all other instances. Defining a reasonable time window is essential for a sliding time window approach. However, the classic sliding time window approach may not be suitable for balancing the old and recent ratings in the radiology education. In this case, the reason that changes occur in the ratings of a trainee on similar cases, or even identical cases, is mainly due to his or her performance level advancement through training rather than simple time passing. Furthermore, the improvement rate of the performance among trainees varies. For example, some trainees’ performance levels may improve rapidly, while others could advance slowly, and could even stay at the same point for a long time. Therefore, defining performance improvement by using a time window is quite difficult in this situation.In addition, the time weight approach discounts old data at a constant rate proportional to the length of time. Frequently, a time decay function is used, underweighting instances as they move further into the past. However, the selection of a suitable discount rate can be quite difficult. A higher rate would lower the accuracy of the prediction algorithm since it is supported by less training data; and a lower rate would make the algorithm less sensitive to the current trend. Furthermore, in the context of radiology education, the discount rate depends on the performance improvement rates of trainees rather than the time passed. This means that the discount rate should vary between different trainees. The slower that the target trainee’s performance improves, the lower that the discount rate is. Therefore, the approved temporal collaborative filtering methods in other domains, such as time weight or sliding window, may not be applicable to radiology education, despite their success in business applications, such as movie and music recommendation [13,15].Therefore, deciding how to deal with the performance improvements, and to balance between the outdated ratings and the recent ratings, is a challenging issue when designing an accurate prediction algorithm in radiology education. Exploring effective approaches as a support to personalized radiology education is critical.In this paper, we propose a novel algorithm, named Performance Weighted Collaborative Filtering (PWCF), based on the item-based collaborative filtering [16–18]. The main idea of our approach is to find an appropriate weight for a rating based on the performance level at which the rating was made, instead of using the time weight and ignoring the trainee’s performance improvement. The ratings made at more recent performance levels are assigned greater weights, thus having higher impact on the prediction of future behaviors.The remainder of this paper is organized as follows. Section 2 describes the two datasets used in our experiment. Section 3 presents the PWCF algorithm and describes each component of the algorithm in detail. Section 4 presents our experimental work, including evaluation metrics, experiment design, experimental results, and a comparison with a previous method. Section 5 concludes this paper with a summary of the work and a discussion of future research directions.Our experimental data were obtained from two radiology training databases. One is a Mammography Training Dataset that is used for training residents or medical students for the interpretation of mammographic images. The other is a Lung CT Dataset used for training the interpretation of lung CT images that contain pulmonary nodules. Each dataset contains training cases and training process data of trainees.The Mammography Training Dataset was provided by our collaborating hospital. Each case in this dataset was annotated by a mammography expert with over 20years of experience as a teaching professor and a practicing doctor. In each mammography case, the lesion of interest was indicated by a marking circle. The expert was required to assign mammographic BI-RADS (the Breast Imaging Reporting and Data System) features and to assess the likelihood of malignancy of the lesion using a 0–100 probabilistic scale range. The BI-RADS features and their nominal values include mass margin (circumscribed, microlobulated, obscured, indistinct and spiculated), mass shape (round, oval, lobular and irregular), mass density (fat containing, low density, equal density, and high density), and parenchyma density (0–25%, 25–50%, 50–75%, and 75–100%) [21]. Each nominal was assigned an integer value from 1 to 5 that can potentially be used as a reference in numerical analysis by researchers in their related studies. In this paper, the expert’s assessment was used as the “gold standard” to evaluate the diagnostic correctness of the trainees.The lung CT dataset was obtained from the Lung Image Database Consortium (LIDC) [20], an image database resource for the development of computer aided diagnosis methods for lung nodule detection, classification, quantitative assessment, and teaching. For each case in this dataset, four experienced radiologists were asked to outline the boundary of each nodule (the findings), and to assign subjective nodule characteristics according to a comprehensive set of written instructions. The characteristics and their nominal values include internal structure (soft tissue, fluid, fat, or air), calcification (popcorn, laminated, solid, non-central, central, or absent), sphericity (linear, ovoid, or round), margin (poorly, or sharp), spiculation (marked, or no spiculation), subtlety (extremely subtle, or obvious), and texture (non-solid/ground class opacity, part solid/mixed, or solid texture). Each nominal was assigned an integer value from 1 to 5. These nominal values can be used as references in numerical analysis by researchers in their related studies. The radiologists were also required to assess the likelihood of malignancy of each nodule on a 1–5 scale (1: highly unlikely for cancer, 2: moderately unlikely for cancer, 3: indeterminate likelihood cancer, 4: moderately suspicious for cancer, and 5: highly suspicious for cancer). The assessments of cases are subjective, and variability exists across radiologists in the task of lung nodule identification, assessment of nodule features, and rating the likelihood of malignancy of them [22]. We chose only those nodules that are marked by all four radiologists as cases for training tasks. The average of the assessment values from all four radiologists was computed, and the normalized average was used as the “gold standard” of those chosen nodules. The choice of the average value is a commonly used approach to obtain a robust and reliable assessment [11].Our datasets contain also the training process data such as the trainees, the cases, the ratings given by trainees, and the times when the ratings were given. The absolute value of the difference between the assessment of likelihood of malignancy of a lesion (case) by a trainee and the “gold standard” is defined as the difficulty level of the lesion for the trainee. For trainee u and case i, the difficulty level of this case for trainee u can be expressed as:(1)Ru,i=|lu,i-li||R|,where lu,iis the assessment of likelihood of malignancy of case i that trainee u makes, liis the “gold standard” of case i and |R| denotes the rating scale. In this paper, |R| is equal to 1. For example, in Mammography Training Dataset, if the probability that a lesion is malignant in a case assigned by a trainee is 60% and by the “gold standard” is 75%, then the difficulty level of this case for this trainee is 15%. If another trainee’s assessment of the same case is 70%, then the difficulty level of this case for him or her will be 5%.Since our Performance Weighted Collaborative Filtering is based on the item-based collaborative filtering [16–18], it is first described in detail below.The goal of collaborative filtering (CF) is to suggest a new item or to predict the utility of a certain item for a particular user based on the user’s previous behaviors. The item-based CF is a main category of CF algorithms. Its fundamental assumption is that if a set of items is similar, a particular user will rate these similar items similarly. For radiology education, if a set of lesions is similar in terms of appearance features, then a trainee will likely rate them similarly. These days, item-based CF algorithms are widely used in the domain of E-commerce and have become one of the most successful approaches in the development of recommendation systems [17,18]. In a typical item-based CF scenario, there is a list of m users, U={u1, u2, …, um}, and a list of n items, I={i1, i2, i3, …, in}. Each user, ui, has rated a list of itemsIui.For a given user, ua∊U, called the active user, the objective of a CF algorithm is to find a numerical value, Pa,jexpressing the predicted likeness of item j for user a. This predicted value is in the same scale as the opinion values provided by user a.Fig. 1shows a schematic diagram of a typical item-based CF process. A user-item rating matrix and an item feature matrix are the input data of an item-based CF algorithm. The user-item rating matrix represents the ratings of users to items. As shown in Fig. 1, each entry ai,jin the m×n rating matrix, A, represents the rating of the ith user on the jth item. Each entry Ii,jin the n×l item feature matrix, I, represents the jth features of the ith item. To generate the prediction of item i for user a, two process steps are performed: (1) the similarity between items and the target item is computed, and the k most similar items {i1, i2 … ik} are chosen; (2) the prediction is computed by taking a weighted average of the target user’s ratings over these similar items. When the above definition is mapped to the context of radiology training, the user is the trainee, the item will be the case, and the rating is the user’s assessment of the case. In other words, the rating is defined as the difficulty level of an item for a certain user. The similarity computation and the prediction generation are described in detail as follows.Computing similarity between items and then selecting the most similar items is a major step in item-based CF algorithms. There are a number of different approaches to computing the similarity between items, such as correlation-based similarity and cosine-based similarity.In this paper, we use a cosine-based similarity computation method to measure the similarity of two items. In this situation, each item is thought of as a vector in the item space, and the similarity between two items is measured by computing the cosine angle between two vectors representing the two items. Formally, the similarity between item i and j, denoted by Sim(i, j) is given by Eq. (2), namely(2)Sim(i,j)=cos(Fi,Fj)=Fi·Fj‖Fi‖‖Fj‖=∑k=1mFik×Fjk∑k=1m(Fim)2×∑k=1m(Fjm)2,where “·” denotes the dot-product of the two vectors and Fi is the feature vector of item i. For example, if m equals 3, and the vector Fi={x1, y1,z1}, Fj={x2, y2, z2}, then the vector cosine similarity between item i and j isSim(i,j)=x1x2+y1y2+z1z2x12+y12+z12x22+y22+z22.In this paper, the lesion appearance descriptors are used as features of each item, and the corresponding integer values of the “gold standard” are normalized as the feature values.Generating predictions is the most important step in a CF algorithm. Once a set of the most similar items to the target item are chosen, based on the similarity measure, the next step is to look through the active user ratings and to apply a prediction technique to obtain predictions. Weighted sum and regression are two commonly used techniques. We used the weighted sum approach because of its simplicity. This method computes the prediction of item i for user u by computing the sum of the ratings given by the user among the items similar to item i. Each rating is weighted by the corresponding similarity, Sim(Ii, Ij), between item i and item j. Formally, the prediction, denoted by Pu,i, is given by:(3)Pu,i=∑j=1k(Ru,j·Sim(Ii,Ij))∑j=1kSim(Ii,Ij),where Pu,iis the predication of item i for user u, k is the number of most similar items to item i rated by user u, and Ru,jis the rating on item j rated by user u.As described above, in a traditional item-based CF algorithm, ratings made by a user at different performance levels are weighted equally. In other words, the prediction computation does not take into account the performance level of the user at which the ratings are given. However, in radiology education, the performance level of most users will improve either gradually or rapidly through training. If a CF method utilizes the outdated ratings of users to predict their future ratings regardless of the performance level at which the ratings are given, then it could degrade the prediction accuracy. For example, Table 1shows the ratings of user u to items {i1, i2, i3, i4, i5, i6} and the time that the ratings were given. The items {i1, i2, i3, i4, i5, i6} are the most similar items to item, i. Table 2shows the similarities between these items. In order to predict the rating of user u and item i, according to the traditional CF algorithm, the prediction, Pu,i, is given by Eq. (3), that isPu,j=∑i=1k(Ru,i·Sim(Ij,Ii))∑i=1kSim(Ij,Ii))=0.81×0.7+0.90×0.69+0.88×0.55+0.79×0.42+0.99×0.22+0.89×0.220.81+0.90+0.88+0.79+0.99+0.89≈0.47.A value of 0.47 means that the difficulty level of item i for user u is 47%. That is to say, the likelihood of making an error when it comes to item i by user u is 47%. However, from Table 1, it can be seen that the performance level of user u improved as time went on, and the prediction value of 0.47 may therefore be unreasonable. The reason for the unreasonable prediction is that the traditional item-based CF algorithms do not take into account the fact that users’ performance level has improved through training. In fact, a user would give markedly different ratings for similar items, even for the same item, due to his or her different performance levels at which the ratings are given. In this case, the ratings of a user are related to his or her performance level. Therefore, the ratings given by a user at different performance levels should be modified by additional adjustment weights to reflect their influence on predicting future ratings. As discussed above, the ratings given at the recent performance level should contribute more to the prediction of future ratings, and the ones at outdated performance levels should contribute less to the prediction. In our new approach, an additional adjustment weight will be assigned to each rating based on the prediction computation of traditional CF algorithms. The adjustment rating weight represents its influence on prediction. Therefore, the Eq. (3) is modified as:(4)Pu,i=∑j=1k(Ru,j·Sim(Ii,Ij)·Wu,j)∑j=1kSim(Ii,Ij)·Wu,j,where Wu,jrepresents the adjustment weight assigned to the rating of user u on item j.To define appropriate weights, the conventional variant sliding time window approaches and the time weight methods were carefully considered. The sliding window methods consider only recent ratings and give the same significance to all ratings within the considered time window, while completely discarding all other instances. The time weighted algorithms use a time decay function to discount old data at a constant rate. For sliding time window approaches, the challenge is one of computing the width of the sliding time window. A wider time window is less sensitive to the current trend; on the other hand, a narrower time window might discard valuable ratings and potentially lead to a lower accuracy of prediction. Furthermore, the ratings made by users are related to their performance levels rather than time. For time weight methods, it is a problem of determining how to find an optimal time function to represent the discount rate of data, a task that is quite difficult. It is the performance level improvement that leads to changes in users’ ratings for similar items, or even identical items, rather than the simple passage of time. So, a solution that reflects the performance level of users is more reasonable than the one that reflects the time for achieving accurate predictions. Therefore, we suggest that the weight Wu,jshould be a function of the performance level of the users. The value of the weight should be in the range [0, 1], and the weights of ratings given at the most recent performance level is equal to 1. That is, a rating given in a user’s recent training session will be assigned a greater weight; otherwise, it is given a lower weight. Specifically, for a certain user, the adjustment weight of a rating can be approximated by the deviation of the performance level at which the rating was given from the user’s most recent performance level. The performance level at which a rating was given can be defined as the likelihood of a correct assessment of an item using the rating. So, we defined Wu,jas:(5)Wu,j=1-|PEu,j-PEu,c||R|α,where |R| represents the scale of the performance level and is equal to 1 in our experiment, and α is a tuning parameter. The PEu,jrepresents the performance level of user u when he or she rated item j. The PEu,crepresents the most recent performance level of user u. Here, PEu,jcan be expressed as:PEu,j=1-Ru,j,and PEu,ccan be expressed as:PEu,c=1-Ru,c,where Ru,crepresents the rating of item c, which is the most recent rating among all of the nearest neighbors of the target item for user u. So, the Wu,jcan be described as:(6)Wu,j=1-|PEu,j-PEu,c||R|α=(1-|Ru,c-Ru,j|)α.The following example demonstrates how to compute the value of Pu,iusing Eq. (4). To predict the rating of user u for item i at time Tn, the adjustment weights of items can be computed using Eq. (6). Table 3shows the results of adjustment weight computation for different values of α.The value of Pu,ican be computed using Eq. (4). For example, for α=2,Pu,i=∑j=1k(Ru,j·Sim(Ii,Ij)·Wu,j)∑j=1kSim(Ii,Ij)·Wu,j=0.7×0.81×0.27+0.69×0.90×0.281+0.55×0.88×0.449+0.42×0.79×0.64+0.22×0.99+0.22×0.890.81×0.27+0.90×0.281+0.88×0.449+0.79×0.64+0.99×1+0.89×1≈0.36,for α=3, Pu,i=0.32, and for α=5, Pu,i=0.26. It can be observed that the accuracy of a prediction using our PWCF algorithm can be tuned using the parameter α to achieve an optimal result, as will be shown later in this paper.In radiology education, it is possible for an item to be rated multiple times by a user. The question of how to deal with multiple ratings for the same item by a user is an issue that must be addressed. The method of using the latest rating was employed in our paper, following the assumption that the performance level of a user will generally improve over time.There are several types of measurements for evaluating the quality of a prediction algorithm. Mean Absolute Error (MAE) between ratings and predictions is a widely used metric and, thus, was used in our study. MAE measures the deviation of predictions from their true user-specified values. For each ratings-prediction pair 〈ri, pi〉, MAE computes the absolute error between them. First, this metric is computed by summing the absolute errors of the N corresponding rating–prediction pairs and then computing the average. Formal1y,(7)MAE=∑i=1N|ri-pi|N.The lower the MAE, the more accurate the prediction of the users’ ratings.Experiments involving two datasets were conducted to examine the effectiveness of our newly proposed approach. Specifically, the PWCF was compared with the traditional item-based CF.The Mammography Dataset described in Section 2 was collected from a mammography training system, which is a part of continuing education for radiology residents in a hospital with which we have a collaborating relationship. The mammography training data were collected from July 2012 to December 2012. During the six month period, 300 trainees rated 5000 mammography cases. The Lung CT data were collected from April 2012 to July 2012. During this period of four months, 80 trainees rated 800 cases a total of 2000 times. The global statistics for these two datasets are shown in Table 4.In our experiments, 200 trainees from the Mammography Dataset and 70 trainees from the Lung CT Dataset, respectively, were selected randomly. All of them participated in their training programs from beginning to end. The 10 latest rated cases were reserved for the purpose of evaluation of prediction for each selected trainee. Both the traditional item-based CF algorithm and our PWCF were tested with these withheld cases. In all experiments, the nearest neighbors were selected using a threshold of 0.6. The value of this threshold was determined empirically. If the similarity score between two cases is higher than 0.6, then we consider these two cases to be similar. The parameter α was assigned a value of 3. The MAE metric was used to evaluate and compare the performances of the traditional item-based CF and our PWCF algorithm. The MAE of each of test trainees over the two datasets, as well as each individual test trainee, was computed separately.

@&#CONCLUSIONS@&#
