@&#MAIN-TITLE@&#
The Partitioning Min–Max Weighted Matching Problem

@&#HIGHLIGHTS@&#
We introduce the Partitioning Min–Max Weighted Matching Problem (PMMWM).PMMWM combines a maximum matching and a partitioning problem.Applications arise in the field of intermodal container terminals and sea ports.We prove strong NP-hardness of PMMWM.We present two heuristic frameworks and an extensive computational study.

@&#KEYPHRASES@&#
Assignment,Partitioning,Maximum matching,Bipartite graph,Container transshipment,

@&#ABSTRACT@&#
We introduce and analyze the Partitioning Min–Max Weighted Matching (PMMWM) Problem. PMMWM combines the problem of partitioning a set of vertices of a bipartite graph into disjoint subsets of restricted size and the strongly NP-hard Min–Max Weighted Matching (MMWM) Problem, that has recently been introduced in the literature. In contrast to PMMWM, the latter problem assumes the partitioning to be given. Applications arise in the field of intermodal container terminals and sea ports. We propose a MILP formulation for PMMWM and prove that the problem is NP-hard in the strong sense. Two heuristic frameworks are presented. Both of them outperform standard optimization software. Our extensive computational study proves that the algorithms provide high quality solutions within reasonable time.

@&#INTRODUCTION@&#
In this paper we consider a variant of the strongly NP-hard Min–Max Weighted Matching (MMWM) Problem, that has recently been introduced by Barketau, Pesch, and Shafransky (2015). An instance of MMWM is defined by an edge-weighted bipartite graph G(U, V, E) with disjoint vertex sets U and V (bipartitions), edge set E, and a partitioning of U into disjoint subsets (components). Given a maximum matching on G, the weight of a component is defined as the sum of the weights of the edges of the matching that are incident to the vertices of the component. The objective is to find a maximum matching that minimizes the maximum weight of the components. The components may, for example, correspond to areas of responsibility of managers or tasks to be performed by a worker or machine. The objective is to balance the workload, risk, etc. over these components.While Barketau et al. (2015) assume the components to be fixed, we relax this assumption by assuming the partitioning decision to be part of the optimization, with only the desired number of components being fixed. We refer to this problem as the Partitioning Min–Max Weighted Matching (PMMWM) Problem. Fig. 1 illustrates an exemplary solution to an example instance of PMMWM. The maximum matching is represented by bold edges. Edge weights are solely depicted for the edges of the matching. BipartitionU={u1,…,u7}has been partitioned into the components U1, U2 and U3 with weights 6, 9 and 4, respectively. Hence, the corresponding objective function value of the PMMWM instance ismax{6,9,4}=9. If we move u4 to U3 without changing the matching, the objective function value reduces by 1.This paper is organized as follows. In Section 2 we provide a detailed problem description along with a MILP model of the problem. We present two applications of PMMWM in the context of a reach stacker based container terminal and a rail-road terminal. Next, a proof of the problem’s strong NP-hardness is given in Section 3. Section 4 introduces two heuristic frameworks that are being analyzed based on computational tests in Section 5. In Section 6, we summarize the findings of this paper.Let G(U, V, E) be a weightedbipartite graph with bipartitions U and V and edge set E. The elements of U and V are indexedi=1,…,n1andj=1,…,n2,respectively. Assume n1 ≤ n2. A weightc(e)=cuv∈Q0+is associated with each edgee=(u,v)∈Eof G. Define a matching as a set M⊆E of pairwise nonadjacent edges and a maximum matching as a matching having the largest possible size |M| amongst all matchings on G. Throughout the paper, we will assume that, for any given bipartite graph, there exists a maximum matching Π with|Π|=n1. As in Barketau et al. (2015), given a partitioning of U into m disjoint subsets,U1,U2,…,Um,the value of a maximum matching Π is defined to bew(Π):=maxk∈{1,…,m}{∑u∈Uk,(u,v)∈Πcuv}(refer to Fig. 1 for an illustration). Then PMMWM can formally be defined as follows: find a partitioning of the vertex set U into m (potentially empty) disjoint subsets,U1,U2,…,Um,with at mostu¯elements in each subset, and a maximum matching Π on G, such that the value of Π is minimum amongst all maximum matchings over all possible partitionings of U.We define the following binary variables:(1)xij:={1if(i,j)∈Π,0else,∀(i,j)∈Eand(2)yik:={1ifi∈Uk,0else,∀i∈U,k∈{1,…,m}.Then a nonlinear mathematical model for PMMWM is as follows:(3)minx,ymaxk∈{1,…,m}{∑i∈U∑j∈Vcijyikxij}(4)s.t.∑j∈Vxij=1∀i∈U,(5)∑i∈Uxij≤1∀j∈V,(6)∑k=1myik=1∀i∈U,(7)∑i∈Uyik≤u¯∀k∈{1,…,m},(8)xij∈{0,1}∀(i,j)∈E,(9)yik∈{0,1}∀i∈U,k∈{1,…,m}.The objective function (3) minimizes the value of the maximum matching over all possible partitionings and all maximum matchings. Constraints (4)–(5) are well known maximum matching constraints (recall that n1 ≤ n2). Constraints (6) enforce every vertex u ∈ U to be an element of exactly one partition Uk,k∈1,…,m. Constraints (7) restrict the number of vertices in each partition to be at mostu¯. The domains of the variables are defined by (8)–(9).A specific application of PMMWM arises at small to medium sized sea ports where containers are handled by reach stackers. The corresponding terminals, as schematically represented in Fig. 2, can include large long-term storage areas and additional temporary storage areas (or marshaling-areas; see, for instance, Preston & Kozan, 2001; Kozan & Preston, 1999). The latter areas aim at improving the performance of the terminals by inducing short turnaround times of vessels when distances to long-term storage areas are relatively large. When a vessel arrives at a berth at the terminal, containers are unloaded by quay cranes and then stored in a temporary storage area that is located next to the berth. Containers that leave the terminal by ship are moved to the temporary storage area using reach stackers during previous idle times. We will assume that these vehicles are “fast” if they are unloaded and “slow” if they are loaded and can thus restrict ourselves to considering the movements of loaded vehicles only. This is a common assumption when considering container movements (see, for instance, Boysen & Fliedner, 2010) and is supported by the fact, that “reach stackers [in comparison to straddle carriers] are less stable in the forward direction as the machines will fall forward when breaking in an emergency, particularly if the load is carried high for visibility reasons” (Isoloader, 2012). Then an application of PMMWM arises, when considering the process of emptying or refilling the temporary storage area during idle times. We are faced with the problem of assigning each container in the temporary storage area to an empty slot in the long-term storage area (or vice versa) and assigning the corresponding container movements to a limited number of available vehicles. Consider, for example, the case of filling the temporary storage area with containers of the long-term storage area. The vertex set U corresponds to the set of containers that have to be moved. Bipartition V relates to the set of empty slots in the temporary storage area. The edge weights cuvinclude multiple effects. First, they obviously result from the distances between container locations and their potential temporary storage slots. In addition, the weights include a (potentially container dependent) amount of time needed to lift and drop a container by a reach stacker. Furthermore, it is possible to represent different velocities of loaded vehicles, for example depending on the movement of heavy, sensitive, or empty containers. The parameter m represents the number of available reach stackers.u¯represents an upper bound on the maximum number of containers that a reach-stacker may process. A solution is on one hand composed of an assignment of each container to an empty storage slot, i.e. a maximum matching, and on the other hand of an assignment of container movements to the available vehicles, i.e. a partitioning of U into at most m components. Naturally, the objective is to perform all movements as fast as possible by balancing the workload over the available reach stackers.Applications of PMMWM may also arise when considering container transshipment in rail-road terminals (cf. Boysen, Fliedner, Jaehn, and Pesch (2013), for a survey) and can thus be motivated in analogy to Barketau et al. (2015), who point out that an “interesting direction of [...] research is the case when the components are not fixed and the decision on their sizes is a part of the problem”. A schematic representation of a classical layout of such terminals is given in Fig. 3 (Boysen & Fliedner, 2010; Boysen et al., 2013). The terminal consists of a given number of parallel railway tracks, a container storage area (intermediate storage) including a fully automated sorting system, and truck lanes. Each of these areas is subdivided into segments, usually referred to as slots, that are adjusted to the length of a standardized railcar. Multiple gantry cranes, spanning over these areas, transfer containers between trucks and railcars. In mathematical models, workloads of the cranes are typically approximated by only considering laden movements. Trains are usually served in bundles. A bundle leaves the terminal after all corresponding transshipment operations have been performed. In a classical setting, the gantry cranes may not cross each other. However, one can easily think of a potential (not yet existent) layout of rail-road terminals with gantry cranes being able to pass one another, as such systems can, for example, frequently be found at sea terminals (Kemme, 2012). To extract the most basic problem setting, we assume that these cranes are always able to pass one another (as opposed to modeling more complicated passing rules). In such a case, an application of PMMWM is straight forward: given a set U of containers to be transferred to potential target slots V by m gantry cranes, one has to find a specific assignment of containers to slots, i.e. a maximum matching, and a partitioning of U into m components representing the container movements to be performed by the different cranes, such that the workload of the cranes is “balanced”. Obviously, the edge weights of the corresponding bipartite graph represent workloads of laden movements. Let us now consider the classical layout of rail-road terminals, i.e. the case of the gantry cranes not being able to pass one another. One way of handling the non-passing restrictions is to horizontally subdivide the terminal into crane areas, each being exclusively processed by one of the gantry cranes. Any container transport between the areas is performed using the sorter. The planning process at such rail-road terminals can then be thought of as a sequential process. Two subsequent decisions in this process are concerned with the formation of crane areas followed by the assignment of containers to target slots, where a container stored in a specific crane area has to be operated by the area-specific crane to perform the movement of the container to its assigned target slot. When adding additional restrictions, PMMWM integrates these decisions, with containers U having to be partitioned into m (number of gantry cranes) components (i.e. crane areas), and target slots V having to be assigned to the containers (maximum matching). Again, the edge weights of the corresponding bipartite graph represent the cost of laden movements and we aim for the workloads of the cranes being “as similar as possible” (minimax objective of PMMWM). However, additional restrictions will, for example, need to enforce elements of partitions to be “neighbored” (i.e. crane areas to be connected). In addition, appropriate penalty costs will have to account for transferring containers between crane areas using the sorter.We close this section by noting that model (3)–(9) can easily be linearized by introducing additional variables zijk≥ 0 for all i ∈ U, j ∈ V andk∈{1,…,m}(10)minx,yc(11)s.t.constraints(4)--(9),c≥∑i∈U∑j∈Vcijzijk∀k∈{1,…,m},(12)zijk≥yik+xij−1∀i∈U,j∈V,k∈{1,…,m},(13)zijk≥0∀i∈U,j∈V,k∈{1,…,m}.It is easy to see that if we fix m to one in PMMWM, i.e. if we consider the case of having exactly one component, we are left with the well-known problem of finding a maximum matching of minimum weight in a bipartite graph, which is equivalent to the Linear Assignment Problem and can thus be solved in polynomial time (see Section 4). The special case of PMMWM where the number of components m is equal to |U| is known as the Linear Bottleneck Assignment Problem (cf. Burkard, Dell’Amico, & Martello, 2009, and the references therein). It is polynomially solvable as well. In particular, it can be solved by the threshold method inO(n2n/logn)time. The Weighted Edge Dominating Set Problem is similar to PMMWM with one component but for arbitrary graphs. It is NP-hard and admits a 2-approximation.Now note that PMMWM is not a straight forward generalization of MMWM in the sense that, given an instance I of MMWM, we need only “copy” the corresponding bipartite graph, fix a set of PMMWM parameters to specific values, and solve the resulting PMMWM instance to receive an optimal solution to I. More generally, it is not trivial to construct an instance of PMMWM that (when solved to optimality) is guaranteed to result in the partitioning given in I and thus to provide an optimal solution to I. Thus, MMWM is not simply a subproblem of PMMWM. In MMWM the components of U are fixed and are not necessarily equal in size while PMMWM only imposes an upper bound on the size of the components. Moreover, the fact that the number and the elements of the (non-empty) components of U are a result of the optimization consequently leads to a higher flexibility and a larger search space that does not necessarily contain all solutions of MMWM (even if m is chosen appropriately), unlessu¯is sufficiently large. Thus we cannot simply conclude that PMMWM is NP-hard from the NP-hardness of MMWM.A formal proof of strong NP-hardness of PMMWM, which we will now provide, is more naturally based on a reduction of a classical partitioning problem than on a matching problem.We will consider the decision problem related to PMMWM.Definition 3.1PMMWM-DGiven a weighted bipartite graph as defined in Section 2. Does there exist a partitioning of the vertex set U into m (potentially empty) disjoint subsets,U1,U2,…,Um,with at mostu¯elements in each subset, and a maximum matching Π on G, such that the value of Π is no larger than a givenω∈Q+?The proof is based on a reduction of the strongly NP-complete 3-Partition Problem (see Garey & Johnson, 1979).Definition 3.23-PartitionGiven a set A of 3k elements, a boundB∈Z+,and sizess(a)∈Z+for all a ∈ A such thatB4<s(a)<B2and such that∑a∈As(a)=kB. Is there a partitioning of A into k disjoint subsetsA1,…,Aksuch that, for 1 ≤ i ≤ k,∑a∈Ais(a)=B?PMMWM-D is NP-complete in the strong sense.Obviously PMMWM-D ∈ NP because for any partitioning and maximum matching it can be checked in polynomial time if the corresponding value is no larger than ω.Now consider an arbitrary instance I of 3-Partition and construct a complete bipartite graph G as an instance J of PMMWM-D withU=Aand vertex set V such that|V|=|U|. Furthermore, for each u ∈ U, define the weights of all edges incident to u in G to be equal to the corresponding element’s size s(a), a ∈ A. Setm=k,u¯=3,andω=B. Now note that, given an arbitrary partitioningU1,…,Umof U, every maximum matching has the same value. We are left with the task of showing that there exists a partitioningU1,…,Umof U and a maximum matching Π with a value of no more than ω if and only if the answer to I is yes (we will say that I “has a solution” if its answer is yes and call a corresponding partitioning of A a “solution”).Suppose we are given a solutionA1,…,Akto I. Construct a partitioningU1,…,Umof U such that subset Uicontains all vertices that correspond to elements of Aifor alli=1,…,m,and consider any maximum matching on G. It is immediately implied that the value is ω.Suppose we are given a partitioningU1,…,Umof U and a maximum matching Π such that its value is no more than ω. Asu¯=3and|U|=3m,we necessarily have|Ui|=3for alli=1,…,m. Now note that as the sum of the edge weights of any maximum matching on G equals mω and the value of Π is at most ω, we have∑u∈Ui,(u,v)∈Πcuv=ωfor alli=1,…,m. Hence, the subsets of A that correspond to the given partitioning of U establish a solution to I.□We conclude:Corollary 3.1PMMWM is NP-hard in the strong sense.PMMWM can be considered as a combination of a matching and a partitioning problem. Hence, a natural way of constructing heuristics for PMMWM is to decompose the problem into its matching and partitioning components, solve the resulting problems separately (either exact or heuristically), and combine the resulting solutions to a solution of PMMWM. Obviously, we can construct different heuristics by changing the order of solving the separate stages.Partition–Match heuristics assume that there is a vertex weight associated with each element of vertex set U and, in the first stage, partition U into no more than m components with at mostu¯elements in each component, such that the maximum weight of the components is as small as possible. Here, the weight of a component is defined as the sum of the weights of the vertices of the component. When considering the objective of minimizing the maximum weight of the components, we refer to this problem as the Restriced Partitioning (RP) Problem.We note:Theorem 4.1RP is NP-hard in the strong sense.As the proof of Theorem 4.1 is in analogy to the proof of Theorem 3.1 and Corollary 3.1, we will not present it in detail for the sake of brevity.In the next stage of a Partition–Match heuristic, we drop the weights of the vertices. Given the components resulting from the first stage, we now need to determine a maximum matching of small value. Hence, we are faced with an instance of MMWM. Solving this problem results in a maximum matching, that we may use for restarting the overall procedure by solving RP with each vertex weight being equal to the weight of the edge of the maximum matching that is incident to the very vertex. Fig. 4 illustrates the idea of Partition–Match heuristics.Match–Partition heuristics (see Fig. 5) first consider the classical problem of finding a maximum matching of minimum weight, i.e. minimum sum of the weights of all edges of the matching, which we refer to as the Min-Sum Weighted Matching (MSWM) Problem. MSWM can be solved in polynomial time, for example inO(n3)(where n ≔ max {n1, n2}) by applying the well known Hungarian algorithm (cf. Kuhn, 1955; Burkard et al., 2009). Hereafter, we proceed in analogy to our approach in Partition–Match heuristics, i.e. by defining vertex weights based on the maximum matching and solving RP. Finally, we modify the edge weights of the bipartite graph to restart the procedure by solving MSWM on the modified graph.We will present details on the algorithms in the next subsections. Section 4.1 is concerned with solving RP. Heuristics for solving MMWM are presented in Section 4.2. Hereafter, we will present details of Partition–Match and Match–Partition heuristics in Sections 4.3 and 4.4.As stated in Theorem 4.1, RP is NP-hard in the strong sense. We therefore apply a heuristic algorithm when facing an instance of RP in Partition–Match or Match–Partition heuristics. As RP is similar to the well known Multiprocessor Scheduling Problem, that has been extensively studied in the literature (see, for example, the literature review by Chen, Potts, and Woeginger (1999)), our approach adapts ideas of Lee and Massey (1988), who present a heuristic for the latter problem, in its first stage.An instance of RP is defined by a set U,|U|=n1,of elements (vertices) with weightswi∈Q+,i ∈ U, an upper boundu¯,corresponding to the maximum number of elements in each component, and an upper bound m, defining the maximum number of components. The objective is to find a feasible partitioning of U, such that the maximum weight (as defined above) of the components is minimized. A partitioning is feasible, if and only if it consists of no more than m components with each component containing at mostu¯elements.Our heuristic, denoted by RPH, is composed of two stages. First, we construct a feasible solution as follows: Let U′ be the elements of U sorted in non-increasing order of their weights and initialize m empty componentsU1′,…,Um′. Select an element with largest weight from U′ and add it to a component with the smallest weight among all components with less thanu¯elements. The stage ends when U′ is empty.The next stage is a local search on the obtained solution(U1′,…,Um′). Denote the weight of componentUi′,i∈{1,…,m},byw(Ui′). SelectUmin′∈arg minUi′,i∈{1,…,m}w(Ui′)andUmax′∈arg maxUi′,i∈{1,…,m}w(Ui′)and sort the elements of these sets in non-decreasing order and non-increasing order of their weights, respectively. Letuimaxbe the i-th element of the sorted componentUmax′anduiminthe i-th element of the sorted componentUmin′. Next, select one element ofUmax′after another, starting withu1max,and interchange it with a setS={uimin,…,ujmin|1≤i≤j≤|Umin′|}of elements of componentUmin′,if the interchange results in feasible components and reduces the difference|w(Umax′)−w(Umin′)|. If an interchange has been performed, restart the local search. Otherwise, if we cannot find a suitable set S for any element ofUmax′,stop the local search.We apply two heuristics for solving instances of MMWM. First, we implemented an approximate algorithm that has been developed by Barketau et al. (2015) when introducing MMWM. We will refer to this algorithm as the BPS heuristic. Basically, the algorithm enumerates over a set of m multipliers that are applied to modify edge weights of the bipartite graph. For each modified problem instance, the corresponding MSWM instance is solved by applying the Hungarian algorithm. The resulting matching is then used to compute the corresponding objective function value of MMWM. BPS then chooses the best three solutions and tries to improve them by a local search procedure. We will refer to this local search procedure as LS. For details of the implementation, we refer to Barketau et al. (2015).While Barketau et al. (2015) show BPS to be an adequate method for solving MMWM alone, we implemented another, rather simple, heuristic. This is motivated by the fact that when calling a Partition–Match heuristic, we have to solve multiple instances of MMWM. Hence, in order to reduce running times of the overall procedure, a simple heuristic seems to be promising. As the approach is based on the regret principle (cf., for instance, Domschke & Scholl, 2005), we refer to it as the REG heuristic. We say that an edge belongs to a component, if it is incident to a vertex of the (given) component.REG starts by initializing an empty matchingM=∅. For each componenti=1,…,mof the partitioning, REG then determines the cheapest and second-cheapest edge,e1iande2i,amongst the edges of the component that are not yet incident to matched vertices of the bipartite graph. The difference of the related edge weights determines the regret valueregi=c(e2i)−c(e1i)for each componenti=1,…,m. If all but one (e1i) edges of a componenti∈{1,…,m}are incident to a matched vertex, setregi=L−c(e1i),where L is a sufficiently large number. If no edge of a componenti∈{1,…,m}remains incident to an unmatched vertex, setregi=−1. Next, choose a component c with the largest regret amongst all components and add edgee1cto M. Repeat the procedure untilregi=−1fori=1,…,m. If the corresponding matching is not maximum, determine an augmenting path and augment M by applying the procedure described by Burkard et al. (2009, Chapter 4, Algorithm 4.2). Hereafter, if M is maximum, then stop. Otherwise continue with computing regret values.To initialize a Partition–Match heuristic (see Fig. 4), we generate (vertex) weights that are necessary for partitioning the vertex set U by RPH (Section 4.1). We tested several strategies of generating these weights. As they all performed similarly in computational tests, we decided on applying the average weight of all edges incident to vertex u for each vertex u ∈ U.Once we have generated the initial weights for each vertex u ∈ U, we enter the main loop of Fig. 4. As described above, this loop consists of three stages. First, solve RP based on the vertex weights that have been generated. Here, we apply RPH. Second, solve MMWM based on the resulting partitioning. We tested both of the heuristics described in Section 4.2, i.e. BPS and REG, to solve MMWM. When calling REG, we apply the local search procedure LS (see Section 4.2) to potentially improve the solution found by REG (note that BPS applies LS to three solutions). Third, generate new vertex weights based on the current maximum matching as described above. To avoid cycling of the algorithm, we monitor the best known solution of the PMMWM input-instance, being composed of the solutions of RP and MMWM. If there has been no improvement for 20 iterations of the main loop, we stop the Partition–Match algorithm.We will refer to the Partition–Match heuristic as described in this section as PMBPSwhen applying BPS. When calling REG (including LS), we will refer to the resulting Partition–Match heuristic as PMREG.As described above, Match–Partition heuristics differ from Partition–Match heuristics in the subproblems that need to be solved. Again, the main loop (see Fig. 5) is composed of three stages. First, we transform the PMMWM input-instance into an instance of MSWM by dropping the partitioning constraints. To solve the resulting instance of MSWM, we apply aO(n3)(again n ≔ max {n1, n2}) version of the Hungarian algorithm as presented by Burkard et al. (2009). Given the matching generated in the first stage, we generate an instance of RP by assigning to each vertex u ∈ U the weight of the edge incident to u in the obtained matching. As before, the combination of the solutions of the first two stages define a solution of the PMMWM input-instance. As we may apply LS (see Section 4.2) to potentially improve this solution, we will refer to our Match–Partition heuristic as MP if LS is not used and MPLSif LS is used. If the resulting solution to PMMWM has not improved for 20 iterations, we stop the Match–Partition heuristic. In the third stage, we alter the weights of the edges of the bipartite graph. We apply a simple transformation strategy, that increases the weight of exactly one edge e ∈ E in each iteration of the main loop. The selection of edge e depends on the current solution of the PMMWM input-instance: select the component with the largest weight. Among the current edges of the matching that are incident to vertices of this component, select the one with largest weight. Then, set the weight of this edge to a large value (we set the weight to 102 · cmax, where cmaxis the largest edge weight of the input graph, in our computational tests) to reduce the probability that it will be part of the solution of the altered MSWM instance. After λ iterations of the main loop, restore the original edge weight of edge e. Our computational tests show thatλ=⌈0.1·n1·n2⌉is a reasonable value. Note that the perturbed edge weights are only used for the matching problem in stage one. The vertex weights assigned in stage two are based on the original weights of the input graph.In order to assess the performance of the algorithms introduced in Section 4, we ran extensive computational tests. All computational tests were performed on an Intel Core i7 mobile CPU at 2.8 gigahertz and 8 gigabyte of RAM, running Windows 7 64 bit. All algorithms were implemented in C++ (Microsoft Visual Studio 2010). We used IBM ILOG CPLEX in version 12.5 with 64 bit.In order to get a comprehensive overview of the performance of our algorithms, we use different strategies of generating instances. All instances are defined on bipartite graphs withn1=n2,since the case n1 ≠ n2 trivially reduces to the casen1=n2by adding edges of zero weight. We definen:=n1=n2.The first strategy of generating instances is inspired by Barketau et al. (2015). We refer to the instance sets generated by this strategy as BPS70 and BPS80. We generate n2 rational numbers uniformly distributed in the interval [1, 1000] and a complete bipartite graph with vertex setsU={u1,…,un}andV={v1,…,vn}. We sort the numbers in non-decreasing order and denote the resulting list by L. Hereafter, we consecutively assign these numbers (as edge weights) to the edges in the following manner: we start with vertex v1 and assign the first ⌊0.8n⌋ (in case of BPS80) or ⌊0.7n⌋ (in case of BPS70) elements of L to the edges(u1,v1),(u2,v1),…,(u⌊0.8n⌋,v1)(BPS80) or(u1,v1),(u2,v1),…,(u⌊0.7n⌋,v1)(BPS70) and remove them from L. For the remaining edges being incident to vertex v1, we randomly choose and assign elements of L. Once an element of L has been assigned, we remove it from L. The procedure is repeated for all remaining vertices v ∈ V, v ≠ v1.The second strategy of generating instances constructs complete bipartite graphs and randomly determines and assigns edge weights uniformly distributed in the interval [1, 1000]. We refer to instances generated by this strategy as RAND.Besides BPS70, BPS80, and RAND, all of which are based on complete bipartite graphs, we generate instances defined on non-complete (or sparse) bipartite graphs with|E|=⌈0.7n2⌉or|E|=⌈0.8n2⌉. We refer to them as SPARSE70 and SPARSE80, respectively. When generating the edges, we guarantee that there exists at least one feasible solution for the resulting PMMWM instance (cf. restrictions (4)). Again, edge weights are determined randomly and uniformly distributed in the interval [1, 1000].For each strategy of generating instances, BPS70, BPS80, RAND, SPARSE70, and SPARSE80, we construct instances based on different parameter settings. We vary the size of the bipartitions from 10 to 190, i.e.n=10,30,…,190. Furthermore, we set m to 2, and (if larger than 2) to ⌊0.04n⌋, ⌊0.08n⌋ or ⌊0.125n⌋. Similarly, we setu¯to⌈nm⌉,⌊⌈nm⌉+13(n−⌈nm⌉)⌋,or n. For each combination of parameters and each generation strategy, we construct five PMMWM instances. This results in a total of 2475 instances.Let F* be the value of the objective function (10) of the best solution found by a specific heuristic. Then, we rate the quality of this heuristic with the ratioF*Fbest,where Fbestis the best objective function value among the objective function values of the solutions obtained by any of the heuristics PMREG, PMBPS, MP and MPLSand the best solution found by CPLEX (model (10)–(13)) within a time limit of 180 seconds.Fig. 6gives an overview of the algorithms’ overall qualities over the different values of n. For each n, the figure depicts the average quality over the results of all parameter settings and all generation strategies. Except for PMREG, all heuristics perform very well, even for large values of n.As in Fig. 6, Fig. 7presents a detailed view on the quality of PMBPS, MP, and MPLS. We find that both, MP and MPLS, outperform PMBPSin terms of solution quality. Note, however, that PMBPSstill performs at a high level. The specific effect of including (or not including) LS into Match–Partition heuristics, i.e. MP or MPLS, will be analyzed in Figs. 13 and 14.Fig. 8and 9compare the runtimes of the different heuristics. While for all heuristics, runtimes increase roughly quadratically in n, we find that PMBPSrequires by far the most computational effort. This fact stands against the gap in qualities of PMREGand PMBPS. PMREG, MP, and MPLSare quite similar in terms of runtimes.In what follows, we will focus on the performance of CPLEX and the heuristics with respect to the different generation strategies, i.e. different structures of the underlying bipartite graph.Fig. 10depicts the performance of CPLEX. Preliminary tests proved CPLEX to perform better for the linearized model (10)–(13) than for directly feeding it with model (3)–(9). Hence, we restrict ourselves to the linearized model. As mentioned above, CPLEX is stopped after 180 seconds and returns the best solution found within this time limit. Only instances with a size ofn=10could be solved to optimality within this time limit. In general, Fig. 10 shows the objective function values to be not competitive when compared with the ones determined by the heuristics, which is especially obvious for RAND, SPARSE70, and SPARSE80 instances. The results for BPS70 and BPS80 instances are better. However, the objective function values determined by CPLEX are (on average) still up to 600% larger than the ones determined by the best heuristic (in case ofn=190).Fig. 11 provides results for PMREG. The average quality of PMREGis dramatically better than the average quality of CPLEX (Fig. 10). While CPLEX reaches quality ratios larger than 250, these ratios are strictly smaller than 2.5 in case of PMREG. Both, CPLEX and PMREG, perform best on BPS70 and BPS80 instances. In case of PMREG, the results for BPS70 and BPS80 are, on average, very close to the best solutions of all considered heuristics.The results shown in Fig. 12relate to PMBPS. As before, PMBPSis less effective in case of RAND, SPARSE70, and SPARSE80 instances, but very competitive in case of BPS70 and BPS80 instances. When comparing PMBPSand PMREG, keep in mind that the runtimes of PMBPSincrease noticeably faster with increasing size of the bipartitions (Fig. 8). For PMBPSand PMREG, increasing values of n seem to have a stronger effect on computational effort (in terms of runtime) than on solution quality.Finally, Fig. 13 and 14 present results for MP and MPLS. While MP seems to be less effective for BPS70 and BPS80 instances, MPLSdoes not have this handicap. The peak of the graphs forn=10results from CPLEX being able to solve all related instances to optimality. Note that even in this case of comparison with optimal solutions, the quality ratio of MPLSis less than 1.0011. For all considered values of n, the runtime of MPLSis smaller than 6 seconds. The average runtime forn=190is around 2.2 seconds (see Fig. 9). The influence of including LS on runtimes is (on average) less than a second for all n and all types of instances. Thus it is advisable to always apply MPLSwhen facing a random instance of PMMWM.

@&#CONCLUSIONS@&#
