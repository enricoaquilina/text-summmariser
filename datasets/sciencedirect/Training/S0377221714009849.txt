@&#MAIN-TITLE@&#
Scheduling identical parallel machines with fixed delivery dates to minimize total tardiness

@&#HIGHLIGHTS@&#
We consider identical parallel machine scheduling to minimize total tardiness.Jobs can only be delivered at exogenously given fixed delivery dates.Mathematical programming and a branch-and-bound algorithm solve small problems.A tabu search and a hybrid genetic algorithm are developed for larger problems.

@&#KEYPHRASES@&#
Scheduling,Assignment problems,Branch and bound,Metaheuristics,Fixed delivery dates,

@&#ABSTRACT@&#
This paper addresses the problem of minimizing the total tardiness of a set of jobs to be scheduled on identical parallel machines where jobs can only be delivered at certain fixed delivery dates. Scheduling problems with fixed delivery dates are frequent in industry, for example when a manufacturer has to rely on the timetable of a logistics provider to ship its products to customers. We develop and empirically evaluate both optimal and heuristic solution procedures to solve the problem. As the problem is NP-hard, only relatively small instances can be optimally solved in reasonable computational time using either an efficient mathematical programming formulation or a branch-and-bound algorithm. Consequently, we develop a tabu search and a hybrid genetic algorithm to quickly find good approximate solutions for larger instances.

@&#INTRODUCTION@&#
This paper addresses the problem of scheduling jobs on identical parallel machines to minimize total tardiness, where jobs can only be delivered at certain fixed delivery dates.More precisely, a set of jobs, J, where each job j = 1, …, n has a given integer processing time pjand due date djis to be scheduled non-preemptively on m identical parallel machines, where each machine i = 1, …, m is ready at time zero and can process all jobs. The due dates are the times when a customer asks to receive a job and hence a job has to be both, processed and delivered before or at that due date to avoid tardiness penalties. There is a set K of exogenously given fixed delivery dates k = 1, …, s, where deliveries occur at times Δ1 < ⋅⋅⋅ < Δs. The delivery capacity at each delivery date is assumed to be infinite, and times for delivery are neglected.Each job has a completion time Cjand a delivery time Djwhere Dj= mink ∈ K{Δk|Δk≥ Cj}, i.e. a job is delivered at the first delivery date after its completion, and its tardiness is defined as Tj= max {0, Dj− dj}. In the standard three-field notation we can state this problem asPm|s=s¯|∑jTj,wheres¯implies that the number of delivery dates is known and fixed in advance.Scheduling problems with fixed delivery dates are often found in industry, for example when a manufacturing company relies on the timetables of shipping or airfreight companies to deliver its products to customers. The practical relevance of such problems is underlined by various papers addressing real-world situations with fixed delivery dates. For instance, Wang, Batta, and Szczerba (2005) consider a scheduling problem arising at the U.S. Postal Service, where mail processing operations are scheduled subject to an outbound truck delivery schedule. Scheduling of order consignment tasks at a logistics center subject to inbound and outbound truck arrivals and departures with different objective functions is studied by Carrera, Ramdane-Cherif, and Portmann (2010a); 2010b). Further practical examples of scheduling problems with fixed delivery dates originate in the consumer electronics industry. Li, Ganesan, and Sivakumar (2005) investigate how a computer manufacturer can synchronize its production schedule to airfreight timetables. Computer manufacturer Dell has the completed orders picked up by a logistics provider once a day, and Dell can reduce transportation cost by avoiding costly express services if jobs are scheduled sufficiently early (Stecke and Zhao, 2007). Ma, Chan, and Chung (2012) integrate sea freight schedules and production schedules for a manufacturer of electronic household appliances which essentially results in a single machine earliness-tardiness scheduling problem with additional consideration of different shipping times and costs.Several authors conduct more theoretically oriented studies of scheduling problems with fixed delivery dates. Hall, Lesaoana, and Potts (2001) provide complexity results and algorithms for a variety of problems. Among others, they prove that the problemPm|s=s¯|∑jTjis NP-hard in the ordinary sense and propose a pseudopolynomial dynamic programming algorithm to solve it. Single machine problems with fixed delivery dates are studied by Matsuo (1988) who addresses a weighted total tardiness problem with the possibility of using overtime to expand capacity, by Yang (2000) who studies a problem with earliness penalties, and by Seddik, Gonzales, and Kedad-Sidhoum (2013) who employ a payoff function that aims at maximizing the cumulative number of jobs processed before each delivery date subject to job release dates. Liu (2012) investigates a job shop with job release dates, equidistant fixed delivery dates and the objective to minimize the sum of weighted flow times and storage times.Leung and Chen (2013) and Fu, Huo, and Zhao (2012) consider single machine problems with fixed delivery dates and limited delivery capacity. In particular, Leung and Chen (2013) develop polynomial-time algorithms for minimizing the maximum lateness and the number of vehicles used. Hence, they coordinate production scheduling and delivery decisions. Integrated production and delivery scheduling which may also include delivery date setting has received very strong interest recently. Chen (2010) gives an overview of this research.While very few researchers have addressed the parallel machine scheduling problem with fixed delivery dates, many insights are available on the correspondent scheduling problem without delivery dates, Pm||∑jTj. This problem is also NP-hard in the ordinary sense since 1||∑jTjhas been shown to be NP-hard in the ordinary sense by Du and Leung (1990). However, various efficient branch-and-bound algorithms (e.g., Azizoglu and Kirca, 1998; Schaller, 2009; Shim, 2009; Shim and Kim, 2007b; Tanaka and Araki, 2008; Yalaoui and Chu, 2002) and heuristics (e.g., Biskup, Herrmann, and Gupta, 2008) have been developed for Pm||∑jTj. These findings can be used to develop sequence-oriented solution procedures for the problem with fixed delivery dates. In a sequence-oriented solution approach, the focus is on finding a good schedule where each job is delivered at the first delivery date at or after its completion. Thus, the delivery dates of the jobs depend on the schedule. A schedule is infeasible if some job is completed after the last delivery date. Obviously, the last delivery date should be large enough so that there exists at least one schedule such that Δs≥ Cj∀ j. Throughout this paper, we assume Δs≥ min {Cmax}, i.e., the last delivery date is at least as large as the minimum makespan. Details are provided in Section 4.Apart from the scheduling literature, the problemPm|s=s¯|∑jTjis also related to the generalized assignment problem which consists of assigning agents with limited capacity to a set of tasks. To illustrate this point, let us say that a job is in block k if Δk − 1 < Cj≤ Δkand hence Dj= Δk. The following property holds:Property 1Hall et al., 2001In an optimal solution ofPm|s=s¯|∑jTj,all jobs assigned to one block on one machine can be processed in arbitrary sequence.Consequently, it is sufficient to identify an optimal assignment of jobs to blocks. This may be achieved with assignment-oriented solution approaches that focus on assigning each job to a block with a certain delivery date. An assignment is infeasible if the processing time assigned to a block exceeds the capacity. Both the sequence- and the assignment-oriented approaches appear to have their particular merits and drawbacks. For example, the sequence-oriented approaches appear less likely to generate infeasible solutions because infeasibility can only occur with respect to the last delivery date, but they may add unnecessary complexity. In this paper, we consider both avenues. However, we understand that our discussion of exemplary solution procedures cannot provide a conclusive result if one approach outperforms the other.The remainder of the paper is structured as follows: In Section 2, we present a mathematical programming formulation and a branch-and-bound algorithm to find optimal solutions. Since the problem is NP-hard in the ordinary sense, the optimal solution procedures require much computational time for larger instances. Consequently, we propose an assignment-based tabu search and a more sequence-oriented hybrid genetic algorithm in Section 3. In Section 4, we present numerical results which suggest that the optimal solution procedures can solve instances with up to 20 jobs in a reasonable computational time while both heuristics yield good approximate solutions for instances with up to 50 jobs. Section 5 summarizes the findings and suggests some fruitful directions for future research.Due to Property 1, the problemPm|s=s¯|∑jTjcan be solved by identifying an optimal assignment of jobs to blocks. Let xijk∈ {0, 1} denote if job j is assigned to block k on machine i. Then the assignment problem can be stated as follows.(1)Z=∑jTj→minxijksubject to(2)∑i∑kxijk=1∀j(3)Tj≥0∀j(4)Tj≥∑i∑k(xijkΔk)−dj∀j(5)∑j∑k′:k′≤kxijk′pj≤Δk∀i,k(6)xijk∈{0,1}∀i,j,kApart from the definition of the variables, the constraints make sure that each job is assigned to exactly one block on one machine (2) and that the total processing time assigned to a block and all preceding blocks on one machine does not exceed that block’s delivery date (5). In contrast to standard assignment problems, the capacity of the later blocks depends on the utilization of the prior blocks on the same machine.Our branch-and-bound algorithm is based on finding an optimal sequence of all jobs and constructing the schedule by list scheduling where each job is assigned to the next available machine in ascending order of its position in the job sequence. Each job is delivered at the first delivery date at or after its completion and a solution is infeasible if any job is completed after the last delivery date. We first provide dominance properties and lower bounds and then give an overview of the algorithm. We incorporate findings from the literature on Pm||∑jTj, but we also propose new assignment-oriented properties and bounds.Property 2Let σ be a partial schedule where job j is scheduled last. If Cj> Δs, partial schedule σ is dominated by all feasible schedules.Corollary 1 extends Property 2 to identify infeasible solutions at an earlier stage of the branching procedure. σ′ denotes the set of unscheduled jobs.Corollary 1Let σ be a partial schedule where job j is scheduled last. Let j′ ∈ σ′ denote the unscheduled job with the largest processing time and γi(σ) the time when machine i becomes available after processing the jobs in σ. IfΔs−γi(σ)<pj′∀i,then σ is dominated.There exists an optimal schedule in which the sum of the processing times of the jobs processed on each machine does not exceedA=1m(∑jpj+(m−1)·maxj{pj}).The proof by Azizoglu and Kirca (1998) holds for all regular objective functions. ∑jTj= ∑jmax {0, Dj− dj} with Dj= mink ∈ K{Δk|Δk≥ Cj} is a regular objective function.□There exists an optimal schedule in which job j is completed no later than job j′ ifpj=pj′anddj≤dj′.Substituting the job completion times with the job delivery times, the proof is by an interchange argument similar to Azizoglu and Kirca (1998).□The following dominance property applies for the optimal job sequence on one machine. It is based on Property 1 and properties formulated by Shim and Kim (2007a); 2007b).Property 5Let Dj(σ) denote the delivery time of job j in a partial schedule σ. A (partial) schedule σ where jobs j and j′ are assigned to the same machine and job j′ precedes job j is dominated by another (partial) schedule σ* if at least one of the following conditions holds:(a)pj≤pj′andDj(σ)=Dj′(σ);(b)pj≤pj′anddj≤max{Dj′(σ),dj′};(c)dj≤dj′andDj(σ*)≤dj′≤Dj(σ);(d)Dj(σ)≤dj′.According to Property 1, all jobs that are assigned to one block on one machine can be processed in any order, so they may be processed in ascending order of their processing times (SPT) without increasing the tardiness.Shim and Kim (2007a) provide proofs for (b), (c) and (d) which can easily be updated to account for delivery dates.□The subsequent corollary follows directly from Property 5 (b). It helps to identify unpromising solutions earlier during the branching procedure.Corollary 2Let σ be a partial schedule. If there is an unscheduled job j ∈ σ′, and on each machine there is at least one scheduled job j′ such thatpj≤pj′anddj≤max{dj′,Dj′(σ)},then σ is dominated.Property 6 deals with jobs that are assigned to different machines.Property 6A (partial) schedule σ where job j is scheduled last and another job j′ withpj′>pjis already scheduled on some machine is dominated if dj< Dj(σ),Dj(σ)−max{dj,Dj(σ*)}≥Δs−max{dj′,Dj′(σ)}andΔs−⌊1m∑j′′∈J∖{j′}pj′′⌋≥pj′.From the conditions of Property 6 it is clear that Tj(σ) > 0. Create an alternative schedule σ* by inserting j in the position of j′ and schedule job j′ in the very last position on some machine, such that it is completed at Δs. The concept is illustrated in Fig. 1.The moves will not increase the tardiness of any job other than j′. The tardiness of job j and j′ in σ* is Tj(σ*) = max {0, Dj(σ*) − dj} andTj′(σ*)=max{0,Δs−dj′}.Tj(σ)+Tj′(σ)≥Tj(σ*)+Tj′(σ*)Dj(σ)−dj+max{0,Dj′(σ)−dj′}≥max{0,Dj(σ*)−dj}+max{0,Δs−dj′}Dj(σ)−max{dj,Dj(σ*)}≥max{0,Δs−dj′}−max{dj′,Dj′(σ)}+dj′There are two cases: Ifdj′>Δsthen we also havedj′>Dj′(σ)and the right hand side of the inequality equals 0. For the left hand side, Dj(σ) > djand Dj(σ) ≥ Dj(σ*), and hence the statement is obviously true. On the other hand, ifdj′≤Δsthe statement is true due to the second condition postulated in Property 6.Finally, due to the third condition in Property 6, postponing job j′ always yields a feasible schedule as there is sufficient idle time to schedule j′ on at least one machine, even if all machines are utilized equally and hence the maximum idle time is minimum. As we assumeΔs≥1m(∑j′′pj′′+(m−1)maxj′′{pj′′})(see Section 4), the last condition is always satisfied as can be seen when simplifying it to(m−1)maxj′′{pj′′}+pj′≥mpj′.□Let γ1(σ) denote the time when the first machine becomes ready after processing the jobs in a partial schedule σ and suppose without loss of generality that the machines are indexed in ascending order of these ready times. Furthermore, let Δl= mink ∈ K{Δk|Δk≥ γ1(σ)} denote the first delivery date after the first machine becomes ready. Finally, for ease of notation, throughout the following we write Dj(σ) = Djetc. when no ambiguity arises.Proposition 1Liaw, Lin, Cheng, and Chen, 2003; Shim and Kim, 2007bAny schedule starting with a partial sequence σ will have a total tardiness no less thanLB1=∑j∈σ′max{0,DjLB−dj},whereDjLB=mink=l,…,s{Δk|Δk≥γ1(σ)+pj}is a lower bound on the delivery time of job j.After calculating LB1, the due dates of the unscheduled jobs can be modified such thatdj′=max{dj,DjLB}. Clearly, all jobs with a modified due datedj′<Δk+1should be assigned to block k in order to avoid additional tardiness. The capacity that is required to process these jobs is∑j:dj′<Δk+1pj. On the other hand, the available capacity in block k isWk=∑i=1mmax{0,Δk−γi(σ)}and if the required capacity exceeds the available capacity then some jobs need to be postponed. Note that this includes the assumption that the jobs’ processing can be split among the machines which does not increase the tardiness. In the following, we improve the lower bound based on potential capacity shortages in blocks k = l, …, s − 1. More precisely, we propose three alternative waysLB2kI,LB2kIIandLB2kIIIto calculate a lower bound on the additional tardiness that is caused by postponing the delivery of some jobs from Δkto Δk + 1. Note that in order to maintain optimality the postponement decision is made for each delivery date k = l, …, s − 1 independently, i.e., the decision to process a job before delivery date k is not binding when k + 1 is considered, and for each delivery date we consider only the additional penalty that is caused by delivering a job at Δk + 1 instead of Δk, i.e.,Δk+1−max{dj′,Δk}. The overall lower bound for the branch-and-bound algorithm that results from this approach is defined as follows:Proposition 2Given a partial schedule σ, a lower bound on the total tardiness is given byLB=LB1+∑k=ls−1max{LB2kI,LB2kII,LB2kIII}.We now describe the calculation ofLB2kI,LB2kIIandLB2kIII. Suppose that the available machine capacity before delivery date k exceeds the required capacity, i.e.,∑j:dj′<Δk+1pj>Wk.LB2kIis based on determining the minimum number of jobs that have to be postponed,UkLB,and assuming that these jobs simultaneously have the latest due dates. More precisely,LB2kI=∑j:dj′<Δk+1UkLB(Δk+1−max{dLDD[j]′,Δk}),where LDD[j] denotes that the unscheduled jobs which have a due date before Δk + 1 are indexed in descending order of their due dates. The minimum number of jobs that need to be postponed can be determined by assuming that the longest jobs are postponed. Then,UkLBis the smallest integer such that∑j:dj′<Δk+1UkLBpLPT[j]≥∑j:dj′<Δk+1pj−Wk,where pLPT[j] denotes the processing time of the jth job if the jobs are indexed in descending order of their processing times. In addition, if the idle time on some machine is too small to process even the shortest job that is due before Δk + 1, then this idle time cannot reduce the number of jobs postponed. Consequently, letUkLBbe the smallest integer such that∑j:dj′<Δk+1UkLBpLPT[j]≥∑j:dj′<Δk+1pj−(Wk−∑i:0<Δk−γi(σ)<pSPT[1](Δk−γi(σ))).LB2kIIis analogous toLB2kIapart from one modification. The assumption that the longest jobs also have the latest due dates can reduce the tightness of the bound if there are several jobs with due dates only slightly below Δk + 1. In such cases, a tighter bound can be obtained if for jobs withΔk<dj′<Δk+1we assumedj′=Δk+1. Then, these jobs are not considered for delivery at Δk. We getLB2kII=∑j:dj′<Δk+1UkLB(Δk+1−Δk).LB2kIIIis based on the assumption that jobs can be processed and delivered preemptively. The problem to find an assignment of jobs to be processed before Δkwhich does not exceed available idle time and minimizes the sum of additional penalties is a standard Knapsack problem. Letpj,k′denote the amount of processing of job j that is conducted before Δk. If job j cannot be fully processed before Δk, then an amountpj,k+1′=pj−pj,k′of that job’s processing will be conducted in block k + 1. It is well-known that a lower bound for the Knapsack problem can be obtained by assigning jobs in decreasing order of their per-unit postponement penaltieszj,k=(Δk+1−max{Δk,dj′})/pjuntil Wkis reached. This bound implies that a proportional penalty is only incurred for the part of job j which is processed in block k + 1.LB2kIIIis calculated as follows:LB2kIII=∑j:dj′<Δk+1pj−pj,k′pj(Δk+1−max{dj′,Δk}).The branch-and-bound algorithm uses the branching scheme proposed by Shim (2009) in order to avoid redundant branches. The initial upper bound UB is obtained from a sequence-oriented tabu search which we originally developed for the problem (Mensendiek, 2014). For the test instances described in Section 4, this tabu search provided the optimal solution in more than 70 percent of the instances, yet it is outperformed by the assignment-oriented tabu search described below. The algorithm can be stated as follows:The numerical study in Section 4 indicates that mathematical programming as well as the branch-and-bound algorithm require a lot of computational time to find and confirm optimal solutions for instances with more than 20 jobs. Thus, we propose two metaheuristics for such problems.Recall that a problem instance is infeasible if the last delivery date is too tight to process all jobs before it. To avoid this situation, in this paper we consider only problems where the last delivery date is not lower than the makespan of a schedule where jobs are sequenced in descending order of their processing times (LPT) and assigned to machines by list scheduling (see Section 4). This schedule is used as a back-up solution for the tabu search and it is included in the initial population of the hybrid genetic algorithm, so that both heuristics will always provide a feasible solution.Tabu search is a local search-based improvement heuristic that has been successfully applied to the generalized assignment problem (e.g., by Diaz and Fernandez, 2001; Osman, 1995) as well as parallel machine scheduling problems with tardiness minimization objectives (e.g., Bilge, Kirac, Kurtulan, and Pekguen, 2004; Chen and Wu, 2006). It requires to define the construction of an initial solution and the neighborhood of a current solution, the selection of candidates from the neighborhood and the design of the tabu list.In our problem there are m parallel machines, and hence there are sm possibilities to assign a job to a certain block on a certain machine. An initial solution is obtained by a best fit heuristic that considers the delivery dates in ascending order. For delivery date k, calculate the score max {0, Δk + 1 − dj}/pjfor all unassigned jobs and assign jobs to machines in decreasing order of their score. According to the best fit approach, each job is assigned to the machine with the smallest idle time before Δkthat suffices to process the job. If a job’s processing time exceeds the idle time on all machines, it cannot be assigned until block k + 1 is considered. Consequently, the capacity constraints of blocks 1, …, k − 1 will not be violated in the initial solution. However, any remaining jobs are assigned to the last block and their processing may exceed the last delivery date Δs.As our tabu search is similar to the one by Diaz and Fernandez (2001), we only point out some major features here. Candidate solutions are generated by shift and swap moves. In a shift move, one job is inserted into a different block on the same machine or into a block on a different machine. In a swap move, two jobs from different blocks on the same machine, or from different machines, are exchanged.A key element in the evaluation of candidate solutions is the treatment of infeasible solutions, i.e., solutions where the capacity constraint of some block(s) is violated. Considering these solutions despite their infeasibility may be useful to evade local optima. Thus, candidate solutions are selected according to the objective criterion Z′ = ∑jTj+ β∑i∑kv(k − 1) m + iwhere v(k − 1) m + idenotes the capacity violation of the kth block on machine i. It is defined asv(k−1)m+i=max{0,∑jxijk−min{Δk−1,∑j∑k′:k′≤kxijk′pj′}}∀i,k.β is a dynamically adjusted feasibility violation penalty. A larger value of β drives the search toward feasible solutions while a low value of β allows to investigate promising infeasible solutions. Similar to Diaz and Fernandez (2001), for each iteration we setβ=β·αinfeas/(n−1)−1where infeas is the number of infeasible candidate solutions that were considered during the last n iterations. The parameter α is used to influence how fast β increases or decreases. We set α = 2 for the first n iterations. Afterwards, α is increased by 0.0001 when a selected candidate solution is infeasible and reset to 2 when a new best solution is found.Candidate solutions are selected according to the first improving rule, that is, the first non-tabu candidate solution that has a lower objective value than the current solution is selected. A candidate solution that is tabu is still selected if it is a new best feasible solution. If no candidate solution yields a better objective value than the current solution, then the best candidate is selected.The tabu list is represented by a matrix with tuples ((k − 1)m + i, j) meaning that job j is assigned to block k on machine i. An entry in the tabu list denotes the last iteration during which job j cannot be inserted into a certain block on a certain machine. The tabu tenure is selected randomly from the interval [tmin, tmax] where tmin = 2 and, in contrast to Diaz and Fernandez (2001), tmax is adjusted dynamically. More precisely, starting from tmax = 4, tmax is increased by one if 20 iterations have not resulted in a new best solution, and it is decreased by one whenever a new best solution is found. We settmax = 2 andt¯max=12as lower and upper limits on tmax. Obviously, a larger value of tmax tendentiously increases the tabu tenure and therefore permits to leave local optima.The tabu search was calibrated using 72 test problems with n = 50 jobs that were randomly generated for this purpose. This calibration suggested to use a dynamic tabu tenure, and to initialize β = 10. The high starting value for β makes sure that the algorithm first tends toward providing a feasible solution. The number of iterations is fixed to 3000. The algorithm can be stated as below.Genetic algorithms are commonly used to solve parallel machine scheduling problems (e.g., by Jou, 2005; Mendes, Mueller, Franca, and Moscato, 2002; Vallada and Ruiz, 2011). In each iteration, which is also referred to as a generation, a genetic algorithm maintains a population of several solutions and tries to reach better solutions by stylized application of evolutionary principles. Therefore, in contrast to tabu search, genetic algorithms can investigate several promising solutions in parallel. Since the algorithm proposed here incorporates a local search as a subroutine, we refer to it as a hybrid genetic algorithm (HGA).A genetic algorithm requires a definition of an initial population, the representation of a solution, the design of the crossover and mutation operators, a fitness function, the rule of which individuals are passed on to the next generation and a calibration of the relevant parameters.Testing various simple constructive heuristics such as simple dispatching rules suggested that these heuristics usually provide inferior or even infeasible solutions (Mensendiek, 2014). We finally selected three procedures to construct an initial population for the HGA.The first individual in the initial population is the LPT schedule. It is checked if this solution can be improved by resequencing the jobs on each machine according to their weighted rankrj=rjp+2rjdwhererjpandrjddenote that job j has the rpth smallest processing time and the rdth earliest due date. Ties are broken by scheduling the job with the shorter processing time first.Another 4m individuals are generated using a three-step random backward construction heuristic. The idea is that a high tardiness is often caused by the last jobs on the machines and hence good schedules may be obtained by identifying these jobs. The heuristic works backwards, i.e., an additional job is always inserted before the jobs that are already scheduled. In the first step, the heuristic assigns 2m jobs randomly to machines. First, it assigns all the jobs with dj≥ Δsand then the jobs with the lowest value ofmax{0,Δk−djpj}where k is the last block that contains idle time. In the second step, the heuristic assigns jobs in increasing order of this value. This is done deterministically by a reverse list scheduling approach, that is to say the next job is always scheduled before the first job on the machine with the largest amount of idle time. In the third step, the last 3m jobs are assigned in decreasing order of their processing times according to the best fit approach in order to increase the chance of finding a feasible solution.The remaining individuals of the initial population are generated randomly.Our representation of a solution is one commonly used in the scheduling literature (Cheng and Gen, 1997; Mendes et al., 2002; Vallada and Ruiz, 2011). One solution, also called one individual or chromosome, is represented as a string of genes of length n + m − 1 where the job sequences for the different machines are separated by the asterix *. For instance,(2,5,3,1*4,6,8,7)represents a schedule where the job sequence is 2, 5, 3, 1 on the first machine and 4, 6, 8, 7 on the second machine.The purpose of the crossover operator is to create two new solutions (offspring) from two parent solutions. Parents are selected randomly using the well-known roulette wheel technique. Using this technique, the probability of selecting chromosome r as a parent is r/R where the chromosomes are ranked in descending order of their fitness (i.e., tardiness) and R is the sum of all ranks. We implemented a local search enhanced one-point order crossover mechanism as described by Vallada and Ruiz (2011). The concept is depicted in Fig. 2. The crossover mechanism generates m random pointers, one for each machine of the first parent. Then, for each machine of the first parent all genes prior to and including that pointer are copied to the same machine of the first offspring, and all genes after the pointer are copied to the same machine of the second offspring. In both cases, the subsequences of the genes are maintained. In the second phase, the missing genes of offspring 1 and 2 are added from the second parent. For offspring 1 (for the second offspring the procedure is analog), eliminate all genes that are already contained in the offspring from the second parent. Then, insert the remaining genes from machine i of the second parent 2 at machine i of the offspring. To yield better solutions, a local search enhancement is incorporated at this stage by testing every possible insertion position for each gene and selecting the one that yields the minimum machine tardiness. To illustrate, in Fig. 2 the last gene of parent 2 (“7”) can be inserted in the three last positions of offspring 1.Numerical experiments indicated that the mutation operator used by Vallada and Ruiz (2011) does not yield satisfactory results for the fixed delivery date problem. Consequently, we employ local search heuristics instead of a simple mutation operator. More precisely, with a certain probability a local search based on shift and swap moves is executed for a new chromosome. To shift a job to block k, calculate Δk− pjand schedule job j immediately after the last job j′ that has a completion time satisfyingCj′≤Δk−pj. Due to Property 1, it is sufficient to consider one insertion position for each block which reduces the size of the neighborhood of the chromosome. Whenever the best solution from the neighborhood of a chromosome is better than the current fitness, the chromosome is modified and the local search is repeated until no further improvement is achieved.After application of the crossover and local search procedures the next generation is composed via an elitist strategy, i.e., it consists of the fittest individuals among the parents and the offspring where duplicates are eliminated. The remaining individuals are deleted. Fitness is represented by the objective criterion Z′′ = ∑jTj+ β∑jmax {0, Cj− Δs}, where of course a lower objective value implies a fitter individual. Again, β is a dynamic feasibility violation penalty, but it is adjusted in a simpler way than in the tabu search. For the initial population, β is set prohibitively high to make sure that feasible solutions are obtained. Afterwards, starting with β = 10, the penalty is increased by one for each generation.An additional immigration procedure is used to avoid premature convergence to a local optimum. That is, after ten generations without improvement of the best objective value, the worst 10 percent individuals in the population are replaced by randomly generated new individuals to introduce new DNA. Fig. 3summarizes the structure of the hybrid genetic algorithm.The parameters of the algorithm were calibrated using the aforementioned 72 test problems. The final parameter settings are depicted in Table 1.The mathematical programming formulation, the branch-and-bound algorithm and the heuristics are evaluated in a numerical study. The mathematical program is solved using the CPLEX 12.5 solver implemented in AIMMS. The other algorithms are coded in C + +. All computations are executed on a computer with a 2 gigahertz dual core processor and 4 gigabyte RAM.Instances are randomly generated for different numbers of jobs, machines and delivery dates, denoted by n/m/s. Job processing times are integers drawn from a uniform distribution over [1, 100], and job due dates are drawn from a uniform distribution over[max{0,(∑jpjm)·(1−τ∓0.5R)}]where τ ∈ {0.2, 0.5, 0.8} defines the average tardiness and R ∈ {0.2, 0.6, 1.0} the due date range.The definition of the last delivery date is particularly critical for the solutions of the fixed delivery date scheduling problem. In our empirical study we consider two cases. First, we set the last delivery date sufficiently large to make sure that the list scheduling approach always results in a feasible schedule where all jobs are completed before the last delivery date. We refer to this case as the “unrestrictive” last delivery date and setΔs=1m(∑jpj+(m−1)·maxj{pj}),i.e., the last delivery date equals the upper bound on the makespan of an optimal schedule. On the other hand, we consider the case where the last delivery date is small so that there may be infeasible list schedules where not all jobs can be finished before Δs. To assure that at least one feasible schedule exists, the last delivery date may not be lower than the minimum makespan. However, to allow for some more flexibility in the scheduling decisions, we set Δs= Cmax(SLPT), i.e., the last delivery date equals the makespan of the LPT schedule. We refer to this case as the “tight” or “restrictive” last delivery date. All other delivery dates 1, …, s − 1 are integers drawn from a uniform distribution over [minj{pj}, Δs].In order to evaluate the performance of the mathematical programming approach (MP) and the branch-and-bound algorithm (BB) we consider instances with 15 and 18 jobs, 2–4 machines and 4 or 6 delivery dates. Ten instances are randomly generated for each tuple (τ, R), yielding a total of 540 instances for the unrestrictive and a different 540 instances for the restrictive case. Table 2summarizes the average computation times required by the two approaches.In general, instances with an unrestrictive last delivery date are solved faster than those with a tight last delivery date. However, the average computation times are heavily influenced by some instances that require a significant amount of computation time, in particular in case of the MP. While the BB algorithm always terminates in less than one hour, the MP approach requires more than one hour of computation time for 24 instances. On the other hand, the MP is faster in solving 66 percent of the unrestrictive instances and 53 percent of the tight instances. Yet the results also indicate that the computational effort to find optimal results may often not be viable for larger instances.For the evaluation of the heuristics we consider instances with 20, 30 and 50 jobs. 900 instances with an unrestrictive and another 900 instances with a tight last delivery date are investigated. The tabu search (TS) and the hybrid genetic algorithm (HGA) are evaluated based on the average solutions and solution times resulting from five random replications. As an additional heuristic, we use the commercial solver to solve the MP for each instance, but impose a runtime limit of 600 seconds. Extending that limit to 3600 seconds does not significantly improve the solutions found by the solver. Tables 3and 4depict the average computation times and the average percentage deviations from the best-known solutions. The best-known solutions result either from the time-limited MP, or from any of the replications of the TS or HGA.Interestingly, the MP with the runtime limit on average yields the best solutions for both the unrestrictive and the tight instances. In fact, the solver terminated within 600 seconds in approximately 90 percent of the instances with 20 and 30 jobs and approximately 40 percent of the instances with 50 jobs. The MP also finds the best-known solution in more than 80 percent of the instances. The results suggest that the solver quickly converges toward (near-)optimal solutions even when the optimality cannot be confirmed within the time limit. The assignment-oriented TS also yields good solutions with the average percentage deviation being less than 1 percent in case of the unrestrictive instances. As the TS requires very little computational time, it could also be repeated several times in order to obtain better solutions. In fact, the average percentage deviation of the TS for the unrestrictive (tight) instances reduces to 0.14 percent (0.22 percent) and the best-known solution is achieved in 84 percent (78 percent) of the instances when taking the best result from five random replications. The performance of the sequence-oriented HGA is less satisfactory with an average deviation of almost 2 percent for the tight instances. To analyze this effect, the results for these instances are grouped by the (τ, R)-tuples used for due date generation in Table 5.Table 5 offers two major insights. First, it turns out that the MP performs particularly well on instances with a low average tardiness. These instances can be solved to optimality in little computational time even with 50 jobs. Second, the HGA does not perform well on many of these instances. Further analysis demonstrates that instances with a low average tardiness and medium or high due date range often have a low optimal tardiness, so that even a small absolute deviation results in a high percentage error.22On the other hand, instances with a medium or high average tardiness tend to have a lower percentage error.More precisely, approximately 1 percent of the average deviation of the HGA is caused by only four instances where the average HGA solution deviates by more than 100 percent from the best-known tardiness. In contrast, the HGA does provide solutions within 1percent of the best-known solution for 75 percent of the tight instances with (L, m) and (L, h) due dates structures and it obviously performs well on instances with a high average tardiness. Yet it is noteworthy that the sequence-oriented HGA despite the integrated local search in general does not perform as well as the assignment-oriented MP and TS. In fact, an interesting avenue for further research is to develop and evaluate a more assignment-oriented genetic algorithm, e.g. by using a different chromosome structure.The results reported above are based on the best-known solutions whose optimality could not always be confirmed within the time limit. As an additional benchmark, we calculated the lower bound LB described in Section 2.2 for an empty schedule and compared the heuristic solutions with the lower bound. The average deviation of the heuristics varied between 6 percent (MP) and 8 percent (HGA) for the unrestrictive and between 15 percent (MP) and 17 percent (HGA) for the tight instances. This indicates that LB indeed provides a tight lower bound for the BB algorithm, but also that the heuristic solutions are often (near-)optimal.We conducted some additional computational experiments on two special but practically relevant cases of the fixed delivery date problem. First, we considered various instances generated as above, but with equidistant delivery dates. Equidistant delivery dates are realistic when, for example, a delivery vehicle departs once a day, as in the problem of Stecke and Zhao (2007). Yet neither of the optimal and heuristic solution procedures appears to benefit clearly from this assumption in the sense that either the computational effort or the deviation from the best solutions decreases. Second, we generated additional instances where job due dates are rounded to the closest delivery date, so that all job due dates coincide with one of the delivery dates, dj∈ {Δ1, …, Δs} ∀ j. If the due date is interpreted as the date when the customer desires to receive the order, this date needs not coincide with a delivery date. However, if it is interpreted as a commitment by the manufacturer, it appears realistic that the company will only commit to one of the delivery dates. When the due date range is small, this may yield an instance where (almost) all jobs have one common due date. Still, the MP and BB algorithms frequently require much computational time to solve instances with more than 20 jobs. Also, more restrictive assumptions regarding the job due dates do not seem to lead to significantly better solutions of the TS and HGA.

@&#CONCLUSIONS@&#
