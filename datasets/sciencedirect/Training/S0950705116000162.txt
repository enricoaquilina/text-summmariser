@&#MAIN-TITLE@&#
An effective and efficient fruit fly optimization algorithm with level probability policy and its applications

@&#HIGHLIGHTS@&#
A level probability policy and new mutation parameter are used for proposed FOA.Results of 29 test functions show LP–FOA outperforms the existing FOAs, DE and PSO.A delicate LP–FOA based coding is used to solve joint replenishment problem (JRP).LP–FOA is better than the current best intelligent algorithm for JRPs.

@&#KEYPHRASES@&#
Fruit fly optimization algorithm,Level probability,Continuous function problem,Joint replenishment problems,

@&#ABSTRACT@&#
An improved fruit fly optimization algorithm (FOA) is proposed for optimizing continuous function problems and handling joint replenishment problems (JRPs). In the proposed FOA, a level probability policy and a new mutation parameter are developed to balance the population diversity and stability. Twenty-nine complex continuous benchmark functions are used to verify the performance of the FOA with level probability policy (LP–FOA). Numerical results show that the proposed LP–FOA outperforms two state-of-the-art variants of FOA, the differential evolution algorithm and particle swarm optimization algorithm, in terms of the median and standard deviations. The LP–FOA with a new and delicate coding style is also used to handle the classic JRP, which is a complex combinatorial optimization problem. Experimental results reveal that LP–FOA is better than the current best intelligent algorithm, particularly for large-scale JRPs. Thus, the proposed LP–FOA is a potential tool for various complex optimization problems.

@&#INTRODUCTION@&#
The fruit fly optimization algorithm (FOA) is a novel meta-heuristic method proposed by Pan [17] to solve the global optimization problems. The FOA simulates the intelligent collaboration of fruit flies when they swarm in searching for food. A fruit fly can find food easily with its sensitive osphresis and vision abilities. Considering its simple structure, easy implementation, and good performance, the FOA and its variants are applied to handle many practical optimization fields, such as in financial distress situations [17], power load forecasting [10], neural network parameter optimization [2,11], web auction logistics service [13], proportional–integral–derivative (PID) controller parameter tuning [24], and many other applications [4,8,12,34,35,38].However, the basic FOA often derives a local extreme when solving high-dimensional functions and large-scale combinational optimization problems. Thus, many researchers focused on improving the search ability of the basic FOA. Pan [18] designed a modified FOA by adding a new parameter, wherein the fruit flies search in a three-dimensional space. In contrast to other FOAs with a nonlinear generation mechanism of candidate solutions, a linear generation mechanism of candidate solutions was proposed by Shan et al. [23]. Pan et al. [16] improved the basic FOA by adding a new parameter. With its dynamic search radius, the improved FOA (IFOA1) exhibits an excellent performance. Yuan et al. [36] developed a multi-swarm FOA (MFOA), wherein multiple sub-swarms move independently in the search space at the same time and local behavior between sub-swarms is considered. Wang et al. [32] proposed the swarm collaboration and added random perturbation (RP) to improve the performance of FOA (IFOA2). Although these improvements enhanced the performance of FOA, deriving the global optimal solution is still difficult when facing high-dimensional functions and large-scale combinational optimization problems.This study aims to propose a new and improved FOA to solve the aforementioned complex optimization problems effectively and efficiently. Several advanced techniques are adopted to enhance the effectiveness of the FOA, including a level probability (LP) solution generation method and a novel parameter, to balance the population diversity and stability. The proposed new and improved FOA is called LP–FOA. The LP–FOA is applied to 29 standard functions optimization problems and joint replenishment problems (JRPs) to verify its performance. In fact, JRPs have been extensively investigated because of its significance in the theoretical and practical fields. However, JRPs are typically nondeterministic polynomial hard (NP-hard) problems.IFOA1 has been proven to be better than the basic FOA, MFOA, and five other existing harmony search algorithms [16] for continuous function optimization problems. In this study, the results of the benchmark functions test indicate that the proposed LP–FOA outperforms IFOA1, IFOA2, differential evolution (DE), and particle swarm optimization (PSO). Comparative and randomly generated examples also show that LP–FOA is better than the current best algorithm for JRPs. Thus, the proposed LP–FOA can be a strong candidate for solving complex optimization problems. The main contributions of this study are as follows: (a) An improved FOA with a level probability policy and a new mutation parameter is proposed. (b) A delicate LP–FOA-based coding style is designed to solve JRPs, resulting in major improvements in solving large-scale problems.The remainder of the paper is organized as follows: Section 2 summarizes the related FOA techniques and introduces the basic FOA. Section 3 describes the proposed LP–FOA. In Section 4, two latest variants of FOA are adopted to compare with the LP–FOA by the 29 benchmark function test. In Section 5, the LP–FOA is used to deal with JRPs. Section 6 discusses the results and provides future research recommendations.The fruit fly is a widely existing insect that has well-developed olfactory and visual organs. The fruit fly can easily find a food source through its scent, even if the source is 40kilometer away. When a fruit fly swarm hunts for food, each individual can measure the smell concentration in its current location. Then, the smell concentrations of all individuals are compared by fitness. The best fitness that corresponds to the current location is the best current location. Afterward, the fruit fly swarm will move toward the current location by aid of their sensitive vision. Fig. 1shows the food-searching iterative process of the fruit fly swarm.The steps of the basic FOA [17] can be described as follows:Step 1: Initialization. The fruit fly swarm location range (LR), fly range (FR), maximal central processing unit (CPU) time (Maxtime), and population size (popsize) are initialized. The initial LR is generated as follows:(1)X_I=rand(LR),Y_I=rand(LR).Step 2: Osphresis searching phase.Step 2.1: When each individual hunts for food, its new location can be generated by using Eq. (2):(2)Xi=X_I+rand(FR),Yi=Y_I+rand(FR).Step 2.2: Compute the distance of the food source to the origin by using Eq. (3):(3)Disti=Xi2+Yi2.Step 2.3: Compute the smell concentration judgment value (Si) and the judgment function (Smelli) of the individual location by using Eqs. (4) and (5), respectively:(4)Si=1/Disti,(5)Smelli=fitness(Si).Step 2.4: Select the fruit fly with maximal judgment function and its corresponding location by using the following equation:(6)[bestSmell,bestIndex]=max(Smell).Step 3: Vision searching phase.Maintain the maximal judgment function value and corresponding X, Y coordinates. The fruit fly swarm moves toward the location by using their vision.(7)Smellbest=bestSmell,X_I=X(bestIndex),Y_I=Y(bestIndex).Step 4: The implementation of Steps 2 and 3 are repeated. The circulation stops when the CPU time reaches the Maxtime.The FOAs often derive a local extreme for solving high-dimensional functions and large-scale combinational optimization problems. However, an excellent FOA can easily skip a local extreme. Thus, the LP method is adapted to expand the search space and skip local optima. The LP method divides the randomly generated location of the fruit fly into different levels according to probability.To expand search space and maintain stability simultaneously for the proposed LP method, we set that the fruit fly of level with high probability cannot fly far away, while the fruit fly of level with high probability can fly farther. Fig. 2shows the fly range of the fruit fly in the LP method. The probability in level 1 is two times that in level 2. However, the fly range of the fruit fly in level 2 is 10 times that of the fruit fly in level 1. The probability in level c (c=1,…, C, where C is the maximal level) is two times that in level c+1, similar to levels 1 and 2. We assume that the probability in level c is two to four times that in level c+1 because the search space will be clearly reduced when the probability of two adjacent levels has an evident difference. In this study, we assume that the probability in level c is 10 times that in level c+1.The details are described as follows:Step 1: Initialization. The swarm location range (X_I, Y_I), Maxtime, sizepop, mutation factor (F), and maximal level (C) are initialized, as follows:X_I=rand(LR),Y_I=rand(LR),Smellbest=fitness(S(X_I,Y_I)).Step 2: Osphresis searching phase.Step 2.1: Update the location of the swarm based on the LP method and an adaptive mutation factor. The detailed procedure is provided in Sub-algorithm 1.Steps 2.2 to 2.4: These steps are similar to Steps 2.2 to 2.4 in Section 2.Step 2.5: Swarm collaboration. According to [32], the best 50% individuals are selected to fly toward the best location, whereas the other individuals are randomly generated by initialization. In fact, a slight difference in the performance of the different percentages of individuals that fly to the best location is observed [32]. The detailed procedure is provided in Sub-algorithm 2.Step 2.6: Steps 2.1 to 2.5 are repeated. The judgment function values (Smelli) of the new swarm are calculated. The fruit fly with the maximal judgment function value among the new swarm is discovered.Step 3: Vision searching phase: random perturbation.The best Smelliand corresponding best location are maintained. If the current optimum is inferior to the historical optimum, then a new location is generated by the RP operation to skip the local optimum and selected as the best location. The detailed procedure is provided in Sub-algorithm 3.Step 4: If the CPU time reaches the maximal Maxtime, then the best smell concentration is returned and the implementation is stopped. Otherwise, Steps 2 to 3 are executed again.Algorithm 2shows the pseudo code of the LP–FOA.In summary, the basic FOA is modified to the LP–FOA with a new mutation parameter and a level probability policy. In particular, the level probability policy can provide a large range with a small probability, which can help the fruit fly skip the local optima. A large range with a small probability also ensures the stability of the LP–FOA. Meanwhile, the LP–FOA has several advantages over other algorithms, such as swarm collaboration and random perturbation.In Sections 4 and 5, all the proposed algorithms are coded in Matlab 2014a. The computation is conducted on a personal computer (PC) with an Intel® Core i7-4720MQ, 2.2GHz CPU, 8GB RAM, and Windows 8.1 Operational System.Twenty-nine extensively used benchmark problems were adopted in [16,23,36]. So we also used these functions to test the performance of LP–FOA. Some problems are multimodal with peaks, valleys, channels, and flat hyperplanes of different heights. Functions 1 to 15 are unimodal functions, whereas functions 16 to 29 are multimodal functions. These functions are highly suitable for verifying the performance of LP–FOA in solving complicated problems. The details of the 29 functions are listed in Table 1.At present, the FOA has two typical state-of-the-art variants, namely, IFOA1 and IFOA2. For continuous function optimization problems, IFOA1 has been proven to be better than the basic FOA, MFOA, and five other existing harmony search algorithms [16]. However, in handling continuous function optimization problems, IFOA2 is better than the basic FOA [32]. DE and PSO are also excellent meta-heuristic methods that can solve continuous function optimization problems [32,34]. Thus, the proposed LP–FOA is compared with IFOA1, IFOA2, DE, and PSO.The stopping criterion is not the iteration number, but the same maximal CPU time (Maxtime) which is set to 5, 10, and 20s, respectively. In [16,32], the maximal iteration number was set to 5,000 and 1,000, respectively. When the parameters are set to be the same as that in [16,32], the average running time in the PC is between 1.5s and 20s, which is covered by the maximal CPU time.For the LP–FOA, the level C is compared from 1 to 10. The convergence is observed to be better but with a slight difference when C≥5, thus C=5 is suggested. The population size (popsize) of LP–FOA is set to 10 and F=(UB−LB)/2, which are similar to IFOA1. According to [16], kmax=(UB−LB)/2 and kmin=10−5. Meanwhile, the popsize of IFOA1 is set to 50 and the perturbation amplification factor w is set to 0.3 according to the advice of [32].The parameters of DE are set as follows: popsize =50, crossover probability Cr=0.6, and mutation probability Mu=0.3. As for PSO [23], popsize=50, c1=1.5, c2=1.5, wmax=0.9, wmin=0.4, and vmaxis limited to 20% of the domain. Each problem is run with 30 independent replications. The median and standard deviations (Std) of these 30 replications are shown in Tables 2to 4. The results of the Wilcoxon rank sum test are shown in Table A.1.Tables 2–4 and A.1 present the results, from which we derived the following conclusions:(a)The LP–FOA is highly effective in terms of the median values. For different scales, the LP–FOA can derive better solutions than IFOA1, IFOA2, DE, and PSO in terms of the median values of 25 functions (F1, F3–F5, F7–F10, F12–F19, F21, F22, and F24–F28). That is, the LP–FOA significantly outperforms the other four algorithms for most of the benchmark functions.The LP–FOA is highly robust in terms of the Std. For most of the 29 functions, the Stds of LP–FOA are lower than that of IFOA1, IFOA2, DE, and PSO. Twenty-three Stds obtained by LP–FOA are all zeros.The LP–FOA is highly efficient. For different maximal CPU times, the results show a slight difference. This finding indicates that the LP–FOA can derive satisfactory solutions in a short time.For most of the 29 functions, the results of the LP–FOA do not have a gap with the optimal solutions. As for the several functions with relatively poor performance, the LP–FOA can be further improved in future studies.Fig. 3 shows the curves of the optimization processes for some typical functions by LP–FOA, IFOA1, IFOA2, DE, and PSO. The maximal iterative time is 5s, and the dimension is 50.For most benchmark functions, the overall evolution processes of the LP–FOA occur significantly and efficiently with satisfactory precision. Evidently, LP–FOA outperforms IFOA1, IFOA2, DE, and PSO.The popsize is set to 10, 20, 30, 40, and 50 to investigate its effect on the LP–FOA. The maximal CPU time is set to 5s. The dimensions of the 29 benchmark functions are set to 30, and each problem is run with 30 independent replications. Other parameters of LP–FOA are similar to those in Section 4.2. The results are summarized in Table 5.Table 5 shows that the results only have a slight difference in terms of the median and Std. This finding indicates that different popsize of the LP–FOA only have a slight effect on the performance of the LP–FOA.We set the dimension of the problems to 500 and 1,000 to test the performance of the LP–FOA further. The maximal CPU time is set to 100s, and each problem is run with 10 independent replications. Other parameters are similar to those in Section 4.2. The results are shown in Table 6. The results of the Wilcoxon rank sum test are shown in Table A.2. These results indicate that the LP–FOA is more effective and robust than IFOA1, IFOA2, DE, and PSO for most large-scale benchmark functions. The LP–FOA can obtain 25 better solutions from the 29 benchmark functions.Over the past few years, the JRP has been extensively examined under a global purchasing environment since the publication of previous work [25]. In the JRP procedure, a major ordering cost is incurred whenever an order is placed and a minor ordering cost is incurred if the item is in the order [19,31]. Grouping items into the same order from a supplier may lead to quantity discount [21,22]. The total of the major fixed ordering costs can also be reduced reasonably by gathering several items into a single order [20]. The objective of the JRP is to establish inventory replenishment policies to minimize the average total costs. A more detailed review of JRPs can be found in [7,9].The JRP aims to achieve a minimum total cost, which is composed of the holding and ordering costs. Following the general assumptions [7], the notations of the JRP are as follows:S: major ordering cost;m: number of items;Di: annual demand rate of item i;si: minor ordering cost of item i;hi: inventory holding cost per year of item i;TC: average total cost per year;ki: frequency of replenishing item i(decision variable), integers, ki≥1, i=1, 2,…, m;T: basic cycle time (decision variable), T > 0.The mathematical model of the JRP can be formulated as follows:(8)infTC(T,k1,…,km)=1T(S+∑i=1msiki)+T2∑i=1mDihiki.For a given ki(i=1, 2,…, m), the corresponding optimal cyclic time T* is calculated as follows:(9)T*=2(S+∑i=1m(si/ki))/∑i=1mDihiki.The corresponding average total cost (TC) is derived as follows:(10)TC=2(S+∑i=1m(si/ki))(∑i=1mDihiki).Meanwhile, Goyal [6] proposed that the optimal kifor a particular value of T satisfies the following expression:(11)ki(ki−1)<2siT2Dihi≤ki(ki+1).The best lower bound (LB) for T is proposed by Van Eijs [26] asT̲=2S/TC. This LB is only an initial bound for T. An improvement of the iterative procedure was proposed by [26], as follows:(12)T̲=2(S+∑i=1msi/k¯i)/TC,where TC is the corresponding total cost of any feasible solution andk¯iis the upper bound (UB) of ki.Similarly, the UB of T can be expressed as follows:(13)T¯=TC/(∑i=1mDihiki̲),whereki̲is the LB of ki.Deriving an efficient and effective method to deal with the JRP which has been proven to be a complex combinatorial optimization problem [1,9] is difficult. Current approaches to the JRPs include an iterative algorithm, RAND algorithm, power-of-two policy, genetic algorithm (GA), and DE [28–30]. The improved FOA (IFOA2) recently designed by [32] performs better than DEs and GAs in solving the JRP [3,15,20].However, the FOA2 designed by [32] does not apply the ability of osphresis. Their solution generation mechanism is only based on the LB and UB of the decision variable. Without the ability of osphresis, the performance of the FOA will significantly weaken. Thus, we design a new procedure in the LP–FOA to maintain the ability of sensitive osphresis. The LP method in FOA also enlarges the search space.Wang et al. [32] has proven that IFOA2 is better than DE and GA, which are two extensively used algorithms for JRPs. That is, the IFOA2 is the current best intelligent algorithm. Thus, for the JRPs, the proposed LP–FOA is also compared with IFOA2, DE, and GA.Step 1: Initialization. The parameters for the procedure of LP–FOA (Maxtime, popsize, LR, FR, F, and C) are set. The representation of a solution is similar to that in [32] in the development of LP–FOA. Meanwhile, a novel procedure is designed for the process of generating a solution. Sub-algorithm 4is a simple procedure designed to obtain the LB and UB of ki. The smell in each location for each fruit fly represents a replenishment policy and contains the ordering frequency. In the study of [32], the ordering frequency is the location of each fruit fly in the n-dimensional space.When the location of the fruit fly is predetermined, the smell in the location for the fruit fly can be recorded as Sol=(k1, k2,…, km), where kjis the replenishment cycle of item j and Tj=kjT. According to Sub-algorithm 5, the population of fruit flies can be generated and updated. If the location of a fruit fly generated by LP–FOA is Sol=[(2/2,2/2), (2/4,2/4), (0, 1), (1, 0), (1/3, 0), (1/2, 1/2)], then the replenishment cycle of item 1 is T and the replenishment cycle of item 2 is 2T.The representation of a solution is shown in Fig. 4.The initial individual x, y can be derived by using the following equation:(14)Distij=xij2+yij2,1/ki̲≤Distij≤1/k¯i.As such,(15)xij2+yij2≤(1/ki̲)2;xij2+yij2≥(1/k¯i)2.ki̲≥1; thus,(1/k¯i)2≤xij2+yij2≤1. Then, the swarm initial location range (LR) can be obtained as follows:(16)xij=2/2×(1−rand(0,1)),(17)yij=max[2/2×(1−rand(0,1)),1/(kj¯)2−xij2],(18)Distij=xij2+yij2,Sij=round(1/Distij),wherei=1, 2,…, popsize; j=1, 2,…, m; popsize is the population size of individuals; m is the dimension of each individual; and rand (0, 1) is a uniformly distributed random number in the range [0, 1].Step 2: Update the population of fruit flies. A new procedure of updating the population of fruit flies is designed and the LP method is used to expand the search space. Meanwhile, a novel algorithm is proposed to derive an excellent solution. The detailed procedure is provided in Sub-algorithms 5 and 6.Step 3: Calculating the total cost. When the location is determined, the solution can be obtained. Then, the basic replenishment cycle time can be obtained by using Eq. (9) and the total cost can be calculated by using Eq. (10).Step 4: Sortingthe total cost of different solutions and mutation. The first 50% of the total cost corresponding solutions are mutated by Step 2. Meanwhile, the other 50% of the total cost corresponding solutions are mutated by Step 1.Step 5: The total cost is compared and the best individual that minimizes the total cost is selected. The best individual is set, such that the current time is equal to Maxtime.Algorithm 3 shows the pseudo code of the LP–FOA for JRP.A classic example used by [32] is adopted to test the LP–FOA. In fact, this problem was also used by Moon and Cha [15]. The item number m=6, major ordering cost S=200, and other related data are shown in Table 7.IFOA2 is the current best intelligent algorithm for handling the JRP. Thus, we select IFOA2 as a comparative algorithm. Similar to [32], we also select DE and GA as comparative algorithms that can deal with JRPs. The detailed parameters of DE, GA, and IFOA2 are set with the same values according to the recommendations of [15,19,32]. For LP–FOA, C=3 is fixed to obtain a better result, whereas the other parameters are similar to those in Section 4.2. The maximal CPU time is set to 1s.The results shown in Table 8 reveal that the proposed LP–FOA can obtain the optimal solution. In the same CPU running time, the performance of LP–FOA is no worse than IFOA2, GA, and DE. Convergence curve shown in Fig. 5 reveals that the LP–FOA can derive the global optimal solution faster than the three other algorithms.Fung and Ma [5] studied the large–scale JRPs which are also used to further the performance of LP–FOA. The numbers of items of the test problems are set to 50, 100, 200, and 300, respectively. The major ordering costs, S, are set to 1, 10, 20, 50, 100, and 200, respectively. In each problem, the minor ordering cost si, the demand Di, and the holding cost per year hiare randomly generated from a uniform distribution U [0.5, 5], U [100, 100,000], and U [0.2, 2], respectively. Thirty problems are generated randomly for each combination, and the maximal CPU time is set to 20s. Other parameters of LP–FOA, IFOA2, DE, and GA are similar to those in Section 5.3. The results are shown in Tables 9 and 10. The results of the Wilcoxon rank sum test are shown in Table A.3.Note: (1) BI, BII, and BIII are the numbers that show that the results of LP–FOA are better than IFOA2, GA, and DE, respectively; (2) EI, EII, and EIII are the numbers that show that the results of LP–FOA are equal to IFOA2, GA, and DE, respectively; (3) WI, WII, and WIII are the numbers that show that the results of LP–FOA are worse than IFOA2, GA, and DE, respectively.From Tables 9–10, and A.3, the following conclusions can be obtained:(a)The proposed LP–FOA is highly effective for large-scale JRPs. The average TCs obtained by LP–FOA are significantly lower than IFOA2, GA, and DE, except for several cases with small major ordering costs.The performance of LP–FOA becomes more excellent with the increasing major ordering cost. In the numerical examples, the solutions by LP–FOA are always better than IFOA2, GA, and DE when the major ordering cost is not less than 50.In this study, a new and improved FOA called LP–FOA is designed to solve high-dimensional and complex continuous optimization problems and combinatorial optimization problems. The main contributions are as follows:First, an effective and efficient LP–FOA with a level probability policy and a new mutation parameter is proposed. Besides combining the advantages of the mutation factor and the swarm collaboration, a new adaptive mutation factor and an LP procedure are integrated into the FOA to enhance the diversity of solutions significantly, which aids in skipping the local optimum.According to the results of the 29 high-dimensional and complex benchmark functions, the proposed LP–FOA is more effective and robust than the IFOA1, IFOA2, DE, and PSO for most benchmark functions. The LP–FOA can easily solve higher dimensional problems, such as 500 or 1,000 dimensional problems. The results show that the LP–FOA outperforms the IFOA1, IFOA2, GA, and DE in terms of the median and Stds. When the dimension is set to 30 or 50, 25 out of 29 better solutions can be obtained. Even when the dimension is set to 500 or 1,000, the LP–FOA is still better than the other algorithms for most benchmark functions.Secondly, the application field of FOA is also expanded for solving a practical and challengeable JRP with significant theoretical importance. A new procedure is proposed to calculate the bounds of the decision variables. A novel solution generation mechanism is designed, which can guarantee the fruit fly swarm in a limited area.The numerical results show that the LP–FOA can easily derive lower TC than the current best intelligent algorithm for most cases. The advantage of LP–FOA is more evident with the increase in problem scales. In particular, when the number of items is set to 300, the maximal average saving rates can reach 8.04%, 16.71%, and 15.75% compared with IFOA2, GA, and DE.However, thereare several shortcomings or possible improvement of this study to be further discussed in the future. First, the operations of the proposed LP–FOA are more complex than other variants of FOA. The LP–FOA can be further improved based on the advantages of the quantum evolution algorithm or DE [27,33]. Secondly, the proposed LP–FOA should be improved for certain complex optimization problems under uncertain environment in the network economic era [14,37].

@&#CONCLUSIONS@&#
