@&#MAIN-TITLE@&#
Multi-objectivization, fitness landscape transformation and search performance: A case of study on the hp model for protein structure prediction

@&#HIGHLIGHTS@&#
Multi-objectivization is investigated from a fitness landscape analysis perspective.Multi-objectivization introduces incomparability, increasing landscape neutrality.Multi-objectivization forms neutral connections, merging different neutral networks.The new defined neutral paths play an important role in escaping from local optima.Multi-objectivization significantly improved search performance.

@&#KEYPHRASES@&#
Multi-objectivization,Fitness landscape analysis,Protein structure prediction,Hydrophobic-polar model,Multi-objective evolutionary algorithms,

@&#ABSTRACT@&#
Multi-objectivization represents a current and promising research direction which has led to the development of more competitive search mechanisms. This concept involves the restatement of a single-objective problem in an alternative multi-objective form, which can facilitate the process of finding a solution to the original problem. Recently, this transformation was applied with success to the HP model, a simplified yet challenging representation of the protein structure prediction problem. The use of alternative multi-objective formulations, based on the decomposition of the original objective function of the problem, has significantly increased the performance of search algorithms. The present study goes further on this topic. With the primary aim of understanding and quantifying the potential effects of multi-objectivization, a detailed analysis is first conducted to evaluate the extent to which this problem transformation impacts on an important characteristic of the fitness landscape, neutrality. To the authors’ knowledge, the effects of multi-objectivization have not been previously investigated by explicitly sampling and evaluating the neutrality of the fitness landscape. Although focused on the HP model, most of the findings of such an analysis can be extrapolated to other problem domains, contributing thus to the general understanding of multi-objectivization. Finally, this study presents a comparative analysis where the advantages of multi-objectivization are evaluated in terms of the performance of a basic evolutionary algorithm. Both the two- and three-dimensional variants of the HP model (based on the square and cubic lattices, respectively) are considered.

@&#INTRODUCTION@&#
The term multi-objectivization was originally coined by Knowles et al. to refer to the process of reformulating a single-objective optimization problem in terms of two or more objective functions, i.e., as a multi-objective problem (Knowles, Watson, & Corne, 2001). This transformation can be either based on the addition of new supplementary objectives (Brockhoff et al., 2007; Jensen, 2004), or it can be based on the decomposition of the original objective function of the problem (Handl, Lovell, & Knowles, 2008b; Knowles et al., 2001). In either case, multi-objectivization may result in fundamental changes to the fitness landscape of the problem. Since the performance of search algorithms is dictated by their interaction with the underlying fitness landscape (Watson, 2010), multi-objectivization can thus significantly impact on the ability of these algorithms to solve a given optimization task.It is commonly assumed that the higher the number of objective functions, the more difficult a problem is; and this is usually the case (Ishibuchi, Tsukamoto, & Nojima, 2008; Knowles & Corne, 2007). A single-objective to multi-objective transformation, however, has led to the development of more competitive search mechanisms. A considerable number of successful applications of multi-objectivization have been reported in the literature. For a recent review on applications of multi-objectivization, the reader can be referred to Segura, Coello Coello, Miranda, and León (2013). Multi-objectivization has been largely studied in the context of well-known combinatorial problems such as the traveling salesman problem (Jähne, Li, & Branke, 2009; Jensen, 2004; Knowles et al., 2001; Lochtefeld & Ciarallo, 2014), the job-shop scheduling problem (Jensen, 2004; Lochtefeld & Ciarallo, 2011), the bin packing problem (Segredo, Segura, & León, 2013; Segura, Segredo & León, 2011), the vehicle routing problem (Watanabe & Sakakibara, 2007), and the shortest path and minimum spanning tree problems (Neumann & Wegener, 2008). Also, multi-objectivization has found interesting applications in the fields of mobile communications (Segura, Segredo, González, & León, 2011; Segura, Segredo, & Leõn, 2013), computational mechanics (Greiner, Emperador, Winter, & Galván, 2007), power system planning (Trivedi, Sharma, & Srinivasan, 2012), structural topology optimization (Sharma, Deb, & Kishore, 2014), computer aided manufacturing (Churchill, Husbands, & Philippides, 2013), robotics (Mouret, 2011) and computer vision (Vite-Silva, Cruz-Cortés, Toscano-Pulido, & de la Fraga, 2007). Finally, multi-objectivization has also been proposed to deal with bioinformatic problems, such as those related to gene regulatory networks (Thomas & Jin, 2013) and protein structure prediction (Becerra, Sandoval, Restrepo-Montoya, & Nino, 2010; Cutello, Narzisi, & Nicosia, 2005, 2006, 2008; Day, Zydallis, & Lamont, 2002; Handl, Lovell, & Knowles, 2008a; Olson & Shehu, 2013; Soares Brasil, Botazzo Delbem, & Ferraz Bonetti, 2011; Sudha, Baskar, & Krishnaswamy, 2013).Recently, the concept of multi-objectivization was applied with success to the hydrophobic-polar (HP) model, a reduced representation of the protein structure prediction problem (Dill, 1985). This model abstracts the fact that hydrophobicity is a major determinant of the folded state of proteins. Despite its limited biological significance, from the computational point of view this model still represents an interesting and challenging problem in combinatorial optimization (Berger & Leighton, 1998; Crescenzi, Goldman, Papadimitriou, Piccolboni, & Yannakakis, 1998). Three different multi-objectivization schemes for the HP model have been proposed, all of them based on the decomposition of the original energy (objective) function of the problem (Garza-Fabre, Rodriguez-Tello, & Toscano-Pulido, 2012a, 2012b; Garza-Fabre, Toscano-Pulido, & Rodriguez-Tello, 2012). Decomposition introduces plateaus of incomparable solutions, an effect that can be exploited in order to overcome search difficulties such as that of becoming trapped in local optima (Handl et al., 2008b; Knowles et al., 2001). In this way, the use of alternative multi-objective formulations of the HP model has led to an important increase in the performance of search algorithms (Garza-Fabre et al., 2012a, Garza-Fabre, Rodriguez-Tello, & Toscano-Pulido, 2012b; Garza-Fabre, Toscano-Pulido et al., 2012), motivating further research in this direction.The present study significantly extends preliminary research regarding the multi-objectivization of the HP model. While previous analyses were concerned only with the benefits of multi-objectivization in terms of search performance (Garza-Fabre et al., 2012a, 2012b; Garza-Fabre, Toscano-Pulido et al., 2012), the primary goal of this study is to thoroughly investigate the potential effects that this transformation has on the characteristics of the problem. As pointed out before, multi-objectivization influences the comparability relation among solutions. As a means of illustrating and, to some extent, quantifying this effect, it is first evaluated how the comparability between the different defined fitness classes can be affected. The alteration in the comparability of solutions directly impacts on an essential property of the fitness landscape, neutrality. Hence, a detailed analysis is conducted with the aim of understanding multi-objectivization from a fitness landscape perspective, by focusing on neutrality. Finally, a comparative study is presented where the three multi-objectivization proposals are evaluated with respect to each other, and with respect to the conventional single-objective formulation of the HP model, in terms of the performance of a basic single-solution-based evolutionary algorithm.The remainder of this document is organized as follows. Section 2 provides background concepts and sets the notation used in this study. The three studied multi-objectivization approaches for the HP model are described in detail in Section 3. Section 4 is devoted to the analysis of the effects of multi-objectivization. The comparative study which focuses on search performance is covered in Section 5. Finally, Section 6 discusses the main findings and presents the conclusions of this study. Appendices at the end of this document contain supplementary information with regard to implementation details of the considered search algorithms, performance measures, test instances, the methodology followed for the statistical significance analyses, and the utilized experimental platform.Without loss of generality, a single-objective optimization problem can be formally stated as follows:(1)Minimize0.35em0exf(x),subjectto0.35em0exx∈XF,where x is a solution vector;XFis the feasible set, i.e., the set of all feasible solution vectors in the search spaceX,XF⊊X; andf:X→Ris the objective function to be optimized.Similarly, a multi-objective optimization problem can be formally defined as follows:(2)Minimize0.35em0exf(x)=[f1(x),f2(x),⋯,fk(x)]T,subjectto0.35em0exx∈XF,where f(x) is the objective vector andfi:X→Ris the i-th objective function, i ∈ {1, 2, …, k}. Rather than searching for a single optimal solution, the task in multi-objective optimization is to identify a set of trade-offs among the conflicting objectives. More formally, the goal is to find a set of Pareto-optimal solutionsP*, such thatP*={x*∈XF0.35em0ex|0.25em0ex∄0.25em0exx∈XF:x≺x*}. The symbol “≺” denotes the Pareto-dominance relation (Pareto, 1896):(3)x≺x′⇔∀i∈{1,⋯,k}:fi(x)≤fi(x′)∧∃j∈{1,⋯,k}:fj(x)<fj(x′).If x≺x′, then x is said to dominatex′. Otherwise, x′ is said to be nondominated with respect to x, denoted by x⊀x′. The image ofP*in the objective space is the so-called Pareto-optimal front or trade-off surface.Multi-objectivization refers to the process of reformulating an originally single-objective problem in terms of two or more objective functions (Knowles et al., 2001).11The term multi-objectivization was originally coined by Knowles et al. (2001), but the first studies on this kind of problem transformation date back to the work of Louis and Rawlins (Louis, Rawlins, & Optimality, 1993).Two main directions exist to perform such a transformation: (i) by incorporating additional information in the form of supplementary objectives, also referred to as artificial or helper objectives (Brockhoff et al., 2007; Jensen, 2004); or (ii) by means of the decomposition of the original objective function of the problem (Handl et al., 2008b; Knowles et al., 2001). In either case, the goal remains to solve the original problem, so that the original optima are to be also Pareto-optimal with regard to the alternative multi-objectivized formulation.When multi-objectivization is based on the addition of supplementary objectives, the single-objective problem is restated as a multi-objective problem of the form f(x) = [f(x), g1(x), …, gh(x)]T; where f is the original objective function of the problem and gidenotes the i-th supplementary objective, 1 ≤ i ≤ h. In the literature, this has been the most extensively studied approach to multi-objectivization. In a recent review (Segura et al., 2013), a distinction is made between multi-objectivization proposals where supplementary objectives are problem-dependent and are computed based solely on information from the solution under consideration (Greiner et al., 2007; Jähne et al., 2009; Jensen, 2004; Lochtefeld & Ciarallo, 2011, 2012), and those where they act as diversity measures (Bui, Nguyen, Branke, & Abbass, 2008; Mouret, 2011; Segredo, Segura, & Leon, 2011; Sharma et al., 2014; Tran, Brockhoff, & Derbel, 2013; Wessing, Preuss, & Rudolph, 2013). Separate treatment is given also to those proposals where additional objectives are implemented to handle constraints (Churchill et al., 2013; Garza-Fabre & Rodriguez-Tello, 2013; Singh, Ray, & Sarker, 2013).In multi-objectivization by decomposition, the focus of this research, the original objective is fragmented into several different components, each to be treated as an objective function under the new alternative formulation of the problem. More formally, the problem is restated in terms of d ≥ 2 objectives, f(x) = [f1(x), f2(x), …, fd(x)]T, such that the sum of all the new objectives equals the original objective function; i.e.,f(x)=∑i=1dfi(x), for allx∈XF.22Though other different decompositions are possible, this definition ensures that the original optimum coincides with one of the Pareto-optima in the multi-objective version of the problem (Knowles et al., 2001).It has been demonstrated that the only possible effect of decomposition is the introduction of plateaus in the search landscape (Handl et al., 2008b). That is, originally comparable solutions may become incomparable (mutually nondominated) with regard to the new decomposed formulation. Some of the works reported in this direction include the following (Handl et al., 2008b; Knowles et al., 2001; Vite-Silva et al., 2007). Also, multi-objective optimization approaches for the protein structure prediction problem fall into this category (Becerra et al., 2010; Cutello et al., 2005, Cutello, Narzisi, & Nicosia, 2006, 2008; Day et al., 2002; Handl et al., 2008a; Soares Brasil et al., 2011). Note, however, that such approaches are based on detailed energy models. It was not until the proposal of the methods studied herein that multi-objectivization was applied to the particular HP model of this problem (Garza-Fabre et al., 2012a, 2012b; Garza-Fabre, Toscano-Pulido et al., 2012).The notion of a fitness landscape, first introduced by Wright (1932), has been found to be useful in understanding the most essential characteristics of certain optimization problems, or problem classes. By analyzing the fitness landscape, it is possible to gain further insight into problem difficulty as a means of explaining, or even predicting, the performance of search algorithms. Fitness landscape analysis is expected to provide important clues for guiding the development of more competitive search mechanisms, which are able to deal with (or to take advantage of) the particular characteristics of the given optimization task. Some fundamental definitions on this topic, which are relevant according to the scope of this study, are presented below. For a more comprehensive literature review on fitness landscapes analysis the reader can be referred to Stadler (2002), Verel, Collard, Tomassini, and Vanneschi (2007), Vanneschi et al. (2012), Pitzer and Affenzeller (2012) and Malan and Engelbrecht (2013).A fitness landscape can be generally defined in terms of a triplet(X,N,ξ). The first element,X, represents the set of all potential solutions to the problem, i.e., the search space. The notion of connectedness among solutions inXis introduced by the so-called neighborhood structure,N:X→2X, which maps each possible solutionx∈Xto a set of solutionsN(x)⊆X. Hence,N(x)is referred to as the neighborhood of x and eachx′∈N(x)is called a neighbor of x. Finally, ξ denotes the evaluation scheme, consisting of (1) a measure (or set of measures) to serve as an indicator of the quality of the different solution candidates; and (2) a mechanism to impose an ordering relation given the adopted quality measure(s). As the evaluation scheme, in single-objective optimization a fitness function (usually directly related to the objective function of the problem) is considered and a simple ordering sets the preference relation among solutions.33In this study, a fitness function is assumed to be always maximized (the goal is to search for the fittest solution candidate).In the multi-objective context, however, a number of (conflicting) criteria determine the quality of solutions, so that defining an ordering relation is not as straightforward. The partial order induced by the Pareto-dominance relation is assumed in this study.The fitness landscape of a problem can be studied in terms of different properties, being the neutrality property of particular importance given the purposes of the present study. The standard definition of neutrality, in the single-objective case, refers to the degree to which a landscape contains connected areas of equal fitness (Pitzer & Affenzeller, 2012). Considering a broader notion to cover also the multi-objective case, neutrality can be understood as the result of the incomparability that the adopted evaluation scheme ξ induces. The term incomparability is used in this study to indicate the situation where no preferences can be imposed between a pair of solutions, so that these solutions are considered equivalent when evaluated under ξ. Two different solutionsx1,x2∈Xare said to be neutral (incomparable), denoted by neutral(x1, x2), if either they share the same fitness value (single-objective case), or they are nondominated, in the Pareto sense, with respect to each other (multi-objective case).Having defined neutrality, a series of related basic concepts can be introduced as follows. The neutral neighborhood of a solutionx∈Xis given by the subset of all its neutral neighbors:Nn(x)={x′∈N(x)0.35em0ex|0.35em0exneutral(x,x′)}. The total number of neutral neighbors of x, i.e., the cardinality ofNn(x), is known as the neutrality degree of x, and the ratio of the neutrality degree to the size of the neighborhood is referred to as the neutrality ratio. A neutral fitness landscape is characterized by a large number of solutions presenting a high degree of neutrality. This leads to (potentially large) connected areas of incomparable solutions called plateaus, more formally referred to as neutral networks. Consider the neutrality graphG=(X,En)whereEn={(x1,x2)∈X20.35em0ex|0.35em0exx2∈Nn(x1)}. Each connected component of the graph G corresponds to a different neutral network. In other words, a neutral network is a connected subgraphG′=(X′,En′)of G,X′⊆XandEn′⊆En, where (1) there exists a path connecting any pair of solutionsx1,x2∈X′, and (2) there exists no edge(x1,x2)∈EnEn′such thatx1∈X′andx2∈XX′. The neutral network of a solution x will be denoted as NN(x). Finally, another important concept is that of a neutral walk. A neutral walk from x1 to xkrefers to a sequence of solutions 〈x1, x2, …, xk〉 such thatxi+1∈Nn(xi),1≤i<k. That is, a neutral walk represents a path on a neutral network.Proteins are fundamental elements of living organisms. These chain-like molecules are composed from a set of 20 different building blocks called amino acids. The specific sequence of amino acids of a protein determines how it folds into a unique compact conformation responsible for its biological functioning. Among all the possible conformations that a protein can adopt, it is believed that the optimal conformation, often referred to as the native state, corresponds to the one minimizing the overall free-energy (Anfinsen, 1973). Thus, the protein structure prediction (PSP) problem, can be stated as the problem of finding the functional, energy-minimizing conformation for a protein given only its amino acid sequence.Amino acids can be classified on the basis of their affinity for water. Hydrophilic or polar amino acids (P) are usually found at the outer surface of proteins. By interacting with the aqueous environment, P amino acids contribute to the solubility of the molecule. In contrast, hydrophobic or nonpolar amino acids (H) tend to pack on the inside of proteins, where they interact with one another to form a water-insoluble core. This phenomenon, usually referred to as hydrophobic collapse, is a major driving force in protein folding, representing the reasoning and motivation behind the hydrophobic-polar (HP) model of the PSP problem studied in this paper (Dill, 1985; Lau & Dill, 1989).In the HP model, proteins are abstracted as chains of H- and P-type beads. Protein sequences, which are originally defined over a 20-letters alphabet, are now of the form S = 〈a1, a2, …, aℓ〉, where ai∈ {H, P} denotes the i-th amino acid and ℓ is the length of the sequence. A valid protein conformation is modeled as a self-avoiding walk on a given lattice, that is, as an embedding of the protein chain on the lattice such that the following two properties are satisfied: (i) self-avoidance, two different amino acids cannot be mapped to the same lattice position; and (ii) connectivity, consecutive amino acids in S are to be also adjacent in the lattice. This research work focuses on both, the two-dimensional square and three-dimensional cubic lattices. With the aim of emulating the so-called hydrophobic collapse, the goal in the HP model is to maximize the interaction among H amino acids in the lattice. Such interactions are to be referred to as H–H topological contacts. Two H amino acids aiand ajare said to form a topological contact if they are nonconsecutive in S (i.e., |j − i| ≥ 2) but adjacent in the lattice. The objective is thus to find a valid structure where the number of H–H topological contacts, HHtc, is maximized. Adhering to the notation of the field, an energy function, to be minimized, is defined as the negative of HHtc.LetXbe the set of all potential protein conformations, i.e., the search space, and letXFdenote the subset of all the feasible states(XF⊊X). PSP under the HP model can be formally defined as the problem of findingx*∈XFsuch thatE(x*)=APTARANORMALmin{E(x)0.35em0ex|0.35em0exx∈XF}. The energy functionE:X→Rmaps each possible conformationx∈Xto an energy value; formally,(4)E(x)=∑ai,aje(ai,aj),wheree(ai,aj)={−1,0.35em0exif0.35em0exai0.35em0exand0.35em0exaj0.35em0exareboth0.35em0exH0.35em0exandtheyforma1em0extopologicalcontact;0,otherwise.As an example, the optimal structure for a protein sequence of length ℓ = 20 on the two-dimensional square lattice is presented in Fig. 1. This example corresponds to sequence 2d4, one of the test cases considered in this study, see Appendix A.1.An internal coordinates representation based on absolute moves has been implemented in this study. A protein conformation is encoded as a sequence of moves specifying the lattice position for each amino acid with regard to the preceding one (the position of the first amino acid is fixed). On the three-dimensional cubic lattice, conformations are thus defined as sequences in {F, B, L, R, U, D}L − 1, to denote the forward, backward, left, right, up and down moves from one amino acid to the next. Only moves {F, B, L, R} are considered when using the two-dimensional square lattice, see Fig. 2.The prediction of protein structures based on the HP model is a hard combinatorial optimization problem which has been proved to be NP-complete (Berger & Leighton, 1998; Crescenzi et al., 1998). An extensive literature exists on the use of metaheuristics to address this problem, including genetic algorithms (Custódio, Barbosa, & Dardenne, 2014; Lopes, 2008), memetic and hybrid algorithms (Islam & Chetty, 2013; Krasnogor, Blackburne, Burke, & Hirst, 2002; Rashid et al., 2013), tabu search (Pardalos, Liu, & Xue, 1997), ant colony optimization (Nardelli, Tedesco, & Bechini, 2013; Shmygelska & Hoos, 2005), immune-based algorithms (de Almeida, Gonçalves, & Delgado, 2007; Cutello, Nicosia, Pavone, & Timmis, 2007), particle swarm optimization (Mansour, Kanj, & Khachfe, 2012; Zhou, Hou, Zhang, & Wei, 2013), differential evolution (Lopes & Bitello, 2007; Santos & Diéguez, 2011), estimation of distribution algorithms (Chen, Li, & Hu, 2009; Santana, Larranaga, & Lozano, 2008), artificial plant optimization (Cai, Wu, Wang, Kang, & Wu, 2013), and firefly-inspired algorithms (Maher, Albrecht, Loomes, Yang, & Steinhöfel, 2014).Three different multi-objectivization schemes for the HP model are analyzed in this study: the parity decomposition (Garza-Fabre et al., 2012a), the locality decomposition (Garza-Fabre, Toscano-Pulido et al., 2012) and the H-subsets decomposition (Garza-Fabre et al., 2012b). As their name indicates, these approaches are based on the decomposition of the original energy (objective) function of the HP model. Decomposition, as discussed in Section 2.2, has the potential effect of introducing incomparability among solution candidates. In this way, these alternative multi-objective formulations of the problem can be useful as a means of accepting degrading moves (i.e., replacement of a solution with an inferior one), and thus can be implemented as a mechanism to prevent search algorithms from becoming trapped in local optima. The parity, locality and H-subsets decompositions are described in detail in Sections 3.1, 3.2 and 3.3, respectively.In the two-dimensional square and three-dimensional cubic lattices, the two variants of the HP model covered by this research project, adjacencies (topological contacts) are only possible between amino acids whose positions in the protein sequence are of opposite parity, see Fig. 3. Based on this fact, a two-objective formulation f(x) = [f1(x), f2(x)]Tis defined over the set of all potential protein conformationsx∈X:(5)f1(x)=∑ai,aje(ai,aj),1em0exi≡00.35em0ex(mod2),1em0exi<j;(6)f2(x)=∑ai,aje(ai,aj),1em0exi≡10.35em0ex(mod2),1em0exi<j;where both f1(x) and f2(x) are to be minimized and e(ai, aj) represents the conventional energy contributions of the HP model as defined in Section 2.4. That is, the objective function f1 accounts only for H–H topological contacts between pairs of amino acids ai, aj, where i, the sequence position of amino acid ai, is even (i < j). On the contrary, f2 is defined for those cases where such the i-th sequence position is odd. Note that the sum of the two new alternative objectives equals the conventional energy function of the HP model presented in Section 2.4 (i.e.,E(x)=f1(x)+f2(x)0.35em0exforall0.35em0exx∈X), which is in accordance with the decomposition approach for multi-objectivization, see Section 2.2. Fig. 3 presents the optimal conformation for protein sequence 2d4 on the two-dimensional square lattice. In the particular case of this conformation, the values for the objective functions are f1 = 0 and f2 = −9.In this multi-objectivization scheme, the conventional energy function of the HP model is decomposed based on the locality notion of amino acid interactions. An H–H topological contact between amino acids aiand ajcan be considered to represent either a local or a nonlocal interaction. This classification depends upon whether or not the sequence distance between aiand aj(i.e., |j − i|) is within a given maximum δ, see Fig. 4.From this, a two-objective problem formulation, f(x) = [f1(x), f2(x)]T, is defined for every potential protein conformationx∈X:(7)f1(x)=∑ai,aje(ai,aj),1em0exj−i≤δ,i<j;(8)f2(x)=∑ai,aje(ai,aj),1em0exj−i>δ,i<j;where functions f1(x) and f2(x) are both to be minimized and e(ai, aj) denotes the conventional energy contributions defined previously in Section 2.4. Thus, the objective function f1 is defined for all the local interactions, whereas the objective function f2 accounts for the nonlocal ones. In this way, the evaluation of the example conformation illustrated in Fig. 4 under this alternative formulation leads to objective values f1 = −7 and f2 = −2. Note thatE(x)=f1(x)+f2(x)0.35em0exforall0.35em0exx∈X, which is consistent with the decomposition approach for multi-objectivization, as defined in Section 2.2.It is worthy to mention that parameter δ plays a decisive role for the behavior of this proposal. In Garza-Fabre, Toscano-Pulido et al. (2012), an analysis was conducted in order to investigate the influence of varying this parameter on the performance of two different evolutionary algorithms. All odd values in the range [3,21] were considered in the analysis.44In the two-dimensional square and the three-dimensional cubic lattices, a topological contact can only occur if the sequence distance between the amino acids is odd and at least equal to 3.As a result, the best performance for the evaluated algorithms were observed when δ assumes low values around 7.In the H-subsets decomposition, all H amino acids in the protein sequence are first assigned to one of two possible groups,H1orH2. In this study,H1andH2are to be referred to as the H-subsets and such an assignment of H amino acids to these groups is to be called the H-subsets formation process. Fig. 5illustrates one of different H-subsets formation strategies which are described later at the end of this section.Once the H-subsets have been formed, an alternative two-objective formulation f(x) = [f1(x), f2(x)]Tof the problem can be defined as follows (x∈X):(9)f1(x)=∑ai,aj∈H1e(ai,aj)+∑ai,aj∈H2e(ai,aj),(10)f2(x)=∑ai∈H1,aj∈H2e(ai,aj),where f1(x) and f2(x) are both minimization functions and e(ai, aj) denotes the conventional energy contributions of the HP model (Section 2.4). In this way, function f1 accounts for H–H topological contacts where the two amino acids belong to the same H-subset, either toH1or toH2. On the contrary, f2 is defined for H–H topological contacts between amino acid pairs where each amino acid belongs to a different H-subset. Notice thatE(x)=f1(x)+f2(x)0.35em0exforall0.35em0exx∈X, which adheres to the definition of the decomposition approach for multi-objectivization, as provided in Section 2.2.Given the assignment of H amino acids to the H-subsets illustrated in Fig. 5, the structure in Fig. 6presents four H–H topological contacts defined between amino acids belonging to the same H-subset, while the remaining five H–H interactions occur between amino acids from different H-subsets. In this example the objective values are thus f1 = −4 and f2 = −5.The H-subsets formation process plays a major role for this decomposition proposal. Different strategies can be adopted in order to accomplish this task; three of them have been explored in Garza-Fabre et al. (2012b), namely (i) FIX: the first half of H amino acids in S are assigned toH1, all others toH2, as shown in Fig. 5; (ii) RND: each H amino acid can be assigned toH1or toH2with equal probability; and (iii) DYNk: it is based on the RND strategy, but the H-subsets are recomputed after k iterations of the search algorithm without achieving an improvement. From the results reported in Garza-Fabre et al. (2012b), the best performance can be achieved by implementing the DYNkstrategy. This suggests that the effect of decomposition for allowing algorithms to escape from local optima can be further enhanced by changing the landscape dynamically throughout the search process.This section is devoted to investigating the potential effects that can be achieved by multi-objectivization. Although three different multi-objectivization schemes for the HP model are covered by this research work, only the locality decomposition (defined in Section 3.2), using a value of δ = 7, is considered in this section due to the high computational demands of the conducted analyses. The locality decomposition has been found, in the authors’ previous work (Garza-Fabre et al., 2012b; Garza-Fabre, Toscano-Pulido et al., 2012), to provide a quite promising behavior, as it will also be shown in subsequent sections of this document. For convenience, hereafter the locality decomposition will be simply referred to as the multi-objective (MO) formulation of the problem. Similarly, two (relatively) small test instances, sequences 2d4 and 3d1, are investigated in this section (refer to Appendix A.1 for details).55Notwithstanding, given the absolute moves encoding described in Section 2.4, the size of the search space for these (relatively) small instances is huge, namely 419 for 2d4, and 619 for 3d1.It is expected, however, that other different multi-objectivization proposals and test cases can be explored with similar results.As stated in Section 2.4, the quality of a candidate solution in the HP model is evaluated in terms of an energy function, E, defined as the negative of the total number of H–H topological contacts that the encoded protein structure presents, HHtc. Nevertheless, the use of positive rather than negative values, as well as the adoption of the term fitness (to be maximized) rather than that of energy (to be minimized), is considered more appropriate for the analysis here reported. Therefore, in the remainder of this section the fitness of a solution x, Fitness(x), will assume the value of HHtc(x), i.e.,(11)Fitness(x)=HHtc(x)=−E(x).It is worthy to mention that the term fitness is used in this study to refer to the quality of solutions under the conventional single-objective (SO) evaluation scheme of the HP model.66Although alternative multi-objective formulations of the HP model are studied, the goal remains always to solve the original single-objective problem.In addition, it is important to briefly introduce the concept of a fitness class; a solutionx∈XFwill be said to belong to the fitness class c if it presents a fitness value of Fitness(x) = c.The analyses conducted in this section are based on an initial set of sampled solutions. Hence, the implemented sampling methodology is first introduced in Section 4.1. In Section 4.2, the effects of multi-objectivization are investigated in terms of how this transformation influences the comparability relation among solutions. Finally, Section 4.3 evaluates the extent to which such an alteration in the comparability of solutions can be translated into fundamental changes on the fitness landscape structure of the problem.The implemented sampling strategy was conceived by taking into account the following considerations: (i) a total of M different feasible solutions for the given problem instance are to be generated; (ii) the M generated solutions are to be, if possible, evenly distributed over the different available fitness classes (all fitness classes should be well represented in the collected sample); and finally, (iii) the diversity among solutions belonging to the same fitness class should be maximized.Algorithm 1 outlines the adopted sampling strategy. The procedure starts by initializing the sample setSand by identifying the set of all possible fitness classes for the given problem instance,FC(lines 1 and 2 in Algorithm 1). Iteratively, a search algorithm is executed and all solutions that this algorithm reaches during the search process are kept inU(line 4). Then, the subsetUcof solutions inUbelonging to each possible fitness classc∈FCis identified (line 6). Finally, the solutionAPTARABOLDx^∈Ucthat best contributes to increasing the diversity inS, if any, is included in the sample (lines 7–9). This process continues until completing the required sample.Algorithm 1Sampling of the initial solution sets.Input:MOutput:S1:S←⌀2:FC←{Fitness(x)0.35em0ex|0.35em0exx∈XF}3: while|S|<Mdo4:U←search_algorithm()5:for allc∈FCdo6:Uc←{x∈U0.35em0ex|0.35em0exFitness(x)=c}7:x^←argmaxx∈Ucdiversity(x,S)8:ifdiversity(APTARABOLDx^,S)>0then9:S←S∪{APTARABOLDx^}10:end if11:end for12: end whileAny metaheuristic could be implemented as the embedded search method. An Iterated Local Search (ILS) algorithm (Lourenço, Martin, & Stützle, 2010), based on the SO problem formulation, was used in this study; refer to Appendix B.2 for details. Due to its distinctive exploration behavior, the ILS method can potentially reach a different local optimum at each iteration. Each time the ILS was invoked during the sampling procedure, this algorithm was allowed to run for a total of5×105solution evaluations.The diversity contribution estimates have been partially based on the diversification mechanism proposed by Chira (2011). Instead of measuring diversity in genotype (encoding) space, in Chira (2011) diversity was computed from the contact fingerprint of candidate solutions. The contact fingerprint for a solution is given by the binary vector cf, where each component cfi∈ {0, 1} indicates whether a particular pair of amino acids in the encoded structure defines a topological contact or not. Vector cf considers as many components as the total number of amino acid pairs which can potentially form a topological contact.77In order for an amino acid pair (ai, aj) to form a topological contact, i and j need to be of opposite parity and |j − i| ≥ 3.The use of the contact fingerprint rather than the encoding of solutions certainly fosters the development of more effective diversity promotion mechanisms. This can be explained by the fact that very different encodings may represent the same protein structure (after rotation or reflection). Note, however, that significantly different structures may also present the same contact fingerprint vector if they share the same set of topological contacts. This has motivated the use of a more fine-grained version, referred to in this study as the distance fingerprint.The distance fingerprint for a given solution is defined by the vector df, each of whose components dfimeasures the distance between the lattice coordinates of a particular pair of amino acids. The Manhattan distance was employed for this sake. A total of(ℓ2)−2ℓ+3components describe the distance fingerprint vector df; i.e., only amino acid pairs (ai, aj) such that |j − i| ≥ 3 require to be considered. Finally, the diversity contribution for a new candidate x with respect to the already collected sampleS,diversity(x,S), has been computed as the minimum Hamming distance (Hd) between the distance fingerprint vector of x and that of anyx′∈Swith the same fitness value as x. Formally,(12)diversity(x,S)=APTARANORMALmin{Hd(df(x),df(x′))|x′∈S∧Fitness(x)=Fitness(x′)}.The size of the sample was set to M = 1000 for both the 2d4 and 3d1 instances. Ideally, it is expected to generate a sample such that aboutM/|FC|different solutions represent each possible fitness class. This was the case of the sample set constructed for the three-dimensional instance 3d1, where a total of 83 or 84 different solutions were obtained for each of the|FC|=12available fitness classes, see Table 1. Note, however, that due to the funnel-like energy landscape which characterizes the HP model (Dill, 1997), not all fitness classes for some of the instances can be equally sampled. As detailed in Table 1, only a reduced number of solutions with a high fitness value (Fitness = 8 and Fitness = 9) were obtained when sampling the search space of the 2d4 instance, so that a greater number of representatives for the remaining fitness classes were accepted in order to complete the M required solutions.The three multi-objectivization proposals considered in this study are all of them based on the decomposition of the original energy (objective) function of the HP model, see Section 3. As stated in Section 2.2, the only possible effect that can be achieved through decomposition is that originally comparable solutions may become incomparable (nondominated in terms of the Pareto-dominance relation) under the new multi-objective formulation of the problem. To illustrate this, consider the example provided in Fig. 7. In this figure, conformation x1 (to the left) presents 9 H–H topological contacts, while conformation x2 (to the right) involves only 3. These originally comparable solutions (i.e., x1 is clearly superior to x2) have become mutually nondominated when comparing them under the multi-objective formulation defined by the locality decomposition (δ = 7). The goal of this section is not only to illustrate such an effect of decomposition, but also to explore the extent to which solutions belonging to different fitness classes can become incomparable as a consequence of this transformation.An experiment was performed as follows. A sample set of M = 1000 different solution candidates was generated by implementing the methodology detailed previously in Section 4.1. Then, all possible pairwise comparisons among the sampled solutions were performed. From this, it was computed the ratio between the number of incomparable solution pairs found and the total number of pairwise comparisons carried out; this measure is to be referred to as the incomparability ratio (IR). IR is thus defined in the range [0, 1], and IR = 1 indicates that all the evaluated solution pairs were found to be incomparable. This experiment was replicated for both the conventional single-objective HP model formulation, SO, and the alternative multi-objective formulation, MO. The comparison of solutions under the MO formulation relies on the Pareto-dominance relation and the locality decomposition. Both the 2d4 and 3d1 instances were considered. The obtained results are summarized in Table 2. As it can be seen from this table, 70,616 out of the(10002)=499,500total pairs of sampled solutions for instance 2d4 became incomparable when evaluated under the MO formulation. This represents an IR increase of 0.14 with regard to the conventional SO formulation. Similarly, multi-objectivization increased the IR measure by 0.13 when focusing on the 3d1 instance. Such an increase of 0.13 results from the 63,760 comparable solution pairs for which the original preference relation has been suppressed.88Note that, by definition, only solutions having the same fitness value are incomparable under the SO formulation of the problem.Finally, the results obtained using the MO formulation are broken down in Figs. 8 and 9in order to gain further insights into the likelihood of incomparability taking place among different fitness classes. Figs. 8 and 9 show (for the 2d4 and 3d1 instances, respectively) the IR measure computed separately for each possible pair of fitness classes (i.e., fitness classes with respect to the conventional SO formulation). Heat maps in these figures are symmetric along the diagonal. From Figs. 8 and 9, it is possible to see that multi-objectivization makes incomparability possible even for pairs of solutions which are distant with respect to their fitness values. As an example, Fig. 8 highlights that incomparability has been introduced between fitness classes 3 and 9 of instance 2d4 (as illustrated in Fig. 7). A similar scenario can be found with regard to fitness classes 4 and 10 from the collected sample for sequence 3d1, see Fig. 9. Note, however, that the closer the fitness classes for the selected pairs of solutions, the higher the IR values indicated in these figures (the highest IR values appear close to the diagonal). This can be understood by the fact that the increase in the fitness distance between a pair of solutions increases also the probability for a solution to be dominated (in the Pareto sense) by the other. Finally, it should be observed that in the case of both the 2d4 and 3d1 instances, no solution at fitness class 0 became incomparable with respect to any other solution from a higher fitness class. This is due to the fact that any solution x1 with Fitness(x1) = 0, f1(x1) = 0 and f2(x1) = 0 after applying decomposition, will always be dominated by any other solution x2 with Fitness(x2) > 0, no matter how Fitness(x2) is decomposed into the new set of objectives.As discussed in Section 4.2, multi-objectivization by decomposition exerts an influence on the comparability relation over the search space, in such a way that solutions from different fitness classes may become incomparable when evaluated under the new multi-objective formulation of the problem. This notion of incomparability is equivalent to that of neutrality used in the context of fitness landscapes analysis. Two solutions are said to be neutral (i.e., incomparable) if either they share the same fitness value (single-objective case), or they are Pareto-nondominated with respect to each other (multi-objective case), see Section 2.3. Hence, the potential effect of multi-objectivization, previously described in terms of introducing incomparability among solutions, will be referred in this section to as that of increasing the neutrality in the fitness landscape. This section is intended to contribute in understanding and, to some extent, quantifying such an effect of multi-objectivization on the HP model’s fitness landscape.As detailed in Section 2.3, three important components define a fitness landscape(X,N,ξ). While the search spaceXand the neighborhood structureNwere kept constant in this study,99Xis given by the absolute moves encoding (Section 2.4). Likewise,N(x)is defined by all solutions which can be reached through a single change in the encoding of x. Thus,|N(x)|=3(ℓ−1)and|N(x)|=5(ℓ−1)in the two- and three-dimensional cases, ℓ denoting the length of the protein sequence.ξ has been varied from the conventional single-objective, SO evaluation scheme of the HP model to the alternative multi-objective, MO one (based on the locality decomposition and the Pareto-dominance relation). By analyzing and comparing the landscapes induced by the SO and MO evaluation schemes, it will then be possible to evaluate the extent to which multi-objectivization has impacted on essential problem characteristics, those related to neutrality. Neutrality is here investigated by evaluating different properties of neutral networks (NNs); since neutral fitness landscapes, as those in the HP model, are known to be mainly described by their NNs (Marmion, Dhaenens, Jourdan, Liefooghe, & Vérel, 2011). Nevertheless, NNs in a neutral fitness landscape can be of a considerable size, so that their exhaustive exploration becomes computationally prohibitive even for relatively small problem instances. In the literature, NNs are usually sampled through neutral walks, i.e., series of (neutral) neighboring solutions. In this study, however, an alternative approach was taken, as described below.Algorithm 2pNN() – Partial NN computation.Input:x,depthLevel,maxDepthOutput:NN(x)1:NN(x)←(V,E):V={x},0.35em0exE=⌀2: ifdepthLevel<maxDepththen3:for allx′∈Nn(x)do4:NN(x′)←pNN(x′,depthLevel+1,maxDepth)5:NN(x)←NN(x)⋃NN(x′)6:E←E∪{(x,x′)}7:end for8: end ifGiven a sample setSof M different solution candidates, collected following the methodology previously detailed in Section 4.1, the neutral network NN(x) for each solutionx∈Shas been partially computed based on the pNN() procedure outlined in Algorithm 2. As shown in this algorithm, NN(x) is constructed recursively in a depth-first manner by allowing this procedure to reach a maximum defined depth level (maxDepth). The initially given solution x is assumed to be at depth level 0, so that depthLevel = 0 is used in the first call to pNN(). At each call to the pNN() method, NN(x) is first initialized to the graph containing no edges and including the provided solution x as the only node (line 1 in Algorithm 2). If the maximum allowed depth level has not been reached (line 2), the sub-network NN(x′) for every neutral neighbor x′ of x is obtained from a subsequent execution of the pNN() method (by giving x′ as the new starting point and by increasing the value of depthLevel, see line 4). The resulting sub-network NN(x′) is then merged with the parent network NN(x) by means of a graph union operation, here denoted as⋃(line 5).1010GivenG1=(V1,E1)andG2=(V2,E2), the graph union operationG1⋃G2producesG3=(V3,E3)such thatV3=V1∪V2andE3=E1∪E2.Finally, edge (x, x′) is included in NN(x) in order to establish the linkage between NN(x) and the NN(x′) sub-network. Partially computing the NN for a given solution x, is equivalent to traversing all possible neutral walks departing from x, by restricting the length of the walks to the maximum defined depth level (maxDepth).The 2d4 and 3d1 test instances have been considered for this analysis, and the size of the initial sample sets was fixed to M = 1000 in both cases. Thus, a total of 1000 (potentially different) NNs for each of the instances have been explored by using both, the SO and MO evaluation schemes, as the basis for neutrality verification. In this way, changing the problem formulation from SO to MO will be reflected as an alteration in the properties of the sampled NNs. In the remainder of this section, the neutral network for a given solution x will be either referred to as NNSO(x) or NNMO(x), depending on whether the neutrality relation among solutions was determined based on the SO or MO evaluation schemes during the network computation. Finally, in order to overcome the high computational cost of the conducted analysis, the maximum allowed depth level was set to maxDepth = 10 and maxDepth = 7 for the 2d4 and 3d1 test sequences, respectively.1111Despite the use of such low maxDepth values, the resulting NNs were considerably large, as it will be analyzed in Section 4.3.2.The remaining of this section proceeds as follows. In Section 4.3.1, the fitness landscape transformation is first investigated in terms of how multi-objectivization impacted on the neutrality degree of solutions. This is captured by means of the average neutrality ratio. Then, Section 4.3.2 evaluates the extent to which such alteration on the neutrality degrees led to the increase in the size of the computed NNs. Finally, these increases in the size of the NNs are explained in Section 4.3.3 as a result of the connectivity that multi-objectivization introduces between NNs from different fitness classes.As a means of evaluating the increase on neutrality caused by multi-objectivization, the average neutrality ratio (ANR) of the sampled NNs is investigated. The ANR is defined as the mean of the neutrality ratios (as defined previously in Section 2.3) considering all solutions in a NN (Vanneschi et al., 2007; Vanneschi et al., 2012). This measure assumes values in the range [0, 1], where 1 corresponds to the highest neutrality. Figs. 10 and 11contrast, for the 2d4 and 3d1 instances, respectively, the ANR values obtained when using the SO and MO formulations (i.e., the ANR values computed from NNSO(x) and NNMO(x), for allx∈S). In these figures, the obtained ANR values appear organized according to the fitness of the solution given as the starting point for the NN sampling. In addition, the mean of the ANR values in each fitness class is indicated for both the SO and MO formulations. From Figs. 10 and 11, a general tendency can be perceived with regard to the neutrality of the HP model’s fitness landscapes. In all the cases, ANR rapidly decreases with the increase in fitness. That is, while poor quality solutions (with low fitness values) are usually surrounded by a considerable number of neutral neighbors, leading to large NNs (see Section 4.3.2), solutions at the highest fitness classes tend to be more isolated and enclosed by infeasible states.1212The fitness, defined as the number of H–H topological contacts, is directly related to the compactness of the encoded structures; the higher the fitness value, the more compact the structure tends to be. Hence, it is easy to think that most perturbations to the encoding of a compact structure could lead either to an infeasible solution, or to a less folded state which worsens the fitness.In most fitness classes, it is evident from the figures that there was a slight increase in the ANR measure as a consequence of using the MO formulation (see fitness classes 2–7 of the 2d4 instance, and fitness classes 3–11 of the 3d1 instance). It is important to note that no increase in the ANR is possible for NNs at fitness class 0. This is due to the fact that, as discussed at the end of Section 4.2, a solution at this fitness class cannot become neutral with respect to any other solution at a higher fitness class. After multi-objectivization, any solution x with Fitness(x) = 0 will still be considered inferior (dominated in the Pareto sense) with regard to any solution x′ with Fitness(x′) > 0. Thus, NNs for solutions at fitness class 0 will be exactly the same regardless of whether they are computed based on the SO or MO formulations (this applies also for subsequent analyses presented in Sections 4.3.2 and 4.3.3).Despite the minor increases in the average neutrality ratio (ANR) obtained through the use of a multi-objective formulation, a small variation in the neutrality degree of solutions can still contribute significantly to increasing the size (number of solutions) of a NN. Therefore, in this section the size of the computed NNs is analyzed. For each sampled solutionx∈S, the size of the NNSO(x) and NNMO(x) networks is shown in Figs. 12(for instance 2d4) and 13(for instance 3d1). The results are presented separately for each fitness class, and the arithmetic mean in each of the cases is also indicated. Plots are given in a logarithmic (base 10) scale. These figures expose the high neutrality that characterizes the fitness landscapes in the HP model. Even when the sampling of NNs was restricted in this study by setting a maximum allowed depth level, as stated in Section 4.3, it is possible to see from the plots that NNs at fitness class 0 involve above 106 and around 108 solutions for the 2d4 and 3d1 instances, respectively. From Figs. 12 and 13, it is also possible to confirm that, as suggested in Section 4.3.1, the size of the NNs is usually larger for low fitness classes, but neutrality tends to decrease as higher quality solutions are considered. An important increase in the size of the NNs can be observed in most of the cases due to the use of the MO formulation. As the plots indicate, NNs computed based on the MO formulation can be several orders of magnitude larger than those computed based on the SO formulation.To go further in this analysis, the neutral network size ratio (NSR) is defined as the ratio of the size of NNSO(x) to that of NNMO(x). In fact, NNMO(x) will always be a supergraph containing all nodes and edges of NNSO(x), but including also those nodes and edges which result from the neutrality introduced by the multi-objectivization. Thus, NNMO(x) will have at least the same size as NNSO(x), so that NSR is defined in the range [0, 1] and NSR = 1 indicates that no change in the NN size was achieved when varying the problem formulation. Figs. 14 and 15show the NSR for all the sampled NNs along with the mean values calculated for each fitness class. Multi-objectivization led to an important rise in the size of the explored NNs for most fitness classes of the 2d4 instance (Fig. 14). The sharpest increase in the NNs size can be observed at fitness class 3, for which the lowest average NSR value has been scored. In average, the size of NNSO(x) is only about 65% of the size of NNMO(x) when Fitness(x) = 3. The impact of using the MO formulation becomes more evident when focusing on the 3d1 instance (Fig. 15). The average NSR values for most fitness classes are below 0.5. This evinces that NNMO(x) at least doubled the size of NNSO(x) in the vast majority of the cases. Finally, it is possible to note from Figs. 14 and 15 that a considerable number of very low NSR values (close to 0) have been accounted for, indicating a highly significant increase in the size of the corresponding NNs.The observed increments with regard to the size of the NNs, as analyzed in Section 4.3.2, can be understood as the result of allowing neutral connections to be established between NNs. While in the single-objective case all solutions in a NN share, by definition, the same fitness value, in a multi-objectivization scenario such a strict definition of a NN can no longer be supported. That is, given the adopted notion of neutrality for the multi-objective case, which is based on the Pareto-dominance relation (see Section 2.3), a NN constructed using as the basis the MO formulation may involve solutions from varying fitness classes, thus connecting the corresponding NNs. Consider two NNs, NN1 and NN2, such that the fitness of NN1 is Fitness(NN1) = A and the fitness of NN2 isFitness(NN2)=B,A0.25em0ex≠0.25em0exB. If, as a result of using the MO formulation, at least a solution x1 from NN1 comes to be neutral with respect to a neighboring solution x2 which belongs to NN2, then this neutral connection between NN1 and NN2 will merge the two NNs together into a single NN where both the fitness classes A and B are represented. To further illustrate these ideas, refer to the example provided in Fig. 16. This figure presents a series of neutral moves between neighboring solutions, i.e., a neutral walk, based on the MO formulation. The neutrality that the MO formulation introduced between these solutions led to the formation of neutral connections between three different NNs: NN(x1) at fitness class 5, NN(x2, x3) at fitness class 4 and NN(x4) at fitness class 6. The four solutions x1, x2, x3 and x4, and all solutions belonging to their respective NNs, became part of a single larger NN as a consequence of multi-objectivization.From the above introduced notion of neutral connections, it becomes relevant for this study to investigate the extent to which neutral connections took place, between the different fitness classes, during the performed sampling of NNs. Figs. 17 and 18summarize the results obtained for the 2d4 and 3d1 instances. The NNs constructed for each fitness class c were analyzed (i.e., c is the fitness of the initially given solution for the NN computation), and these figures indicate whether neutral connections were identified between these NNs and NNs at each other possible fitness class c′. The total number of neutral connections found of each type, if any, is shown in parentheses. Diagonals in Figs. 17 and 18 are used only as a reference (i.e., all NNs connect to themselves at their corresponding fitness classes) to illustrate the single-objective case, so that all other connections not appearing along the diagonal are due to the landscape transformation. As an example, Fig. 17 indicates (regarding sequence 2d4) that, out of the 118 sampled NNs for fitness class 1, only 16 formed neutral connections to NNs at fitness class 6. Through these figures it is then possible to gain an insight into the diversity of fitness classes that a NN, computed based on the MO formulation, may involve. Figs. 17 and 18 highlight that a significant number of neutral connections were originated by multi-objectivization. On the one hand, NNs from fitness classes 2 to 6 of instance 2d4 presented neutral connections to all fitness classes between 1 and 7 (at least one connection in each of the cases can be observed from the plot). Note also that only a few neutral connections, all of them to inferior fitness classes, were produced from NNs at fitness classes 7 and 8. No NNs at fitness class 9 connected to others. On the other hand, a higher number of neutral connections were generated with regard to the 3d1 test instance. As it can be seen from Fig. 18, connections were established, in one direction or the other, between almost all pairs of fitness classes. That is, even though the NNs computed for fitness classes 2–5 did not form connections to fitness class 11, multiple connections from class 11 to all such lower fitness classes were created. This points out the fact that inferior fitness classes are easier to reach than the superior ones (because of the funnel-like search landscape that characterizes the studied problem (Dill, 1997)).A neutral connection from a fitness class c to a fitness class c′ indicates that, given an arbitrary solution x with Fitness(x) = c, a neutral walk departing from x could potentially lead to a solution x′ with Fitness(x′) = c′. Nevertheless, as Figs. 17 and 18 suggest, the more distant the fitness classes c and c′, the lower the likelihood that these classes can connect to each other through a neutral walk (in the plots, higher number of neutral connections are shown closer to the diagonal). Such a behavior is certainly accentuated if the length of the walks is bounded (as done in this study with the use of parameter maxDepth). In addition, although (relatively) distant fitness classes can directly connect to each other, i.e., in a single step of the neutral walk, the increase in the fitness distance between a pair of solutions decreases the probability for these solutions to become incomparable after multi-objectivization, as analyzed at the end of Section 4.2. Thus, the connection between distant fitness classes is more likely to occur through a series of intermediate states. This point can be better explained by considering Fig. 19. Taking as examples the fitness class 5 for instance 2d4 and fitness class 10 for instance 3d1, this figure illustrates how the neutral connections to the different fitness classes arose as each allowed depth level was reached during the NNs computation.1313Similar results to those presented in Fig. 19 were obtained for the different fitness classes of the considered test instances.The mean depth level at which connections to the different fitness classes were produced is also provided. It is possible to see from the plots that neutral connections to different fitness classes were given directly at depth level 1. Classes {2, 3, 4, 6} were directly connected from NNs at fitness class 5 of instance 2d4. Similarly, classes {4, 6, 7, 8, 9, 11} were connected in a single step from NNs at fitness class 10 of instance 3d1. Note, however, that the mean depth level values in these plots confirm the above suggested tendency, that the distance between fitness classes is closely related to the number of neutral steps that will be usually required to connect different NNs.Finally, it is important to address the question of how the formation of neutral connections may impact on the behavior of a search algorithm. As it has been seen, multi-objectivization can affect the neutrality relation for a given solution x in two possible directions: (i) x becoming neutral with respect to an inferior solution, i.e., connection to a lower fitness class; or (ii) x becoming neutral with respect to a superior solution, i.e., connection to a higher fitness class. In the former scenario, multi-objectivization can be thought of as enhancing the mobility of the search algorithm. By connecting to lower fitness classes, the algorithm is allowed to traverse landscape areas which were originally inaccessible under the conventional SO evaluation scheme. In the neutral walk illustrated in Fig. 16, for example, to move from fitness class 5 (x1) to fitness class 6 (x4) it was required to accept a degrading move to fitness class 4 (x2 and x3). In this way, the movement through inferior solutions constitutes the basis for a potential strategy to escape from local optima. It should be noted, therefore, that the design of the search algorithm will play a critical role for achieving success through the problem transformation. The new defined neutral paths can only be exploited if the algorithm is designed so as to accept moves between neutral solutions (or, in the words of Barnett, if the algorithm is able to crawl the NNs (Barnett, 2001)). The formation of neutral connections to superior fitness classes, the later scenario, can be analyzed from two different perspectives. On the one hand, these connections (indeed all neutral connections in general) reduce what is called selective pressure in the context of evolutionary optimization (Back, 1994), which can boost the exploration behavior of an algorithm. On the other hand, neutral connections to superior fitness classes can be interpreted as a loss in gradient information. Rather than benefiting from multi-objectivization, for instance, a search algorithm based on a strictly-better acceptance criterion could easily stagnate due to its inability to perform a proper discrimination. By relaxing the comparability relation among solutions, thus, multi-objectivization may also hinder the ability of an algorithm to identify a promising search direction.The aim of this section is to investigate the influence that multi-objectivization can exert on the search behavior of metaheuristic algorithms. To this end, the three studied multi-objectivization schemes, based on the parity (PD), locality (LD) and H-subsets (HD) decompositions, are evaluated and compared with respect to each other and with respect to the conventional single-objective (SO) formulation of the HP model. A basic single-solution-based evolutionary algorithm (EA), the so-called (1 + 1) EA, has been adopted for this sake.All the implementation details of the (1 + 1) EA, as well as all the considered settings for the experiments reported in this section, are presented in Appendix B.1. In the (1 + 1) EA, the discrimination among candidate individuals can be either based on the conventional energy evaluation of the HP model, when using the SO formulation, or it can be based on the Pareto-dominance relation if using the alternative PD, LD and HD multi-objective formulations. Hence, the change in the problem formulation will be determinant for the performance of this algorithm. Details on the used test instances, performance measures, the statistical significance testing methodology and the utilized experimental platform are provided in Appendix A.Tables 3 and 4detail the results that the four studied HP model formulations obtained for all two- and three-dimensional test instances. For each instance, these tables show the best obtained energy value (Eb), the number of performed executions where this solution was found (ν) and the arithmetic mean (E¯). Also, the overall relative root mean square error (O-RMSE) is presented at the bottom of the tables in order to evaluate the general performance of the different formulations analyzed. Additionally, the lowest average energy for each of the instances and the lowest O-RMSE values have been shaded in these tables. As shown in Table 3, HD reached the best average performance for all the 15 two-dimensional instances. This is reflected as an O-RMSE decrease of (31.28 − 19.12) = 12.16% with respect to the conventional SO formulation of the HP model. It can also be noted that LD and PD presented a lower average energy than SO in all the cases, improving the O-RMSE measure by 6.16% and by 2.68%, respectively. The LD formulation achieved the lowest average energy for 12 out of the 15 three-dimensional instances, see Table 4. The best results for the remaining test instances were obtained by using HD. In general, the results of the PD, LD and HD formulations are found to be quite competitive. These approaches improved the O-RMSE measure by 4.55%, 12.36% and 11.55% with respect to the SO formulation, respectively.Table 5outlines how the four studied formulations compare statistically with respect to each other in all the test cases. Each row in this table compares two formulations, say A and B, which is denoted as “A/B”. If a significant performance difference exists between A and B for a particular instance, the corresponding cell is marked eitherordepending on whether such a difference was in favor of, or against A. Empty cells indicate that there was not a statistically important difference between the compared approaches. The rightmost column presents the overall results of this analysis. Out of a total of 30 instances, it can be seen from Table 5 that the multi-objective PD, LD and HD approaches significantly outperformed the conventional SO formulation of the HP model in 23, 28 and 29 of the cases, respectively. By comparing among the multi-objective formulations, the results of LD for 25 of the instances were statistically superior to those obtained by PD. Compared with respect to PD, HD significantly increased the performance of the algorithm for all but one of the test sequences (2d1). Finally, HD was found to perform significantly better than LD in 16 of the instances, while there was a significant difference in favor of LD for 9 of the three-dimensional test cases.Finally, the LD formulation is used as an example in order to illustrate how multi-objectivization affects the search behavior of the (1 + 1) EA. Plots in Figs. 20 and 21contrast the online (throughout the search) performance scored by the SO and LD formulations during a single execution of the (1 + 1) EA when solving, respectively, instances 2d4 and 3d1. Adhering to the notation used previously in Section 4, performance is measured as the fitness class of the current individual at each iteration of the algorithm.1414As it was defined in Section 4, Fitness(x) = HHtc(x) = −E(x).Notice that these figures cover only the first stages of the search process, where the algorithm reached the optimum solution of the considered test instances by using LD (fitness class 9 for instance 2d4 and fitness class 11 for instance 3d1). By focusing first on the convergence behavior achieved through the use of the conventional SO formulation, it is possible to observe from the plots that the algorithm exhibits the punctuated equilibrium that characterizes evolutionary dynamics on neutral fitness landscapes (Gould & Eldredge, 1993). Such a behavior presents long periods of stasis in which the algorithm drifts along neutral networks, thus remaining in the same fitness class, punctuated by occasional transitions between networks (Barnett, 1998). As shown in the plots, the algorithm scored a similar behavior either using the SO or LD formulations at the beginning of the search process (both the SO- and LD-based executions started from the same initial randomly generated individual). It can be noted, however, that the neutrality (incomparability) introduced through the use of the LD formulation, as analyzed in Section 4, allowed the algorithm to accept degrading moves towards inferior fitness classes (in the figures, such degrading moves are shown as decreases in the corresponding LD curves). It is important to emphasize that such degrading moves were perceived as neutral moves from the perspective of the search algorithm. That is, each accepted degrading move represents the movement towards an individual that, despite having a lower fitness value, became part of the neutral network of the parent individual from which it was generated due to the problem transformation. The new defined neutral paths enhance exploration and eventually lead the algorithm to escape from local optima.Multi-objectivization concerns the reformulation of a single-objective problem as a multi-objective one (Knowles et al., 2001). When applied to the particular case of study of this research project, the HP model for protein structure prediction, it has been reported that this transformation provides significant improvements in terms of the performance of search algorithms (Garza-Fabre et al., 2012a, 2012b; Garza-Fabre, Toscano-Pulido et al., 2012). Motivated from these previous findings, the multi-objectivization of the HP model has been further investigated in this study.This study has been divided into two main parts. The first part was devoted to address the primary aim of this study: to inquire into the potential effects of multi-objectivization as a means of understanding how this transformation can influence the behavior of search algorithms. When multi-objectivization is achieved through the decomposition of the original objective function of the problem, as considered in this study, incomparability among solution candidates can be introduced (Handl et al., 2008b). That is, originally comparable solutions may become incomparable when evaluated under the new multi-objective formulation of the problem. As a first step in understanding and quantifying such an effect, it was explored the extent to which incomparability may arise between the different fitness classes. To this end, a large set of sampled solution pairs were evaluated, out of which a considerable number became incomparable as a consequence of the multi-objectivization. It was also found that the more distant the fitness classes for a given pair of solutions, the lower the likelihood that the comparability relation between these solutions can be affected by multi-objectivization.Introducing incomparability among solutions can be alternatively understood as the increase in the neutrality of the fitness landscape. Therefore, a detailed fitness landscape analysis was conducted in order to investigate how multi-objectivization has impacted on such an important problem characteristic. A large number of neutral networks (NNs) were sampled, and the main findings of their analysis can be summarized as follows. By rising the neutrality degree of solutions, multi-objectivization led to the formation of neutral connections between NNs from different fitness classes. That is, when originally comparable neighboring solutions become incomparable by multi-objectivization, their corresponding NNs are merged together into larger connected neutral areas of the landscape.The aforementioned effects of multi-objectivization may lead to different implications from the perspective of a search algorithm. On the one hand, introducing neutrality in the fitness landscape can be reflected as an enhancement in the exploration behavior of the algorithm. That is, by reducing the so-called selective pressure (Back, 1994), an algorithm can be allowed to move through inferior fitness classes as a means of escaping from local optima. On the other hand, the increase in neutrality can also be understood as a loss in gradient information, so that multi-objectivization may also prevent algorithms from identifying promising search directions in some cases.Understanding the potential effects and consequences of multi-objectivization could lead to the design of more effective search algorithms. To the best of the authors’ knowledge, in most of the reported applications of multi-objectivization the original evaluation scheme of the problem is completely replaced by the alternative multi-objectivized one. This corresponds also to the approach assumed in the second part of this study, as it will be discussed later in this section. While the complete replacement of the evaluation scheme has reported very promising results in the literature, the above presented analysis suggests that a better strategy may involve applying multi-objectivization only under certain conditions during the search process; e.g., when stagnation at a local optimum has been detected. Such a strategy could benefit from the potential effects of multi-objectivization as a means of escaping from local optima, at the same time that the gradient information is preserved in order to drive the search process in an effective manner. In the context of the HP model for protein structure prediction, a high degree of neutrality is inherently induced by the conventional evaluation scheme, as it was observed along the conducted analysis. Thus, another interesting approach may consist of alternating the use of multi-objectivization with the use of some other alternative formulation specifically designed to cope with the neutrality of the problem; such as those evaluated in Garza-Fabre, Rodriguez-Tello, and Toscano-Pulido (2013). Exploring these kind of strategies related to the partial (rather than total) use of multi-objectivization is considered as a possible direction for future research.The second part of this study revisited the evaluation of multi-objectivization from the perspective of search performance, as reported in Garza-Fabre et al. (2012a, 2012b) and Garza-Fabre, Toscano-Pulido et al. (2012). Three different multi-objectivization schemes for the HP model were compared and evaluated with respect to the conventional single-objective formulation of the problem. A basic (1 + 1) evolutionary algorithm was considered in this analysis. As a result, it has been found that the use of the alternative multi-objective formulations of the problem significantly increased the average performance of the implemented algorithm in most of the conducted experiments. The obtained results give further support to the suitability of multi-objectivization as a strategy to overcome search difficulties such as that of becoming trapped in local optima.To the best of the authors’ knowledge, the multi-objectivization approaches evaluated in this study represent the first efforts on the use of multi-objective optimization techniques to address the HP model of the protein structure prediction problem. In addition, no previous work has been reported, as far as the authors are aware, where the potential effects of multi-objectivization are investigated through the explicit sampling and evaluation of the characteristics of the fitness landscape. The conducted analysis focused on neutrality. Extending this analysis to evaluate the problem transformation from the perspective of other different landscape properties, e.g., ruggedness (Vassilev, Fogarty, & Miller, 2003), can certainly be seen as a relevant research direction that will contribute to build a more comprehensive picture. Although the performed analysis was applied to a particular case of study, most of the findings regarding the fitness landscape transformation can be generalized to other problem domains. In this way, using the HP model as an example, this study is expected to contribute to the general understanding of multi-objectivization, a concept which represents a current and promising research direction.A total of 30 well-known benchmark sequences for the HP model have been considered for the experimentation of this research project. Out of them, 15 are for the two-dimensional square lattice and the other 15 are for three-dimensional cubic lattice. Tables A.6 and A.7present the full HP sequences, their length (ℓ) and the optimal or best known energy value (E*) reported in the literature (Cutello et al., 2007; Islam & Chetty, 2013; Krasnogor et al., 2002; Thachuk, Shmygelska, & Hoos, 2007; Wüst, Li, & Landau, 2011; Zhang, Kou, & Liu, 2007).Although alternative (multi-objectivized) formulations of the HP model are analyzed in this study, it is important to remark that the goal remains always to solve the original problem. Thus, the experimental results presented in Section 5 are evaluated in terms of the conventional energy function of the HP model defined in Section 2.4. Additionally, the overall relative root mean square error, O-RMSE measure has been adopted in order to assess the overall performance of the studied approaches. Before introducing the O-RMSE measure, the relative root mean square error for a given test instance t, RMSE(t), can be formally defined as follows:(A.1)RMSE(t)=100%1R∑r=1R(Er(t)−E*(t)E*(t))2,where Er(t) denotes the energy of the best solution found during a particular execution r, R is the total number of performed executions, and E*(t) is the optimal (or best known) energy value for instance t. Thus, RMSE expresses the performance of the evaluated approaches in a 0% to 100% scale, being RMSE(t) = 0% the preferred value for this measure.Finally, O-RMSE is defined as the arithmetic mean of the RMSE computed over all the considered instances. Formally,(A.2)O-RMSE=1|T|∑t∈TRMSE(t),whereTis the set of all test instances. Thus, O-RMSE = 0% suggests the ideal situation where the optimal solution for each instance was reached during all the performed executions.The statistical significance analysis was conducted as follows. First, D’Agostino-Pearson’s omnibus K2 test was used to evaluate the normality of data distributions. For normally distributed data, either ANOVA or the Welch’s t parametric tests were used depending on whether the variances across the samples were homogeneous (homoskedasticity) or not. This was investigated using the Bartlett’s test. For non-normal data, the nonparametric Kruskal–Wallis test was adopted. Finally, a significance level of α = 0.05 has been considered.The algorithms implemented in this study were coded in ANSI C and compiled with gcc using the optimization flag -O3. All experiments performed were run sequentially on the Neptuno cluster at the Information Technology Laboratory, CINVESTAV-Tamaulipas. This cluster is equipped with 10 InfiniBand interconnected nodes, each of which features 8 cores running at 2.66 gigahertz, has a total of 16 gigabytes of RAM, and uses the CentOS distribution of the Linux operating system.The so-called (1 + 1) evolutionary algorithm is described in Algorithm 3. First, an initial parent individual x is generated at random. At each generation, an offspring x′ is created by randomly and independently mutating x at each encoding position with probability pm. The new individual x′ is rejected only if it is strictly worse than the parent individual x, otherwise x′ is accepted as the starting point for the next generation. Such an acceptance criterion can be either based on a single-objective discrimination between x and x′, or it can be based on the Pareto-dominance relation when implementing a multi-objective formulation of the problem.Algorithm 3Basic (1 + 1) evolutionary algorithm.1:choose0.35em0exx∈X0.35em0exuniformly0.35em0exat0.35em0exrandom2: repeat3:x′0.35em0ex←mutate(x)4:ifx′0.35em0exnot0.35em0exworse0.35em0exthan0.35em0exxthen5:x←x′6:end if7: until〈stop0.35em0excondition〉In this algorithm, individuals encode protein conformations using an internal coordinates representation based on absolute moves, see Section 2.4. In mutation, each encoding position is randomly and independently perturbed with probability pm. In all the cases, this probability is fixed topm=1ℓ−1, where ℓ − 1 denotes the length of the individuals encoding. A maximum number of5×105solution evaluations was adopted as the stopping condition and a total of 100 independent executions were performed for all two- and three-dimensional instances. Finally, it is important to remark that only individuals encoding feasible conformations are considered during the search process; once mutation is to be applied to a particular encoding position, all possible perturbations to this position are explored in random order until a feasible conformation is obtained. If no change in this position leads to a feasible conformation, the original value is restored (infeasible offspring are rejected without consuming objective function evaluations). The initial feasible individuals are generated using a backtracking procedure reported in Cotta (2003).The LD and HD formulations are sensitive to the adjustment of some parameters. As pointed out in Section 3.2, the distance parameter δ of the LD formulation has been found in the authors’ previous work to provide the best performance at low values around 7 (Garza-Fabre, Toscano-Pulido et al., 2012). Thus, the value of this parameter was set to δ = 7 for the analysis here presented. Similarly, an important issue for the HD formulation is how the H-subsets formation process is carried out. The DYNkstrategy, with k = 30, was considered in this study given the results reported in Garza-Fabre et al. (2012b).Algorithm 4 outlines the general structure of a basic iterated local search (ILS) algorithm. The algorithm starts with a randomly generated conformation, denoted as x. Then, a local search strategy (embedded heuristic) is applied to x until a local optimum x* is found. At each iteration, a perturbation x′ of the current local optimum x* is obtained and used as the starting point of another round of local search. After each local search, the new local optimum solution found x′* may be accepted as the new incumbent solution x*, based on a given acceptance criterion. This is repeated until a given stop condition is met.Algorithm 4Iterated local search (ILS).1:choose0.35em0exx∈X0.35em0exuniformly0.35em0exat0.35em0exrandom2:x*←LocalSearch(x)3: repeat4:x′0.35em0ex←Perturbation(x*)5:x′*←LocalSearch(x′)6:x*0.35em0ex←AcceptanceCriterion(x*,x′*)7: until〈stop0.35em0excondition〉Three main components, which determine the behavior of an ILS algorithm, have to be defined: (i) the embedded local search heuristic; (ii) the perturbation strength; and (iii) the acceptance criterion. A best improvement local search algorithm was used as the embedded heuristic, and basic settings for the perturbation strength and acceptance criterion were adopted according to the authors’ previous work reported in Garza-Fabre et al. (2013).

@&#CONCLUSIONS@&#
