@&#MAIN-TITLE@&#
Optimal burn-in procedure for mixed populations based on the device degradation process history

@&#HIGHLIGHTS@&#
This paper proposes a new degradation history-based burn-in procedure.The proposed procedure utilizes degradation process history of the item observed during burn-in.This paper provides a new ‘general insight/perspective’ on the burn-in models.This work opens new possibilities for further developments of similar approaches.

@&#KEYPHRASES@&#
Burn-in,Degradation process,Non-homogeneous gamma process,Mixed population,Cost optimization,

@&#ABSTRACT@&#
Burn-in is a method of ‘elimination’ of initial failures (infant mortality). In the conventional burn-in procedures, to burn-in an item means to subject it to a fixed time period of simulated use prior to actual operation. Then, the items which failed during burn-in are just scrapped and only those which survived the burn-in procedure are considered to be of satisfactory quality. Thus, when the items are subject to degradation phenomena, those whose degradation levels at the end of burn-in exceed a given failure threshold level are eliminated. In this paper, we consider a new burn-in procedure for items subject to degradation phenomena and belonging to mixed populations composed of a weak and a strong subpopulation. The new procedure is based on the ‘whole history’ of the degradation process of an item periodically observed during the burn-in and utilizes the information contained in the observed degradation process to assess whether the item belongs to the strong or weak subpopulation. The problem of determining the optimal burn-in parameters is considered and the properties of the optimal parameters are derived. A numerical example is also provided to illustrate the theoretical results obtained in this paper.

@&#INTRODUCTION@&#
Burn-in is a method of ‘elimination’ of initial failures (infant mortality). Usually, to burn-in a component or a system means to subject it to a fixed time period of simulated use prior to actual operation. That is, before delivery to the customers, the components or systems are operated under operating conditions that approximate at best the working conditions in field operation. Then, the components or systems which fail during the burn-in procedure will be scrapped or repaired and only those which survived the burn-in procedure will be considered to be of satisfactory quality. These will then be shipped to the customers or put into field operation. Under the assumption of decreasing or bathtub-shaped failure rate functions, various problems of determining optimal burn-in have been intensively studied in the literature. Due to the high failure rate at early stages of component life, burn-in has been widely accepted as an effective method of screening out these initial failures. An introduction to this important area of reliability engineering can be found in Jensen and Petersen (1982) and Kuo and Kuo (1983).Basically, the type of burn-in can be classified into three categories: (i) burn-in based on lifetime (homogeneous and heterogeneous populations) (ii) burn-in based on shocks (iii) burn-in based on degradation model. In category (i), for some examples, Mi (1994) takes into account both burn-in and maintenance policy at the same time and Cha (2001) studied generalized burn-in procedure for systems which can be minimally repaired. Mi (1996) considered cost model which includes the mean residual lifetime and Block, Savits, and Singh (2002) studied optimal burn-in which balances the mean residual lifetime and the mean residual variance. All the above mentioned works dealt with burn-in under homogeneous population setting. However, in many cases, the initial high failure rate stems from the mixture of stochastically ordered lifetimes (see, e.g., Jensen and Petersen (1982)). Recently, burn-in under heterogeneous population setting have been intensively studied. For instance, Cha and Finkelstein, 2011a, 2012b) studied optimal burn-in under the mixed population setting assuming that the performance of the items depend on the corresponding subpopulation. More recently, burn-in procedure based on shocks (category (ii)) have been intensively studied. Cha and Finkelstein, 2011b, 2013) studied a shock-based burn-in procedure for systems working under shock environment. Cha and Finkelstein (2010, 2012a) considered a shock based burn-in for items from the mixture of stochastically ordered subpopulations. In category (iii), a lot of works assume that the degradation process follows a Wiener process. For instance, Tseng and Tang (2001) studied optimal burn-in based on Wiener degradation process. Tseng, Tang, and Ku (2003) proposed a screening procedure for items from a mixed population. Tseng and Peng (2004) used an integrated Wiener process to model the cumulative wear process in optimal burn-in problem. Ye, Shen, and Xie (2012a) studied joint burn-in and maintenance decisions are to minimize the long run average cost per unit time assuming that the degradation process follows a Wiener process.However, the Wiener process can be inappropriate for modeling monotone degradation process because it does not necessarily monotonically increasing or decreasing (see, e.g., Tsai et al. (2012)). In this regard, recently, the gamma process is employed to model the degradation phenomena in the study of optimal burn-in. For example, Tsai et al. (2011) studied optimal burn-in problem minimizing total misclassification cost based on gamma degradation model. Ye, Xie, Tang, and Shen (2012b) used gamma process with random effect to model the degradation process.As burn-in is usually costly, one of the major problems is to determine the duration of this procedure. The best (usually in terms of costs involved) time to stop the burn-in process for a given criterion is called the optimal burn-in time. In the literature, in addition to different reliability performance criteria (see, e.g., Kim & Kuo, 2009), various cost structures have been proposed, and the corresponding problem of finding the optimal burn-in time has been considered (see, for example, Clarotti & Spizzichino, 1990; Mi, 1994; Cha, 2000; Cha & Finkelstein, 2011a; Kim, 2011; Sheu & Chien, 2005). An excellent survey of research in this area can be found in Block and Savits (1997).In conventional burn-in procedures, to burn-in a component or a system means to subject it to a simulated operation for some time prior to its actual operation. Then, the items which failed during the burn-in period are just scraped and discarded. In this conventional case, the information which is used for the burn-in decision is that whether the item has survived the burn-in period or not. On the other hand, suppose that the items are subject to degradation phenomena and that they belong to a heterogeneous population composed of stochastically ordered subpopulations: strong subpopulation with low degradation rate and weak subpopulation with high degradation rate. Suppose further that the degradation levels of items during burn-in are observable periodically. Then, this operational history of the items conveys important information about the subpopulation from which each item under burn-in comes; then this information can be used for establishing an additional reasonable elimination procedure.As the degradation process can be described by a continuous stochastic process, from a probabilistic point of view, the ‘operational history’ in this case corresponds to the ‘random paths’ of the corresponding stochastic process. Motivated by this reasoning, a history-dependent burn-in procedure will be suggested and relevant discussions will be given in this paper. In the proposed burn-in procedure, not only the degradation level at the end of burn-in, but also all the degradation levels periodically observed during the burn-in procedure are used for the elimination procedure. From a statistical methodological aspect, the proposed burn-in procedure utilizes ‘likelihood ratio statistic’ for the elimination procedure. To the authors’ knowledge, this type of burn-in procedure has not been yet considered in the literature and this is one of the most important differences from the other degradation-based burn-in models from a methodological point of view.In general, our method has a wide range of applications where the degradation phenomenon is the cause of the item failure. For instance, plasma display panels, vacuum fluorescent displays, liquid crystal displays and digital light processing projectors, the contact image scanner (CIS) of a copy/fax machine, laser diodes and the optical fiber in high-speed computer networks or communication systems, and numerous other dependable systems.This paper is organized as follows. In Section 2, the population structure will be described and the population lifetime distribution will be defined. In Section 3, the history-dependent burn-in procedure will be defined and, based on it, the objective function to be optimized will be obtained. Under the suggested mathematical framework, general discussions on the burn-in procedure will be provided. A numerical example will also be provided for illustration, where a Monte Carlo simulation procedure will be used to obtain the optimal burn-in. In Section 4, determining optimal burn-in procedures will be studied in detail assuming that the degradation processes in the subpopulations follow stochastically ordered non-homogeneous gamma processes. An efficient two-dimensional optimization procedure will be suggested and an illustrative numerical example will be given. Concluding remarks and discussions will be given in Section 5.A population of manufactured items is often composed of two subpopulations: a subpopulation with “normal” lifetimes (main distribution) and a subpopulation with relatively shorter lifetimes (‘freak’ distribution). Thus, in this paper, we assume that the population is composed of the mixture of two subpopulations: the strong (i.e., the subpopulation with “normal” lifetimes) and weak subpopulations (i.e., the subpopulation with relatively shorter lifetimes). In practice, items belonging to the ‘freak distribution’ can be produced along with the items of the main distribution due to, for example, defective resources and components, human errors and unstable production environment caused by uncontrolled significant quality factors, etc. Note that the infant mortality period of a life cycle that exhibits large failure rate often results from failures in the weak subpopulation of a heterogeneous population. In this case, the ‘elimination’ of these weak items from the population is crucial for improving the reliability of the whole population and this should be the aim of the burn-in procedure.The items are assumed to be subject to degradation phenomena, and {Wi(t), t ≥ 0},i=1,2, denotes the process of the accumulated degradation of an item selected from strong and weak subpopulations, respectively. That is, {Wi(t), t ≥ 0},i=1,2, are the corresponding conditional degradation processes of the population degradation process {W(t), t ≥ 0}. We assume that items fail when the accumulated degradation exceeds the predetermined threshold level κ > 0.Denote the time to the failure of a component from the strong subpopulation by T1 and that of a component from the weak subpopulation by T2. The corresponding survival function (Sf), cumulative distribution function (Cdf), probability density function (pdf), and the failure rate function are denoted byF¯i(t), Fi(t), fi(t), and λi(t),i=1,2, respectively. Obviously,F¯i(t)=P(Ti>t)=P(Wi(t)≤κ),i=1,2.The initial (t=0)composition of our mixed population is as follows: the (initial) proportion of the strong items is π, whereas the (initial) proportion of the weak items is1−π. It means that the distribution of the discrete frailty random variable Z with realizations 1 and 2 in this case isπ(z)={π,z=11−π,z=2and 1 and 2 correspond to the strong and the weak subpopulations, respectively. From the above setting, the mixture (population) survival function is given byF¯m(t)=πF¯1(t)+(1−π)F¯2(t).Under the above assumptions, the pdf of the mixed population is given byfm(t)=πf1(t)+(1−π)f2(t),and the failure rate isλm(t)=ρ(t)λ1(t)+[1−ρ(t)]λ2(t),whereρ(t)=πF¯1(t)/[πF¯1(t)+(1−π)F¯2(t)]=πF¯1(t)/F¯m(t)is the proportion of strong items in the (mixed) population at time t, that is, the fraction of strong items still functioning at time t. The readers could refer to, e.g., Finkelstein (2008) and Cha and Finkelstein (2012a) for more general discussions on the mixture populations.Although the problem in this paper can be stated in a more general setting, for convenience, we assume that the conditional degradation processes {Wi(t), t ≥ 0},i=1,2, follow non-homogeneous gamma processes. This choice is due to the fact that the gamma process is intensively used in degradation modeling. For instance, in Wu, Xie, Wu, and Li (2011), a gamma process is employed to model gradual damage monotonically accumulating over time. In Tseng, Balakrishnan, and Tsai (2009) and Tsai et al. (2011), optimal testing plans of gamma degradation models are discussed. In Xu and Wang (2012), an adaptive gamma process is used to describe the deteriorating nature of the observed condition indicator. In Pan and Balakrishnan (2011), gamma processes are used to model degradation of products with multiple performance characteristics. An excellent survey on the application of gamma processes in maintenance modeling can be found in van Noortwijk (2009).For our further discussions, we briefly summarize some properties of the gamma process. The gamma process (see, e.g., Çinlar, 1980) possesses the property of independent increments and is commonly used to describe degradation phenomena whose growth depends on the system age. The widespread use of the gamma process is due to its mathematical tractability and its flexibility, that makes the gamma process suitable to model the growth of wear, fatigue, corrosion, crack, erosion and degrading health index, et cetera (see, e.g., van Noortwijk, 2009). Under the gamma process assumption, the pdfs’ of Wi(t),i=1,2, are given by(1)fi(y;t)=g(y;αi(t),βi)=1Γ(αi(t))βiαi(t)yαi(t)−1exp(−βiy),i=1,2,y≥0,where g(y; αi(t), βi)is the pdf of the gamma distribution, βi> 0 and αi(t) is monotonically increasing in t ≥ 0, withαi(0)=0.Note that a gamma process is said to be homogeneous when the shape function αi(t) is linear with t. Under the gamma process defined in (1), the cumulative distribution function of Wi(t),i=1,2, is given byP(Wi(t)≤y)=G(y;αi(t),βi)=∫0y1Γ(αi(t))βiαi(t)xαi(t)−1exp(−βix)dx,i=1,2.Thus, the survival function relative to an item belonging to the subpopulation i isF¯i(t)=P(Ti>t)=P(Wi(t)≤κ)=G(κ;αi(t),βi),i=1,2,and the corresponding failure rate function can be obtained byλi(t)=−dln(F¯i(t))dt=−ddt[G(κ;αi(t),βi)]G(κ;αi(t),βi)=Ai(t)G(κ;αi(t),βi)(∫0∞vαi(t)−1exp(−v)dv)2,i=1,2,whereAi(t)=∫0κ[−(lnβi+lnu)αi′(t)βiαi(t)uαi(t)−1exp(−βiu)×(∫0∞vαi(t)−1exp(−v)dv)+βiαi(t)uαi(t)−1exp(−βiu)×(∫0∞αi′(t)(lnv)vαi(t)−1exp(−v)dv)]du,i=1,2,and αi′(t) denotes the first derivative of αi(t) with respect to t.Throughout this paper, in order to model our stochastically ordered subpopulations, we will assume that(2)α1(t)≤α2(t),t≥0,andβ1≥β2,where at most one equality can hold. Indeed, under this assumption, the ratiof1(y;t)f2(y;t)=Γ(α2(t))β1α1(t)Γ(α1(t))β2α2(t)yα1(t)−α2(t)exp(−(β1−β2)y)is decreasing in y, for all fixed t, which means W1(t) <lrW2(t), where “ <lr” denotes the likelihood ratio order between two random variables (see Shaked and Shanthikumar (2007)). Thus, we have thatF¯1(t)>F¯2(t), for all t, i.e., T1 >stT2 (“ <st” denotes the usual stochastic order) and it can also be shown that T1 >hrT2 (“ <hr” denotes the hazard rate order). Thus, due to the assumption in (2), T1 is greater than T2 in the sense of the above stated stochastic orders and the assumption in (2) properly defines and models our stochastically ordered subpopulations.As mentioned before, the aim of the burn-in procedure under the above described setting is to eliminate weak items from the population. Suppose that the degradation level of items can be periodically observed during the burn-in procedure. Then, this information contains important information on the subpopulation from which the item under burn-in comes because the items from weak subpopulation would exhibit higher degradation rate than those from strong subpopulation. This allows one to evaluate the probability that the item belong to the weak or strong subpopulation and to eliminate an item supposed to be weak even if it did not fail during the burn-in. Accordingly, the proposed burn-in and the related decision rules should follow the following procedure.Burn-in Procedure: An item randomly chosen from the population is operated at most for time b. Let τ ≡ b/n. During the burn-in procedure, at equi-spaced timest=kτ,k=1,2,…,n, the degradation level W(kτ) of the item is observed (the observation is denoted by w(kτ)). If w(kτ) exceeds the threshold level κ (i.e., ifW((k−1)τ)≤κand W(kτ) > κ, withW(0)=0), then the item is eliminated at kτ and the burn-in is stopped. Otherwise, the burn-in proceeds. If the item did not fail during the burn-in, then its degradation historyhb≡{w(τ),w(2τ),…,w(b)}has been observed. Define Spas the whole set of observed histories such that, if the historyhb≡{w(τ),w(2τ),…,w(b)}of an item belongs to Sp, then the probability that the item under burn-in comes from the strong subpopulation is greater than ρ ∈ [0, 1]:Sp≡{{w(τ),w(2τ),…,w(b)}|P(Z=1|Hb={w(τ),w(2τ),…,w(b)})≥ρ}.Then, an unfailed item is put into field operation only if hb∈ Sp.Therefore, by this burn-in procedure, an item is discarded by the following two discarding criteria:Criterion 1) an item is discarded at timet=kτ,k=1,2,…,n, if during the interval((k−1)τ,kτ]the degradation level of the item exceeded the threshold level κ,Criterion 2) an item is discarded at the end of the burn-in period, if the observed historyhb≡{w(τ),w(2τ),…,w(b)}of the item does not belong to the set Sp.Otherwise, that is, if W(b) ≤ κ and hb∈ Sb, the item is put into field operation.Define event E1 as the event when the item fails during the burn-in and event E2 as the event when the item is eliminated at the end of the burn-in although it is unfailed:E1≡{W(b)>κ},E2≡{W(b)≤κ,hb∉Sp}.Then, the above elimination procedure implies that an item is eliminated if one of the two (incompatible) events E1 and E2 occurs. In other words, not only the items that fails during the burn-in will be eliminated as soon as the failure is detected, but also the unfailed items whose (conditional) probability that the item under burn-in comes from the strong subpopulation (Z=1), given the observed degradation history{w(τ),w(2τ),…,w(b)}, sayP(Z=1|Hb={w(τ),w(2τ),…,w(b)}), is less than a prefixed probability ρ. Note that the conventional time burn-in corresponds to the case whenρ=0andn=1.For convenience, we letw(kτ)−w((k−1)τ)≡vk,k=1,2,…,n. Because we have assumed that the degradation processes are gamma, the probability of observing the degradation historyhb≡{w(τ),w(2τ),…,w(nτ)}for the strong and weak item is given, respectively, by(3)Li(v1,v2,…,vn)≡∏k=1ng(vk;αi(kτ)−αi((k−1)τ),βi),i=1,2.The belonging condition hb∈ Spis equivalent to(4)L1(v1,v2,…,vn)π1L1(v1,v2,…,vn)π1+L2(v1,v2,…,vn)π2≥ρ,where π1 ≡ π andπ2≡1−π, or, using (3), is equivalent to(5)∑k=1n{([α2(kτ)−α1(kτ)]−[α2((k−1)τ)−α1((k−1)τ)])lnvk+(β1−β2)vk}≤ln(1φπ1π21−ρρ),whereφ≡∏k=1nΓ(α1(kτ)−α1((k−1)τ))Γ(α2(kτ)−α2((k−1)τ))β2α2(kτ)−α2((k−1)τ)β1α1(kτ)−α1((k−1)τ)=(∏k=1nΓ(α1(kτ)−α1((k−1)τ))Γ(α2(kτ)−α2((k−1)τ)))·β2α2(b)β1α1(b).We have assumed that the failure of items can be detected only by inspection, i.e., observation of the degradation level (the case when the failures are instantly detected can also be considered without difficulty, see Remark 1 in Section 4).Now, the relevant probabilities of events which will be necessary in deriving the cost functions in the next subsection are obtained. Under the above setting, define N as the random number of inspections performed before the stopping of the burn-in procedure. Then,p(1,E1)≡P(N=1,E1)=P(W(τ)>κ)=∑i=12G¯(κ;αi(τ),βi)πi,p(k,E1)≡P(N=k,E1)=P(W((k−1)τ)≤κ,W(kτ)>κ)=∑i=12[∫0κG¯(κ−x;αi(kτ)−αi((k−1)τ),βi)·g(x;αi((k−1)τ),βi)dx]πi,k=2,…,n,whereG¯(x;α,β)=1−G(x;α,β), andp(n,E2)≡P(N=n,E2)=P(W(nτ)≤κ,hb∉Sp)=∑i=12(∫∫…∫{v1,v2,…,vn}∉Sp,∑k=1nvk≤κLi(v1,v2,…,vn)dv1dv2…dvn)πi.Also,P(E1)=∑i=12G¯(κ;αi(b),βi)πi,P(E2)=∑i=12(∫∫…∫{v1,v2,…,vn}∉Sp,∑k=1nvk≤κLi(v1,v2,…,vn)dv1dv2…dvn)πi,andP(E1∪E2)=P(E1)+P(E2). Furthermore, the probability that an item belonging to the subpopulation i is eliminated during the burn-in is given by(6)r(i,E1∪E2)≡P(Z=i,E1∪E2)=G¯(κ;αi(b),βi)πi+(∫∫…∫{v1,v2,…,vn}∉Sp,∑k=1nvk≤κLi(v1,v2,…,vn)dv1dv2…dvn)πi,i=1,2.Now, from (6), the fraction of strong and weak items in the initial population that are eliminated during the burn-in is equal to, respectively, r(i, E1∪E2)/πi,i=1,2.Finally, we have that the fraction of the strong and weak subpopulation in the population of items which have passed the burn-in procedure is given by, respectively,rF(i)≡P(Z=i|(E1∪E2)C)=πi−r(i,E1∪E2)1−P(E1∪E2),i=1,2,where (E1∪E2)Cdenotes the event complementary to E1∪E2.The total expected cost function for ‘one item’ that survives the burn-in process and is put into field operation is the sum of three components: (1) the average total burn-in cost needed for obtaining one component that can be used in field operation, (2) the average penalty for an item which is put into field operation and fails before completing the mission, and (3) the average gain (a negative cost) for an item which is put into field operation and completes successfully the mission.We assume that the number n of planned observations during the burn-in is prefixed, so that the total expected cost is a function of the burn-in time b and of the probability ρ (also called the “elimination level”).In order to evaluate the average total burn-in cost, we assume that the burn-in cost is proportional to the total burn-in time, and we denote by c0 the cost per unit burn-in time. Denote by c1 and c2 (c1 > c2) the corresponding cost (or loss) incurred when a strong or a weak item is discarded or eliminated by the burn-in procedure, respectively. Furthermore, let c3 be the cost per one observation of the degradation level during burn-in.The burn-in cost for ‘one item’ which fails during the burn-in process depends on the random stopping time of the burn-in procedure and on the random nature (strong or weak) of the eliminated item, and its average is given by∑k=1nk(c0τ+c3)p(k,E1)+(c0b+c3n)p(n,E2)+c1r(1,E1∪E2)+c2r(2,E1∪E2)P(E1∪E2).On the other hand, the burn-in cost for an item that survives the burn-in process is fixed and is given byc0b+c3n. Thus, the average total burn-in cost E[q(b, ρ)] needed for obtaining one component that can be used in field operation is given byE[q(b,ρ)]=(11−P(E1∪E2)−1)×∑k=1nk(c0τ+c3)p(k,E1)+(c0b+c3n)p(n,E2)+c1r(1,E1∪E2)+c2r(2,E1∪E2)P(E1∪E2)+(c0b+c3n)=(∑k=1nk(c0τ+c3)p(k,E1)+(c0b+c3n)p(n,E2)+c1r(1,E1∪E2)+c2r(2,E1∪E2))1−P(E1∪E2)+(c0b+c3n).We assume that, in the field operation, if a mission (of lengthM) is successful, then the gain K is earned; otherwise a penalty C is imposed. The conditional pdf of Wi(b),i=1,2, given that Wi(b) ≤ κ and hb∈ Sp, is given byf(Wi(b)|Wi(b)≤κ,hb∈Sp)(w)=∫∫…∫{v1,v2,…,vn}∈Sp,∑k=1nvk=wLi(v1,v2,…,vn)dv1dv2…dvn∫∫…∫{v1,v2,…,vn}∈Sp,∑k=1nvk≤κLi(v1,v2,…,vn)dv1dv2…dvn×I(w≤κ),i=1,2,where I(w ≤ κ) is defined as “1” if w ≤ κ; “0” otherwise. Then, the mission survival function of the burned-in component from the subpopulation i,i=1,2, is given byF¯i(M|b,ρ)=∫0κG(κ−w;αi(b+M)−αi(b),βi)·f(Wi(b)|Wi(b)≤κ,hb∈Sp)(w)dw,i=1,2,and hence the mission survival functionF¯m(M|b,ρ)of the burned-in component isF¯m(M|b,ρ)=∑i=12F¯i(M|b,ρ)·rF(i).Therefore, the total expected cost function for ‘one item’ that survives the burn-in process and is put into field operation is given by(7)c(b,ρ)=E[q(b,ρ)]−K·F¯m(M|b,ρ)+C·Fm(M|b,ρ).The proposed burn-in procedure outperforms the conventional time burn-in in the following sense: minb ≥ 0, 0 ≤ ρ ≤ 1c(b, ρ) ≤ minb ≥ 0c(b, 0).For obtaining the optimal solution of the proposed burn-in procedure, a numerical optimization algorithm is required, that in turn generally involves several multivariate integrals of order n andn+1. This is an almost prohibitive task, also because of the very long run times (note that under some restrictions on the shape functions αi(t), a quite simple calculation of the total expected cost and nice properties on the optimal solution will be derived in Section 4).However, an attractive alternative to the numerical computation of the cost function (7) and of the involved probabilities, is the use of the Monte Carlo simulation procedure. It consists in simulating a very large sample of pseudo-random degradation pathshb≡{w(τ),w(2τ),…,w(b)}drawn from the gamma processes of strong or weak subpopulation, once selected values of n and b are given. Of course, a fraction π of the paths are drawn from {W1(t), t ≥ 0}, and the remaining fraction1−πare drawn from {W2(t), t ≥ 0}. Then, given the elimination level ρ, the (generic) probability that an event E occurs is estimated as the fraction of times that event is observed in the pseudo-random sample of paths. For example, the probability P(E1∪E2) is estimated by the fraction of times the condition (5) hb∈ Spis not satisfied or the inequality W(b) > κ is satisfied. Any time the simulated path satisfies the event {W(b) ≤ κ, hb∈ Sp}, that is, the simulated path allows the item to survives the burn-in, then the degradation levelW(b+M)up to the timeb+Mis simulated, where M is the mission length. Then, the survival function of the burned-in items, that is, the probability that an item that survives the burn-in successfully completes its mission of length M, is given by the ratio between the number of timesW(b+M)≤κand the number of times the simulated path satisfies {W(b) ≤ κ, hb∈ Sp}.Then, once all the probabilities involved in (7) have been estimated, the total expected cost function for ‘one item’ that survives the burn-in process can be estimated by using (7). Alternatively, the total expected cost (7) can be estimated as the ratio between the sum of the total cost of each item and the number of times {W(b) ≤ κ, hb∈ Sp}, where the total cost of each item is given by:•k(c0τ+c3)+c1,if a strong item is eliminated at the inspection time kτ,k=1,…,n,k(c0τ+c3)+c2,if a weak item is eliminated at the inspection time kτ,k=1,…,n,n(c0τ+c3)−K,if an item is not eliminated during the burn-in, andW(b+M)≤κ,n(c0τ+c3)+C,is an item is not eliminated during the burn-in, andW(b+M)>κ,The simulation procedure is repeated by changing b and ρ until the minimum total expected cost is obtained. In the following subsection, a numerical example that exploits the Monte Carlo simulation procedure to derive the optimal burn-in is illustrated.Let us now consider the burn-in based on the degradation process of high-power semiconductor lasers, whose degradation paths and data are given in Meeker and Escobar (1998, pages 324, 642). The corresponding data set was more recently analyzed by Tsai et al. (2011). The quality characteristic of a laser device is its operating current and when the current reaches a prefixed threshold level, the laser is considered to be failed. The data set consists of 15 degradation paths observed up to 4000 hours. The operating current is measured at equi-spaced intervals of width 250 hours. The paths appears to be monotonically increasing with time t, and it is possible to classify the paths into two subpopulations: a strong (or typical) subpopulation that has a lower degradation rate, and a weak subpopulation with a higher rate.The fraction π of strong units is assumed to be equal to 0.945, and the degradation processes are assumed to be homogeneous gamma, whose parameters are set equal to the maximum likelihood estimates (cf. Tsai et al. (2011)). Thus,α1(t)=0.0359t,α2(t)=0.0466t,β1=20.04, andβ2=17.15.The laser devices are assumed to be failed when the percent increase in operating time reaches the threshold levelκ=10%, and the mission length is equal toM=4000hours. The burn-in procedure involvesn=3inspections and measurements of the percent increase in operating current accumulated during the burn-in. The cost c3 of each inspection/measurement is equal to 0.0005 $, and the cost c0 per unit burn-in time is equal to 0.0009 $/h. The costs c1 and c2 incurred when a strong or a weak device is eliminated by the burn-in procedure are equal to 8 $ and 0.6 $, respectively. Finally, the mission success produces the gainK=15$, whereas the failure of the mission causes the penaltyC=80$.By using the Monte Carlo simulation procedure described in the previous Section with sizeNsim=10,000,000, the burn-in time and elimination level that minimize the total expected cost are obtained by an iterative procedure, sayb*=573hours andρ*=0.90, and the resulting minimum cost isc(b*,ρ*)=−11.92$. Then, sincen=3, the devices should be inspected at (optimal) equi-spaced intervals of widthτ*=191hours, and a device is not eliminated during the burn-in if its wear history hb≡ {w(τ*), w(2τ*), w(b*)} satisfies the condition (5) that∑k=13{([α2(kτ*)−α1(kτ*)]−[α2((k−1)τ*)−α1((k−1)τ*)])×lnvk+(β1−β2)vk}<−1.3398,whereνk=w(kτ*)−w((k−1)τ*),k=1,2,3, are the observed wear increments.The fraction of discarded devices is quite high, say 0.346, because the costs incurred when a device is eliminated by the burn-in procedure are relatively low when compared to the gain K and the penalty C. As the result of burn-in, it is observed that about 75.85% of weak devices are eliminated and only 8.97% of strong devices are eliminated.As a consequence of the performed burn-in, the fraction of devices shipped to the customers that belong to the strong subpopulation is extremely high, and equal to 0.9848. Thus, also the mission success probability of a burned-in laser is very high:F¯m(M|b*,ρ*)=0.9823, and only 1.77% of the burned-in lasers fail before completing the mission. It should be noted that the mission success probability without performing the burn-in is much lower, and equal to 0.9525 (that is, the burn-in reduced the failure probability by a factor of 2.7 times).If the burn-in is not performed, the total expected cost for ‘one item’ is equal to −10.49 $, that is, when the proposed (optimal) burn-in procedure is performed, the expected cost for 1000 items put into field operation decreases by 1432 $ compared to the case of no burn-in.Of course, all the estimates are affected by the finite, even if very large, simulation size. A graphical analysis on the convergence of the estimated values to the “true” ones is provided by the Fig. 1, where: (a) the probability that a weak item is eliminated during the burn-in (for optimal burn-in), (b) the mission success probability of the burned-in population (for optimal burn-in), and (c) the (minimum) total expected cost, estimated on the basis of Monte Carlo simulation procedure of selected sizes ranging fromNsim=1000andNsim=10,000,000are plotted. The burn-in time b and elimination level ρ used in this simulation study are set equal to the optimal valuesb*=573hours andρ*=0.90.As noted by a reviewer, the optimal burn-in time is quite large, even with respect to the mission length. However, this large burn-in time does not compromise the mission success probability of the devices that are shipped to the customers, because the fraction of devices that will fail during the mission is very low, sayFm(M|b*,ρ*)=0.0177.The main reason of a large value of the optimal burn-in time in our application, is the fact that the degradation process of the weak devices is only slightly faster than the degradation process of strong devices. Thus, only a large burn-in time can assure that weak devices are correctly detected and eliminated with high probability. Indeed, if we assume that the degradation rate of weak devices is faster than the one in the observed data set, the optimal burn-in time decreases. Table 1compares the results of burn-in procedure under the assumption that the degradation rate of weak devices is: (i) equal to the current rate, (ii) 2 times greater, (iii) 2.5 times greater, and (iii) 3 times greater than the current rate, so that by unchangingβ2=17.15, we assume that: (i)α2(t)=0.0466t, (ii)α2(t)=0.0932t, (iii)α2(t)=0.1165t, (iv)α2(t)=0.1398t.The results given in Table 1 show that as the differences between the degradation processes of the two subpopulations become more pronounced, the optimal burn-in time decreases and the effectiveness of the proposed burn-in procedure increases. Indeed, the mission success probability increases and the characteristics of the device population that is shipped to the customers improve: the fraction of weak (strong) devices that are eliminated during the burn-in increases (decreases) significantly. Note that, if no burn-in is performed, the expected cost and the success mission probability do not change in cases (ii)–(iv) because already whenα2(t)=0.0932tall the weak devices fail during the mission with probability close to 1.Of course, a longer mission time M also produces a shorter optimal burn-in time, in order to avoid that a large fraction of burned-in devices fail during the mission. For example, if we setM=4500, the optimal burn-in is obtained forb*=208hours (andρ*=0.888). The resulting minimum expected cost isc(b*,ρ*)=−10.06$, whereas the expected cost is equal to−9.60$ when no burn-in is performed. ForM=4500, the mission success probabilities are equal toF¯m(M|b*,ρ*)=0.9602andF¯m(M)=0.9432, when the optimal burn-in and no burn-in is performed, respectively.In the previous Section, no restriction was imposed to the shape functions α1(t) and α2(t) of the gamma degradation models of strong and weak subpopulations. In the following, a more specific model, which allows simpler calculation of total expected cost and nice properties on optimal solutions, will be considered and discussed.In particular, in this section, we will assume that the shape functions αi(t),i=1,2, in (1) are the same:αi(t)=a(t),i=1,2. This assumption is justified by considering that the distribution of the degradation level at a given time t of the weak subpopulation keeps the same shape of the distribution of the strong subpopulation, and is rescaled by the factor β1/β2. Even in this case, of course, the subpopulation 1 is the stronger than the subpopulation 2 due to β1 > β2.For illustrative purpose, Fig. 2depicts the mean degradation functions and the probability distribution functions of the degradation level Wi(t) at two different operating times t relative to the strong (i=1) and weak (i=2) subpopulation, under the assumption thatαi(t)=a(t),i=1,2. In particular, in Fig. 2 a power law function for a(t) is assumed.Under the above assumption thatαi(t)=a(t),i=1,2,L1(v1,v2,…,vn)π1L1(v1,v2,…,vn)π1+L2(v1,v2,…,vn)π2=(∏k=1ng(vk;α(kτ)−α((k−1)k),β1))π1∑i=12(∏k=1ng(vk;α(kτ)−α((k−1)k),βi))πi=β1a(b)exp(−β1∑k=1nvk)π1β1a(b)exp(−β1∑k=1nvk)π1+β2a(b)exp(−β2∑k=1nvk)π2.and then the condition hb∈ Spis equivalent to11+π2β2a(b)π1β1a(b)exp[(β1−β2)∑k=1nvk]≥ρor∑k=1nvk=w(b)≤1β1−β2ln(π1β1a(b)π2β2a(b)1−ρρ).Therefore, under the assumed model, the condition hb∈ Spin (4) or in (5) is equivalent toW(b)≤1β1−β2ln(π1β1a(b)π2β2a(b)1−ρρ)≡ξ(b,ρ).Observe that ξ(b, ρ) is strictly decreasing in ρ, withlimρ→0ξ(b,ρ)=∞andlimρ→1ξ(b,ρ)=−∞(for any fixed b > 0). A negative value of ξ(b, ρ) implies that no item passes the burn-in procedure and these settings of burn-in must be excluded from our consideration. This issue will be considered when we discuss detailed optimization procedure later. As ξ(b, ρ) is strictly decreasing in ρ, there exists a value of ρ, say ρ0, which satisfies1β1−β2ln(π1β1a(b)π2β2a(b)1−ρ0ρ0)=κ,that isρ0=[π2π1(β2β1)a(b)exp[κ(β1−β2)]+1]−1.Thus, we now consider the following two different cases: Case 1: 0 ≤ ρ ≤ ρ0, and Case 2: ρ0 < ρ ≤ 1.•Case 1: if 0 ≤ ρ ≤ ρ0, then ξ(b, ρ) ≥ ξ(b, ρ0) ≡ κ. In this case, because the condition hb∉Spis equivalent to “W(b) > ξ(b, ρ)”, we have that E2 ≡ {W(b) ≤ κ, hb∉Sp} ≡ ⊘. Therefore, we have thatE1∪E2={W(b)>κ}.Case 2: if ρ0 < ρ ≤ 1, then ξ(b, ρ) < κ. As before, the condition hb∉Spis equivalent to “W(b) > ξ(b, ρ)”, and now we have that E2 ≡ {W(b) ≤ κ, hb∉Sp} ≡ {ξ(b, ρ) < W(b) ≤ κ}. Thus, because E1 ≡ {W(b) > κ}, we have thatE1∪E2={W(b)>ξ(b,ρ)}.Of course, w(kτ) > ξ(b, ρ) implies that W(b) > ξ(b, ρ). Then, we can provide a unique formulation for Case 1 and Case 2 by slightly modifying the burn-in procedure in Case 2 as follows: at equi-spaced timest=kτ,k=1,2,…,n, if w(kτ) exceeds ξ(b, ρ) (not κ), then the item should be eliminated at kτ,k=1,2,…,n. Accordingly, the event E1 becomes the event that the item is eliminated if w(kτ) exceeds ξ(b, ρ) at kτ,k=1,2,…,n, and the event E2 is now a null event: E2 ≡ ⊘. Under this events modification, we have thatP(E1∪E2)=∑i=12G¯(B;a(b),βi)πiwhereB={κ,if0≤ρ≤ρ0(Case1)ξ(b,ρ),ifρ0<ρ≤1(Case2).Furthermore,p(k,E1)={∑i=12G¯(B;a(τ),βi)πi,k=1∑i=12[∫0BG¯(B−x;a(kτ)−a((k−1)τ),βi)·g(x;a((k−1)τ),βi)dx]πi,k=2,…,n,and, because E2 ≡ ⊘,p(n,E2)=0. Finally,r(i,E1∪E2)=G¯(B;a(b),βi)πi,i=1,2,andF¯i(M|b,ρ)=∫0BG(κ−w;a(b+M)−a(b),βi)·f(Wi(b)|Wi(b)≤B)(w)dw,i=1,2,wheref(Wi(b)|Wi(b)≤B)(w)=g(w;a(b),βi)G(B;a(b),βi)I(w≤B),i=1,2.The above result shows that, ifαi(t)=a(t),i=1,2, then W(b) is a ‘sufficient statistic’ for our decision. That is, our decision does not have to rely on the full historyHb≡{W(τ),W(2τ),…,W(b)}, but it is sufficient to consider the partial history W(b).The objective is now to find the joint optimal burn-in parameters (b*, ρ*) that satisfiesc(b*,ρ*)=minb≥0,ρ∈[0,1]c(b,ρ).Then, in order to find the joint optimal burn-in parameters (b*, ρ*) efficiently, the following procedures will be applied.(i)At the first stage, we fix the elimination level ρ ∈ [0, 1] and find the optimal b*(ρ) that satisfiesc(b*(ρ),ρ)=minb≥0c(b,ρ).At the second stage, we search for ρ* that satisfiesc(b*(ρ*),ρ*)=minρ∈[0,1]c(b*(ρ),ρ).Then the joint optimal solution is given by (b*(ρ*), ρ*), since the above procedure implies thatc(b*(ρ*),ρ*)≤c(b*(ρ),ρ),forallρ∈[0,1],≤c(b,ρ),forallb≥0,ρ∈[0,1].However, as mentioned before, ξ(b, ρ) is strictly decreasing in ρ, withlimρ→0ξ(b,ρ)=∞andlimρ→1ξ(b,ρ)=−∞. For any fixed b,ξ(b,1)=−∞and, clearly, the case whenρ=1should be excluded from the parameter set. Furthermore, for a fixed ρ (at the first stage), all the burn-in time values b’s such that(8)(π1β1a(b)π2β2a(b)1−ρρ)<1should also be excluded from our consideration, as these time values imply a negative value of ξ(b, ρ) and the impossibility for an item to pass the burn-in. Note that: (i) this can happen especially when ρ is close to 1, and (ii) the left-hand side of the inequality (8) is strictly increasing in b, with its limit ∞. Thus, this can be interpreted as follows: when the elimination criterion is very strict (ρ is close to 1), sufficiently large burn-in time is necessary for our decision. Thus, for a fixed ρ, we will only consider burn-in time values b’s such thatb∈B(ρ)≡{b≥0|(π1β1a(b)π2β2a(b)1−ρρ)>1}.Thus, the above two stage optimization procedure should be simplified as:(i)At the first stage, we fix the elimination level ρ ∈ [0, 1) and find the optimal b*(ρ) that satisfies(9)c(b*(ρ),ρ)=minb∈B(ρ)c(b,ρ).At the second stage, we search for ρ* that satisfiesc(b*(ρ*),ρ*)=minρ∈[0,1)c(b*(ρ),ρ).Following the procedure described above, first search for the optimal b*(ρ) satisfying (9) for each fixed ρ. In this case, aslimb→∞P(W(b)≤κ,hb∈Sp)=0, we have thatlimb→∞c(b,ρ)=∞and, thus, we always have the finite optimal b*(ρ): b*(ρ) < ∞. In addition to this, if there exists a finite upper bound for b*(ρ), then it would make the search for b*(ρ) substantially efficient. We denoted by bU(ρ) the finite upper bound for b*(ρ). For this purpose, we need to state the following theorem.Theorem 1For each fixed ρ, defineΨ(b|ρ)≡F¯1(M|b,ρ)−F¯2(M|0,ρ)Then Ψ(b|ρ) is strictly decreasing function of b with Ψ(0|ρ) > 0 and the upper bound bU(ρ) for b*(ρ) is given by the unique solution of the equation:Ψ(b|ρ)≡F¯1(M|b,ρ)−F¯2(M|0,ρ)=0.ProofWe prove for the case when ξ(b, ρ) ≥ κ. The other case can be proved in a similar way. We compare c(0, ρ) and c(b, ρ) for b > bU(ρ). Recallc(b,ρ)=E[q(b,ρ)]−(K+C)F¯m(M|b,ρ)+C.Whenb=0, we have thatE[q(0,ρ)]=0; whereas, when b > bU(ρ), E[q(b, ρ)] > 0. Note thatF¯m(M|b,ρ)=∑i=12F¯i(M|b,ρ)·rF(i),whereF¯i(M|b,ρ)=∫0κ(∫0κ−wβia(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−βiu)du)·f(Wi(b)|Wi(b)≤κ)(w)dwandf(Wi(b)|Wi(b)≤κ)(w)=βia(b)wa(b)−1Γ(a(b))exp(−βiw)∫0κβia(b)ua(b)−1Γ(a(b))exp(−βiu)duI(w≤κ),i=1,2.As β1 > β2, the ratioβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)β2a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β2u)=(β1β2)a(b+t)−a(b)exp[−(β1−β2)u]is decreasing in u, which implies that the distribution in the denominator is larger than that in the numerator in the likelihood order sense. Thus,∫0κ−wβ2a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β2u)du<∫0κ−wβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)du.Furthermore, the ratiof(W1(b)|W1(b)≤κ)(w)f(W2(b)|W2(b)≤κ)(w)is also decreasing in w, implying the likelihood ratio order between (W1(b)|W1(b) ≤ κ) and (W2(b)|W2(b) ≤ κ). Therefore, we haveF¯2(M|b,ρ)=∫0κ(∫0κ−wβ2a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β2u)du)·f(W2(b)|W2(b)≤κ)(w)dw<∫0κ(∫0κ−wβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)du)·f(W2(b)|W2(b)≤κ)(w)dw<∫0κ(∫0κ−wβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)du)·f(W1(b)|W1(b)≤κ)(w)dw=F¯1(M|b,ρ),where the last inequality holds due to the fact that the integral∫0κ−wβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)duis decreasing in w and (W1(b)|W1(b) ≤ κ) <lr(W2(b)|W2(b) ≤ κ).Furthermore, for b1 < b2,f(W1(b1)|W1(b1)≤κ)(w)f(W1(b2)|W1(b2)≤κ)(w)is decreasing in w. This implies thatF¯1(M|b,ρ)=∫0κ(∫0κ−wβ1a(b+M)−a(b)ua(b+M)−a(b)−1Γ(a(b+M)−a(b))exp(−β1u)du)·f(W1(b)|W1(b)≤κ)(w)dwis decreasing in b for all fixed M and ρ. Therefore, the differenceΨ(b|ρ)≡F¯1(M|b,ρ)−F¯2(M|0,ρ)is strictly decreasing function of b, with Ψ(0|ρ) > 0, and limb → ∞Ψ(b|ρ) < 0. Therefore, there exists the unique solution of the equationΨ(b|ρ)=0, which is denoted by bU(ρ). Then, for all b > bU(ρ), we haveF¯1(M|0,ρ)>F¯2(M|0,ρ)>F¯1(M|b,ρ)>F¯2(M|b,ρ).Note thatF¯m(M|0,ρ)is a weighted average ofF¯i(M|0,ρ),i=1,2, andF¯m(M|b,ρ)is also a weighted average ofF¯i(M|b,ρ),i=1,2. Therefore, for all b > bU(ρ),F¯m(M|0,ρ)>F¯m(M|b,ρ).This implies that c(0, ρ) < c(b, ρ), for all b > bU(ρ).■Remark 1It was shown that, under the considered setting, the decision of eliminating an unfailed item at the end of the burn-in is based only on the degradation level observed at time b: the condition that hb∈ Spis equivalent to W(b) ≤ ξ(b, ρ). However, when the failures are detected only by inspection and the unit cost c0 is relatively very high, it may be still advantageous to observe the degradation level at timest=kτ,k=1,2,…,n, just to eliminate the failed component as soon as the failure is detected, thus reducing the burn-in time. In this case, the previous cost function can be applied. On the other hand, if the failures are automatically detected instantly without observing the degradation level and the unit cost c0 is relatively very low but c3 (cost per one observation) is relatively very high, then it would be sufficient to observe the degradation level only at time b and eliminate the items based on W(b). In this case, the expected burn-in cost can be obtained similarly as those in Mi (1994) and Cha (2001). For instance, when ξ(b, ρ) ≥ κ the total expected cost function is given byc(b,ρ)=(1P(W(b)≤κ)−1)·(c0∫0b[F¯m(u)−F¯m(b)]duFm(b)+c1r(1,E1∪E2)P(E1∪E2)+c2r(2,E1∪E2)P(E1∪E2))+(c0b+c3)−KF¯m(M|b,ρ)+CFm(M|b,ρ)The total expected cost can also be similarly defined for the case ξ(b, ρ) < κ. Even in this case, by similar arguments, we still have the same results for the upper bound as those in Theorem 1.Alternatively to the cost function (7), we now assume that, during the field operation, the gain is proportional to the mean time to failure. Therefore, the total expected cost function in this case is(10)c(b,ρ)=E[q(b,ρ)]−K∫0∞F¯m(t|b,ρ)dt.We will now consider the problem of finding the optimal joint burn-in parameters (b*, ρ*) which minimizes the total expected cost c(b, ρ) in (10). Then, in order to find the joint optimal burn-in parameters (b*, ρ*) efficiently, the optimization procedures described in the previous case will be applied. In this case, as before, the existence of a finite upper bound for b*(ρ) for each fixed ρ would make the search for b*(ρ) substantially efficient.Theorem 2For each fixed ρ, defineΨ(b|ρ)≡∫0∞F¯1(t|b,ρ)dt−∫0∞F¯2(t|0,ρ)dt.Then Ψ(b|ρ) is strictly decreasing function of b with Ψ(0|ρ) > 0 and the upper bound bU(ρ) is given by the unique solution of the equation:Ψ(b|ρ)≡∫0∞F¯1(t|b,ρ)dt−∫0∞F¯2(t|0,ρ)dt=0.ProofFix ρ ∈ [0, 1) and letM(b,ρ)≡∫0∞F¯m(t|b,ρ)dt=rF(1)∫0∞F¯1(t|b,ρ)dt+rF(2)∫0∞F¯2(t|b,ρ)dt.As in the proof of Theorem 1,E[q(0,ρ)]=0; whereas, when b > bU(ρ), E[q(b, ρ)] > 0. Thus, it is sufficient to show that M(0, ρ) > M(b, ρ), for b > bU(ρ). Observe that M(b, ρ) is the weighted average of∫0∞F¯1(t|b,ρ)dtand∫0∞F¯2(t|b,ρ)dt. Then, by similar arguments as those described in the proof of Theorem 1, it can be shown thatF¯1(t|b,ρ)is strictly decreasing in b for any fixed t. This implies that∫0∞F¯1(t|b,ρ)dtis strictly decreasing in b. Therefore, there exists a value bU(ρ) such that∫0∞F¯2(t|0,ρ)dt>∫0∞F¯1(t|b,ρ)dtforallb>bU(ρ).Clearly, bU(ρ) is the unique solution of the equationΨ(b|ρ)≡∫0∞F¯1(t|b,ρ)dt−∫0∞F¯2(t|0,ρ)dt=0.Then, similar to the procedure given in the poof of Theorem 1,∫0∞F¯1(t|0,ρ)dt>∫0∞F¯2(t|0,ρ)dt>∫0∞F¯1(t|b,ρ)dt≥∫0∞F¯2(t|b,ρ)dt,for all b > bU(ρ), and, thus, M(0, ρ) > M( b, ρ), for all b > bU(ρ). This inequality implies that any b ∈ (bU(ρ), ∞) cannot be the optimal burn-in time for the fixed ρ. Therefore, bU(ρ) is the upper bound for the optimal burn-in time b*(ρ) for the fixed ρ.■Consider again the example discussed inSection 3.3, where now the shape functions αi(t),i=1,2, of the gamma processes are assumed to be common, and equal toa(t)=0.0382t, where 0.0382 is the maximum likelihood estimate of the multiplicative coefficient of the shape function under the assumption thatα1(t)=α2(t)=a(t). In this case, thus, the optimization procedure requires the solution of univariate integrals, involving the (numerical) computation of the incomplete gamma function, and then there is no need to resort to Monte Carlo simulation.The scale parameters are still equal to the values used inSection 3.3, sayβ1=20.04, andβ2=21.46, as well as the proportions of subpopulations, the threshold value κ, the number n of inspections, the mission length M, and all the cost parameters remain the same.By using the optimization procedure described inSection 4.1, the optimal burn-in time and elimination level are equal to, respectively,b*=584hours andρ*=0.90. This implies a positive value of ξ(b*, ρ*), sayξ(b*,ρ*)=1.3701, and then a laser device must be eliminated during the burn-in if its wear exceeds the valueW*=1.3701mm (see Fig. 3). The optimal total expected cost for ‘one item’ that survives the burn-in process and is put into field operation is equal to −11.87 $.The fraction of discarded devices is equal to 0.1171, and about 73.0% of weak devices are eliminated and only 8.1% of strong devices are eliminated.The fraction of the strong subpopulation in the lasers shipped to the customers is very high, and equal to 0.983 and hence also the mission success probability of a burned-in lasers is very high:F¯m(M|b*,ρ*)=0.9810. Because the mission success probability without performing the burn-in is equal to 0.9536, we have that the burn-in reduced the failure probability by a factor of 2.4 times.Finally, Fig. 4plots the contour plot of the total expected cost function (7) versus burn-in time and elimination level, together to the optimal solution,b*=584hours andρ*=0.90.In conventional burn-in procedure, the only information used for the elimination procedure is the corresponding ‘lifetime’ of the item. In this paper, under the assumptions that the items are subject to observable degradation phenomena and that the population of items is heterogeneous and is constituted by a strong and a weak subpopulation, a new burn-in procedure which employs the information contained in the degradation process is proposed and studied. As the degradation process can be described by a continuous stochastic process, from a probabilistic point of view, the new burn-in procedure utilizes the information contained in ‘sample path’ of the corresponding stochastic process. In this way, given the observed degradation process, the burn-in procedure is optimized in terms both of the burn-in time b and the elimination level ρ for the (conditional) probability that the item under the burn-in will be from the strong subpopulation.General framework for the new burn-in procedure was established assuming the nonhomogeneous gamma processes for the degradation processes. Under the condition that the shape functions for both subpopulations are the same, the sufficient statistic for the burn-in decision was characterized and the detailed properties of the optimal burn-in parameters were obtained. Two-stage optimization procedure for determining the joint optimal burn-in parameters was developed.The application of the proposed burn-in procedure to a real data set showed the advantages provided by the burn-in even when the degradation rate is constant with time. Larger advantages are obtained when the degradation paths are concave downward, so that the burn-in period covers the time interval with larger degradation rate.Finally, the new burn-in procedure proposed in this paper assumes that the degradation processes follow the nonhomogeneous gamma process. However, the application of the general approach is not limited to this case. Based on the suggested general framework, other stochastic processes for item degradation could also be employed.

@&#CONCLUSIONS@&#
