@&#MAIN-TITLE@&#
New approaches to nurse rostering benchmark instances

@&#HIGHLIGHTS@&#
New upper and lower bounds for benchmark nurse rostering instances.A general model which can be applied to a wide variety of staff rostering problems.A powerful dynamic programming method used to solve sub-problems.

@&#KEYPHRASES@&#
Staff scheduling,Nurse rostering,Branch and price,Ejection chain,

@&#ABSTRACT@&#
This paper presents the results of developing a branch and price algorithm and an ejection chain method for nurse rostering problems. The approach is general enough to be able to apply it to a wide range of benchmark nurse rostering instances. The majority of the instances are real world applications. They have been collected from a variety of sources including industrial collaborators, other researchers and various publications. The results of entering these algorithms in the 2010 International Nurse Rostering Competition are also presented and discussed. In addition, incorporated within both algorithms is a dynamic programming method which we present. The algorithm contains a number of heuristics and other features which make it very effective on the broad rostering model introduced.

@&#INTRODUCTION@&#
Rostering problems are found in a wide range of workplaces and industries including healthcare, manufacturing, transportation, emergency services, call centres and many more. Using a computational search algorithm to address these problems results in cost savings and better work schedules. As such, rostering problems in various forms have received a large amount of research attention over the years. This body of research grew steadily throughout the 1960s, 1970s and 1980s and then accelerated in growth as more powerful desktop personal computers became commonplace in workplaces during the 1990s. As the computational and processing power has grown so has the range and complexity of algorithms that can be applied and the size and complexity of the instances that can be solved. For an overview of rostering problems and solution methodologies see (Ernst, Jiang, Krishnamoorthy, & Sier, 2004). A very large annotated bibliography of publications relating to staff scheduling is also provided by Ernst, Jiang, Krishnamoorthy, Owens, and Sier (2004). For a literature review specifically aimed at the nurse rostering problem, see (Burke, De Causmaecker, Vanden Berghe & Van Landeghem, 2004).As these review papers show, many different approaches have been used to solve nurse rostering problems. These include metaheuristics (Bellanti, Carello, Croce, & Tadei, 2004; Burke, Curtois, Post, Qu, & Veltman, 2008; Burke, Curtois, Qu, et al., 2010; Ikegami & Niwa, 2003; Moz & Pato, 2007), constraint programming (Darmoni et al., 1995; Meyer auf’m Hofe, 2000; Weil, Heus, Francois, & Poujade, 1995), mathematical programming (Azaiez & Al Sharif, 2005; Bard & Purnomo, 2005), other artificial intelligence techniques (such as case-based reasoning (Beddoe & Petrovic, 2007) and hybrid approaches (Burke, Li, & Qu, 2010; Qu & He, 2008). Each method has strengths and weaknesses. For example, as will be shown in this paper, a mathematical programming approach may be able to solve some instances to optimality extremely quickly but on other instances it may take infeasible amounts of time or use too much memory. A metaheuristic, on the other hand, may be able to find a good solution to difficult instances quite quickly but may not be able to find the optimal solution to another instance which an exact method can solve very quickly. An obvious solution to this well-known phenomenon is to combine and hybridise different techniques. This is one of the principles behind adaptive approaches such as hyperheuristics.The aim of this paper, however, is to provide new results (upper bounds and lower bounds) for a large collection of diverse rostering benchmark instances. This is the first occasion that a branch and price method has been applied to these instances. We also introduce the dynamic programming algorithm which is at the core of the branch and price method and we present a general rostering model which was used for all the instances tested.Branch and price is a branch and bound method in which each node of the branch and bound tree is a linear programming relaxation which is solved using column generation. The column generation consists of a restricted master problem and a pricing problem. Solving the pricing problem provides new negative reduced cost columns to add to the master problem. The pricing problem can be considered as the problem of finding the optimal work schedule for an individual employee but with the addition of dual costs, that is, additional (possibly negative) costs based on which shift assignments are made or not made. In non-root nodes of the branch and bound tree, there may also be additional branching constraints on certain assignments that must or must not be made.Although this is the first time that branch and price has been applied to these instances, it has previously been used on the nurse rostering problem (Eveborn & Rönnqvist, 2004; Jaumard, Semet, & Vovor, 1998; Maenhout & Vanhoucke, 2010; Mason & Smith, 1998). All these earlier applications have similar structure and the same structure is adopted here. The master problem is modelled as a set covering problem and solved using a linear programming method such as the simplex method. The pricing problem is formulated as a resource constrained shortest path problem and solved using a dynamic programming approach. The branch and bound tree is generally too large for a complete search and so heuristic, constraint branching schemes are adopted in which branching is performed on shift assignments in the roster. Although the dynamic programming algorithms all use the same principles (dominance pruning and bound pruning), the actual implementations are dependent on the constraints and objectives present in the pricing problem. For a recent overview of column generation see (Lubbecke & Desrosiers, 2005) and for further reading on resource constrained shortest path problems see (Irnich & Desaulniers, 2005).In the next section, we discuss the challenge of modelling such a wide variety of instances and how it was solved. In Section 3, we introduce the benchmark instances and Section 4 presents the branch and price algorithm. Section 5 contains the results of applying the algorithms to the benchmark instances. In Section 6, we discuss the International Nurse Rostering Competition and finish with conclusions in Section 7.One of the most significant challenges in addressing a large diverse collection of instances is developing a model which can be used for all the instances with their varying types of constraints and objectives. In all the instances, there are common types of constraints/objectives which are relatively straightforward to model. These include the cover constraints (ensuring that there is a correct or a preferable number of employees assigned to each shift). However, the types of constraints that can be present in each employee’s work schedule can vary significantly from instance to instance. This is due to the reality of each workplace having its own set of rules and requirements defined by different employers, employees, unions and national legislation. Furthermore, each employee often has a different contract to reflect such features as full-time employment, part-time employment and night shift working. To provide a system which can incorporate these variations, we developed a general constraint based on pattern/string matching or more specifically regular expressions. Regular expressions are a powerful yet compact way of specifying patterns to be found or matched. They are commonly used in Computer Science and so we will not expand upon the subject here. Instead, we refer readers to one of the many textbooks on the subject such as (Friedl, 2006). Using a regular expression constraint in staff scheduling problems appears to be a natural fit and this is not the first example of its application to these type of problems (Côté, Gendron, Quimper, & Rousseau, 2011; Demassey, Pesant, & Rousseau, 2006; Pesant, 2004). However, in order to fully include all the variations in the instances we used, our approach is broader than some of this earlier work. First though, we will illustrate by example how this constraint can be applied in staff rostering problems. The basic idea behind the constraint is to consider the employee’s work schedule as the ‘search text’ containing the regular expressions to be matched and the regular expressions to be matched are sequences of shifts. After presenting the examples below, we also provide a figure to illustrate how the constraint works in practice (Figs. 1–3). The figures show a short section of a single employee’s schedule. The coloured squares labelled E, D and N represent early, day and night shifts respectively. The highlighted days show where the regular expression in question has been matched.Example 1If a night shift (N) can only be followed by another night shift or a day off then it could be modelled by the constraint “maximum zero matches of the pattern ‘N followed by any shift other than N’”. Note that we use the expression “maximum zero” here as another way of saying this pattern must not appear at all. We use this expression instead though because all the matches are expressed as either a maximum or minimum number of matches in order to provide more modelling power (Fig. 1).If an employee must not work more than five consecutive shifts then it could be modelled by the constraint “maximum zero matches of the pattern ‘Any, Any, Any, Any, Any, Any’” where Any is any shift (that is, not a day off) (Fig. 2).If an employee must have a minimum of two consecutive night shifts then the constraint would be “maximum zero matches of the pattern ‘anything but N, followed by N, followed by anything but N’” (Fig. 3).As can be seen, the constraint is based on the idea of string/pattern matching. However, it is more like a regular expression and extends some of the previous work because we also allow:▪Grouping: Matching one of a group of shifts at a point in the sequence.Negation: Matching anything but a specific shift or group of shifts at a point in the sequence.Alternation: Matching multiple patterns.Quantifiers: The pattern(s) must appear a minimum or maximum number of times.Restricting the search text to a specific region of the work schedule.Only matching a pattern if it starts on a particular day in the work schedule.This enables us to model some of the more complicated constraints such as those relating to weekend work or constraints that only apply between certain dates in the planning period. Using this general regular expression constraint, we can model many of the constraints found in staff scheduling problems. An example list is provided below.▪Minimum/maximum consecutive work days.Minimum/maximum consecutive non-work days.Day on/off requests.Shift on/off requests.Minimum/maximum number of shifts (optionally within a specific time frame).Minimum/maximum number of shifts of a specific type (optionally within a specific time frame).Minimum/maximum number of consecutive shifts of a specific type (optionally within a specific time frame).Days off after a series of shifts of a specific type.Shift rotations (which shifts can follow which shifts).Minimum/maximum shift rotations.Minimum/maximum number of weekends worked (or any group of days/dates).Minimum/maximum number of consecutive weekends worked.Although all these constraints can be modelled using the regular expression constraint there are though some constraints which cannot. In particular, this includes those relating to the minimum and maximum amount of work time an employee can be assigned. For this type of constraint, we developed a general constraint called Workload which is simply a minimum or maximum amount of work time which can be assigned to a single employee between any two dates in the planning horizon.A mathematical model of the problem is now presented.SetsEEmployees to be scheduled, e∊ETShift types to be assigned, t∊TDDays in the planning horizon, d∊{1,… ,|D|}ReRegular expressions for employee e, r∊ReWeWorkload limits for employee e, w∊WeParametersRUermaxMaximum number of matches of regular expression r in the work schedule of employee eRLerminMinimum number of matches of regular expression r in the work schedule of employee eRWerWeight associated with regular expression r for employee eWUewmaxMaximum number of hours to be assigned to employee e within the time period defined by workload limit wWLewminMinimum number of hours to be assigned to employee e within the time period defined by workload limit wWWewWeight associated with workload limit w for employee eCUtdmaxMaximum number of shifts of type t required on day dCLtdminMinimum number of shifts of type t required on day dCWtdWeight associated with the cover requirements of shift type t on day dVariablesxetd1 if employee e is assigned shift type t on day d, 0 otherwiseRNerThe number of matches of regular expression r in the work schedule of employee eWNewThe number of hours assigned to employee e within the time period defined by workload limit wCNtdThe number of shifts of type t assigned on day dConstraintsEmployees can be assigned only one shift per day(1a)∑t∈Txetd⩽1,∀e∈E,d∈DObjective Function(1b)Minf(x)=∑e∈E∑i=14fe,i(x)+∑t∈T∑d∈D∑i=56ft,d,i(x)where(1c)fe,1(x)=∑r∈Remax0,RNer-RUermaxRWer(1d)fe,2(x)=∑r∈Remax0,RLermin-RNerRWer(1e)fe,3(x)=∑w∈Wemax0,WNew-WUewmaxWWew(1f)fe,4(x)=∑w∈Wemax0,WLewmin-WNewWWew(1g)ft,d,5(x)=max0,CLtdmin-CNtdCWtd(1h)ft,d,6(x)=max0,CNtd-CUtdmaxCWtdThe objective function (1b) is a weighted sum of the soft constraints (1c)–(1h). (1c) and (1d) relate to the regular expression constraints, (1e) and (1f) relate to the workload constraints and (1g) and (1h) the cover constraints. When applying this model to an instance in which one of the employee’s constraints or a cover constraints is a hard constraint we simply set the weight to a very high number (significantly higher than any of the other weights).The significant advantage of this model is that it can incorporate the requirements of many different workplaces without needing to be extended. This means that the algorithm does not need to be modified when a new constraint is encountered as long as it can be modelled as a regular expression. For example, the benchmark instances discussed in the next section could be described as different problems because most of them have a different set of constraints and objectives. However, we were able to model them all using this single model.In order to validate our algorithms and encourage more competition and collaboration between researchers working on rostering we have built a collection of diverse and challenging benchmark instances. The collection has grown over several years and has been drawn from various sources such as industrial collaborators (including software companies and hospitals), scientific publications and other researchers. The collection continues to grow, is currently drawn from thirteen different countries and the majority of the data sets are based on real world rostering scenarios. Table 1lists the instances. As can be seen, they vary in the length of the planning horizon, the number of employees, the number of shift types and the number of skills. Each instance also varies in the number, priority and type of constraints and objectives present. The objectives were set by the organisation that provided the data. For example, some prefer to minimise overstaffing whereas other prefer to maximise staff satisfaction by setting the weights for those objectives higher instead.The instances are available for download from http://www.cs.nott.ac.uk/~tec/NRP/, where all the required information on each instance, best solutions, visualisations and other software is also available. The data set files are not included within this paper because of their large size.Table 2lists the instances used in the First International Nurse Rostering Competition. The instances were created by the competition organisers and not released before the competition. They are discussed further in Section 6.The implementation of the branch and price approach follows the previously published algorithms mentioned in section 1. However, quite a lot of time was spent improving the performance of the implementation. For example, profiling the algorithm reveals that during the column generation, typically about 5% of the computation time is spent re-solving the restricted master problem (using the simplex method) whereas the other 95% of the time is used in solving the sub-problems (generating the new columns using the dynamic programming algorithm). This meant that the performance of the algorithm could be most significantly improved through:(1)Reducing the number of calls to the pricing problem solver.Improving the performance of the pricing problem solver.Stabilization (reducing the oscillation of the dual values) was particularly important and effective for the first. For the second, additional heuristics and bounding methods were very effective, especially exploiting the fact that it is not necessary to find the most negative reduced cost column each time (that is, the pricing problem does not have to be solved to optimality until it is necessary to show that there are no more negative reduced cost columns). These heuristics are discussed in more detail in Section 4.1. For the stabilization, we used the method presented in Pigatti et al. (2005) which is relatively straightforward to implement and does not depend on instance specific parameters but was also very effective.To solve the master problem we used the simplex method of the open-source, Coin-OR linear programming solver (clp) (COIN-OR, 2010) which we found to be fast and stable.Within a time limit, two different heuristic branching strategies are applied in the branch and bound tree to try and find new solutions (upper bounds). For the first strategy, we simply branch on the variables in the master problem by selecting the variable that is closest to one. This strategy often quickly provides an upper bound but this upper bound can usually be improved by the second branching strategy. In the second strategy, we branch on individual employee-shift assignments (constraint branching). At each node in the tree, we select the employee-shift assignment that has the value closest to one when summing all the master problem variables (columns) that contain this assignment. Columns that do not contain this assignment are then removed from the master problem and when the master problem is re-solved the pricing problem solver only generates columns which contain this assignment (and any other forced assignments from ancestor nodes in the tree). We carried out some initial experiments with branching on the most fractional assignments (closest to 0.5) instead. There did not appear to be much difference in solution quality but it was slightly slower on average so chose to branch on assignments closest to one.The initial solution is provided by applying the variable depth search algorithm for 5seconds. If a provable optimal solution (lower bound equal to upper bound) is not found within the time limit, then the best upper bound is returned.We use a dynamic programming approach to solve the pricing problem. That is, to generate new columns where the columns are basically new work schedules (also called shift patterns) for individual employees. The problem can be classified as a resource constrained shortest path problem. Fig. 4shows an example graph for an instance with three shift types (Early, Day and Night). A path consists of n connected nodes between the source and sink node where n is the number of days in the planning horizon. Each shift type and a day off represent the nodes that can be chosen on each day. Resources are collected along the path depending on which nodes are part of that path.The idea behind dynamic programming is to use bounding and dominance to prune paths/nodes that can be shown to be unnecessary to expand. Although dynamic programming can be very effective at solving certain types of problem, in worst cases the number of paths can still grow exponentially.An interesting feature of our implementation is that we solve the problem over a number of iterations where at each iteration the number of paths that can be expanded is restricted to a maximum and the paths to expand are selected heuristically. If at the end of an iteration the maximum limit was not reached then the problem was solved. Otherwise, we try again with a higher limit but possibly also with a new upper bound (i.e. the best solution found at the previous limit). We also resume the search at the point the limit was reached in order to avoid superfluous repetitions. An outline of the algorithm is provided by Fig. 5and discussed in more detail below.The algorithm is able to solve the problem to proven optimality or just return the first set of solutions it finds with an objective function value below a bound. This bound and the flag indicating whether to solve it to optimality are passed as parameters to the algorithm. The other algorithm parameters are variables which may change between calls to the method: The dual costs (from the cover constraints) and any branching constraints. (The branching constraints are assignments which must or must not be made in the shift pattern because they are fixed in the branch and bound tree).As already discussed, in the column generation algorithm it is not necessary to solve the pricing problem to optimality every time (that is, it does not need to find the most negative reduced cost column) but any negative reduced cost columns are acceptable.The maximum array sizes to use at each iteration of the algorithm is set at step 3. In the pseudocode, the values shown are: {32, 128, 512, 2048, 8192, infinity} which is the setting used for the results shown in Section 5. Some testing was performed varying the size of this set and the values in it but no clear best setting was found when tested over all instances. However, a general strategy of starting with small values which are solved very quickly before gradually moving to the larger values appears to work best.At step 15 (i.e. after a shift assignment is made), a lower bound is calculated (a minimum objective function value) for a partially complete pattern by looking at the assignments already made, the objectives for that employee and the dual costs. This lower bound is then used to discard the pattern if it is greater than or equal to the best upper bound found so far. (Although not shown in the pseudocode this exact same procedure is also done at step 5 where other assignments are made due to branching constraints).After creating a new partial pattern, it is necessary to compare this pattern to the partial patterns in NextArray for dominance. The dominance checking simply involves comparing the patterns by examining the values of the variables RNerand WNewused in the objectives (1c)–(1f) for the employee e that the pattern is being generated for. For example, if it is a minimum objective (1f) or (1d) then the pattern with the higher variable value is dominant for that objective. If it is a maximum objective (1c) or (1e) then the pattern with the lower variable value dominates. A pattern dominates another pattern if it dominates for at least one objective and is not dominated on any other objectives.If the pattern is dominated by an existing pattern then it is discarded (to significantly increase the computation speed the pattern that dominates it is moved to the start of the NextArray, this has the effect that the next time the array is iterated through to check for dominance there is a greater chance it finds a dominant pattern more quickly). If the pattern dominates any existing patterns then it is added to NextArray and all the patterns that it dominates are removed. If it is identical to an existing pattern (that is, neither are better for any of the objectives) then it is also discarded. If it is incomparable to an existing pattern (that is, they each are better on an objective or cannot yet be compared for an objective) then it must be added. It may still dominate other patterns though which can be removed. It is also useful to note that when comparing two patterns, an objective which can be shown to be already satisfied in both patterns can be ignored in the comparison.Dominance checking is the most time consuming part of the algorithm, particularly when the number of patterns to compare is large. A number of suggestions have been made in the literature to speed up this process. These include maintaining sorted lists or checking for dominance at different points in the algorithm. However, the feasibility of these suggestions depends upon the type and number of objectives present. We perform the dominance testing at step 19 but it is also possible to compare patterns at steps 30 and 31 instead.At step 23, the new pattern cannot be added to NextArray as it would cause the maximum array size to be exceeded. However, the pattern with the worst objective function value is replaced with the new pattern if it has a better objective function value. This is another heuristic rule which improves the speed of the algorithm.At step 24, the algorithm moves to step 29 and tries a different shift assignment at the current day (TryNextAssignment is simply a label at the end of that loop which in effect immediately moves to the start of the loop and tries the next shift type). During development we did experiment though with going to step 9 (move to the next day) instead of going to the step 29 as it may appear more efficient to not test every shift type if we already have a valid pattern. However, it was found to be much more effective to continue generating new patterns by going to step 29. This is because we are testing all possible shift types which although slower, as a result of the heuristics and rules within lines 16–27 the patterns which remain by the next day (step 9) are the dominant patterns with lower partial objective function values.It is worth mentioning that although adding the heuristics described had the most significant impact on the performance of the algorithm, how the algorithm is implemented can also have an effect on the speed of the algorithm. This is particularly the case with respect to memory management and the types of data structures used.

@&#CONCLUSIONS@&#
