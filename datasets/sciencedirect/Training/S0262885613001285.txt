@&#MAIN-TITLE@&#
A new evaluation measure for color image segmentation based on genetic programming approach

@&#HIGHLIGHTS@&#
A genetic programming (GP) approach is proposed to design a combined evaluation measure for image segmentation algorithms.The proposed approach improved the performance of image segmentation evaluation.A new fitness evaluation scheme is proposed for GP.A new evaluation measure based on intra-region similarity and inter-region disparity is proposed in this paper.

@&#KEYPHRASES@&#
Image segmentation,Evaluation measure,Genetic programming,Intra-region,Inter-region,Over-segmentation,

@&#ABSTRACT@&#
One of the greatest challenges while working on image segmentation algorithms is a comprehensive measure to evaluate their accuracy. Although there are some measures for doing this task, but they can consider only one aspect of segmentation in evaluation process. The performance of evaluation measures can be improved using a combination of single measures. However, combination of single measures does not always lead to an appropriate criterion. Besides its effectiveness, the efficiency of the new measure should be considered. In this paper, a new and combined evaluation measure based on genetic programming (GP) has been sought. Because of the nature of evolutionary approaches, the proposed approach allows nonlinear and linear combinations of other single evaluation measures and can search within many and different combinations of basic operators to find a good enough one. We have also proposed a new fitness function to make GP enable to search within search space effectively and efficiently. To test the method, Berkeley and Weizmann datasets besides several different experiments have been used. Experimental results demonstrate that the GP based approach is suitable for effective combination of single evaluation measures.

@&#INTRODUCTION@&#
Image segmentation is an essential problem in image processing, computer vision, video and image retrieval applications. It is often used to partition an image into separate regions for content analysis and image understanding. Because segmentation algorithms are often used as a preprocessing step for larger systems, we have to say that their improper performance can highly impress on the final results. To address this challenge, a variety of segmentation algorithms have been proposed [1–4]. Because defining a unique algorithm applicable in all domains is almost impossible, most of these algorithms are domain-specific. Hence, looking for some measures for assessing segmentation results is needed. Defining a good measure to evaluate the segmentation is a known challenging problem in machine vision and image processing applications.Generally, supervised and unsupervised techniques are two well-known approaches used for obtaining a good evaluation measure. Generally, supervised algorithms have been used more in researches [5–8]. Supervised evaluations are also called relative evaluation or empirical discrepancy methods and need some prior knowledge such as a ground truth image. Unsupervised evaluation techniques are also known as stand-alone algorithms or empirical goodness methods. They are quantitative and objective. Unsupervised methods compute some statistical data in the segmentation results, without any prior knowledge. They compare segmentation methods without requiring human intervention or a manually segmented or pre-processed reference image. Unsupervised methods are important for real-time segmentation evaluation and can also be used for self-tuning algorithm [9].From segmentation point of view, different images can be divided into several categories including color, gray-level, textural images, etc. Each of these categories can have its own offsprings like natural, medical, satellite, submarine images, etc. Both segmentation approaches and their evaluation measures are selected according to the images' features. For example we can refer to evaluation measures for medical images [10–12], for natural images [6,8,9], etc.One of the important characteristics of evaluation measures is their accuracy. Almost all of the existing measures can evaluate only one or two features in a segmented image (such as error color, entropy, homogeneity regions, variance, etc.). Most of them are not sensitive to under and over-segmentation and cannot detect them. To improve the accuracy of evaluation, one approach is combining them. However, combining various measures can be too complicated to do. Furthermore, they may not be effective for all images, even for image in one class.In this paper, a genetic programming based approach has been considered for proposing a new, effective and efficient evaluation measure. GP has been employed to combine different and unrelated evaluation measures. Each evaluation measure can be used either without any or with a little modification. For doing so, some proper single measures for a particular image type, according to the database, should be selected. After selecting the single measures, GP combines them so that the new measure works for all images in that particular category.GP [13] belongs to a set of artificial intelligence problem-solving techniques which are based on the principles of biological inheritance and evolution. Each potential solution is called an individual (i.e. a chromosome) in the population. The main difference between GA [14] and GP is their internal representation (or data structure) for an individual. Collectively, GA-based applications usually represent each individual as a fixed-length bit string. In GP, on the other hand, more complex data structures like trees, linked lists, or stacks are used [15].GP iteratively transforms a population of computer programs into a new generation by applying naturally occurring genetic operations. These operations are applied to individuals selected from the previous population [16]. The individuals are probabilistically selected to be applied into the genetic operations based on their fitness. The genetic operators include crossover (sexual recombination), mutation, reproduction, gene duplication, and gene deletion. In short, GP becomes a powerful method to solve the NP hard problems by using the capabilities of evolutionary search [13] and has been applied successfully in several problems [17,18].In this paper, four unsupervised evaluation measures based on intra-region similarity and inter-regions disparity have been employed in combination process. The evaluation measures include extended version of Zeboudj [19] and Rosenberger evaluation [20], an evaluation measure based on entropy [21], and a new measure based on intra-region similarity and inter-region disparity. The proposed combined measure is able to take all features of these four evaluation criteria including color error, squared color error, entropy on each region, average color difference between regions, local color difference along boundaries, and layout entropy and then combine them in an effective way. Also, a new fitness function for GP has been proposed.The rest of this paper is organized as follows. In Section 2, some proposed evaluation measures will be reviewed. Section 3 presents the GP framework for combining evaluation measures. Section 4 discusses about the experiments and the results. In Section 5, besides a brief conclusion, some opportunities for further studies will be discussed.A variety of techniques have been proposed to evaluate image segmentation algorithms. In this section, the previously proposed measures for addressing image segmentation evaluation task will be reviewed.Levine and Nazif [9] defined a criterion that calculates the uniformity of a region based on the variance of its characteristic. Complementary to the intra-region uniformity, Levine and Nazif defined a disparity measurement between two regions to evaluate the dissimilarity of regions in segmentation results [22].Liu and Yang [9] proposed an evaluation function based on empirical studies. The parameters of their approach do not need to be set by a user and are defined automatically. Also, they are independent of the type of image. Borsotti et al. [22] improved Liu and Yang's method by some modified quantitative measures. All of these evaluation functions were generated from the results of empirical analysis and had no theoretical foundations.Zeboudj [23] proposed a measure based on the combination of maximum inter-region similarity and minimal intra-region disparity in a neighborhood. Rosenberger [20] presented a criterion that estimated the intra region homogeneity and the inter regions disparity. This criterion quantifies the quality of a segmentation result.Zhang et al. [24] proposed a novel segmentation evaluation method based on information theory. This method uses entropy to measure the uniformity of pixel characteristics within a segmentation region. Instead of using squared color error, they used the Shannon entropy of the luminance of all pixels in a region to measure its uniformity. Pal and Bhandari [25] proposed an entropy-based segmentation evaluation measure for intra-region uniformity based on the second order local entropy.Chen and Wang [26] proposed a composite evaluation method for color images. Their method uses intra-region visual error to evaluate the degree of under-segmentation, and uses inter-region visual error to evaluate the degree of over-segmentation.Zhang et al. [27] proposed a co-evaluation framework in which different measures judge the performance of the segmentation in different ways. Then, their results are combined by using a machine learning approach. After determining different evaluation measures as well or poor, their approach gains the appropriate measures to achieve a reliable result [27]. However, each single basic evaluator typically performs well in some types of images/segmentations, whereas works poorly for some others. Therefore, Zhang et al. [28] proposed a meta-evaluation method to resolve limitations of co-evaluation frameworks.Meta-evaluation methods combine the results of a set of basic measures using machine learning algorithms (Naive Bayes, support vector machine, or the weighted majority algorithm) in order to obtain an overall acceptable evaluation measure. The training data used by the machine learning algorithm can be labeled by a user, based on either similarity to reference segmentation or system-level performance.Several evaluation metrics that are designed for video frames can be easily modified and be used for image segmentation evaluation [29,30]. These methods use measures similar to image segmentation evaluation.Correia and Pereira [31] proposed a method which consists of a set of metrics for both intra-object measures (e.g. shape regularity, spatial uniformity) and inter-object measures (such as contrast). Furthermore, each object in the image is weighted according to its relevance, which is an estimation of how much the reviewer's attention is attracted to that particular object.Erdem et al. [32] proposed an evaluation measure based on spatial color contrast within the boundary of each object. The key component is the difference between the average colors of pixels and their neighbors in a region, averaged by the total number of lines drawn on object boundaries.In [33] a Bayesian network framework for unsupervised evaluation of image segmentation has been proposed. This image understanding algorithm utilizes a set of given Segmentation Maps (SMs) ranging from results of under to over-segmentation for a target image. This method identifies some semantically meaningful objects in an image and ranks the SMs according to their applicability.In this section, details of the proposed GP framework will be discussed in details. The details include the different aspects of GP learning systems such as selection of terminal set, function set, fitness measure, input parameters, and determining the termination conditions.The so far existing measures cannot have a comprehensive evaluation for image segmentation algorithm because they do not consider all the parameters which can impress on the performance. So, they have to be combined, of course in a proper manner which must be effective and efficient. According to the number of evaluation measures and different possible arithmetic operations, there is a large search space in which, we have to find the optimum, or at least a good enough solution.The proposed approach uses GP to combine evaluation measures. This method relies on the creation of a composite measure, which is the combination of pre-defined evaluation measures. It also produces meaningful combination of evaluation measures.GP is guided by the fitness function to search for the most effective computer program for solving a given problem. A fitness function assigns a fitness value to each individual in order to select the best ones. Then, genetic operators such as reproduction, crossover, and mutation are applied to create more diverse and efficient ones.The reproduction operator simply involves the selection of an individual based on the fitness function and making a copy of it in the next generation. Mutation and crossover are two primary genetic operators, which are used to create new programs based on existing ones. The crossover operator combines two parents by swapping a sub tree of one parent with a part of the other one. The mutation can be defined as a random manipulation of one individual. This operator selects a point in the GP tree randomly and replaces the existing sub tree at that point with a new randomly generated sub tree [34]. If a point is a terminal, then it is replaced by another randomly chosen terminal. If it is a function, then it will be replaced by another randomly chosen function with the same number of inputs. The key components of a GP system have been listed in Table 1. This process is repeated over and over again until a stopping criterion (e.g., an acceptable solution be found or maximum number of generations be reached) is satisfied. In the end, the GP system selects an individual with the best performance as a composite evaluation measure (e.g., the best tree in the last generation). The details of GP-based evaluation algorithm can be found in Fig. 1.Fig. 2illustrates the proposed framework for producing the composite measure, EComposite, for evaluating segmented images. Using a set of training images with their corresponding segmented images, GP first operates on a large population of randomly combined functions (individuals). As Fig. 2 shows, evaluation measures (E1, E2… En) have been utilized to create the individuals for initial population in the GP-based system. Each individual is a tree that is created randomly. Single evaluation measures are leaf nodes in the tree structure. Each tree can be the solution.The advantages of the proposed method are its improved accuracy in comparison with the current evaluation methods, the ability to use any evaluation criterion, the potential of combining different types of evaluation measures, and evaluating the segmented images came from any segmentation algorithms. Also, the flexible nature of GP enables system to deal with any type of images because GP automatically solves problems without requiring the user to know or specify the form or structure of the solution in advance. The only important thing is selecting some related evaluation measure for combination.The selected evaluation measures for this approach are based on minimal intra-region similarity and maximum inter-regions disparity. Intra-region similarity is calculated based on color error, squared color error and entropy for each region. Inter-region disparity is calculated based on average color difference between regions, local color difference along boundaries and layout entropy. Table 2presents an overview of the evaluation measures used in our experiments.It is important to note that the selected evaluation measures for combination must be selected according to the type of images in dataset. After selecting the basic measures, the GP approach combines them. According to the GP characteristics and because it supports different types of encoding and combination, it will discover a good and effective combination of these measures in search space.We have used the following notations for the evaluation measures. Let Iobe the original image and Isbe the segmented image that is defined as a division of Iointo N arbitrarily-shaped regions. Rjis the set of pixels in region j, and Sj=|Rj| denotes the area of region j. Let SI be the area (as measured by the number of pixels) of the full image. We have considered images in the RGB color space. A color image in its distinct components is processed using gray-level methods. Each intra-region color error of segmented image is computed according to its R, G and B components. According to each component, one error value for each region is obtained. The average of three color errors of each region represents the total color error of that region.In a segmented image the pixels that are located in a same region should have similar properties while pixels of neighboring regions must be different from each other. Thus a good segmentation criterion should consider two conditions: homogeneity of intra-regions and disparity of neighboring regions.Intra-region squared color error is equal to the proportion of misclassified pixels in a region. This parameter, in the uniform case is equal to the normalized standard deviation of the region. Cx(p) is used to denote the value of component x for pixel p (or for pixel p and its neighboring pixels in the same region). The average value of component x in region j is defined as follows:(1)C^xRj=∑p∈RjCxp/Sjwhere x∈{color components} (RGB in our experiments). The squared color error of region j is defined as:(2)ex2Rj=∑p∈Rj1L−1Cxp−C^xRj2where L is the total number of gray levels. The total interior disparity denoted by V_intra(Rj) computes the homogeneity of each region in the segmented image:(3)V_intraRj=∑x∈RGBex2Rj3×Sj.The intra-boundary pixels of each region are different from the intra-boundary pixels of their neighboring regions. The regions with a high value of disparity are more separable and accurate. The inter-region disparity is computed based on the average disparity between a given region and its neighboring pixels in other regions. For a pixel, being in a wrong region makes a low value of disparity. The less number of incorrect pixels leads to more accurate region boundaries and consequently more accurate segmented image.The inter-region disparity computes the average disparity of a region with its neighbors. The disparity CE of two neighbor regions Ri, and Rjis calculated as:(4)CExRj=1Bj∑pn∈Wp,pn∉RjC^xRj−pn2/L−1where Bjis the number of pnpixels. W(p) includes the neighbors of p. pnbelongs to neighboring region Rjand CE(Rj) is the average inter-region disparity of region Rj. V_inter(Rj) is the total disparity of an inter-region which is defined as follows:(5)V_interRj=1NR×3∑x∈RGBCExwhere NR is the number of regions that are neighbor with Rj.If an intra-region disparity is less than its inter-region disparity, that region will be more accurate. The disparity of the region Rjis defined by measuring CR(Rj)ϵ[0, 1] defined as follows:(6)CRRj=1−V_intraRjV_intraRjif0<V_intraRj<V_intraRjV_intraRjifV_intraRj=00otherwise.The accuracy of segmented image depends on accuracy of its regions. So, the evaluation measure for segmented image is as follows:(7)E1=1SI∑j=1NCRRj×Sj.Zeboudj's evaluation measure [19] is an evaluation criterion based on the internal and external disparity of the regions for gray-level segmented images. We have extended this approach to evaluate segmentation of color images. Intra-region disparity is defined as error color. Cx(s,t)=|gI(s)−gI(t)|/(L−1) is defined as the disparity between two pixels s and t, and L is the maximum value of the gray-level. The interior disparity CIx(Rj) of the region Rjis defined as follows:(8)CIxRj=1Sj∑s∈RjmaxCxst,t∈Ws∩Rjwhere CIx(Rj) is the value of component x for intra-region Rjand W(s). An intra-region disparity can be calculated using Eq. (9):(9)CIRj=13∑x∈RGBCIx.The inter-region disparity is computed based on the average disparity between internal boundary pixels of desired region and its neighboring pixels in separate regions. Also, it is calculated based on local color difference. External disparity CE(i) of region Rjis defined as follows:(10)CExRj=∑s∈FjmaxCspn,pn∈Ws,pn∉Rj(11)CERj=1Bj×3∑x∈RGBCExRj(12)CRRj=1−CIRjCERjif0<CIRj<CERjCERjifCERj=00otherwise.The evaluation measure for segmented image is as follows:(13)E2=1SI∑j=1NCRRjSj.Rosenberger has proposed a measure enable to estimate the intra-region homogeneity and the inter-regions disparity of gray-level images [20]. Here, we have extended this measure to be used in evaluation of color image segmentation. This measure computes the disparity of an intra-region by CI (Rj) as Eq. (9).The inter-region disparity is computed as the average of the disparity of a region with its neighbors. Also, it is calculated based on regions' color difference. The disparity of two uniform regions Riand Rjis calculated as:(14)DExRj=1NR∑Ri∈ωRjC^xRj−C^xRiNgRj+NgRiwhere Ng(Rj) is the number of gray-level pixels in the region Rj. ω(Rj) is the neighborhood of the regions.(15)DERj=13∑x∈RGBDExRj(16)CRRj=1−CIRjDERjif0<CIRj<DERjDERjifCERj=00otherwise(17)E3=1N∑j=1NCRRj.As mentioned before, the proposed method combines some single measures to achieve a more accurate segmentation ranking. Although it is still depends on the type of images in dataset, but it is flexible because it can adapt itself to the new and different basic measures. It can finally find a more accurate solution by combining these single measures. These measures cannot deal with all images in dataset, even in the same type. In this section we will clearly find out that those single features are not good enough to be applied to the whole dataset. On the other hand, GP-based proposed approach can rank segmentation with a high degree of accuracy.Although using GP come with an overhead for its training, but the result and achieved accuracy makes it tolerable. As can be seen in this section, the new measure is completely robust against under and over-segmentation, whereas the single features cannot do it well.The performance of the proposed method depends on many factors and parameters. In this section, we will discuss about determining the appropriate parameters of our system and the results. Section 4.1 introduces the image database used in our experiments. In Section 4.2, the parameters of GP system will be described in details. Several fitness functions will be introduced in Section 4.3 and we will find which one is more appropriate. In Section 4.4, some experiments based on the described parameters will be brought and finally, different image segmentation algorithms will be evaluated by our proposed evaluation measure in Section 4.5.300 color images from the Berkeley11http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/.dataset [23] have been considered for our experiments. These images have been divided in two sets, training set containing 200 images that can be used to tune the parameters of algorithm, and the test set containing the remaining 100 images. The evaluations have been performed on the ground truth images from Berkeley dataset and segmented images are from Edison Image segmentation system [35]. Eight segmented images by applying different parameters with Edison segmentation system and 2 ground truth images are used for each image of dataset. For each original image, 10 segmented images are obtained including those with approximately equal, more and less than the number of regions in the ground truth image. Therefore, the train set includes (10∗200) 2000 segmented images and the test set includes (10∗100) 1000 segmented images. We have also used Weizmann horses22http://jamie.shotton.org/work/data.html.dataset as a test set in our experiments. Table 3shows image set used in experiments.Similar to the other evolutionary algorithms, individuals (chromosomes) in the initial population are generated randomly. The detail description of parameters of the system can be seen in the following:1)List of terminals: The terminals are the evaluation functions (E1, E2, E3, …).Functions (arithmetic operators): +, ∗, /, sqrt as non-leaf nodes are used in the tree implementation. Subtraction is not used to enable system for handling negative results. This function set is widely used in common GP experiments.Initial population: a tree-based structure used for representing the combination of operators. The initial set of trees constrained to have a maximum depth of four. There are some different approaches to generate random initial population e.g. the full and grow methods and a widely used one is known as ramped half-and-half [13,34,36,37]. The ramped half-and-half method has been employed to generate initial trees. This method guarantees that half of the randomly generated trees must be generated with maximum number of nodes which should not exceed the maximum defined depth. The remaining randomly generated trees require branches whose lengths do not exceed this depth. In the experiments a population containing 100 individuals has been considered.Fitness function: The fitness function plays a key role in guiding GP to obtain the best solutions within a large search space. In our problems, a fitness function measures the effectiveness of combined functions. Three fitness functions have been assessed and the most suitable one was selected for GP. Three fitness functions are:(18)F1=∑i=1Nrootg1i+rootg2iI^g1i+I^g2iwhere rootg1 and rootg2 are the accuracy of two ground truth images.I^g1iandI^g2iare the position of ground truth images i after evaluation. N is the total number of original training images.(19)F2=1N∑i=1N1I^g1i+I^g2i(20)F3=1N∑i=1NrI^gi..Once the fitness value of each individual is evaluated according to Eqs. (18)–(20), GP selects the best individual from the population for next generation.Reproduction: Reproduction copies the top R×P trees from current to the next generation, directly without any genetic transformation. R is the reproduction rate and P is the population size. We defined R=0.1 and P=100 in our experiments.Crossover: Crossover ensures variety by creating trees that differ from their parents. Tournament selection method [16,34] has been used to select trees from current generation for crossover.Mutation: The mutation rate in our experiments was 20% which is the percentage of individuals selected for mutation.Stop criterion: the GP process is stopped after 25 generations. It has been observed that defining a number more than 25 as the maximum number of generation cannot help the system to achieve a better performance.In this section, performance of the three fitness functions F1, F2, and F3are compared. Good fitness functions will help GP to explore the search space more effectively and more efficiently. On the other hand, unfit fitness functions can easily make GP to be trapped in a local optimum and lose the discovery power.Four set of segmented images from Table 3 have been selected for comparing performance of the three fitness functions, and their corresponding results shown in Table 4. The first part of these sets is the train set, considered as sample 1, including 200 train images and their segmented images. Fifty images from test set and their corresponding segmented images were considered as sample 2. Images in test set have been selected as sample 3 and sample 4 includes a combination of sample 1 and sample 3, e.g. train and test sets. All images from train and test sets include 10 segmented images in which two of them are the ground truth images.An optimal evaluation measure should correctly evaluate segmentation and obtain high accuracy for the ground truth images compared with other segmented images. As we know the ground truth images, the best fitness function should assign the highest value to the optimal tree.First, the GP framework is trained using fitness functions and sample 1. After this phase, images from sample 1 through sample 4 are evaluated by the best composite evaluation measures obtained from different fitness functions. The segmented images of each class are ranked based on their segmentation accuracy in order to determine the best fitness function. The fitness function would be appropriate for the proposed method if its optimal composite evaluation measure gives the highest accuracy for all samples. Table 5shows average accuracy of the each optimal composite evaluation obtained by different fitness functions. According to Table 5, the fitness function F2presented better individual than F1and F3. Therefore, F2is an appropriate fitness function for the proposed method, which its obtained optimal composite evaluation measure has been used in our experiments.In this section, performance of the composite evaluation measure, (((E4∗E1)/(E4sqrtE3))+((E4sqrtE4)∗(E4+E2)))=EComposite, achieved from the best tree from the last generation of GP populations is compared with others: E1, E2, E3, and E4. Then, the effect of under and over-segmentation will be analyzed.To compare the performance of the evaluation measures, images of sample 1, sample 2 and sample 3 have been considered. Each image in these three samples is evaluated by E1, E2, E3, E4, and ECompositeand the average number of correctly evaluated classes will be calculated. Table 6shows the average accuracy for each evaluation measure. According to Table 6, ECompositeevaluated more classes correctly.To examine the effects of under and over-segmentation, 20 images from test set have been selected randomly. For each image, three types of segmentation have been employed including segmentation with more regions, approximately equal, and less than the number of regions exist in the ground truth images. The optimal evaluation measure must be able to recognize under and over-segmentation. So, normal segmented images should have higher accuracy than under- and over-segmented images.Fig. 3shows the results of E1, E2, E3, E4, and ECompositefor 20 selected images. The E1, E2, E3, and E4cannot penalize under and over-segmentation cases and in some cases, the accuracy of under and/or over-segmented images is more than normal values. Therefore, we can obtain that E1, E2, E3, and E4are not sensitive to under and over-segmentation. As can be seen, the proposed method is able achieve to a suitable degree of similarity for different images and penalize under and over-segmentation.To continue the experiments, test set images (from Berkeley and Weizmann datasets) have been evaluated by EComposite. The outcomes of three classes of the test set have been shown in Figs. 4, 5 and 6. Each class consists of 10 different segmented images including the ground truth, normal segmentation, under and over-segmented images. The image No.1 is the most acceptable image and the No.10 is the worst. A good evaluation measure should be able to evaluate and rank the images 1 to 10 correctly and assign highest accuracy value to the image No.1. In all of these figures, the highest value achieved for each measure has been emphasized in bold.Consider Fig. 4 at first. As can be seen, except E4and EComposite, the others could not detect the best segmentation among ten images. According to the ranks these algorithms assigned to segmented images, E2and E3recognized the third acceptable segmentation as the best and E1chose the second one. To continue evaluating the proposed approach we have considered another image shown in Fig. 5. The performance of the single measure became more challenging for this image. As can be seen, except E1and EComposite, the others made mistake in detecting the best segmented image. E3and E4assigned highest rank to the forth segmented images. But in the case of E2, we faced to the worst judgment. This measure recognized the worst segmentation as the best one.Fig. 6 gives us better demonstration about performance of the proposed method. Except EComposite, the others have wrong choices. E1and E3chose the third and E2chose the second segmented image. E4gave the fifth segmented image the highest accuracy rate. But, the same as previous cases, we can see only ECompositehas the most correct judgment. In all cases, each single measure showed different behaviors, while they are suitable for this kind of images. On the other hand, the proposed GP-based measure showed a good performance for all cases.All of the selected evaluation measures can be computed very quickly. Most of the cost is associated with the training time which is a pre-processing step for our GP system and must be done only one time. So, the computation time achieved by the proposed combined evaluation measure is still low.In this section, segmentation accuracy of three segmentation algorithms, i. e. Edison system [35], Normalized-Cut method (NC) [24,38] and image segmentation based on improved ant colony algorithm (ISIACA) [4] are evaluated and compared by the proposed method. 14 color images of original images are randomly selected to perform this experiment. The selected images have been segmented by each of the above segmentation methods (each segmentation method was adjusted by the best input parameters). The accuracy of segmentation algorithms obtained from each of these 14 selected images has been shown in Fig. 7. To draw this chart, for each algorithm, the number of images that an algorithm achieved the highest accuracy for them is counted. For example, if Edison achieved the best accuracy for image No.1, Edison was considered the winner for “1”.The Edison system was the winner mostly among these three methods. It achieved more accuracy value (in 8 cases of 14) and the NC won more times than the ISIACA method. The average accuracy of Edison, NC and ISIACA methods on 14 images were 0.5598, 0.4554, and 0.3187 respectively. Therefore, the average accuracy of Edison system was higher than NC and ISIACA.

@&#CONCLUSIONS@&#
