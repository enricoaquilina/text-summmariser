@&#MAIN-TITLE@&#
Fault-tolerant multi-agent control architecture for autonomous mobile manipulators: Simulation results

@&#HIGHLIGHTS@&#
We propose a generic multi-agent control architecture for mobile manipulators.Robot complex mathematical models are not required, so computing time is reduced.The strategy is fault-tolerant to breakdowns without needing specific treatments.The proposed approach works in 3D environments with high dof mobile manipulators.Accuracy of the proposed approach is good comparatively to classical approaches.

@&#KEYPHRASES@&#
Multi-agent control architecture,Fault-tolerant architecture,Mobile manipulators,Simulation-Verification technique,Reaching tasks,RobuTER/ULM,

@&#ABSTRACT@&#
This paper presents our ongoing efforts toward the development of a multi-agent distributed framework for autonomous control of mobile manipulators. The proposed scheme assigns a reactive agent to control each degree-of-freedom of the manipulator(s), a hybrid agent to control the mobile base, and a supervisory agent to coordinate and synchronize the work of the control agents. Each control agent implements a Simulation-Verification technique to optimize, locally and independently from the other agents, a predefined objective function. The final goal consists of bringing the end-effector as close as possible to imposed operational targets (reaching tasks).Different simulation scenarios are described and carried out for the case of RobuTER/ULM robot, with and without considering failures of some articulations of the manipulator or the mobile base. Results show that the main advantage of the proposed approach is that the system pledges a fault-tolerant response to some breakdowns without needing any specific additional treatment.it represents the situation (position and orientation) of the imposed Targetit represents the initial/current situation of the end-effector of the robot in the absolute frame. The first three values are the position of the end-effector; the last three represent its orientation anglesit corresponds to the new situation of the end-effector after the Move Up/Move Down movement of the joint i of the manipulatorit represents the new situation of the end-effector of the robot after the forward/backward/turn left/turn right movement of the mobile baseit represents the initial/current/final situation (position and orientation) of the mobile baseit represents the new situation of the mobile base after the forward/backward/turn left/turn right movement carried out by the Mobile base agentit corresponds to the initial/current/final configuration of the manipulator jointsit corresponds to the new configuration of the manipulator joints after the Move Up/Move Down movement carried out by the Joint agentit represents the initial/current/final (after optimization) value of the objective function

@&#INTRODUCTION@&#
Typically, mobile manipulators are mechanical systems consisting of one or more articulated manipulators mounted on holonomic or non-holonomic mobile bases [1]. Such systems, which are usually characterized by a high degree of redundancy (generally, greater than six degrees of freedom (dof)), combine the manipulability of fixed-base manipulators with the mobility of mobile bases. Accordingly, they are able to accomplish most common complicated tasks that require locomotion and manipulation capabilities [2] in large workspaces that may include many obstacles [3]. The high mobility of mobile manipulators and their dexterous manipulation abilities make this type of robots increasingly utilized in various fields, such as planetary exploration, urban search-and-rescue operations, mining, agriculture, military missions, and nuclear reactor maintenance and hazardous site clean-ups [4,5].Autonomous robot is a kind of intelligent system that accepts a task, changes its description into executable commands [6] and, finally, autonomously performs it in a complex, unknown and changing environment. The robotic system achieves that, by using only its limited physical and computational resources with no/reduced human interventions [7], thanks to its sensing, perceptive, knowledge acquisition, learning, inference, decision-making and acting abilities [8].The autonomy of a mobile manipulator is insured by an integrated system of special software sub-systems with various functions (manipulation, locomotion, vision, planning, etc.). In order to realize the assigned task, the sub-systems need to cooperate with each other and compete for limited resources. Moreover, due to the strong interaction and coupling between the mobile base sub-system and the mounted manipulator(s) sub-system(s), a proper coordination is needed [1]. Thus, a high performance control system is required to make these sub-systems work harmoniously. This constitutes the downside of such robots (more complex modeling and control) [9].The purpose of this paper is to present our ongoing efforts toward the development of a generic distributed fault-tolerant multi-agent framework for autonomous control of mobile manipulators. The proposed scheme assigns a reactive agent (Joint agent) to control each articulation of the manipulator, a hybrid agent (Mobile base agent) to control the mobile base, and a Supervisory agent to coordinate and synchronize the work of all the aforementioned agents. Each Control agent, i.e. Joints agents and Mobile base agent, makes a virtual movement (Simulation-Verification technique), in all possible directions with different steps (Joint step, Base Translation step, Base Rotation step), locally and independently from the other agents.For the validation of the proposed multi-agent control approach, we focus on the reaching task, which involves computing a trajectory for the mobile manipulator to move its end-effector from its initial position to a goal position (imposed Target). Throughout this movement, the Control agents compute an Objective function (fObj) consisting of the distance between the current position of the end-effector and that of the imposed Target. The retained movement, of each agent, is that which optimizes fObj. Simulation results are given via different reaching tasks executed by RobuTER/ULM with and without considering unexpected breakdowns of some articulations or failure of the mobile base.The main contributions of this work are summarized as follows. First, our approach works in 3D environments with high dof mobile manipulators. Second, it is generic in the sense that we just need to modify the Direct Kinematic Model (DKM) and to associate the required number of agents to adapt the proposed approach to a different robot’ structure. Third, its accuracy is similar to that of classical approaches (Section 2.1) while needing only simple geometric formulas. Complex mathematical models, especially Inverse Kinematic Model (IKM), do not have to be computed. Finally, the proposed strategy is fault-tolerant to unexpected breakdowns of the robot without needing any specific treatment to handle the failure. If an articulation of the manipulator or the mobile base breaks down, the control system will be able to provide a good alternative solution.The rest of the paper is organized as follows. Section 2 gives a brief summary of the various control approaches for autonomous mobile manipulators. Section 3 describes our proposed multi-agent control scheme. Section 4 describes the RobuTER/ULM mobile manipulator which is used in our case study, the implementation tool and the considered validation scenarios. Section 5 is devoted to the determination of the appropriate step sizes for the search of the optimal solution. Section 6 presents and discusses the obtained simulation results.One of the most challenging problems in mobile manipulators research field is to develop accurate control architectures for the whole system (mobile base and manipulator(s)). Different approaches have been proposed in the literature. They can be divided into two main classes (i) Traditional/Classical control approaches and (ii) Multi-agent control approaches[2,10].The first class of approaches is based on the study of the mathematical models of the mechanical structures of both the manipulator(s) and the mobile base [3,11,12]. Controlling such a robot consists of computing the motion of the manipulator(s) joints and that of the mobile base. For this aim, the study of DKM and IKM of the robot is required [13]. These approaches produce good and accurate results, and offer a fairly exact control for repetitive tasks in controlled and well-known environments (industrial robotics, etc.). In such environments, when the robot is required to repeat a trajectory thousands of times, very complicated computation of these models is done off-line, in most cases, and with the ability to optimize time and/or energy.The methods used for computing DKM represent generic rules, whereas IKM are, apart from special cases, constructed according to the structure of the robot as no effective analytic method has been identified so far [14,15]. Moreover, DKM and IKM do not tolerate any unexpected changes in the mechanical structure of the robot (malfunction of a joint, etc.) without adding a specific mode for failures treatment (soft-computing techniques, etc.) [16]. Another disadvantage is the very important computation time depending on the number of dof of the robot, especially in frequently-changing unknown environments [17].During the last two decades, Multi-agent systems (MAS) have been deeply investigated and have received much attention [18]. They are largely adopted in complex systems and in distributed applications, in particular, those dedicated to control robotic systems such as mobile-robot teams, flexible cells, manipulators, and mobile manipulators. Multi-agent control is necessary when more than one robot is used to execute a task (a group of autonomous vehicles, multi-robot team [19], etc.), when one robot must coordinate the use of its own resources (coordinating the manipulator and the mobile base in a mobile manipulator [20], etc.) or when a robot society functions independently on multiple tasks in a shared environment (applications in unmanned ground/air vehicles [21], etc.). MAS are very suitable to deal with the new software requirements thanks to their properties of decentralization, modularity, autonomy, effectiveness, reliability, reusability of agents for the implementation of other systems and advanced adaptive behaviors.MAS propose a decomposition of the robot control into many small and distinct sub-systems (i.e. agents) [22–24]. Every agent tries to align the position of the end-effector of the robot with that of the imposed target position, without prior knowledge on the actions of the other agents. Consequently, a global behavior can emerge from all these agents working independently to satisfy the desired objective.Multi-agent approaches offer simple solutions and benefit of all the advantages of distributed problem solving. The MAS perspective made it possible to consider the architecture as a compound of simpler modules, which gave an easier way to design the whole system. In addition, the need for heavy mathematical models, IKM and differential-equation solvers, is overcome [22]. Therefore, there is a considerable decrease in design effort and computation time compared to classical approaches. Finally, with such a usage of MAS, the control architecture is flexible enough to be applied to any type of robots (mobile manipulator, fixed-base manipulator, mobile platform).A mobile manipulator being a heterogeneous system, distinct entities are solicited to ensure a modular, yet robust control scheme. The interactions among these entities provide the robot with the required cognitive behaviors to accomplish different tasks. In our proposed MAS, an agent is modeled as a software representing the decision-making process which may interact in specific scenarios [25], solve large and complex problems and cooperate with other agents [26].In Fig. 1, we use a class diagram to show a generalized view for the proposed scheme, in which two main kinds of agents can be distinguished [27]:This kind of agents is intended for the treatment of data issued by the different sensors equipping the robot. These agents can assure the main functionalities related to or used in the control process, such as Vision agent, Robot localization agent, and Moving-target localization agent. However, this list is not exhaustive as the other modules could be implemented progressively.In this paper, we focus mainly on this second type of agents, which are dedicated to the control process itself. We can distinguish two sub-classes within this type of agents:•Control agents: they are involved in the computation of the commands to be sent to the robot (Joints agents and Mobile base agent). Each control agent implements a Simulation-Verification technique in order to optimize, locally and independently from the other agents, the predefined fObj. The final goal consists of bringing the end-effector of the robot as close as possible to the imposed Target.Supervisory agent: it is responsible of the synchronization and the coordination between the Control agents, and of the selection of the fittest choice.Each Control agent receives, from the Supervisory agent, the initial situation of the robot (ConfigurationInitand BaseInit) and the imposed Target which must be reached. The Control agent drives its corresponding mechanical part (either one joint of the manipulator or the mobile base) independently from the other agents, trying to bring the end-effector as close as possible to the Target. Throughout this process, EffectorCurrentis computed by using the DKM of the robot. The DKM of the robot, function of BaseCurrentand ConfigurationCurrent, is computed as follows:(1)EffectorCurrent=DKM(BaseCurrent,ConfigurationCurrent)In the following, we deal with the elementary movements of each Control agent, along with a short description of the corresponding behaviors.Each articulation is controlled by a Joint agent, which allows two possible elementary movements. The following process, illustrated in Fig. 2, is implemented to find the fittest choice [28]:•Joint agent makes a virtual rotation in the positive direction (moveUp) with a given Joint step. The obtained configuration is ConfigurationUp.The agent computes the new value of fObj(fObj_Up) between EffectorUpand Target as shown by (2) where EffectorUp= DKM(BaseCurrent, ConfigurationUp):•The agent repeats these two actions while changing the direction of the rotation (moveDown, ConfigurationDown, EffectorDown, fObj_Down). The summary is shown in Table 1.After comparing the two values of fObj(fObj_Up, fObj_Down) with its current value (fObj_Current), the Joint agent selects the best choice. In some cases, the best choice would be to stay still because neither of the two virtual movements would improve fObj. Subsequently, the selected movement will be sent, as a proposal (fObj_Joint, Configuration_Best), to the Supervisory agent.The diagram of Fig. 3explains the behavior of a Joint agent[28].The environment where the mobile base evolves is considered free of obstacles (i.e. no obstacles avoidance). For the Mobile base agent, we have defined four elementary movements, as presented in Fig. 4[28]:•The Mobile base agent makes a virtual forward movement (moveForward) with a Base Translation step. The obtained situation of the mobile base is BaseFW.The agent computes the new value of fObj(fObj_FW) between EffectorFWand Target as shown previously in (2).The mobile base agent repeats the previous actions while changing every time the nature of its movement. The summary is shown in Table 2.Afterward, the Mobile base agent will choose its local best choice, which will optimize fObjamongst the four elementary movements. Here again, the choice could be to remain in the current situation if it is better than the other four new situations. Finally, the selected choice will be sent, as a proposal (fObj_Base, Base_Best), to the Supervisory agent.The diagram shown in Fig. 5explains the behavior of the Mobile base agent[28].This hybrid agent is responsible of the coordination and synchronization between the entire Control agents (Joints agents and Mobile base agent). After receiving the imposed Target from the human operator, the Supervisory agent verifies its reachability (zT∈[zMin, zMax] where zMinand zMaxare the minimum and maximum reachable heights in the workspace of the robot), respectively. If the Target is not reachable, the agent displays “unreachable Target error” message and terminates the process. Otherwise, it calculates EffectorInitand fObj_Init. After that, the Supervisory agent sends this information along with BaseInitand ConfigurationInitto the Control agents. Then, the Supervisory agent waits for their proposals (as shown previously).Once all the proposals are received, the Supervisory agent chooses the best one (best fObjvalue). The holder of this proposal will expect a Contract message to confirm the selection, and thus to execute the proposed movement.When fObjreaches a predefined optimum value (fObj<ε), the Supervisory agent terminates the process and sends the “Target reached successfully” message. Otherwise, the Supervisory agent reiterates the precedent phases and continues the process until reaching the goal (fObjis optimal).After receiving all the required information, the Control agents will perform, in parallel and independently, their actions in order to choose the best new configurations, each agent according to its fObjdetermined locally. Thereafter, the Supervisory agent will receive the replies sent by the Control agents, i.e., the best new joint configuration chosen by each Joint agent, the new situation of the mobile base chosen by the Mobile base agent and their best local objective functions (Configuration_Besti, fObj_Jointi(i =1…dof), Base_Best, fObj_Base). Next, the Supervisory agent selects the best proposal (minimizing fObj) and sends a Contract message to the holder in order to confirm the selection, and thus to execute the proposed movement. If the optimum of fObjis reached, the Supervisory agent terminates the process by sending an “End-task (END)” message to all the Control agents and by displaying a “Target reached successfully” message. Otherwise, the Supervisory agent sends the chosen values to be applied on the mobile manipulator. This process continues until reaching the goal.The diagram shown in Fig. 6describes the behavior of the Supervisory agent [28].The interaction between the system agents is implemented via a messages exchange protocol based on the well-known Contract-net protocol[29]. The sequence diagram shown in Fig. 7gives a global vision of the whole interactions among the Control agents (Joints agents, Mobile base agent), the Supervisory agent, the Virtual robot and the Human operator. The most important messages are defined as follows [27]:•INFORM: it is sent by the Supervisory agent to all the active Control agents at the beginning of each iteration. This message contains the current situation of the mobile base (BaseCurrent), the current configuration of the manipulator (ConfigurationCurrent) and the current value of the objective function (fObj_Current).CFP (Call For Proposal): this message, which is sent just after the precedent message by the Supervisory agent, contains the position of the imposed Target. However, in the case of a stationary Target, this message can be sent just once at the beginning of the control process.PROPOSE: following the reception of a CFP message, this message, is sent by each Control agent to the Supervisory agent. It comprises the best local proposition of the Control agent (fObj_Joint, Configuration_Best/fObj_Base, Base_Best).ACCEPT_PROPOSAL/REJECT_PROPOSAL: after receiving all the proposals from the Control agents (PROPOSE messages), the Supervisory agent selects the best choice and sends an ACCEPT_PROPOSAL message to the agent holding this proposition. All the other Control agents will receive a REJECT_PROPOSAL message.ACK: following the reception and the execution of the best selected movement by a Control agent, an ACK message (acknowledgment) is sent to the Supervisory agent.Fault tolerance means the ability of the robot to carry out the reaching task despite any failure that could happen to the joints of its manipulator or its mobile base during the execution of the assigned task.For the proposed multi-agent control system and in case of a breakdown of some articulations of the manipulator or the mobile base, i.e. some Control agents breakdown, the other Control agents, still functional controlling the other joints of the manipulator or the mobile base, are able to take over, recover the unexpected malfunction and improve the objective function without needing any particular recovery technique or modification in the initial control process. Consequently, the proposed approach is fault-tolerant and could provide a good alternative solution even in presence of severe faults. Thus, it is guaranteeing minimal and acceptable behavior which could lead the end-effector near the imposed Target. More details are given in Sections 6.2.2.1 and 6.2.2.2.In the following sections, the proposed approach will be validated using the RobuTER/ULM mobile manipulator under different simulation scenarios. The main results will be presented, discussed and compared to other results previously obtained in [30] with the same robot using a different technique.RobuTER/ULM is composed of a rectangular mobile base on which a manipulator is mounted [30]. The mobile base (RobuTER) has two driving wheels ensuring its mobility and two free wheels to maintain its stability. The manipulator is a six-dof ultra-light manipulator (ULM) with two-finger electrical gripper. All of the joints of the ULM manipulator are rotatable.We have applied the proposed control system to the characteristics of our experimental robotic platform. Fig. 8presents a global view for the control structure of RobuTER/ULM. The architecture involves a set of eight agents [28]:•Six reactive Joint agents are assigned to control the six-dof ULM manipulator.One hybrid Mobile base agent to control the RobuTER mobile base.One hybrid Supervisory agent to coordinate and synchronize the seven aforementioned agents.In what follows, the objective of each agent (fObj) is to minimize the Euclidean distance between the current position of the end-effector EffectorCurrent(xE, yE, zE)Currentand that of the imposed Target(xT, yT, zT).JADE (Java Agent DEvelopment Framework) [31] has been used as an implementation framework of the proposed control architecture. The main reason for this selection was the fact that JADE is one of the best modern agent environments. JADE is FIPA compliant [32] and runs on a variety of operating systems including Windows and Linux. Moreover, this agent open source platform [33] provides basic middleware-layer functionalities which simplify the realization of distributed applications using the software agent abstraction [31,34]. A considerable merit of JADE is that it implements this abstraction over a well-known object-oriented language, JAVA, providing a simple and user-friendly Application Programming Interface (API).Different simulation scenarios have been considered in this work. They are intended to tune the performances of our approach under different Target positions and different initial situations. Each reaching task consists of bringing the end-effector as close as possible to the imposed Target. The parameters that define each reaching task are as follows:•The predefined Target(xT, yT, zT).The initial situation of the mobile base BaseInit(xB, yB, θB)Init.The initial configuration of the manipulator ConfigurationInit(q1, q2, q3, q4, q5, q6)Init.For validation purposes, we have chosen five tasks as presented in Table 3. The distances are given in millimeters and the angles in degrees.The next section illustrates the methodology used in order to determine the best step sizes for the Control agents of the system. These predefined step sizes will be the input of the procedure seeking to find the optimal solution.In this paper, we have considered a predefined selection of the step sizes: {Joint step, Base Translation step, Base Rotation step}. Our goal in this section is to try to find the best triplet for these steps.After many preliminary tests have been carried out on numerous different tasks, we have fixed, for each of the three steps, the initial search interval [1,10]. After further testing within this initial search interval, we have finally retained, for each of the three steps, the following three enumerable values: 1, 5 and 10. This yields then 3×3×3=27 possible triplets which need to be tested. Examples of such triplets are {1,1,1}, {1,1,5}, {1,1,10} and {10,10,10}.For the evaluation of each triplet, we have considered two criteria: (i) the final value of fObj, along with (ii) the number of iterations. These two criteria will be evaluated for each of the five previous tasks in three different cases: (i) no breakdown (first case), (ii) breakdown of joints 3 and 4 of the manipulator (second case) and (iii) the failure of the mobile base (third case).These prior validation tasks have been evaluated without considering the breakdown (first case). Fig. 9presents a summary histogram for all the obtained simulation results of each task with the 27 different triplets [27].For enhancing further our selection of the best triplet, the two other cases have been considered. However, the third case is not useful for determining the best triplet because all the scenarios give almost identical results.Fig. 10presents a summary histogram for the obtained results of each task with all the considered triplets for the second case [27].Depending on fObj, we have ranked the five best results in the two cases (without breakdown and with joints breakdown) for all the five tasks. The collected data allowed us to draw different tables in order to determine the best triplet. Each case emphasizes the number of best results obtained using the corresponding triplet steps. The best triplet is the one generating the maximum best solutions for all the considered tasks.Table 4gives the best Joint step (in degrees). It is obvious, from this table, that the best triplet class is {1,∗,∗}, i.e. Joint step = 1°.Table 5gives the best Base Translation step (in millimeters). In this case, we have selected two distinct classes of triplets: {∗,1,∗} and {∗,5,∗}.Table 6gives the best Base Rotation step (in degrees). In this case, the obvious choice is the class {∗,∗,1}∗}, i.e. Base Rotation step = 1°.In order to define the best triplet, four possibilities have been selected {1,∗,∗}, {∗,1,∗}, {∗,5,∗} and {∗,∗,1}. The crossing between them yields two candidate triplets: {1,1,1} and {1,5,1}.In order to separate these two candidates, we have considered the other criterion (number of iterations). Table 7shows that the triplet {1,1,1} requires a very high number of iterations and, consequently, an important execution time comparatively to the other triplet {1,5,1}. Therefore, this latter has been selected as the best triplet [27].In this section, we will present simulation results obtained from the validation scenarios described above (Table 3) by using the RobuTER/ULM mobile manipulator.In order to provide a better comparison support for the proposed multi-agent control approach, all the parameters of the utilized mobile manipulators and the considered reaching tasks have to be identical whether for the pseudo-classical approach or for the proposed multi-agent approach. Unfortunately, the lack of validation benchmarks in the literature (same parameters of mobile manipulators and, same initial and final conditions of considered reaching tasks) has led us to establish our own validation tasks as shown in Table 3.The prior tasks (Table 3) have been previously carried out in [30] (obtained results are shown in Table 8) using the pseudo-classical control approach proposed in [35]. This approach consists principally of three agents (i) a Supervisory Agent, (ii) a Mobile Robot Agent and (iii) a Manipulator Robot Agent. The control process is performed in three sequential phases:•Supervisory Agent receives the reaching task to be carried out by the robot, and decides on its feasibility according to the status and the availability of all the required equipment and resources (sensors, mobile base, manipulator, etc.). If the assigned task is feasible, the Supervisory Agent distributes it to the other agents for execution.Mobile Robot Agent calculates the final situation of the mobile base (BaseFin) in the vicinity of the imposed Target in case where this latter does not belong to the current workspace of the carried manipulator. After that, this agent controls the motion of the mobile base towards the calculated situation. Arriving to BaseFin, this agent informs the Manipulator Robot Agent about its final situation.Manipulator Robot Agent calculates, subsequently, the final configuration for the manipulator (ConfigurationFin) basing on BaseFin, via the IKM of the manipulator, in order to reach the imposed Target. Finally, the Manipulator Robot Agent controls the motion of the manipulator until reaching ConfigurationFin.In the rest of the paper, the selected triplet simulation parameters (Joint step, Base Translation step, Base Rotation step), for the execution of the different tasks by the robot, are given in Table 9.In the first case, the mobile base and all the articulations of the manipulator are considered as functional (no breakdown). The obtained results are shown in Table 10:In order to demonstrate that the proposed multi-agent control architecture is designed to be fault-tolerant, the system reaction in case of failures is shown.Suppose that the breakdown of the joints 3 and 4 appears at time t =0. The breakdowns are at q3 =q3Init=0 and q4 =q4Init=0. The results are given in Table 11.Other scenarios are shown to test the reaction of the system in fault cases. Assume that the breakdown of the mobile base occurs at time t =0. The breakdown is at Base(xB, yB, θB)=BaseInit(xB, yB, θB)Init=(0, 0, 0). Table 12gives the results:The following Figs. 11–13illustrate the variations of some manipulator joints (Q2,…,Q5), the trajectories of the mobile base and the evolutions of the objective functions for the first, second and the third tasks and for all the cases (no breakdown, breakdown of the joints 3 and 4 of the manipulator, breakdown of the mobile base):•The red lines denote the obtained results in normal case (first case).The blue lines represent the results in case of a breakdown of some joints of the manipulator (second case).The green curves represent the obtained results in case of the mobile base failure (third case).Fig. 11 shows the results for the first task while moving to Target (Target belongs to the current workspace of the carried manipulator).Fig. 12 illustrates the main results obtained for the second task while moving the robot end-effector to the imposed Target. Here, Target is outside of the current robot workspace.Fig. 13 shows results obtained for the third task while moving to Target. In this task, the Target is outside of the current manipulator workspace too.

@&#CONCLUSIONS@&#
