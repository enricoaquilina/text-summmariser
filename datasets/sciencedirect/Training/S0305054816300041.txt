@&#MAIN-TITLE@&#
Mean-univariate GARCH VaR portfolio optimization: Actual portfolio approach

@&#HIGHLIGHTS@&#
We introduce mean-univariate GARCH VaR actual portfolio optimization in accordance with Basel Capital Accords.We develop optimization software that combines NSGA-II algorithm and R statistical software.Computational results show that our approach provides better mean-univariate GARCH VaR trade-offs of actual portfolios in comparison to benchmarks estimated by analytical methods.Empirical tests cover both low and high volatility samples.

@&#KEYPHRASES@&#
Portfolio optimization,Actual portfolios,Value at Risk,GARCH,NSGA-II,

@&#ABSTRACT@&#
In accordance with Basel Capital Accords, the Capital Requirements (CR) for market risk exposure of banks is a nonlinear function of Value-at-Risk (VaR). Importantly, the CR is calculated based on a bank’s actual portfolio, i.e. the portfolio represented by its current holdings. To tackle mean-VaR portfolio optimization within the actual portfolio framework (APF), we propose a novel mean-VaR optimization method where VaR is estimated using a univariate Generalized AutoRegressive Conditional Heteroscedasticity (GARCH) volatility model. The optimization was performed by employing a Nondominated Sorting Genetic Algorithm (NSGA-II). On a sample of 40 large US stocks, our procedure provided superior mean-VaR trade-offs compared to those obtained from applying more customary mean-multivariate GARCH and historical VaR models. The results hold true in both low and high volatility samples.

@&#INTRODUCTION@&#
Value-at-Risk (VaR) is defined as the loss associated with the low (typically first or fifth) percentile of the return distribution.11For classification and comparison of risk measures see [1,2], among others.The Basel II Capital Accord codifies VaR as the de-facto industry standard for the banking and insurance industries alike (see, BIS [3–5]). In particular, for the market risk exposure of banks, a bank’s internal VaR estimates corresponding to the actual portfolio, i.e. the portfolio represented by its current holdings, translate directly into the regulatory capital charge (see [6]). Motivated by this regulatory feature, we utilized the actual portfolio framework (APF) to determine a set of portfolios characterized by the optimal trade-off between the expected return and VaR (i.e. Pareto-optimal frontier). We further proposed a mean-univariate Generalized AutoRegressive Conditional Heteroscedasticity (GARCH) VaR portfolio optimization model. We assumed that portfolio returns, standardized by time varying volatility, have a conditional Student’s t distribution, while conditional variance follows а GARCH (1, 1) process.22GARCH was introduced in Engle [7] and GARCH (1, 1) in Bollerslev [8].The Student’s t distribution efficiently captures the fat tails of standardized asset returns (see [9,10]) whilst the GARCH model addresses issues related to volatility clustering observed in the data.33For more on superiority of GARCH VaR compared to historical VaR see [11–15], among others.To the best of our knowledge, this is the first paper that studies mean-VaR portfolio optimization using the actual portfolio approach and also the first paper that uses the univariate GARCH VaR model in this context.Previous studies on mean-VaR optimization implicitly assumed fixed weights (i.e. fractions of assets) over the observed time period.44For example, [16–21].Since prices change over time, maintaining the fixed portfolio weights (FWA) requires frequent trading and leads to changes in the number of shares of each asset in a portfolio. Regulatory capital charges, however, are determined by the VaR of an actual portfolio where the number of shares of an asset (rather than its weighting) is fixed over the observed period. It is, therefore, APF, rather than FWA, that is more relevant for asset managers facing regulatory VaR limits. To illustrate the effectiveness of our APF approach and univariate GARCH model, we compared our results with two benchmarks. Our first benchmark is the mean-historical VaR approach developed in Rockafellar and Uryasev [20,21] and Krokhmal et al. [22]. These authors mapped conditional VaR (CVaR) optimization into a linear programming problem and argued that the mean-CVaR efficient frontier provided near-optimal solutions in the context of the mean-historical VaR trade-off.55CVaR (or Expected Shortfall, ES) is the expected loss, conditional that loss is higher than VaR. Thus, CVaR and VaR are closely related risk measures. The LP model is widely used in CVaR and VaR optimization literature (see [23–25], among others).We referred to this benchmark as the Linear Programming (LP) model. The second point of comparison for our approach is the mean-multivariate GARCH VaR optimization that can be mapped into the Quadratic Programming (QP) problem (see [26]).Use of the univariate GARCH approach for VaR modeling, however, makes the mean-VaR optimization problem rather complex. Previous literature documented that Multi-Objective Evolutionary Algorithms (MOEA) could reliably and efficiently be applied in complex portfolio optimization problems.66For comprehensive surveys of MOEA applications in portfolio optimization, see [27–30].For example, Anagnostopoulos and Mamanis [31] studied the effectiveness of different MOEA (e.g. Nondominated Sorting Genetic Algorithm (NSGA-II), Strength Pareto Evolutionary Algorithm (SPEA2), Pareto Envelope-based Selection Algorithm (PESA), etc.) in solving various complex mean-variance optimization problems. They reported the best NSGA-II and SPEA2 average performance in terms of hypervolume indicators, while PESA performed best in terms of the proximity to the Pareto-optimal frontier. The same authors (see [32]) also examined the mean-variance, mean-ES, and mean-VaR optimization problem with quantity, cardinality and class constraints. They showed that NSGA-II, SPEA2 and PESA performed efficiently and their performance was independent of the risk measure used.77Anagnostopoulos and Mamanis also showed that NSGA-II, SPEA2, and PESA provide a good approximation of risk-return trade-offs in a 3 objectives optimization problem (see [33]).Deb et al. [34] reported NSGA-II’s advantages over the Pareto Archived Evolutionary Strategy (PAES) and SPEA. Deb et al. [35] developed a hybrid NSGA-II procedure for handling a mean-variance portfolio optimization problem with the cardinality constraint and lower and upper bounds as investment criteria. The authors provided evidence of NSGA-II’s superiority over classical quadratic programming approaches. Branke et al. [36] considered the mean-variance problem with the maximum exposure constraint. The authors generated mean-variance Pareto-optimal frontiers by using a hybrid algorithm that combined NSGA-II with the critical line algorithm.In this study we used the NSGA-II algorithm. Our choice was motivated by the above studies, whose results highlighted the advantages of NSGA-II in tackling complex portfolio optimization problems.88NSGA-II algorithm is also the most widely used MOEA in portfolio optimization literature. According to the number of studies reviewed in [30], NSGA-II was used in twice as many studies compared to second most popular method (SPEA2).NSGA-II was first introduced by Deb et al. [34] and subsequently developed in Deb et al. [37]. Recently, a new version of NSGA (NSGA-III) was developed by Deb and Jain [38] and also Jain and Deb [39]. NSGA-III is better suited to many-objective optimization problems (three and more objectives) and offers the ability to define the desired part of a solution space defined by reference points.99The number of the Pareto optimal solutions could also be reduced by combination of NSGA-II with Data Envelopment Analysis (see [40]).Here, we prefer NSGA-II to NSGA-III, since we consider only two objectives and are interested in the entire Pareto-optimal frontier. Knowledge of the entire frontier of the risk-return trade-offs is particularly useful for asset managers in banks and other financial institutions in order to comply with different in-house and regulatory requirements.For our numerical tests we selected 40 of the largest US stocks in the Standard and Poor’s stock market index (S&P 100) for which sufficient data was available. First, we determined the mean-historical VaR Pareto-optimal frontier, in the APF framework, using the NSGA-II algorithm and compared it to the LP Pareto optimal frontier. The comparison showed that NSGA-II produced better mean-historical VaR trade-offs compared to the LP optimization approach, in both Low and High volatility samples. Second, we compared our mean-univariate GARCH VaR Pareto-optimal frontier with the frontiers obtained by the two benchmarks (mean-historical VaR and mean-multivariate GARCH VaR). In comparison with the two benchmarks, the proposed univariate GARCH VaR procedure provided actual portfolios with better mean-univariate GARCH VaR trade-offs, in both Low and High volatility samples.Previous portfolio optimization studies typically neglect the differences between using portfolios with fixed weights and portfolios with fixed holdings of assets. We contribute to portfolio optimization literature by addressing recent real world regulatory changes which impose VaR based on actual portfolio holdings. The rare MOEA portfolio optimization studies that measured risk by using VaR tend to use historical rather than analytical VaR (see [33,41–43]).1010Only 4.27% of MOEA studies use VaR as one of the objectives in the portfolio optimization problem (see [27]).We therefore also contribute to MOEA literature by examining the mean-VaR optimization problem with analytical univariate GARCH VaR instead of historical VAR.The remainder of this paper is organized as follows. In Section 2 we introduce historical and GARCH VaR models. The optimization problem is introduced in Section 3. MOAE and implementation details are discussed in Section 4. Section 5 contains sample descriptive statistics. Results of mean-historical VaR optimization are presented in Section 6. Results of our univariate and multivariate mean-GARCH VaR optimization are presented and discussed in Section 7. We conclude in Section 8. All acronyms and notations are listed in Appendix.For a given portfolio, significance level α and time horizon h, portfolio VaR is a loss that will be exceeded, on average, only α×100 percent of the time. If expressed in terms of portfolio value, VaR is the α-quantile of profit and loss distribution (cash VaR), while if expressed in terms of portfolio return r, it is the α-quantile of the return distribution (relative VaR or, simply, VaR). We focused on the α-quantile of the return distribution. Consider time horizon of h=1 day and return rαsuch that probability ρ(r<rα)=α. In that case, 1-day VaR with significance level α is(1)VaRα=−rαThe minus sign is needed since VaR is defined as a loss. Given the cumulative distribution function of returns F(α), the α-quantile is calculated as rα=F−1(α). The main reason for the popularity of this method is ease of its implementation and the fact that it makes no assumptions about the parametric form of return distributions. On the other hand, the historical VaR often slowly reacts to abrupt changes in market conditions (see [11]).A popular alternative to historical simulation is provided by analytical (or parametric) VaR models. These models take a stand on the shape of the return distribution and capture the following stylized facts about asset returns (see [9]). First, asset returns are difficult to predict based on their past realizations. Second, volatility of daily returns dominates their mean. Third, unlike returns, the variance of daily returns tends to exhibit clustering over time. Namely, days with highly volatile returns are likely followed by days with highly volatile returns and vice versa. Fourth, after periods of high or low asset volatility, volatility tends to return toward a stable long run level. Fifth, even though asset returns are often modeled using a normal distribution, an unconditional return distribution usually has much heavier tails than predicted by a normal distribution.1111Although this is partially rectified when returns are standardized by time-varying volatility, some residual non-normality still remains.Using the first two conditional moments of distribution, the return can be presented in the form:(2)rt=μt+σtztwhere rtis the return at time t, μtis the conditional mean, σtis conditional volatility of the return, and ztis the residual (innovation term) of the process. It is assumed that ztare independently and identically distributed and follow a known theoretical distribution D with zero mean and unit variance D (0, 1).To specify the analytical VaR model we specified the volatility updating model, as well as the shape of the conditional return distribution D (0, 1). A commonly applied class of conditional volatility models that captures all of the above stylized facts of returns is the GARCH model.1212GARCH process was first applied to VaR modeling in [14].In estimating GARCH parameters on daily data, we have taken into account that the conditional mean is dominated by the standard deviation of returns (see [9,15,44]).1313Alternatively, one can apply the same model to mean-adjusted returns.This implies:(3)rt≈σtztWe took into account non-normality of standardized returns by assuming they follow a standardized Student’s t distribution (with zero mean and unit variance) with d degrees of freedom t (d). The degree of freedom parameter is an additional parameter estimated jointly with the other model parameters using Maximum Likelihood Estimation (MLE) method. The 1-day ahead analytical VaR estimate with significance level α, calculated at time t, is obtained as follows:(4)VaRt+1α=−σt+1tα−1(d)where σt+1 is the 1-day ahead conditional volatility estimate at time t obtained by applying the proposed model, d are degrees of freedom of the estimated Student’s t distribution of standardized portfolio returns, and tα−1(d) is α-quantile of the standardized Student’s t distribution with d degrees of freedom.Conditional portfolio volatility can be modeled directly using the time series of portfolio returns (we referred to this method as the Univariate GARCH approach). Alternatively, one can estimate conditional portfolio volatility using the conditional variance–covariance matrix estimated via the multivariate GARCH model. We referred to this method as the multivariate GARCH approach.Consider the (univariate) time series of portfolio returns and denote byrtthe portfolio return at time t. The simplest and by far the most popular GARCH model of conditional volatility, commonly referred to as GARCH (1, 1), has the following form (see [8]):(5)σt+12=ω+θrt2+βσt2Here, θ, β>0 and θ+β<1.1414The second condition assures stationarity of the conditional volatility process.Thus, the univariate GARCH VaR is(6)VaRt+1α=−(ω+θrt2+βσt2)1/2tα−1(d)In a multivariate GARCH modeling framework, the 1-day ahead portfolio conditional volatility can be estimated as a function of the returns on individual assets (from the opportunity set) as follows:1515See, for example, [26,45].(7)σt+12=wt′Ht+1wtwhere Ht+1is N×N conditional variance–covariance matrix of returns of individual assets, and wtis the vector of portfolio weights at time t.1616Boldface denotes matrices and vectors. Matrices are in upper case, whereas vectors are in lower case.Importantly, the multivariate GARCH implicitly assumes a fixed portfolio weights approach (FWA).1717As discussed in [46], the fixed weights assumption further implies continuous portfolio rebalancing.The portfolio weights are thus fixed atwi,t=wi,Tfor all,t≤T, where T denotes optimization date. Thus, the multivariate GARCH VaR is(8)VaRt+1α=−(w′Ht+1w)1/2tα−1(d)The problem we are trying to solve has the following general form:(9)minWVaRt+1α=−(ω+θrT2+βσT2)1/2tα−1(d)(10)maxWE(r)(11)subjectto∑i=1Nwi=1(12)0≤wi≤1,i=1,...,NHere, w denotes the vector of portfolio weights at optimization date t=T, its components are wi, r is the return on the portfolio,VaRT+1αdenotes the portfolio risk measure that we try to minimize, and E(r) is the expected return on the portfolio. tα−1(d) here refers to a quantile of a univariate Student’s t distribution with d degrees of freedom. Eq. (11) describes the standard budget constraint which requires that weights sum up to 1. Eq. (12) states that no short sales are allowed.1818Short sale prohibition is a common constraint imposed on large institutional investors such as mutual or pension funds.To calculate actual portfolio VaR and the corresponding expected return, a time series of portfolio returns with fixed asset holdings is needed. We determined asset holdings at the optimization date by adopting an arbitrary dollar portfolio value (set, without loss of generality, to 1). Thus, we assumed that, at optimization date t=Т, dollar portfolio value Vp,t=T=1. Portfolio holdings niat time T were determined based on weights at t=T:(13)ni=wiVp,t=TPi,t=T=wiPi,t=THere Pi,tdenotes the price of shares in company i at time t. In the actual portfolio approach, holdings are held fixed over time. The actual portfolio return at timet≤Tis, therefore, determined as follows:(14)rt=Vp,tVp,t−1−1=∑i=1NniPi,t∑i=1NniPi,t−1−1Vp,tdenotes the dollar portfolio value at time t. The actual portfolio mean-VaR optimization problem simply means that we used Eq. (14) when determining input returns for the above optimization problem.In the actual portfolio approach, portfolio weights at timet≤T, are given by the expression:(15)wi,t=niPi,t∑i=1NniPi,tEqs. (14) and (15) imply that(16)rt=∑i=1Nwi,t−1ri,twhere ri,tis simple return on asset i at time t.The portfolio optimization problem (Eqs. (9–12)) can be specified as follows:(17)minwVaRT+1α=−(w′HT+1w)1/2tα−1(d)(18)subjecttow′μ=r¯(19)subjectto∑i=1Nwi=1(20)0≤wi≤1,i=1,...,Nwhere HT+1 denotes the conditional variance–covariance matrix of individual returns estimated at the time of optimization t=Т, μ denotes vector of expected returns of individual assets, andr¯denotes the expected portfolio return as a weighted average of constituents’ expected returns.A portfolio return for an arbitrary,t≤T, is given by the expression:(21)rt=∑i=1Nwi,Tri,tQuantile tα−1(d) refers to a quantile of a multivariate Student’s t distribution with d degrees of freedom. Here, d does not depend on a portfolio composition. Namely, d and, thus, quantile tα−1(d) depend solely on the choice of constituent return series and not on the way in which they are combined into a particular portfolio. HT+1 and d are obtained using the Dynamic Conditional Correlation (DCC) model of Engle [47].1919We used ‘rmgarch’ package [48] within software R [49]. For fitting GARCH model we used ‘dccfit’ method. For the 1-day ahead estimation of conditional covariance matrix we used ‘dccforecast’ method.DCC decomposes conditional variance–covariance matrix Ht+1 into conditional standard deviations and correlations, that is:(22)Ht+1=Dt+1Rt+1Dt+1.where Dt+1=diag(σ1,t+1,...,σN,t+1). Here diag (⁎) is the operator transforming a N×1 vector into a N×N diagonal matrix. We assume that conditional variances σ2i,t+1, i=1,..., N, follow a standard univariate GARCH (1,1) model.Matrix Rt+1 is a symmetric positive definite conditional correlation matrix defined as(23)Rt+1=diag(Qt+1)−1/2Qt+1diag(Qt+1)−1/2where Qt+1 is a proxy process which is assumed to follow GARCH-type dynamics:(24)Qt+1=(1−θ−β)Q¯+θztztT+βQtVector zt=(z1,t,...,zN,t)T has elements zi,t=ri,t/σi,t(standardized unexpected returns or innovations),Q¯is the N×N covariance matrix of ztand θ and β are non-negative scalar parameters satisfying θ+β<1.Since tα−1(d) is constant, the optimization problem (Eq. (17)) is equivalent to a problem represented by quadratic programming formulation (referred to as QP model):2020This problem is of the standard Markowitz type (see [50]) with added short sales constraints.(25)minww′HT+1wIt should be emphasized that quantile tα−1(d) in this approach is constant and therefore not portfolio specific. Thus, the multivariate GARCH approach is more restrictive compared to the univariate GARCH approach where the degrees of freedom of the estimated standardized Student’s t distribution (and therefore quantile tα−1(d)) were portfolio specific.i)Short sales are not allowed (Eqs. (12) and (21));The standard budget constraint which requires that weights must sum up to 1 (Eqs. (11) and (20)).i)Portfolio returns, standardized by time varying volatility, follow a conditional standardized Student’s t distribution (with zero mean and unit variance);Conditional variance follows GARCH (1, 1) process,σt+12=ω+θrt2+βσt2(Eq. (5));In estimating GARCH parameters on daily data, the mean value of daily returns is dominated by the standard deviation of returns and that rt≈σtzt(Eq. (3));At optimization date t=Т, without loss of generality, dollar portfolio value Vp,t=T=1.i)Portfolio weights are fixed over the observed period;Returns of assets from the opportunity set jointly follow a multivariate Student’s t distribution;Qt+1 (Eq. (23)) follows GARCH-type dynamics:Qt+1=(1−θ−β)Q¯+θztztT+βQtIn matrix Dt+1 conditional variance σ2i,t+1 follows a univariate GARCH (1, 1) processEA are efficient stochastic search techniques for solving complex optimization and search problems (e.g., optimization problems with non-differentiable objective functions, large and non-convex solution spaces, complex constraints, etc.) through an emulation of natural selection i.e. survival of the fittest (see [51]). EA begin with a set of randomly generated candidate solutions, referred to as a population. In each of the iterations (i.e. generations) the following processes are performed: (i) Good solutions from the current population are selected and transferred into a set of potential parents (mating pool); (ii) Randomly selected parent solutions are combined (crossover) producing new solutions (offspring solutions); (iii) Some randomly selected offspring solutions are slightly modified (mutation); (iv) Generated offspring solutions constitute the population of the next generation. By performing these processes in each generation (until the termination condition is satisfied) the solutions ”evolve” and become even better in fulfilling the stated objectives.Over the past two decades, significant advances have been made on EA methods to solve multi-objective optimization problems.2121For a detailed introduction to MOEA, see [52].This has led to the creation of multi-objective evolutionary algorithms (MOEA). In general, MOEA address two important issues: (i) How to generate a Pareto-optimal frontier; and (ii) How to provide diversity in alternative solutions (i.e. how to avoid convergence to a single point on the Pareto-optimal frontier). To achieve the first goal, most MOEA implementations use ranking based on the concept of dominance, while different diversity-preserving techniques are employed to achieve the second goal.We directly borrowed the NSGA-II algorithm from Deb et al. [37].2222The algorithm was coded in C# and run on a personal computer with Intel i5 processor and 4GB of RAM.Implementation of NSGA-II involves adopting settings for the solution representation, the population size, the crossover and mutation probabilities and the termination condition. Solution representation depends upon the specific optimization problem. For the model at hand, the solution was defined as a non-negative real-valued vector of portfolio weights at time t=T, that is, the vector of fractions of the total budget invested in individual securities (see Section 4). Population size (the number of candidate portfolios in each generation), was set to 100. The Pareto-optimal frontier was, therefore, approximated with 100 points. The step by step flow chart which presents a schematic view of the proposed portfolio optimization method is shown inFig. 1.In the preparatory phase our software generated and printed a data file (data.csv) with a time series of occurrences of assets under consideration. Next, it generated and printed an R script file (Script.R) with commands for estimation of the univariate GARCH VaR. It then executed the NSGA-II algorithm in the execution phase.2323For more details on the algorithm steps, see [37].For the breeding of an offspring population we used the uniform crossover operator. Two solutions (portfolios) from the current population were randomly selected and were recombined with a predefined crossover probability. If the two solutions undergo recombination, every allele (individual asset weight) is exchanged between the pair of randomly selected solutions with a certain probability, known as the swapping probability, otherwise, the two offspring are simply copies of their parents (see [51]).2424Candidate solutions are also referred to as chromosomes, decision variables are referred to as genes and the values of decision variables are called alleles.In accordance with previous literature, we set the swapping probability to be 0.5.2525See [31–33,51].We applied a uniform mutation operator (uniform replacement). When applying uniform mutation, each allele is selected with a predefined mutation probability and replaced with a realization of a random variable, uniformly distributed in the range defined by the lower and upper domain bounds. The selected crossover and mutation operator ensured that the constraint defined by Eq. (12) was satisfied for each offspring. However, these operators did not ensure satisfaction of the budget constraint (Eq. (11)). Hence, we had to normalize each of the offspring solutions.2626We have done this by dividing each weight by sum of all weights.In order to find the appropriate parameter values for the crossover and mutation probabilities, we performed a series of experiments. The performance was assessed using the ε-indicator, and the hypervolume metric (see [53]). The ε-indicator is a binary performance metric which is used to measure how close the approximation set is to the reference set. As a reference set, the true or the best known Pareto-optimal frontier was used. The ε-indicator determines a minimum value the reference set must be multiplied by in order for every solution in the reference set to become weakly dominated by at least one solution in the approximation set. If the approximation set matches the reference set exactly then the ε-indicator takes the value of one. For this metric, values close to one indicate that the approximation set very closely matches the reference set. The hypervolume indicator was used to measure the diversity of the approximation set. The hypervolume measure quantifies the volume of the objective space dominated by an approximation set. For optimization problems with two objectives, it quantifies the area of the objective space dominated by the approximation set, bounded by a predefined reference point. Thus, for this metric higher values are preferable.To determine the best performing mutation and crossover probability sets, we tested four crossover probabilities (0.7, 0.8, 0.9, 1.0) and five uniform mutation probabilities (0.001, 0.005, 0.01, 0.05, 0.1). The above tests resulted in 20 different configurations for each set of objectives (mean-historical VaR, mean-GARCH VaR) and for each data sample that we used. For each configuration, the algorithm was left to run until 100,000 solutions were generated.The interactions between the NSGA-II algorithm and our statistical analysis were highlighted inFig. 2. For the evaluation of each individual solution portfolio, our software performed the following steps: (i) It generated and printed a file with portfolio weights (weights.csv); (ii) It called software R and executed the R script file (Script.R) created in the preparatory phase. During the execution of the script file, software R used the data file (data.csv) and the solution portfolio weights file (weights.csv) and generated a time series of actual portfolio returns (applying Eqs. (13) and (14)); and (Eqs. (4) and (5)).2727We used ‘rugarch’ package [54] within software R [49]. For fitting GARCH model we used ‘ugarchfit’ method; For the 1-day ahead estimation of conditional volatility we used ‘ugarchforecast’ method.In the case of the mean-historical VaR approach, algorithm execution requires calculating the α quantile of the empirical distribution of 100,000 candidate portfolios. However, in the case of the mean-univariate GARCH VaR approach, the optimization procedure implies calculating the α quantile of the parametric distribution of candidate portfolios. Additional complexity of the univariate GARCH VaR approach stems from the fact that the GARCH parameters for each of 100,000 portfolios were obtained by the MLE method. We ensure that all Pareto-optimal frontiers, obtained using different configurations, include solutions which provide the minimum risk and the maximum return.2828We obtained these solutions and included them into the initial population of each MOEA execution. Maximum return solution was obtained analytically, while minimum risk solution was obtained using single-objective genetic algorithm.For the purposes of this study, we selected 40 constituents of the S&P 100 with the highest market capitalization as of September 6, 2013.2929Initially, 43 stocks were considered of which 3 were discarded (tickers: PM, V, KFT) due to incomplete data during the sample period.We observed the constituents’ time series of 1421 returns in the period January 15, 2008–September 6, 2013. We used a rolling window of 1000 returns for VaR estimation. For each day within the rolling estimation period of 421 days (January 4, 2012–September 6, 2013) we estimated 1-day ahead daily volatility of the S&P 100 time series. The volatilities were estimated using the univariate GARCH (1, 1) model. Standardized returns were assumed to have a standardized t-distribution. GARCH volatility estimations of the S&P 100 index were based on a rolling window of 1000 daily returns. Maximum volatility of 0.01294 (20.5% in annual terms) was determined on June 29, 2012. Minimum volatility of 0.00583 (9.3% in annual terms) was determined on July 31, 2013.3030We annualize volatility using square root of time assuming 252 trading days per annum.From the chosen sample of 40 stocks we created two samples with 1001 daily prices: (i) First, ending on the maximum volatility date (referred to as the High volatility sample); and (ii) Second, ending on the minimum volatility date (referred to as the Low volatility sample). All VaR values in this paper correspond to a significance level of 0.01, with a time horizon of one day.Table 1 presents a summary statistics of the time series comprising the Low and High volatility samples.Rockafellar and Uryasev [20,21] and Krokhmal et al. [22] argue that the mean-CVaR efficient frontier generated by the LP model also provides near-optimal solutions in the context of mean-historical VaR optimization. We tested this assertion in an actual portfolio framework. Namely, for each portfolio belonging to the mean-CVaR Pareto-optimal frontier generated by a LP (FWA approach), we created a time series of actual portfolio returns (applying Eqs. (13) and (14)), calculated the corresponding 1% historical VaR and expected return, and represented the portfolios in the actual portfolio mean-VaR plane. In this way we generated an approximate Pareto-optimal frontier corresponding to the LP solution. Next, we determined the mean-historical VaR Pareto-optimal frontier (in the actual portfolio framework directly) using the NSGA-II optimization approach (seeFig. 3). Fig. 3 shows that the NSGA-II frontiers dominate the LP frontiers, especially in the High volatility sample.Best performing NSGA-II mean-historical VaR approximate of the Pareto-optimal set was selected based on the hypervolume metric. To compare the NSGA-II mean-historical VaR Pareto-optimal frontier to the LP Pareto-optimal set, we used the ε-indicator. As a reference set, we adopted the NSGA-II mean-historical VaR Pareto-optimal frontier. The comparison is presented inTable 2. The values of the hypervolume parameter and reference points, together with the ε-indicator, were for the best performing NSGA-II approximates of the mean-VaR Pareto-optimal frontier.The values for the ε-indicator confirm that the NSGA-II optimization approach provides better mean-historical VaR trade-offs of actual portfolios compared to the LP solutions in both the High and Low volatility samples. The relatively higher value of the ε-indicator (1.1526) suggests that NSGA-II performed particularly well during the High volatility period.In this section we compared the Pareto-optimal frontiers for: (i) the mean-univariate GARCH VaR (or univariate GARCH for short); (ii) the mean-multivariate GARCH VaR (benchmark 1); and (iii) the mean-historical VaR (benchmark 2).3131As presented in Fig. 3, the NSGA-II method provided superior actual portfolio mean- historical VaR trade-offs compared to the LP model, in both samples. Consequently, we adopted the NSGA-II mean-historical VaR portfolios as benchmark 2.In order to obtain solutions in the actual portfolio framework for both benchmark portfolio solutions (represented by the corresponding vector of weights w), we generated a times series of portfolio returns. The time series of portfolio returns was generated by employing Eqs. (13) and (14); and (Eqs. (4) and (5)).3232During this process some of benchmark 1 and benchmark 2 portfolio solutions became dominated and thus have been discarded from the approximation set.The results are shown inFig. 4. The Pareto-optimal frontiers, for actual portfolios, are for the two volatility regimes when 1%VaR was estimated using the univariate GARCH model. Triangle markers represent the univariate GARCH frontier (obtained via NSGA-II), while filled dots represent benchmark 1 solutions and empty dots represent benchmark 2 solutions.The differences are particularly prominent in the area of low returns (and low risk). In this segment of the Pareto-optimal set, thus, the opportunities for improving the mean-VaR trade-off through optimization are the greatest. It is worth noting that this segment of the Pareto-optimal set is associated with most diversified portfolios. In contrast, with higher expected return values, the cardinality of efficient portfolios is reduced (the highest return portfolio, by construction, corresponds to a single asset).To further compare the univariate GARCH Pareto-optimal frontier to the respective benchmarks, we used the ε-indicator. As a reference set, we adopted the univariate GARCH frontier.Table 3 presents the values of the hypervolume parameter and reference points for the best performing NSGA-II mean-univariate GARCH VaR approximate Pareto-optimal sets. The table also shows ε-indicators corresponding to the respective benchmarks in the Low and High volatility samples.The above presented ε-indicators confirm superiority of the univariate GARCH VaR optimization approach. The advantages of the univariate GARCH VaR optimization approach are particularly pronounced in the Low volatility sample. Measured by the ε-indicators, the mean-historical VaR approach provides the worst approximations out of the three approaches. The above result is particularly important given that approximately 75% of banks tend to use the historical VaR models for portfolio optimization (see [55]).As expected, our CPU time is longer compared to the CPU time of the traditional methods (e.g. QP). For example, the execution of one generation of NSGA-II, when solving the mean-univariate GARCH VaR problem, lasted 41s. Hence, to execute 1000 generations of NSGA-II we needed 41,000s.3333In comparison, it took only 1s for the LP model to generate mean-historical VaR Pareto-optimal frontier consisting of 100 solutions.The total CPU time for mean-univariate GARCH VaR optimization with the QP solver was 424s.3434The mean-univariate GARCH VaR optimization (using multivariate GARCH VaR approach) consisted of three steps: (i) Determination of conditional variance–covariance matrix of individual returns (HT+1); (ii) Execution of QP solver; and (iii) Estimation of univariate GARCH VaR for each solution obtained by using QP solver. To determine conditional variance–covariance matrix 382seconds was needed. The execution of QP solver for Pareto optimal front of 100 solutions lasted 1second. Finally the estimation of univariate GARCH VaR, for 100 solutions obtained by using QP solver, lasted 41seconds.Our additional analysis, however, revealed that the NSGA-II CPU time could be shorter since the execution of 1000 generations was not always necessary. For example, for the mean-historical VaR optimization, 99% of final hypervolume was achieved after 50 generations (12s) in the Low volatility sample, and after 52 generations (12.5s) in the High volatility sample.3535We define final hypervolume as a hypervolume of Pareto-optimal set generated after 1000 generations.The same analysis applied on the mean-univariate GARCH VaR optimization revealed that 99% of final hypervolume was achieved after 40 generations (1640s) in the Low volatility sample. The corresponding values in the High volatility sample were 20 generations and 820s. Given its longer CPU time, the use of NSGA-II could be justified by its greater flexibility and ability to deal with more complex real-life portfolio optimization problems compared to the QP method (see [35]).Bank managers and regulators are interested in the out-of-sample performance of different optimization models. Thus, we compared out-of-sample performance of the different optimization models used in our study (seeFig. 5). The optimization dates for our High and Low volatility samples were dates with the highest (29 June 2012) and lowest (31 July 2013) volatilities. Based on the estimated portfolios on the optimization dates, we calculated respective mean and VaR values for dates which fall exactly 1 month later (30 July 2012 and 3 September 2013 respectively).The results of the out-of-sample analysis were consistent with the results reported in Fig. 4, thus confirming the superiority of estimates based on the mean-univariate GARCH model in both volatility samples. As expected, the differences between the results for the mean-univariate and mean-multivariate GARCH models are less pronounced in the Low volatility sample.

@&#CONCLUSIONS@&#
According to Basel regulation, the riskiness of a portfolio and the implied capital charge are calculated using VaR estimations of an actual portfolio of a financial institution (i.e. the portfolio that corresponds to current portfolio holdings). This paper proposes a novel approach to mean-VaR portfolio optimization within the actual portfolio framework when VaR is estimated by the analytical univariate GARCH VaR model with the assumption of a conditional t distribution of standardized portfolio returns. Due to the complexity of the proposed optimization problem, we applied metaheuristics. Specifically, we developed software which combined a NSGA-II multi-objective evolutionary algorithm with software for statistical computing R. In the empirical section, we examined the opportunity set consisting of 40 large US stocks belonging to the S&P 100 index in two volatility regimes. We found that the NSGA-II method resulted in better actual portfolio mean-historical VaR trade-offs in both Low and High volatility regimes.Next, we compared the mean-univariate GARCH VaR Pareto-optimal frontier to the mean-multivariate GARCH VaR and to the mean-historical VaR Pareto-optimal frontiers. In comparison to the two benchmarks, the proposed univariate GARCH VaR procedure, again, provided actual portfolios with a superior mean-univariate VaR frontier for both volatility samples. The results suggest that the multivariate GARCH modeling framework lacks flexibility to conform to the actual portfolio framework which is inherent in regulation. At the same time, the mean-historical VaR frontier provided the worst mean-univariate GARCH VaR trade-offs. Overall, our results bear two important implications for financial institutions and their regulators. First, the results highlighted differences between the actual portfolio approach and the approach based on the fixed weights. Second, the results show the importance of carefully selecting amongst different VaR methodologies used in portfolio optimization.Recently, some multiple criteria decision making (MCDM) tools were combined with NSGA-III to either rank or reduce the Pareto optimal frontier (see [56]). Further enhancement of our optimization approach with some of the MCDM reduction techniques could be an interesting area for future research.