@&#MAIN-TITLE@&#
Evaluating predictive performance of sensor configurations in wind studies around buildings

@&#HIGHLIGHTS@&#
This paper proposes metrics to estimate the expected predictive performance of sensor configurations.The metrics evaluate the robustness of sensor configurations with respect to reducing uncertainty of model predictions.The evaluations are based on the premise that measurement data are best used for falsifying model instances.Potential of the predictive performance metrics is demonstrated using full-scale high-rise buildings in Singapore.

@&#KEYPHRASES@&#
Computational fluid dynamics (CFD),System identification,Sensor configuration,Performance evaluation,Simulation prediction,

@&#ABSTRACT@&#
A great challenge associated with urban growth is to design for energy efficient and healthy built environments. Exploiting the potential for natural ventilation in buildings might improve pedestrian comfort and lower cooling loads, particularly in warm and tropical climates. As a result, predicting wind behavior around naturally ventilated buildings has become important and one of the most common prediction approaches is computational fluid dynamics (CFD) simulation. While accurate wind prediction is essential, simulation is complex and predictions are often inconsistent with field measurements. Discrepancies are due to the large uncertainties associated with modeling assumptions, as well as the high spatial and temporal climatic variability that influences sensor data. This paper proposes metrics to estimate the expected predictive performance of sensor configurations and assesses their usefulness in improving simulation predictions. The evaluations are based on the premise that measurement data are best used for falsifying model instances whose predictions are inconsistent with the data. The potential of the predictive performance metrics is demonstrated using full-scale high-rise buildings in Singapore. The metrics are applied to assess previously proposed sensor configurations. Results show that the performance metrics successfully evaluate the robustness of sensor configurations with respect to reducing uncertainty of wind predictions at other unmeasured locations.

@&#INTRODUCTION@&#
The continuous growth of the global population living in cities has increased interest in outdoor thermal comfort [1], air quality [2,3], safety [4], and particularly in warm climates, building energy consumption and natural ventilation [5]. The wind environment has a primary role in mitigating these issues and, consequently, improving knowledge of wind behavior around buildings has been the focus of much recent research work (a detailed review can be found in [6]). The most common approach for wind prediction is based on computational models, such as those used in computational fluid dynamics (CFD) simulations.Today, CFD simulations are used to overcome constraints of laboratory and field measurements [5], since they provide detailed information on wind flow and allow treatment of complex geometries with a high degree of repeatability. Although CFD simulations provide reasonable predictions, the accuracy is not superior to laboratory and field measurements [6]. Uncertainties are large in both modeling and measurements and should be taken into account [7].Tamura [8] and Schatzmann et al. [9] suggested that measurements, both laboratory and field, should be used in a complementary manner to ensure that simulation results are sound, even when using modeling methods of high predictability, such as the large eddy simulation (LES) [8]. However, the use of simplified arrays of roughness elements in laboratory measurements results in idealized representations of the parameters affecting wind flow [10], and it is often unclear how sensitive wind predictions are to these parameter uncertainties [11]. Moreover, certain physical phenomena, such as buoyancy-driven natural ventilation, cannot be fully represented in reduced-scale laboratory experiments [5].In these situations, field measurements are essential for ensuring that modeling is sound, especially in studies involving high-rise buildings [10,11]. Nevertheless, field measurements have been rare, and sensor placement still remains a challenging task [12]. Most of earlier studies have used historically measured data and only a few configured full-scale measurement campaigns [13–16]. In most cases, sensors locations have been selected based on educated guesses, although some researchers have investigated optimal sensor configurations using systematic and data-driven strategies [17–20]. Such strategies require prior knowledge of data distributions and spatial correlations, obtained from a denser pre-deployment of sensors, a task that is however both costly and time-intensive. A recent study in Singapore has used the concept of maximum entropy for sensor selection, in a similar way to [21], yet modeling and measurement data were assumed to be free of errors and sensor placement was performed iteratively, disregarding the mutual information content between sensor locations.All of these studies employed data from sensor locations placed outside the urban canopy, or on building rooftops, although reports on methods to obtain representative data suggest that, unless interested in topographic-generated climate patterns, sensor locations subject to local and mesoscale effects should be avoided and target measurement areas of acceptable homogeneity at screen-level (∼1.5m) or high-level (about the roughness sub-layer) should be selected [22]. Wind flow varies considerably over space and time and measurements within the urban canopy depend on the location of sensors and sampling frequency [23,24]. In addition, it has been shown [7] that even under steady ambient conditions, large discrepancies occur between measured and predicted values that are caused by low frequency variations of the wind flow.A recent study done by the authors explored systematic sensor placement strategies that are applicable to time-dependent wind prediction within the urban canopy, involving buildings of varying size and use [25]. The study adapted and compared sequential strategies and criteria used in the field of infrastructure diagnosis, which can achieve high levels of accuracy with low computational cost compared to global search strategies [26] and genetic algorithms [27]. The typical information-based criteria found in literature for optimal sensor configuration were information entropy [26–28], cost and expected identifiability [29], while some studies incorporated uncertainty correlations and their values [29,30]. Based on the conclusions of the authors’ initial study [25], a novel hierarchical sensor placement strategy has been developed that uses the concept of joint-entropy to account for the mutual information between sensor locations [31]. The strategy also explicitly incorporated the spatial distributions of modeling errors and their values, which has been shown to affect optimal sensor configuration [30–32].In conclusion, typical information-based criteria used for optimal sensor configuration focused primarily on increasing information value, measured either with entropy from information theory or using identifiability metrics to reduce parameter-value uncertainty. Nonetheless, earlier studies [33] have suggested that the performance of sensor configurations in reducing uncertainty of model predictions should be assessed by additional criteria, such as robustness-to-uncertainty and “prediction-looseness”—equivalent to the range of predictions—which are often conflicting.This paper proposes metrics to evaluate the predictive performance of sensor configurations and assess their usefulness in improving simulation predictions. The performance of the configurations is assessed for their capability to falsify multiple model instances whose predictions are inconsistent with the data (Section 2.1). Expected identifiability metrics found in literature [29] are adapted (Section 2.2) and then new metrics are developed (Section 2.3) to estimate the sensor configurations robustness-to-uncertainties associated with model predictions. In the end, a multi-criteria decision-making (MCDM) approach is proposed to evaluate the influence of the conflicting metrics on the choice of optimal sensor configuration (Section 2.4). In Section 3, the proposed metrics are applied to evaluate the performance of several hierarchically-constructed sensor configurations [31], in improving wind predictions around a full-scale building system in Singapore. A list of the main conclusions and a critical assessment on the results are provided in the final two sections (Sections 4 and 5).Metrics are developed to estimate the expected predictive performance of sensor configurations and assess their usefulness in improving predictions. The study builds upon previous work on sensor placement performed by the authors [25,31], where the premise is that sensor data are best used for falsifying multiple model instances1A specific combination of values for the input parameters in a CFD simulation and the corresponding wind predictions at all potential locations is one model instance.1whose predictions are inconsistent with the data. Therefore the performance of sensor configurations is assessed in terms of their capability to falsify multiple model instances (Section 2.1). First, expected identifiability metrics are adapted from literature to estimate the expected reduction in the number of candidate models (retained model instances) and in the prediction range associated with each sensor configuration (Section 2.2). Several optimal sensor configurations, which have been constructed using the hierarchical-sensor placement strategy, have been compared in [31]. Metrics are then developed to estimate the robustness of the sensor configurations to uncertainty associated with model predictions (Section 2.3). In the end, an MCDM approach is proposed to evaluate the influence of multiple metrics on the selection of optimal sensor configurations (Section 2.4).Falsification of multiple model instances is performed at each sensor location of the hierarchically-constructed sensor configurations using simulated measurements generated following the procedure described in [25]. As justified in these earlier studies done by the authors [31,25], the reason for employing simulated measurements is that the evaluations of sensor locations are done prior to measuring and therefore data at these sensor locations are not yet available. In addition, the performance of several sensor configurations needs to be evaluated and compared at the same time instant, which would require a costly pre-deployment of a large number of sensors.During falsification, multiple model instances are rejected if the difference between their predicted values and the measurements falls outside defined threshold bounds. These bounds correspond to confidence intervals that include plausible model instances. The interval width at each sensor location is equal to the prediction range, obtained from the model instances, and estimates of modeling and measurement errors.The term model instance refers to a computational model in which input parameters are assigned a definite combination of values and the corresponding values of output variables are predicted using simulation. The core of the methodology is the multiple-model approach introduced by Raphael and Smith [34].(1)P(∩i=1nmTlow,i⩽Uc,i⩽Thigh,i)whereφis the confidence level,Uc,iis obtained from by subtracting the modelingUmod,iand measurementUmeas,iuncertainty,Tlow,iandThigh,iare the computed threshold bounds equal to the minimum and maximum values of the combined modeling and measurement residuals, withnmthe number of measurements used.An illustration of the falsification process is shown in Fig. 1. The remaining model instances—called candidate models—are used to update the predictions at other, unmeasured, locations and enhance inference (more information on this process is available in [25,31]).Since optimal sensor configurations often include more than one sensor locations, model instances are evaluated multiple times. However, a complication arises when confidence intervals result from multiple testing, which is known as the inflation of the alpha level [35] The Šidák correction (Eq. (1)) is therefore employed to correct the alpha values,α=1-φ, for the threshold bounds in order to maintain a constant confidence levelφ=0.95. The Šidák correction has been successfully applied in the field of infrastructure diagnosis [29] to counteract the effect of the inflation of the alpha level during multiple hypothesis testing. This adjustment will affect the number of candidate models estimated after the sensor addition, since it corrects for the models instances that have been falsely rejected.(2)α′=1-(1-α)1/Nwhere N is the number of sensors.The expected number of candidate models obtained during model falsification is a trade-off between the number of sensor locations, the confidence level (related toα) and the threshold-bound width, which depends on measurement and modeling errors. This trade-off is quantified with the expected identifiability metrics described below.Expected identifiability metrics have been used in literature [29] to predict probabilistically to what extent a sensor configuration is useful in falsifying model instances. These metrics have been employed to select optimal sensor locations, whereas in this work they are adapted for evaluating the performance of existing sensor configurations in improving simulations predictions.The expected identifiability of configurations is calculated with respect to the expected number of candidate models and their range of predictions at unmeasured locations. Empirical cumulative distribution functions of the number of candidate models and prediction range are built for each sensor configuration using a sample set of simulated measurements. Two quantities are then extracted from the cumulative distributions, the maximum number of candidate models and the maximum prediction range. These quantities express the expected identifiability of the current sensor configuration and depend on the confidence level,φ(often fixed at 95%), the number of sensorsns, and modelingemodand measurement errorsemeas, since these define the width of the falsification thresholds.Fig. 2shows example cumulative distributions that are used to estimate the maximum number of candidate models, as a percentage of the initial-model-set size. Fig.2(a) represents the trade-off between the number of sensors,ns, and the level of confidence. Fig.2(b) represents the effect that variations in modeling error,emod, have on the expected maximum number of candidate models of a fixed configuration. The same example can be provided by displaying on the horizontal axis the prediction range as a percentage of the initial possible range. For a fixed confidence level of 95%, the expected maximum number of candidate models (or prediction range) decreases with an increase in the number of sensors(ns2>ns1)and with a decrease in modeling errors(emod2<emod1).Although expected identifiability metrics are useful for providing information on the performance of sensor configurations with respect to reducing the number or candidate models and the prediction ranges, they do not provide information on the success of the identification. This represents the number of correct predictions that are made at an unmeasured location using the information obtained from the current configuration. Such a metric evaluates the robustness of the configuration with respect to the uncertainty associated with predictions and is discussed in the following section.Model falsification is performed using threshold bounds that are equal to modeling and measurement uncertainties. Therefore, if modeling errors are misevaluated, there is a probability that a model is falsely rejected, a Type I error. This probability is estimated by counting the number of simulated measurements that fall outside the predicted range at an unmeasured location, signifying that a correct model instance has been wrongly rejected. On the other hand, the probability of falsely accepting a model instance, a Type II error, and is equal to the size of the candidate model set minus one—the correct model instance.The probability of a Type I and Type II error is calculated at an unmeasured location for each sensor configuration, in a similar manner to Section 2.2. The empirical cumulative distribution functions are used to extract the probability values of Type I and Type II error, as well as the prediction range (% of initial plausible range), for a 95% certainty. Fig.3(a), illustrates an example of the conflicting relationship between the probability of prediction error with the number of sensors in a configuration: more sensors decrease the number of models that are falsified (Type II), yet the chance of making false predictions (Type I errors) increases. There is however a number of sensors that provide an equal probability of committing either error. Similarly Fig.3(b) illustrates the expected maximum prediction range (as a percentage of the initial plausible range), with the number of sensors: the larger the number of sensors in the configuration the lower the range of predictions. However, the minimum range of predictions depends on the range of measurement data and is restricted by the range of modeling uncertainty. Overall, such metrics reveal the conflicting relationships between the probabilities of committing prediction errors and assess the robustness of sensor configurations to misevaluation of modeling uncertainties.In comparison with the metrics described in Section 2.2, the above robustness-to-uncertainty metrics are conflicting criteria to consider in an optimal sensor configuration problem. The following section proposes a multi-criteria decision making approach (MCDM) that allows assessment of the influence of these criteria on the selection of optimal sensor configurations.MCDM approaches are concerned with solving decision problems that typically involve multiple conflicting criteria. Therefore an optimal sensor placement problem can be treated with an MCDM approach to take into account the multiple, conflicting criteria that influence optimal sensor configuration.Table 1lists a set of 5 criteria that influence an optimal sensor placement problem based on the earlier studies. These criteria are ranked according to a decision maker’s preference on measurement objectives: minimize cost, reduce the range of predictions and the prediction errors (Type I and Type II), and maximize joint-entropy of predictions. Among these, cost conflicts with joint-entropy and prediction range, and Type I errors conflicts with Type II errors.The RR-Pareto3 algorithm (in improved version of RR-Pareto algorithm [36]) is used to identify a good compromise solution by first ordering the criteria according to their importance, normalizing the criteria-values and finally filtering through bisecting the range of values, one at a time and according to their order, until a unique solution is found. Fig. 4illustrates an example where the RR-Pareto3 algorithm is applied to assess the 5 criteria of Table 1 for 10 sensor configurations, in order to obtain a compromise configuration of 4 sensors.Typically in an MCDM problem there is no single optimal solution and a set of best compromise solutions is provided. This is illustrated with an example in Fig. 5, where the RR-Pareto3 algorithm recognized a set of 10 compromise optimal configurations, of 7–16 sensors, from the initial set of 60 configurations, with respect to the 5 criteria of Table 1. The decision maker can then decide using additional information on a single optimal configuration that meets the measurement needs.Often in wind studies several variables are measured with the same sensor configuration, such as wind speed and wind direction, which necessitates that a common configuration is found between these variables. A solution involves calculating criteria values for all possible sensor configurations and variables, and employing the RR-Pareto3 algorithm to find the best compromise solution among them. Such calculations however, have high computational costs that are related to the number of variables and criteria.In the presence of a decision maker’s preferences, the above MCDM problem can be solved in a hierarchical manner with low computational cost: first, variables are ranked in order of importance; then the RR-Pareto3 algorithm is employed to obtain a reduced set of compromise sensor configurations, from the initial set of optimal configurations, using the criteria values of the variable of highest importance (i.e. wind speed); this set of compromise configurations is used to recalculate the criteria values for the second variable in order (i.e. wind direction); the RR-Pareto3 algorithm is rerun to recognize a reduced set of compromise configurations that satisfy the measurement objectives for both variables. When applicable, additional variables or information are used to further reduce the number of compromise sensor configurations until a single optimal configuration is obtained.The predictive performance metrics for sensor configurations were applied to a full-scale residential estate, called Treelodge, which is located in Punggol, Singapore (Fig.6(a)). The estate consists of seven 16-story building blocks with an average height of 63m. Treelodge is Singapore’s first experimental ecofriendly public housing project [37].The experimental design for multiple CFD simulations is organized in a similar way to [25,31]: FLUENT 14.5 is used as a solver for the equations of flow behavior and the Design Exploration tool for sensitivity analysis and parameter selection.The geometric simplifications and assumptions related to the numerical methods that control the solver are made as follows:1.The geometries of the domain of interest consist of 7 building blocks with average dimensions 26×53×63m (Fig.6(b)). The orography of the area is assumed to be uniform and surface details of buildings are omitted.The entire size of the computational domain (or ABL domain) is 955m×1598m×504m (Fig.7(a)), according to recommendations available in literature [38,39].The CutCell Cartesian meshing is used as a discretization method to generate a predominantly hexahedral mesh with minimum user input (Fig.7(b)). After grid sensitivity analysis the minimal element size to 0.05m and the mesh growth rate to 1.175, generating 13.4×10e6 elements.The SIMPLE algorithm is employed to achieve pressure-velocity coupling.Second-order discretization is used as a pressure interpolation scheme.A single-precision solver is assumed to be sufficiently accurate for this study.The convergence criteria of the scaled residuals for all variables are set to 10−4.The multiple-model CFD simulation approach is applied to predict possible wind behavior around the Treelodge estate according to the following assumptions:1.RANS-equations are used to characterize wind behavior around buildings, the realizable k–ε equations to represent turbulence and the standard wall-functions to treat near-wall turbulence, since it is one of the most computationally efficient approaches to approximate turbulent flows.The inlet boundary conditions of wind speed are described in Eq. (2) and Eqs. (3) and (4) are used to calculate the TKE and TDE as functions of the varying wind speed profile at the inlet. The sand-grain roughness of the ABL domain and domain of interest are calculated using Eq. (5). Finally, the pressure at the outlet boundary is set to zero Gauge pressure.(3)U(z)=u∗lnz+z0z0κwhereU(z)is the wind speed at heightz,uis the atmospheric-boundary-layer friction (or shear) velocity,z0the surface roughness andκis the von Kármán constant.(4)k=u∗2Cμ,wherekis the turbulence kinetic energy andCμa model constant.(5)ε(z)=u∗3κ(z+z0)whereε(z)is the turbulence eddy dissipation at heightz.(6)ks,ABL=9.793z0CswhereCsis the roughness constant, set to satisfy the constraintks,ABL⩽zp, andzpis the grid resolution (the distance of the centroid of the wall-adjacent cell to the wall).In total 9 uncertain parameters are found related to the assumptions made in geometric simplifications, meshing and boundary conditions. Ranges of values for these parameters are found in the literature and are based on engineering judgment.The output variables of the simulations are the wind speed, referring to the magnitude of the horizontal component of the velocity vector, and the horizontal direction. Simulation predictions of wind speed and horizontal direction are obtained at 290 potential sensor locations, which are fixed at 3m height near the pedestrian eco-deck, which is the canyon separating the building blocks) (Fig. 8). Potential locations are selected remote from the buildings and distances are set taking into account the eco-deck length, the size of the measurement equipment and the orography of the domain of interest.Sensitivity analysis is then carried out in ANSYS Workbench 14.5 with design exploration tools in order to evaluate the parameter uncertainties on predictions and reduce computational cost. An Optimal Space-Filling design [40] with CCD sampling [41] is applied and Spearman’s rho correlation coefficient,ρj, is calculated from Eq. (6) for the 9 uncertain parameters and the output variables, wind speed and horizontal direction, at each potential sensor location shown in Fig. 8. Computational cost is reduced through selecting three of the uncertain parameters with the highestρj‾and Z-scores, averaged over all locations. These are the inlet wind speed, the inlet horizontal direction and the surface roughness of buildings, with coefficients 0.76, 0.4 and 0.1 and Z-scores 2.4, 1.3 and 0.23, respectively.(7)ρj=-∑k(xk,j-xj‾)(yk,j-yj‾)∑k(xk,j-xj‾)2(yk,j-yj‾)2wherexk,j,yk,jare the ranks of the input parameters and output variables respectively at each locationj∈{1,…,63}, withk=1,…,nthe size of the sample andxj‾,yj‾the mean values.Multiple simulations are the performed taking discrete values for the three parameters within plausible ranges shown in Table 2. The reduced number of parameters allows a simple-grid sampling with values selected uniformly within the ranges, with discretization intervals of 0.1m/s, 22.5deg and 0.25m. A set of 3648 combinations of parameter values is created and used to carry out CFD simulations. A discrete population of predictions of wind-speed and horizontal-direction at the 290 potential sensor locations (Fig. 8) is the output of the simulations that comprises the initial model set.The hierarchical sensor placement strategy using joint entropy [31] is applied to the initial model set in order to reveal optimal sensor configurations. Modeling and measurement errors are explicitly incorporated in the strategy, with measurement errors set to ±0.05m/s for wind speed and ±1deg for wind direction, while Eqs. (7) and (8) are used to define modeling errors with non-uniform spatial distribution for wind speed,emod,speedand wind direction,emod,dir. These equations are based on recent findings of the studies conducted by the Simulation-Platform research group at the Future Cities Laboratory. Simplifications are made similar to [42]:(8)emod,speed=[(-0.33U(z)-0.62),(0.34U(z)+0.86)],uj(z)U(z)<1[(-0.18U(z)-0.62),(0.12U(z)+0.84)],uj(z)U(z)⩾1(9)emod,dir={(1.18U(z)-65.06),(2.09U(z)+30.44)}:uj(z)U(z)⩾0.33whereuj(z)is the local wind speed at heightzat possible sensor locationsj∈{1,…,290}andU(z)is the wind speed that would occur without the presence of buildings. Wind-direction predictions with amplification factoruj(z)/U(z)<0.33are not considered since modeling errors are high (around ±180deg).Fig. 9shows a comparison of the calculated (a) joint-entropy in predictions and (b) maximum number of candidate models, of wind speed and horizontal direction during hierarchical sensor placement. Only the first 15 optimal locations are displayed in the graph, yet calculations over all 290 possible sensor locations are considered. An effect similar to [31] is observed, since joint entropy of wind-speed predictions is higher than that of wind-direction predictions, which have relatively low values. Fig. 10illustrates the maximum number of candidate models of wind speed and horizontal direction that is estimated during hierarchical sensor placement. The incremental reduction in the maximum number of candidate models flattens after selecting the 5th sensor for wind speed and the 3rd sensor for wind direction. This is equivalent to an incremental change in the number of models of less than 1%. At maximum 1/5 of the initial-model-set size of both wind speed and direction is retained using a configuration of five sensors.Fig. 11illustrates the optimal sensor configurations of the first 5 sensors for predicting (a) wind-speed and (b) wind-direction. As observed in earlier studies done in Singapore [25,31], the optimal locations for the two variables differ: wind-speed locations are selected uniformly within the canopy of buildings, while wind-direction locations are selected near the center and northeast part of the canopy.A measurement campaign was carried out by Shanshan Pan near Treelodge at Punggol [43], as part of research conducted by Nanyang Technological University and the Singapore-MIT Alliance for Research and Technology (SMART) Center for Environmental Sensing and Modeling (CENSAM), with support from the National Research Foundation and the Ministry of Education. Measurement data were recorded between February 24 to March 23, 2012, and August 28 to September 9, 2012 with nine sets of Vaisala WXT520 Weather transmitters and data loggers employed at ground level.Measurements at Punggol are used here to evaluate and compare the predictive performance of various sensor configurations. Out of the nine weather transmitters, six were used, since one was not in operation and two were in locations not modeled in CFD. One of the highest records of wind speed was observed on February 28, 2012 and the measured data (24h) were selected for evaluation in order to capture short-term variations in atmospheric boundary conditions and support the premise of negligible convective effects and isothermal conditions during modeling (Section 3.1). Sample distributions of simulated measurements were generated at all potential sensor locations shown in Fig. 8 based on field measurements, following the procedure described in [25,31].The sensor configurations constructed with the hierarchical strategy (Section 3.2) are evaluated for their predictive performance at a random unmeasured location near the northwest part of the canopy. The evaluation of each sensor configuration is done using the metrics described in Sections 2.2 and 2.3. The aim is to support a model-falsification approach to data interpretation (Section 2.1) and demonstrate the usefulness of the optimal configurations in improving simulation predictions.Fig. 13shows the relationship between the number of sensors and the probability of (a) the Type I and Type II prediction errors and (b) the expected prediction range of wind speed, for a 95% certainty. The probabilities of committing either error are equal when a configuration of twelve sensors is deployed. Type II errors are increased using fewer sensors, while with more sensors Type I errors are increased. When more than 12 sensors are deployed, a 55% refinement from the initial plausible range is expected and the predicted range is nearly 10% higher than the range of the measurements. Around 20% of this range is owed to modeling uncertainty and the remaining to parameter uncertainties. During sensor placement, a large reduction in prediction range occurs when the 5th, 8th, 9th and 13th sensors are deployed, yet none exceeds 10%. After the 13th sensor, the reduction rate drops steadily with the addition of sensors and converges toward the measurement range.Fig.14(a) shows the relationship between the number of sensors and the probability of Type I and Type II errors in predictions of wind direction, for 95% certainty. In contrast to wind speed predictions, the expected prediction range is not displayed since the range of measurements is almost 360deg due to the long duration of the measurement campaign (24h). Here, the probabilities of committing either error are diverging for all sensor configurations, signifying no sensor configuration is useful.Since Type II errors are considerably low and Type I errors large, even from the first sensor selected, it is evident that a large number of model instances are falsified and retained candidate models are not able to improve predictions at the unmeasured location. This location was randomly selected near the northwest part of the canopy, where values of wind speed predictions are low and modeling errors associated with wind direction are large. From Eq. (8), corresponding model instances of wind direction are not considered in the calculations.To cross-validate this finding, the procedure is repeated by randomly selecting another (unmeasured) location near the center-east side of the canopy, where values of wind-speed are high. Fig.14(b) shows the relationship between the number of sensors deployed and the probability of Type I and Type II errors in predictions of wind direction, for 95% certainty. Compared to the NW location, the predictive performance is better at the center-east location: the probabilities of committing either error are equal to almost 20% when five sensors are deployed. Type II errors are increased with fewer sensors, while adding sensors increases Type I errors. These results show that unlike wind-speed predictions, for the specific model-set, no sensor configuration is able to improve predictions of wind direction at low wind-speed regions where modeling errors are large.A comparison of the performance of the configuration of six sensors constructed with the hierarchical strategy is performed against the historical sensor configuration selected by Shanshan Pan (Fig. 12). Table 3shows the results of this comparison with respect to improving predictions of wind speed, at the randomly selected NW location. The three metrics used for comparison are Type I errors, Type II errors and prediction range. Both configurations achieved an equal refinement in the range of predictions, which is well above the measurement range of 46% (Fig. 13). However, the probabilities of prediction errors are larger using the historical configuration as compared to the configuration constructed with the hierarchical strategy: Type I errors are nearly 8 times larger, while Type II errors are increased around 30%.A multi-criteria decision-making (MCDM) approach is adopted to evaluate the influence of complementary and conflicting criteria on the choice of sensor configuration. The MCDM approach described in Section 2.4 is applied to the optimal sensor configurations constructed with the hierarchical strategy and the criteria evaluated are listed in Table 3.Fig. 15illustrates the evaluation of the five criteria using the RR-Pareto3 algorithm for wind-speed sensor configurations: (a) all sensor configurations and (b) the set of 31 compromise configurations of 12–42 sensors with respect to these criteria. Although no single optimal solution is found, this set of solutions is refined when the decision maker provides additional information. Such an example is shown in Fig.16(a) where the 31 compromise configurations are evaluated using only three criteria: range, cost and Type I errors. A reduced set of 6 compromise configurations, of 15–20 sensors is recognized with respect to these three criteria (Fig.16(b)). When the decision maker provides additional information, a single compromise configuration can be obtained that meets the measurement needs.In wind studies, however, it is often the case that more than one variable is measured with the same sensor configuration, such as wind speed and wind direction. As demonstrated in Section 3.2, the optimal sensor configurations can differ between these variables, which necessitates that a common configuration is found. In the presence of a decision maker’s preference, this problem can be solved using an MCDM approach in a hierarchical manner with less computational cost (Section 2.4).Firstly, the two variables, wind speed and wind direction are ordered according to their significance in measurement. Based on the earlier analysis (Section 3.3), it is not possible to predict wind direction with reasonable reliability and therefore it is assessed as a secondary variable of lesser significance, while wind speed is considered the variable of highest importance. The set of 6 compromise configurations for wind-speed predictions (Fig.16(b)), are employed to recalculate criteria values for the second variable, wind direction. The RR-Pareto algorithm is rerun to recognize the single compromise configuration that satisfies the measurement criteria for both wind speed and direction. Results are displayed in Fig. 17, with the criteria values (a) for wind-direction predictions and (b) for wind-speed predictions using the single compromise configuration of 17 sensors.

@&#CONCLUSIONS@&#
The main results of this study point to the following conclusions:1.Sensor locations configured using a hierarchical sensor placement strategy enhance wind predictions compared to a situation with no measurement.Predictive performance metrics evaluate the usefulness of sensor configurations prior to field measurements through calculating the expected accuracy and range of predictions at unmeasured locations.The usefulness of sensor configurations in improving predictions is influenced by modeling errors and depends on the variable and location of interest to predict.An MCDM approach to sensor placement identifies set of compromise sensor configurations that accounts for multiple and conflicting criteria, as well as the decision maker’s preferences.Solving an MCDM sensor-placement problem in a hierarchical manner identifies common optimal configurations between several variables of different significance.