@&#MAIN-TITLE@&#
A scalable architecture for geometric correction of multi-projector display systems

@&#HIGHLIGHTS@&#
Multi projector rendering allows immersive projection on large projection surfaces.Such multi projector schemes require dedicated GPU based systems to perform rendering.Our work proposes an embedded and standalone system for performing multi projector rendering.The system applied the geometric correction in real time without using LUTs.

@&#KEYPHRASES@&#
Immersive projection,Multi-projector displays,Panoramic displays,FPGA based rendering,

@&#ABSTRACT@&#
Multi-projector displays allow the realization of large and immersive projection environments by allowing the tiling of projections from multiple projectors. Such tiled displays require real time geometrical warping of the content that is being projected from each projector. This geometrical warping is a computationally intensive operation and is typically applied using high-end graphics processing units (GPUs) that are able to process a defined number of projector channels. Furthermore, this limits the applicability of such multi-projector display systems only to the content that is being generated using desktop based systems. In this paper we propose a platform independent FPGA based scalable hardware architecture for geometric correction of projected content that allows addition of each projector channel at a fractional increase in logic area. The proposed scheme provides real time correction of HD quality video streams and thus enables the use of this technology for embedded and standalone devices.

@&#INTRODUCTION@&#
Applications like home theater, gaming, remote collaboration, scientific visualization, and immersive human–computer interaction require life-size visual experience, so high resolution, large-scale and wide field-of-view displays are the requirements for such applications. Projector tiling is often used to increase the resolution and area of the projection surface. This is achieved by placing the projectors such that part of their projection overlaps with that of the neighboring projectors. The content to be projected is distributed across all the projectors and the content are geometrically corrected to account for the content alignment across the different projectors. Specifically, in the overlapping region between the two neighboring projectors, the contribution from each of the projector needs to be perfectly aligned. For perfect planar surfaces, this geometrical warping can be applied by using a set of linear equations in homogenous coordinates defined by the homography matrix [27,28]. However, many a times cylindrical or dome like projection surfaces are also employed to enhance the field-of-view along with immersive visual experience. On such surfaces the projected content are further distorted due to the particular shape and orientation of projection surface. For such surfaces homography alone cannot be used to perform the geometric correction and a higher order transformation is typically required. The most widely used such systems [1,3,4,7–10,13] make use of camera feedback for estimating this transformation in either 2D or 3D [6]. During a calibration phase some pre-defined patterns are projected and captured using the feedback camera. These captured images of the projected patterns provide an estimate of the distortion caused due to the projection surface and also provide a measure of the relative misalignment of the projectors. A geometric correction is then computed using the estimated misalignment information and applied during the rendering phase. Fig. 1(a) shows a basic multi-projector display system having two projectors. The content to be projected is fed to the projectors via a workstation equipped with a graphic processing unit (GPU). The GPU is responsible for applying the computed geometric correction on the corresponding content of each projector. Rather than computing the geometric correction in real time; the computed correction transformation is stored in the form of Look up Tables (LUTs) to allow real time rendering. The figure illustrates the benefit achieved as a result of application of geometric correction since the content from the two projectors are now aligned. The requirement of GPUs, for multi-projector displays, limits the use of this immersive technology to video content that is being generated from desktop PCs. Furthermore, most of the commercial projector alignment systems are platform dependent and are available for a particular operating system. Recently a few hardware based solutions have been proposed however they are either designed for lower resolutions and lower frame rates or they have limited capabilities [5,6,19] as discussed in Section 2. Thus, there is a need of platform independent standalone system that allows affordable multi-projector projection. In this paper we present a design for a standalone system that provides a novel scalable architecture for tiling multiple projectors on planar and quadratic projection surfaces for full HD resolution at 300 frames per second (fps). By carefully analyzing and optimizing the required transformation equations we are able to provide an architecture that allows addition of each additional projector channel at a fractional increase (13%) in the logic area overhead. The proposed hardware intercepts video feed coming from a PC, gaming console, or an embedded system, applies the required geometric correction, and then outputs the corrected video feed to an output. The architecture was tested by implementing it on a Virtex xc5vlx FPGA board. The paper is organized as follows. Section 2 provides the overview of the previous work done, both in the software domain and in the hardware domain. Section 3 presents the details of the proposed system and describes functionalities of its sub-modules. Section 4 evaluates the system performance in terms of resource utilization and timing achieved. Section 5 concludes the paper.Most of the prior work applies the computed geometric correction in software by making use of GPUs [1,3,4,7–10,13]. In such a scenario, a computer having graphics card performs the functions of splitting the video stream for multi projectors, calculating the correction parameters and finally correcting the images accordingly. A geometrically aware and self-configuring multi-projector system was proposed in Ref. [4]. It was proposed that each projector be coupled with a camera that will provide the feedback image to compute the required geometric correction. In order to apply the computed geometric correction, each projector was attached to a laptop having an ATI Radeon graphics card. A coordinate transform based approach is used for geometric correction in Ref. [1] for the construction of a panoramic projection system from four projectors, each having a resolution of 1024∗768. The system employs two AMD Opteron 2.19GHz CPUs and two Nvidia Quadro FX3400 GPUs. The proposed system requires a high end processor, a large memory, and can operate at the maximum rate of 24 fps. Furthermore, projectors can only be added by employing more CPUs and GPUs. One of the major issues of image correction is the handling of data, which was outlined in Ref. [2]. For a video stream with resolution of 1920×1080 at 90 fps, a continuous read and write access to RAM at the rate of over 1GBps is required. This is a further challenge for software based techniques, as the system has to run several other applications simultaneously.Schemes that perform geometric correction in dedicated hardware [5,6,17,19,26,27] allow platform independence and can also be employed for use cases such as embedded video consoles that do not provide software or operating system access to a multi projector rendering system. For such systems, most commonly used platform are Field Programmable Gate Arrays (FPGAs), which enable easy prototyping along with ability to introduce parallelism and pipelining. Furthermore, ASIC production is one step away from FPGA implementation. Standalone hardware systems apply the geometric correction either by making use of the LUTs or by implementing the correction transformation equations directly in hardware. Eadie et al. [5] provides two hardware based approaches: A run time approach in which the computation of the transformation polynomial is performed inside the FPGA, and an LUT based scheme in which the polynomials are evaluated offline and the computed transformation stored as LUT entries. They provided a comparison between the implementation using Pentium 4 and on FPGA using both the pipelined, and the non-pipelined variants of the two approaches. From the results, it was shown that the run time polynomial computation based approach is two times faster than the Pentium 4, 1.7GHz implementation. Furthermore, its pipelined implementation is approximately 50 times faster than the Pentium 4 implementation. Qiang [6] provided a standalone hardware system for barrel distortion correction that is one of the elementary geometric corrections. First of all, to get the radius and angle information, the cartesian coordinates are transformed into the polar coordinates. A pre-defined correction polynomial is then applied to calculate the corrected coordinates. Finally the corrected polar coordinates are transformed back to the cartesian coordinates and bilinear interpolation is performed to get the final output display. To achieve this, CORDIC [20] (COordinate Rotation DIgital Computer) was employed. N iterations of the CORDIC algorithm were unrolled, which add up to make a large critical path. The critical path delay introduced due to the unrolling of the CORDIC stages was minimized by adding pipeline stages. The paper concluded that the multiplier used in interpolator added up to make a significant combinational path, so pipeline stages were also introduced in the interpolator to increase the clock frequency. The proposed system can run at the frequencies up to 64MHz, and was tested for 80×80 images. However, the use of this system was limited to the barrel correction only.Biswal et. al. [17] proposed an architecture for affine transformation which can be employed for the geometric correction of projectors when projecting on planar walls. The proposed technique applies affine transformation at a rate of 540 fps for a 1920×1080 resolution. In their paper, an approach named as modified affine transform by pixel replication (MATPR) is proposed, in which the whole image is divided into 4 sub images and correction is applied to one pixel from each sub images in a parallel manner to reduce the computational effort. Assuming a frame resolution of 512×512; during the first cycle pixel values from locations (1, 1), (1, 257), (257, 1) and (257, 257) are required. Thus, the processing of frame cannot be initiated unless the contents at location (257, 257) are read. This requirement is unlike the typical video protocols (VGA, DVI) that acquire the data from top row to the bottom row in a sequential or raster scan manner. This requires memory for buffering of complete frame before processing and also after processing. For a higher resolution, it translates into a large memory and memory I/O overhead. Furtler et al. [26] proposed an architecture for geometric correction using FPGAs using LUT based approach. In this approach, the transform is applied offline and results are stored as pre-computed row and column addresses. The pre-computed row and column addresses are stored into an external memory and a multiport read/write interface is used to read or write into that memory. Multiple memory interface units and interpolation units are used, hence parallelism of FPGA is exploited and a higher throughput is achieved. To be able to use this scheme in a practical scenario, again the frame has to be either buffered before and after processing or the multiple I/O channels have to be converted to single I/O channels. If reduced to a single channel I/O system with no buffering most of the parallel logic becomes redundant since the parallel data will not be available.As highlighted the software based approaches do not provide platform independence while the hardware based solutions are either limited to simpler geometric transformations such as barrel or affine, or have limited frame rate or resolution. In this paper we provide a hardware architecture that provides the implementation of a Bezier based [23,24] geometric correction scheme that not only allows distortion free projection on non-planar surfaces but can also allow alignment of multiple projectors on such curved or planar surfaces. The scheme of Ref. [23] was chosen for its simplicity since it does not require camera calibration.In this section we provide the details of the proposed architecture for implementation of real time geometric correction for multi-projector displays using a Bezier based approach [23]. The scheme of Ref. [23] requires projection of pre-defined patterns consisting of 2D grid of control points of Bezier transformation on the surface. A feedback camera is used to capture the projected patterns. The distortion caused to the grid of control points is taken as an estimate of the geometric distortion caused by the projection surface and a 2D Bezier surface is fitted using the detected control points. This step is followed by estimation of an inverse Bezier surface that provides the correction for surface specific geometric correction. Using the four corner control points, a homography relation is also computed that provides the alignment across multiple neighboring projectors. Once the Bezier and homography corrections are estimated; both of these are applied during the run time stage. This paper relates with the design of the later run-time stage in which the Bezier based geometric correction is applied and assumes that the parameters of the Homography and Bezier transformation are already computed and provided to the proposed hardware module. Fig. 2provides a higher level design of the proposed architecture for run time geometric correction of projected content. The description of each of the modules of Fig. 2 is provided below.To keep the architecture independent of video I/O standard, there are two independent input and output unit. The input unit provides the interface to the common display interfaces such as DVI and HDMI. Two FIFOs in the form of ping-pong buffers have been implemented inside the input unit that receives the input from the DVI input port and temporarily buffers the frame data until it is written into the SRAM memory. This technique ensures that none of the pixel data is discarded while memory is busy for other purposes. Fig. 3(a) shows the architecture of input unit and Fig. 3(b) shows the read and write timings for both FIFOs. Memory Interface Unit (MIU) is responsible for generation of the addresses and the transfer of data between SRAM and other units of the system. A central controller unit coordinates across all the I/O and processing units. All the correction parameters that define the required transformation for geometric correction are provided to the system once via the configuration unit. A UART interface module is used to get the configuration file from the PC. UART interface module decodes the configuration file and stores the configuration into parameter registers. These parameters include system resolution, Bezier transform parameters and homography parameters. All these parameters are transferred to the Transformation Computation Unit (TCU) that is the heart of geometric correction system. The TCU generates the corrected row and column index corresponding to the current row and column indexes by applying homography and Bezier transformation. The output of TCU is used by MIU, as the read address of the memory. MIU reads the data from memory (SRAM) and stores it into an n Row Cache. An n Row Cache provides local caching of n rows for storing neighborhood pixel values and the value of n is provided via the configuration file. The motivation for storing only n neighboring rows arise from the observation that for most common cases the transformed coordinates require the interpolation of pixel intensity values from locations located within the neighborhood of the current coordinate. The n-row FIFO acts a cache for the data, hence reduces the read load on the memory. Interpolation Unit approximates the outgoing pixel value by applying bilinear interpolation in real time. Output Unit sends the corrected pixel data to the output video display. This system requires the buffering of complete video frame only once, and applies the correction and sends the geometrically corrected output in real time. A latency of only one frame is thus introduced by this system. The TCU and Interpolation units are discussed in detail below.TCU is used to generate the corrected row and column index. A two pass approach is used for the geometric correction [23]. In the first step homography matrix is applied to the row and column index. Homography is a linear relationship between the vector space of the projector and the vector space of the viewer. ConsideringPaas the original coordinates andHabas the homography transformation matrix, the new coordinatesPbare computed using the following equation in the homogenous coordinate system.(1)pb=HabpaThe scheme of Ref. [23] makes use of bi-cubic Bezier surfaces to model the distortion caused to projection due to the surface. The corrected indices (Pb) are thus further transformed using a 2D Bezier transformation. A 2D-Bezier patch in a parametric (a,c)-plane having degree (n,m) and can be considered as a composition of two independent parametric curves orthogonal to each other, and defined by (n+1)(m+1) control points. In this work, a 2nd order Bezier patch is used, thus the value of both ‘m’ and ‘n’ is 2 and a total of nine control points were used. For each pixel (k,l) of the output projector frame, its corresponding source (X(k,l),Y(k,l)) from the input video frame is computed as follows:(2)Y(k,l)=cp1,1ya2c2+2cp1,2ya2cd+cp1,3ya2d2+2cp2,1yabc2+4cp2,2yabcd+2cp2,3yabd2+cp3,1yb2c2+2cp3,2yb2cd+cp3,3yb2d2(3)X(k,l)=cp1,1xa2c2+2cp1,2xa2cd+cp1,3xa2d2+2cp2,1xabc2+4cp2,2xabcd+2cp2,3xabd2+cp3,1xb2c2+2cp3,2xb2cd+cp3,3xb2d2Here,a,b,canddare the parametric axes defined asa=y/ymax,b=1−a, andc=x/xmax,d=1−c. Here,Y(k,l) andX(k,l) represent the transformed coordinates as a result of homography and Bezier transformation. Thecpi,jxandcpi,jyare the x and y coordinates of the control points. Eqs. (2) and (3) is a computationally extensive transformation and its hardware implementation requires multipliers, adders and subtractors. Furthermore, addition of each additional projector channel shall require a replication of resources consumed for implementing Eqs. (2) and (3). Here we apply two novel optimizations that are applicable to not just the scheme of Ref. [23], rather they can be applied to any geometric transformation utilizing parametric coordinates.1.Firstly, with the help of substitutions and algebraic transformations a few multiplication operation are replaced by subtraction operations. Thus, by taking benefit of the dependability of parametersbanddonaandcrespectively, we can reduce the number of multipliers by using algebraic equalities and properties of binary numbering systems as(4)a2=(1-b)2=(1+b2)-2b={1′b1,b2}-{b,1′b0}Here, {} represent a concatenation operation and 0⩽b<1. Thus, onceb2is computed, computation ofa2just requires concatenation and subtraction operation. Similarly, the following simplifications may also be derived.(5)ab=(1-b)b=b-b2Thus, onceb2is computed, there is no multiplier required to compute the value ofab. Similarly,cdandc2can also be represented in the terms ofdandd2. Hence a total of 4 multiplication operations are converted into addition/subtraction operation, so there is a decrease in logic area.Secondly, since for any number of projectors the content being projected and the frames are synchronized, the value of parametersa,b,c and dfor each of these projector channels are same and hence they have identical values for terms likea2c2,a2cd,a2d2,…,b2d2in Eqs. (2) and (3). Only the values ofcpi,jxandcpi,jychange for each projector. Thus, regardless of the number of channels being added, the logic for computation of products of parametersa,b,canddneed not to be replicated rather only the logic for multiplication of these terms withcpi,jyandcpi,jyneeds to bee replicated.In the proposed architecture each TCU is tasked to compute the transformation of Eqs. (2) and (3). Each TCU comprises of multiple Coordinate Transformation Units (CTUs) that generate each of the corrected row or column index. Fig. 4provides the microarchitecture of the CTU that implements Eq. (2). Fixed-point format for each portion of the circuit is also labelled. A similar data path can be formed for implementation of Eq. (3). The figure also highlights the portion of CTU that needs not to be replicated for each additional projector channel. Thus the greyed, portion of the CTU needs to be implanted only once for the whole design while the rest of the CTU circuit (highlighted in light blue) needs to be replicated for each additional projector channel.The proposed architecture is aimed as a high throughout real time system and hence it requires processing of a single row and column within one cycle. To meet the requirement of single cycle, all the blocks of the CTU i.e. adders, subtractors and multipliers are made combinational. All the blocks add up and make a large combinational path of approximately 50ns. To improve upon the timing of circuit two optimizations were performed. Firstly, 4-stage pipelining was introduced within each CTU to reduce the combinational delay. In Fig. 4 dashed bold line shows the delay insertion points for the datapath. Hence the critical path delay is reduced to 17ns approximately. In Ref. [25], it is shown that iterations without any inter-dependence in a data flow can be unfolded to achieve higher throughput. A similar approach is adopted in this case. To reduce the time period further, for each projector’s TCU, four CTUs are organized in multiple input multiple output (MIMO) configuration to allow for parallel processing at a slower clock rate that is one-fourth of the original clock rate. Fig. 5shows the connectivity of CTUs and clock path. Thus, within 4 cycles of a 165MHz clock (DVI compatible) four transformed indices are computed. Finally to cater the clock domain crossing issues, a dual port asynchronous FIFO is used, which gets data from four CTUs at 41.25MHz and sends data out at original clock rate.TCU provides the corresponding source coordinate (X(k, l), Y(k, l)) for each display coordinate (k, l). However, the computed source coordinate may have a non-integer value and hence requires the content to be interpolated at that location. Bilinear implementation provides a balanced performance in terms of interpolation quality and the required computational effort [30] and hence selected for our design. It interpolates the pixel intensity value using the intensity values of the four neighbors (p11,p12,p21,p22) of the transformed location. The transformed coordinates computed by the TCU are sent to the MIU which ensures that its four nearest neighbors are placed in the n-row cache. The designed micro-architecture for bilinear interpolation is provided in Fig. 6. Here,fXandfYare the fractional parts of X(k, l) and Y(k, l) respectively. The fractional parts are used as input to the interpolator module to calculate the weights of the neighboring four pixels. The combinational multipliers, adder and subtractors are used in the design which add up to make a significant combination delay. Two pipeline stages are thus inserted to minimize the critical path delay caused by this block.

@&#CONCLUSIONS@&#
